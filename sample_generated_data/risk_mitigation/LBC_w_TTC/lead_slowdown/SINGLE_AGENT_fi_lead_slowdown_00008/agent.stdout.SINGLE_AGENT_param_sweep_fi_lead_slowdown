New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190739-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190739-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190739-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190739-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190739-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190739-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 41.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 41}
1.4823663346469402 seconds in game passed.
Action: tensor([[[0.0032, 0.5918],
         [0.0022, 0.3304],
         [0.0020, 0.2343],
         [0.0013, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002928, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5073663350194693 seconds in game passed.
Action: tensor([[[0.0032, 0.5918],
         [0.0022, 0.3304],
         [0.0020, 0.2343],
         [0.0013, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5323663353919983 seconds in game passed.
Action: tensor([[[0.0032, 0.5918],
         [0.0022, 0.3304],
         [0.0020, 0.2343],
         [0.0013, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5573663357645273 seconds in game passed.
Action: tensor([[[0.0032, 0.5918],
         [0.0022, 0.3304],
         [0.0020, 0.2343],
         [0.0013, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5823663361370564 seconds in game passed.
Action: tensor([[[0.0032, 0.5918],
         [0.0022, 0.3304],
         [0.0020, 0.2343],
         [0.0013, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6073663365095854 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003853, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.6323663368821144 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003689, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6573663372546434 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6823663376271725 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003775, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7073663379997015 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7323663383722305 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7573663387447596 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7823663391172886 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8073663394898176 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8323663398623466 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002622, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8573663402348757 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002649, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8823663406074047 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9073663409799337 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9323663413524628 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9573663417249918 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9823663420975208 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.00736634247005 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4404e-03, 5.9047e-01],
         [1.3295e-03, 3.2230e-01],
         [1.1019e-03, 2.2210e-01],
         [5.5908e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.032366342842579 seconds in game passed.
Action: tensor([[[2.4404e-03, 5.9047e-01],
         [1.3295e-03, 3.2230e-01],
         [1.1019e-03, 2.2210e-01],
         [5.5908e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.057366343215108 seconds in game passed.
Action: tensor([[[2.4404e-03, 5.9047e-01],
         [1.3295e-03, 3.2230e-01],
         [1.1019e-03, 2.2210e-01],
         [5.5908e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.082366343587637 seconds in game passed.
Action: tensor([[[2.4404e-03, 5.9047e-01],
         [1.3295e-03, 3.2230e-01],
         [1.1019e-03, 2.2210e-01],
         [5.5908e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.107366343960166 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.132366344332695 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.157366344705224 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.182366345077753 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.207366345450282 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.232366345822811 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.25736634619534 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.282366346567869 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.307366346940398 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.3323663473129272 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3573663476854563 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3823663480579853 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.4073663484305143 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4323663488030434 seconds in game passed.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002719, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4573663491755724 seconds in game passed.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002740, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4823663495481014 seconds in game passed.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5073663499206305 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5887],
         [0.0015, 0.3217],
         [0.0013, 0.2217],
         [0.0006, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5323663502931595 seconds in game passed.
Action: tensor([[[0.0019, 0.5887],
         [0.0015, 0.3217],
         [0.0013, 0.2217],
         [0.0006, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5573663506656885 seconds in game passed.
Action: tensor([[[0.0019, 0.5887],
         [0.0015, 0.3217],
         [0.0013, 0.2217],
         [0.0006, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5823663510382175 seconds in game passed.
Action: tensor([[[0.0019, 0.5887],
         [0.0015, 0.3217],
         [0.0013, 0.2217],
         [0.0006, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6073663514107466 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002654, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6323663517832756 seconds in game passed.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6573663521558046 seconds in game passed.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6823663525283337 seconds in game passed.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7073663529008627 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.7323663532733917 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7573663536459208 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.78236635401845 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.807366354390979 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.832366354763508 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.857366355136037 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.882366355508566 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.907366355881095 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.932366356253624 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.957366356626153 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.982366356998682 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.007366357371211 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.03236635774374 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.057366358116269 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.082366358488798 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.107366358861327 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.132366359233856 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1573663596063852 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1823663599789143 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.2073663603514433 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.2323663607239723 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2573663610965014 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2823663614690304 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3073663618415594 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3323663622140884 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3573663625866175 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3823663629591465 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4073663633316755 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4323663637042046 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4573663640767336 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4823663644492626 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5073663648217916 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5323663651943207 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5573663655668497 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5823663659393787 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6073663663119078 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002420, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.632366366684437 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.657366367056966 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.682366367429495 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.707366367802024 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.732366368174553 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.757366368547082 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.782366368919611 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.80736636929214 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.832366369664669 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.857366370037198 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.882366370409727 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.907366370782256 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.932366371154785 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.957366371527314 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.982366371899843 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.007366372272372 seconds in game passed.
At 4.007366372272372 seconds, saving state-action tuples.
Action: tensor([[[1.4127e-03, 5.8610e-01],
         [1.1319e-03, 3.2068e-01],
         [9.9576e-04, 2.2101e-01],
         [3.4234e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.032366372644901 seconds in game passed.
Action: tensor([[[1.4127e-03, 5.8610e-01],
         [1.1319e-03, 3.2068e-01],
         [9.9576e-04, 2.2101e-01],
         [3.4234e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.05736637301743 seconds in game passed.
Action: tensor([[[1.4127e-03, 5.8610e-01],
         [1.1319e-03, 3.2068e-01],
         [9.9576e-04, 2.2101e-01],
         [3.4234e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.082366373389959 seconds in game passed.
Action: tensor([[[1.4127e-03, 5.8610e-01],
         [1.1319e-03, 3.2068e-01],
         [9.9576e-04, 2.2101e-01],
         [3.4234e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.883738821806649
4.107366373762488 seconds in game passed.
At 4.107366373762488 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.65612528475237
4.132366374135017 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
4.157366374507546 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 0.65612528475237
4.1823663748800755 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
+++++++++++++: 8.843383999601484
4.2073663752526045 seconds in game passed.
At 4.2073663752526045 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383999601484
Current reward: 0.49259322239340864
Current mitigation activation: 0
#############################
Total reward: 1.1487185071457786
4.2323663756251335 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.2573663759976625 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.282366376370192 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
+++++++++++++: 7.228547872515916
4.307366376742721 seconds in game passed.
At 4.307366376742721 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228547872515916
Current reward: 0.5118171203336291
Current mitigation activation: 0
#############################
Total reward: 1.6605356274794079
4.33236637711525 seconds in game passed.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
4.357366377487779 seconds in game passed.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
4.382366377860308 seconds in game passed.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
+++++++++++++: 6.215940449165687
4.407366378232837 seconds in game passed.
At 4.407366378232837 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.215940449165687
Current reward: 0.5264941677236088
Current mitigation activation: 0
#############################
Total reward: 2.1870297952030167
4.432366378605366 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
4.457366378977895 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
4.482366379350424 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
+++++++++++++: 5.508366078862486
4.507366379722953 seconds in game passed.
At 4.507366379722953 seconds, saving state-action tuples.
Action: tensor([[[-1.0351e-04,  5.8859e-01],
         [ 1.6709e-04,  3.2199e-01],
         [ 2.8673e-04,  2.2120e-01],
         [-9.4943e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508366078862486
Current reward: 0.5376235138087542
Current mitigation activation: 0
#############################
Total reward: 2.724653309011771
4.532366380095482 seconds in game passed.
Action: tensor([[[-1.0351e-04,  5.8859e-01],
         [ 1.6709e-04,  3.2199e-01],
         [ 2.8673e-04,  2.2120e-01],
         [-9.4943e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
4.557366380468011 seconds in game passed.
Action: tensor([[[-1.0351e-04,  5.8859e-01],
         [ 1.6709e-04,  3.2199e-01],
         [ 2.8673e-04,  2.2120e-01],
         [-9.4943e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000878, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
4.58236638084054 seconds in game passed.
Action: tensor([[[-1.0351e-04,  5.8859e-01],
         [ 1.6709e-04,  3.2199e-01],
         [ 2.8673e-04,  2.2120e-01],
         [-9.4943e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
+++++++++++++: 4.97613284310945
4.607366381213069 seconds in game passed.
At 4.607366381213069 seconds, saving state-action tuples.
Action: tensor([[[ 2.7198e-04,  5.8914e-01],
         [-3.1357e-04,  3.2137e-01],
         [-2.2316e-04,  2.2104e-01],
         [-3.8922e-04,  1.6752e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.97613284310945
Current reward: 0.5459292759962195
Current mitigation activation: 0
#############################
Total reward: 3.2705825850079906
4.632366381585598 seconds in game passed.
Action: tensor([[[ 2.7198e-04,  5.8914e-01],
         [-3.1357e-04,  3.2137e-01],
         [-2.2316e-04,  2.2104e-01],
         [-3.8922e-04,  1.6752e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825850079906
4.657366381958127 seconds in game passed.
Action: tensor([[[ 2.7198e-04,  5.8914e-01],
         [-3.1357e-04,  3.2137e-01],
         [-2.2316e-04,  2.2104e-01],
         [-3.8922e-04,  1.6752e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825850079906
4.682366382330656 seconds in game passed.
Action: tensor([[[ 2.7198e-04,  5.8914e-01],
         [-3.1357e-04,  3.2137e-01],
         [-2.2316e-04,  2.2104e-01],
         [-3.8922e-04,  1.6752e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825850079906
+++++++++++++: 4.552591376135179
4.707366382703185 seconds in game passed.
At 4.707366382703185 seconds, saving state-action tuples.
Action: tensor([[[-2.5138e-04,  5.9080e-01],
         [-9.4093e-04,  3.2156e-01],
         [-8.1411e-04,  2.2111e-01],
         [-9.4453e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552591376135179
Current reward: 0.5519989175021012
Current mitigation activation: 0
#############################
Total reward: 3.8225815025100918
4.732366383075714 seconds in game passed.
Action: tensor([[[-2.5138e-04,  5.9080e-01],
         [-9.4093e-04,  3.2156e-01],
         [-8.1411e-04,  2.2111e-01],
         [-9.4453e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000001, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225815025100918
4.757366383448243 seconds in game passed.
Action: tensor([[[-2.5138e-04,  5.9080e-01],
         [-9.4093e-04,  3.2156e-01],
         [-8.1411e-04,  2.2111e-01],
         [-9.4453e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225815025100918
4.782366383820772 seconds in game passed.
Action: tensor([[[-2.5138e-04,  5.9080e-01],
         [-9.4093e-04,  3.2156e-01],
         [-8.1411e-04,  2.2111e-01],
         [-9.4453e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225815025100918
+++++++++++++: 4.199611186046198
4.807366384193301 seconds in game passed.
At 4.807366384193301 seconds, saving state-action tuples.
Action: tensor([[[ 5.4795e-04,  5.9008e-01],
         [-5.7681e-04,  3.2162e-01],
         [-4.5140e-04,  2.2128e-01],
         [-4.8167e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199611186046198
Current reward: 0.5563326768472109
Current mitigation activation: 0
#############################
Total reward: 4.378914179357302
4.83236638456583 seconds in game passed.
Action: tensor([[[ 5.4795e-04,  5.9008e-01],
         [-5.7681e-04,  3.2162e-01],
         [-4.5140e-04,  2.2128e-01],
         [-4.8167e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914179357302
4.857366384938359 seconds in game passed.
Action: tensor([[[ 5.4795e-04,  5.9008e-01],
         [-5.7681e-04,  3.2162e-01],
         [-4.5140e-04,  2.2128e-01],
         [-4.8167e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914179357302
4.882366385310888 seconds in game passed.
Action: tensor([[[ 5.4795e-04,  5.9008e-01],
         [-5.7681e-04,  3.2162e-01],
         [-4.5140e-04,  2.2128e-01],
         [-4.8167e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914179357302
+++++++++++++: 3.8947631908725375
4.907366385683417 seconds in game passed.
At 4.907366385683417 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5879],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.8947631908725375
Current reward: 0.5593082190793719
Current mitigation activation: 0
#############################
Total reward: 4.938222398436674
4.932366386055946 seconds in game passed.
Action: tensor([[[0.0016, 0.5879],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222398436674
4.957366386428475 seconds in game passed.
Action: tensor([[[0.0016, 0.5879],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222398436674
4.982366386801004 seconds in game passed.
Action: tensor([[[0.0016, 0.5879],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222398436674
+++++++++++++: 3.6246755571702436
5.007366387173533 seconds in game passed.
At 5.007366387173533 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2673e-03, 5.8988e-01],
         [1.0552e-03, 3.2205e-01],
         [9.1553e-04, 2.2280e-01],
         [5.5947e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6246755571702436
Current reward: 0.5611771359376196
Current mitigation activation: 0
#############################
Total reward: 5.4993995343742945
5.0323663875460625 seconds in game passed.
Action: tensor([[[1.2673e-03, 5.8988e-01],
         [1.0552e-03, 3.2205e-01],
         [9.1553e-04, 2.2280e-01],
         [5.5947e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993995343742945
5.0573663879185915 seconds in game passed.
Action: tensor([[[1.2673e-03, 5.8988e-01],
         [1.0552e-03, 3.2205e-01],
         [9.1553e-04, 2.2280e-01],
         [5.5947e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993995343742945
5.0823663882911205 seconds in game passed.
Action: tensor([[[1.2673e-03, 5.8988e-01],
         [1.0552e-03, 3.2205e-01],
         [9.1553e-04, 2.2280e-01],
         [5.5947e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993995343742945
+++++++++++++: 3.380484844102797
5.10736638866365 seconds in game passed.
At 5.10736638866365 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5875],
         [0.0021, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380484844102797
Current reward: 0.5621374910415209
Current mitigation activation: 0
#############################
Total reward: 6.061537025415816
5.132366389036179 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0021, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537025415816
5.157366389408708 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0021, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537025415816
5.182366389781237 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0021, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002390, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537025415816
+++++++++++++: 3.1565713071109585
5.207366390153766 seconds in game passed.
At 5.207366390153766 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1565713071109585
Current reward: 0.5623126484668874
Current mitigation activation: 0
#############################
Total reward: 6.623849673882703
5.232366390526295 seconds in game passed.
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849673882703
5.257366390898824 seconds in game passed.
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849673882703
5.282366391271353 seconds in game passed.
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849673882703
+++++++++++++: 2.9489508795530655
5.307366391643882 seconds in game passed.
At 5.307366391643882 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5890],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9489508795530655
Current reward: 0.5617968510831078
Current mitigation activation: 0
#############################
Total reward: 7.1856465249658115
5.332366392016411 seconds in game passed.
Action: tensor([[[0.0023, 0.5890],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1856465249658115
5.35736639238894 seconds in game passed.
Action: tensor([[[0.0023, 0.5890],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1856465249658115
5.382366392761469 seconds in game passed.
Action: tensor([[[0.0023, 0.5890],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1856465249658115
+++++++++++++: 2.7880681870539696
5.407366393133998 seconds in game passed.
At 5.407366393133998 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.8882e-04,  5.8830e-01],
         [ 8.3268e-05,  3.2098e-01],
         [-8.4743e-05,  2.2108e-01],
         [-3.9043e-04,  1.6782e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7880681870539696
Current reward: 0.557529023973091
Current mitigation activation: 0
#############################
Total reward: 7.743175548938902
5.432366393506527 seconds in game passed.
Action: tensor([[[ 8.8882e-04,  5.8830e-01],
         [ 8.3268e-05,  3.2098e-01],
         [-8.4743e-05,  2.2108e-01],
         [-3.9043e-04,  1.6782e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175548938902
5.457366393879056 seconds in game passed.
Action: tensor([[[ 8.8882e-04,  5.8830e-01],
         [ 8.3268e-05,  3.2098e-01],
         [-8.4743e-05,  2.2108e-01],
         [-3.9043e-04,  1.6782e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175548938902
5.482366394251585 seconds in game passed.
Action: tensor([[[ 8.8882e-04,  5.8830e-01],
         [ 8.3268e-05,  3.2098e-01],
         [-8.4743e-05,  2.2108e-01],
         [-3.9043e-04,  1.6782e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175548938902
+++++++++++++: 2.691322903482139
5.507366394624114 seconds in game passed.
At 5.507366394624114 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5933],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.691322903482139
Current reward: 0.5472019808242039
Current mitigation activation: 0
#############################
Total reward: 8.290377529763106
5.532366394996643 seconds in game passed.
Action: tensor([[[-0.0010,  0.5933],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377529763106
5.557366395369172 seconds in game passed.
Action: tensor([[[-0.0010,  0.5933],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377529763106
5.582366395741701 seconds in game passed.
Action: tensor([[[-0.0010,  0.5933],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377529763106
+++++++++++++: 2.5950276115538995
5.60736639611423 seconds in game passed.
At 5.60736639611423 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003161, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5950276115538995
Current reward: 0.536827996552327
Current mitigation activation: 0
#############################
Total reward: 8.827205526315433
5.632366396486759 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205526315433
5.657366396859288 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205526315433
5.682366397231817 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002962, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205526315433
+++++++++++++: 2.498633208803452
5.707366397604346 seconds in game passed.
At 5.707366397604346 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0051,  0.2219],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.498633208803452
Current reward: 0.5264624727682432
Current mitigation activation: 0
#############################
Total reward: 9.353667999083676
5.732366397976875 seconds in game passed.
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0051,  0.2219],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667999083676
5.757366398349404 seconds in game passed.
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0051,  0.2219],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667999083676
5.782366398721933 seconds in game passed.
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0051,  0.2219],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667999083676
+++++++++++++: 2.402219182009931
5.807366399094462 seconds in game passed.
At 5.807366399094462 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6781e-04,  5.9092e-01],
         [-7.6393e-04,  3.2175e-01],
         [-7.9640e-04,  2.2138e-01],
         [-9.8787e-04,  1.6806e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.402219182009931
Current reward: 0.5160983110892772
Current mitigation activation: 0
#############################
Total reward: 9.869766310172952
5.832366399466991 seconds in game passed.
Action: tensor([[[-1.6781e-04,  5.9092e-01],
         [-7.6393e-04,  3.2175e-01],
         [-7.9640e-04,  2.2138e-01],
         [-9.8787e-04,  1.6806e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869766310172952
5.8573663998395205 seconds in game passed.
Action: tensor([[[-1.6781e-04,  5.9092e-01],
         [-7.6393e-04,  3.2175e-01],
         [-7.9640e-04,  2.2138e-01],
         [-9.8787e-04,  1.6806e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869766310172952
5.8823664002120495 seconds in game passed.
Action: tensor([[[-1.6781e-04,  5.9092e-01],
         [-7.6393e-04,  3.2175e-01],
         [-7.9640e-04,  2.2138e-01],
         [-9.8787e-04,  1.6806e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869766310172952
+++++++++++++: 2.2737360377691105
5.9073664005845785 seconds in game passed.
At 5.9073664005845785 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1697e-06,  5.9305e-01],
         [ 2.0850e-04,  3.2258e-01],
         [ 2.5392e-04,  2.2190e-01],
         [-1.0684e-04,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2737360377691105
Current reward: 0.5093359059676834
Current mitigation activation: 0
#############################
Total reward: 10.379102216140636
5.9323664009571075 seconds in game passed.
Action: tensor([[[-1.1697e-06,  5.9305e-01],
         [ 2.0850e-04,  3.2258e-01],
         [ 2.5392e-04,  2.2190e-01],
         [-1.0684e-04,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379102216140636
5.957366401329637 seconds in game passed.
Action: tensor([[[-1.1697e-06,  5.9305e-01],
         [ 2.0850e-04,  3.2258e-01],
         [ 2.5392e-04,  2.2190e-01],
         [-1.0684e-04,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379102216140636
5.982366401702166 seconds in game passed.
Action: tensor([[[-1.1697e-06,  5.9305e-01],
         [ 2.0850e-04,  3.2258e-01],
         [ 2.5392e-04,  2.2190e-01],
         [-1.0684e-04,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379102216140636
+++++++++++++: 2.0694043099203983
6.007366402074695 seconds in game passed.
At 6.007366402074695 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0694043099203983
Current reward: 0.5122398980536316
Current mitigation activation: 0
#############################
Total reward: 10.891342114194266
6.032366402447224 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.873568, steer=0.003273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891342114194266
6.057366402819753 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.820737, steer=0.003301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891342114194266
6.082366403192282 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.769077, steer=0.003328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891342114194266
+++++++++++++: 1.8865394064069507
6.107366403564811 seconds in game passed.
At 6.107366403564811 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6214],
         [0.0024, 0.3400],
         [0.0020, 0.2340],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.473864, steer=0.001978, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865394064069507
Current reward: 0.5134810325735318
Current mitigation activation: 0
#############################
Total reward: 11.404823146767798
6.13236640393734 seconds in game passed.
Action: tensor([[[0.0020, 0.6214],
         [0.0024, 0.3400],
         [0.0020, 0.2340],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.448123, steer=0.002207, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404823146767798
6.157366404309869 seconds in game passed.
Action: tensor([[[0.0020, 0.6214],
         [0.0024, 0.3400],
         [0.0020, 0.2340],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.398749, steer=0.002210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404823146767798
6.182366404682398 seconds in game passed.
Action: tensor([[[0.0020, 0.6214],
         [0.0024, 0.3400],
         [0.0020, 0.2340],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.362541, steer=0.002213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404823146767798
+++++++++++++: 1.7242683868610946
6.207366405054927 seconds in game passed.
At 6.207366405054927 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.1852e-04,  6.3533e-01],
         [-3.4131e-05,  3.4378e-01],
         [-7.3186e-04,  2.3577e-01],
         [-1.8214e-03,  1.8006e-01]]])
agent 0 action: VehicleControl(throttle=0.352418, steer=-0.000155, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7242683868610946
Current reward: 0.5125423661375073
Current mitigation activation: 0
#############################
Total reward: 11.917365512905306
6.232366405427456 seconds in game passed.
Action: tensor([[[ 6.1852e-04,  6.3533e-01],
         [-3.4131e-05,  3.4378e-01],
         [-7.3186e-04,  2.3577e-01],
         [-1.8214e-03,  1.8006e-01]]])
agent 0 action: VehicleControl(throttle=0.339805, steer=0.000213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917365512905306
6.257366405799985 seconds in game passed.
Action: tensor([[[ 6.1852e-04,  6.3533e-01],
         [-3.4131e-05,  3.4378e-01],
         [-7.3186e-04,  2.3577e-01],
         [-1.8214e-03,  1.8006e-01]]])
agent 0 action: VehicleControl(throttle=0.327610, steer=0.000189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917365512905306
6.282366406172514 seconds in game passed.
Action: tensor([[[ 6.1852e-04,  6.3533e-01],
         [-3.4131e-05,  3.4378e-01],
         [-7.3186e-04,  2.3577e-01],
         [-1.8214e-03,  1.8006e-01]]])
agent 0 action: VehicleControl(throttle=0.315829, steer=0.000166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917365512905306
+++++++++++++: 1.588756175328624
6.307366406545043 seconds in game passed.
At 6.307366406545043 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6533],
         [-0.0007,  0.3517],
         [-0.0018,  0.2412],
         [-0.0030,  0.1841]]])
agent 0 action: VehicleControl(throttle=0.304841, steer=-0.000135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.588756175328624
Current reward: 0.507572458020269
Current mitigation activation: 0
#############################
Total reward: 12.424937970925575
6.332366406917572 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6533],
         [-0.0007,  0.3517],
         [-0.0018,  0.2412],
         [-0.0030,  0.1841]]])
agent 0 action: VehicleControl(throttle=0.294263, steer=-0.000121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424937970925575
6.357366407290101 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6533],
         [-0.0007,  0.3517],
         [-0.0018,  0.2412],
         [-0.0030,  0.1841]]])
agent 0 action: VehicleControl(throttle=0.283638, steer=-0.000153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424937970925575
6.38236640766263 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6533],
         [-0.0007,  0.3517],
         [-0.0018,  0.2412],
         [-0.0030,  0.1841]]])
agent 0 action: VehicleControl(throttle=0.272987, steer=-0.000184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424937970925575
+++++++++++++: 1.477466502831155
6.407366408035159 seconds in game passed.
At 6.407366408035159 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.6664],
         [-0.0050,  0.3559],
         [-0.0064,  0.2424],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.262233, steer=-0.004539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.477466502831155
Current reward: 0.49817939941110334
Current mitigation activation: 0
#############################
Total reward: 12.923117370336678
6.432366408407688 seconds in game passed.
Action: tensor([[[-0.0017,  0.6664],
         [-0.0050,  0.3559],
         [-0.0064,  0.2424],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.251460, steer=-0.003871, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923117370336678
6.457366408780217 seconds in game passed.
Action: tensor([[[-0.0017,  0.6664],
         [-0.0050,  0.3559],
         [-0.0064,  0.2424],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.240668, steer=-0.003921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923117370336678
6.482366409152746 seconds in game passed.
Action: tensor([[[-0.0017,  0.6664],
         [-0.0050,  0.3559],
         [-0.0064,  0.2424],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.229857, steer=-0.003971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923117370336678
+++++++++++++: 1.381256360083202
6.507366409525275 seconds in game passed.
At 6.507366409525275 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6435e-04,  6.8300e-01],
         [-3.3248e-03,  3.6533e-01],
         [-4.6713e-03,  2.5026e-01],
         [-5.6231e-03,  1.9075e-01]]])
agent 0 action: VehicleControl(throttle=0.219105, steer=-0.002146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.381256360083202
Current reward: 0.48566949611736654
Current mitigation activation: 0
#############################
Total reward: 13.408786866454045
6.532366409897804 seconds in game passed.
Action: tensor([[[-1.6435e-04,  6.8300e-01],
         [-3.3248e-03,  3.6533e-01],
         [-4.6713e-03,  2.5026e-01],
         [-5.6231e-03,  1.9075e-01]]])
agent 0 action: VehicleControl(throttle=0.208334, steer=-0.002458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408786866454045
6.557366410270333 seconds in game passed.
Action: tensor([[[-1.6435e-04,  6.8300e-01],
         [-3.3248e-03,  3.6533e-01],
         [-4.6713e-03,  2.5026e-01],
         [-5.6231e-03,  1.9075e-01]]])
agent 0 action: VehicleControl(throttle=0.197545, steer=-0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408786866454045
6.582366410642862 seconds in game passed.
Action: tensor([[[-1.6435e-04,  6.8300e-01],
         [-3.3248e-03,  3.6533e-01],
         [-4.6713e-03,  2.5026e-01],
         [-5.6231e-03,  1.9075e-01]]])
agent 0 action: VehicleControl(throttle=0.186737, steer=-0.002472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408786866454045
+++++++++++++: 1.2938706522769354
6.607366411015391 seconds in game passed.
At 6.607366411015391 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-4.6801e-04,  1.0000e+00],
         [-4.7553e-03,  1.0000e+00],
         [-5.9439e-03,  1.0000e+00],
         [-6.4854e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003233, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2938706522769354
Current reward: 0.47115962265620126
Current mitigation activation: 1
#############################
Total reward: 13.879946489110246
6.63236641138792 seconds in game passed.
Action: tensor([[[-4.6801e-04,  1.0000e+00],
         [-4.7553e-03,  1.0000e+00],
         [-5.9439e-03,  1.0000e+00],
         [-6.4854e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003100, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879946489110246
6.657366411760449 seconds in game passed.
Action: tensor([[[-4.6801e-04,  1.0000e+00],
         [-4.7553e-03,  1.0000e+00],
         [-5.9439e-03,  1.0000e+00],
         [-6.4854e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003095, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879946489110246
6.682366412132978 seconds in game passed.
Action: tensor([[[-4.6801e-04,  1.0000e+00],
         [-4.7553e-03,  1.0000e+00],
         [-5.9439e-03,  1.0000e+00],
         [-6.4854e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003091, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879946489110246
+++++++++++++: 1.2141774930007145
6.7073664125055075 seconds in game passed.
At 6.7073664125055075 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0038,  1.0000],
         [-0.0052,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000684, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2141774930007145
Current reward: 0.45479880213781687
Current mitigation activation: 1
#############################
Total reward: 14.334745291248062
6.7323664128780365 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0038,  1.0000],
         [-0.0052,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001043, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334745291248062
6.7573664132505655 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0038,  1.0000],
         [-0.0052,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001007, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334745291248062
6.782366413623095 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0038,  1.0000],
         [-0.0052,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000971, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334745291248062
+++++++++++++: 1.1613338043305137
6.807366413995624 seconds in game passed.
At 6.807366413995624 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0089,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0012,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006319, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1613338043305137
Current reward: 0.432000908994679
Current mitigation activation: 1
#############################
Total reward: 14.766746200242741
6.832366414368153 seconds in game passed.
Action: tensor([[[ 0.0089,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0012,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005188, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766746200242741
6.857366414740682 seconds in game passed.
Action: tensor([[[ 0.0089,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0012,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005260, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766746200242741
6.882366415113211 seconds in game passed.
Action: tensor([[[ 0.0089,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0012,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005332, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766746200242741
+++++++++++++: 1.1426997131330703
6.90736641548574 seconds in game passed.
At 6.90736641548574 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012382, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1426997131330703
Current reward: 0.401817413546656
Current mitigation activation: 1
#############################
Total reward: 15.168563613789397
6.932366415858269 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009569, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168563613789397
6.957366416230798 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009688, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168563613789397
6.982366416603327 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009808, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168563613789397
+++++++++++++: 1.1445959619384327
7.007366416975856 seconds in game passed.
At 7.007366416975856 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0136,  1.0000],
         [-0.0079,  1.0000],
         [-0.0091,  1.0000],
         [-0.0088,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012189, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1445959619384327
Current reward: 0.3690956877300934
Current mitigation activation: 1
#############################
Total reward: 15.53765930151949
7.032366417348385 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0079,  1.0000],
         [-0.0091,  1.0000],
         [-0.0088,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012003, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53765930151949
7.057366417720914 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0079,  1.0000],
         [-0.0091,  1.0000],
         [-0.0088,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012185, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53765930151949
7.082366418093443 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0079,  1.0000],
         [-0.0091,  1.0000],
         [-0.0088,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012366, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53765930151949
+++++++++++++: 1.164179669813539
7.107366418465972 seconds in game passed.
At 7.107366418465972 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0085,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016270, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.164179669813539
Current reward: 0.335828693737458
Current mitigation activation: 1
#############################
Total reward: 15.873487995256948
7.132366418838501 seconds in game passed.
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0085,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015859, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.873487995256948
7.15736641921103 seconds in game passed.
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0085,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016065, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.873487995256948
7.182366419583559 seconds in game passed.
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0085,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016271, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.873487995256948
+++++++++++++: 1.2039473264097034
7.207366419956088 seconds in game passed.
At 7.207366419956088 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0109,  1.0000],
         [-0.0151,  1.0000],
         [-0.0201,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015610, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2039473264097034
Current reward: 0.30283678930801683
Current mitigation activation: 1
#############################
Total reward: 16.176324784564965
7.232366420328617 seconds in game passed.
Action: tensor([[[-0.0109,  1.0000],
         [-0.0151,  1.0000],
         [-0.0201,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015922, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176324784564965
7.257366420701146 seconds in game passed.
Action: tensor([[[-0.0109,  1.0000],
         [-0.0151,  1.0000],
         [-0.0201,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016095, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176324784564965
7.282366421073675 seconds in game passed.
Action: tensor([[[-0.0109,  1.0000],
         [-0.0151,  1.0000],
         [-0.0201,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016267, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176324784564965
+++++++++++++: 1.2694202518479822
7.307366421446204 seconds in game passed.
At 7.307366421446204 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0096,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021654, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2694202518479822
Current reward: 0.270605597410731
Current mitigation activation: 1
#############################
Total reward: 16.446930381975697
7.332366421818733 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0096,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015593, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446930381975697
7.357366422191262 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0096,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015816, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446930381975697
7.382366422563791 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0096,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016039, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446930381975697
+++++++++++++: 1.3677208924024615
7.40736642293632 seconds in game passed.
At 7.40736642293632 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9270e-03, 9.5602e-01],
         [1.1442e-03, 9.5436e-01],
         [3.2719e-04, 9.5375e-01],
         [6.7866e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003316, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3677208924024615
Current reward: 0.23974607232597556
Current mitigation activation: 0
#############################
Total reward: 16.686676454301672
7.432366423308849 seconds in game passed.
Action: tensor([[[1.9270e-03, 9.5602e-01],
         [1.1442e-03, 9.5436e-01],
         [3.2719e-04, 9.5375e-01],
         [6.7866e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000014, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686676454301672
7.457366423681378 seconds in game passed.
Action: tensor([[[1.9270e-03, 9.5602e-01],
         [1.1442e-03, 9.5436e-01],
         [3.2719e-04, 9.5375e-01],
         [6.7866e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000051, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686676454301672
7.482366424053907 seconds in game passed.
Action: tensor([[[1.9270e-03, 9.5602e-01],
         [1.1442e-03, 9.5436e-01],
         [3.2719e-04, 9.5375e-01],
         [6.7866e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000116, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686676454301672
+++++++++++++: 1.5103688607306902
7.507366424426436 seconds in game passed.
At 7.507366424426436 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.6946e-04, 9.5595e-01],
         [1.1249e-03, 9.5433e-01],
         [1.0497e-03, 9.5376e-01],
         [1.4996e-03, 9.5343e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000579, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5103688607306902
Current reward: 0.21064168404696598
Current mitigation activation: 0
#############################
Total reward: 16.897318138348638
7.5323664247989655 seconds in game passed.
Action: tensor([[[7.6946e-04, 9.5595e-01],
         [1.1249e-03, 9.5433e-01],
         [1.0497e-03, 9.5376e-01],
         [1.4996e-03, 9.5343e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000418, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.897318138348638
7.5573664251714945 seconds in game passed.
Action: tensor([[[7.6946e-04, 9.5595e-01],
         [1.1249e-03, 9.5433e-01],
         [1.0497e-03, 9.5376e-01],
         [1.4996e-03, 9.5343e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000379, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.897318138348638
7.5823664255440235 seconds in game passed.
Action: tensor([[[7.6946e-04, 9.5595e-01],
         [1.1249e-03, 9.5433e-01],
         [1.0497e-03, 9.5376e-01],
         [1.4996e-03, 9.5343e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000341, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.897318138348638
+++++++++++++: 1.7387842963553317
7.6073664259165525 seconds in game passed.
At 7.6073664259165525 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.0067e-04, 9.5610e-01],
         [1.5235e-03, 9.5459e-01],
         [1.8301e-03, 9.5409e-01],
         [1.9369e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000023, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7387842963553317
Current reward: 0.18265778305310176
Current mitigation activation: 0
#############################
Total reward: 17.07997592140174
7.632366426289082 seconds in game passed.
Action: tensor([[[8.0067e-04, 9.5610e-01],
         [1.5235e-03, 9.5459e-01],
         [1.8301e-03, 9.5409e-01],
         [1.9369e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000018, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.07997592140174
7.657366426661611 seconds in game passed.
Action: tensor([[[8.0067e-04, 9.5610e-01],
         [1.5235e-03, 9.5459e-01],
         [1.8301e-03, 9.5409e-01],
         [1.9369e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000031, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.07997592140174
7.68236642703414 seconds in game passed.
Action: tensor([[[8.0067e-04, 9.5610e-01],
         [1.5235e-03, 9.5459e-01],
         [1.8301e-03, 9.5409e-01],
         [1.9369e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000080, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.07997592140174
+++++++++++++: 2.157608131287656
7.707366427406669 seconds in game passed.
At 7.707366427406669 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.2663e-04, 9.5621e-01],
         [1.5128e-03, 9.5477e-01],
         [1.7814e-03, 9.5430e-01],
         [1.8738e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000052, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.157608131287656
Current reward: 0.15682062329571256
Current mitigation activation: 0
#############################
Total reward: 17.23679654469745
7.732366427779198 seconds in game passed.
Action: tensor([[[7.2663e-04, 9.5621e-01],
         [1.5128e-03, 9.5477e-01],
         [1.7814e-03, 9.5430e-01],
         [1.8738e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000085, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.23679654469745
7.757366428151727 seconds in game passed.
Action: tensor([[[7.2663e-04, 9.5621e-01],
         [1.5128e-03, 9.5477e-01],
         [1.7814e-03, 9.5430e-01],
         [1.8738e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000109, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.23679654469745
7.782366428524256 seconds in game passed.
Action: tensor([[[7.2663e-04, 9.5621e-01],
         [1.5128e-03, 9.5477e-01],
         [1.7814e-03, 9.5430e-01],
         [1.8738e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000133, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.23679654469745
+++++++++++++: 2.965046950734694
7.807366428896785 seconds in game passed.
At 7.807366428896785 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.8852e-04, 9.5620e-01],
         [1.5127e-03, 9.5475e-01],
         [1.7778e-03, 9.5428e-01],
         [1.8908e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000121, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.965046950734694
Current reward: 0.13273247952111245
Current mitigation activation: 0
#############################
Total reward: 17.369529024218565
7.832366429269314 seconds in game passed.
Action: tensor([[[7.8852e-04, 9.5620e-01],
         [1.5127e-03, 9.5475e-01],
         [1.7778e-03, 9.5428e-01],
         [1.8908e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000064, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369529024218565
7.857366429641843 seconds in game passed.
Action: tensor([[[7.8852e-04, 9.5620e-01],
         [1.5127e-03, 9.5475e-01],
         [1.7778e-03, 9.5428e-01],
         [1.8908e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000013, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369529024218565
7.882366430014372 seconds in game passed.
Action: tensor([[[7.8852e-04, 9.5620e-01],
         [1.5127e-03, 9.5475e-01],
         [1.7778e-03, 9.5428e-01],
         [1.8908e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000038, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369529024218565
+++++++++++++: 4.776267264831351
7.907366430386901 seconds in game passed.
At 7.907366430386901 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.3318e-04, 9.5606e-01],
         [1.5029e-03, 9.5455e-01],
         [1.7808e-03, 9.5405e-01],
         [1.9054e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000180, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.776267264831351
Current reward: 0.11052743286725884
Current mitigation activation: 0
#############################
Total reward: 17.480056457085823
7.93236643075943 seconds in game passed.
Action: tensor([[[9.3318e-04, 9.5606e-01],
         [1.5029e-03, 9.5455e-01],
         [1.7808e-03, 9.5405e-01],
         [1.9054e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000300, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.480056457085823
7.957366431131959 seconds in game passed.
Action: tensor([[[9.3318e-04, 9.5606e-01],
         [1.5029e-03, 9.5455e-01],
         [1.7808e-03, 9.5405e-01],
         [1.9054e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000433, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.480056457085823
7.982366431504488 seconds in game passed.
Action: tensor([[[9.3318e-04, 9.5606e-01],
         [1.5029e-03, 9.5455e-01],
         [1.7808e-03, 9.5405e-01],
         [1.9054e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.004321, steer=0.000567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.480056457085823
+++++++++++++: 23.485246771376318
8.007366431877017 seconds in game passed.
At 8.007366431877017 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006646, steer=0.000668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03960110997588508
Current mitigation activation: 0
#############################
Total reward: 17.519657567061707
8.032366432249546 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006647, steer=0.000833, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519657567061707
8.057366432622075 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006813, steer=0.000989, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519657567061707
8.082366432994604 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006926, steer=0.001145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519657567061707
+++++++++++++: 2100.702905260555
8.107366433367133 seconds in game passed.
At 8.107366433367133 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.4642e-03,  9.5574e-01],
         [ 1.6798e-03,  9.5383e-01],
         [-1.7613e-03,  9.5308e-01],
         [-4.1718e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.033330, steer=0.006879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0004644135355229141
Current mitigation activation: 0
#############################
Total reward: 17.520121980597228
8.132366433739662 seconds in game passed.
Action: tensor([[[ 9.4642e-03,  9.5574e-01],
         [ 1.6798e-03,  9.5383e-01],
         [-1.7613e-03,  9.5308e-01],
         [-4.1718e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.007826, steer=0.006217, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520121980597228
8.157366434112191 seconds in game passed.
Action: tensor([[[ 9.4642e-03,  9.5574e-01],
         [ 1.6798e-03,  9.5383e-01],
         [-1.7613e-03,  9.5308e-01],
         [-4.1718e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.011047, steer=0.006468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520121980597228
8.18236643448472 seconds in game passed.
Action: tensor([[[ 9.4642e-03,  9.5574e-01],
         [ 1.6798e-03,  9.5383e-01],
         [-1.7613e-03,  9.5308e-01],
         [-4.1718e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.011812, steer=0.006720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520121980597228
+++++++++++++: 165.83564722643246
8.20736643485725 seconds in game passed.
At 8.20736643485725 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0236,  0.9551],
         [ 0.0027,  0.9523],
         [-0.0071,  0.9508],
         [-0.0023,  0.9467]]])
agent 0 action: VehicleControl(throttle=0.061463, steer=0.016497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0061761631699840695
Current mitigation activation: 0
#############################
Total reward: 17.52629814376721
8.232366435229778 seconds in game passed.
Action: tensor([[[ 0.0236,  0.9551],
         [ 0.0027,  0.9523],
         [-0.0071,  0.9508],
         [-0.0023,  0.9467]]])
agent 0 action: VehicleControl(throttle=0.057536, steer=0.015266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52629814376721
8.257366435602307 seconds in game passed.
Action: tensor([[[ 0.0236,  0.9551],
         [ 0.0027,  0.9523],
         [-0.0071,  0.9508],
         [-0.0023,  0.9467]]])
agent 0 action: VehicleControl(throttle=0.058735, steer=0.015607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52629814376721
8.282366435974836 seconds in game passed.
Action: tensor([[[ 0.0236,  0.9551],
         [ 0.0027,  0.9523],
         [-0.0071,  0.9508],
         [-0.0023,  0.9467]]])
agent 0 action: VehicleControl(throttle=0.059852, steer=0.015948, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52629814376721
+++++++++++++: 207.3653832266114
8.307366436347365 seconds in game passed.
At 8.307366436347365 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4403e-02,  9.5365e-01],
         [ 2.2214e-05,  9.4733e-01],
         [-1.3230e-02,  9.1303e-01],
         [-8.7054e-03,  5.9812e-01]]])
agent 0 action: VehicleControl(throttle=0.077088, steer=0.014674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.005193060978606422
Current mitigation activation: 0
#############################
Total reward: 17.531491204745816
8.332366436719894 seconds in game passed.
Action: tensor([[[ 2.4403e-02,  9.5365e-01],
         [ 2.2214e-05,  9.4733e-01],
         [-1.3230e-02,  9.1303e-01],
         [-8.7054e-03,  5.9812e-01]]])
agent 0 action: VehicleControl(throttle=0.076556, steer=0.014812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.531491204745816
8.357366437092423 seconds in game passed.
Action: tensor([[[ 2.4403e-02,  9.5365e-01],
         [ 2.2214e-05,  9.4733e-01],
         [-1.3230e-02,  9.1303e-01],
         [-8.7054e-03,  5.9812e-01]]])
agent 0 action: VehicleControl(throttle=0.077690, steer=0.014748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.531491204745816
8.382366437464952 seconds in game passed.
Action: tensor([[[ 2.4403e-02,  9.5365e-01],
         [ 2.2214e-05,  9.4733e-01],
         [-1.3230e-02,  9.1303e-01],
         [-8.7054e-03,  5.9812e-01]]])
agent 0 action: VehicleControl(throttle=0.078770, steer=0.014683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.531491204745816
+++++++++++++: 245.96885638150334
8.407366437837481 seconds in game passed.
At 8.407366437837481 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0095,  0.9527],
         [-0.0042,  0.9420],
         [-0.0109,  0.8778],
         [-0.0053,  0.6101]]])
agent 0 action: VehicleControl(throttle=0.054203, steer=0.002813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0046079472861264474
Current mitigation activation: 0
#############################
Total reward: 17.53609915203194
8.43236643821001 seconds in game passed.
Action: tensor([[[ 0.0095,  0.9527],
         [-0.0042,  0.9420],
         [-0.0109,  0.8778],
         [-0.0053,  0.6101]]])
agent 0 action: VehicleControl(throttle=0.057641, steer=0.004808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53609915203194
8.45736643858254 seconds in game passed.
Action: tensor([[[ 0.0095,  0.9527],
         [-0.0042,  0.9420],
         [-0.0109,  0.8778],
         [-0.0053,  0.6101]]])
agent 0 action: VehicleControl(throttle=0.058349, steer=0.004823, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53609915203194
8.482366438955069 seconds in game passed.
Action: tensor([[[ 0.0095,  0.9527],
         [-0.0042,  0.9420],
         [-0.0109,  0.8778],
         [-0.0053,  0.6101]]])
agent 0 action: VehicleControl(throttle=0.059063, steer=0.004837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53609915203194
+++++++++++++: 276.32236424173146
8.507366439327598 seconds in game passed.
At 8.507366439327598 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0317,  0.9511],
         [-0.0181,  0.9038],
         [-0.0119,  0.7312],
         [-0.0084,  0.5437]]])
agent 0 action: VehicleControl(throttle=0.211208, steer=-0.029469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004318712509916633
Current mitigation activation: 0
#############################
Total reward: 17.54041786454186
8.532366439700127 seconds in game passed.
Action: tensor([[[-0.0317,  0.9511],
         [-0.0181,  0.9038],
         [-0.0119,  0.7312],
         [-0.0084,  0.5437]]])
agent 0 action: VehicleControl(throttle=0.197546, steer=-0.024139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54041786454186
8.557366440072656 seconds in game passed.
Action: tensor([[[-0.0317,  0.9511],
         [-0.0181,  0.9038],
         [-0.0119,  0.7312],
         [-0.0084,  0.5437]]])
agent 0 action: VehicleControl(throttle=0.199886, steer=-0.024471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54041786454186
8.582366440445185 seconds in game passed.
Action: tensor([[[-0.0317,  0.9511],
         [-0.0181,  0.9038],
         [-0.0119,  0.7312],
         [-0.0084,  0.5437]]])
agent 0 action: VehicleControl(throttle=0.202072, steer=-0.024803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54041786454186
+++++++++++++: 300.70782312900866
8.607366440817714 seconds in game passed.
At 8.607366440817714 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0389,  0.9496],
         [-0.0171,  0.8221],
         [-0.0071,  0.6116],
         [-0.0043,  0.4915]]])
agent 0 action: VehicleControl(throttle=0.628401, steer=-0.027905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00417999858376674
Current mitigation activation: 0
#############################
Total reward: 17.544597863125624
8.632366441190243 seconds in game passed.
Action: tensor([[[-0.0389,  0.9496],
         [-0.0171,  0.8221],
         [-0.0071,  0.6116],
         [-0.0043,  0.4915]]])
agent 0 action: VehicleControl(throttle=0.590072, steer=-0.027812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544597863125624
8.657366441562772 seconds in game passed.
Action: tensor([[[-0.0389,  0.9496],
         [-0.0171,  0.8221],
         [-0.0071,  0.6116],
         [-0.0043,  0.4915]]])
agent 0 action: VehicleControl(throttle=0.596558, steer=-0.028175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544597863125624
8.6823664419353 seconds in game passed.
Action: tensor([[[-0.0389,  0.9496],
         [-0.0171,  0.8221],
         [-0.0071,  0.6116],
         [-0.0043,  0.4915]]])
agent 0 action: VehicleControl(throttle=0.602725, steer=-0.028538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544597863125624
+++++++++++++: 287.8947446875014
8.70736644230783 seconds in game passed.
At 8.70736644230783 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0332,  0.9491],
         [-0.0098,  0.8029],
         [-0.0052,  0.5908],
         [-0.0069,  0.4831]]])
agent 0 action: VehicleControl(throttle=0.720476, steer=-0.020606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004596795020849741
Current mitigation activation: 0
#############################
Total reward: 17.549194658146472
8.732366442680359 seconds in game passed.
Action: tensor([[[-0.0332,  0.9491],
         [-0.0098,  0.8029],
         [-0.0052,  0.5908],
         [-0.0069,  0.4831]]])
agent 0 action: VehicleControl(throttle=0.714808, steer=-0.022252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.549194658146472
8.757366443052888 seconds in game passed.
Action: tensor([[[-0.0332,  0.9491],
         [-0.0098,  0.8029],
         [-0.0052,  0.5908],
         [-0.0069,  0.4831]]])
agent 0 action: VehicleControl(throttle=0.720191, steer=-0.022529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.549194658146472
8.782366443425417 seconds in game passed.
Action: tensor([[[-0.0332,  0.9491],
         [-0.0098,  0.8029],
         [-0.0052,  0.5908],
         [-0.0069,  0.4831]]])
agent 0 action: VehicleControl(throttle=0.724204, steer=-0.022806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.549194658146472
+++++++++++++: 194.36520610492977
8.807366443797946 seconds in game passed.
At 8.807366443797946 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.5528e-02,  9.4363e-01],
         [-5.1047e-03,  6.0747e-01],
         [-2.0826e-03,  4.7220e-01],
         [-5.3616e-04,  4.1653e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.007162046883569173
Current mitigation activation: 0
#############################
Total reward: 17.55635670503004
8.832366444170475 seconds in game passed.
Action: tensor([[[-2.5528e-02,  9.4363e-01],
         [-5.1047e-03,  6.0747e-01],
         [-2.0826e-03,  4.7220e-01],
         [-5.3616e-04,  4.1653e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015194, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55635670503004
8.857366444543004 seconds in game passed.
Action: tensor([[[-2.5528e-02,  9.4363e-01],
         [-5.1047e-03,  6.0747e-01],
         [-2.0826e-03,  4.7220e-01],
         [-5.3616e-04,  4.1653e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55635670503004
8.882366444915533 seconds in game passed.
Action: tensor([[[-2.5528e-02,  9.4363e-01],
         [-5.1047e-03,  6.0747e-01],
         [-2.0826e-03,  4.7220e-01],
         [-5.3616e-04,  4.1653e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55635670503004
+++++++++++++: 44.0906976276972
8.907366445288062 seconds in game passed.
At 8.907366445288062 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1735e-02,  9.3342e-01],
         [-2.2108e-04,  5.6182e-01],
         [ 3.0849e-04,  4.3898e-01],
         [ 1.3168e-03,  3.8259e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03311226645420879
Current mitigation activation: 0
#############################
Total reward: 17.589468971484248
8.932366445660591 seconds in game passed.
Action: tensor([[[-1.1735e-02,  9.3342e-01],
         [-2.2108e-04,  5.6182e-01],
         [ 3.0849e-04,  4.3898e-01],
         [ 1.3168e-03,  3.8259e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.589468971484248
8.95736644603312 seconds in game passed.
Action: tensor([[[-1.1735e-02,  9.3342e-01],
         [-2.2108e-04,  5.6182e-01],
         [ 3.0849e-04,  4.3898e-01],
         [ 1.3168e-03,  3.8259e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.589468971484248
8.98236644640565 seconds in game passed.
Action: tensor([[[-1.1735e-02,  9.3342e-01],
         [-2.2108e-04,  5.6182e-01],
         [ 3.0849e-04,  4.3898e-01],
         [ 1.3168e-03,  3.8259e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.589468971484248
+++++++++++++: 20.180508855471494
9.007366446778178 seconds in game passed.
At 9.007366446778178 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0084,  0.8832],
         [-0.0034,  0.4964],
         [-0.0055,  0.3613],
         [-0.0059,  0.2912]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008056, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.07556964775650402
Current mitigation activation: 0
#############################
Total reward: 17.66503861924075
9.032366447150707 seconds in game passed.
Action: tensor([[[-0.0084,  0.8832],
         [-0.0034,  0.4964],
         [-0.0055,  0.3613],
         [-0.0059,  0.2912]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66503861924075
9.057366447523236 seconds in game passed.
Action: tensor([[[-0.0084,  0.8832],
         [-0.0034,  0.4964],
         [-0.0055,  0.3613],
         [-0.0059,  0.2912]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66503861924075
9.082366447895765 seconds in game passed.
Action: tensor([[[-0.0084,  0.8832],
         [-0.0034,  0.4964],
         [-0.0055,  0.3613],
         [-0.0059,  0.2912]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66503861924075
+++++++++++++: 11.148758730378397
9.107366448268294 seconds in game passed.
At 9.107366448268294 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0027,  0.8315],
         [-0.0038,  0.4709],
         [-0.0066,  0.3360],
         [-0.0075,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.14212334062488308
Current mitigation activation: 0
#############################
Total reward: 17.807161959865635
9.132366448640823 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8315],
         [-0.0038,  0.4709],
         [-0.0066,  0.3360],
         [-0.0075,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.807161959865635
9.157366449013352 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8315],
         [-0.0038,  0.4709],
         [-0.0066,  0.3360],
         [-0.0075,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.807161959865635
9.182366449385881 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8315],
         [-0.0038,  0.4709],
         [-0.0066,  0.3360],
         [-0.0075,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.807161959865635
+++++++++++++: 7.648902863283784
9.20736644975841 seconds in game passed.
At 9.20736644975841 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0053,  0.8091],
         [-0.0025,  0.4577],
         [-0.0057,  0.3241],
         [-0.0074,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003030, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.648902863283784
Current reward: 0.1746994738673161
Current mitigation activation: 0
#############################
Total reward: 17.981861433732952
9.23236645013094 seconds in game passed.
Action: tensor([[[ 0.0053,  0.8091],
         [-0.0025,  0.4577],
         [-0.0057,  0.3241],
         [-0.0074,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.981861433732952
9.257366450503469 seconds in game passed.
Action: tensor([[[ 0.0053,  0.8091],
         [-0.0025,  0.4577],
         [-0.0057,  0.3241],
         [-0.0074,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.981861433732952
9.282366450875998 seconds in game passed.
Action: tensor([[[ 0.0053,  0.8091],
         [-0.0025,  0.4577],
         [-0.0057,  0.3241],
         [-0.0074,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.981861433732952
+++++++++++++: 6.056017477807871
9.307366451248527 seconds in game passed.
At 9.307366451248527 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0066,  0.7989],
         [-0.0012,  0.4484],
         [-0.0039,  0.3127],
         [-0.0057,  0.2395]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.056017477807871
Current reward: 0.1923353626915051
Current mitigation activation: 0
#############################
Total reward: 18.174196796424457
9.332366451621056 seconds in game passed.
Action: tensor([[[ 0.0066,  0.7989],
         [-0.0012,  0.4484],
         [-0.0039,  0.3127],
         [-0.0057,  0.2395]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.174196796424457
9.357366451993585 seconds in game passed.
Action: tensor([[[ 0.0066,  0.7989],
         [-0.0012,  0.4484],
         [-0.0039,  0.3127],
         [-0.0057,  0.2395]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.174196796424457
9.382366452366114 seconds in game passed.
Action: tensor([[[ 0.0066,  0.7989],
         [-0.0012,  0.4484],
         [-0.0039,  0.3127],
         [-0.0057,  0.2395]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.174196796424457
+++++++++++++: 5.146320473738149
9.407366452738643 seconds in game passed.
At 9.407366452738643 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0058,  0.7701],
         [-0.0009,  0.4321],
         [-0.0034,  0.3002],
         [-0.0050,  0.2299]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.146320473738149
Current reward: 0.20808195964670695
Current mitigation activation: 0
#############################
Total reward: 18.382278756071166
9.432366453111172 seconds in game passed.
Action: tensor([[[ 0.0058,  0.7701],
         [-0.0009,  0.4321],
         [-0.0034,  0.3002],
         [-0.0050,  0.2299]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.382278756071166
9.4573664534837 seconds in game passed.
Action: tensor([[[ 0.0058,  0.7701],
         [-0.0009,  0.4321],
         [-0.0034,  0.3002],
         [-0.0050,  0.2299]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.382278756071166
9.48236645385623 seconds in game passed.
Action: tensor([[[ 0.0058,  0.7701],
         [-0.0009,  0.4321],
         [-0.0034,  0.3002],
         [-0.0050,  0.2299]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.382278756071166
+++++++++++++: 4.518618210459528
9.507366454228759 seconds in game passed.
At 9.507366454228759 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0050,  0.7542],
         [-0.0015,  0.4224],
         [-0.0038,  0.2934],
         [-0.0054,  0.2252]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003768, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.518618210459528
Current reward: 0.22286555560751434
Current mitigation activation: 0
#############################
Total reward: 18.605144311678682
9.532366454601288 seconds in game passed.
Action: tensor([[[ 0.0050,  0.7542],
         [-0.0015,  0.4224],
         [-0.0038,  0.2934],
         [-0.0054,  0.2252]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.605144311678682
9.557366454973817 seconds in game passed.
Action: tensor([[[ 0.0050,  0.7542],
         [-0.0015,  0.4224],
         [-0.0038,  0.2934],
         [-0.0054,  0.2252]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.605144311678682
9.582366455346346 seconds in game passed.
Action: tensor([[[ 0.0050,  0.7542],
         [-0.0015,  0.4224],
         [-0.0038,  0.2934],
         [-0.0054,  0.2252]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002652, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.605144311678682
+++++++++++++: 4.043601689773679
9.607366455718875 seconds in game passed.
At 9.607366455718875 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0881e-02,  7.5330e-01],
         [ 4.2227e-04,  4.1867e-01],
         [-1.1751e-03,  2.9186e-01],
         [-1.9390e-03,  2.2513e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.043601689773679
Current reward: 0.2370148272099824
Current mitigation activation: 0
#############################
Total reward: 18.842159138888665
9.632366456091404 seconds in game passed.
Action: tensor([[[ 1.0881e-02,  7.5330e-01],
         [ 4.2227e-04,  4.1867e-01],
         [-1.1751e-03,  2.9186e-01],
         [-1.9390e-03,  2.2513e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.842159138888665
9.657366456463933 seconds in game passed.
Action: tensor([[[ 1.0881e-02,  7.5330e-01],
         [ 4.2227e-04,  4.1867e-01],
         [-1.1751e-03,  2.9186e-01],
         [-1.9390e-03,  2.2513e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001736, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.842159138888665
9.682366456836462 seconds in game passed.
Action: tensor([[[ 1.0881e-02,  7.5330e-01],
         [ 4.2227e-04,  4.1867e-01],
         [-1.1751e-03,  2.9186e-01],
         [-1.9390e-03,  2.2513e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.842159138888665
+++++++++++++: 3.6637100571599777
9.707366457208991 seconds in game passed.
At 9.707366457208991 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5257e-02,  7.4702e-01],
         [ 1.3209e-03,  4.1854e-01],
         [-9.3579e-05,  2.9252e-01],
         [-5.7849e-04,  2.2562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004959, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6637100571599777
Current reward: 0.25067432755368235
Current mitigation activation: 0
#############################
Total reward: 19.092833466442347
9.73236645758152 seconds in game passed.
Action: tensor([[[ 1.5257e-02,  7.4702e-01],
         [ 1.3209e-03,  4.1854e-01],
         [-9.3579e-05,  2.9252e-01],
         [-5.7849e-04,  2.2562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.092833466442347
9.757366457954049 seconds in game passed.
Action: tensor([[[ 1.5257e-02,  7.4702e-01],
         [ 1.3209e-03,  4.1854e-01],
         [-9.3579e-05,  2.9252e-01],
         [-5.7849e-04,  2.2562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.092833466442347
9.782366458326578 seconds in game passed.
Action: tensor([[[ 1.5257e-02,  7.4702e-01],
         [ 1.3209e-03,  4.1854e-01],
         [-9.3579e-05,  2.9252e-01],
         [-5.7849e-04,  2.2562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.092833466442347
+++++++++++++: 3.3486375215841893
9.807366458699107 seconds in game passed.
At 9.807366458699107 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4924e-02, 7.3840e-01],
         [2.5150e-03, 4.1599e-01],
         [1.1859e-03, 2.9054e-01],
         [5.7602e-04, 2.2374e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3486375215841893
Current reward: 0.2639053178917135
Current mitigation activation: 0
#############################
Total reward: 19.35673878433406
9.832366459071636 seconds in game passed.
Action: tensor([[[1.4924e-02, 7.3840e-01],
         [2.5150e-03, 4.1599e-01],
         [1.1859e-03, 2.9054e-01],
         [5.7602e-04, 2.2374e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.35673878433406
9.857366459444165 seconds in game passed.
Action: tensor([[[1.4924e-02, 7.3840e-01],
         [2.5150e-03, 4.1599e-01],
         [1.1859e-03, 2.9054e-01],
         [5.7602e-04, 2.2374e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.35673878433406
9.882366459816694 seconds in game passed.
Action: tensor([[[1.4924e-02, 7.3840e-01],
         [2.5150e-03, 4.1599e-01],
         [1.1859e-03, 2.9054e-01],
         [5.7602e-04, 2.2374e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.35673878433406
+++++++++++++: 3.1976132577632455
9.907366460189223 seconds in game passed.
At 9.907366460189223 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1688e-02,  7.0715e-01],
         [ 1.4083e-03,  3.9646e-01],
         [ 3.8242e-04,  2.7691e-01],
         [-8.3447e-06,  2.1447e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1976132577632455
Current reward: 0.27223406489511975
Current mitigation activation: 0
#############################
Total reward: 19.62897284922918
9.932366460561752 seconds in game passed.
Action: tensor([[[ 1.1688e-02,  7.0715e-01],
         [ 1.4083e-03,  3.9646e-01],
         [ 3.8242e-04,  2.7691e-01],
         [-8.3447e-06,  2.1447e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.62897284922918
9.957366460934281 seconds in game passed.
Action: tensor([[[ 1.1688e-02,  7.0715e-01],
         [ 1.4083e-03,  3.9646e-01],
         [ 3.8242e-04,  2.7691e-01],
         [-8.3447e-06,  2.1447e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.62897284922918
9.98236646130681 seconds in game passed.
Action: tensor([[[ 1.1688e-02,  7.0715e-01],
         [ 1.4083e-03,  3.9646e-01],
         [ 3.8242e-04,  2.7691e-01],
         [-8.3447e-06,  2.1447e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.62897284922918
+++++++++++++: 3.2323927340502343
10.00736646167934 seconds in game passed.
At 10.00736646167934 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.6757e-03, 6.7621e-01],
         [1.0074e-03, 3.7629e-01],
         [5.6214e-04, 2.6331e-01],
         [2.4725e-04, 2.0552e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2323927340502343
Current reward: 0.2735548276216304
Current mitigation activation: 0
#############################
Total reward: 19.90252767685081
10.032366462051868 seconds in game passed.
Action: tensor([[[6.6757e-03, 6.7621e-01],
         [1.0074e-03, 3.7629e-01],
         [5.6214e-04, 2.6331e-01],
         [2.4725e-04, 2.0552e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.90252767685081
10.057366462424397 seconds in game passed.
Action: tensor([[[6.6757e-03, 6.7621e-01],
         [1.0074e-03, 3.7629e-01],
         [5.6214e-04, 2.6331e-01],
         [2.4725e-04, 2.0552e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.90252767685081
10.082366462796926 seconds in game passed.
Action: tensor([[[6.6757e-03, 6.7621e-01],
         [1.0074e-03, 3.7629e-01],
         [5.6214e-04, 2.6331e-01],
         [2.4725e-04, 2.0552e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.90252767685081
+++++++++++++: 3.2681981582104056
10.107366463169456 seconds in game passed.
At 10.107366463169456 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.9828e-03, 6.5838e-01],
         [1.4812e-03, 3.6479e-01],
         [1.0364e-03, 2.5456e-01],
         [3.0477e-04, 1.9864e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2681981582104056
Current reward: 0.2748561203236809
Current mitigation activation: 0
#############################
Total reward: 20.17738379717449
10.132366463541985 seconds in game passed.
Action: tensor([[[3.9828e-03, 6.5838e-01],
         [1.4812e-03, 3.6479e-01],
         [1.0364e-03, 2.5456e-01],
         [3.0477e-04, 1.9864e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003689, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.17738379717449
10.157366463914514 seconds in game passed.
Action: tensor([[[3.9828e-03, 6.5838e-01],
         [1.4812e-03, 3.6479e-01],
         [1.0364e-03, 2.5456e-01],
         [3.0477e-04, 1.9864e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003734, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.17738379717449
10.182366464287043 seconds in game passed.
Action: tensor([[[3.9828e-03, 6.5838e-01],
         [1.4812e-03, 3.6479e-01],
         [1.0364e-03, 2.5456e-01],
         [3.0477e-04, 1.9864e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003779, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.17738379717449
+++++++++++++: 3.304338731689771
10.207366464659572 seconds in game passed.
At 10.207366464659572 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.1759e-03, 6.5492e-01],
         [1.1728e-03, 3.6278e-01],
         [8.4929e-04, 2.5290e-01],
         [2.5233e-04, 1.9705e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003246, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.304338731689771
Current reward: 0.2761654198628755
Current mitigation activation: 0
#############################
Total reward: 20.453549217037363
10.2323664650321 seconds in game passed.
Action: tensor([[[3.1759e-03, 6.5492e-01],
         [1.1728e-03, 3.6278e-01],
         [8.4929e-04, 2.5290e-01],
         [2.5233e-04, 1.9705e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.453549217037363
10.25736646540463 seconds in game passed.
Action: tensor([[[3.1759e-03, 6.5492e-01],
         [1.1728e-03, 3.6278e-01],
         [8.4929e-04, 2.5290e-01],
         [2.5233e-04, 1.9705e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.453549217037363
10.282366465777159 seconds in game passed.
Action: tensor([[[3.1759e-03, 6.5492e-01],
         [1.1728e-03, 3.6278e-01],
         [8.4929e-04, 2.5290e-01],
         [2.5233e-04, 1.9705e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.453549217037363
+++++++++++++: 3.34096843366462
10.307366466149688 seconds in game passed.
At 10.307366466149688 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.6709e-03,  6.4377e-01],
         [ 4.0249e-04,  3.5879e-01],
         [ 5.6244e-05,  2.5165e-01],
         [-5.5299e-04,  1.9658e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.34096843366462
Current reward: 0.27747561635029927
Current mitigation activation: 0
#############################
Total reward: 20.73102483338766
10.332366466522217 seconds in game passed.
Action: tensor([[[ 2.6709e-03,  6.4377e-01],
         [ 4.0249e-04,  3.5879e-01],
         [ 5.6244e-05,  2.5165e-01],
         [-5.5299e-04,  1.9658e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.73102483338766
10.357366466894746 seconds in game passed.
Action: tensor([[[ 2.6709e-03,  6.4377e-01],
         [ 4.0249e-04,  3.5879e-01],
         [ 5.6244e-05,  2.5165e-01],
         [-5.5299e-04,  1.9658e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.73102483338766
10.382366467267275 seconds in game passed.
Action: tensor([[[ 2.6709e-03,  6.4377e-01],
         [ 4.0249e-04,  3.5879e-01],
         [ 5.6244e-05,  2.5165e-01],
         [-5.5299e-04,  1.9658e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.73102483338766
+++++++++++++: 3.2620964539892356
10.407366467639804 seconds in game passed.
At 10.407366467639804 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.7936e-03,  6.3806e-01],
         [ 8.5138e-05,  3.5400e-01],
         [-3.5793e-04,  2.4719e-01],
         [-9.8294e-04,  1.9251e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2620964539892356
Current reward: 0.2829705587566661
Current mitigation activation: 0
#############################
Total reward: 21.013995392144327
10.432366468012333 seconds in game passed.
Action: tensor([[[ 1.7936e-03,  6.3806e-01],
         [ 8.5138e-05,  3.5400e-01],
         [-3.5793e-04,  2.4719e-01],
         [-9.8294e-04,  1.9251e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.013995392144327
10.457366468384862 seconds in game passed.
Action: tensor([[[ 1.7936e-03,  6.3806e-01],
         [ 8.5138e-05,  3.5400e-01],
         [-3.5793e-04,  2.4719e-01],
         [-9.8294e-04,  1.9251e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002217, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.013995392144327
10.482366468757391 seconds in game passed.
Action: tensor([[[ 1.7936e-03,  6.3806e-01],
         [ 8.5138e-05,  3.5400e-01],
         [-3.5793e-04,  2.4719e-01],
         [-9.8294e-04,  1.9251e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.013995392144327
+++++++++++++: 2.9856377405823915
10.50736646912992 seconds in game passed.
At 10.50736646912992 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1689e-03,  6.4318e-01],
         [ 5.2133e-04,  3.5508e-01],
         [ 3.3773e-05,  2.4624e-01],
         [-6.6556e-04,  1.9071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9856377405823915
Current reward: 0.2966853160476473
Current mitigation activation: 0
#############################
Total reward: 21.310680708191974
10.532366469502449 seconds in game passed.
Action: tensor([[[ 2.1689e-03,  6.4318e-01],
         [ 5.2133e-04,  3.5508e-01],
         [ 3.3773e-05,  2.4624e-01],
         [-6.6556e-04,  1.9071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.310680708191974
10.557366469874978 seconds in game passed.
Action: tensor([[[ 2.1689e-03,  6.4318e-01],
         [ 5.2133e-04,  3.5508e-01],
         [ 3.3773e-05,  2.4624e-01],
         [-6.6556e-04,  1.9071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.310680708191974
10.582366470247507 seconds in game passed.
Action: tensor([[[ 2.1689e-03,  6.4318e-01],
         [ 5.2133e-04,  3.5508e-01],
         [ 3.3773e-05,  2.4624e-01],
         [-6.6556e-04,  1.9071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.310680708191974
+++++++++++++: 2.7680982760141855
10.607366470620036 seconds in game passed.
At 10.607366470620036 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5369e-04,  6.5832e-01],
         [-1.2738e-03,  3.6182e-01],
         [-1.9576e-03,  2.5022e-01],
         [-2.7120e-03,  1.9341e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7680982760141855
Current reward: 0.3088117061255191
Current mitigation activation: 0
#############################
Total reward: 21.61949241431749
10.632366470992565 seconds in game passed.
Action: tensor([[[ 1.5369e-04,  6.5832e-01],
         [-1.2738e-03,  3.6182e-01],
         [-1.9576e-03,  2.5022e-01],
         [-2.7120e-03,  1.9341e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.61949241431749
10.657366471365094 seconds in game passed.
Action: tensor([[[ 1.5369e-04,  6.5832e-01],
         [-1.2738e-03,  3.6182e-01],
         [-1.9576e-03,  2.5022e-01],
         [-2.7120e-03,  1.9341e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.61949241431749
10.682366471737623 seconds in game passed.
Action: tensor([[[ 1.5369e-04,  6.5832e-01],
         [-1.2738e-03,  3.6182e-01],
         [-1.9576e-03,  2.5022e-01],
         [-2.7120e-03,  1.9341e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.61949241431749
+++++++++++++: 2.5873819569113157
10.707366472110152 seconds in game passed.
At 10.707366472110152 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0014,  0.3648],
         [-0.0020,  0.2506],
         [-0.0027,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000875, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5873819569113157
Current reward: 0.3197267557783862
Current mitigation activation: 0
#############################
Total reward: 21.93921917009588
10.732366472482681 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0014,  0.3648],
         [-0.0020,  0.2506],
         [-0.0027,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000735, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.93921917009588
10.75736647285521 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0014,  0.3648],
         [-0.0020,  0.2506],
         [-0.0027,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000654, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.93921917009588
10.78236647322774 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0014,  0.3648],
         [-0.0020,  0.2506],
         [-0.0027,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.93921917009588
+++++++++++++: 2.428894231671901
10.807366473600268 seconds in game passed.
At 10.807366473600268 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.6527e-04,  6.7622e-01],
         [-1.8602e-03,  3.6505e-01],
         [-2.7394e-03,  2.5020e-01],
         [-3.5594e-03,  1.9252e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.428894231671901
Current reward: 0.3298414491599009
Current mitigation activation: 0
#############################
Total reward: 22.26906061925578
10.832366473972797 seconds in game passed.
Action: tensor([[[ 3.6527e-04,  6.7622e-01],
         [-1.8602e-03,  3.6505e-01],
         [-2.7394e-03,  2.5020e-01],
         [-3.5594e-03,  1.9252e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.26906061925578
10.857366474345326 seconds in game passed.
Action: tensor([[[ 3.6527e-04,  6.7622e-01],
         [-1.8602e-03,  3.6505e-01],
         [-2.7394e-03,  2.5020e-01],
         [-3.5594e-03,  1.9252e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.26906061925578
10.882366474717855 seconds in game passed.
Action: tensor([[[ 3.6527e-04,  6.7622e-01],
         [-1.8602e-03,  3.6505e-01],
         [-2.7394e-03,  2.5020e-01],
         [-3.5594e-03,  1.9252e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.26906061925578
+++++++++++++: 2.2855567793506775
10.907366475090384 seconds in game passed.
At 10.907366475090384 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6821],
         [-0.0025,  0.3676],
         [-0.0033,  0.2533],
         [-0.0044,  0.1954]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2855567793506775
Current reward: 0.3393568777570525
Current mitigation activation: 0
#############################
Total reward: 22.60841749701283
10.932366475462914 seconds in game passed.
Action: tensor([[[-0.0011,  0.6821],
         [-0.0025,  0.3676],
         [-0.0033,  0.2533],
         [-0.0044,  0.1954]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.60841749701283
10.957366475835443 seconds in game passed.
Action: tensor([[[-0.0011,  0.6821],
         [-0.0025,  0.3676],
         [-0.0033,  0.2533],
         [-0.0044,  0.1954]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.60841749701283
10.982366476207972 seconds in game passed.
Action: tensor([[[-0.0011,  0.6821],
         [-0.0025,  0.3676],
         [-0.0033,  0.2533],
         [-0.0044,  0.1954]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.60841749701283
+++++++++++++: 2.153490411202519
11.0073664765805 seconds in game passed.
At 11.0073664765805 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6787],
         [-0.0038,  0.3697],
         [-0.0046,  0.2556],
         [-0.0052,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.153490411202519
Current reward: 0.34837503539436065
Current mitigation activation: 0
#############################
Total reward: 22.956792532407192
11.03236647695303 seconds in game passed.
Action: tensor([[[-0.0014,  0.6787],
         [-0.0038,  0.3697],
         [-0.0046,  0.2556],
         [-0.0052,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.956792532407192
11.057366477325559 seconds in game passed.
Action: tensor([[[-0.0014,  0.6787],
         [-0.0038,  0.3697],
         [-0.0046,  0.2556],
         [-0.0052,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002728, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.956792532407192
11.082366477698088 seconds in game passed.
Action: tensor([[[-0.0014,  0.6787],
         [-0.0038,  0.3697],
         [-0.0046,  0.2556],
         [-0.0052,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002799, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.956792532407192
+++++++++++++: 2.0306665331486604
11.107366478070617 seconds in game passed.
At 11.107366478070617 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0024,  0.6767],
         [-0.0010,  0.3716],
         [-0.0020,  0.2573],
         [-0.0029,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0306665331486604
Current reward: 0.356917260518324
Current mitigation activation: 0
#############################
Total reward: 23.313709792925515
11.132366478443146 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6767],
         [-0.0010,  0.3716],
         [-0.0020,  0.2573],
         [-0.0029,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.313709792925515
11.157366478815675 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6767],
         [-0.0010,  0.3716],
         [-0.0020,  0.2573],
         [-0.0029,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.313709792925515
11.182366479188204 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6767],
         [-0.0010,  0.3716],
         [-0.0020,  0.2573],
         [-0.0029,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.313709792925515
+++++++++++++: 1.9155898844259556
11.207366479560733 seconds in game passed.
At 11.207366479560733 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6782],
         [-0.0011,  0.3741],
         [-0.0019,  0.2594],
         [-0.0025,  0.2001]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9155898844259556
Current reward: 0.3649983039667902
Current mitigation activation: 0
#############################
Total reward: 23.678708096892304
11.232366479933262 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6782],
         [-0.0011,  0.3741],
         [-0.0019,  0.2594],
         [-0.0025,  0.2001]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.678708096892304
11.257366480305791 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6782],
         [-0.0011,  0.3741],
         [-0.0019,  0.2594],
         [-0.0025,  0.2001]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.678708096892304
11.28236648067832 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6782],
         [-0.0011,  0.3741],
         [-0.0019,  0.2594],
         [-0.0025,  0.2001]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.678708096892304
+++++++++++++: 1.8071781773015707
11.307366481050849 seconds in game passed.
At 11.307366481050849 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.5884e-03,  6.7665e-01],
         [ 1.8813e-04,  3.8435e-01],
         [-5.7524e-04,  2.7107e-01],
         [-1.1647e-03,  2.1103e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8071781773015707
Current reward: 0.3726149014307233
Current mitigation activation: 0
#############################
Total reward: 24.051322998323027
11.332366481423378 seconds in game passed.
Action: tensor([[[ 5.5884e-03,  6.7665e-01],
         [ 1.8813e-04,  3.8435e-01],
         [-5.7524e-04,  2.7107e-01],
         [-1.1647e-03,  2.1103e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.051322998323027
11.357366481795907 seconds in game passed.
Action: tensor([[[ 5.5884e-03,  6.7665e-01],
         [ 1.8813e-04,  3.8435e-01],
         [-5.7524e-04,  2.7107e-01],
         [-1.1647e-03,  2.1103e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.051322998323027
11.382366482168436 seconds in game passed.
Action: tensor([[[ 5.5884e-03,  6.7665e-01],
         [ 1.8813e-04,  3.8435e-01],
         [-5.7524e-04,  2.7107e-01],
         [-1.1647e-03,  2.1103e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.051322998323027
+++++++++++++: 1.7044959921267164
11.407366482540965 seconds in game passed.
At 11.407366482540965 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.5841e-03,  7.0022e-01],
         [ 2.2143e-04,  3.9372e-01],
         [-6.9384e-04,  2.7578e-01],
         [-1.1577e-03,  2.1319e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7044959921267164
Current reward: 0.37977120146076615
Current mitigation activation: 0
#############################
Total reward: 24.431094199783793
11.432366482913494 seconds in game passed.
Action: tensor([[[ 6.5841e-03,  7.0022e-01],
         [ 2.2143e-04,  3.9372e-01],
         [-6.9384e-04,  2.7578e-01],
         [-1.1577e-03,  2.1319e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002268, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.431094199783793
11.457366483286023 seconds in game passed.
Action: tensor([[[ 6.5841e-03,  7.0022e-01],
         [ 2.2143e-04,  3.9372e-01],
         [-6.9384e-04,  2.7578e-01],
         [-1.1577e-03,  2.1319e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.431094199783793
11.482366483658552 seconds in game passed.
Action: tensor([[[ 6.5841e-03,  7.0022e-01],
         [ 2.2143e-04,  3.9372e-01],
         [-6.9384e-04,  2.7578e-01],
         [-1.1577e-03,  2.1319e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.431094199783793
+++++++++++++: 1.6067735720352678
11.507366484031081 seconds in game passed.
At 11.507366484031081 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.3641e-03,  7.2520e-01],
         [ 5.9979e-04,  4.0739e-01],
         [-2.4230e-04,  2.8497e-01],
         [-4.0501e-04,  2.1985e-01]]])
agent 0 action: VehicleControl(throttle=0.722138, steer=0.003773, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6067735720352678
Current reward: 0.3864712552523531
Current mitigation activation: 0
#############################
Total reward: 24.817565455036146
11.53236648440361 seconds in game passed.
Action: tensor([[[ 9.3641e-03,  7.2520e-01],
         [ 5.9979e-04,  4.0739e-01],
         [-2.4230e-04,  2.8497e-01],
         [-4.0501e-04,  2.1985e-01]]])
agent 0 action: VehicleControl(throttle=0.676806, steer=0.003567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.817565455036146
11.55736648477614 seconds in game passed.
Action: tensor([[[ 9.3641e-03,  7.2520e-01],
         [ 5.9979e-04,  4.0739e-01],
         [-2.4230e-04,  2.8497e-01],
         [-4.0501e-04,  2.1985e-01]]])
agent 0 action: VehicleControl(throttle=0.617041, steer=0.003598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.817565455036146
11.582366485148668 seconds in game passed.
Action: tensor([[[ 9.3641e-03,  7.2520e-01],
         [ 5.9979e-04,  4.0739e-01],
         [-2.4230e-04,  2.8497e-01],
         [-4.0501e-04,  2.1985e-01]]])
agent 0 action: VehicleControl(throttle=0.559318, steer=0.003630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.817565455036146
+++++++++++++: 1.5141264614886016
11.607366485521197 seconds in game passed.
At 11.607366485521197 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1056e-02, 7.4798e-01],
         [2.1767e-03, 4.1375e-01],
         [9.7823e-04, 2.8960e-01],
         [3.9010e-04, 2.2438e-01]]])
agent 0 action: VehicleControl(throttle=0.529339, steer=0.005533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5141264614886016
Current reward: 0.3926032784524771
Current mitigation activation: 0
#############################
Total reward: 25.210168733488622
11.632366485893726 seconds in game passed.
Action: tensor([[[1.1056e-02, 7.4798e-01],
         [2.1767e-03, 4.1375e-01],
         [9.7823e-04, 2.8960e-01],
         [3.9010e-04, 2.2438e-01]]])
agent 0 action: VehicleControl(throttle=0.505843, steer=0.005301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.210168733488622
11.657366486266255 seconds in game passed.
Action: tensor([[[1.1056e-02, 7.4798e-01],
         [2.1767e-03, 4.1375e-01],
         [9.7823e-04, 2.8960e-01],
         [3.9010e-04, 2.2438e-01]]])
agent 0 action: VehicleControl(throttle=0.481882, steer=0.005374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.210168733488622
11.682366486638784 seconds in game passed.
Action: tensor([[[1.1056e-02, 7.4798e-01],
         [2.1767e-03, 4.1375e-01],
         [9.7823e-04, 2.8960e-01],
         [3.9010e-04, 2.2438e-01]]])
agent 0 action: VehicleControl(throttle=0.458403, steer=0.005447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.210168733488622
+++++++++++++: 1.4343957036788633
11.707366487011313 seconds in game passed.
At 11.707366487011313 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4762e-02,  7.6134e-01],
         [ 1.3045e-03,  4.2315e-01],
         [-2.4292e-04,  2.9739e-01],
         [-7.3357e-04,  2.3062e-01]]])
agent 0 action: VehicleControl(throttle=0.435224, steer=0.006427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4343957036788633
Current reward: 0.3967662041798171
Current mitigation activation: 0
#############################
Total reward: 25.606934937668438
11.732366487383842 seconds in game passed.
Action: tensor([[[ 1.4762e-02,  7.6134e-01],
         [ 1.3045e-03,  4.2315e-01],
         [-2.4292e-04,  2.9739e-01],
         [-7.3357e-04,  2.3062e-01]]])
agent 0 action: VehicleControl(throttle=0.412517, steer=0.006356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.606934937668438
11.757366487756371 seconds in game passed.
Action: tensor([[[ 1.4762e-02,  7.6134e-01],
         [ 1.3045e-03,  4.2315e-01],
         [-2.4292e-04,  2.9739e-01],
         [-7.3357e-04,  2.3062e-01]]])
agent 0 action: VehicleControl(throttle=0.390282, steer=0.006434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.606934937668438
11.7823664881289 seconds in game passed.
Action: tensor([[[ 1.4762e-02,  7.6134e-01],
         [ 1.3045e-03,  4.2315e-01],
         [-2.4292e-04,  2.9739e-01],
         [-7.3357e-04,  2.3062e-01]]])
agent 0 action: VehicleControl(throttle=0.368515, steer=0.006513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.606934937668438
+++++++++++++: 1.3718404610419637
11.80736648850143 seconds in game passed.
At 11.80736648850143 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0092,  0.7900],
         [-0.0011,  0.4264],
         [-0.0030,  0.2956],
         [-0.0040,  0.2272]]])
agent 0 action: VehicleControl(throttle=0.346705, steer=0.002435, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3718404610419637
Current reward: 0.39792838773352696
Current mitigation activation: 0
#############################
Total reward: 26.004863325401963
11.832366488873959 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7900],
         [-0.0011,  0.4264],
         [-0.0030,  0.2956],
         [-0.0040,  0.2272]]])
agent 0 action: VehicleControl(throttle=0.325358, steer=0.003165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.004863325401963
11.857366489246488 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7900],
         [-0.0011,  0.4264],
         [-0.0030,  0.2956],
         [-0.0040,  0.2272]]])
agent 0 action: VehicleControl(throttle=0.304473, steer=0.003208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.004863325401963
11.882366489619017 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7900],
         [-0.0011,  0.4264],
         [-0.0030,  0.2956],
         [-0.0040,  0.2272]]])
agent 0 action: VehicleControl(throttle=0.284047, steer=0.003251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.004863325401963
+++++++++++++: 1.3235060529345124
11.907366489991546 seconds in game passed.
At 11.907366489991546 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0110,  0.8184],
         [-0.0008,  0.4443],
         [-0.0032,  0.3079],
         [-0.0043,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.264348, steer=0.004236, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3235060529345124
Current reward: 0.39639027872439736
Current mitigation activation: 0
#############################
Total reward: 26.40125360412636
11.932366490364075 seconds in game passed.
Action: tensor([[[ 0.0110,  0.8184],
         [-0.0008,  0.4443],
         [-0.0032,  0.3079],
         [-0.0043,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.245106, steer=0.004147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.40125360412636
11.957366490736604 seconds in game passed.
Action: tensor([[[ 0.0110,  0.8184],
         [-0.0008,  0.4443],
         [-0.0032,  0.3079],
         [-0.0043,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.226320, steer=0.004211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.40125360412636
11.982366491109133 seconds in game passed.
Action: tensor([[[ 0.0110,  0.8184],
         [-0.0008,  0.4443],
         [-0.0032,  0.3079],
         [-0.0043,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.207988, steer=0.004275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.40125360412636
+++++++++++++: 1.2868635137399957
12.007366491481662 seconds in game passed.
At 12.007366491481662 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0016,  1.0000],
         [-0.0051,  1.0000],
         [-0.0086,  1.0000],
         [-0.0097,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001761, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2868635137399957
Current reward: 0.3925744292320604
Current mitigation activation: 1
#############################
Total reward: 26.79382803335842
12.03236649185419 seconds in game passed.
Action: tensor([[[ 0.0016,  1.0000],
         [-0.0051,  1.0000],
         [-0.0086,  1.0000],
         [-0.0097,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000741, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.79382803335842
12.05736649222672 seconds in game passed.
Action: tensor([[[ 0.0016,  1.0000],
         [-0.0051,  1.0000],
         [-0.0086,  1.0000],
         [-0.0097,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000729, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.79382803335842
12.082366492599249 seconds in game passed.
Action: tensor([[[ 0.0016,  1.0000],
         [-0.0051,  1.0000],
         [-0.0086,  1.0000],
         [-0.0097,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000717, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.79382803335842
+++++++++++++: 1.2634357384382036
12.107366492971778 seconds in game passed.
At 12.107366492971778 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0034,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000703, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2634357384382036
Current reward: 0.38626186496302617
Current mitigation activation: 1
#############################
Total reward: 27.180089898321445
12.132366493344307 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0034,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000454, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.180089898321445
12.157366493716836 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0034,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000443, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.180089898321445
12.182366494089365 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0034,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000433, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.180089898321445
+++++++++++++: 1.2820744575511036
12.207366494461894 seconds in game passed.
At 12.207366494461894 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0036,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0184,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006981, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2820744575511036
Current reward: 0.3724429119053647
Current mitigation activation: 1
#############################
Total reward: 27.552532810226808
12.232366494834423 seconds in game passed.
Action: tensor([[[ 0.0036,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0184,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005840, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.552532810226808
12.257366495206952 seconds in game passed.
Action: tensor([[[ 0.0036,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0184,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005921, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.552532810226808
12.282366495579481 seconds in game passed.
Action: tensor([[[ 0.0036,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0184,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006002, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.552532810226808
+++++++++++++: 1.3675746814902865
12.30736649595201 seconds in game passed.
At 12.30736649595201 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0032,  0.9401],
         [-0.0105,  0.5613],
         [-0.0118,  0.3680],
         [-0.0106,  0.2746]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004314, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3675746814902865
Current reward: 0.34924357676090034
Current mitigation activation: 0
#############################
Total reward: 27.90177638698771
12.33236649632454 seconds in game passed.
Action: tensor([[[ 0.0032,  0.9401],
         [-0.0105,  0.5613],
         [-0.0118,  0.3680],
         [-0.0106,  0.2746]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004702, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.90177638698771
12.357366496697068 seconds in game passed.
Action: tensor([[[ 0.0032,  0.9401],
         [-0.0105,  0.5613],
         [-0.0118,  0.3680],
         [-0.0106,  0.2746]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004793, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.90177638698771
12.382366497069597 seconds in game passed.
Action: tensor([[[ 0.0032,  0.9401],
         [-0.0105,  0.5613],
         [-0.0118,  0.3680],
         [-0.0106,  0.2746]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004885, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.90177638698771
+++++++++++++: 1.5052179138062038
12.407366497442126 seconds in game passed.
At 12.407366497442126 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0072,  0.9438],
         [-0.0140,  0.5748],
         [-0.0154,  0.3670],
         [-0.0141,  0.2706]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005729, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5052179138062038
Current reward: 0.323498674901435
Current mitigation activation: 0
#############################
Total reward: 28.225275061889143
12.432366497814655 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9438],
         [-0.0140,  0.5748],
         [-0.0154,  0.3670],
         [-0.0141,  0.2706]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005709, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.225275061889143
12.457366498187184 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9438],
         [-0.0140,  0.5748],
         [-0.0154,  0.3670],
         [-0.0141,  0.2706]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005813, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.225275061889143
12.482366498559713 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9438],
         [-0.0140,  0.5748],
         [-0.0154,  0.3670],
         [-0.0141,  0.2706]]])
agent 0 action: VehicleControl(throttle=0.002858, steer=-0.005917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.225275061889143
+++++++++++++: 1.6913642483217677
12.507366498932242 seconds in game passed.
At 12.507366498932242 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0104,  0.9457],
         [-0.0121,  0.5947],
         [-0.0134,  0.3713],
         [-0.0109,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002955, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6913642483217677
Current reward: 0.2986747956224288
Current mitigation activation: 0
#############################
Total reward: 28.52394985751157
12.532366499304771 seconds in game passed.
Action: tensor([[[ 0.0104,  0.9457],
         [-0.0121,  0.5947],
         [-0.0134,  0.3713],
         [-0.0109,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.000596, steer=-0.003550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.52394985751157
12.5573664996773 seconds in game passed.
Action: tensor([[[ 0.0104,  0.9457],
         [-0.0121,  0.5947],
         [-0.0134,  0.3713],
         [-0.0109,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.000099, steer=-0.003637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.52394985751157
12.58236650004983 seconds in game passed.
Action: tensor([[[ 0.0104,  0.9457],
         [-0.0121,  0.5947],
         [-0.0134,  0.3713],
         [-0.0109,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.52394985751157
+++++++++++++: 1.91651742602581
12.607366500422359 seconds in game passed.
At 12.607366500422359 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0117,  0.9441],
         [-0.0088,  0.5834],
         [-0.0099,  0.3659],
         [-0.0073,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.91651742602581
Current reward: 0.27716793891162295
Current mitigation activation: 0
#############################
Total reward: 28.801117796423195
12.632366500794888 seconds in game passed.
Action: tensor([[[ 0.0117,  0.9441],
         [-0.0088,  0.5834],
         [-0.0099,  0.3659],
         [-0.0073,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.012206, steer=-0.001464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.801117796423195
12.657366501167417 seconds in game passed.
Action: tensor([[[ 0.0117,  0.9441],
         [-0.0088,  0.5834],
         [-0.0099,  0.3659],
         [-0.0073,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.015949, steer=-0.001540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.801117796423195
12.682366501539946 seconds in game passed.
Action: tensor([[[ 0.0117,  0.9441],
         [-0.0088,  0.5834],
         [-0.0099,  0.3659],
         [-0.0073,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.016515, steer=-0.001615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.801117796423195
+++++++++++++: 2.0311271221483786
12.707366501912475 seconds in game passed.
At 12.707366501912475 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.9447],
         [-0.0082,  0.6033],
         [-0.0067,  0.3784],
         [-0.0041,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007835, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0311271221483786
Current reward: 0.2689475959435075
Current mitigation activation: 0
#############################
Total reward: 29.070065392366704
12.732366502285004 seconds in game passed.
Action: tensor([[[-0.0027,  0.9447],
         [-0.0082,  0.6033],
         [-0.0067,  0.3784],
         [-0.0041,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.000522, steer=-0.006972, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.070065392366704
12.757366502657533 seconds in game passed.
Action: tensor([[[-0.0027,  0.9447],
         [-0.0082,  0.6033],
         [-0.0067,  0.3784],
         [-0.0041,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.000522, steer=-0.007120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.070065392366704
12.782366503030062 seconds in game passed.
Action: tensor([[[-0.0027,  0.9447],
         [-0.0082,  0.6033],
         [-0.0067,  0.3784],
         [-0.0041,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.000522, steer=-0.007269, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.070065392366704
+++++++++++++: 2.128020386660326
12.80736650340259 seconds in game passed.
At 12.80736650340259 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0103, 0.9386],
         [0.0056, 0.5473],
         [0.0018, 0.3618],
         [0.0017, 0.2636]]])
agent 0 action: VehicleControl(throttle=0.635153, steer=0.008665, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.128020386660326
Current reward: 0.26339093617053366
Current mitigation activation: 0
#############################
Total reward: 29.33345632853724
12.83236650377512 seconds in game passed.
Action: tensor([[[0.0103, 0.9386],
         [0.0056, 0.5473],
         [0.0018, 0.3618],
         [0.0017, 0.2636]]])
agent 0 action: VehicleControl(throttle=0.627553, steer=0.006079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.33345632853724
12.857366504147649 seconds in game passed.
Action: tensor([[[0.0103, 0.9386],
         [0.0056, 0.5473],
         [0.0018, 0.3618],
         [0.0017, 0.2636]]])
agent 0 action: VehicleControl(throttle=0.679397, steer=0.006139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.33345632853724
12.882366504520178 seconds in game passed.
Action: tensor([[[0.0103, 0.9386],
         [0.0056, 0.5473],
         [0.0018, 0.3618],
         [0.0017, 0.2636]]])
agent 0 action: VehicleControl(throttle=0.727813, steer=0.006199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.33345632853724
+++++++++++++: 2.3517527636843316
12.907366504892707 seconds in game passed.
At 12.907366504892707 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0079, 0.9341],
         [0.0046, 0.5284],
         [0.0012, 0.3510],
         [0.0010, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3517527636843316
Current reward: 0.2516575132844113
Current mitigation activation: 0
#############################
Total reward: 29.58511384182165
12.932366505265236 seconds in game passed.
Action: tensor([[[0.0079, 0.9341],
         [0.0046, 0.5284],
         [0.0012, 0.3510],
         [0.0010, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.58511384182165
12.957366505637765 seconds in game passed.
Action: tensor([[[0.0079, 0.9341],
         [0.0046, 0.5284],
         [0.0012, 0.3510],
         [0.0010, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.58511384182165
12.982366506010294 seconds in game passed.
Action: tensor([[[0.0079, 0.9341],
         [0.0046, 0.5284],
         [0.0012, 0.3510],
         [0.0010, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.58511384182165
+++++++++++++: 2.529781504175831
13.007366506382823 seconds in game passed.
At 13.007366506382823 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0053, 0.9300],
         [0.0048, 0.5175],
         [0.0026, 0.3445],
         [0.0026, 0.2532]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.529781504175831
Current reward: 0.24503871163361335
Current mitigation activation: 0
#############################
Total reward: 29.83015255345526
13.032366506755352 seconds in game passed.
Action: tensor([[[0.0053, 0.9300],
         [0.0048, 0.5175],
         [0.0026, 0.3445],
         [0.0026, 0.2532]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.83015255345526
13.057366507127881 seconds in game passed.
Action: tensor([[[0.0053, 0.9300],
         [0.0048, 0.5175],
         [0.0026, 0.3445],
         [0.0026, 0.2532]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.83015255345526
13.08236650750041 seconds in game passed.
Action: tensor([[[0.0053, 0.9300],
         [0.0048, 0.5175],
         [0.0026, 0.3445],
         [0.0026, 0.2532]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.83015255345526
+++++++++++++: 2.5627933991453125
13.107366507872939 seconds in game passed.
At 13.107366507872939 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.7754e-03, 9.1481e-01],
         [3.3795e-03, 4.9716e-01],
         [4.2178e-04, 3.3446e-01],
         [2.4958e-04, 2.4769e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5627933991453125
Current reward: 0.24634034216017292
Current mitigation activation: 0
#############################
Total reward: 30.076492895615434
13.132366508245468 seconds in game passed.
Action: tensor([[[7.7754e-03, 9.1481e-01],
         [3.3795e-03, 4.9716e-01],
         [4.2178e-04, 3.3446e-01],
         [2.4958e-04, 2.4769e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.076492895615434
13.157366508617997 seconds in game passed.
Action: tensor([[[7.7754e-03, 9.1481e-01],
         [3.3795e-03, 4.9716e-01],
         [4.2178e-04, 3.3446e-01],
         [2.4958e-04, 2.4769e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.076492895615434
13.182366508990526 seconds in game passed.
Action: tensor([[[7.7754e-03, 9.1481e-01],
         [3.3795e-03, 4.9716e-01],
         [4.2178e-04, 3.3446e-01],
         [2.4958e-04, 2.4769e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.076492895615434
+++++++++++++: 2.4830745434608774
13.207366509363055 seconds in game passed.
At 13.207366509363055 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1837e-03,  9.0486e-01],
         [ 1.2980e-03,  4.9119e-01],
         [-7.4968e-05,  3.3455e-01],
         [ 5.3194e-04,  2.5075e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4830745434608774
Current reward: 0.25303992172034717
Current mitigation activation: 0
#############################
Total reward: 30.32953281733578
13.232366509735584 seconds in game passed.
Action: tensor([[[ 1.1837e-03,  9.0486e-01],
         [ 1.2980e-03,  4.9119e-01],
         [-7.4968e-05,  3.3455e-01],
         [ 5.3194e-04,  2.5075e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.32953281733578
13.257366510108113 seconds in game passed.
Action: tensor([[[ 1.1837e-03,  9.0486e-01],
         [ 1.2980e-03,  4.9119e-01],
         [-7.4968e-05,  3.3455e-01],
         [ 5.3194e-04,  2.5075e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001246, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.32953281733578
13.282366510480642 seconds in game passed.
Action: tensor([[[ 1.1837e-03,  9.0486e-01],
         [ 1.2980e-03,  4.9119e-01],
         [-7.4968e-05,  3.3455e-01],
         [ 5.3194e-04,  2.5075e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.32953281733578
+++++++++++++: 2.3582793584137702
13.307366510853171 seconds in game passed.
At 13.307366510853171 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.6341e-03,  9.0692e-01],
         [-3.4504e-04,  5.0510e-01],
         [-8.8519e-04,  3.4918e-01],
         [-3.7253e-05,  2.6515e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3582793584137702
Current reward: 0.26212503002695636
Current mitigation activation: 0
#############################
Total reward: 30.59165784736274
13.3323665112257 seconds in game passed.
Action: tensor([[[-5.6341e-03,  9.0692e-01],
         [-3.4504e-04,  5.0510e-01],
         [-8.8519e-04,  3.4918e-01],
         [-3.7253e-05,  2.6515e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.59165784736274
13.35736651159823 seconds in game passed.
Action: tensor([[[-5.6341e-03,  9.0692e-01],
         [-3.4504e-04,  5.0510e-01],
         [-8.8519e-04,  3.4918e-01],
         [-3.7253e-05,  2.6515e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.59165784736274
13.382366511970758 seconds in game passed.
Action: tensor([[[-5.6341e-03,  9.0692e-01],
         [-3.4504e-04,  5.0510e-01],
         [-8.8519e-04,  3.4918e-01],
         [-3.7253e-05,  2.6515e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.59165784736274
+++++++++++++: 2.2217471612258293
13.407366512343287 seconds in game passed.
At 13.407366512343287 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0043,  0.9015],
         [-0.0033,  0.5132],
         [-0.0044,  0.3670],
         [-0.0032,  0.2879]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2217471612258293
Current reward: 0.27215069337290165
Current mitigation activation: 0
#############################
Total reward: 30.86380854073564
13.432366512715816 seconds in game passed.
Action: tensor([[[-0.0043,  0.9015],
         [-0.0033,  0.5132],
         [-0.0044,  0.3670],
         [-0.0032,  0.2879]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.86380854073564
13.457366513088346 seconds in game passed.
Action: tensor([[[-0.0043,  0.9015],
         [-0.0033,  0.5132],
         [-0.0044,  0.3670],
         [-0.0032,  0.2879]]])
agent 0 action: VehicleControl(throttle=0.894748, steer=-0.003263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.86380854073564
13.482366513460875 seconds in game passed.
Action: tensor([[[-0.0043,  0.9015],
         [-0.0033,  0.5132],
         [-0.0044,  0.3670],
         [-0.0032,  0.2879]]])
agent 0 action: VehicleControl(throttle=0.864254, steer=-0.003234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.86380854073564
+++++++++++++: 2.0874530286427277
13.507366513833404 seconds in game passed.
At 13.507366513833404 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.5420e-04,  8.7779e-01],
         [-1.3296e-03,  5.0272e-01],
         [-2.9126e-03,  3.6238e-01],
         [-2.2353e-03,  2.8485e-01]]])
agent 0 action: VehicleControl(throttle=0.874789, steer=0.000521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0874530286427277
Current reward: 0.282397774787554
Current mitigation activation: 0
#############################
Total reward: 31.146206315523195
13.532366514205933 seconds in game passed.
Action: tensor([[[ 8.5420e-04,  8.7779e-01],
         [-1.3296e-03,  5.0272e-01],
         [-2.9126e-03,  3.6238e-01],
         [-2.2353e-03,  2.8485e-01]]])
agent 0 action: VehicleControl(throttle=0.839374, steer=-0.000063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.146206315523195
13.557366514578462 seconds in game passed.
Action: tensor([[[ 8.5420e-04,  8.7779e-01],
         [-1.3296e-03,  5.0272e-01],
         [-2.9126e-03,  3.6238e-01],
         [-2.2353e-03,  2.8485e-01]]])
agent 0 action: VehicleControl(throttle=0.808155, steer=-0.000028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.146206315523195
13.58236651495099 seconds in game passed.
Action: tensor([[[ 8.5420e-04,  8.7779e-01],
         [-1.3296e-03,  5.0272e-01],
         [-2.9126e-03,  3.6238e-01],
         [-2.2353e-03,  2.8485e-01]]])
agent 0 action: VehicleControl(throttle=0.776615, steer=0.000008, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.146206315523195
+++++++++++++: 1.961092060754638
13.60736651532352 seconds in game passed.
At 13.60736651532352 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0060,  0.8906],
         [-0.0011,  0.4980],
         [-0.0023,  0.3501],
         [-0.0021,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.883966, steer=-0.002759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.961092060754638
Current reward: 0.29244391414246057
Current mitigation activation: 0
#############################
Total reward: 31.438650229665654
13.632366515696049 seconds in game passed.
Action: tensor([[[-0.0060,  0.8906],
         [-0.0011,  0.4980],
         [-0.0023,  0.3501],
         [-0.0021,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.839912, steer=-0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.438650229665654
13.657366516068578 seconds in game passed.
Action: tensor([[[-0.0060,  0.8906],
         [-0.0011,  0.4980],
         [-0.0023,  0.3501],
         [-0.0021,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.810888, steer=-0.002348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.438650229665654
13.682366516441107 seconds in game passed.
Action: tensor([[[-0.0060,  0.8906],
         [-0.0011,  0.4980],
         [-0.0023,  0.3501],
         [-0.0021,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.781353, steer=-0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.438650229665654
+++++++++++++: 1.847830847154857
13.707366516813636 seconds in game passed.
At 13.707366516813636 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0032,  0.9221],
         [-0.0012,  0.5117],
         [-0.0032,  0.3483],
         [-0.0028,  0.2617]]])
agent 0 action: VehicleControl(throttle=0.691549, steer=-0.001251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.847830847154857
Current reward: 0.3017149040261385
Current mitigation activation: 0
#############################
Total reward: 31.740365133691792
13.732366517186165 seconds in game passed.
Action: tensor([[[-0.0032,  0.9221],
         [-0.0012,  0.5117],
         [-0.0032,  0.3483],
         [-0.0028,  0.2617]]])
agent 0 action: VehicleControl(throttle=0.668307, steer=-0.001378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.740365133691792
13.757366517558694 seconds in game passed.
Action: tensor([[[-0.0032,  0.9221],
         [-0.0012,  0.5117],
         [-0.0032,  0.3483],
         [-0.0028,  0.2617]]])
agent 0 action: VehicleControl(throttle=0.639422, steer=-0.001327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.740365133691792
13.782366517931223 seconds in game passed.
Action: tensor([[[-0.0032,  0.9221],
         [-0.0012,  0.5117],
         [-0.0032,  0.3483],
         [-0.0028,  0.2617]]])
agent 0 action: VehicleControl(throttle=0.612018, steer=-0.001276, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.740365133691792
+++++++++++++: 1.7477791835786154
13.807366518303752 seconds in game passed.
At 13.807366518303752 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0061,  0.9305],
         [-0.0029,  0.5079],
         [-0.0060,  0.3391],
         [-0.0052,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.674355, steer=0.001218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7477791835786154
Current reward: 0.30996178923661144
Current mitigation activation: 0
#############################
Total reward: 32.050326922928406
13.832366518676281 seconds in game passed.
Action: tensor([[[ 0.0061,  0.9305],
         [-0.0029,  0.5079],
         [-0.0060,  0.3391],
         [-0.0052,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.633537, steer=0.000701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.050326922928406
13.85736651904881 seconds in game passed.
Action: tensor([[[ 0.0061,  0.9305],
         [-0.0029,  0.5079],
         [-0.0060,  0.3391],
         [-0.0052,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.603769, steer=0.000614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.050326922928406
13.882366519421339 seconds in game passed.
Action: tensor([[[ 0.0061,  0.9305],
         [-0.0029,  0.5079],
         [-0.0060,  0.3391],
         [-0.0052,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.574400, steer=0.000526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.050326922928406
+++++++++++++: 1.6665728065006438
13.907366519793868 seconds in game passed.
At 13.907366519793868 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0041,  0.9378],
         [-0.0026,  0.5249],
         [-0.0046,  0.3431],
         [-0.0026,  0.2523]]])
agent 0 action: VehicleControl(throttle=0.336227, steer=-0.000101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6665728065006438
Current reward: 0.3163316017256316
Current mitigation activation: 0
#############################
Total reward: 32.366658524654035
13.932366520166397 seconds in game passed.
Action: tensor([[[ 0.0041,  0.9378],
         [-0.0026,  0.5249],
         [-0.0046,  0.3431],
         [-0.0026,  0.2523]]])
agent 0 action: VehicleControl(throttle=0.348753, steer=-0.000083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.366658524654035
13.957366520538926 seconds in game passed.
Action: tensor([[[ 0.0041,  0.9378],
         [-0.0026,  0.5249],
         [-0.0046,  0.3431],
         [-0.0026,  0.2523]]])
agent 0 action: VehicleControl(throttle=0.336437, steer=-0.000157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.366658524654035
13.982366520911455 seconds in game passed.
Action: tensor([[[ 0.0041,  0.9378],
         [-0.0026,  0.5249],
         [-0.0046,  0.3431],
         [-0.0026,  0.2523]]])
agent 0 action: VehicleControl(throttle=0.323950, steer=-0.000231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.366658524654035
+++++++++++++: 1.6043020020149497
14.007366521283984 seconds in game passed.
At 14.007366521283984 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0047,  0.9404],
         [-0.0016,  0.5421],
         [-0.0033,  0.3542],
         [-0.0013,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.309880, steer=0.000788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6043020020149497
Current reward: 0.3204977166111762
Current mitigation activation: 0
#############################
Total reward: 32.687156241265214
14.032366521656513 seconds in game passed.
Action: tensor([[[ 0.0047,  0.9404],
         [-0.0016,  0.5421],
         [-0.0033,  0.3542],
         [-0.0013,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.295842, steer=0.000556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.687156241265214
14.057366522029042 seconds in game passed.
Action: tensor([[[ 0.0047,  0.9404],
         [-0.0016,  0.5421],
         [-0.0033,  0.3542],
         [-0.0013,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.281914, steer=0.000503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.687156241265214
14.082366522401571 seconds in game passed.
Action: tensor([[[ 0.0047,  0.9404],
         [-0.0016,  0.5421],
         [-0.0033,  0.3542],
         [-0.0013,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.268159, steer=0.000450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.687156241265214
+++++++++++++: 1.5699692112492207
14.1073665227741 seconds in game passed.
At 14.1073665227741 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0046,  0.9401],
         [-0.0046,  0.5464],
         [-0.0063,  0.3540],
         [-0.0043,  0.2573]]])
agent 0 action: VehicleControl(throttle=0.251970, steer=-0.001814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5699692112492207
Current reward: 0.32117989813782755
Current mitigation activation: 0
#############################
Total reward: 33.00833613940304
14.13236652314663 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9401],
         [-0.0046,  0.5464],
         [-0.0063,  0.3540],
         [-0.0043,  0.2573]]])
agent 0 action: VehicleControl(throttle=0.236050, steer=-0.001524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.00833613940304
14.157366523519158 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9401],
         [-0.0046,  0.5464],
         [-0.0063,  0.3540],
         [-0.0043,  0.2573]]])
agent 0 action: VehicleControl(throttle=0.220435, steer=-0.001599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.00833613940304
14.182366523891687 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9401],
         [-0.0046,  0.5464],
         [-0.0063,  0.3540],
         [-0.0043,  0.2573]]])
agent 0 action: VehicleControl(throttle=0.205154, steer=-0.001673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.00833613940304
+++++++++++++: 1.5624628765947477
14.207366524264216 seconds in game passed.
At 14.207366524264216 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.0587e-04,  9.4006e-01],
         [-1.9591e-03,  5.4465e-01],
         [-4.0093e-03,  3.5520e-01],
         [-3.2543e-03,  2.6058e-01]]])
agent 0 action: VehicleControl(throttle=0.189697, steer=-0.002135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5624628765947477
Current reward: 0.318526064804621
Current mitigation activation: 0
#############################
Total reward: 33.326862204207664
14.232366524636745 seconds in game passed.
Action: tensor([[[-8.0587e-04,  9.4006e-01],
         [-1.9591e-03,  5.4465e-01],
         [-4.0093e-03,  3.5520e-01],
         [-3.2543e-03,  2.6058e-01]]])
agent 0 action: VehicleControl(throttle=0.174621, steer=-0.002098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.326862204207664
14.257366525009274 seconds in game passed.
Action: tensor([[[-8.0587e-04,  9.4006e-01],
         [-1.9591e-03,  5.4465e-01],
         [-4.0093e-03,  3.5520e-01],
         [-3.2543e-03,  2.6058e-01]]])
agent 0 action: VehicleControl(throttle=0.159944, steer=-0.002133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.326862204207664
14.282366525381804 seconds in game passed.
Action: tensor([[[-8.0587e-04,  9.4006e-01],
         [-1.9591e-03,  5.4465e-01],
         [-4.0093e-03,  3.5520e-01],
         [-3.2543e-03,  2.6058e-01]]])
agent 0 action: VehicleControl(throttle=0.145681, steer=-0.002167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.326862204207664
+++++++++++++: 1.5621677338869093
14.307366525754333 seconds in game passed.
At 14.307366525754333 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.0615e-03,  9.4367e-01],
         [-3.6788e-04,  5.7682e-01],
         [-1.0263e-03,  3.6879e-01],
         [-6.6238e-04,  2.6613e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003815, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5621677338869093
Current reward: 0.3151379632852501
Current mitigation activation: 0
#############################
Total reward: 33.64200016749292
14.332366526126862 seconds in game passed.
Action: tensor([[[-7.0615e-03,  9.4367e-01],
         [-3.6788e-04,  5.7682e-01],
         [-1.0263e-03,  3.6879e-01],
         [-6.6238e-04,  2.6613e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003551, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.64200016749292
14.35736652649939 seconds in game passed.
Action: tensor([[[-7.0615e-03,  9.4367e-01],
         [-3.6788e-04,  5.7682e-01],
         [-1.0263e-03,  3.6879e-01],
         [-6.6238e-04,  2.6613e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003559, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.64200016749292
14.38236652687192 seconds in game passed.
Action: tensor([[[-7.0615e-03,  9.4367e-01],
         [-3.6788e-04,  5.7682e-01],
         [-1.0263e-03,  3.6879e-01],
         [-6.6238e-04,  2.6613e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003568, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.64200016749292
+++++++++++++: 1.557502873558763
14.407366527244449 seconds in game passed.
At 14.407366527244449 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1935e-02,  9.4338e-01],
         [ 2.5680e-04,  6.0469e-01],
         [-3.1085e-04,  4.0671e-01],
         [-1.0046e-03,  3.0895e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005502, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.557502873558763
Current reward: 0.31245803145936046
Current mitigation activation: 0
#############################
Total reward: 33.954458198952274
14.432366527616978 seconds in game passed.
Action: tensor([[[-1.1935e-02,  9.4338e-01],
         [ 2.5680e-04,  6.0469e-01],
         [-3.1085e-04,  4.0671e-01],
         [-1.0046e-03,  3.0895e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005192, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.954458198952274
14.457366527989507 seconds in game passed.
Action: tensor([[[-1.1935e-02,  9.4338e-01],
         [ 2.5680e-04,  6.0469e-01],
         [-3.1085e-04,  4.0671e-01],
         [-1.0046e-03,  3.0895e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005203, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.954458198952274
14.482366528362036 seconds in game passed.
Action: tensor([[[-1.1935e-02,  9.4338e-01],
         [ 2.5680e-04,  6.0469e-01],
         [-3.1085e-04,  4.0671e-01],
         [-1.0046e-03,  3.0895e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005213, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.954458198952274
+++++++++++++: 1.6452130422864892
14.507366528734565 seconds in game passed.
At 14.507366528734565 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0194,  0.9427],
         [-0.0045,  0.5860],
         [-0.0044,  0.3853],
         [-0.0038,  0.2832]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012104, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6452130422864892
Current reward: 0.29976664756414495
Current mitigation activation: 0
#############################
Total reward: 34.25422484651642
14.532366529107094 seconds in game passed.
Action: tensor([[[-0.0194,  0.9427],
         [-0.0045,  0.5860],
         [-0.0044,  0.3853],
         [-0.0038,  0.2832]]])
agent 0 action: VehicleControl(throttle=0.059672, steer=-0.011096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.25422484651642
14.557366529479623 seconds in game passed.
Action: tensor([[[-0.0194,  0.9427],
         [-0.0045,  0.5860],
         [-0.0044,  0.3853],
         [-0.0038,  0.2832]]])
agent 0 action: VehicleControl(throttle=0.053895, steer=-0.011216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.25422484651642
14.582366529852152 seconds in game passed.
Action: tensor([[[-0.0194,  0.9427],
         [-0.0045,  0.5860],
         [-0.0044,  0.3853],
         [-0.0038,  0.2832]]])
agent 0 action: VehicleControl(throttle=0.048579, steer=-0.011336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.25422484651642
+++++++++++++: 1.8631328783397993
14.607366530224681 seconds in game passed.
At 14.607366530224681 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0236,  0.9480],
         [-0.0071,  0.6359],
         [-0.0038,  0.3926],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015785, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8631328783397993
Current reward: 0.27784194012409535
Current mitigation activation: 0
#############################
Total reward: 34.53206678664052
14.63236653059721 seconds in game passed.
Action: tensor([[[-0.0236,  0.9480],
         [-0.0071,  0.6359],
         [-0.0038,  0.3926],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015203, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.53206678664052
14.657366530969739 seconds in game passed.
Action: tensor([[[-0.0236,  0.9480],
         [-0.0071,  0.6359],
         [-0.0038,  0.3926],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015339, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.53206678664052
14.682366531342268 seconds in game passed.
Action: tensor([[[-0.0236,  0.9480],
         [-0.0071,  0.6359],
         [-0.0038,  0.3926],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015476, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.53206678664052
+++++++++++++: 2.038853201839065
14.707366531714797 seconds in game passed.
At 14.707366531714797 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5959e-02,  9.4852e-01],
         [-9.0592e-04,  6.4490e-01],
         [-1.7509e-05,  4.0122e-01],
         [ 8.6667e-04,  2.8922e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007483, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.038853201839065
Current reward: 0.26475586154480935
Current mitigation activation: 0
#############################
Total reward: 34.796822648185326
14.732366532087326 seconds in game passed.
Action: tensor([[[-1.5959e-02,  9.4852e-01],
         [-9.0592e-04,  6.4490e-01],
         [-1.7509e-05,  4.0122e-01],
         [ 8.6667e-04,  2.8922e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008890, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.796822648185326
14.757366532459855 seconds in game passed.
Action: tensor([[[-1.5959e-02,  9.4852e-01],
         [-9.0592e-04,  6.4490e-01],
         [-1.7509e-05,  4.0122e-01],
         [ 8.6667e-04,  2.8922e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008953, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.796822648185326
14.782366532832384 seconds in game passed.
Action: tensor([[[-1.5959e-02,  9.4852e-01],
         [-9.0592e-04,  6.4490e-01],
         [-1.7509e-05,  4.0122e-01],
         [ 8.6667e-04,  2.8922e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009017, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.796822648185326
+++++++++++++: 2.2246049509521297
14.807366533204913 seconds in game passed.
At 14.807366533204913 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0081,  0.9467],
         [ 0.0022,  0.5970],
         [ 0.0014,  0.3799],
         [ 0.0017,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.164443, steer=-0.002820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2246049509521297
Current reward: 0.2541377158453268
Current mitigation activation: 0
#############################
Total reward: 35.05096036403065
14.832366533577442 seconds in game passed.
Action: tensor([[[-0.0081,  0.9467],
         [ 0.0022,  0.5970],
         [ 0.0014,  0.3799],
         [ 0.0017,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.194416, steer=-0.003882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.05096036403065
14.857366533949971 seconds in game passed.
Action: tensor([[[-0.0081,  0.9467],
         [ 0.0022,  0.5970],
         [ 0.0014,  0.3799],
         [ 0.0017,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.237089, steer=-0.003908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.05096036403065
14.8823665343225 seconds in game passed.
Action: tensor([[[-0.0081,  0.9467],
         [ 0.0022,  0.5970],
         [ 0.0014,  0.3799],
         [ 0.0017,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.270496, steer=-0.003934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.05096036403065
+++++++++++++: 2.405931249835208
14.90736653469503 seconds in game passed.
At 14.90736653469503 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.5550e-04,  9.4210e-01],
         [ 3.1661e-03,  5.4785e-01],
         [ 1.3207e-03,  3.5610e-01],
         [ 1.6541e-03,  2.5994e-01]]])
agent 0 action: VehicleControl(throttle=0.864353, steer=0.000316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.405931249835208
Current reward: 0.24625822757606128
Current mitigation activation: 0
#############################
Total reward: 35.297218591606715
14.932366535067558 seconds in game passed.
Action: tensor([[[-7.5550e-04,  9.4210e-01],
         [ 3.1661e-03,  5.4785e-01],
         [ 1.3207e-03,  3.5610e-01],
         [ 1.6541e-03,  2.5994e-01]]])
agent 0 action: VehicleControl(throttle=0.821698, steer=-0.000364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.297218591606715
14.957366535440087 seconds in game passed.
Action: tensor([[[-7.5550e-04,  9.4210e-01],
         [ 3.1661e-03,  5.4785e-01],
         [ 1.3207e-03,  3.5610e-01],
         [ 1.6541e-03,  2.5994e-01]]])
agent 0 action: VehicleControl(throttle=0.833863, steer=-0.000340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.297218591606715
14.982366535812616 seconds in game passed.
Action: tensor([[[-7.5550e-04,  9.4210e-01],
         [ 3.1661e-03,  5.4785e-01],
         [ 1.3207e-03,  3.5610e-01],
         [ 1.6541e-03,  2.5994e-01]]])
agent 0 action: VehicleControl(throttle=0.844416, steer=-0.000316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.297218591606715
+++++++++++++: 2.5194464540382295
15.007366536185145 seconds in game passed.
At 15.007366536185145 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.9417e-03,  9.3051e-01],
         [ 2.0740e-03,  5.1224e-01],
         [-3.6359e-06,  3.4169e-01],
         [ 1.2067e-04,  2.5147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5194464540382295
Current reward: 0.24333276916575608
Current mitigation activation: 0
#############################
Total reward: 35.54055136077247
15.032366536557674 seconds in game passed.
Action: tensor([[[-2.9417e-03,  9.3051e-01],
         [ 2.0740e-03,  5.1224e-01],
         [-3.6359e-06,  3.4169e-01],
         [ 1.2067e-04,  2.5147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.54055136077247
15.057366536930203 seconds in game passed.
Action: tensor([[[-2.9417e-03,  9.3051e-01],
         [ 2.0740e-03,  5.1224e-01],
         [-3.6359e-06,  3.4169e-01],
         [ 1.2067e-04,  2.5147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.54055136077247
15.082366537302732 seconds in game passed.
Action: tensor([[[-2.9417e-03,  9.3051e-01],
         [ 2.0740e-03,  5.1224e-01],
         [-3.6359e-06,  3.4169e-01],
         [ 1.2067e-04,  2.5147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001749, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.54055136077247
+++++++++++++: 2.5157385800849994
15.107366537675261 seconds in game passed.
At 15.107366537675261 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.8946e-03, 9.2760e-01],
         [3.7059e-03, 5.0427e-01],
         [4.7939e-04, 3.3432e-01],
         [2.2914e-04, 2.4419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5157385800849994
Current reward: 0.24641172375438947
Current mitigation activation: 0
#############################
Total reward: 35.78696308452686
15.13236653804779 seconds in game passed.
Action: tensor([[[2.8946e-03, 9.2760e-01],
         [3.7059e-03, 5.0427e-01],
         [4.7939e-04, 3.3432e-01],
         [2.2914e-04, 2.4419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001424, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.78696308452686
15.15736653842032 seconds in game passed.
Action: tensor([[[2.8946e-03, 9.2760e-01],
         [3.7059e-03, 5.0427e-01],
         [4.7939e-04, 3.3432e-01],
         [2.2914e-04, 2.4419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.78696308452686
15.182366538792849 seconds in game passed.
Action: tensor([[[2.8946e-03, 9.2760e-01],
         [3.7059e-03, 5.0427e-01],
         [4.7939e-04, 3.3432e-01],
         [2.2914e-04, 2.4419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.78696308452686
+++++++++++++: 2.43537582185023
15.207366539165378 seconds in game passed.
At 15.207366539165378 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4685e-02, 9.1558e-01],
         [4.5378e-03, 4.9522e-01],
         [8.5925e-04, 3.2980e-01],
         [7.4327e-04, 2.3983e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.43537582185023
Current reward: 0.2531881809940533
Current mitigation activation: 0
#############################
Total reward: 36.04015126552091
15.232366539537907 seconds in game passed.
Action: tensor([[[1.4685e-02, 9.1558e-01],
         [4.5378e-03, 4.9522e-01],
         [8.5925e-04, 3.2980e-01],
         [7.4327e-04, 2.3983e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.04015126552091
15.257366539910436 seconds in game passed.
Action: tensor([[[1.4685e-02, 9.1558e-01],
         [4.5378e-03, 4.9522e-01],
         [8.5925e-04, 3.2980e-01],
         [7.4327e-04, 2.3983e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.04015126552091
15.282366540282965 seconds in game passed.
Action: tensor([[[1.4685e-02, 9.1558e-01],
         [4.5378e-03, 4.9522e-01],
         [8.5925e-04, 3.2980e-01],
         [7.4327e-04, 2.3983e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.04015126552091
+++++++++++++: 2.3208793052722325
15.307366540655494 seconds in game passed.
At 15.307366540655494 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0158, 0.9112],
         [0.0048, 0.4956],
         [0.0020, 0.3311],
         [0.0021, 0.2404]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3208793052722325
Current reward: 0.26181088843944333
Current mitigation activation: 0
#############################
Total reward: 36.30196215396035
15.332366541028023 seconds in game passed.
Action: tensor([[[0.0158, 0.9112],
         [0.0048, 0.4956],
         [0.0020, 0.3311],
         [0.0021, 0.2404]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.30196215396035
15.357366541400552 seconds in game passed.
Action: tensor([[[0.0158, 0.9112],
         [0.0048, 0.4956],
         [0.0020, 0.3311],
         [0.0021, 0.2404]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.30196215396035
15.38236654177308 seconds in game passed.
Action: tensor([[[0.0158, 0.9112],
         [0.0048, 0.4956],
         [0.0020, 0.3311],
         [0.0021, 0.2404]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007706, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.30196215396035
+++++++++++++: 2.1974478824243997
15.40736654214561 seconds in game passed.
At 15.40736654214561 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0170, 0.9154],
         [0.0040, 0.4945],
         [0.0015, 0.3289],
         [0.0017, 0.2388]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1974478824243997
Current reward: 0.2711380407163866
Current mitigation activation: 0
#############################
Total reward: 36.57310019467674
15.432366542518139 seconds in game passed.
Action: tensor([[[0.0170, 0.9154],
         [0.0040, 0.4945],
         [0.0015, 0.3289],
         [0.0017, 0.2388]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007899, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.57310019467674
15.457366542890668 seconds in game passed.
Action: tensor([[[0.0170, 0.9154],
         [0.0040, 0.4945],
         [0.0015, 0.3289],
         [0.0017, 0.2388]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.57310019467674
15.482366543263197 seconds in game passed.
Action: tensor([[[0.0170, 0.9154],
         [0.0040, 0.4945],
         [0.0015, 0.3289],
         [0.0017, 0.2388]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.57310019467674
+++++++++++++: 2.0750760672308637
15.507366543635726 seconds in game passed.
At 15.507366543635726 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0139, 0.9158],
         [0.0039, 0.4894],
         [0.0021, 0.3264],
         [0.0027, 0.2385]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0750760672308637
Current reward: 0.2806438933080522
Current mitigation activation: 0
#############################
Total reward: 36.85374408798479
15.532366544008255 seconds in game passed.
Action: tensor([[[0.0139, 0.9158],
         [0.0039, 0.4894],
         [0.0021, 0.3264],
         [0.0027, 0.2385]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.85374408798479
15.557366544380784 seconds in game passed.
Action: tensor([[[0.0139, 0.9158],
         [0.0039, 0.4894],
         [0.0021, 0.3264],
         [0.0027, 0.2385]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007733, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.85374408798479
15.582366544753313 seconds in game passed.
Action: tensor([[[0.0139, 0.9158],
         [0.0039, 0.4894],
         [0.0021, 0.3264],
         [0.0027, 0.2385]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.85374408798479
+++++++++++++: 1.9572143133796844
15.607366545125842 seconds in game passed.
At 15.607366545125842 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.0520e-03,  9.2232e-01],
         [-1.3031e-05,  4.9523e-01],
         [-1.8348e-03,  3.2885e-01],
         [-1.3751e-03,  2.4097e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9572143133796844
Current reward: 0.29008536437815735
Current mitigation activation: 0
#############################
Total reward: 37.14382945236295
15.632366545498371 seconds in game passed.
Action: tensor([[[ 4.0520e-03,  9.2232e-01],
         [-1.3031e-05,  4.9523e-01],
         [-1.8348e-03,  3.2885e-01],
         [-1.3751e-03,  2.4097e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.14382945236295
15.6573665458709 seconds in game passed.
Action: tensor([[[ 4.0520e-03,  9.2232e-01],
         [-1.3031e-05,  4.9523e-01],
         [-1.8348e-03,  3.2885e-01],
         [-1.3751e-03,  2.4097e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.14382945236295
15.68236654624343 seconds in game passed.
Action: tensor([[[ 4.0520e-03,  9.2232e-01],
         [-1.3031e-05,  4.9523e-01],
         [-1.8348e-03,  3.2885e-01],
         [-1.3751e-03,  2.4097e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002867, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.14382945236295
+++++++++++++: 1.8449008894662295
15.707366546615958 seconds in game passed.
At 15.707366546615958 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.0971e-03,  9.2521e-01],
         [-5.3672e-04,  5.0318e-01],
         [-2.4412e-03,  3.3372e-01],
         [-1.5234e-03,  2.4414e-01]]])
agent 0 action: VehicleControl(throttle=0.851009, steer=-0.000403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8449008894662295
Current reward: 0.2993269836653243
Current mitigation activation: 0
#############################
Total reward: 37.443156436028275
15.732366546988487 seconds in game passed.
Action: tensor([[[-3.0971e-03,  9.2521e-01],
         [-5.3672e-04,  5.0318e-01],
         [-2.4412e-03,  3.3372e-01],
         [-1.5234e-03,  2.4414e-01]]])
agent 0 action: VehicleControl(throttle=0.832642, steer=0.000224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.443156436028275
15.757366547361016 seconds in game passed.
Action: tensor([[[-3.0971e-03,  9.2521e-01],
         [-5.3672e-04,  5.0318e-01],
         [-2.4412e-03,  3.3372e-01],
         [-1.5234e-03,  2.4414e-01]]])
agent 0 action: VehicleControl(throttle=0.802086, steer=0.000294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.443156436028275
15.782366547733545 seconds in game passed.
Action: tensor([[[-3.0971e-03,  9.2521e-01],
         [-5.3672e-04,  5.0318e-01],
         [-2.4412e-03,  3.3372e-01],
         [-1.5234e-03,  2.4414e-01]]])
agent 0 action: VehicleControl(throttle=0.771634, steer=0.000364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.443156436028275
+++++++++++++: 1.738570517604811
15.807366548106074 seconds in game passed.
At 15.807366548106074 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9497e-04,  9.3389e-01],
         [-4.5415e-04,  5.1201e-01],
         [-3.4935e-03,  3.3341e-01],
         [-3.3738e-03,  2.4174e-01]]])
agent 0 action: VehicleControl(throttle=0.644707, steer=0.001851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.738570517604811
Current reward: 0.30825581972668337
Current mitigation activation: 0
#############################
Total reward: 37.75141225575496
15.832366548478603 seconds in game passed.
Action: tensor([[[ 2.9497e-04,  9.3389e-01],
         [-4.5415e-04,  5.1201e-01],
         [-3.4935e-03,  3.3341e-01],
         [-3.3738e-03,  2.4174e-01]]])
agent 0 action: VehicleControl(throttle=0.621761, steer=0.001627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.75141225575496
15.857366548851132 seconds in game passed.
Action: tensor([[[ 2.9497e-04,  9.3389e-01],
         [-4.5415e-04,  5.1201e-01],
         [-3.4935e-03,  3.3341e-01],
         [-3.3738e-03,  2.4174e-01]]])
agent 0 action: VehicleControl(throttle=0.589249, steer=0.001648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.75141225575496
15.882366549223661 seconds in game passed.
Action: tensor([[[ 2.9497e-04,  9.3389e-01],
         [-4.5415e-04,  5.1201e-01],
         [-3.4935e-03,  3.3341e-01],
         [-3.3738e-03,  2.4174e-01]]])
agent 0 action: VehicleControl(throttle=0.558265, steer=0.001668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.75141225575496
+++++++++++++: 1.6431660189377157
15.90736654959619 seconds in game passed.
At 15.90736654959619 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8614e-03,  9.3575e-01],
         [-1.2159e-04,  5.1144e-01],
         [-3.4938e-03,  3.3459e-01],
         [-2.9613e-03,  2.4400e-01]]])
agent 0 action: VehicleControl(throttle=0.539376, steer=0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6431660189377157
Current reward: 0.31623905707284566
Current mitigation activation: 0
#############################
Total reward: 38.067651312827806
15.93236654996872 seconds in game passed.
Action: tensor([[[ 1.8614e-03,  9.3575e-01],
         [-1.2159e-04,  5.1144e-01],
         [-3.4938e-03,  3.3459e-01],
         [-2.9613e-03,  2.4400e-01]]])
agent 0 action: VehicleControl(throttle=0.503914, steer=0.002393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.067651312827806
15.957366550341249 seconds in game passed.
Action: tensor([[[ 1.8614e-03,  9.3575e-01],
         [-1.2159e-04,  5.1144e-01],
         [-3.4938e-03,  3.3459e-01],
         [-2.9613e-03,  2.4400e-01]]])
agent 0 action: VehicleControl(throttle=0.472169, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.067651312827806
15.982366550713778 seconds in game passed.
Action: tensor([[[ 1.8614e-03,  9.3575e-01],
         [-1.2159e-04,  5.1144e-01],
         [-3.4938e-03,  3.3459e-01],
         [-2.9613e-03,  2.4400e-01]]])
agent 0 action: VehicleControl(throttle=0.442357, steer=0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.067651312827806
+++++++++++++: 1.5677167042801559
16.007366551086307 seconds in game passed.
At 16.007366551086307 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8963e-03,  9.4140e-01],
         [-6.5355e-04,  5.3789e-01],
         [-5.4926e-03,  3.5167e-01],
         [-5.3741e-03,  2.5789e-01]]])
agent 0 action: VehicleControl(throttle=0.360386, steer=0.002006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5677167042801559
Current reward: 0.32197749700834544
Current mitigation activation: 0
#############################
Total reward: 38.389628809836154
16.032366551458836 seconds in game passed.
Action: tensor([[[ 1.8963e-03,  9.4140e-01],
         [-6.5355e-04,  5.3789e-01],
         [-5.4926e-03,  3.5167e-01],
         [-5.3741e-03,  2.5789e-01]]])
agent 0 action: VehicleControl(throttle=0.353103, steer=0.002066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.389628809836154
16.057366551831365 seconds in game passed.
Action: tensor([[[ 1.8963e-03,  9.4140e-01],
         [-6.5355e-04,  5.3789e-01],
         [-5.4926e-03,  3.5167e-01],
         [-5.3741e-03,  2.5789e-01]]])
agent 0 action: VehicleControl(throttle=0.338500, steer=0.002066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.389628809836154
16.082366552203894 seconds in game passed.
Action: tensor([[[ 1.8963e-03,  9.4140e-01],
         [-6.5355e-04,  5.3789e-01],
         [-5.4926e-03,  3.5167e-01],
         [-5.3741e-03,  2.5789e-01]]])
agent 0 action: VehicleControl(throttle=0.324090, steer=0.002065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.389628809836154
+++++++++++++: 1.5131429073923353
16.107366552576423 seconds in game passed.
At 16.107366552576423 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.8576e-05,  9.4360e-01],
         [ 2.3694e-03,  5.6205e-01],
         [-2.3362e-03,  3.7794e-01],
         [-2.9179e-03,  2.8636e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003506, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5131429073923353
Current reward: 0.3250196379222092
Current mitigation activation: 0
#############################
Total reward: 38.714648447758364
16.13236655294895 seconds in game passed.
Action: tensor([[[ 5.8576e-05,  9.4360e-01],
         [ 2.3694e-03,  5.6205e-01],
         [-2.3362e-03,  3.7794e-01],
         [-2.9179e-03,  2.8636e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003239, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.714648447758364
16.15736655332148 seconds in game passed.
Action: tensor([[[ 5.8576e-05,  9.4360e-01],
         [ 2.3694e-03,  5.6205e-01],
         [-2.3362e-03,  3.7794e-01],
         [-2.9179e-03,  2.8636e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003216, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.714648447758364
16.18236655369401 seconds in game passed.
Action: tensor([[[ 5.8576e-05,  9.4360e-01],
         [ 2.3694e-03,  5.6205e-01],
         [-2.3362e-03,  3.7794e-01],
         [-2.9179e-03,  2.8636e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003193, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.714648447758364
+++++++++++++: 1.4840867839902196
16.20736655406654 seconds in game passed.
At 16.20736655406654 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.9959e-04,  9.4434e-01],
         [ 5.3644e-07,  5.8729e-01],
         [-6.4937e-03,  4.0610e-01],
         [-8.1658e-03,  3.1746e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001537, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4840867839902196
Current reward: 0.32458450476943407
Current mitigation activation: 0
#############################
Total reward: 39.0392329525278
16.232366554439068 seconds in game passed.
Action: tensor([[[ 4.9959e-04,  9.4434e-01],
         [ 5.3644e-07,  5.8729e-01],
         [-6.4937e-03,  4.0610e-01],
         [-8.1658e-03,  3.1746e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001700, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.0392329525278
16.257366554811597 seconds in game passed.
Action: tensor([[[ 4.9959e-04,  9.4434e-01],
         [ 5.3644e-07,  5.8729e-01],
         [-6.4937e-03,  4.0610e-01],
         [-8.1658e-03,  3.1746e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001604, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.0392329525278
16.282366555184126 seconds in game passed.
Action: tensor([[[ 4.9959e-04,  9.4434e-01],
         [ 5.3644e-07,  5.8729e-01],
         [-6.4937e-03,  4.0610e-01],
         [-8.1658e-03,  3.1746e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001507, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.0392329525278
+++++++++++++: 1.533521464852083
16.307366555556655 seconds in game passed.
At 16.307366555556655 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0088,  0.9439],
         [ 0.0016,  0.6222],
         [-0.0084,  0.4509],
         [-0.0122,  0.3684]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006546, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.533521464852083
Current reward: 0.31422618341707015
Current mitigation activation: 0
#############################
Total reward: 39.35345913594487
16.332366555929184 seconds in game passed.
Action: tensor([[[ 0.0088,  0.9439],
         [ 0.0016,  0.6222],
         [-0.0084,  0.4509],
         [-0.0122,  0.3684]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005647, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.35345913594487
16.357366556301713 seconds in game passed.
Action: tensor([[[ 0.0088,  0.9439],
         [ 0.0016,  0.6222],
         [-0.0084,  0.4509],
         [-0.0122,  0.3684]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005597, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.35345913594487
16.382366556674242 seconds in game passed.
Action: tensor([[[ 0.0088,  0.9439],
         [ 0.0016,  0.6222],
         [-0.0084,  0.4509],
         [-0.0122,  0.3684]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005546, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.35345913594487
+++++++++++++: 1.7155307509382816
16.40736655704677 seconds in game passed.
At 16.40736655704677 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0032,  0.9474],
         [ 0.0027,  0.6494],
         [-0.0046,  0.4416],
         [-0.0062,  0.3480]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000485, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7155307509382816
Current reward: 0.29156574265837226
Current mitigation activation: 0
#############################
Total reward: 39.64502487860324
16.4323665574193 seconds in game passed.
Action: tensor([[[-0.0032,  0.9474],
         [ 0.0027,  0.6494],
         [-0.0046,  0.4416],
         [-0.0062,  0.3480]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001211, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.64502487860324
16.45736655779183 seconds in game passed.
Action: tensor([[[-0.0032,  0.9474],
         [ 0.0027,  0.6494],
         [-0.0046,  0.4416],
         [-0.0062,  0.3480]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001110, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.64502487860324
16.482366558164358 seconds in game passed.
Action: tensor([[[-0.0032,  0.9474],
         [ 0.0027,  0.6494],
         [-0.0046,  0.4416],
         [-0.0062,  0.3480]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001010, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.64502487860324
+++++++++++++: 1.9891016474084318
16.507366558536887 seconds in game passed.
At 16.507366558536887 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0037,  0.9474],
         [ 0.0030,  0.6440],
         [-0.0047,  0.4207],
         [-0.0068,  0.3139]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000937, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9891016474084318
Current reward: 0.2679855759902967
Current mitigation activation: 0
#############################
Total reward: 39.91301045459353
16.532366558909416 seconds in game passed.
Action: tensor([[[-0.0037,  0.9474],
         [ 0.0030,  0.6440],
         [-0.0047,  0.4207],
         [-0.0068,  0.3139]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000848, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.91301045459353
16.557366559281945 seconds in game passed.
Action: tensor([[[-0.0037,  0.9474],
         [ 0.0030,  0.6440],
         [-0.0047,  0.4207],
         [-0.0068,  0.3139]]])
agent 0 action: VehicleControl(throttle=0.077427, steer=0.000762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.91301045459353
16.582366559654474 seconds in game passed.
Action: tensor([[[-0.0037,  0.9474],
         [ 0.0030,  0.6440],
         [-0.0047,  0.4207],
         [-0.0068,  0.3139]]])
agent 0 action: VehicleControl(throttle=0.067476, steer=0.000676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.91301045459353
+++++++++++++: 2.382140652219708
16.607366560027003 seconds in game passed.
At 16.607366560027003 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.0430e-03,  9.4707e-01],
         [-7.8968e-04,  6.2650e-01],
         [-6.6712e-03,  4.1021e-01],
         [-7.7093e-03,  3.0618e-01]]])
agent 0 action: VehicleControl(throttle=0.163146, steer=-0.003200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.382140652219708
Current reward: 0.24556749275111134
Current mitigation activation: 0
#############################
Total reward: 40.15857794734465
16.632366560399532 seconds in game passed.
Action: tensor([[[-6.0430e-03,  9.4707e-01],
         [-7.8968e-04,  6.2650e-01],
         [-6.6712e-03,  4.1021e-01],
         [-7.7093e-03,  3.0618e-01]]])
agent 0 action: VehicleControl(throttle=0.205048, steer=-0.002616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.15857794734465
16.65736656077206 seconds in game passed.
Action: tensor([[[-6.0430e-03,  9.4707e-01],
         [-7.8968e-04,  6.2650e-01],
         [-6.6712e-03,  4.1021e-01],
         [-7.7093e-03,  3.0618e-01]]])
agent 0 action: VehicleControl(throttle=0.227728, steer=-0.002669, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.15857794734465
16.68236656114459 seconds in game passed.
Action: tensor([[[-6.0430e-03,  9.4707e-01],
         [-7.8968e-04,  6.2650e-01],
         [-6.6712e-03,  4.1021e-01],
         [-7.7093e-03,  3.0618e-01]]])
agent 0 action: VehicleControl(throttle=0.229044, steer=-0.002722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.15857794734465
+++++++++++++: 2.7410409075097153
16.70736656151712 seconds in game passed.
At 16.70736656151712 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0140, 0.9430],
         [0.0074, 0.5658],
         [0.0018, 0.3706],
         [0.0013, 0.2694]]])
agent 0 action: VehicleControl(throttle=0.879589, steer=0.012574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7410409075097153
Current reward: 0.23290014896983308
Current mitigation activation: 0
#############################
Total reward: 40.39147809631448
16.73236656188965 seconds in game passed.
Action: tensor([[[0.0140, 0.9430],
         [0.0074, 0.5658],
         [0.0018, 0.3706],
         [0.0013, 0.2694]]])
agent 0 action: VehicleControl(throttle=0.815026, steer=0.010187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.39147809631448
16.757366562262177 seconds in game passed.
Action: tensor([[[0.0140, 0.9430],
         [0.0074, 0.5658],
         [0.0018, 0.3706],
         [0.0013, 0.2694]]])
agent 0 action: VehicleControl(throttle=0.820438, steer=0.010327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.39147809631448
16.782366562634706 seconds in game passed.
Action: tensor([[[0.0140, 0.9430],
         [0.0074, 0.5658],
         [0.0018, 0.3706],
         [0.0013, 0.2694]]])
agent 0 action: VehicleControl(throttle=0.836906, steer=0.010467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.39147809631448
+++++++++++++: 2.848394839770152
16.807366563007236 seconds in game passed.
At 16.807366563007236 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0720e-02,  9.2956e-01],
         [ 2.0359e-03,  5.1489e-01],
         [-1.0578e-04,  3.4208e-01],
         [-2.4342e-04,  2.4894e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.848394839770152
Current reward: 0.23365758794072805
Current mitigation activation: 0
#############################
Total reward: 40.625135684255206
16.832366563379765 seconds in game passed.
Action: tensor([[[ 1.0720e-02,  9.2956e-01],
         [ 2.0359e-03,  5.1489e-01],
         [-1.0578e-04,  3.4208e-01],
         [-2.4342e-04,  2.4894e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.625135684255206
16.857366563752294 seconds in game passed.
Action: tensor([[[ 1.0720e-02,  9.2956e-01],
         [ 2.0359e-03,  5.1489e-01],
         [-1.0578e-04,  3.4208e-01],
         [-2.4342e-04,  2.4894e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.625135684255206
16.882366564124823 seconds in game passed.
Action: tensor([[[ 1.0720e-02,  9.2956e-01],
         [ 2.0359e-03,  5.1489e-01],
         [-1.0578e-04,  3.4208e-01],
         [-2.4342e-04,  2.4894e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.625135684255206
+++++++++++++: 3.0188508372311573
16.90736656449735 seconds in game passed.
At 16.90736656449735 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4348e-02,  8.8869e-01],
         [ 2.8842e-03,  4.8266e-01],
         [-1.4307e-04,  3.2692e-01],
         [-6.5516e-04,  2.4134e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0188508372311573
Current reward: 0.2329120537142615
Current mitigation activation: 0
#############################
Total reward: 40.858047737969464
16.93236656486988 seconds in game passed.
Action: tensor([[[ 2.4348e-02,  8.8869e-01],
         [ 2.8842e-03,  4.8266e-01],
         [-1.4307e-04,  3.2692e-01],
         [-6.5516e-04,  2.4134e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.011375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.858047737969464
16.95736656524241 seconds in game passed.
Action: tensor([[[ 2.4348e-02,  8.8869e-01],
         [ 2.8842e-03,  4.8266e-01],
         [-1.4307e-04,  3.2692e-01],
         [-6.5516e-04,  2.4134e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.011495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.858047737969464
16.98236656561494 seconds in game passed.
Action: tensor([[[ 2.4348e-02,  8.8869e-01],
         [ 2.8842e-03,  4.8266e-01],
         [-1.4307e-04,  3.2692e-01],
         [-6.5516e-04,  2.4134e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.011615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.858047737969464
+++++++++++++: 3.0267138693089017
17.007366565987468 seconds in game passed.
At 17.007366565987468 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1632e-02,  8.6309e-01],
         [ 2.2799e-03,  4.7364e-01],
         [ 2.3320e-06,  3.2190e-01],
         [-1.1066e-04,  2.3839e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0267138693089017
Current reward: 0.23868857984774838
Current mitigation activation: 0
#############################
Total reward: 41.09673631781721
17.032366566359997 seconds in game passed.
Action: tensor([[[ 2.1632e-02,  8.6309e-01],
         [ 2.2799e-03,  4.7364e-01],
         [ 2.3320e-06,  3.2190e-01],
         [-1.1066e-04,  2.3839e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.09673631781721
17.057366566732526 seconds in game passed.
Action: tensor([[[ 2.1632e-02,  8.6309e-01],
         [ 2.2799e-03,  4.7364e-01],
         [ 2.3320e-06,  3.2190e-01],
         [-1.1066e-04,  2.3839e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.09673631781721
17.082366567105055 seconds in game passed.
Action: tensor([[[ 2.1632e-02,  8.6309e-01],
         [ 2.2799e-03,  4.7364e-01],
         [ 2.3320e-06,  3.2190e-01],
         [-1.1066e-04,  2.3839e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.09673631781721
+++++++++++++: 2.923878996858846
17.107366567477584 seconds in game passed.
At 17.107366567477584 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.3110e-02,  8.5802e-01],
         [ 1.9037e-03,  4.6724e-01],
         [-6.0682e-04,  3.1729e-01],
         [-9.2956e-04,  2.3461e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.011118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.923878996858846
Current reward: 0.24887758303600477
Current mitigation activation: 0
#############################
Total reward: 41.345613900853216
17.132366567850113 seconds in game passed.
Action: tensor([[[ 2.3110e-02,  8.5802e-01],
         [ 1.9037e-03,  4.6724e-01],
         [-6.0682e-04,  3.1729e-01],
         [-9.2956e-04,  2.3461e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.011168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.345613900853216
17.157366568222642 seconds in game passed.
Action: tensor([[[ 2.3110e-02,  8.5802e-01],
         [ 1.9037e-03,  4.6724e-01],
         [-6.0682e-04,  3.1729e-01],
         [-9.2956e-04,  2.3461e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.011264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.345613900853216
17.18236656859517 seconds in game passed.
Action: tensor([[[ 2.3110e-02,  8.5802e-01],
         [ 1.9037e-03,  4.6724e-01],
         [-6.0682e-04,  3.1729e-01],
         [-9.2956e-04,  2.3461e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.011359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.345613900853216
+++++++++++++: 2.785884429297254
17.2073665689677 seconds in game passed.
At 17.2073665689677 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0149,  0.8070],
         [-0.0010,  0.4428],
         [-0.0032,  0.3028],
         [-0.0037,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.785884429297254
Current reward: 0.26105304658877726
Current mitigation activation: 0
#############################
Total reward: 41.606666947441994
17.23236656934023 seconds in game passed.
Action: tensor([[[ 0.0149,  0.8070],
         [-0.0010,  0.4428],
         [-0.0032,  0.3028],
         [-0.0037,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006846, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.606666947441994
17.257366569712758 seconds in game passed.
Action: tensor([[[ 0.0149,  0.8070],
         [-0.0010,  0.4428],
         [-0.0032,  0.3028],
         [-0.0037,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006900, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.606666947441994
17.282366570085287 seconds in game passed.
Action: tensor([[[ 0.0149,  0.8070],
         [-0.0010,  0.4428],
         [-0.0032,  0.3028],
         [-0.0037,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.606666947441994
+++++++++++++: 2.6447316309869207
17.307366570457816 seconds in game passed.
At 17.307366570457816 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0172,  0.7992],
         [-0.0014,  0.4385],
         [-0.0040,  0.2979],
         [-0.0048,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6447316309869207
Current reward: 0.2741037772808729
Current mitigation activation: 0
#############################
Total reward: 41.880770724722865
17.332366570830345 seconds in game passed.
Action: tensor([[[ 0.0172,  0.7992],
         [-0.0014,  0.4385],
         [-0.0040,  0.2979],
         [-0.0048,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.880770724722865
17.357366571202874 seconds in game passed.
Action: tensor([[[ 0.0172,  0.7992],
         [-0.0014,  0.4385],
         [-0.0040,  0.2979],
         [-0.0048,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.880770724722865
17.382366571575403 seconds in game passed.
Action: tensor([[[ 0.0172,  0.7992],
         [-0.0014,  0.4385],
         [-0.0040,  0.2979],
         [-0.0048,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.880770724722865
+++++++++++++: 2.512932528597908
17.407366571947932 seconds in game passed.
At 17.407366571947932 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0144,  0.7835],
         [-0.0021,  0.4282],
         [-0.0044,  0.2903],
         [-0.0049,  0.2172]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.512932528597908
Current reward: 0.2874461244685834
Current mitigation activation: 0
#############################
Total reward: 42.168216849191445
17.43236657232046 seconds in game passed.
Action: tensor([[[ 0.0144,  0.7835],
         [-0.0021,  0.4282],
         [-0.0044,  0.2903],
         [-0.0049,  0.2172]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.168216849191445
17.45736657269299 seconds in game passed.
Action: tensor([[[ 0.0144,  0.7835],
         [-0.0021,  0.4282],
         [-0.0044,  0.2903],
         [-0.0049,  0.2172]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.168216849191445
17.48236657306552 seconds in game passed.
Action: tensor([[[ 0.0144,  0.7835],
         [-0.0021,  0.4282],
         [-0.0044,  0.2903],
         [-0.0049,  0.2172]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006239, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.168216849191445
+++++++++++++: 2.393832852101474
17.50736657343805 seconds in game passed.
At 17.50736657343805 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0099,  0.7820],
         [-0.0043,  0.4198],
         [-0.0072,  0.2817],
         [-0.0082,  0.2105]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.393832852101474
Current reward: 0.3007799974983981
Current mitigation activation: 0
#############################
Total reward: 42.46899684668984
17.532366573810577 seconds in game passed.
Action: tensor([[[ 0.0099,  0.7820],
         [-0.0043,  0.4198],
         [-0.0072,  0.2817],
         [-0.0082,  0.2105]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.46899684668984
17.557366574183106 seconds in game passed.
Action: tensor([[[ 0.0099,  0.7820],
         [-0.0043,  0.4198],
         [-0.0072,  0.2817],
         [-0.0082,  0.2105]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.46899684668984
17.582366574555635 seconds in game passed.
Action: tensor([[[ 0.0099,  0.7820],
         [-0.0043,  0.4198],
         [-0.0072,  0.2817],
         [-0.0082,  0.2105]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.46899684668984
+++++++++++++: 2.2871644060174665
17.607366574928164 seconds in game passed.
At 17.607366574928164 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0044,  0.7766],
         [-0.0069,  0.4118],
         [-0.0096,  0.2750],
         [-0.0106,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000816, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2871644060174665
Current reward: 0.31395315175952815
Current mitigation activation: 0
#############################
Total reward: 42.78294999844937
17.632366575300694 seconds in game passed.
Action: tensor([[[ 0.0044,  0.7766],
         [-0.0069,  0.4118],
         [-0.0096,  0.2750],
         [-0.0106,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.78294999844937
17.657366575673223 seconds in game passed.
Action: tensor([[[ 0.0044,  0.7766],
         [-0.0069,  0.4118],
         [-0.0096,  0.2750],
         [-0.0106,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.78294999844937
17.68236657604575 seconds in game passed.
Action: tensor([[[ 0.0044,  0.7766],
         [-0.0069,  0.4118],
         [-0.0096,  0.2750],
         [-0.0106,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.78294999844937
+++++++++++++: 2.1916463445297047
17.70736657641828 seconds in game passed.
At 17.70736657641828 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.7693],
         [-0.0097,  0.4023],
         [-0.0122,  0.2706],
         [-0.0128,  0.2039]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1916463445297047
Current reward: 0.3268821433054289
Current mitigation activation: 0
#############################
Total reward: 43.109832141754794
17.73236657679081 seconds in game passed.
Action: tensor([[[ 0.0011,  0.7693],
         [-0.0097,  0.4023],
         [-0.0122,  0.2706],
         [-0.0128,  0.2039]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.109832141754794
17.75736657716334 seconds in game passed.
Action: tensor([[[ 0.0011,  0.7693],
         [-0.0097,  0.4023],
         [-0.0122,  0.2706],
         [-0.0128,  0.2039]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.109832141754794
17.782366577535868 seconds in game passed.
Action: tensor([[[ 0.0011,  0.7693],
         [-0.0097,  0.4023],
         [-0.0122,  0.2706],
         [-0.0128,  0.2039]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.109832141754794
+++++++++++++: 2.105899102636649
17.807366577908397 seconds in game passed.
At 17.807366577908397 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0029,  0.7425],
         [-0.0130,  0.3930],
         [-0.0154,  0.2666],
         [-0.0162,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008008, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.105899102636649
Current reward: 0.3395164986019019
Current mitigation activation: 0
#############################
Total reward: 43.449348640356696
17.832366578280926 seconds in game passed.
Action: tensor([[[-0.0029,  0.7425],
         [-0.0130,  0.3930],
         [-0.0154,  0.2666],
         [-0.0162,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.449348640356696
17.857366578653455 seconds in game passed.
Action: tensor([[[-0.0029,  0.7425],
         [-0.0130,  0.3930],
         [-0.0154,  0.2666],
         [-0.0162,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.449348640356696
17.882366579025984 seconds in game passed.
Action: tensor([[[-0.0029,  0.7425],
         [-0.0130,  0.3930],
         [-0.0154,  0.2666],
         [-0.0162,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.449348640356696
+++++++++++++: 2.0284756231164893
17.907366579398513 seconds in game passed.
At 17.907366579398513 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0063,  0.7474],
         [-0.0184,  0.3900],
         [-0.0220,  0.2632],
         [-0.0234,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0284756231164893
Current reward: 0.3518307796393655
Current mitigation activation: 0
#############################
Total reward: 43.80117941999606
17.932366579771042 seconds in game passed.
Action: tensor([[[-0.0063,  0.7474],
         [-0.0184,  0.3900],
         [-0.0220,  0.2632],
         [-0.0234,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.80117941999606
17.95736658014357 seconds in game passed.
Action: tensor([[[-0.0063,  0.7474],
         [-0.0184,  0.3900],
         [-0.0220,  0.2632],
         [-0.0234,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.80117941999606
17.9823665805161 seconds in game passed.
Action: tensor([[[-0.0063,  0.7474],
         [-0.0184,  0.3900],
         [-0.0220,  0.2632],
         [-0.0234,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.80117941999606
+++++++++++++: 1.9582082594414765
18.00736658088863 seconds in game passed.
At 18.00736658088863 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.7491],
         [-0.0104,  0.3878],
         [-0.0135,  0.2609],
         [-0.0149,  0.1964]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9582082594414765
Current reward: 0.3638047282762559
Current mitigation activation: 0
#############################
Total reward: 44.16498414827232
18.032366581261158 seconds in game passed.
Action: tensor([[[-0.0008,  0.7491],
         [-0.0104,  0.3878],
         [-0.0135,  0.2609],
         [-0.0149,  0.1964]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.16498414827232
18.057366581633687 seconds in game passed.
Action: tensor([[[-0.0008,  0.7491],
         [-0.0104,  0.3878],
         [-0.0135,  0.2609],
         [-0.0149,  0.1964]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.16498414827232
18.082366582006216 seconds in game passed.
Action: tensor([[[-0.0008,  0.7491],
         [-0.0104,  0.3878],
         [-0.0135,  0.2609],
         [-0.0149,  0.1964]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.16498414827232
+++++++++++++: 1.8939950653917763
18.107366582378745 seconds in game passed.
At 18.107366582378745 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0036,  0.7475],
         [-0.0136,  0.3857],
         [-0.0166,  0.2596],
         [-0.0182,  0.1953]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8939950653917763
Current reward: 0.3754562174830751
Current mitigation activation: 0
#############################
Total reward: 44.540440365755394
18.132366582751274 seconds in game passed.
Action: tensor([[[-0.0036,  0.7475],
         [-0.0136,  0.3857],
         [-0.0166,  0.2596],
         [-0.0182,  0.1953]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010957, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.540440365755394
18.157366583123803 seconds in game passed.
Action: tensor([[[-0.0036,  0.7475],
         [-0.0136,  0.3857],
         [-0.0166,  0.2596],
         [-0.0182,  0.1953]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011192, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.540440365755394
18.182366583496332 seconds in game passed.
Action: tensor([[[-0.0036,  0.7475],
         [-0.0136,  0.3857],
         [-0.0166,  0.2596],
         [-0.0182,  0.1953]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.540440365755394
+++++++++++++: 1.8349565356418305
18.20736658386886 seconds in game passed.
At 18.20736658386886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.7542],
         [-0.0120,  0.3885],
         [-0.0149,  0.2598],
         [-0.0160,  0.1949]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8349565356418305
Current reward: 0.3867762543796417
Current mitigation activation: 0
#############################
Total reward: 44.927216620135034
18.23236658424139 seconds in game passed.
Action: tensor([[[-0.0016,  0.7542],
         [-0.0120,  0.3885],
         [-0.0149,  0.2598],
         [-0.0160,  0.1949]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.927216620135034
18.25736658461392 seconds in game passed.
Action: tensor([[[-0.0016,  0.7542],
         [-0.0120,  0.3885],
         [-0.0149,  0.2598],
         [-0.0160,  0.1949]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.927216620135034
18.28236658498645 seconds in game passed.
Action: tensor([[[-0.0016,  0.7542],
         [-0.0120,  0.3885],
         [-0.0149,  0.2598],
         [-0.0160,  0.1949]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.927216620135034
+++++++++++++: 1.7846762006253583
18.307366585358977 seconds in game passed.
At 18.307366585358977 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.7252],
         [-0.0054,  0.3793],
         [-0.0070,  0.2554],
         [-0.0079,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7846762006253583
Current reward: 0.3972256229636802
Current mitigation activation: 0
#############################
Total reward: 45.324442243098716
18.332366585731506 seconds in game passed.
Action: tensor([[[-0.0016,  0.7252],
         [-0.0054,  0.3793],
         [-0.0070,  0.2554],
         [-0.0079,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.324442243098716
18.357366586104035 seconds in game passed.
Action: tensor([[[-0.0016,  0.7252],
         [-0.0054,  0.3793],
         [-0.0070,  0.2554],
         [-0.0079,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.324442243098716
18.382366586476564 seconds in game passed.
Action: tensor([[[-0.0016,  0.7252],
         [-0.0054,  0.3793],
         [-0.0070,  0.2554],
         [-0.0079,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.324442243098716
+++++++++++++: 1.7915979140505798
18.407366586849093 seconds in game passed.
At 18.407366586849093 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6804],
         [-0.0055,  0.3663],
         [-0.0065,  0.2518],
         [-0.0070,  0.1922]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7915979140505798
Current reward: 0.40052113607091494
Current mitigation activation: 0
#############################
Total reward: 45.72496337916963
18.432366587221622 seconds in game passed.
Action: tensor([[[-0.0024,  0.6804],
         [-0.0055,  0.3663],
         [-0.0065,  0.2518],
         [-0.0070,  0.1922]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.72496337916963
18.45736658759415 seconds in game passed.
Action: tensor([[[-0.0024,  0.6804],
         [-0.0055,  0.3663],
         [-0.0065,  0.2518],
         [-0.0070,  0.1922]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.72496337916963
18.48236658796668 seconds in game passed.
Action: tensor([[[-0.0024,  0.6804],
         [-0.0055,  0.3663],
         [-0.0065,  0.2518],
         [-0.0070,  0.1922]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.72496337916963
+++++++++++++: 1.8152831297902567
18.50736658833921 seconds in game passed.
At 18.50736658833921 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.6721],
         [-0.0032,  0.3665],
         [-0.0040,  0.2532],
         [-0.0047,  0.1941]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8152831297902567
Current reward: 0.402050693715557
Current mitigation activation: 0
#############################
Total reward: 46.12701407288519
18.53236658871174 seconds in game passed.
Action: tensor([[[-0.0010,  0.6721],
         [-0.0032,  0.3665],
         [-0.0040,  0.2532],
         [-0.0047,  0.1941]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005543, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12701407288519
18.557366589084268 seconds in game passed.
Action: tensor([[[-0.0010,  0.6721],
         [-0.0032,  0.3665],
         [-0.0040,  0.2532],
         [-0.0047,  0.1941]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12701407288519
18.582366589456797 seconds in game passed.
Action: tensor([[[-0.0010,  0.6721],
         [-0.0032,  0.3665],
         [-0.0040,  0.2532],
         [-0.0047,  0.1941]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12701407288519
+++++++++++++: 1.8413124727946057
18.607366589829326 seconds in game passed.
At 18.607366589829326 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0044,  0.6755],
         [-0.0012,  0.3668],
         [-0.0022,  0.2521],
         [-0.0032,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8413124727946057
Current reward: 0.4037738623238409
Current mitigation activation: 0
#############################
Total reward: 46.53078793520903
18.632366590201855 seconds in game passed.
Action: tensor([[[ 0.0044,  0.6755],
         [-0.0012,  0.3668],
         [-0.0022,  0.2521],
         [-0.0032,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.53078793520903
18.657366590574384 seconds in game passed.
Action: tensor([[[ 0.0044,  0.6755],
         [-0.0012,  0.3668],
         [-0.0022,  0.2521],
         [-0.0032,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.53078793520903
18.682366590946913 seconds in game passed.
Action: tensor([[[ 0.0044,  0.6755],
         [-0.0012,  0.3668],
         [-0.0022,  0.2521],
         [-0.0032,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.53078793520903
+++++++++++++: 1.8696726111864836
18.707366591319442 seconds in game passed.
At 18.707366591319442 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0045, 0.6574],
         [0.0018, 0.3574],
         [0.0019, 0.2452],
         [0.0015, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8696726111864836
Current reward: 0.4056884800900198
Current mitigation activation: 0
#############################
Total reward: 46.93647641529905
18.73236659169197 seconds in game passed.
Action: tensor([[[0.0045, 0.6574],
         [0.0018, 0.3574],
         [0.0019, 0.2452],
         [0.0015, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93647641529905
18.7573665920645 seconds in game passed.
Action: tensor([[[0.0045, 0.6574],
         [0.0018, 0.3574],
         [0.0019, 0.2452],
         [0.0015, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93647641529905
18.78236659243703 seconds in game passed.
Action: tensor([[[0.0045, 0.6574],
         [0.0018, 0.3574],
         [0.0019, 0.2452],
         [0.0015, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93647641529905
+++++++++++++: 1.8981700030175217
18.807366592809558 seconds in game passed.
At 18.807366592809558 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0058, 0.6493],
         [0.0039, 0.3442],
         [0.0036, 0.2348],
         [0.0028, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8981700030175217
Current reward: 0.40804189602946306
Current mitigation activation: 0
#############################
Total reward: 47.344518311328514
18.832366593182087 seconds in game passed.
Action: tensor([[[0.0058, 0.6493],
         [0.0039, 0.3442],
         [0.0036, 0.2348],
         [0.0028, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.344518311328514
18.857366593554616 seconds in game passed.
Action: tensor([[[0.0058, 0.6493],
         [0.0039, 0.3442],
         [0.0036, 0.2348],
         [0.0028, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002062, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.344518311328514
18.882366593927145 seconds in game passed.
Action: tensor([[[0.0058, 0.6493],
         [0.0039, 0.3442],
         [0.0036, 0.2348],
         [0.0028, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.344518311328514
+++++++++++++: 1.847999063756529
18.907366594299674 seconds in game passed.
At 18.907366594299674 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6289],
         [0.0027, 0.3380],
         [0.0030, 0.2322],
         [0.0026, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.847999063756529
Current reward: 0.4202493712980119
Current mitigation activation: 0
#############################
Total reward: 47.76476768262653
18.932366594672203 seconds in game passed.
Action: tensor([[[0.0032, 0.6289],
         [0.0027, 0.3380],
         [0.0030, 0.2322],
         [0.0026, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.76476768262653
18.957366595044732 seconds in game passed.
Action: tensor([[[0.0032, 0.6289],
         [0.0027, 0.3380],
         [0.0030, 0.2322],
         [0.0026, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.76476768262653
18.98236659541726 seconds in game passed.
Action: tensor([[[0.0032, 0.6289],
         [0.0027, 0.3380],
         [0.0030, 0.2322],
         [0.0026, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.76476768262653
+++++++++++++: 1.7771033089999138
19.00736659578979 seconds in game passed.
At 19.00736659578979 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.6564],
         [0.0023, 0.3476],
         [0.0021, 0.2380],
         [0.0014, 0.1823]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7771033089999138
Current reward: 0.4353000453659761
Current mitigation activation: 0
#############################
Total reward: 48.200067727992504
19.03236659616232 seconds in game passed.
Action: tensor([[[0.0023, 0.6564],
         [0.0023, 0.3476],
         [0.0021, 0.2380],
         [0.0014, 0.1823]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.200067727992504
19.057366596534848 seconds in game passed.
Action: tensor([[[0.0023, 0.6564],
         [0.0023, 0.3476],
         [0.0021, 0.2380],
         [0.0014, 0.1823]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.200067727992504
19.082366596907377 seconds in game passed.
Action: tensor([[[0.0023, 0.6564],
         [0.0023, 0.3476],
         [0.0021, 0.2380],
         [0.0014, 0.1823]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.200067727992504
+++++++++++++: 1.7199224034320582
19.107366597279906 seconds in game passed.
At 19.107366597279906 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.8800e-03,  6.6262e-01],
         [ 1.8199e-03,  3.5139e-01],
         [ 8.9666e-04,  2.4011e-01],
         [-2.8193e-05,  1.8340e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7199224034320582
Current reward: 0.4485513092789536
Current mitigation activation: 0
#############################
Total reward: 48.64861903727146
19.132366597652435 seconds in game passed.
Action: tensor([[[ 3.8800e-03,  6.6262e-01],
         [ 1.8199e-03,  3.5139e-01],
         [ 8.9666e-04,  2.4011e-01],
         [-2.8193e-05,  1.8340e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.64861903727146
19.157366598024964 seconds in game passed.
Action: tensor([[[ 3.8800e-03,  6.6262e-01],
         [ 1.8199e-03,  3.5139e-01],
         [ 8.9666e-04,  2.4011e-01],
         [-2.8193e-05,  1.8340e-01]]])
agent 0 action: VehicleControl(throttle=0.866901, steer=0.002059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.64861903727146
19.182366598397493 seconds in game passed.
Action: tensor([[[ 3.8800e-03,  6.6262e-01],
         [ 1.8199e-03,  3.5139e-01],
         [ 8.9666e-04,  2.4011e-01],
         [-2.8193e-05,  1.8340e-01]]])
agent 0 action: VehicleControl(throttle=0.823773, steer=0.002211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.64861903727146
+++++++++++++: 1.6711255089888342
19.207366598770022 seconds in game passed.
At 19.207366598770022 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.6713],
         [-0.0018,  0.3512],
         [-0.0030,  0.2388],
         [-0.0038,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.864248, steer=-0.001099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6711255089888342
Current reward: 0.4605650866467741
Current mitigation activation: 0
#############################
Total reward: 49.10918412391823
19.23236659914255 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6713],
         [-0.0018,  0.3512],
         [-0.0030,  0.2388],
         [-0.0038,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.815149, steer=-0.000437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.10918412391823
19.25736659951508 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6713],
         [-0.0018,  0.3512],
         [-0.0030,  0.2388],
         [-0.0038,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.775866, steer=-0.000342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.10918412391823
19.28236659988761 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6713],
         [-0.0018,  0.3512],
         [-0.0030,  0.2388],
         [-0.0038,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.737328, steer=-0.000247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.10918412391823
+++++++++++++: 1.6285752977732617
19.30736660026014 seconds in game passed.
At 19.30736660026014 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.4926e-04,  6.7856e-01],
         [-1.1256e-03,  3.4980e-01],
         [-1.7910e-03,  2.3704e-01],
         [-2.1577e-03,  1.8149e-01]]])
agent 0 action: VehicleControl(throttle=0.806622, steer=-0.000569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6285752977732617
Current reward: 0.4715458669192212
Current mitigation activation: 0
#############################
Total reward: 49.580729990837455
19.332366600632668 seconds in game passed.
Action: tensor([[[-1.4926e-04,  6.7856e-01],
         [-1.1256e-03,  3.4980e-01],
         [-1.7910e-03,  2.3704e-01],
         [-2.1577e-03,  1.8149e-01]]])
agent 0 action: VehicleControl(throttle=0.759192, steer=-0.000470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.580729990837455
19.357366601005197 seconds in game passed.
Action: tensor([[[-1.4926e-04,  6.7856e-01],
         [-1.1256e-03,  3.4980e-01],
         [-1.7910e-03,  2.3704e-01],
         [-2.1577e-03,  1.8149e-01]]])
agent 0 action: VehicleControl(throttle=0.724112, steer=-0.000432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.580729990837455
19.382366601377726 seconds in game passed.
Action: tensor([[[-1.4926e-04,  6.7856e-01],
         [-1.1256e-03,  3.4980e-01],
         [-1.7910e-03,  2.3704e-01],
         [-2.1577e-03,  1.8149e-01]]])
agent 0 action: VehicleControl(throttle=0.689438, steer=-0.000393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.580729990837455
+++++++++++++: 1.5931492979328765
19.407366601750255 seconds in game passed.
At 19.407366601750255 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0007,  0.6603],
         [-0.0009,  0.3443],
         [-0.0012,  0.2338],
         [-0.0014,  0.1791]]])
agent 0 action: VehicleControl(throttle=0.676451, steer=-0.000375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5931492979328765
Current reward: 0.4812436396240507
Current mitigation activation: 0
#############################
Total reward: 50.06197363046151
19.432366602122784 seconds in game passed.
Action: tensor([[[-0.0007,  0.6603],
         [-0.0009,  0.3443],
         [-0.0012,  0.2338],
         [-0.0014,  0.1791]]])
agent 0 action: VehicleControl(throttle=0.641594, steer=-0.000328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.06197363046151
19.457366602495313 seconds in game passed.
Action: tensor([[[-0.0007,  0.6603],
         [-0.0009,  0.3443],
         [-0.0012,  0.2338],
         [-0.0014,  0.1791]]])
agent 0 action: VehicleControl(throttle=0.610178, steer=-0.000286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.06197363046151
19.48236660286784 seconds in game passed.
Action: tensor([[[-0.0007,  0.6603],
         [-0.0009,  0.3443],
         [-0.0012,  0.2338],
         [-0.0014,  0.1791]]])
agent 0 action: VehicleControl(throttle=0.580010, steer=-0.000244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.06197363046151
+++++++++++++: 1.565417326295221
19.50736660324037 seconds in game passed.
At 19.50736660324037 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6350],
         [0.0020, 0.3399],
         [0.0019, 0.2336],
         [0.0018, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.460387, steer=0.003220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.565417326295221
Current reward: 0.4894800253996203
Current mitigation activation: 0
#############################
Total reward: 50.55145365586113
19.5323666036129 seconds in game passed.
Action: tensor([[[0.0025, 0.6350],
         [0.0020, 0.3399],
         [0.0019, 0.2336],
         [0.0018, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.442839, steer=0.002707, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.55145365586113
19.55736660398543 seconds in game passed.
Action: tensor([[[0.0025, 0.6350],
         [0.0020, 0.3399],
         [0.0019, 0.2336],
         [0.0018, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.417572, steer=0.002762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.55145365586113
19.582366604357958 seconds in game passed.
Action: tensor([[[0.0025, 0.6350],
         [0.0020, 0.3399],
         [0.0019, 0.2336],
         [0.0018, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.395046, steer=0.002817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.55145365586113
+++++++++++++: 1.5474448971240906
19.607366604730487 seconds in game passed.
At 19.607366604730487 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0050, 0.6406],
         [0.0025, 0.3450],
         [0.0022, 0.2381],
         [0.0017, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.282019, steer=0.004142, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5474448971240906
Current reward: 0.49582806334544893
Current mitigation activation: 0
#############################
Total reward: 51.04728171920658
19.632366605103016 seconds in game passed.
Action: tensor([[[0.0050, 0.6406],
         [0.0025, 0.3450],
         [0.0022, 0.2381],
         [0.0017, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.283394, steer=0.003956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.04728171920658
19.657366605475545 seconds in game passed.
Action: tensor([[[0.0050, 0.6406],
         [0.0025, 0.3450],
         [0.0022, 0.2381],
         [0.0017, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.273513, steer=0.003987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.04728171920658
19.682366605848074 seconds in game passed.
Action: tensor([[[0.0050, 0.6406],
         [0.0025, 0.3450],
         [0.0022, 0.2381],
         [0.0017, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.263617, steer=0.004018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.04728171920658
+++++++++++++: 1.5437018284733273
19.707366606220603 seconds in game passed.
At 19.707366606220603 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6264],
         [0.0025, 0.3361],
         [0.0025, 0.2314],
         [0.0022, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.372066, steer=0.003744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5437018284733273
Current reward: 0.4994606687047308
Current mitigation activation: 0
#############################
Total reward: 51.54674238791131
19.732366606593132 seconds in game passed.
Action: tensor([[[0.0042, 0.6264],
         [0.0025, 0.3361],
         [0.0025, 0.2314],
         [0.0022, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.352645, steer=0.003795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.54674238791131
19.75736660696566 seconds in game passed.
Action: tensor([[[0.0042, 0.6264],
         [0.0025, 0.3361],
         [0.0025, 0.2314],
         [0.0022, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.347952, steer=0.003800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.54674238791131
19.78236660733819 seconds in game passed.
Action: tensor([[[0.0042, 0.6264],
         [0.0025, 0.3361],
         [0.0025, 0.2314],
         [0.0022, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.344158, steer=0.003804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.54674238791131
+++++++++++++: 1.5559382122916912
19.80736660771072 seconds in game passed.
At 19.80736660771072 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0535e-03,  6.2970e-01],
         [-3.9734e-04,  3.3540e-01],
         [-4.5955e-04,  2.3146e-01],
         [-4.6618e-04,  1.7835e-01]]])
agent 0 action: VehicleControl(throttle=0.394637, steer=0.001161, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5559382122916912
Current reward: 0.5002142692235902
Current mitigation activation: 0
#############################
Total reward: 52.0469566571349
19.832366608083248 seconds in game passed.
Action: tensor([[[ 3.0535e-03,  6.2970e-01],
         [-3.9734e-04,  3.3540e-01],
         [-4.5955e-04,  2.3146e-01],
         [-4.6618e-04,  1.7835e-01]]])
agent 0 action: VehicleControl(throttle=0.384630, steer=0.001550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.0469566571349
19.857366608455777 seconds in game passed.
Action: tensor([[[ 3.0535e-03,  6.2970e-01],
         [-3.9734e-04,  3.3540e-01],
         [-4.5955e-04,  2.3146e-01],
         [-4.6618e-04,  1.7835e-01]]])
agent 0 action: VehicleControl(throttle=0.381945, steer=0.001506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.0469566571349
19.882366608828306 seconds in game passed.
Action: tensor([[[ 3.0535e-03,  6.2970e-01],
         [-3.9734e-04,  3.3540e-01],
         [-4.5955e-04,  2.3146e-01],
         [-4.6618e-04,  1.7835e-01]]])
agent 0 action: VehicleControl(throttle=0.380093, steer=0.001462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.0469566571349
+++++++++++++: 1.5776231591635526
19.907366609200835 seconds in game passed.
At 19.907366609200835 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7231e-03,  6.1509e-01],
         [-2.2130e-04,  3.3394e-01],
         [-6.5787e-04,  2.3115e-01],
         [-1.0073e-03,  1.7846e-01]]])
agent 0 action: VehicleControl(throttle=0.282107, steer=0.001452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5776231591635526
Current reward: 0.4996277689496253
Current mitigation activation: 0
#############################
Total reward: 52.54658442608452
19.932366609573364 seconds in game passed.
Action: tensor([[[ 2.7231e-03,  6.1509e-01],
         [-2.2130e-04,  3.3394e-01],
         [-6.5787e-04,  2.3115e-01],
         [-1.0073e-03,  1.7846e-01]]])
agent 0 action: VehicleControl(throttle=0.291143, steer=0.001425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.54658442608452
19.957366609945893 seconds in game passed.
Action: tensor([[[ 2.7231e-03,  6.1509e-01],
         [-2.2130e-04,  3.3394e-01],
         [-6.5787e-04,  2.3115e-01],
         [-1.0073e-03,  1.7846e-01]]])
agent 0 action: VehicleControl(throttle=0.291093, steer=0.001401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.54658442608452
19.982366610318422 seconds in game passed.
Action: tensor([[[ 2.7231e-03,  6.1509e-01],
         [-2.2130e-04,  3.3394e-01],
         [-6.5787e-04,  2.3115e-01],
         [-1.0073e-03,  1.7846e-01]]])
agent 0 action: VehicleControl(throttle=0.292900, steer=0.001377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.54658442608452
+++++++++++++: 1.6040207413615526
20.00736661069095 seconds in game passed.
At 20.00736661069095 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.7058e-04,  6.2053e-01],
         [-4.4066e-03,  3.3675e-01],
         [-5.1631e-03,  2.3226e-01],
         [-5.5336e-03,  1.7845e-01]]])
agent 0 action: VehicleControl(throttle=0.254900, steer=-0.002968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6040207413615526
Current reward: 0.4987686136441874
Current mitigation activation: 0
#############################
Total reward: 53.04535303972871
20.03236661106348 seconds in game passed.
Action: tensor([[[-3.7058e-04,  6.2053e-01],
         [-4.4066e-03,  3.3675e-01],
         [-5.1631e-03,  2.3226e-01],
         [-5.5336e-03,  1.7845e-01]]])
agent 0 action: VehicleControl(throttle=0.264160, steer=-0.002316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.04535303972871
20.05736661143601 seconds in game passed.
Action: tensor([[[-3.7058e-04,  6.2053e-01],
         [-4.4066e-03,  3.3675e-01],
         [-5.1631e-03,  2.3226e-01],
         [-5.5336e-03,  1.7845e-01]]])
agent 0 action: VehicleControl(throttle=0.270337, steer=-0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.04535303972871
20.08236661180854 seconds in game passed.
Action: tensor([[[-3.7058e-04,  6.2053e-01],
         [-4.4066e-03,  3.3675e-01],
         [-5.1631e-03,  2.3226e-01],
         [-5.5336e-03,  1.7845e-01]]])
agent 0 action: VehicleControl(throttle=0.278023, steer=-0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.04535303972871
+++++++++++++: 1.6368905649836736
20.107366612181067 seconds in game passed.
At 20.107366612181067 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.6298],
         [-0.0067,  0.3339],
         [-0.0076,  0.2277],
         [-0.0081,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.478941, steer=-0.005426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6368905649836736
Current reward: 0.4974072243121713
Current mitigation activation: 0
#############################
Total reward: 53.54276026404088
20.132366612553596 seconds in game passed.
Action: tensor([[[-0.0034,  0.6298],
         [-0.0067,  0.3339],
         [-0.0076,  0.2277],
         [-0.0081,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.471513, steer=-0.005039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.54276026404088
20.157366612926126 seconds in game passed.
Action: tensor([[[-0.0034,  0.6298],
         [-0.0067,  0.3339],
         [-0.0076,  0.2277],
         [-0.0081,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.485059, steer=-0.005134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.54276026404088
20.182366613298655 seconds in game passed.
Action: tensor([[[-0.0034,  0.6298],
         [-0.0067,  0.3339],
         [-0.0076,  0.2277],
         [-0.0081,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.497828, steer=-0.005229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.54276026404088
+++++++++++++: 1.6760075894583673
20.207366613671184 seconds in game passed.
At 20.207366613671184 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.6354],
         [-0.0049,  0.3346],
         [-0.0056,  0.2279],
         [-0.0061,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.539846, steer=-0.003661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6760075894583673
Current reward: 0.49571140368118705
Current mitigation activation: 0
#############################
Total reward: 54.038471667722064
20.232366614043713 seconds in game passed.
Action: tensor([[[-0.0027,  0.6354],
         [-0.0049,  0.3346],
         [-0.0056,  0.2279],
         [-0.0061,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.546819, steer=-0.003972, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.038471667722064
20.25736661441624 seconds in game passed.
Action: tensor([[[-0.0027,  0.6354],
         [-0.0049,  0.3346],
         [-0.0056,  0.2279],
         [-0.0061,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.556108, steer=-0.004015, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.038471667722064
20.28236661478877 seconds in game passed.
Action: tensor([[[-0.0027,  0.6354],
         [-0.0049,  0.3346],
         [-0.0056,  0.2279],
         [-0.0061,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.564245, steer=-0.004058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.038471667722064
+++++++++++++: 1.7131105724609603
20.3073666151613 seconds in game passed.
At 20.3073666151613 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0009,  0.6207],
         [-0.0008,  0.3330],
         [-0.0014,  0.2295],
         [-0.0022,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.479644, steer=0.000383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7131105724609603
Current reward: 0.4951490989929762
Current mitigation activation: 0
#############################
Total reward: 54.53362076671504
20.33236661553383 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6207],
         [-0.0008,  0.3330],
         [-0.0014,  0.2295],
         [-0.0022,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.491348, steer=-0.000349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.53362076671504
20.357366615906358 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6207],
         [-0.0008,  0.3330],
         [-0.0014,  0.2295],
         [-0.0022,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.493367, steer=-0.000341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.53362076671504
20.382366616278887 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6207],
         [-0.0008,  0.3330],
         [-0.0014,  0.2295],
         [-0.0022,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.495722, steer=-0.000334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.53362076671504
+++++++++++++: 1.74226903438609
20.407366616651416 seconds in game passed.
At 20.407366616651416 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0044, 0.6248],
         [0.0029, 0.3376],
         [0.0025, 0.2326],
         [0.0016, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.381097, steer=0.003825, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.74226903438609
Current reward: 0.4965219635780931
Current mitigation activation: 0
#############################
Total reward: 55.03014273029313
20.432366617023945 seconds in game passed.
Action: tensor([[[0.0044, 0.6248],
         [0.0029, 0.3376],
         [0.0025, 0.2326],
         [0.0016, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.395040, steer=0.003190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.03014273029313
20.457366617396474 seconds in game passed.
Action: tensor([[[0.0044, 0.6248],
         [0.0029, 0.3376],
         [0.0025, 0.2326],
         [0.0016, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.396923, steer=0.003240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.03014273029313
20.482366617769003 seconds in game passed.
Action: tensor([[[0.0044, 0.6248],
         [0.0029, 0.3376],
         [0.0025, 0.2326],
         [0.0016, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.399099, steer=0.003291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.03014273029313
+++++++++++++: 1.7689326856872893
20.507366618141532 seconds in game passed.
At 20.507366618141532 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0047, 0.6440],
         [0.0025, 0.3440],
         [0.0020, 0.2361],
         [0.0012, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.370639, steer=0.003040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7689326856872893
Current reward: 0.4987151896317331
Current mitigation activation: 0
#############################
Total reward: 55.52885791992486
20.53236661851406 seconds in game passed.
Action: tensor([[[0.0047, 0.6440],
         [0.0025, 0.3440],
         [0.0020, 0.2361],
         [0.0012, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.377407, steer=0.003096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.52885791992486
20.55736661888659 seconds in game passed.
Action: tensor([[[0.0047, 0.6440],
         [0.0025, 0.3440],
         [0.0020, 0.2361],
         [0.0012, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.381025, steer=0.003108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.52885791992486
20.58236661925912 seconds in game passed.
Action: tensor([[[0.0047, 0.6440],
         [0.0025, 0.3440],
         [0.0020, 0.2361],
         [0.0012, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.384842, steer=0.003120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.52885791992486
+++++++++++++: 1.7969166592751937
20.607366619631648 seconds in game passed.
At 20.607366619631648 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6268],
         [0.0029, 0.3366],
         [0.0026, 0.2310],
         [0.0016, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.474854, steer=0.002870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7969166592751937
Current reward: 0.5010377839212052
Current mitigation activation: 0
#############################
Total reward: 56.029895703846066
20.632366620004177 seconds in game passed.
Action: tensor([[[0.0032, 0.6268],
         [0.0029, 0.3366],
         [0.0026, 0.2310],
         [0.0016, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.471813, steer=0.002907, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.029895703846066
20.657366620376706 seconds in game passed.
Action: tensor([[[0.0032, 0.6268],
         [0.0029, 0.3366],
         [0.0026, 0.2310],
         [0.0016, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.477798, steer=0.002903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.029895703846066
20.682366620749235 seconds in game passed.
Action: tensor([[[0.0032, 0.6268],
         [0.0029, 0.3366],
         [0.0026, 0.2310],
         [0.0016, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.483803, steer=0.002898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.029895703846066
+++++++++++++: 1.8261532512449101
20.707366621121764 seconds in game passed.
At 20.707366621121764 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.0727e-04,  6.2010e-01],
         [-8.1331e-05,  3.3262e-01],
         [-3.2819e-04,  2.2876e-01],
         [-1.0518e-03,  1.7579e-01]]])
agent 0 action: VehicleControl(throttle=0.560817, steer=-0.000630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8261532512449101
Current reward: 0.5034920997341377
Current mitigation activation: 0
#############################
Total reward: 56.533387803580204
20.732366621494293 seconds in game passed.
Action: tensor([[[-1.0727e-04,  6.2010e-01],
         [-8.1331e-05,  3.3262e-01],
         [-3.2819e-04,  2.2876e-01],
         [-1.0518e-03,  1.7579e-01]]])
agent 0 action: VehicleControl(throttle=0.558641, steer=-0.000086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.533387803580204
20.757366621866822 seconds in game passed.
Action: tensor([[[-1.0727e-04,  6.2010e-01],
         [-8.1331e-05,  3.3262e-01],
         [-3.2819e-04,  2.2876e-01],
         [-1.0518e-03,  1.7579e-01]]])
agent 0 action: VehicleControl(throttle=0.564087, steer=-0.000124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.533387803580204
20.78236662223935 seconds in game passed.
Action: tensor([[[-1.0727e-04,  6.2010e-01],
         [-8.1331e-05,  3.3262e-01],
         [-3.2819e-04,  2.2876e-01],
         [-1.0518e-03,  1.7579e-01]]])
agent 0 action: VehicleControl(throttle=0.569477, steer=-0.000161, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.533387803580204
+++++++++++++: 1.8566290985698677
20.80736662261188 seconds in game passed.
At 20.80736662261188 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6259],
         [-0.0011,  0.3342],
         [-0.0014,  0.2291],
         [-0.0021,  0.1761]]])
agent 0 action: VehicleControl(throttle=0.576179, steer=-0.001369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8566290985698677
Current reward: 0.5060723927981415
Current mitigation activation: 0
#############################
Total reward: 57.03946019637834
20.83236662298441 seconds in game passed.
Action: tensor([[[-0.0013,  0.6259],
         [-0.0011,  0.3342],
         [-0.0014,  0.2291],
         [-0.0021,  0.1761]]])
agent 0 action: VehicleControl(throttle=0.580612, steer=-0.001194, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.03946019637834
20.85736662335694 seconds in game passed.
Action: tensor([[[-0.0013,  0.6259],
         [-0.0011,  0.3342],
         [-0.0014,  0.2291],
         [-0.0021,  0.1761]]])
agent 0 action: VehicleControl(throttle=0.564873, steer=-0.001217, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.03946019637834
20.882366623729467 seconds in game passed.
Action: tensor([[[-0.0013,  0.6259],
         [-0.0011,  0.3342],
         [-0.0014,  0.2291],
         [-0.0021,  0.1761]]])
agent 0 action: VehicleControl(throttle=0.553485, steer=-0.001240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.03946019637834
+++++++++++++: 1.8783007244027083
20.907366624101996 seconds in game passed.
At 20.907366624101996 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0029,  0.6191],
         [-0.0028,  0.3331],
         [-0.0032,  0.2287],
         [-0.0040,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.516279, steer=-0.003160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8783007244027083
Current reward: 0.5102556752451085
Current mitigation activation: 0
#############################
Total reward: 57.54971587162345
20.932366624474525 seconds in game passed.
Action: tensor([[[-0.0029,  0.6191],
         [-0.0028,  0.3331],
         [-0.0032,  0.2287],
         [-0.0040,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.509865, steer=-0.002889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.54971587162345
20.957366624847054 seconds in game passed.
Action: tensor([[[-0.0029,  0.6191],
         [-0.0028,  0.3331],
         [-0.0032,  0.2287],
         [-0.0040,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.501275, steer=-0.002932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.54971587162345
20.982366625219584 seconds in game passed.
Action: tensor([[[-0.0029,  0.6191],
         [-0.0028,  0.3331],
         [-0.0032,  0.2287],
         [-0.0040,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.493503, steer=-0.002974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.54971587162345
+++++++++++++: 1.8857894364832009
21.007366625592113 seconds in game passed.
At 21.007366625592113 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0028,  0.6227],
         [-0.0032,  0.3354],
         [-0.0032,  0.2303],
         [-0.0033,  0.1769]]])
agent 0 action: VehicleControl(throttle=0.442138, steer=-0.003267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8857894364832009
Current reward: 0.5166756935046348
Current mitigation activation: 0
#############################
Total reward: 58.066391565128086
21.03236662596464 seconds in game passed.
Action: tensor([[[-0.0028,  0.6227],
         [-0.0032,  0.3354],
         [-0.0032,  0.2303],
         [-0.0033,  0.1769]]])
agent 0 action: VehicleControl(throttle=0.440378, steer=-0.003219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.066391565128086
21.05736662633717 seconds in game passed.
Action: tensor([[[-0.0028,  0.6227],
         [-0.0032,  0.3354],
         [-0.0032,  0.2303],
         [-0.0033,  0.1769]]])
agent 0 action: VehicleControl(throttle=0.434541, steer=-0.003220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.066391565128086
21.0823666267097 seconds in game passed.
Action: tensor([[[-0.0028,  0.6227],
         [-0.0032,  0.3354],
         [-0.0032,  0.2303],
         [-0.0033,  0.1769]]])
agent 0 action: VehicleControl(throttle=0.429559, steer=-0.003221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.066391565128086
+++++++++++++: 1.8996564654658665
21.10736662708223 seconds in game passed.
At 21.10736662708223 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.8950e-04,  6.1006e-01],
         [-1.0905e-03,  3.2773e-01],
         [-7.5375e-04,  2.2406e-01],
         [-5.3740e-04,  1.7131e-01]]])
agent 0 action: VehicleControl(throttle=0.565111, steer=-0.000900, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8996564654658665
Current reward: 0.5220769065266246
Current mitigation activation: 0
#############################
Total reward: 58.58846847165471
21.132366627454758 seconds in game passed.
Action: tensor([[[-9.8950e-04,  6.1006e-01],
         [-1.0905e-03,  3.2773e-01],
         [-7.5375e-04,  2.2406e-01],
         [-5.3740e-04,  1.7131e-01]]])
agent 0 action: VehicleControl(throttle=0.545760, steer=-0.001225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.58846847165471
21.157366627827287 seconds in game passed.
Action: tensor([[[-9.8950e-04,  6.1006e-01],
         [-1.0905e-03,  3.2773e-01],
         [-7.5375e-04,  2.2406e-01],
         [-5.3740e-04,  1.7131e-01]]])
agent 0 action: VehicleControl(throttle=0.541700, steer=-0.001172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.58846847165471
21.182366628199816 seconds in game passed.
Action: tensor([[[-9.8950e-04,  6.1006e-01],
         [-1.0905e-03,  3.2773e-01],
         [-7.5375e-04,  2.2406e-01],
         [-5.3740e-04,  1.7131e-01]]])
agent 0 action: VehicleControl(throttle=0.536909, steer=-0.001119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.58846847165471
+++++++++++++: 1.9194036096886362
21.207366628572345 seconds in game passed.
At 21.207366628572345 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6181],
         [0.0036, 0.3338],
         [0.0031, 0.2287],
         [0.0021, 0.1748]]])
agent 0 action: VehicleControl(throttle=0.397045, steer=0.004127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9194036096886362
Current reward: 0.5266174532520985
Current mitigation activation: 0
#############################
Total reward: 59.11508592490681
21.232366628944874 seconds in game passed.
Action: tensor([[[0.0034, 0.6181],
         [0.0036, 0.3338],
         [0.0031, 0.2287],
         [0.0021, 0.1748]]])
agent 0 action: VehicleControl(throttle=0.403824, steer=0.003357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.11508592490681
21.257366629317403 seconds in game passed.
Action: tensor([[[0.0034, 0.6181],
         [0.0036, 0.3338],
         [0.0031, 0.2287],
         [0.0021, 0.1748]]])
agent 0 action: VehicleControl(throttle=0.396473, steer=0.003447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.11508592490681
21.282366629689932 seconds in game passed.
Action: tensor([[[0.0034, 0.6181],
         [0.0036, 0.3338],
         [0.0031, 0.2287],
         [0.0021, 0.1748]]])
agent 0 action: VehicleControl(throttle=0.390060, steer=0.003537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.11508592490681
+++++++++++++: 1.9405199339762853
21.30736663006246 seconds in game passed.
At 21.30736663006246 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6221],
         [0.0035, 0.3300],
         [0.0035, 0.2247],
         [0.0030, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.560345, steer=0.002990, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9405199339762853
Current reward: 0.5310478648266229
Current mitigation activation: 0
#############################
Total reward: 59.64613378973343
21.33236663043499 seconds in game passed.
Action: tensor([[[0.0020, 0.6221],
         [0.0035, 0.3300],
         [0.0035, 0.2247],
         [0.0030, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.539659, steer=0.003125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.64613378973343
21.35736663080752 seconds in game passed.
Action: tensor([[[0.0020, 0.6221],
         [0.0035, 0.3300],
         [0.0035, 0.2247],
         [0.0030, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.537889, steer=0.003162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.64613378973343
21.382366631180048 seconds in game passed.
Action: tensor([[[0.0020, 0.6221],
         [0.0035, 0.3300],
         [0.0035, 0.2247],
         [0.0030, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.535342, steer=0.003200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.64613378973343
+++++++++++++: 1.9650791283001217
21.407366631552577 seconds in game passed.
At 21.407366631552577 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.6065],
         [0.0029, 0.3252],
         [0.0029, 0.2218],
         [0.0022, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.549577, steer=0.002537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9650791283001217
Current reward: 0.5350734045782727
Current mitigation activation: 0
#############################
Total reward: 60.1812071943117
21.432366631925106 seconds in game passed.
Action: tensor([[[0.0015, 0.6065],
         [0.0029, 0.3252],
         [0.0029, 0.2218],
         [0.0022, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.545656, steer=0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.1812071943117
21.457366632297635 seconds in game passed.
Action: tensor([[[0.0015, 0.6065],
         [0.0029, 0.3252],
         [0.0029, 0.2218],
         [0.0022, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.542976, steer=0.002622, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.1812071943117
21.482366632670164 seconds in game passed.
Action: tensor([[[0.0015, 0.6065],
         [0.0029, 0.3252],
         [0.0029, 0.2218],
         [0.0022, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.539813, steer=0.002609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.1812071943117
+++++++++++++: 1.9892624678111108
21.507366633042693 seconds in game passed.
At 21.507366633042693 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.6630e-04, 6.1235e-01],
         [2.5731e-03, 3.2738e-01],
         [2.3476e-03, 2.2271e-01],
         [1.2395e-03, 1.7005e-01]]])
agent 0 action: VehicleControl(throttle=0.516855, steer=0.001847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9892624678111108
Current reward: 0.5392887624284887
Current mitigation activation: 0
#############################
Total reward: 60.720495956740194
21.532366633415222 seconds in game passed.
Action: tensor([[[2.6630e-04, 6.1235e-01],
         [2.5731e-03, 3.2738e-01],
         [2.3476e-03, 2.2271e-01],
         [1.2395e-03, 1.7005e-01]]])
agent 0 action: VehicleControl(throttle=0.515250, steer=0.001954, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.720495956740194
21.55736663378775 seconds in game passed.
Action: tensor([[[2.6630e-04, 6.1235e-01],
         [2.5731e-03, 3.2738e-01],
         [2.3476e-03, 2.2271e-01],
         [1.2395e-03, 1.7005e-01]]])
agent 0 action: VehicleControl(throttle=0.511365, steer=0.001937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.720495956740194
21.58236663416028 seconds in game passed.
Action: tensor([[[2.6630e-04, 6.1235e-01],
         [2.5731e-03, 3.2738e-01],
         [2.3476e-03, 2.2271e-01],
         [1.2395e-03, 1.7005e-01]]])
agent 0 action: VehicleControl(throttle=0.507471, steer=0.001920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.720495956740194
+++++++++++++: 2.0113476846155676
21.60736663453281 seconds in game passed.
At 21.60736663453281 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6201],
         [0.0042, 0.3284],
         [0.0045, 0.2228],
         [0.0038, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.546955, steer=0.003732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0113476846155676
Current reward: 0.5439146685198393
Current mitigation activation: 0
#############################
Total reward: 61.264410625260034
21.63236663490534 seconds in game passed.
Action: tensor([[[0.0018, 0.6201],
         [0.0042, 0.3284],
         [0.0045, 0.2228],
         [0.0038, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.537901, steer=0.003435, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.264410625260034
21.657366635277867 seconds in game passed.
Action: tensor([[[0.0018, 0.6201],
         [0.0042, 0.3284],
         [0.0045, 0.2228],
         [0.0038, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.533463, steer=0.003439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.264410625260034
21.682366635650396 seconds in game passed.
Action: tensor([[[0.0018, 0.6201],
         [0.0042, 0.3284],
         [0.0045, 0.2228],
         [0.0038, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.528687, steer=0.003444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.264410625260034
+++++++++++++: 2.0332104343687063
21.707366636022925 seconds in game passed.
At 21.707366636022925 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6315],
         [0.0057, 0.3310],
         [0.0061, 0.2239],
         [0.0058, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.541370, steer=0.005591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0332104343687063
Current reward: 0.548628326415601
Current mitigation activation: 0
#############################
Total reward: 61.81303895167564
21.732366636395454 seconds in game passed.
Action: tensor([[[0.0042, 0.6315],
         [0.0057, 0.3310],
         [0.0061, 0.2239],
         [0.0058, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.533738, steer=0.005306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.81303895167564
21.757366636767983 seconds in game passed.
Action: tensor([[[0.0042, 0.6315],
         [0.0057, 0.3310],
         [0.0061, 0.2239],
         [0.0058, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.527953, steer=0.005368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.81303895167564
21.782366637140512 seconds in game passed.
Action: tensor([[[0.0042, 0.6315],
         [0.0057, 0.3310],
         [0.0061, 0.2239],
         [0.0058, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.521966, steer=0.005430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.81303895167564
+++++++++++++: 2.054627478590984
21.80736663751304 seconds in game passed.
At 21.80736663751304 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0097, 0.6443],
         [0.0140, 0.3357],
         [0.0152, 0.2255],
         [0.0145, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.473659, steer=0.013812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.054627478590984
Current reward: 0.5534377055943178
Current mitigation activation: 0
#############################
Total reward: 62.366476657269956
21.83236663788557 seconds in game passed.
Action: tensor([[[0.0097, 0.6443],
         [0.0140, 0.3357],
         [0.0152, 0.2255],
         [0.0145, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.471526, steer=0.012602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.366476657269956
21.8573666382581 seconds in game passed.
Action: tensor([[[0.0097, 0.6443],
         [0.0140, 0.3357],
         [0.0152, 0.2255],
         [0.0145, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.465444, steer=0.012762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.366476657269956
21.88236663863063 seconds in game passed.
Action: tensor([[[0.0097, 0.6443],
         [0.0140, 0.3357],
         [0.0152, 0.2255],
         [0.0145, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.459852, steer=0.012923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.366476657269956
+++++++++++++: 2.075989987372203
21.907366639003158 seconds in game passed.
At 21.907366639003158 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0103, 0.6508],
         [0.0118, 0.3389],
         [0.0120, 0.2282],
         [0.0106, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.404730, steer=0.011768, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.075989987372203
Current reward: 0.5582633224422686
Current mitigation activation: 0
#############################
Total reward: 62.92473997971223
21.932366639375687 seconds in game passed.
Action: tensor([[[0.0103, 0.6508],
         [0.0118, 0.3389],
         [0.0120, 0.2282],
         [0.0106, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.405205, steer=0.012154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.92473997971223
21.957366639748216 seconds in game passed.
Action: tensor([[[0.0103, 0.6508],
         [0.0118, 0.3389],
         [0.0120, 0.2282],
         [0.0106, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.400922, steer=0.012320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.92473997971223
21.982366640120745 seconds in game passed.
Action: tensor([[[0.0103, 0.6508],
         [0.0118, 0.3389],
         [0.0120, 0.2282],
         [0.0106, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.397527, steer=0.012486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.92473997971223
+++++++++++++: 2.09968988754847
22.007366640493274 seconds in game passed.
At 22.007366640493274 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0046, 0.6293],
         [0.0049, 0.3335],
         [0.0047, 0.2263],
         [0.0037, 0.1724]]])
agent 0 action: VehicleControl(throttle=0.378893, steer=0.005238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.09968988754847
Current reward: 0.5627517083641483
Current mitigation activation: 0
#############################
Total reward: 63.487491688076375
22.032366640865803 seconds in game passed.
Action: tensor([[[0.0046, 0.6293],
         [0.0049, 0.3335],
         [0.0047, 0.2263],
         [0.0037, 0.1724]]])
agent 0 action: VehicleControl(throttle=0.378875, steer=0.006554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.487491688076375
22.057366641238332 seconds in game passed.
Action: tensor([[[0.0046, 0.6293],
         [0.0049, 0.3335],
         [0.0047, 0.2263],
         [0.0037, 0.1724]]])
agent 0 action: VehicleControl(throttle=0.377648, steer=0.006647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.487491688076375
22.08236664161086 seconds in game passed.
Action: tensor([[[0.0046, 0.6293],
         [0.0049, 0.3335],
         [0.0047, 0.2263],
         [0.0037, 0.1724]]])
agent 0 action: VehicleControl(throttle=0.377079, steer=0.006740, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.487491688076375
+++++++++++++: 2.1275558176530485
22.10736664198339 seconds in game passed.
At 22.10736664198339 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6361],
         [0.0053, 0.3334],
         [0.0052, 0.2254],
         [0.0043, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.443103, steer=0.006769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1275558176530485
Current reward: 0.5666628898444019
Current mitigation activation: 0
#############################
Total reward: 64.05415457792078
22.13236664235592 seconds in game passed.
Action: tensor([[[0.0039, 0.6361],
         [0.0053, 0.3334],
         [0.0052, 0.2254],
         [0.0043, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.435507, steer=0.006844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.05415457792078
22.157366642728448 seconds in game passed.
Action: tensor([[[0.0039, 0.6361],
         [0.0053, 0.3334],
         [0.0052, 0.2254],
         [0.0043, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.435259, steer=0.006913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.05415457792078
22.182366643100977 seconds in game passed.
Action: tensor([[[0.0039, 0.6361],
         [0.0053, 0.3334],
         [0.0052, 0.2254],
         [0.0043, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.434773, steer=0.006981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.05415457792078
+++++++++++++: 2.158953177089637
22.207366643473506 seconds in game passed.
At 22.207366643473506 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6184],
         [0.0056, 0.3271],
         [0.0055, 0.2222],
         [0.0048, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.485885, steer=0.007326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.158953177089637
Current reward: 0.5701369826188238
Current mitigation activation: 0
#############################
Total reward: 64.6242915605396
22.232366643846035 seconds in game passed.
Action: tensor([[[0.0042, 0.6184],
         [0.0056, 0.3271],
         [0.0055, 0.2222],
         [0.0048, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.481989, steer=0.007290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.6242915605396
22.257366644218564 seconds in game passed.
Action: tensor([[[0.0042, 0.6184],
         [0.0056, 0.3271],
         [0.0055, 0.2222],
         [0.0048, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.483230, steer=0.007308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.6242915605396
22.282366644591093 seconds in game passed.
Action: tensor([[[0.0042, 0.6184],
         [0.0056, 0.3271],
         [0.0055, 0.2222],
         [0.0048, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.483991, steer=0.007326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.6242915605396
+++++++++++++: 2.190482209948387
22.307366644963622 seconds in game passed.
At 22.307366644963622 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.6075],
         [0.0036, 0.3250],
         [0.0031, 0.2216],
         [0.0018, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.447911, steer=0.005118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.190482209948387
Current reward: 0.5736806256066868
Current mitigation activation: 0
#############################
Total reward: 65.19797218614629
22.33236664533615 seconds in game passed.
Action: tensor([[[0.0023, 0.6075],
         [0.0036, 0.3250],
         [0.0031, 0.2216],
         [0.0018, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.449388, steer=0.005488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.19797218614629
22.35736664570868 seconds in game passed.
Action: tensor([[[0.0023, 0.6075],
         [0.0036, 0.3250],
         [0.0031, 0.2216],
         [0.0018, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.447028, steer=0.005489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.19797218614629
22.38236664608121 seconds in game passed.
Action: tensor([[[0.0023, 0.6075],
         [0.0036, 0.3250],
         [0.0031, 0.2216],
         [0.0018, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.444790, steer=0.005491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.19797218614629
+++++++++++++: 2.22006269561857
22.407366646453738 seconds in game passed.
At 22.407366646453738 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.5355e-03, 6.1586e-01],
         [1.6229e-03, 3.2657e-01],
         [1.0915e-03, 2.2232e-01],
         [2.2054e-05, 1.7038e-01]]])
agent 0 action: VehicleControl(throttle=0.471505, steer=0.003753, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.22006269561857
Current reward: 0.577552954227688
Current mitigation activation: 0
#############################
Total reward: 65.77552514037397
22.432366646826267 seconds in game passed.
Action: tensor([[[1.5355e-03, 6.1586e-01],
         [1.6229e-03, 3.2657e-01],
         [1.0915e-03, 2.2232e-01],
         [2.2054e-05, 1.7038e-01]]])
agent 0 action: VehicleControl(throttle=0.466486, steer=0.004031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.77552514037397
22.457366647198796 seconds in game passed.
Action: tensor([[[1.5355e-03, 6.1586e-01],
         [1.6229e-03, 3.2657e-01],
         [1.0915e-03, 2.2232e-01],
         [2.2054e-05, 1.7038e-01]]])
agent 0 action: VehicleControl(throttle=0.464556, steer=0.004021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.77552514037397
22.482366647571325 seconds in game passed.
Action: tensor([[[1.5355e-03, 6.1586e-01],
         [1.6229e-03, 3.2657e-01],
         [1.0915e-03, 2.2232e-01],
         [2.2054e-05, 1.7038e-01]]])
agent 0 action: VehicleControl(throttle=0.462496, steer=0.004011, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.77552514037397
+++++++++++++: 2.2491224899759334
22.507366647943854 seconds in game passed.
At 22.507366647943854 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.6174],
         [0.0033, 0.3277],
         [0.0034, 0.2230],
         [0.0028, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.435737, steer=0.005586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2491224899759334
Current reward: 0.5815205497089395
Current mitigation activation: 0
#############################
Total reward: 66.35704569008291
22.532366648316383 seconds in game passed.
Action: tensor([[[0.0023, 0.6174],
         [0.0033, 0.3277],
         [0.0034, 0.2230],
         [0.0028, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.436210, steer=0.005340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.35704569008291
22.557366648688912 seconds in game passed.
Action: tensor([[[0.0023, 0.6174],
         [0.0033, 0.3277],
         [0.0034, 0.2230],
         [0.0028, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.434148, steer=0.005354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.35704569008291
22.58236664906144 seconds in game passed.
Action: tensor([[[0.0023, 0.6174],
         [0.0033, 0.3277],
         [0.0034, 0.2230],
         [0.0028, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.432331, steer=0.005368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.35704569008291
+++++++++++++: 2.2779997895044977
22.60736664943397 seconds in game passed.
At 22.60736664943397 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0036, 0.6307],
         [0.0055, 0.3327],
         [0.0054, 0.2252],
         [0.0044, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.385404, steer=0.007460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2779997895044977
Current reward: 0.5855243156651717
Current mitigation activation: 0
#############################
Total reward: 66.94257000574808
22.6323666498065 seconds in game passed.
Action: tensor([[[0.0036, 0.6307],
         [0.0055, 0.3327],
         [0.0054, 0.2252],
         [0.0044, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.387736, steer=0.007131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.94257000574808
22.65736665017903 seconds in game passed.
Action: tensor([[[0.0036, 0.6307],
         [0.0055, 0.3327],
         [0.0054, 0.2252],
         [0.0044, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.385656, steer=0.007148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.94257000574808
22.682366650551558 seconds in game passed.
Action: tensor([[[0.0036, 0.6307],
         [0.0055, 0.3327],
         [0.0054, 0.2252],
         [0.0044, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.384131, steer=0.007165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.94257000574808
+++++++++++++: 2.3078637613382114
22.707366650924087 seconds in game passed.
At 22.707366650924087 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6089],
         [0.0054, 0.3272],
         [0.0054, 0.2232],
         [0.0046, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.358543, steer=0.007304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3078637613382114
Current reward: 0.5894078751515486
Current mitigation activation: 0
#############################
Total reward: 67.53197788089963
22.732366651296616 seconds in game passed.
Action: tensor([[[0.0042, 0.6089],
         [0.0054, 0.3272],
         [0.0054, 0.2232],
         [0.0046, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.359949, steer=0.007277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.53197788089963
22.757366651669145 seconds in game passed.
Action: tensor([[[0.0042, 0.6089],
         [0.0054, 0.3272],
         [0.0054, 0.2232],
         [0.0046, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.359208, steer=0.007274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.53197788089963
22.782366652041674 seconds in game passed.
Action: tensor([[[0.0042, 0.6089],
         [0.0054, 0.3272],
         [0.0054, 0.2232],
         [0.0046, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.358993, steer=0.007271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.53197788089963
+++++++++++++: 2.3404949372697685
22.807366652414203 seconds in game passed.
At 22.807366652414203 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2034e-03, 6.0528e-01],
         [1.1778e-03, 3.2603e-01],
         [8.4617e-04, 2.2286e-01],
         [5.9821e-05, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.362122, steer=0.002903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3404949372697685
Current reward: 0.5929513091164786
Current mitigation activation: 0
#############################
Total reward: 68.1249291900161
22.83236665278673 seconds in game passed.
Action: tensor([[[1.2034e-03, 6.0528e-01],
         [1.1778e-03, 3.2603e-01],
         [8.4617e-04, 2.2286e-01],
         [5.9821e-05, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.362934, steer=0.003476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.1249291900161
22.85736665315926 seconds in game passed.
Action: tensor([[[1.2034e-03, 6.0528e-01],
         [1.1778e-03, 3.2603e-01],
         [8.4617e-04, 2.2286e-01],
         [5.9821e-05, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.364297, steer=0.003343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.1249291900161
22.88236665353179 seconds in game passed.
Action: tensor([[[1.2034e-03, 6.0528e-01],
         [1.1778e-03, 3.2603e-01],
         [8.4617e-04, 2.2286e-01],
         [5.9821e-05, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.365919, steer=0.003210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.1249291900161
+++++++++++++: 2.3761733703365087
22.90736665390432 seconds in game passed.
At 22.90736665390432 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.5099e-04,  6.2651e-01],
         [-3.8331e-04,  3.3165e-01],
         [-8.3517e-04,  2.2482e-01],
         [-1.6813e-03,  1.7110e-01]]])
agent 0 action: VehicleControl(throttle=0.383997, steer=0.001083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3761733703365087
Current reward: 0.5961489965645599
Current mitigation activation: 0
#############################
Total reward: 68.72107818658067
22.932366654276848 seconds in game passed.
Action: tensor([[[-9.5099e-04,  6.2651e-01],
         [-3.8331e-04,  3.3165e-01],
         [-8.3517e-04,  2.2482e-01],
         [-1.6813e-03,  1.7110e-01]]])
agent 0 action: VehicleControl(throttle=0.385064, steer=0.001274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72107818658067
22.957366654649377 seconds in game passed.
Action: tensor([[[-9.5099e-04,  6.2651e-01],
         [-3.8331e-04,  3.3165e-01],
         [-8.3517e-04,  2.2482e-01],
         [-1.6813e-03,  1.7110e-01]]])
agent 0 action: VehicleControl(throttle=0.387877, steer=0.001134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72107818658067
22.982366655021906 seconds in game passed.
Action: tensor([[[-9.5099e-04,  6.2651e-01],
         [-3.8331e-04,  3.3165e-01],
         [-8.3517e-04,  2.2482e-01],
         [-1.6813e-03,  1.7110e-01]]])
agent 0 action: VehicleControl(throttle=0.390649, steer=0.000994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72107818658067
+++++++++++++: 2.4136194821916765
23.007366655394435 seconds in game passed.
At 23.007366655394435 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6164],
         [-0.0017,  0.3271],
         [-0.0022,  0.2222],
         [-0.0031,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.454054, steer=-0.000634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4136194821916765
Current reward: 0.5991957579836167
Current mitigation activation: 0
#############################
Total reward: 69.32027394456429
23.032366655766964 seconds in game passed.
Action: tensor([[[-0.0025,  0.6164],
         [-0.0017,  0.3271],
         [-0.0022,  0.2222],
         [-0.0031,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.451179, steer=-0.000455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.32027394456429
23.057366656139493 seconds in game passed.
Action: tensor([[[-0.0025,  0.6164],
         [-0.0017,  0.3271],
         [-0.0022,  0.2222],
         [-0.0031,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.454472, steer=-0.000535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.32027394456429
23.082366656512022 seconds in game passed.
Action: tensor([[[-0.0025,  0.6164],
         [-0.0017,  0.3271],
         [-0.0022,  0.2222],
         [-0.0031,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.457162, steer=-0.000615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.32027394456429
+++++++++++++: 2.450876837511284
23.10736665688455 seconds in game passed.
At 23.10736665688455 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6084],
         [-0.0014,  0.3254],
         [-0.0019,  0.2213],
         [-0.0028,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.439810, steer=-0.000096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.450876837511284
Current reward: 0.6023505295133815
Current mitigation activation: 0
#############################
Total reward: 69.92262447407768
23.13236665725708 seconds in game passed.
Action: tensor([[[-0.0015,  0.6084],
         [-0.0014,  0.3254],
         [-0.0019,  0.2213],
         [-0.0028,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.442703, steer=-0.000268, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.92262447407768
23.15736665762961 seconds in game passed.
Action: tensor([[[-0.0015,  0.6084],
         [-0.0014,  0.3254],
         [-0.0019,  0.2213],
         [-0.0028,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.443294, steer=-0.000341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.92262447407768
23.182366658002138 seconds in game passed.
Action: tensor([[[-0.0015,  0.6084],
         [-0.0014,  0.3254],
         [-0.0019,  0.2213],
         [-0.0028,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.443740, steer=-0.000414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.92262447407768
+++++++++++++: 2.485449759988719
23.207366658374667 seconds in game passed.
At 23.207366658374667 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.7157e-04,  6.0889e-01],
         [-7.2160e-04,  3.2619e-01],
         [-9.5553e-04,  2.2249e-01],
         [-1.4791e-03,  1.6974e-01]]])
agent 0 action: VehicleControl(throttle=0.418689, steer=0.000534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.485449759988719
Current reward: 0.6059007689067559
Current mitigation activation: 0
#############################
Total reward: 70.52852524298443
23.232366658747196 seconds in game passed.
Action: tensor([[[-1.7157e-04,  6.0889e-01],
         [-7.2160e-04,  3.2619e-01],
         [-9.5553e-04,  2.2249e-01],
         [-1.4791e-03,  1.6974e-01]]])
agent 0 action: VehicleControl(throttle=0.420641, steer=0.000299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.52852524298443
23.257366659119725 seconds in game passed.
Action: tensor([[[-1.7157e-04,  6.0889e-01],
         [-7.2160e-04,  3.2619e-01],
         [-9.5553e-04,  2.2249e-01],
         [-1.4791e-03,  1.6974e-01]]])
agent 0 action: VehicleControl(throttle=0.419928, steer=0.000233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.52852524298443
23.282366659492254 seconds in game passed.
Action: tensor([[[-1.7157e-04,  6.0889e-01],
         [-7.2160e-04,  3.2619e-01],
         [-9.5553e-04,  2.2249e-01],
         [-1.4791e-03,  1.6974e-01]]])
agent 0 action: VehicleControl(throttle=0.419343, steer=0.000168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.52852524298443
+++++++++++++: 2.51829836519811
23.307366659864783 seconds in game passed.
At 23.307366659864783 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.5554e-04,  6.0525e-01],
         [-8.2050e-04,  3.2623e-01],
         [-1.3078e-03,  2.2252e-01],
         [-1.8390e-03,  1.6912e-01]]])
agent 0 action: VehicleControl(throttle=0.379161, steer=-0.000060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.51829836519811
Current reward: 0.6096901995401569
Current mitigation activation: 0
#############################
Total reward: 71.13821544252458
23.332366660237312 seconds in game passed.
Action: tensor([[[-4.5554e-04,  6.0525e-01],
         [-8.2050e-04,  3.2623e-01],
         [-1.3078e-03,  2.2252e-01],
         [-1.8390e-03,  1.6912e-01]]])
agent 0 action: VehicleControl(throttle=0.382920, steer=-0.000075, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.13821544252458
23.35736666060984 seconds in game passed.
Action: tensor([[[-4.5554e-04,  6.0525e-01],
         [-8.2050e-04,  3.2623e-01],
         [-1.3078e-03,  2.2252e-01],
         [-1.8390e-03,  1.6912e-01]]])
agent 0 action: VehicleControl(throttle=0.382626, steer=-0.000119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.13821544252458
23.38236666098237 seconds in game passed.
Action: tensor([[[-4.5554e-04,  6.0525e-01],
         [-8.2050e-04,  3.2623e-01],
         [-1.3078e-03,  2.2252e-01],
         [-1.8390e-03,  1.6912e-01]]])
agent 0 action: VehicleControl(throttle=0.382745, steer=-0.000164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.13821544252458
+++++++++++++: 2.5515711023134267
23.4073666613549 seconds in game passed.
At 23.4073666613549 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.3910e-04,  6.1514e-01],
         [ 1.4960e-04,  3.2891e-01],
         [-1.8816e-04,  2.2353e-01],
         [-8.6899e-04,  1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.388920, steer=0.000881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5515711023134267
Current reward: 0.613440301583041
Current mitigation activation: 0
#############################
Total reward: 71.75165574410762
23.43236666172743 seconds in game passed.
Action: tensor([[[ 4.3910e-04,  6.1514e-01],
         [ 1.4960e-04,  3.2891e-01],
         [-1.8816e-04,  2.2353e-01],
         [-8.6899e-04,  1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.388672, steer=0.000688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.75165574410762
23.457366662099957 seconds in game passed.
Action: tensor([[[ 4.3910e-04,  6.1514e-01],
         [ 1.4960e-04,  3.2891e-01],
         [-1.8816e-04,  2.2353e-01],
         [-8.6899e-04,  1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.389262, steer=0.000672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.75165574410762
23.482366662472486 seconds in game passed.
Action: tensor([[[ 4.3910e-04,  6.1514e-01],
         [ 1.4960e-04,  3.2891e-01],
         [-1.8816e-04,  2.2353e-01],
         [-8.6899e-04,  1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.389980, steer=0.000657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.75165574410762
+++++++++++++: 2.5868264422101457
23.507366662845016 seconds in game passed.
At 23.507366662845016 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.8800e-03, 6.1945e-01],
         [2.2150e-03, 3.3015e-01],
         [1.3408e-03, 2.2483e-01],
         [1.2553e-04, 1.7101e-01]]])
agent 0 action: VehicleControl(throttle=0.390793, steer=0.003122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5868264422101457
Current reward: 0.6169761723741041
Current mitigation activation: 0
#############################
Total reward: 72.36863191648173
23.532366663217545 seconds in game passed.
Action: tensor([[[2.8800e-03, 6.1945e-01],
         [2.2150e-03, 3.3015e-01],
         [1.3408e-03, 2.2483e-01],
         [1.2553e-04, 1.7101e-01]]])
agent 0 action: VehicleControl(throttle=0.392030, steer=0.002704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.36863191648173
23.557366663590074 seconds in game passed.
Action: tensor([[[2.8800e-03, 6.1945e-01],
         [2.2150e-03, 3.3015e-01],
         [1.3408e-03, 2.2483e-01],
         [1.2553e-04, 1.7101e-01]]])
agent 0 action: VehicleControl(throttle=0.393326, steer=0.002698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.36863191648173
23.582366663962603 seconds in game passed.
Action: tensor([[[2.8800e-03, 6.1945e-01],
         [2.2150e-03, 3.3015e-01],
         [1.3408e-03, 2.2483e-01],
         [1.2553e-04, 1.7101e-01]]])
agent 0 action: VehicleControl(throttle=0.394678, steer=0.002692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.36863191648173
+++++++++++++: 2.6234461970232723
23.60736666433513 seconds in game passed.
At 23.60736666433513 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2419e-03,  6.2020e-01],
         [ 3.6044e-04,  3.2929e-01],
         [-5.8636e-05,  2.2464e-01],
         [-5.7306e-04,  1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.435241, steer=0.001034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6234461970232723
Current reward: 0.6203948793265778
Current mitigation activation: 0
#############################
Total reward: 72.98902679580831
23.63236666470766 seconds in game passed.
Action: tensor([[[ 2.2419e-03,  6.2020e-01],
         [ 3.6044e-04,  3.2929e-01],
         [-5.8636e-05,  2.2464e-01],
         [-5.7306e-04,  1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.433488, steer=0.001258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.98902679580831
23.65736666508019 seconds in game passed.
Action: tensor([[[ 2.2419e-03,  6.2020e-01],
         [ 3.6044e-04,  3.2929e-01],
         [-5.8636e-05,  2.2464e-01],
         [-5.7306e-04,  1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.435728, steer=0.001213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.98902679580831
23.68236666545272 seconds in game passed.
Action: tensor([[[ 2.2419e-03,  6.2020e-01],
         [ 3.6044e-04,  3.2929e-01],
         [-5.8636e-05,  2.2464e-01],
         [-5.7306e-04,  1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.437629, steer=0.001169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.98902679580831
+++++++++++++: 2.6603739761020346
23.707366665825248 seconds in game passed.
At 23.707366665825248 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.9957e-04,  6.1476e-01],
         [-1.2522e-03,  3.2729e-01],
         [-1.3487e-03,  2.2333e-01],
         [-1.6839e-03,  1.6965e-01]]])
agent 0 action: VehicleControl(throttle=0.456390, steer=-0.001077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6603739761020346
Current reward: 0.6238245415746433
Current mitigation activation: 0
#############################
Total reward: 73.61285133738296
23.732366666197777 seconds in game passed.
Action: tensor([[[-2.9957e-04,  6.1476e-01],
         [-1.2522e-03,  3.2729e-01],
         [-1.3487e-03,  2.2333e-01],
         [-1.6839e-03,  1.6965e-01]]])
agent 0 action: VehicleControl(throttle=0.456487, steer=-0.000783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.61285133738296
23.757366666570306 seconds in game passed.
Action: tensor([[[-2.9957e-04,  6.1476e-01],
         [-1.2522e-03,  3.2729e-01],
         [-1.3487e-03,  2.2333e-01],
         [-1.6839e-03,  1.6965e-01]]])
agent 0 action: VehicleControl(throttle=0.458112, steer=-0.000852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.61285133738296
23.782366666942835 seconds in game passed.
Action: tensor([[[-2.9957e-04,  6.1476e-01],
         [-1.2522e-03,  3.2729e-01],
         [-1.3487e-03,  2.2333e-01],
         [-1.6839e-03,  1.6965e-01]]])
agent 0 action: VehicleControl(throttle=0.459387, steer=-0.000920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.61285133738296
+++++++++++++: 2.695577081300257
23.807366667315364 seconds in game passed.
At 23.807366667315364 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6181],
         [-0.0032,  0.3274],
         [-0.0035,  0.2225],
         [-0.0036,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.490799, steer=-0.002782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.695577081300257
Current reward: 0.6274833836309108
Current mitigation activation: 0
#############################
Total reward: 74.24033472101388
23.832366667687893 seconds in game passed.
Action: tensor([[[-0.0013,  0.6181],
         [-0.0032,  0.3274],
         [-0.0035,  0.2225],
         [-0.0036,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.488615, steer=-0.002523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.24033472101388
23.857366668060422 seconds in game passed.
Action: tensor([[[-0.0013,  0.6181],
         [-0.0032,  0.3274],
         [-0.0035,  0.2225],
         [-0.0036,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.489344, steer=-0.002566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.24033472101388
23.88236666843295 seconds in game passed.
Action: tensor([[[-0.0013,  0.6181],
         [-0.0032,  0.3274],
         [-0.0035,  0.2225],
         [-0.0036,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.489591, steer=-0.002610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.24033472101388
+++++++++++++: 2.7282557655976314
23.90736666880548 seconds in game passed.
At 23.90736666880548 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.6160],
         [-0.0054,  0.3285],
         [-0.0057,  0.2236],
         [-0.0058,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.426020, steer=-0.004921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7282557655976314
Current reward: 0.6314338897335552
Current mitigation activation: 0
#############################
Total reward: 74.87176861074744
23.93236666917801 seconds in game passed.
Action: tensor([[[-0.0030,  0.6160],
         [-0.0054,  0.3285],
         [-0.0057,  0.2236],
         [-0.0058,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.431411, steer=-0.004590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.87176861074744
23.957366669550538 seconds in game passed.
Action: tensor([[[-0.0030,  0.6160],
         [-0.0054,  0.3285],
         [-0.0057,  0.2236],
         [-0.0058,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.430017, steer=-0.004637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.87176861074744
23.982366669923067 seconds in game passed.
Action: tensor([[[-0.0030,  0.6160],
         [-0.0054,  0.3285],
         [-0.0057,  0.2236],
         [-0.0058,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.428923, steer=-0.004683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.87176861074744
+++++++++++++: 2.75823467611321
24.007366670295596 seconds in game passed.
At 24.007366670295596 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6011],
         [-0.0011,  0.3238],
         [-0.0009,  0.2211],
         [-0.0010,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.442546, steer=-0.000766, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.75823467611321
Current reward: 0.6356653585424726
Current mitigation activation: 0
#############################
Total reward: 75.5074339692899
24.032366670668125 seconds in game passed.
Action: tensor([[[-0.0011,  0.6011],
         [-0.0011,  0.3238],
         [-0.0009,  0.2211],
         [-0.0010,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.439648, steer=-0.001406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.5074339692899
24.057366671040654 seconds in game passed.
Action: tensor([[[-0.0011,  0.6011],
         [-0.0011,  0.3238],
         [-0.0009,  0.2211],
         [-0.0010,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.438442, steer=-0.001396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.5074339692899
24.082366671413183 seconds in game passed.
Action: tensor([[[-0.0011,  0.6011],
         [-0.0011,  0.3238],
         [-0.0009,  0.2211],
         [-0.0010,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.437231, steer=-0.001386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.5074339692899
+++++++++++++: 2.788799564244366
24.107366671785712 seconds in game passed.
At 24.107366671785712 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.1774e-04,  5.9832e-01],
         [ 8.3674e-04,  3.2371e-01],
         [ 1.1705e-03,  2.2124e-01],
         [ 1.0083e-03,  1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.411043, steer=0.000372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.788799564244366
Current reward: 0.6398041002279038
Current mitigation activation: 0
#############################
Total reward: 76.14723806951781
24.13236667215824 seconds in game passed.
Action: tensor([[[-2.1774e-04,  5.9832e-01],
         [ 8.3674e-04,  3.2371e-01],
         [ 1.1705e-03,  2.2124e-01],
         [ 1.0083e-03,  1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.412506, steer=0.000105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.14723806951781
24.15736667253077 seconds in game passed.
Action: tensor([[[-2.1774e-04,  5.9832e-01],
         [ 8.3674e-04,  3.2371e-01],
         [ 1.1705e-03,  2.2124e-01],
         [ 1.0083e-03,  1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.411415, steer=0.000127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.14723806951781
24.1823666729033 seconds in game passed.
Action: tensor([[[-2.1774e-04,  5.9832e-01],
         [ 8.3674e-04,  3.2371e-01],
         [ 1.1705e-03,  2.2124e-01],
         [ 1.0083e-03,  1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.410583, steer=0.000149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.14723806951781
+++++++++++++: 2.8203017716711654
24.20736667327583 seconds in game passed.
At 24.20736667327583 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0009, 0.6030],
         [0.0018, 0.3254],
         [0.0021, 0.2219],
         [0.0018, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.398188, steer=0.001345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8203017716711654
Current reward: 0.6438223898577642
Current mitigation activation: 0
#############################
Total reward: 76.79106045937557
24.232366673648357 seconds in game passed.
Action: tensor([[[0.0009, 0.6030],
         [0.0018, 0.3254],
         [0.0021, 0.2219],
         [0.0018, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.399131, steer=0.001174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.79106045937557
24.257366674020886 seconds in game passed.
Action: tensor([[[0.0009, 0.6030],
         [0.0018, 0.3254],
         [0.0021, 0.2219],
         [0.0018, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.398987, steer=0.001198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.79106045937557
24.282366674393415 seconds in game passed.
Action: tensor([[[0.0009, 0.6030],
         [0.0018, 0.3254],
         [0.0021, 0.2219],
         [0.0018, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.399071, steer=0.001222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.79106045937557
+++++++++++++: 2.8533778013094535
24.307366674765944 seconds in game passed.
At 24.307366674765944 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.6025],
         [0.0027, 0.3248],
         [0.0025, 0.2225],
         [0.0018, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.416586, steer=0.002550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8533778013094535
Current reward: 0.6476608367449371
Current mitigation activation: 0
#############################
Total reward: 77.4387212961205
24.332366675138474 seconds in game passed.
Action: tensor([[[0.0027, 0.6025],
         [0.0027, 0.3248],
         [0.0025, 0.2225],
         [0.0018, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.415840, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.4387212961205
24.357366675511003 seconds in game passed.
Action: tensor([[[0.0027, 0.6025],
         [0.0027, 0.3248],
         [0.0025, 0.2225],
         [0.0018, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.416951, steer=0.002414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.4387212961205
24.38236667588353 seconds in game passed.
Action: tensor([[[0.0027, 0.6025],
         [0.0027, 0.3248],
         [0.0025, 0.2225],
         [0.0018, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.418002, steer=0.002453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.4387212961205
+++++++++++++: 2.8881498023128436
24.40736667625606 seconds in game passed.
At 24.40736667625606 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6130],
         [0.0026, 0.3274],
         [0.0027, 0.2234],
         [0.0024, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.433005, steer=0.002668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8881498023128436
Current reward: 0.6513232066070915
Current mitigation activation: 0
#############################
Total reward: 78.0900445027276
24.43236667662859 seconds in game passed.
Action: tensor([[[0.0032, 0.6130],
         [0.0026, 0.3274],
         [0.0027, 0.2234],
         [0.0024, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.432584, steer=0.002667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.0900445027276
24.45736667700112 seconds in game passed.
Action: tensor([[[0.0032, 0.6130],
         [0.0026, 0.3274],
         [0.0027, 0.2234],
         [0.0024, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.433566, steer=0.002698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.0900445027276
24.482366677373648 seconds in game passed.
Action: tensor([[[0.0032, 0.6130],
         [0.0026, 0.3274],
         [0.0027, 0.2234],
         [0.0024, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.434376, steer=0.002728, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.0900445027276
+++++++++++++: 2.923110748010326
24.507366677746177 seconds in game passed.
At 24.507366677746177 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.6207],
         [0.0006, 0.3290],
         [0.0008, 0.2236],
         [0.0008, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.458789, steer=0.000541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.923110748010326
Current reward: 0.6549770953112944
Current mitigation activation: 0
#############################
Total reward: 78.74502159803889
24.532366678118706 seconds in game passed.
Action: tensor([[[0.0014, 0.6207],
         [0.0006, 0.3290],
         [0.0008, 0.2236],
         [0.0008, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.457097, steer=0.000884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.74502159803889
24.557366678491235 seconds in game passed.
Action: tensor([[[0.0014, 0.6207],
         [0.0006, 0.3290],
         [0.0008, 0.2236],
         [0.0008, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.457734, steer=0.000866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.74502159803889
24.582366678863764 seconds in game passed.
Action: tensor([[[0.0014, 0.6207],
         [0.0006, 0.3290],
         [0.0008, 0.2236],
         [0.0008, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.458065, steer=0.000847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.74502159803889
+++++++++++++: 2.9570233278443063
24.607366679236293 seconds in game passed.
At 24.607366679236293 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.6139],
         [-0.0033,  0.3254],
         [-0.0037,  0.2214],
         [-0.0040,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.519383, steer=-0.003216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9570233278443063
Current reward: 0.6587362939612058
Current mitigation activation: 0
#############################
Total reward: 79.4037578920001
24.632366679608822 seconds in game passed.
Action: tensor([[[-0.0016,  0.6139],
         [-0.0033,  0.3254],
         [-0.0037,  0.2214],
         [-0.0040,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.513003, steer=-0.002589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.4037578920001
24.65736667998135 seconds in game passed.
Action: tensor([[[-0.0016,  0.6139],
         [-0.0033,  0.3254],
         [-0.0037,  0.2214],
         [-0.0040,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.512824, steer=-0.002632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.4037578920001
24.68236668035388 seconds in game passed.
Action: tensor([[[-0.0016,  0.6139],
         [-0.0033,  0.3254],
         [-0.0037,  0.2214],
         [-0.0040,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.511952, steer=-0.002676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.4037578920001
+++++++++++++: 2.988656000541936
24.70736668072641 seconds in game passed.
At 24.70736668072641 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.6129],
         [-0.0081,  0.3260],
         [-0.0090,  0.2219],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.477009, steer=-0.007031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.988656000541936
Current reward: 0.6626826963823313
Current mitigation activation: 0
#############################
Total reward: 80.06644058838243
24.732366681098938 seconds in game passed.
Action: tensor([[[-0.0035,  0.6129],
         [-0.0081,  0.3260],
         [-0.0090,  0.2219],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.478253, steer=-0.006382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.06644058838243
24.757366681471467 seconds in game passed.
Action: tensor([[[-0.0035,  0.6129],
         [-0.0081,  0.3260],
         [-0.0090,  0.2219],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.475770, steer=-0.006447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.06644058838243
24.782366681843996 seconds in game passed.
Action: tensor([[[-0.0035,  0.6129],
         [-0.0081,  0.3260],
         [-0.0090,  0.2219],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.473281, steer=-0.006512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.06644058838243
+++++++++++++: 3.016337276814539
24.807366682216525 seconds in game passed.
At 24.807366682216525 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.6079],
         [-0.0058,  0.3261],
         [-0.0060,  0.2225],
         [-0.0061,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.415354, steer=-0.004996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.016337276814539
Current reward: 0.6667793598295271
Current mitigation activation: 0
#############################
Total reward: 80.73321994821197
24.832366682589054 seconds in game passed.
Action: tensor([[[-0.0039,  0.6079],
         [-0.0058,  0.3261],
         [-0.0060,  0.2225],
         [-0.0061,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.417753, steer=-0.005284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.73321994821197
24.857366682961583 seconds in game passed.
Action: tensor([[[-0.0039,  0.6079],
         [-0.0058,  0.3261],
         [-0.0060,  0.2225],
         [-0.0061,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.414491, steer=-0.005315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.73321994821197
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:07:45 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:08:29 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 44.97s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.4s               │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.52                │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 80.73, average_reward: 80.73321994821197 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00008/fi_lead_slowdown_data
