New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190632-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190632-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190632-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190632-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190632-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190632-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 39.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 39}
1.5332676284015179 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.558267628774047 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.583267629146576 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.608267629519105 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002708, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.633267629891634 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.658267630264163 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0053, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.683267630636692 seconds in game passed.
Action: tensor([[[0.0053, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.708267631009221 seconds in game passed.
Action: tensor([[[0.0053, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.73326763138175 seconds in game passed.
Action: tensor([[[0.0053, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7582676317542791 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7832676321268082 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8082676324993372 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8332676328718662 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8582676332443953 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8832676336169243 seconds in game passed.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9082676339894533 seconds in game passed.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9332676343619823 seconds in game passed.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9582676347345114 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5918],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9832676351070404 seconds in game passed.
Action: tensor([[[0.0028, 0.5918],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0082676354795694 seconds in game passed.
Action: tensor([[[0.0028, 0.5918],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0332676358520985 seconds in game passed.
Action: tensor([[[0.0028, 0.5918],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0582676362246275 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4502e-03, 5.9045e-01],
         [1.3482e-03, 3.2229e-01],
         [1.1192e-03, 2.2210e-01],
         [5.7514e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0832676365971565 seconds in game passed.
Action: tensor([[[2.4502e-03, 5.9045e-01],
         [1.3482e-03, 3.2229e-01],
         [1.1192e-03, 2.2210e-01],
         [5.7514e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1082676369696856 seconds in game passed.
Action: tensor([[[2.4502e-03, 5.9045e-01],
         [1.3482e-03, 3.2229e-01],
         [1.1192e-03, 2.2210e-01],
         [5.7514e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1332676373422146 seconds in game passed.
Action: tensor([[[2.4502e-03, 5.9045e-01],
         [1.3482e-03, 3.2229e-01],
         [1.1192e-03, 2.2210e-01],
         [5.7514e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.1582676377147436 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.1832676380872726 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2082676384598017 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2332676388323307 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.2582676392048597 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.2832676395773888 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.308267639949918 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.333267640322447 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.358267640694976 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.383267641067505 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.408267641440034 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.433267641812563 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.458267642185092 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.483267642557621 seconds in game passed.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.50826764293015 seconds in game passed.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.533267643302679 seconds in game passed.
Action: tensor([[[0.0021, 0.5883],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002791, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.558267643675208 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.583267644047737 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.608267644420266 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.633267644792795 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.658267645165324 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6832676455378532 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7082676459103823 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002612, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7332676462829113 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7582676466554403 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.7832676470279694 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8082676474004984 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8332676477730274 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.8582676481455564 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.8832676485180855 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9082676488906145 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9332676492631435 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.9582676496356726 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.9832676500082016 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0082676503807306 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0332676507532597 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.0582676511257887 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.0832676514983177 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1082676518708467 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.133267652243376 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.158267652615905 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.183267652988434 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.208267653360963 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.233267653733492 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.258267654106021 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.28326765447855 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.308267654851079 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.333267655223608 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.358267655596137 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002268, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.383267655968666 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.408267656341195 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.433267656713724 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.458267657086253 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.483267657458782 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5082676578313112 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5332676582038403 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5582676585763693 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5832676589488983 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6082676593214273 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6332676596939564 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6582676600664854 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6832676604390144 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7082676608115435 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7332676611840725 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7582676615566015 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7832676619291306 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8082676623016596 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8332676626741886 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8582676630467176 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8832676634192467 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9082676637917757 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9332676641643047 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.9582676645368338 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.983267664909363 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.008267665281892 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.033267665654421 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.05826766602695 seconds in game passed.
At 4.05826766602695 seconds, saving state-action tuples.
Action: tensor([[[1.4083e-03, 5.8604e-01],
         [1.1365e-03, 3.2065e-01],
         [1.0061e-03, 2.2099e-01],
         [3.5717e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.083267666399479 seconds in game passed.
Action: tensor([[[1.4083e-03, 5.8604e-01],
         [1.1365e-03, 3.2065e-01],
         [1.0061e-03, 2.2099e-01],
         [3.5717e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.108267666772008 seconds in game passed.
Action: tensor([[[1.4083e-03, 5.8604e-01],
         [1.1365e-03, 3.2065e-01],
         [1.0061e-03, 2.2099e-01],
         [3.5717e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.133267667144537 seconds in game passed.
Action: tensor([[[1.4083e-03, 5.8604e-01],
         [1.1365e-03, 3.2065e-01],
         [1.0061e-03, 2.2099e-01],
         [3.5717e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.883738821806649
4.158267667517066 seconds in game passed.
At 4.158267667517066 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.65612528475237
4.183267667889595 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
4.208267668262124 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 0.65612528475237
4.233267668634653 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
+++++++++++++: 8.843383999601484
4.258267669007182 seconds in game passed.
At 4.258267669007182 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3201],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383999601484
Current reward: 0.49259322239340864
Current mitigation activation: 0
#############################
Total reward: 1.1487185071457786
4.283267669379711 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3201],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002958, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.30826766975224 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3201],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.333267670124769 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3201],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002972, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
+++++++++++++: 7.228547872515916
4.358267670497298 seconds in game passed.
At 4.358267670497298 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5864],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228547872515916
Current reward: 0.5118171203336291
Current mitigation activation: 0
#############################
Total reward: 1.6605356274794079
4.383267670869827 seconds in game passed.
Action: tensor([[[0.0028, 0.5864],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
4.408267671242356 seconds in game passed.
Action: tensor([[[0.0028, 0.5864],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
4.433267671614885 seconds in game passed.
Action: tensor([[[0.0028, 0.5864],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
+++++++++++++: 6.215940449165687
4.458267671987414 seconds in game passed.
At 4.458267671987414 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5896],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002807, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.215940449165687
Current reward: 0.5264941677236088
Current mitigation activation: 0
#############################
Total reward: 2.1870297952030167
4.483267672359943 seconds in game passed.
Action: tensor([[[0.0021, 0.5896],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
4.508267672732472 seconds in game passed.
Action: tensor([[[0.0021, 0.5896],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002954, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
4.5332676731050014 seconds in game passed.
Action: tensor([[[0.0021, 0.5896],
         [0.0023, 0.3221],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
+++++++++++++: 5.508366078862486
4.5582676734775305 seconds in game passed.
At 4.5582676734775305 seconds, saving state-action tuples.
Action: tensor([[[-9.5792e-05,  5.8869e-01],
         [ 1.7975e-04,  3.2203e-01],
         [ 2.9904e-04,  2.2122e-01],
         [-8.2493e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508366078862486
Current reward: 0.5376235138087542
Current mitigation activation: 0
#############################
Total reward: 2.724653309011771
4.5832676738500595 seconds in game passed.
Action: tensor([[[-9.5792e-05,  5.8869e-01],
         [ 1.7975e-04,  3.2203e-01],
         [ 2.9904e-04,  2.2122e-01],
         [-8.2493e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
4.6082676742225885 seconds in game passed.
Action: tensor([[[-9.5792e-05,  5.8869e-01],
         [ 1.7975e-04,  3.2203e-01],
         [ 2.9904e-04,  2.2122e-01],
         [-8.2493e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000890, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
4.633267674595118 seconds in game passed.
Action: tensor([[[-9.5792e-05,  5.8869e-01],
         [ 1.7975e-04,  3.2203e-01],
         [ 2.9904e-04,  2.2122e-01],
         [-8.2493e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
+++++++++++++: 4.976064786060188
4.658267674967647 seconds in game passed.
At 4.658267674967647 seconds, saving state-action tuples.
Action: tensor([[[ 2.9235e-04,  5.8913e-01],
         [-2.9992e-04,  3.2138e-01],
         [-2.1324e-04,  2.2104e-01],
         [-3.8227e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.976064786060188
Current reward: 0.5459318040269082
Current mitigation activation: 0
#############################
Total reward: 3.270585113038679
4.683267675340176 seconds in game passed.
Action: tensor([[[ 2.9235e-04,  5.8913e-01],
         [-2.9992e-04,  3.2138e-01],
         [-2.1324e-04,  2.2104e-01],
         [-3.8227e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.270585113038679
4.708267675712705 seconds in game passed.
Action: tensor([[[ 2.9235e-04,  5.8913e-01],
         [-2.9992e-04,  3.2138e-01],
         [-2.1324e-04,  2.2104e-01],
         [-3.8227e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.270585113038679
4.733267676085234 seconds in game passed.
Action: tensor([[[ 2.9235e-04,  5.8913e-01],
         [-2.9992e-04,  3.2138e-01],
         [-2.1324e-04,  2.2104e-01],
         [-3.8227e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.270585113038679
+++++++++++++: 4.5525901226174925
4.758267676457763 seconds in game passed.
At 4.758267676457763 seconds, saving state-action tuples.
Action: tensor([[[-2.5316e-04,  5.9065e-01],
         [-9.6764e-04,  3.2154e-01],
         [-8.4390e-04,  2.2112e-01],
         [-9.7445e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.5525901226174925
Current reward: 0.5519988231085199
Current mitigation activation: 0
#############################
Total reward: 3.8225839361471987
4.783267676830292 seconds in game passed.
Action: tensor([[[-2.5316e-04,  5.9065e-01],
         [-9.6764e-04,  3.2154e-01],
         [-8.4390e-04,  2.2112e-01],
         [-9.7445e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225839361471987
4.808267677202821 seconds in game passed.
Action: tensor([[[-2.5316e-04,  5.9065e-01],
         [-9.6764e-04,  3.2154e-01],
         [-8.4390e-04,  2.2112e-01],
         [-9.7445e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225839361471987
4.83326767757535 seconds in game passed.
Action: tensor([[[-2.5316e-04,  5.9065e-01],
         [-9.6764e-04,  3.2154e-01],
         [-8.4390e-04,  2.2112e-01],
         [-9.7445e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225839361471987
+++++++++++++: 4.199610002184684
4.858267677947879 seconds in game passed.
At 4.858267677947879 seconds, saving state-action tuples.
Action: tensor([[[ 5.4682e-04,  5.9008e-01],
         [-5.5993e-04,  3.2162e-01],
         [-4.3843e-04,  2.2127e-01],
         [-4.7404e-04,  1.6780e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199610002184684
Current reward: 0.5563325824537015
Current mitigation activation: 0
#############################
Total reward: 4.3789165186009
4.883267678320408 seconds in game passed.
Action: tensor([[[ 5.4682e-04,  5.9008e-01],
         [-5.5993e-04,  3.2162e-01],
         [-4.3843e-04,  2.2127e-01],
         [-4.7404e-04,  1.6780e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.3789165186009
4.908267678692937 seconds in game passed.
Action: tensor([[[ 5.4682e-04,  5.9008e-01],
         [-5.5993e-04,  3.2162e-01],
         [-4.3843e-04,  2.2127e-01],
         [-4.7404e-04,  1.6780e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.3789165186009
4.933267679065466 seconds in game passed.
Action: tensor([[[ 5.4682e-04,  5.9008e-01],
         [-5.5993e-04,  3.2162e-01],
         [-4.3843e-04,  2.2127e-01],
         [-4.7404e-04,  1.6780e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.3789165186009
+++++++++++++: 3.8947620647612147
4.958267679437995 seconds in game passed.
At 4.958267679437995 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0011, 0.2219],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.8947620647612147
Current reward: 0.5593081246861429
Current mitigation activation: 0
#############################
Total reward: 4.938224643287043
4.983267679810524 seconds in game passed.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0011, 0.2219],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938224643287043
5.008267680183053 seconds in game passed.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0011, 0.2219],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938224643287043
5.033267680555582 seconds in game passed.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0011, 0.2219],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938224643287043
+++++++++++++: 3.624633372069584
5.058267680928111 seconds in game passed.
At 5.058267680928111 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3060e-03, 5.8981e-01],
         [1.0733e-03, 3.2206e-01],
         [9.2360e-04, 2.2281e-01],
         [5.6433e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.624633372069584
Current reward: 0.5611795704650537
Current mitigation activation: 0
#############################
Total reward: 5.499404213752097
5.08326768130064 seconds in game passed.
Action: tensor([[[1.3060e-03, 5.8981e-01],
         [1.0733e-03, 3.2206e-01],
         [9.2360e-04, 2.2281e-01],
         [5.6433e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499404213752097
5.108267681673169 seconds in game passed.
Action: tensor([[[1.3060e-03, 5.8981e-01],
         [1.0733e-03, 3.2206e-01],
         [9.2360e-04, 2.2281e-01],
         [5.6433e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499404213752097
5.133267682045698 seconds in game passed.
Action: tensor([[[1.3060e-03, 5.8981e-01],
         [1.0733e-03, 3.2206e-01],
         [9.2360e-04, 2.2281e-01],
         [5.6433e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499404213752097
+++++++++++++: 3.3804845491563755
5.158267682418227 seconds in game passed.
At 5.158267682418227 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3203],
         [0.0021, 0.2212],
         [0.0018, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3804845491563755
Current reward: 0.5621373023945144
Current mitigation activation: 0
#############################
Total reward: 6.061541516146612
5.183267682790756 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3203],
         [0.0021, 0.2212],
         [0.0018, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061541516146612
5.208267683163285 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3203],
         [0.0021, 0.2212],
         [0.0018, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061541516146612
5.233267683535814 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3203],
         [0.0021, 0.2212],
         [0.0018, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061541516146612
+++++++++++++: 3.156571837292092
5.258267683908343 seconds in game passed.
At 5.258267683908343 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2216],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.156571837292092
Current reward: 0.562312477867865
Current mitigation activation: 0
#############################
Total reward: 6.6238539940144765
5.283267684280872 seconds in game passed.
Action: tensor([[[0.0026, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2216],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.6238539940144765
5.308267684653401 seconds in game passed.
Action: tensor([[[0.0026, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2216],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.6238539940144765
5.33326768502593 seconds in game passed.
Action: tensor([[[0.0026, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2216],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.6238539940144765
+++++++++++++: 2.948950634627769
5.358267685398459 seconds in game passed.
At 5.358267685398459 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5891],
         [0.0029, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.948950634627769
Current reward: 0.5617966939849393
Current mitigation activation: 0
#############################
Total reward: 7.1856506879994155
5.3832676857709885 seconds in game passed.
Action: tensor([[[0.0023, 0.5891],
         [0.0029, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003008, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1856506879994155
5.4082676861435175 seconds in game passed.
Action: tensor([[[0.0023, 0.5891],
         [0.0029, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003004, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1856506879994155
5.4332676865160465 seconds in game passed.
Action: tensor([[[0.0023, 0.5891],
         [0.0029, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003001, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1856506879994155
+++++++++++++: 2.788067992603945
5.4582676868885756 seconds in game passed.
At 5.4582676868885756 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.4791e-04,  5.8854e-01],
         [ 7.2494e-05,  3.2104e-01],
         [-7.7009e-05,  2.2112e-01],
         [-3.7526e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.788067992603945
Current reward: 0.5575288841583876
Current mitigation activation: 0
#############################
Total reward: 7.743179572157803
5.483267687261105 seconds in game passed.
Action: tensor([[[ 8.4791e-04,  5.8854e-01],
         [ 7.2494e-05,  3.2104e-01],
         [-7.7009e-05,  2.2112e-01],
         [-3.7526e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743179572157803
5.508267687633634 seconds in game passed.
Action: tensor([[[ 8.4791e-04,  5.8854e-01],
         [ 7.2494e-05,  3.2104e-01],
         [-7.7009e-05,  2.2112e-01],
         [-3.7526e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743179572157803
5.533267688006163 seconds in game passed.
Action: tensor([[[ 8.4791e-04,  5.8854e-01],
         [ 7.2494e-05,  3.2104e-01],
         [-7.7009e-05,  2.2112e-01],
         [-3.7526e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743179572157803
+++++++++++++: 2.6913249524416223
5.558267688378692 seconds in game passed.
At 5.558267688378692 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5928],
         [-0.0020,  0.3225],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6913249524416223
Current reward: 0.547201898842634
Current mitigation activation: 0
#############################
Total reward: 8.290381471000437
5.583267688751221 seconds in game passed.
Action: tensor([[[-0.0010,  0.5928],
         [-0.0020,  0.3225],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290381471000437
5.60826768912375 seconds in game passed.
Action: tensor([[[-0.0010,  0.5928],
         [-0.0020,  0.3225],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290381471000437
5.633267689496279 seconds in game passed.
Action: tensor([[[-0.0010,  0.5928],
         [-0.0020,  0.3225],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290381471000437
+++++++++++++: 2.5950022282949567
5.658267689868808 seconds in game passed.
At 5.658267689868808 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.5906],
         [-0.0038,  0.3218],
         [-0.0045,  0.2209],
         [-0.0050,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5950022282949567
Current reward: 0.5368304149185856
Current mitigation activation: 0
#############################
Total reward: 8.827211885919022
5.683267690241337 seconds in game passed.
Action: tensor([[[-0.0023,  0.5906],
         [-0.0038,  0.3218],
         [-0.0045,  0.2209],
         [-0.0050,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827211885919022
5.708267690613866 seconds in game passed.
Action: tensor([[[-0.0023,  0.5906],
         [-0.0038,  0.3218],
         [-0.0045,  0.2209],
         [-0.0050,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827211885919022
5.733267690986395 seconds in game passed.
Action: tensor([[[-0.0023,  0.5906],
         [-0.0038,  0.3218],
         [-0.0045,  0.2209],
         [-0.0050,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827211885919022
+++++++++++++: 2.4986330940415096
5.758267691358924 seconds in game passed.
At 5.758267691358924 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4986330940415096
Current reward: 0.5264622754040121
Current mitigation activation: 0
#############################
Total reward: 9.353674161323035
5.783267691731453 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353674161323035
5.808267692103982 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353674161323035
5.833267692476511 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353674161323035
+++++++++++++: 2.4022191258676284
5.85826769284904 seconds in game passed.
At 5.85826769284904 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.6872e-05,  5.9088e-01],
         [-7.1903e-04,  3.2168e-01],
         [-7.5116e-04,  2.2133e-01],
         [-9.4490e-04,  1.6802e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4022191258676284
Current reward: 0.5160981082091306
Current mitigation activation: 0
#############################
Total reward: 9.869772269532165
5.883267693221569 seconds in game passed.
Action: tensor([[[-9.6872e-05,  5.9088e-01],
         [-7.1903e-04,  3.2168e-01],
         [-7.5116e-04,  2.2133e-01],
         [-9.4490e-04,  1.6802e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869772269532165
5.908267693594098 seconds in game passed.
Action: tensor([[[-9.6872e-05,  5.9088e-01],
         [-7.1903e-04,  3.2168e-01],
         [-7.5116e-04,  2.2133e-01],
         [-9.4490e-04,  1.6802e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869772269532165
5.933267693966627 seconds in game passed.
Action: tensor([[[-9.6872e-05,  5.9088e-01],
         [-7.1903e-04,  3.2168e-01],
         [-7.5116e-04,  2.2133e-01],
         [-9.4490e-04,  1.6802e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869772269532165
+++++++++++++: 2.2737125009408232
5.958267694339156 seconds in game passed.
At 5.958267694339156 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.8979e-05,  5.9201e-01],
         [ 1.8895e-04,  3.2211e-01],
         [ 2.4424e-04,  2.2163e-01],
         [-1.0989e-04,  1.6828e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000204, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2737125009408232
Current reward: 0.509338237005649
Current mitigation activation: 0
#############################
Total reward: 10.379110506537813
5.983267694711685 seconds in game passed.
Action: tensor([[[-5.8979e-05,  5.9201e-01],
         [ 1.8895e-04,  3.2211e-01],
         [ 2.4424e-04,  2.2163e-01],
         [-1.0989e-04,  1.6828e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000081, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379110506537813
6.008267695084214 seconds in game passed.
Action: tensor([[[-5.8979e-05,  5.9201e-01],
         [ 1.8895e-04,  3.2211e-01],
         [ 2.4424e-04,  2.2163e-01],
         [-1.0989e-04,  1.6828e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379110506537813
6.033267695456743 seconds in game passed.
Action: tensor([[[-5.8979e-05,  5.9201e-01],
         [ 1.8895e-04,  3.2211e-01],
         [ 2.4424e-04,  2.2163e-01],
         [-1.0989e-04,  1.6828e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379110506537813
+++++++++++++: 2.069402787615965
6.058267695829272 seconds in game passed.
At 6.058267695829272 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0030, 0.5964],
         [0.0037, 0.3256],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.069402787615965
Current reward: 0.512239614937432
Current mitigation activation: 0
#############################
Total reward: 10.891350121475245
6.083267696201801 seconds in game passed.
Action: tensor([[[0.0030, 0.5964],
         [0.0037, 0.3256],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.874257, steer=0.003263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891350121475245
6.10826769657433 seconds in game passed.
Action: tensor([[[0.0030, 0.5964],
         [0.0037, 0.3256],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.821443, steer=0.003290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891350121475245
6.133267696946859 seconds in game passed.
Action: tensor([[[0.0030, 0.5964],
         [0.0037, 0.3256],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.769799, steer=0.003317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891350121475245
+++++++++++++: 1.8865582793206217
6.158267697319388 seconds in game passed.
At 6.158267697319388 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6220],
         [0.0024, 0.3405],
         [0.0019, 0.2344],
         [0.0007, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.460901, steer=0.001937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865582793206217
Current reward: 0.5134782570971447
Current mitigation activation: 0
#############################
Total reward: 11.40482837857239
6.183267697691917 seconds in game passed.
Action: tensor([[[0.0020, 0.6220],
         [0.0024, 0.3405],
         [0.0019, 0.2344],
         [0.0007, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.436468, steer=0.002170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.40482837857239
6.2082676980644464 seconds in game passed.
Action: tensor([[[0.0020, 0.6220],
         [0.0024, 0.3405],
         [0.0019, 0.2344],
         [0.0007, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.386946, steer=0.002172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.40482837857239
6.2332676984369755 seconds in game passed.
Action: tensor([[[0.0020, 0.6220],
         [0.0024, 0.3405],
         [0.0019, 0.2344],
         [0.0007, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.363972, steer=0.002174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.40482837857239
+++++++++++++: 1.7242531401111614
6.2582676988095045 seconds in game passed.
At 6.2582676988095045 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.0693e-04,  6.3464e-01],
         [-4.2632e-05,  3.4330e-01],
         [-7.2219e-04,  2.3542e-01],
         [-1.8044e-03,  1.7981e-01]]])
agent 0 action: VehicleControl(throttle=0.352452, steer=-0.000193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7242531401111614
Current reward: 0.5125447778678981
Current mitigation activation: 0
#############################
Total reward: 11.917373156440288
6.2832676991820335 seconds in game passed.
Action: tensor([[[ 5.0693e-04,  6.3464e-01],
         [-4.2632e-05,  3.4330e-01],
         [-7.2219e-04,  2.3542e-01],
         [-1.8044e-03,  1.7981e-01]]])
agent 0 action: VehicleControl(throttle=0.339859, steer=0.000174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917373156440288
6.308267699554563 seconds in game passed.
Action: tensor([[[ 5.0693e-04,  6.3464e-01],
         [-4.2632e-05,  3.4330e-01],
         [-7.2219e-04,  2.3542e-01],
         [-1.8044e-03,  1.7981e-01]]])
agent 0 action: VehicleControl(throttle=0.327683, steer=0.000150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917373156440288
6.333267699927092 seconds in game passed.
Action: tensor([[[ 5.0693e-04,  6.3464e-01],
         [-4.2632e-05,  3.4330e-01],
         [-7.2219e-04,  2.3542e-01],
         [-1.8044e-03,  1.7981e-01]]])
agent 0 action: VehicleControl(throttle=0.315922, steer=0.000126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917373156440288
+++++++++++++: 1.5889227833393964
6.358267700299621 seconds in game passed.
At 6.358267700299621 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6534],
         [-0.0008,  0.3516],
         [-0.0019,  0.2411],
         [-0.0031,  0.1840]]])
agent 0 action: VehicleControl(throttle=0.304945, steer=-0.000169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5889227833393964
Current reward: 0.5075419648827179
Current mitigation activation: 0
#############################
Total reward: 12.424915121323005
6.38326770067215 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6534],
         [-0.0008,  0.3516],
         [-0.0019,  0.2411],
         [-0.0031,  0.1840]]])
agent 0 action: VehicleControl(throttle=0.294378, steer=-0.000157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424915121323005
6.408267701044679 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6534],
         [-0.0008,  0.3516],
         [-0.0019,  0.2411],
         [-0.0031,  0.1840]]])
agent 0 action: VehicleControl(throttle=0.283763, steer=-0.000190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424915121323005
6.433267701417208 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6534],
         [-0.0008,  0.3516],
         [-0.0019,  0.2411],
         [-0.0031,  0.1840]]])
agent 0 action: VehicleControl(throttle=0.273123, steer=-0.000222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424915121323005
+++++++++++++: 1.4777702284463026
6.458267701789737 seconds in game passed.
At 6.458267701789737 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.6667],
         [-0.0051,  0.3559],
         [-0.0065,  0.2424],
         [-0.0074,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.262365, steer=-0.004672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4777702284463026
Current reward: 0.4981222697229968
Current mitigation activation: 0
#############################
Total reward: 12.923037391046002
6.483267702162266 seconds in game passed.
Action: tensor([[[-0.0018,  0.6667],
         [-0.0051,  0.3559],
         [-0.0065,  0.2424],
         [-0.0074,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.251587, steer=-0.003989, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923037391046002
6.508267702534795 seconds in game passed.
Action: tensor([[[-0.0018,  0.6667],
         [-0.0051,  0.3559],
         [-0.0065,  0.2424],
         [-0.0074,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.240790, steer=-0.004040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923037391046002
6.533267702907324 seconds in game passed.
Action: tensor([[[-0.0018,  0.6667],
         [-0.0051,  0.3559],
         [-0.0065,  0.2424],
         [-0.0074,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.229975, steer=-0.004091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923037391046002
+++++++++++++: 1.3816434471953802
6.558267703279853 seconds in game passed.
At 6.558267703279853 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.2325e-04,  6.8508e-01],
         [-4.1634e-03,  3.6645e-01],
         [-5.9221e-03,  2.5068e-01],
         [-7.2214e-03,  1.9088e-01]]])
agent 0 action: VehicleControl(throttle=0.219226, steer=-0.002822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3816434471953802
Current reward: 0.4855968523672426
Current mitigation activation: 0
#############################
Total reward: 13.408634243413244
6.583267703652382 seconds in game passed.
Action: tensor([[[-3.2325e-04,  6.8508e-01],
         [-4.1634e-03,  3.6645e-01],
         [-5.9221e-03,  2.5068e-01],
         [-7.2214e-03,  1.9088e-01]]])
agent 0 action: VehicleControl(throttle=0.208458, steer=-0.003050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408634243413244
6.608267704024911 seconds in game passed.
Action: tensor([[[-3.2325e-04,  6.8508e-01],
         [-4.1634e-03,  3.6645e-01],
         [-5.9221e-03,  2.5068e-01],
         [-7.2214e-03,  1.9088e-01]]])
agent 0 action: VehicleControl(throttle=0.197672, steer=-0.003064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408634243413244
6.63326770439744 seconds in game passed.
Action: tensor([[[-3.2325e-04,  6.8508e-01],
         [-4.1634e-03,  3.6645e-01],
         [-5.9221e-03,  2.5068e-01],
         [-7.2214e-03,  1.9088e-01]]])
agent 0 action: VehicleControl(throttle=0.186867, steer=-0.003078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408634243413244
+++++++++++++: 1.2942831621831752
6.658267704769969 seconds in game passed.
At 6.658267704769969 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.8885e-04,  1.0000e+00],
         [-4.5933e-03,  1.0000e+00],
         [-5.7994e-03,  1.0000e+00],
         [-6.3687e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003002, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2942831621831752
Current reward: 0.4710847580949755
Current mitigation activation: 1
#############################
Total reward: 13.87971900150822
6.683267705142498 seconds in game passed.
Action: tensor([[[-3.8885e-04,  1.0000e+00],
         [-4.5933e-03,  1.0000e+00],
         [-5.7994e-03,  1.0000e+00],
         [-6.3687e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003008, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87971900150822
6.708267705515027 seconds in game passed.
Action: tensor([[[-3.8885e-04,  1.0000e+00],
         [-4.5933e-03,  1.0000e+00],
         [-5.7994e-03,  1.0000e+00],
         [-6.3687e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003002, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87971900150822
6.733267705887556 seconds in game passed.
Action: tensor([[[-3.8885e-04,  1.0000e+00],
         [-4.5933e-03,  1.0000e+00],
         [-5.7994e-03,  1.0000e+00],
         [-6.3687e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002996, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87971900150822
+++++++++++++: 1.2146002266842912
6.758267706260085 seconds in game passed.
At 6.758267706260085 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0027,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000577, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2146002266842912
Current reward: 0.45472693454972385
Current mitigation activation: 1
#############################
Total reward: 14.334445936057945
6.783267706632614 seconds in game passed.
Action: tensor([[[ 0.0027,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000936, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334445936057945
6.808267707005143 seconds in game passed.
Action: tensor([[[ 0.0027,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000899, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334445936057945
6.833267707377672 seconds in game passed.
Action: tensor([[[ 0.0027,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000862, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334445936057945
+++++++++++++: 1.1618189165919612
6.858267707750201 seconds in game passed.
At 6.858267707750201 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.4498e-03,  1.0000e+00],
         [ 7.0100e-04,  1.0000e+00],
         [-1.5905e-03,  1.0000e+00],
         [-1.6239e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005724, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1618189165919612
Current reward: 0.4319244177816791
Current mitigation activation: 1
#############################
Total reward: 14.766370353839624
6.88326770812273 seconds in game passed.
Action: tensor([[[ 8.4498e-03,  1.0000e+00],
         [ 7.0100e-04,  1.0000e+00],
         [-1.5905e-03,  1.0000e+00],
         [-1.6239e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004704, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766370353839624
6.908267708495259 seconds in game passed.
Action: tensor([[[ 8.4498e-03,  1.0000e+00],
         [ 7.0100e-04,  1.0000e+00],
         [-1.5905e-03,  1.0000e+00],
         [-1.6239e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004769, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766370353839624
6.933267708867788 seconds in game passed.
Action: tensor([[[ 8.4498e-03,  1.0000e+00],
         [ 7.0100e-04,  1.0000e+00],
         [-1.5905e-03,  1.0000e+00],
         [-1.6239e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004835, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766370353839624
+++++++++++++: 1.143229872361356
6.958267709240317 seconds in game passed.
At 6.958267709240317 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0143,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012648, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.143229872361356
Current reward: 0.40174664239617996
Current mitigation activation: 1
#############################
Total reward: 15.168116996235804
6.983267709612846 seconds in game passed.
Action: tensor([[[-0.0143,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009877, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168116996235804
7.008267709985375 seconds in game passed.
Action: tensor([[[-0.0143,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009999, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168116996235804
7.033267710357904 seconds in game passed.
Action: tensor([[[-0.0143,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010121, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168116996235804
+++++++++++++: 1.1451942243721973
7.0582677107304335 seconds in game passed.
At 7.0582677107304335 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0133,  1.0000],
         [-0.0069,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011477, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1451942243721973
Current reward: 0.3690305596738949
Current mitigation activation: 1
#############################
Total reward: 15.5371475559097
7.0832677111029625 seconds in game passed.
Action: tensor([[[-0.0133,  1.0000],
         [-0.0069,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011454, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.5371475559097
7.1082677114754915 seconds in game passed.
Action: tensor([[[-0.0133,  1.0000],
         [-0.0069,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011628, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.5371475559097
7.1332677118480206 seconds in game passed.
Action: tensor([[[-0.0133,  1.0000],
         [-0.0069,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011801, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.5371475559097
+++++++++++++: 1.1648924648466974
7.15826771222055 seconds in game passed.
At 7.15826771222055 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0168,  1.0000],
         [-0.0116,  1.0000],
         [-0.0087,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017061, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1648924648466974
Current reward: 0.3357654216627449
Current mitigation activation: 1
#############################
Total reward: 15.872912977572444
7.183267712593079 seconds in game passed.
Action: tensor([[[-0.0168,  1.0000],
         [-0.0116,  1.0000],
         [-0.0087,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016431, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872912977572444
7.208267712965608 seconds in game passed.
Action: tensor([[[-0.0168,  1.0000],
         [-0.0116,  1.0000],
         [-0.0087,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016643, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872912977572444
7.233267713338137 seconds in game passed.
Action: tensor([[[-0.0168,  1.0000],
         [-0.0116,  1.0000],
         [-0.0087,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016855, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872912977572444
+++++++++++++: 1.2047801902148805
7.258267713710666 seconds in game passed.
At 7.258267713710666 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0072,  1.0000],
         [-0.0126,  1.0000],
         [-0.0182,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011642, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2047801902148805
Current reward: 0.3027804906872513
Current mitigation activation: 1
#############################
Total reward: 16.175693468259695
7.283267714083195 seconds in game passed.
Action: tensor([[[-0.0072,  1.0000],
         [-0.0126,  1.0000],
         [-0.0182,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012665, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175693468259695
7.308267714455724 seconds in game passed.
Action: tensor([[[-0.0072,  1.0000],
         [-0.0126,  1.0000],
         [-0.0182,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012797, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175693468259695
7.333267714828253 seconds in game passed.
Action: tensor([[[-0.0072,  1.0000],
         [-0.0126,  1.0000],
         [-0.0182,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012929, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175693468259695
+++++++++++++: 1.2704366361323525
7.358267715200782 seconds in game passed.
At 7.358267715200782 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0081,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021072, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2704366361323525
Current reward: 0.27055554409297045
Current mitigation activation: 1
#############################
Total reward: 16.446249012352666
7.383267715573311 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0081,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015665, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446249012352666
7.40826771594584 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0081,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015888, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446249012352666
7.433267716318369 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0081,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016111, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446249012352666
+++++++++++++: 1.3689724747726553
7.458267716690898 seconds in game passed.
At 7.458267716690898 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9611e-03, 9.5602e-01],
         [1.1151e-03, 9.5436e-01],
         [2.7600e-04, 9.5376e-01],
         [6.2394e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003197, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3689724747726553
Current reward: 0.23970295598094382
Current mitigation activation: 0
#############################
Total reward: 16.68595196833361
7.483267717063427 seconds in game passed.
Action: tensor([[[1.9611e-03, 9.5602e-01],
         [1.1151e-03, 9.5436e-01],
         [2.7600e-04, 9.5376e-01],
         [6.2394e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000099, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.68595196833361
7.508267717435956 seconds in game passed.
Action: tensor([[[1.9611e-03, 9.5602e-01],
         [1.1151e-03, 9.5436e-01],
         [2.7600e-04, 9.5376e-01],
         [6.2394e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000165, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.68595196833361
7.533267717808485 seconds in game passed.
Action: tensor([[[1.9611e-03, 9.5602e-01],
         [1.1151e-03, 9.5436e-01],
         [2.7600e-04, 9.5376e-01],
         [6.2394e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000232, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.68595196833361
+++++++++++++: 1.5118491628323156
7.558267718181014 seconds in game passed.
At 7.558267718181014 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.1750e-04, 9.5593e-01],
         [1.1038e-03, 9.5429e-01],
         [9.5329e-04, 9.5371e-01],
         [1.4413e-03, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000442, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5118491628323156
Current reward: 0.21061057820082743
Current mitigation activation: 0
#############################
Total reward: 16.89656254653444
7.583267718553543 seconds in game passed.
Action: tensor([[[8.1750e-04, 9.5593e-01],
         [1.1038e-03, 9.5429e-01],
         [9.5329e-04, 9.5371e-01],
         [1.4413e-03, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000276, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89656254653444
7.608267718926072 seconds in game passed.
Action: tensor([[[8.1750e-04, 9.5593e-01],
         [1.1038e-03, 9.5429e-01],
         [9.5329e-04, 9.5371e-01],
         [1.4413e-03, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000230, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89656254653444
7.633267719298601 seconds in game passed.
Action: tensor([[[8.1750e-04, 9.5593e-01],
         [1.1038e-03, 9.5429e-01],
         [9.5329e-04, 9.5371e-01],
         [1.4413e-03, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000184, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89656254653444
+++++++++++++: 1.7408266477598204
7.65826771967113 seconds in game passed.
At 7.65826771967113 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.8637e-04, 9.5610e-01],
         [1.5236e-03, 9.5459e-01],
         [1.8290e-03, 9.5409e-01],
         [1.9292e-03, 9.5381e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000106, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7408266477598204
Current reward: 0.18262658478561294
Current mitigation activation: 0
#############################
Total reward: 17.079189131320053
7.683267720043659 seconds in game passed.
Action: tensor([[[7.8637e-04, 9.5610e-01],
         [1.5236e-03, 9.5459e-01],
         [1.8290e-03, 9.5409e-01],
         [1.9292e-03, 9.5381e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000113, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.079189131320053
7.708267720416188 seconds in game passed.
Action: tensor([[[7.8637e-04, 9.5610e-01],
         [1.5236e-03, 9.5459e-01],
         [1.8290e-03, 9.5409e-01],
         [1.9292e-03, 9.5381e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000161, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.079189131320053
7.733267720788717 seconds in game passed.
Action: tensor([[[7.8637e-04, 9.5610e-01],
         [1.5236e-03, 9.5459e-01],
         [1.8290e-03, 9.5409e-01],
         [1.9292e-03, 9.5381e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000209, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.079189131320053
+++++++++++++: 2.1605604840242134
7.758267721161246 seconds in game passed.
At 7.758267721161246 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.5453e-04, 9.5621e-01],
         [1.5235e-03, 9.5475e-01],
         [1.7856e-03, 9.5428e-01],
         [1.8688e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000212, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1605604840242134
Current reward: 0.15679457891115
Current mitigation activation: 0
#############################
Total reward: 17.235983710231203
7.783267721533775 seconds in game passed.
Action: tensor([[[7.5453e-04, 9.5621e-01],
         [1.5235e-03, 9.5475e-01],
         [1.7856e-03, 9.5428e-01],
         [1.8688e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000238, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235983710231203
7.808267721906304 seconds in game passed.
Action: tensor([[[7.5453e-04, 9.5621e-01],
         [1.5235e-03, 9.5475e-01],
         [1.7856e-03, 9.5428e-01],
         [1.8688e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000260, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235983710231203
7.833267722278833 seconds in game passed.
Action: tensor([[[7.5453e-04, 9.5621e-01],
         [1.5235e-03, 9.5475e-01],
         [1.7856e-03, 9.5428e-01],
         [1.8688e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000283, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235983710231203
+++++++++++++: 2.9701781439468675
7.858267722651362 seconds in game passed.
At 7.858267722651362 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.7950e-04, 9.5619e-01],
         [1.5332e-03, 9.5473e-01],
         [1.7979e-03, 9.5426e-01],
         [1.9052e-03, 9.5399e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000260, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9701781439468675
Current reward: 0.13270642991303824
Current mitigation activation: 0
#############################
Total reward: 17.368690140144242
7.8832677230238914 seconds in game passed.
Action: tensor([[[7.7950e-04, 9.5619e-01],
         [1.5332e-03, 9.5473e-01],
         [1.7979e-03, 9.5426e-01],
         [1.9052e-03, 9.5399e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000211, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.368690140144242
7.9082677233964205 seconds in game passed.
Action: tensor([[[7.7950e-04, 9.5619e-01],
         [1.5332e-03, 9.5473e-01],
         [1.7979e-03, 9.5426e-01],
         [1.9052e-03, 9.5399e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000166, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.368690140144242
7.9332677237689495 seconds in game passed.
Action: tensor([[[7.7950e-04, 9.5619e-01],
         [1.5332e-03, 9.5473e-01],
         [1.7979e-03, 9.5426e-01],
         [1.9052e-03, 9.5399e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000121, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.368690140144242
+++++++++++++: 4.7871402280861375
7.9582677241414785 seconds in game passed.
At 7.9582677241414785 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.0963e-04, 9.5606e-01],
         [1.5085e-03, 9.5455e-01],
         [1.7947e-03, 9.5406e-01],
         [1.9209e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000323, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.7871402280861375
Current reward: 0.11050764121998022
Current mitigation activation: 0
#############################
Total reward: 17.47919778136422
7.983267724514008 seconds in game passed.
Action: tensor([[[9.0963e-04, 9.5606e-01],
         [1.5085e-03, 9.5455e-01],
         [1.7947e-03, 9.5406e-01],
         [1.9209e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000449, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.47919778136422
8.008267724886537 seconds in game passed.
Action: tensor([[[9.0963e-04, 9.5606e-01],
         [1.5085e-03, 9.5455e-01],
         [1.7947e-03, 9.5406e-01],
         [1.9209e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000585, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.47919778136422
8.033267725259066 seconds in game passed.
Action: tensor([[[9.0963e-04, 9.5606e-01],
         [1.5085e-03, 9.5455e-01],
         [1.7947e-03, 9.5406e-01],
         [1.9209e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.004371, steer=0.000722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.47919778136422
+++++++++++++: 23.593785049888314
8.058267725631595 seconds in game passed.
At 8.058267725631595 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006675, steer=0.000790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03944431364064646
Current mitigation activation: 0
#############################
Total reward: 17.518642095004868
8.083267726004124 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006678, steer=0.000951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518642095004868
8.108267726376653 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006844, steer=0.001099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518642095004868
8.133267726749182 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006956, steer=0.001247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518642095004868
+++++++++++++: 2075.047616956986
8.15826772712171 seconds in game passed.
At 8.15826772712171 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.7757e-03,  9.5572e-01],
         [ 1.7442e-03,  9.5380e-01],
         [-1.8034e-03,  9.5303e-01],
         [-3.8474e-04,  9.5248e-01]]])
agent 0 action: VehicleControl(throttle=0.034239, steer=0.007262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0004704448760831186
Current mitigation activation: 0
#############################
Total reward: 17.51911253988095
8.18326772749424 seconds in game passed.
Action: tensor([[[ 9.7757e-03,  9.5572e-01],
         [ 1.7442e-03,  9.5380e-01],
         [-1.8034e-03,  9.5303e-01],
         [-3.8474e-04,  9.5248e-01]]])
agent 0 action: VehicleControl(throttle=0.008656, steer=0.006563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51911253988095
8.208267727866769 seconds in game passed.
Action: tensor([[[ 9.7757e-03,  9.5572e-01],
         [ 1.7442e-03,  9.5380e-01],
         [-1.8034e-03,  9.5303e-01],
         [-3.8474e-04,  9.5248e-01]]])
agent 0 action: VehicleControl(throttle=0.011886, steer=0.006824, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51911253988095
8.233267728239298 seconds in game passed.
Action: tensor([[[ 9.7757e-03,  9.5572e-01],
         [ 1.7442e-03,  9.5380e-01],
         [-1.8034e-03,  9.5303e-01],
         [-3.8474e-04,  9.5248e-01]]])
agent 0 action: VehicleControl(throttle=0.012659, steer=0.007084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51911253988095
+++++++++++++: 165.93280761474526
8.258267728611827 seconds in game passed.
At 8.258267728611827 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0252,  0.9550],
         [ 0.0024,  0.9520],
         [-0.0084,  0.9502],
         [-0.0032,  0.9397]]])
agent 0 action: VehicleControl(throttle=0.068548, steer=0.017408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006176163153804912
Current mitigation activation: 0
#############################
Total reward: 17.525288703034754
8.283267728984356 seconds in game passed.
Action: tensor([[[ 0.0252,  0.9550],
         [ 0.0024,  0.9520],
         [-0.0084,  0.9502],
         [-0.0032,  0.9397]]])
agent 0 action: VehicleControl(throttle=0.064038, steer=0.016048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.525288703034754
8.308267729356885 seconds in game passed.
Action: tensor([[[ 0.0252,  0.9550],
         [ 0.0024,  0.9520],
         [-0.0084,  0.9502],
         [-0.0032,  0.9397]]])
agent 0 action: VehicleControl(throttle=0.065309, steer=0.016357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.525288703034754
8.333267729729414 seconds in game passed.
Action: tensor([[[ 0.0252,  0.9550],
         [ 0.0024,  0.9520],
         [-0.0084,  0.9502],
         [-0.0032,  0.9397]]])
agent 0 action: VehicleControl(throttle=0.066491, steer=0.016666, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.525288703034754
+++++++++++++: 207.2618382851674
8.358267730101943 seconds in game passed.
At 8.358267730101943 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4846e-02,  9.5366e-01],
         [ 1.8528e-04,  9.4743e-01],
         [-1.3290e-02,  9.1443e-01],
         [-8.9680e-03,  6.0263e-01]]])
agent 0 action: VehicleControl(throttle=0.077550, steer=0.014963, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00519901901365502
Current mitigation activation: 0
#############################
Total reward: 17.53048772204841
8.383267730474472 seconds in game passed.
Action: tensor([[[ 2.4846e-02,  9.5366e-01],
         [ 1.8528e-04,  9.4743e-01],
         [-1.3290e-02,  9.1443e-01],
         [-8.9680e-03,  6.0263e-01]]])
agent 0 action: VehicleControl(throttle=0.077667, steer=0.015177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53048772204841
8.408267730847001 seconds in game passed.
Action: tensor([[[ 2.4846e-02,  9.5366e-01],
         [ 1.8528e-04,  9.4743e-01],
         [-1.3290e-02,  9.1443e-01],
         [-8.9680e-03,  6.0263e-01]]])
agent 0 action: VehicleControl(throttle=0.078788, steer=0.015118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53048772204841
8.43326773121953 seconds in game passed.
Action: tensor([[[ 2.4846e-02,  9.5366e-01],
         [ 1.8528e-04,  9.4743e-01],
         [-1.3290e-02,  9.1443e-01],
         [-8.9680e-03,  6.0263e-01]]])
agent 0 action: VehicleControl(throttle=0.079860, steer=0.015058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53048772204841
+++++++++++++: 244.78862448383757
8.45826773159206 seconds in game passed.
At 8.45826773159206 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0107,  0.9528],
         [-0.0035,  0.9423],
         [-0.0106,  0.8778],
         [-0.0053,  0.6056]]])
agent 0 action: VehicleControl(throttle=0.055372, steer=0.003969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004632151237156933
Current mitigation activation: 0
#############################
Total reward: 17.535119873285566
8.483267731964588 seconds in game passed.
Action: tensor([[[ 0.0107,  0.9528],
         [-0.0035,  0.9423],
         [-0.0106,  0.8778],
         [-0.0053,  0.6056]]])
agent 0 action: VehicleControl(throttle=0.058797, steer=0.005848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.535119873285566
8.508267732337117 seconds in game passed.
Action: tensor([[[ 0.0107,  0.9528],
         [-0.0035,  0.9423],
         [-0.0106,  0.8778],
         [-0.0053,  0.6056]]])
agent 0 action: VehicleControl(throttle=0.059504, steer=0.005874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.535119873285566
8.533267732709646 seconds in game passed.
Action: tensor([[[ 0.0107,  0.9528],
         [-0.0035,  0.9423],
         [-0.0106,  0.8778],
         [-0.0053,  0.6056]]])
agent 0 action: VehicleControl(throttle=0.060218, steer=0.005900, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.535119873285566
+++++++++++++: 273.4701856419788
8.558267733082175 seconds in game passed.
At 8.558267733082175 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0310,  0.9513],
         [-0.0186,  0.9090],
         [-0.0126,  0.7397],
         [-0.0085,  0.5423]]])
agent 0 action: VehicleControl(throttle=0.186969, steer=-0.029510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004366693463057005
Current mitigation activation: 0
#############################
Total reward: 17.539486566748625
8.583267733454704 seconds in game passed.
Action: tensor([[[-0.0310,  0.9513],
         [-0.0186,  0.9090],
         [-0.0126,  0.7397],
         [-0.0085,  0.5423]]])
agent 0 action: VehicleControl(throttle=0.175720, steer=-0.023995, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.539486566748625
8.608267733827233 seconds in game passed.
Action: tensor([[[-0.0310,  0.9513],
         [-0.0186,  0.9090],
         [-0.0126,  0.7397],
         [-0.0085,  0.5423]]])
agent 0 action: VehicleControl(throttle=0.177786, steer=-0.024327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.539486566748625
8.633267734199762 seconds in game passed.
Action: tensor([[[-0.0310,  0.9513],
         [-0.0186,  0.9090],
         [-0.0126,  0.7397],
         [-0.0085,  0.5423]]])
agent 0 action: VehicleControl(throttle=0.179720, steer=-0.024658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.539486566748625
+++++++++++++: 296.920691391838
8.658267734572291 seconds in game passed.
At 8.658267734572291 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0378,  0.9497],
         [-0.0166,  0.8238],
         [-0.0072,  0.6118],
         [-0.0048,  0.4907]]])
agent 0 action: VehicleControl(throttle=0.620194, steer=-0.026869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004234982206638061
Current mitigation activation: 0
#############################
Total reward: 17.54372154895526
8.68326773494482 seconds in game passed.
Action: tensor([[[-0.0378,  0.9497],
         [-0.0166,  0.8238],
         [-0.0072,  0.6118],
         [-0.0048,  0.4907]]])
agent 0 action: VehicleControl(throttle=0.580295, steer=-0.026913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54372154895526
8.70826773531735 seconds in game passed.
Action: tensor([[[-0.0378,  0.9497],
         [-0.0166,  0.8238],
         [-0.0072,  0.6118],
         [-0.0048,  0.4907]]])
agent 0 action: VehicleControl(throttle=0.586753, steer=-0.027266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54372154895526
8.733267735689878 seconds in game passed.
Action: tensor([[[-0.0378,  0.9497],
         [-0.0166,  0.8238],
         [-0.0072,  0.6118],
         [-0.0048,  0.4907]]])
agent 0 action: VehicleControl(throttle=0.592913, steer=-0.027620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54372154895526
+++++++++++++: 289.16018541273513
8.758267736062407 seconds in game passed.
At 8.758267736062407 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0334,  0.9491],
         [-0.0105,  0.7992],
         [-0.0056,  0.5854],
         [-0.0068,  0.4786]]])
agent 0 action: VehicleControl(throttle=0.742994, steer=-0.021120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004578704228853626
Current mitigation activation: 0
#############################
Total reward: 17.548300253184117
8.783267736434937 seconds in game passed.
Action: tensor([[[-0.0334,  0.9491],
         [-0.0105,  0.7992],
         [-0.0056,  0.5854],
         [-0.0068,  0.4786]]])
agent 0 action: VehicleControl(throttle=0.734313, steer=-0.022533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.548300253184117
8.808267736807466 seconds in game passed.
Action: tensor([[[-0.0334,  0.9491],
         [-0.0105,  0.7992],
         [-0.0056,  0.5854],
         [-0.0068,  0.4786]]])
agent 0 action: VehicleControl(throttle=0.740149, steer=-0.022816, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.548300253184117
8.833267737179995 seconds in game passed.
Action: tensor([[[-0.0334,  0.9491],
         [-0.0105,  0.7992],
         [-0.0056,  0.5854],
         [-0.0068,  0.4786]]])
agent 0 action: VehicleControl(throttle=0.744630, steer=-0.023099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.548300253184117
+++++++++++++: 201.24125799149328
8.858267737552524 seconds in game passed.
At 8.858267737552524 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.4747e-02,  9.4331e-01],
         [-4.8600e-03,  6.0792e-01],
         [-1.8987e-03,  4.7369e-01],
         [-3.7701e-04,  4.1838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006920294313236305
Current mitigation activation: 0
#############################
Total reward: 17.555220547497353
8.883267737925053 seconds in game passed.
Action: tensor([[[-2.4747e-02,  9.4331e-01],
         [-4.8600e-03,  6.0792e-01],
         [-1.8987e-03,  4.7369e-01],
         [-3.7701e-04,  4.1838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.555220547497353
8.908267738297582 seconds in game passed.
Action: tensor([[[-2.4747e-02,  9.4331e-01],
         [-4.8600e-03,  6.0792e-01],
         [-1.8987e-03,  4.7369e-01],
         [-3.7701e-04,  4.1838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.555220547497353
8.93326773867011 seconds in game passed.
Action: tensor([[[-2.4747e-02,  9.4331e-01],
         [-4.8600e-03,  6.0792e-01],
         [-1.8987e-03,  4.7369e-01],
         [-3.7701e-04,  4.1838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.555220547497353
+++++++++++++: 40.17692356053657
8.95826773904264 seconds in game passed.
At 8.95826773904264 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2563e-02,  9.3246e-01],
         [-5.3347e-04,  5.5925e-01],
         [ 1.4538e-04,  4.3632e-01],
         [ 1.3230e-03,  3.7943e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03634511068163429
Current mitigation activation: 0
#############################
Total reward: 17.591565658178986
8.983267739415169 seconds in game passed.
Action: tensor([[[-1.2563e-02,  9.3246e-01],
         [-5.3347e-04,  5.5925e-01],
         [ 1.4538e-04,  4.3632e-01],
         [ 1.3230e-03,  3.7943e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.591565658178986
9.008267739787698 seconds in game passed.
Action: tensor([[[-1.2563e-02,  9.3246e-01],
         [-5.3347e-04,  5.5925e-01],
         [ 1.4538e-04,  4.3632e-01],
         [ 1.3230e-03,  3.7943e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.591565658178986
9.033267740160227 seconds in game passed.
Action: tensor([[[-1.2563e-02,  9.3246e-01],
         [-5.3347e-04,  5.5925e-01],
         [ 1.4538e-04,  4.3632e-01],
         [ 1.3230e-03,  3.7943e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.591565658178986
+++++++++++++: 18.09181422124442
9.058267740532756 seconds in game passed.
At 9.058267740532756 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0111,  0.8869],
         [-0.0034,  0.4990],
         [-0.0053,  0.3626],
         [-0.0056,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.08426085080772952
Current mitigation activation: 0
#############################
Total reward: 17.675826508986717
9.083267740905285 seconds in game passed.
Action: tensor([[[-0.0111,  0.8869],
         [-0.0034,  0.4990],
         [-0.0053,  0.3626],
         [-0.0056,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008878, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.675826508986717
9.108267741277814 seconds in game passed.
Action: tensor([[[-0.0111,  0.8869],
         [-0.0034,  0.4990],
         [-0.0053,  0.3626],
         [-0.0056,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.675826508986717
9.133267741650343 seconds in game passed.
Action: tensor([[[-0.0111,  0.8869],
         [-0.0034,  0.4990],
         [-0.0053,  0.3626],
         [-0.0056,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.675826508986717
+++++++++++++: 10.83859806357412
9.158267742022872 seconds in game passed.
At 9.158267742022872 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0016,  0.8353],
         [-0.0037,  0.4716],
         [-0.0067,  0.3355],
         [-0.0077,  0.2622]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.14609992663148813
Current mitigation activation: 0
#############################
Total reward: 17.821926435618206
9.183267742395401 seconds in game passed.
Action: tensor([[[ 0.0016,  0.8353],
         [-0.0037,  0.4716],
         [-0.0067,  0.3355],
         [-0.0077,  0.2622]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.821926435618206
9.20826774276793 seconds in game passed.
Action: tensor([[[ 0.0016,  0.8353],
         [-0.0037,  0.4716],
         [-0.0067,  0.3355],
         [-0.0077,  0.2622]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.821926435618206
9.233267743140459 seconds in game passed.
Action: tensor([[[ 0.0016,  0.8353],
         [-0.0037,  0.4716],
         [-0.0067,  0.3355],
         [-0.0077,  0.2622]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.821926435618206
+++++++++++++: 7.514325711289482
9.258267743512988 seconds in game passed.
At 9.258267743512988 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0047,  0.8135],
         [-0.0026,  0.4577],
         [-0.0057,  0.3237],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.514325711289482
Current reward: 0.17538873396485688
Current mitigation activation: 0
#############################
Total reward: 17.997315169583064
9.283267743885517 seconds in game passed.
Action: tensor([[[ 0.0047,  0.8135],
         [-0.0026,  0.4577],
         [-0.0057,  0.3237],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.997315169583064
9.308267744258046 seconds in game passed.
Action: tensor([[[ 0.0047,  0.8135],
         [-0.0026,  0.4577],
         [-0.0057,  0.3237],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.997315169583064
9.333267744630575 seconds in game passed.
Action: tensor([[[ 0.0047,  0.8135],
         [-0.0026,  0.4577],
         [-0.0057,  0.3237],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.997315169583064
+++++++++++++: 6.018253288891946
9.358267745003104 seconds in game passed.
At 9.358267745003104 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0075,  0.8035],
         [-0.0009,  0.4497],
         [-0.0039,  0.3130],
         [-0.0057,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.018253288891946
Current reward: 0.19254366341486479
Current mitigation activation: 0
#############################
Total reward: 18.189858832997928
9.383267745375633 seconds in game passed.
Action: tensor([[[ 0.0075,  0.8035],
         [-0.0009,  0.4497],
         [-0.0039,  0.3130],
         [-0.0057,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.189858832997928
9.408267745748162 seconds in game passed.
Action: tensor([[[ 0.0075,  0.8035],
         [-0.0009,  0.4497],
         [-0.0039,  0.3130],
         [-0.0057,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.189858832997928
9.433267746120691 seconds in game passed.
Action: tensor([[[ 0.0075,  0.8035],
         [-0.0009,  0.4497],
         [-0.0039,  0.3130],
         [-0.0057,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.189858832997928
+++++++++++++: 5.132667542171766
9.45826774649322 seconds in game passed.
At 9.45826774649322 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.7664],
         [-0.0013,  0.4299],
         [-0.0038,  0.2992],
         [-0.0055,  0.2296]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.132667542171766
Current reward: 0.20808864789711246
Current mitigation activation: 0
#############################
Total reward: 18.39794748089504
9.48326774686575 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7664],
         [-0.0013,  0.4299],
         [-0.0038,  0.2992],
         [-0.0055,  0.2296]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.39794748089504
9.508267747238278 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7664],
         [-0.0013,  0.4299],
         [-0.0038,  0.2992],
         [-0.0055,  0.2296]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.39794748089504
9.533267747610807 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7664],
         [-0.0013,  0.4299],
         [-0.0038,  0.2992],
         [-0.0055,  0.2296]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.39794748089504
+++++++++++++: 4.513143259231385
9.558267747983336 seconds in game passed.
At 9.558267747983336 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0053,  0.7560],
         [-0.0014,  0.4242],
         [-0.0037,  0.2952],
         [-0.0053,  0.2270]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.513143259231385
Current reward: 0.22277038740154032
Current mitigation activation: 0
#############################
Total reward: 18.62071786829658
9.583267748355865 seconds in game passed.
Action: tensor([[[ 0.0053,  0.7560],
         [-0.0014,  0.4242],
         [-0.0037,  0.2952],
         [-0.0053,  0.2270]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.62071786829658
9.608267748728395 seconds in game passed.
Action: tensor([[[ 0.0053,  0.7560],
         [-0.0014,  0.4242],
         [-0.0037,  0.2952],
         [-0.0053,  0.2270]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.62071786829658
9.633267749100924 seconds in game passed.
Action: tensor([[[ 0.0053,  0.7560],
         [-0.0014,  0.4242],
         [-0.0037,  0.2952],
         [-0.0053,  0.2270]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.62071786829658
+++++++++++++: 4.040806463348827
9.658267749473453 seconds in game passed.
At 9.658267749473453 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1212e-02,  7.5153e-01],
         [ 2.6926e-04,  4.1775e-01],
         [-1.3580e-03,  2.9102e-01],
         [-2.1704e-03,  2.2437e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.040806463348827
Current reward: 0.2368756890346177
Current mitigation activation: 0
#############################
Total reward: 18.8575935573312
9.683267749845982 seconds in game passed.
Action: tensor([[[ 1.1212e-02,  7.5153e-01],
         [ 2.6926e-04,  4.1775e-01],
         [-1.3580e-03,  2.9102e-01],
         [-2.1704e-03,  2.2437e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.8575935573312
9.70826775021851 seconds in game passed.
Action: tensor([[[ 1.1212e-02,  7.5153e-01],
         [ 2.6926e-04,  4.1775e-01],
         [-1.3580e-03,  2.9102e-01],
         [-2.1704e-03,  2.2437e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.8575935573312
9.73326775059104 seconds in game passed.
Action: tensor([[[ 1.1212e-02,  7.5153e-01],
         [ 2.6926e-04,  4.1775e-01],
         [-1.3580e-03,  2.9102e-01],
         [-2.1704e-03,  2.2437e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002067, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.8575935573312
+++++++++++++: 3.6619488904268205
9.758267750963569 seconds in game passed.
At 9.758267750963569 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5010e-02,  7.4748e-01],
         [ 1.1768e-03,  4.1869e-01],
         [-1.7186e-04,  2.9293e-01],
         [-5.7648e-04,  2.2625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6619488904268205
Current reward: 0.2505142953463566
Current mitigation activation: 0
#############################
Total reward: 19.108107852677556
9.783267751336098 seconds in game passed.
Action: tensor([[[ 1.5010e-02,  7.4748e-01],
         [ 1.1768e-03,  4.1869e-01],
         [-1.7186e-04,  2.9293e-01],
         [-5.7648e-04,  2.2625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.108107852677556
9.808267751708627 seconds in game passed.
Action: tensor([[[ 1.5010e-02,  7.4748e-01],
         [ 1.1768e-03,  4.1869e-01],
         [-1.7186e-04,  2.9293e-01],
         [-5.7648e-04,  2.2625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.108107852677556
9.833267752081156 seconds in game passed.
Action: tensor([[[ 1.5010e-02,  7.4748e-01],
         [ 1.1768e-03,  4.1869e-01],
         [-1.7186e-04,  2.9293e-01],
         [-5.7648e-04,  2.2625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.108107852677556
+++++++++++++: 3.3473863829797854
9.858267752453685 seconds in game passed.
At 9.858267752453685 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3871e-02, 7.4590e-01],
         [2.2296e-03, 4.1968e-01],
         [9.0168e-04, 2.9285e-01],
         [4.7830e-04, 2.2536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3473863829797854
Current reward: 0.26373290084743295
Current mitigation activation: 0
#############################
Total reward: 19.37184075352499
9.883267752826214 seconds in game passed.
Action: tensor([[[1.3871e-02, 7.4590e-01],
         [2.2296e-03, 4.1968e-01],
         [9.0168e-04, 2.9285e-01],
         [4.7830e-04, 2.2536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.37184075352499
9.908267753198743 seconds in game passed.
Action: tensor([[[1.3871e-02, 7.4590e-01],
         [2.2296e-03, 4.1968e-01],
         [9.0168e-04, 2.9285e-01],
         [4.7830e-04, 2.2536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.37184075352499
9.933267753571272 seconds in game passed.
Action: tensor([[[1.3871e-02, 7.4590e-01],
         [2.2296e-03, 4.1968e-01],
         [9.0168e-04, 2.9285e-01],
         [4.7830e-04, 2.2536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.37184075352499
+++++++++++++: 3.1966663586148996
9.958267753943801 seconds in game passed.
At 9.958267753943801 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0292e-02, 7.0538e-01],
         [1.4450e-03, 3.9522e-01],
         [5.7063e-04, 2.7596e-01],
         [1.3993e-04, 2.1377e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1966663586148996
Current reward: 0.27205358881220437
Current mitigation activation: 0
#############################
Total reward: 19.643894342337195
9.98326775431633 seconds in game passed.
Action: tensor([[[1.0292e-02, 7.0538e-01],
         [1.4450e-03, 3.9522e-01],
         [5.7063e-04, 2.7596e-01],
         [1.3993e-04, 2.1377e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.643894342337195
10.008267754688859 seconds in game passed.
Action: tensor([[[1.0292e-02, 7.0538e-01],
         [1.4450e-03, 3.9522e-01],
         [5.7063e-04, 2.7596e-01],
         [1.3993e-04, 2.1377e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.643894342337195
10.033267755061388 seconds in game passed.
Action: tensor([[[1.0292e-02, 7.0538e-01],
         [1.4450e-03, 3.9522e-01],
         [5.7063e-04, 2.7596e-01],
         [1.3993e-04, 2.1377e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.643894342337195
+++++++++++++: 3.231443840549386
10.058267755433917 seconds in game passed.
At 10.058267755433917 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.8446e-03, 6.7730e-01],
         [1.4033e-03, 3.7619e-01],
         [8.9638e-04, 2.6312e-01],
         [4.7792e-04, 2.0540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.231443840549386
Current reward: 0.2733791318123151
Current mitigation activation: 0
#############################
Total reward: 19.91727347414951
10.083267755806446 seconds in game passed.
Action: tensor([[[6.8446e-03, 6.7730e-01],
         [1.4033e-03, 3.7619e-01],
         [8.9638e-04, 2.6312e-01],
         [4.7792e-04, 2.0540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004239, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.91727347414951
10.108267756178975 seconds in game passed.
Action: tensor([[[6.8446e-03, 6.7730e-01],
         [1.4033e-03, 3.7619e-01],
         [8.9638e-04, 2.6312e-01],
         [4.7792e-04, 2.0540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.91727347414951
10.133267756551504 seconds in game passed.
Action: tensor([[[6.8446e-03, 6.7730e-01],
         [1.4033e-03, 3.7619e-01],
         [8.9638e-04, 2.6312e-01],
         [4.7792e-04, 2.0540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.91727347414951
+++++++++++++: 3.2672926014687316
10.158267756924033 seconds in game passed.
At 10.158267756924033 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.7382e-03, 6.5869e-01],
         [1.4105e-03, 3.6451e-01],
         [9.9526e-04, 2.5431e-01],
         [2.9355e-04, 1.9852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2672926014687316
Current reward: 0.27468382139774095
Current mitigation activation: 0
#############################
Total reward: 20.19195729554725
10.183267757296562 seconds in game passed.
Action: tensor([[[3.7382e-03, 6.5869e-01],
         [1.4105e-03, 3.6451e-01],
         [9.9526e-04, 2.5431e-01],
         [2.9355e-04, 1.9852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.19195729554725
10.208267757669091 seconds in game passed.
Action: tensor([[[3.7382e-03, 6.5869e-01],
         [1.4105e-03, 3.6451e-01],
         [9.9526e-04, 2.5431e-01],
         [2.9355e-04, 1.9852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003560, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.19195729554725
10.23326775804162 seconds in game passed.
Action: tensor([[[3.7382e-03, 6.5869e-01],
         [1.4105e-03, 3.6451e-01],
         [9.9526e-04, 2.5431e-01],
         [2.9355e-04, 1.9852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.19195729554725
+++++++++++++: 3.303492500097517
10.25826775841415 seconds in game passed.
At 10.25826775841415 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.0793e-03, 6.5823e-01],
         [1.1339e-03, 3.6400e-01],
         [8.4286e-04, 2.5365e-01],
         [2.6903e-04, 1.9766e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.303492500097517
Current reward: 0.27599530308129094
Current mitigation activation: 0
#############################
Total reward: 20.467952598628543
10.283267758786678 seconds in game passed.
Action: tensor([[[3.0793e-03, 6.5823e-01],
         [1.1339e-03, 3.6400e-01],
         [8.4286e-04, 2.5365e-01],
         [2.6903e-04, 1.9766e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.467952598628543
10.308267759159207 seconds in game passed.
Action: tensor([[[3.0793e-03, 6.5823e-01],
         [1.1339e-03, 3.6400e-01],
         [8.4286e-04, 2.5365e-01],
         [2.6903e-04, 1.9766e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.467952598628543
10.333267759531736 seconds in game passed.
Action: tensor([[[3.0793e-03, 6.5823e-01],
         [1.1339e-03, 3.6400e-01],
         [8.4286e-04, 2.5365e-01],
         [2.6903e-04, 1.9766e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.467952598628543
+++++++++++++: 3.3403319095412463
10.358267759904265 seconds in game passed.
At 10.358267759904265 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0649e-03,  6.4647e-01],
         [ 6.1355e-04,  3.5923e-01],
         [ 2.2674e-04,  2.5155e-01],
         [-3.9759e-04,  1.9630e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3403319095412463
Current reward: 0.2773025926748156
Current mitigation activation: 0
#############################
Total reward: 20.745255191303357
10.383267760276794 seconds in game passed.
Action: tensor([[[ 3.0649e-03,  6.4647e-01],
         [ 6.1355e-04,  3.5923e-01],
         [ 2.2674e-04,  2.5155e-01],
         [-3.9759e-04,  1.9630e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.745255191303357
10.408267760649323 seconds in game passed.
Action: tensor([[[ 3.0649e-03,  6.4647e-01],
         [ 6.1355e-04,  3.5923e-01],
         [ 2.2674e-04,  2.5155e-01],
         [-3.9759e-04,  1.9630e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.745255191303357
10.433267761021852 seconds in game passed.
Action: tensor([[[ 3.0649e-03,  6.4647e-01],
         [ 6.1355e-04,  3.5923e-01],
         [ 2.2674e-04,  2.5155e-01],
         [-3.9759e-04,  1.9630e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.745255191303357
+++++++++++++: 3.2614592781382705
10.458267761394382 seconds in game passed.
At 10.458267761394382 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0208e-03,  6.4058e-01],
         [ 2.2855e-04,  3.5516e-01],
         [-2.7005e-04,  2.4796e-01],
         [-9.3500e-04,  1.9313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2614592781382705
Current reward: 0.282801144121874
Current mitigation activation: 0
#############################
Total reward: 21.02805633542523
10.48326776176691 seconds in game passed.
Action: tensor([[[ 2.0208e-03,  6.4058e-01],
         [ 2.2855e-04,  3.5516e-01],
         [-2.7005e-04,  2.4796e-01],
         [-9.3500e-04,  1.9313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.02805633542523
10.50826776213944 seconds in game passed.
Action: tensor([[[ 2.0208e-03,  6.4058e-01],
         [ 2.2855e-04,  3.5516e-01],
         [-2.7005e-04,  2.4796e-01],
         [-9.3500e-04,  1.9313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.02805633542523
10.533267762511969 seconds in game passed.
Action: tensor([[[ 2.0208e-03,  6.4058e-01],
         [ 2.2855e-04,  3.5516e-01],
         [-2.7005e-04,  2.4796e-01],
         [-9.3500e-04,  1.9313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.02805633542523
+++++++++++++: 2.9850352523710297
10.558267762884498 seconds in game passed.
At 10.558267762884498 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.3349e-03,  6.4587e-01],
         [ 5.2211e-04,  3.5602e-01],
         [ 4.2543e-06,  2.4671e-01],
         [-6.7689e-04,  1.9100e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9850352523710297
Current reward: 0.29651568337051065
Current mitigation activation: 0
#############################
Total reward: 21.32457201879574
10.583267763257027 seconds in game passed.
Action: tensor([[[ 2.3349e-03,  6.4587e-01],
         [ 5.2211e-04,  3.5602e-01],
         [ 4.2543e-06,  2.4671e-01],
         [-6.7689e-04,  1.9100e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.32457201879574
10.608267763629556 seconds in game passed.
Action: tensor([[[ 2.3349e-03,  6.4587e-01],
         [ 5.2211e-04,  3.5602e-01],
         [ 4.2543e-06,  2.4671e-01],
         [-6.7689e-04,  1.9100e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.32457201879574
10.633267764002085 seconds in game passed.
Action: tensor([[[ 2.3349e-03,  6.4587e-01],
         [ 5.2211e-04,  3.5602e-01],
         [ 4.2543e-06,  2.4671e-01],
         [-6.7689e-04,  1.9100e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.32457201879574
+++++++++++++: 2.7676395725932887
10.658267764374614 seconds in game passed.
At 10.658267764374614 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.3872e-05,  6.6042e-01],
         [-1.3795e-03,  3.6220e-01],
         [-2.0301e-03,  2.5025e-01],
         [-2.7655e-03,  1.9336e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7676395725932887
Current reward: 0.3086368813706165
Current mitigation activation: 0
#############################
Total reward: 21.63320890016636
10.683267764747143 seconds in game passed.
Action: tensor([[[-2.3872e-05,  6.6042e-01],
         [-1.3795e-03,  3.6220e-01],
         [-2.0301e-03,  2.5025e-01],
         [-2.7655e-03,  1.9336e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63320890016636
10.708267765119672 seconds in game passed.
Action: tensor([[[-2.3872e-05,  6.6042e-01],
         [-1.3795e-03,  3.6220e-01],
         [-2.0301e-03,  2.5025e-01],
         [-2.7655e-03,  1.9336e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63320890016636
10.7332677654922 seconds in game passed.
Action: tensor([[[-2.3872e-05,  6.6042e-01],
         [-1.3795e-03,  3.6220e-01],
         [-2.0301e-03,  2.5025e-01],
         [-2.7655e-03,  1.9336e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63320890016636
+++++++++++++: 2.5869354234596758
10.75826776586473 seconds in game passed.
At 10.75826776586473 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0015,  0.6701],
         [-0.0013,  0.3649],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000984, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5869354234596758
Current reward: 0.3195533740672092
Current mitigation activation: 0
#############################
Total reward: 21.952762274233567
10.783267766237259 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6701],
         [-0.0013,  0.3649],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.952762274233567
10.808267766609788 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6701],
         [-0.0013,  0.3649],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.952762274233567
10.833267766982317 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6701],
         [-0.0013,  0.3649],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.952762274233567
+++++++++++++: 2.4284465086159575
10.858267767354846 seconds in game passed.
At 10.858267767354846 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0582e-04,  6.7474e-01],
         [-1.7798e-03,  3.6497e-01],
         [-2.6677e-03,  2.5049e-01],
         [-3.5228e-03,  1.9295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4284465086159575
Current reward: 0.32967082117728636
Current mitigation activation: 0
#############################
Total reward: 22.282433095410855
10.883267767727375 seconds in game passed.
Action: tensor([[[ 2.0582e-04,  6.7474e-01],
         [-1.7798e-03,  3.6497e-01],
         [-2.6677e-03,  2.5049e-01],
         [-3.5228e-03,  1.9295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.282433095410855
10.908267768099904 seconds in game passed.
Action: tensor([[[ 2.0582e-04,  6.7474e-01],
         [-1.7798e-03,  3.6497e-01],
         [-2.6677e-03,  2.5049e-01],
         [-3.5228e-03,  1.9295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.282433095410855
10.933267768472433 seconds in game passed.
Action: tensor([[[ 2.0582e-04,  6.7474e-01],
         [-1.7798e-03,  3.6497e-01],
         [-2.6677e-03,  2.5049e-01],
         [-3.5228e-03,  1.9295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.282433095410855
+++++++++++++: 2.285152725064967
10.958267768844962 seconds in game passed.
At 10.958267768844962 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6829],
         [-0.0024,  0.3677],
         [-0.0033,  0.2532],
         [-0.0045,  0.1952]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.285152725064967
Current reward: 0.33918641875670186
Current mitigation activation: 0
#############################
Total reward: 22.621619514167556
10.983267769217491 seconds in game passed.
Action: tensor([[[-0.0011,  0.6829],
         [-0.0024,  0.3677],
         [-0.0033,  0.2532],
         [-0.0045,  0.1952]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.621619514167556
11.00826776959002 seconds in game passed.
Action: tensor([[[-0.0011,  0.6829],
         [-0.0024,  0.3677],
         [-0.0033,  0.2532],
         [-0.0045,  0.1952]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.621619514167556
11.03326776996255 seconds in game passed.
Action: tensor([[[-0.0011,  0.6829],
         [-0.0024,  0.3677],
         [-0.0033,  0.2532],
         [-0.0045,  0.1952]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001543, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.621619514167556
+++++++++++++: 2.1530650327396774
11.058267770335078 seconds in game passed.
At 11.058267770335078 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6801],
         [-0.0037,  0.3704],
         [-0.0045,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1530650327396774
Current reward: 0.34820992077377344
Current mitigation activation: 0
#############################
Total reward: 22.969829434941328
11.083267770707607 seconds in game passed.
Action: tensor([[[-0.0012,  0.6801],
         [-0.0037,  0.3704],
         [-0.0045,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.969829434941328
11.108267771080136 seconds in game passed.
Action: tensor([[[-0.0012,  0.6801],
         [-0.0037,  0.3704],
         [-0.0045,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.969829434941328
11.133267771452665 seconds in game passed.
Action: tensor([[[-0.0012,  0.6801],
         [-0.0037,  0.3704],
         [-0.0045,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.969829434941328
+++++++++++++: 2.030252344505728
11.158267771825194 seconds in game passed.
At 11.158267771825194 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0024,  0.6751],
         [-0.0012,  0.3711],
         [-0.0022,  0.2573],
         [-0.0030,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.030252344505728
Current reward: 0.35675489760583856
Current mitigation activation: 0
#############################
Total reward: 23.326584332547167
11.183267772197723 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6751],
         [-0.0012,  0.3711],
         [-0.0022,  0.2573],
         [-0.0030,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.326584332547167
11.208267772570252 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6751],
         [-0.0012,  0.3711],
         [-0.0022,  0.2573],
         [-0.0030,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.326584332547167
11.233267772942781 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6751],
         [-0.0012,  0.3711],
         [-0.0022,  0.2573],
         [-0.0030,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.326584332547167
+++++++++++++: 1.9151640183995646
11.25826777331531 seconds in game passed.
At 11.25826777331531 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6814],
         [-0.0013,  0.3757],
         [-0.0021,  0.2604],
         [-0.0027,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9151640183995646
Current reward: 0.36484122422042553
Current mitigation activation: 0
#############################
Total reward: 23.69142555676759
11.28326777368784 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6814],
         [-0.0013,  0.3757],
         [-0.0021,  0.2604],
         [-0.0027,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.69142555676759
11.308267774060369 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6814],
         [-0.0013,  0.3757],
         [-0.0021,  0.2604],
         [-0.0027,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.69142555676759
11.333267774432898 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6814],
         [-0.0013,  0.3757],
         [-0.0021,  0.2604],
         [-0.0027,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.69142555676759
+++++++++++++: 1.8067907654825164
11.358267774805427 seconds in game passed.
At 11.358267774805427 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.5489e-03,  6.7746e-01],
         [ 1.4456e-04,  3.8516e-01],
         [-5.4072e-04,  2.7189e-01],
         [-1.0454e-03,  2.1179e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8067907654825164
Current reward: 0.37245791499637404
Current mitigation activation: 0
#############################
Total reward: 24.063883471763965
11.383267775177956 seconds in game passed.
Action: tensor([[[ 5.5489e-03,  6.7746e-01],
         [ 1.4456e-04,  3.8516e-01],
         [-5.4072e-04,  2.7189e-01],
         [-1.0454e-03,  2.1179e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001819, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.063883471763965
11.408267775550485 seconds in game passed.
Action: tensor([[[ 5.5489e-03,  6.7746e-01],
         [ 1.4456e-04,  3.8516e-01],
         [-5.4072e-04,  2.7189e-01],
         [-1.0454e-03,  2.1179e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.063883471763965
11.433267775923014 seconds in game passed.
Action: tensor([[[ 5.5489e-03,  6.7746e-01],
         [ 1.4456e-04,  3.8516e-01],
         [-5.4072e-04,  2.7189e-01],
         [-1.0454e-03,  2.1179e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.063883471763965
+++++++++++++: 1.7041223079265908
11.458267776295543 seconds in game passed.
At 11.458267776295543 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.8155e-03,  7.0271e-01],
         [ 3.4206e-04,  3.9481e-01],
         [-5.3498e-04,  2.7638e-01],
         [-9.6157e-04,  2.1354e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7041223079265908
Current reward: 0.37961698621134343
Current mitigation activation: 0
#############################
Total reward: 24.443500457975308
11.483267776668072 seconds in game passed.
Action: tensor([[[ 6.8155e-03,  7.0271e-01],
         [ 3.4206e-04,  3.9481e-01],
         [-5.3498e-04,  2.7638e-01],
         [-9.6157e-04,  2.1354e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.443500457975308
11.5082677770406 seconds in game passed.
Action: tensor([[[ 6.8155e-03,  7.0271e-01],
         [ 3.4206e-04,  3.9481e-01],
         [-5.3498e-04,  2.7638e-01],
         [-9.6157e-04,  2.1354e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.443500457975308
11.53326777741313 seconds in game passed.
Action: tensor([[[ 6.8155e-03,  7.0271e-01],
         [ 3.4206e-04,  3.9481e-01],
         [-5.3498e-04,  2.7638e-01],
         [-9.6157e-04,  2.1354e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.443500457975308
+++++++++++++: 1.6063968253128633
11.558267777785659 seconds in game passed.
At 11.558267777785659 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.4198e-03,  7.2242e-01],
         [ 7.6082e-04,  4.0574e-01],
         [-1.3927e-04,  2.8385e-01],
         [-3.8458e-04,  2.1914e-01]]])
agent 0 action: VehicleControl(throttle=0.740585, steer=0.003885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6063968253128633
Current reward: 0.3863222947456389
Current mitigation activation: 0
#############################
Total reward: 24.829822752720947
11.583267778158188 seconds in game passed.
Action: tensor([[[ 9.4198e-03,  7.2242e-01],
         [ 7.6082e-04,  4.0574e-01],
         [-1.3927e-04,  2.8385e-01],
         [-3.8458e-04,  2.1914e-01]]])
agent 0 action: VehicleControl(throttle=0.692723, steer=0.003686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.829822752720947
11.608267778530717 seconds in game passed.
Action: tensor([[[ 9.4198e-03,  7.2242e-01],
         [ 7.6082e-04,  4.0574e-01],
         [-1.3927e-04,  2.8385e-01],
         [-3.8458e-04,  2.1914e-01]]])
agent 0 action: VehicleControl(throttle=0.633197, steer=0.003718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.829822752720947
11.633267778903246 seconds in game passed.
Action: tensor([[[ 9.4198e-03,  7.2242e-01],
         [ 7.6082e-04,  4.0574e-01],
         [-1.3927e-04,  2.8385e-01],
         [-3.8458e-04,  2.1914e-01]]])
agent 0 action: VehicleControl(throttle=0.575567, steer=0.003751, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.829822752720947
+++++++++++++: 1.5137270437359873
11.658267779275775 seconds in game passed.
At 11.658267779275775 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1058e-02, 7.4742e-01],
         [2.2121e-03, 4.1374e-01],
         [1.0451e-03, 2.8927e-01],
         [4.8834e-04, 2.2383e-01]]])
agent 0 action: VehicleControl(throttle=0.526366, steer=0.005545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5137270437359873
Current reward: 0.3924632074835247
Current mitigation activation: 0
#############################
Total reward: 25.22228596020447
11.683267779648304 seconds in game passed.
Action: tensor([[[1.1058e-02, 7.4742e-01],
         [2.2121e-03, 4.1374e-01],
         [1.0451e-03, 2.8927e-01],
         [4.8834e-04, 2.2383e-01]]])
agent 0 action: VehicleControl(throttle=0.504823, steer=0.005333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.22228596020447
11.708267780020833 seconds in game passed.
Action: tensor([[[1.1058e-02, 7.4742e-01],
         [2.2121e-03, 4.1374e-01],
         [1.0451e-03, 2.8927e-01],
         [4.8834e-04, 2.2383e-01]]])
agent 0 action: VehicleControl(throttle=0.480765, steer=0.005408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.22228596020447
11.733267780393362 seconds in game passed.
Action: tensor([[[1.1058e-02, 7.4742e-01],
         [2.2121e-03, 4.1374e-01],
         [1.0451e-03, 2.8927e-01],
         [4.8834e-04, 2.2383e-01]]])
agent 0 action: VehicleControl(throttle=0.457188, steer=0.005483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.22228596020447
+++++++++++++: 1.4335188414499294
11.758267780765891 seconds in game passed.
At 11.758267780765891 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4771e-02,  7.5979e-01],
         [ 1.3610e-03,  4.2310e-01],
         [-2.0149e-04,  2.9710e-01],
         [-7.1194e-04,  2.3004e-01]]])
agent 0 action: VehicleControl(throttle=0.434016, steer=0.006486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4335188414499294
Current reward: 0.3967095036404943
Current mitigation activation: 0
#############################
Total reward: 25.618995463844964
11.78326778113842 seconds in game passed.
Action: tensor([[[ 1.4771e-02,  7.5979e-01],
         [ 1.3610e-03,  4.2310e-01],
         [-2.0149e-04,  2.9710e-01],
         [-7.1194e-04,  2.3004e-01]]])
agent 0 action: VehicleControl(throttle=0.411316, steer=0.006410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.618995463844964
11.80826778151095 seconds in game passed.
Action: tensor([[[ 1.4771e-02,  7.5979e-01],
         [ 1.3610e-03,  4.2310e-01],
         [-2.0149e-04,  2.9710e-01],
         [-7.1194e-04,  2.3004e-01]]])
agent 0 action: VehicleControl(throttle=0.389087, steer=0.006488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.618995463844964
11.833267781883478 seconds in game passed.
Action: tensor([[[ 1.4771e-02,  7.5979e-01],
         [ 1.3610e-03,  4.2310e-01],
         [-2.0149e-04,  2.9710e-01],
         [-7.1194e-04,  2.3004e-01]]])
agent 0 action: VehicleControl(throttle=0.367326, steer=0.006566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.618995463844964
+++++++++++++: 1.3705213386233077
11.858267782256007 seconds in game passed.
At 11.858267782256007 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0096,  0.7919],
         [-0.0011,  0.4274],
         [-0.0030,  0.2964],
         [-0.0040,  0.2279]]])
agent 0 action: VehicleControl(throttle=0.345619, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3705213386233077
Current reward: 0.3979507034850668
Current mitigation activation: 0
#############################
Total reward: 26.01694616733003
11.883267782628536 seconds in game passed.
Action: tensor([[[ 0.0096,  0.7919],
         [-0.0011,  0.4274],
         [-0.0030,  0.2964],
         [-0.0040,  0.2279]]])
agent 0 action: VehicleControl(throttle=0.324375, steer=0.003324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.01694616733003
11.908267783001065 seconds in game passed.
Action: tensor([[[ 0.0096,  0.7919],
         [-0.0011,  0.4274],
         [-0.0030,  0.2964],
         [-0.0040,  0.2279]]])
agent 0 action: VehicleControl(throttle=0.303593, steer=0.003369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.01694616733003
11.933267783373594 seconds in game passed.
Action: tensor([[[ 0.0096,  0.7919],
         [-0.0011,  0.4274],
         [-0.0030,  0.2964],
         [-0.0040,  0.2279]]])
agent 0 action: VehicleControl(throttle=0.283270, steer=0.003414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.01694616733003
+++++++++++++: 1.3219865973655138
11.958267783746123 seconds in game passed.
At 11.958267783746123 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1374e-02,  8.1946e-01],
         [-7.1223e-04,  4.4412e-01],
         [-3.0665e-03,  3.0740e-01],
         [-4.0653e-03,  2.3549e-01]]])
agent 0 action: VehicleControl(throttle=0.263507, steer=0.004488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3219865973655138
Current reward: 0.39644443079947433
Current mitigation activation: 0
#############################
Total reward: 26.413390598129503
11.983267784118652 seconds in game passed.
Action: tensor([[[ 1.1374e-02,  8.1946e-01],
         [-7.1223e-04,  4.4412e-01],
         [-3.0665e-03,  3.0740e-01],
         [-4.0653e-03,  2.3549e-01]]])
agent 0 action: VehicleControl(throttle=0.244202, steer=0.004386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.413390598129503
12.008267784491181 seconds in game passed.
Action: tensor([[[ 1.1374e-02,  8.1946e-01],
         [-7.1223e-04,  4.4412e-01],
         [-3.0665e-03,  3.0740e-01],
         [-4.0653e-03,  2.3549e-01]]])
agent 0 action: VehicleControl(throttle=0.225353, steer=0.004452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.413390598129503
12.03326778486371 seconds in game passed.
Action: tensor([[[ 1.1374e-02,  8.1946e-01],
         [-7.1223e-04,  4.4412e-01],
         [-3.0665e-03,  3.0740e-01],
         [-4.0653e-03,  2.3549e-01]]])
agent 0 action: VehicleControl(throttle=0.206958, steer=0.004518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.413390598129503
+++++++++++++: 1.28527836694726
12.05826778523624 seconds in game passed.
At 12.05826778523624 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0049,  1.0000],
         [-0.0085,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001346, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.28527836694726
Current reward: 0.3926300666721359
Current mitigation activation: 1
#############################
Total reward: 26.80602066480164
12.083267785608768 seconds in game passed.
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0049,  1.0000],
         [-0.0085,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000351, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.80602066480164
12.108267785981297 seconds in game passed.
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0049,  1.0000],
         [-0.0085,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000336, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.80602066480164
12.133267786353827 seconds in game passed.
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0049,  1.0000],
         [-0.0085,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000321, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.80602066480164
+++++++++++++: 1.2618314097248249
12.158267786726356 seconds in game passed.
At 12.158267786726356 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0012,  1.0000],
         [-0.0037,  1.0000],
         [-0.0081,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000127, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2618314097248249
Current reward: 0.3863061820227013
Current mitigation activation: 1
#############################
Total reward: 27.19232684682434
12.183267787098885 seconds in game passed.
Action: tensor([[[ 0.0012,  1.0000],
         [-0.0037,  1.0000],
         [-0.0081,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000180, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.19232684682434
12.208267787471414 seconds in game passed.
Action: tensor([[[ 0.0012,  1.0000],
         [-0.0037,  1.0000],
         [-0.0081,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000197, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.19232684682434
12.233267787843943 seconds in game passed.
Action: tensor([[[ 0.0012,  1.0000],
         [-0.0037,  1.0000],
         [-0.0081,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000215, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.19232684682434
+++++++++++++: 1.2803493136220676
12.258267788216472 seconds in game passed.
At 12.258267788216472 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0034,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0183,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006957, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2803493136220676
Current reward: 0.37247979998195196
Current mitigation activation: 1
#############################
Total reward: 27.564806646806293
12.283267788589 seconds in game passed.
Action: tensor([[[ 0.0034,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0183,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005927, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.564806646806293
12.30826778896153 seconds in game passed.
Action: tensor([[[ 0.0034,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0183,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006007, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.564806646806293
12.333267789334059 seconds in game passed.
Action: tensor([[[ 0.0034,  1.0000],
         [-0.0165,  1.0000],
         [-0.0198,  1.0000],
         [-0.0183,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006087, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.564806646806293
+++++++++++++: 1.3656048862558083
12.358267789706588 seconds in game passed.
At 12.358267789706588 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0062,  0.9390],
         [-0.0084,  0.5562],
         [-0.0100,  0.3659],
         [-0.0090,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001442, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3656048862558083
Current reward: 0.34927311505818076
Current mitigation activation: 0
#############################
Total reward: 27.914079761864475
12.383267790079117 seconds in game passed.
Action: tensor([[[ 0.0062,  0.9390],
         [-0.0084,  0.5562],
         [-0.0100,  0.3659],
         [-0.0090,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002288, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.914079761864475
12.408267790451646 seconds in game passed.
Action: tensor([[[ 0.0062,  0.9390],
         [-0.0084,  0.5562],
         [-0.0100,  0.3659],
         [-0.0090,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002350, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.914079761864475
12.433267790824175 seconds in game passed.
Action: tensor([[[ 0.0062,  0.9390],
         [-0.0084,  0.5562],
         [-0.0100,  0.3659],
         [-0.0090,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002412, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.914079761864475
+++++++++++++: 1.5029048348939191
12.458267791196704 seconds in game passed.
At 12.458267791196704 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0058,  0.9437],
         [-0.0137,  0.5740],
         [-0.0153,  0.3660],
         [-0.0145,  0.2686]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006508, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5029048348939191
Current reward: 0.3235224545326
Current mitigation activation: 0
#############################
Total reward: 28.237602216397075
12.483267791569233 seconds in game passed.
Action: tensor([[[ 0.0058,  0.9437],
         [-0.0137,  0.5740],
         [-0.0153,  0.3660],
         [-0.0145,  0.2686]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005954, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.237602216397075
12.508267791941762 seconds in game passed.
Action: tensor([[[ 0.0058,  0.9437],
         [-0.0137,  0.5740],
         [-0.0153,  0.3660],
         [-0.0145,  0.2686]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006064, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.237602216397075
12.533267792314291 seconds in game passed.
Action: tensor([[[ 0.0058,  0.9437],
         [-0.0137,  0.5740],
         [-0.0153,  0.3660],
         [-0.0145,  0.2686]]])
agent 0 action: VehicleControl(throttle=0.003718, steer=-0.006174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.237602216397075
+++++++++++++: 1.688541922157379
12.55826779268682 seconds in game passed.
At 12.55826779268682 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0086,  0.9457],
         [-0.0122,  0.5994],
         [-0.0129,  0.3747],
         [-0.0101,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003685, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.688541922157379
Current reward: 0.2986952881668923
Current mitigation activation: 0
#############################
Total reward: 28.53629750456397
12.583267793059349 seconds in game passed.
Action: tensor([[[ 0.0086,  0.9457],
         [-0.0122,  0.5994],
         [-0.0129,  0.3747],
         [-0.0101,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004214, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.53629750456397
12.608267793431878 seconds in game passed.
Action: tensor([[[ 0.0086,  0.9457],
         [-0.0122,  0.5994],
         [-0.0129,  0.3747],
         [-0.0101,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.000313, steer=-0.004312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.53629750456397
12.633267793804407 seconds in game passed.
Action: tensor([[[ 0.0086,  0.9457],
         [-0.0122,  0.5994],
         [-0.0129,  0.3747],
         [-0.0101,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.53629750456397
+++++++++++++: 1.923894922264369
12.658267794176936 seconds in game passed.
At 12.658267794176936 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0134,  0.9432],
         [-0.0094,  0.5777],
         [-0.0105,  0.3651],
         [-0.0079,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.100648, steer=-0.000426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.923894922264369
Current reward: 0.2763355431607222
Current mitigation activation: 0
#############################
Total reward: 28.81263304772469
12.683267794549465 seconds in game passed.
Action: tensor([[[ 0.0134,  0.9432],
         [-0.0094,  0.5777],
         [-0.0105,  0.3651],
         [-0.0079,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.152524, steer=-0.001175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.81263304772469
12.708267794921994 seconds in game passed.
Action: tensor([[[ 0.0134,  0.9432],
         [-0.0094,  0.5777],
         [-0.0105,  0.3651],
         [-0.0079,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.184119, steer=-0.001248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.81263304772469
12.733267795294523 seconds in game passed.
Action: tensor([[[ 0.0134,  0.9432],
         [-0.0094,  0.5777],
         [-0.0105,  0.3651],
         [-0.0079,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.193892, steer=-0.001322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.81263304772469
+++++++++++++: 2.1269520247521125
12.758267795667052 seconds in game passed.
At 12.758267795667052 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.9435],
         [-0.0075,  0.5930],
         [-0.0062,  0.3755],
         [-0.0035,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.020138, steer=-0.006525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1269520247521125
Current reward: 0.2623201760911056
Current mitigation activation: 0
#############################
Total reward: 29.074953223815797
12.783267796039581 seconds in game passed.
Action: tensor([[[-0.0010,  0.9435],
         [-0.0075,  0.5930],
         [-0.0062,  0.3755],
         [-0.0035,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.059158, steer=-0.005816, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.074953223815797
12.80826779641211 seconds in game passed.
Action: tensor([[[-0.0010,  0.9435],
         [-0.0075,  0.5930],
         [-0.0062,  0.3755],
         [-0.0035,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.114294, steer=-0.005951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.074953223815797
12.83326779678464 seconds in game passed.
Action: tensor([[[-0.0010,  0.9435],
         [-0.0075,  0.5930],
         [-0.0062,  0.3755],
         [-0.0035,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.162837, steer=-0.006087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.074953223815797
+++++++++++++: 2.2455241725157027
12.858267797157168 seconds in game passed.
At 12.858267797157168 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0101, 0.9388],
         [0.0053, 0.5491],
         [0.0017, 0.3624],
         [0.0016, 0.2642]]])
agent 0 action: VehicleControl(throttle=0.716537, steer=0.008320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2455241725157027
Current reward: 0.2565351534013368
Current mitigation activation: 0
#############################
Total reward: 29.331488377217134
12.883267797529697 seconds in game passed.
Action: tensor([[[0.0101, 0.9388],
         [0.0053, 0.5491],
         [0.0017, 0.3624],
         [0.0016, 0.2642]]])
agent 0 action: VehicleControl(throttle=0.711472, steer=0.005984, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.331488377217134
12.908267797902226 seconds in game passed.
Action: tensor([[[0.0101, 0.9388],
         [0.0053, 0.5491],
         [0.0017, 0.3624],
         [0.0016, 0.2642]]])
agent 0 action: VehicleControl(throttle=0.756995, steer=0.006039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.331488377217134
12.933267798274755 seconds in game passed.
Action: tensor([[[0.0101, 0.9388],
         [0.0053, 0.5491],
         [0.0017, 0.3624],
         [0.0016, 0.2642]]])
agent 0 action: VehicleControl(throttle=0.797922, steer=0.006095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.331488377217134
+++++++++++++: 2.4667855255683713
12.958267798647285 seconds in game passed.
At 12.958267798647285 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0079, 0.9323],
         [0.0049, 0.5234],
         [0.0018, 0.3471],
         [0.0017, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4667855255683713
Current reward: 0.24663670015063968
Current mitigation activation: 0
#############################
Total reward: 29.578125077367773
12.983267799019814 seconds in game passed.
Action: tensor([[[0.0079, 0.9323],
         [0.0049, 0.5234],
         [0.0018, 0.3471],
         [0.0017, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.578125077367773
13.008267799392343 seconds in game passed.
Action: tensor([[[0.0079, 0.9323],
         [0.0049, 0.5234],
         [0.0018, 0.3471],
         [0.0017, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.578125077367773
13.033267799764872 seconds in game passed.
Action: tensor([[[0.0079, 0.9323],
         [0.0049, 0.5234],
         [0.0018, 0.3471],
         [0.0017, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.578125077367773
+++++++++++++: 2.60727792044817
13.0582678001374 seconds in game passed.
At 13.0582678001374 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0048, 0.9249],
         [0.0055, 0.5118],
         [0.0034, 0.3426],
         [0.0033, 0.2527]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.60727792044817
Current reward: 0.24274850426130523
Current mitigation activation: 0
#############################
Total reward: 29.820873581629076
13.08326780050993 seconds in game passed.
Action: tensor([[[0.0048, 0.9249],
         [0.0055, 0.5118],
         [0.0034, 0.3426],
         [0.0033, 0.2527]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004505, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.820873581629076
13.108267800882459 seconds in game passed.
Action: tensor([[[0.0048, 0.9249],
         [0.0055, 0.5118],
         [0.0034, 0.3426],
         [0.0033, 0.2527]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.820873581629076
13.133267801254988 seconds in game passed.
Action: tensor([[[0.0048, 0.9249],
         [0.0055, 0.5118],
         [0.0034, 0.3426],
         [0.0033, 0.2527]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.820873581629076
+++++++++++++: 2.5944213367029967
13.158267801627517 seconds in game passed.
At 13.158267801627517 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0041, 0.9107],
         [0.0035, 0.4932],
         [0.0012, 0.3312],
         [0.0010, 0.2450]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5944213367029967
Current reward: 0.24635999148332724
Current mitigation activation: 0
#############################
Total reward: 30.067233573112404
13.183267802000046 seconds in game passed.
Action: tensor([[[0.0041, 0.9107],
         [0.0035, 0.4932],
         [0.0012, 0.3312],
         [0.0010, 0.2450]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.067233573112404
13.208267802372575 seconds in game passed.
Action: tensor([[[0.0041, 0.9107],
         [0.0035, 0.4932],
         [0.0012, 0.3312],
         [0.0010, 0.2450]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.067233573112404
13.233267802745104 seconds in game passed.
Action: tensor([[[0.0041, 0.9107],
         [0.0035, 0.4932],
         [0.0012, 0.3312],
         [0.0010, 0.2450]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.067233573112404
+++++++++++++: 2.491312056310562
13.258267803117633 seconds in game passed.
At 13.258267803117633 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.8091e-03,  8.9128e-01],
         [-4.6477e-04,  4.8026e-01],
         [-1.7891e-03,  3.2863e-01],
         [-1.1838e-03,  2.4677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.491312056310562
Current reward: 0.25418182733589734
Current mitigation activation: 0
#############################
Total reward: 30.321415400448302
13.283267803490162 seconds in game passed.
Action: tensor([[[-1.8091e-03,  8.9128e-01],
         [-4.6477e-04,  4.8026e-01],
         [-1.7891e-03,  3.2863e-01],
         [-1.1838e-03,  2.4677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.321415400448302
13.308267803862691 seconds in game passed.
Action: tensor([[[-1.8091e-03,  8.9128e-01],
         [-4.6477e-04,  4.8026e-01],
         [-1.7891e-03,  3.2863e-01],
         [-1.1838e-03,  2.4677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.321415400448302
13.33326780423522 seconds in game passed.
Action: tensor([[[-1.8091e-03,  8.9128e-01],
         [-4.6477e-04,  4.8026e-01],
         [-1.7891e-03,  3.2863e-01],
         [-1.1838e-03,  2.4677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.321415400448302
+++++++++++++: 2.356097854803903
13.358267804607749 seconds in game passed.
At 13.358267804607749 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0097,  0.9030],
         [-0.0017,  0.4999],
         [-0.0025,  0.3447],
         [-0.0020,  0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.356097854803903
Current reward: 0.2638097501278483
Current mitigation activation: 0
#############################
Total reward: 30.58522515057615
13.383267804980278 seconds in game passed.
Action: tensor([[[-0.0097,  0.9030],
         [-0.0017,  0.4999],
         [-0.0025,  0.3447],
         [-0.0020,  0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004420, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.58522515057615
13.408267805352807 seconds in game passed.
Action: tensor([[[-0.0097,  0.9030],
         [-0.0017,  0.4999],
         [-0.0025,  0.3447],
         [-0.0020,  0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.58522515057615
13.433267805725336 seconds in game passed.
Action: tensor([[[-0.0097,  0.9030],
         [-0.0017,  0.4999],
         [-0.0025,  0.3447],
         [-0.0020,  0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.58522515057615
+++++++++++++: 2.2154530794546425
13.458267806097865 seconds in game passed.
At 13.458267806097865 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0070,  0.8988],
         [-0.0034,  0.5058],
         [-0.0042,  0.3599],
         [-0.0030,  0.2809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2154530794546425
Current reward: 0.27408185424958786
Current mitigation activation: 0
#############################
Total reward: 30.859307004825737
13.483267806470394 seconds in game passed.
Action: tensor([[[-0.0070,  0.8988],
         [-0.0034,  0.5058],
         [-0.0042,  0.3599],
         [-0.0030,  0.2809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.859307004825737
13.508267806842923 seconds in game passed.
Action: tensor([[[-0.0070,  0.8988],
         [-0.0034,  0.5058],
         [-0.0042,  0.3599],
         [-0.0030,  0.2809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.859307004825737
13.533267807215452 seconds in game passed.
Action: tensor([[[-0.0070,  0.8988],
         [-0.0034,  0.5058],
         [-0.0042,  0.3599],
         [-0.0030,  0.2809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.859307004825737
+++++++++++++: 2.0796950061729147
13.558267807587981 seconds in game passed.
At 13.558267807587981 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0041,  0.8695],
         [-0.0011,  0.5008],
         [-0.0033,  0.3644],
         [-0.0029,  0.2886]]])
agent 0 action: VehicleControl(throttle=0.864641, steer=0.002043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0796950061729147
Current reward: 0.2844350685844137
Current mitigation activation: 0
#############################
Total reward: 31.143742073410152
13.58326780796051 seconds in game passed.
Action: tensor([[[ 0.0041,  0.8695],
         [-0.0011,  0.5008],
         [-0.0033,  0.3644],
         [-0.0029,  0.2886]]])
agent 0 action: VehicleControl(throttle=0.840125, steer=0.001018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.143742073410152
13.60826780833304 seconds in game passed.
Action: tensor([[[ 0.0041,  0.8695],
         [-0.0011,  0.5008],
         [-0.0033,  0.3644],
         [-0.0029,  0.2886]]])
agent 0 action: VehicleControl(throttle=0.807925, steer=0.001079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.143742073410152
13.633267808705568 seconds in game passed.
Action: tensor([[[ 0.0041,  0.8695],
         [-0.0011,  0.5008],
         [-0.0033,  0.3644],
         [-0.0029,  0.2886]]])
agent 0 action: VehicleControl(throttle=0.775518, steer=0.001141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.143742073410152
+++++++++++++: 1.9526007888610355
13.658267809078097 seconds in game passed.
At 13.658267809078097 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0052,  0.8860],
         [-0.0019,  0.4969],
         [-0.0028,  0.3502],
         [-0.0023,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.888691, steer=-0.003446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9526007888610355
Current reward: 0.2945464627237969
Current mitigation activation: 0
#############################
Total reward: 31.43828853613395
13.683267809450626 seconds in game passed.
Action: tensor([[[-0.0052,  0.8860],
         [-0.0019,  0.4969],
         [-0.0028,  0.3502],
         [-0.0023,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.841497, steer=-0.002715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.43828853613395
13.708267809823155 seconds in game passed.
Action: tensor([[[-0.0052,  0.8860],
         [-0.0019,  0.4969],
         [-0.0028,  0.3502],
         [-0.0023,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.809876, steer=-0.002743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.43828853613395
13.733267810195684 seconds in game passed.
Action: tensor([[[-0.0052,  0.8860],
         [-0.0019,  0.4969],
         [-0.0028,  0.3502],
         [-0.0023,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.777625, steer=-0.002772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.43828853613395
+++++++++++++: 1.8388800732971262
13.758267810568213 seconds in game passed.
At 13.758267810568213 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.2529e-03,  9.1726e-01],
         [-8.6690e-04,  5.0523e-01],
         [-2.6843e-03,  3.4392e-01],
         [-2.2141e-03,  2.5828e-01]]])
agent 0 action: VehicleControl(throttle=0.767423, steer=-0.001989, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8388800732971262
Current reward: 0.3038554990501606
Current mitigation activation: 0
#############################
Total reward: 31.74214403518411
13.783267810940742 seconds in game passed.
Action: tensor([[[-5.2529e-03,  9.1726e-01],
         [-8.6690e-04,  5.0523e-01],
         [-2.6843e-03,  3.4392e-01],
         [-2.2141e-03,  2.5828e-01]]])
agent 0 action: VehicleControl(throttle=0.735416, steer=-0.002081, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.74214403518411
13.808267811313272 seconds in game passed.
Action: tensor([[[-5.2529e-03,  9.1726e-01],
         [-8.6690e-04,  5.0523e-01],
         [-2.6843e-03,  3.4392e-01],
         [-2.2141e-03,  2.5828e-01]]])
agent 0 action: VehicleControl(throttle=0.705483, steer=-0.002049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.74214403518411
13.8332678116858 seconds in game passed.
Action: tensor([[[-5.2529e-03,  9.1726e-01],
         [-8.6690e-04,  5.0523e-01],
         [-2.6843e-03,  3.4392e-01],
         [-2.2141e-03,  2.5828e-01]]])
agent 0 action: VehicleControl(throttle=0.675622, steer=-0.002017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.74214403518411
+++++++++++++: 1.738219857542734
13.85826781205833 seconds in game passed.
At 13.85826781205833 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.9281],
         [-0.0036,  0.5065],
         [-0.0067,  0.3387],
         [-0.0059,  0.2510]]])
agent 0 action: VehicleControl(throttle=0.672040, steer=0.000337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.738219857542734
Current reward: 0.31214561831682264
Current mitigation activation: 0
#############################
Total reward: 32.05428965350093
13.883267812430859 seconds in game passed.
Action: tensor([[[ 0.0057,  0.9281],
         [-0.0036,  0.5065],
         [-0.0067,  0.3387],
         [-0.0059,  0.2510]]])
agent 0 action: VehicleControl(throttle=0.634609, steer=-0.000162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.05428965350093
13.908267812803388 seconds in game passed.
Action: tensor([[[ 0.0057,  0.9281],
         [-0.0036,  0.5065],
         [-0.0067,  0.3387],
         [-0.0059,  0.2510]]])
agent 0 action: VehicleControl(throttle=0.601316, steer=-0.000254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.05428965350093
13.933267813175917 seconds in game passed.
Action: tensor([[[ 0.0057,  0.9281],
         [-0.0036,  0.5065],
         [-0.0067,  0.3387],
         [-0.0059,  0.2510]]])
agent 0 action: VehicleControl(throttle=0.568872, steer=-0.000346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.05428965350093
+++++++++++++: 1.652915563169129
13.958267813548446 seconds in game passed.
At 13.958267813548446 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6252e-03,  9.3664e-01],
         [-4.7273e-04,  5.2018e-01],
         [-2.7395e-03,  3.4000e-01],
         [-9.5949e-04,  2.4908e-01]]])
agent 0 action: VehicleControl(throttle=0.367940, steer=0.002861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.652915563169129
Current reward: 0.31892129174723444
Current mitigation activation: 0
#############################
Total reward: 32.37321094524817
13.983267813920975 seconds in game passed.
Action: tensor([[[ 7.6252e-03,  9.3664e-01],
         [-4.7273e-04,  5.2018e-01],
         [-2.7395e-03,  3.4000e-01],
         [-9.5949e-04,  2.4908e-01]]])
agent 0 action: VehicleControl(throttle=0.363006, steer=0.002275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.37321094524817
14.008267814293504 seconds in game passed.
Action: tensor([[[ 7.6252e-03,  9.3664e-01],
         [-4.7273e-04,  5.2018e-01],
         [-2.7395e-03,  3.4000e-01],
         [-9.5949e-04,  2.4908e-01]]])
agent 0 action: VehicleControl(throttle=0.350683, steer=0.002231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.37321094524817
14.033267814666033 seconds in game passed.
Action: tensor([[[ 7.6252e-03,  9.3664e-01],
         [-4.7273e-04,  5.2018e-01],
         [-2.7395e-03,  3.4000e-01],
         [-9.5949e-04,  2.4908e-01]]])
agent 0 action: VehicleControl(throttle=0.337050, steer=0.002186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.37321094524817
+++++++++++++: 1.5867264933171372
14.058267815038562 seconds in game passed.
At 14.058267815038562 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0053,  0.9400],
         [-0.0016,  0.5403],
         [-0.0032,  0.3523],
         [-0.0012,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.321964, steer=0.000327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5867264933171372
Current reward: 0.3234647587077541
Current mitigation activation: 0
#############################
Total reward: 32.696675703955925
14.08326781541109 seconds in game passed.
Action: tensor([[[ 0.0053,  0.9400],
         [-0.0016,  0.5403],
         [-0.0032,  0.3523],
         [-0.0012,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.307010, steer=0.000575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.696675703955925
14.10826781578362 seconds in game passed.
Action: tensor([[[ 0.0053,  0.9400],
         [-0.0016,  0.5403],
         [-0.0032,  0.3523],
         [-0.0012,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.292247, steer=0.000521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.696675703955925
14.133267816156149 seconds in game passed.
Action: tensor([[[ 0.0053,  0.9400],
         [-0.0016,  0.5403],
         [-0.0032,  0.3523],
         [-0.0012,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.277726, steer=0.000468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.696675703955925
+++++++++++++: 1.548685737497602
14.158267816528678 seconds in game passed.
At 14.158267816528678 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0050,  0.9394],
         [-0.0036,  0.5443],
         [-0.0053,  0.3528],
         [-0.0035,  0.2562]]])
agent 0 action: VehicleControl(throttle=0.261027, steer=-0.001150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.548685737497602
Current reward: 0.32441874187281594
Current mitigation activation: 0
#############################
Total reward: 33.021094445828744
14.183267816901207 seconds in game passed.
Action: tensor([[[ 0.0050,  0.9394],
         [-0.0036,  0.5443],
         [-0.0053,  0.3528],
         [-0.0035,  0.2562]]])
agent 0 action: VehicleControl(throttle=0.244644, steer=-0.000940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.021094445828744
14.208267817273736 seconds in game passed.
Action: tensor([[[ 0.0050,  0.9394],
         [-0.0036,  0.5443],
         [-0.0053,  0.3528],
         [-0.0035,  0.2562]]])
agent 0 action: VehicleControl(throttle=0.228606, steer=-0.000991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.021094445828744
14.233267817646265 seconds in game passed.
Action: tensor([[[ 0.0050,  0.9394],
         [-0.0036,  0.5443],
         [-0.0053,  0.3528],
         [-0.0035,  0.2562]]])
agent 0 action: VehicleControl(throttle=0.212938, steer=-0.001042, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.021094445828744
+++++++++++++: 1.537137161369091
14.258267818018794 seconds in game passed.
At 14.258267818018794 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.9377e-05,  9.3905e-01],
         [-1.1240e-03,  5.4177e-01],
         [-3.1323e-03,  3.5565e-01],
         [-2.4460e-03,  2.6196e-01]]])
agent 0 action: VehicleControl(throttle=0.196333, steer=-0.001367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.537137161369091
Current reward: 0.32196085529746626
Current mitigation activation: 0
#############################
Total reward: 33.34305530112621
14.283267818391323 seconds in game passed.
Action: tensor([[[-1.9377e-05,  9.3905e-01],
         [-1.1240e-03,  5.4177e-01],
         [-3.1323e-03,  3.5565e-01],
         [-2.4460e-03,  2.6196e-01]]])
agent 0 action: VehicleControl(throttle=0.180134, steer=-0.001310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.34305530112621
14.308267818763852 seconds in game passed.
Action: tensor([[[-1.9377e-05,  9.3905e-01],
         [-1.1240e-03,  5.4177e-01],
         [-3.1323e-03,  3.5565e-01],
         [-2.4460e-03,  2.6196e-01]]])
agent 0 action: VehicleControl(throttle=0.164353, steer=-0.001307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.34305530112621
14.333267819136381 seconds in game passed.
Action: tensor([[[-1.9377e-05,  9.3905e-01],
         [-1.1240e-03,  5.4177e-01],
         [-3.1323e-03,  3.5565e-01],
         [-2.4460e-03,  2.6196e-01]]])
agent 0 action: VehicleControl(throttle=0.149004, steer=-0.001304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.34305530112621
+++++++++++++: 1.5337989334422104
14.35826781950891 seconds in game passed.
At 14.35826781950891 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.1103e-03,  9.4271e-01],
         [-3.0095e-04,  5.6364e-01],
         [-1.2297e-03,  3.6069e-01],
         [-7.4623e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003365, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5337989334422104
Current reward: 0.3185866895335608
Current mitigation activation: 0
#############################
Total reward: 33.661641990659774
14.38326781988144 seconds in game passed.
Action: tensor([[[-6.1103e-03,  9.4271e-01],
         [-3.0095e-04,  5.6364e-01],
         [-1.2297e-03,  3.6069e-01],
         [-7.4623e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002992, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.661641990659774
14.408267820253968 seconds in game passed.
Action: tensor([[[-6.1103e-03,  9.4271e-01],
         [-3.0095e-04,  5.6364e-01],
         [-1.2297e-03,  3.6069e-01],
         [-7.4623e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002966, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.661641990659774
14.433267820626497 seconds in game passed.
Action: tensor([[[-6.1103e-03,  9.4271e-01],
         [-3.0095e-04,  5.6364e-01],
         [-1.2297e-03,  3.6069e-01],
         [-7.4623e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002941, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.661641990659774
+++++++++++++: 1.5272696659042697
14.458267820999026 seconds in game passed.
At 14.458267820999026 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.8516e-03,  9.4286e-01],
         [ 1.9596e-04,  5.7610e-01],
         [-6.4105e-04,  3.7495e-01],
         [-8.8732e-04,  2.7635e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004289, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5272696659042697
Current reward: 0.31577904888142183
Current mitigation activation: 0
#############################
Total reward: 33.9774210395412
14.483267821371555 seconds in game passed.
Action: tensor([[[-9.8516e-03,  9.4286e-01],
         [ 1.9596e-04,  5.7610e-01],
         [-6.4105e-04,  3.7495e-01],
         [-8.8732e-04,  2.7635e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004049, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.9774210395412
14.508267821744084 seconds in game passed.
Action: tensor([[[-9.8516e-03,  9.4286e-01],
         [ 1.9596e-04,  5.7610e-01],
         [-6.4105e-04,  3.7495e-01],
         [-8.8732e-04,  2.7635e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004036, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.9774210395412
14.533267822116613 seconds in game passed.
Action: tensor([[[-9.8516e-03,  9.4286e-01],
         [ 1.9596e-04,  5.7610e-01],
         [-6.4105e-04,  3.7495e-01],
         [-8.8732e-04,  2.7635e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004023, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.9774210395412
+++++++++++++: 1.609597669381936
14.558267822489142 seconds in game passed.
At 14.558267822489142 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0206,  0.9431],
         [-0.0058,  0.5855],
         [-0.0057,  0.3809],
         [-0.0052,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013526, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.609597669381936
Current reward: 0.30296371679214706
Current mitigation activation: 0
#############################
Total reward: 34.28038475633335
14.583267822861671 seconds in game passed.
Action: tensor([[[-0.0206,  0.9431],
         [-0.0058,  0.5855],
         [-0.0057,  0.3809],
         [-0.0052,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.058640, steer=-0.012120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.28038475633335
14.6082678232342 seconds in game passed.
Action: tensor([[[-0.0206,  0.9431],
         [-0.0058,  0.5855],
         [-0.0057,  0.3809],
         [-0.0052,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.053283, steer=-0.012272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.28038475633335
14.63326782360673 seconds in game passed.
Action: tensor([[[-0.0206,  0.9431],
         [-0.0058,  0.5855],
         [-0.0057,  0.3809],
         [-0.0052,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.048393, steer=-0.012424, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.28038475633335
+++++++++++++: 1.8165414956572725
14.658267823979259 seconds in game passed.
At 14.658267823979259 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0248,  0.9479],
         [-0.0085,  0.6338],
         [-0.0052,  0.3942],
         [-0.0035,  0.2805]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016948, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8165414956572725
Current reward: 0.280885649915092
Current mitigation activation: 0
#############################
Total reward: 34.56127040624844
14.683267824351788 seconds in game passed.
Action: tensor([[[-0.0248,  0.9479],
         [-0.0085,  0.6338],
         [-0.0052,  0.3942],
         [-0.0035,  0.2805]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016369, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.56127040624844
14.708267824724317 seconds in game passed.
Action: tensor([[[-0.0248,  0.9479],
         [-0.0085,  0.6338],
         [-0.0052,  0.3942],
         [-0.0035,  0.2805]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016520, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.56127040624844
14.733267825096846 seconds in game passed.
Action: tensor([[[-0.0248,  0.9479],
         [-0.0085,  0.6338],
         [-0.0052,  0.3942],
         [-0.0035,  0.2805]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016670, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.56127040624844
+++++++++++++: 1.9818545487011072
14.758267825469375 seconds in game passed.
At 14.758267825469375 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6548e-02,  9.4852e-01],
         [-1.5867e-03,  6.5079e-01],
         [-4.3549e-04,  4.0737e-01],
         [ 5.7213e-04,  2.9480e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007942, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9818545487011072
Current reward: 0.2676795693299253
Current mitigation activation: 0
#############################
Total reward: 34.82894997557837
14.783267825841904 seconds in game passed.
Action: tensor([[[-1.6548e-02,  9.4852e-01],
         [-1.5867e-03,  6.5079e-01],
         [-4.3549e-04,  4.0737e-01],
         [ 5.7213e-04,  2.9480e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009474, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.82894997557837
14.808267826214433 seconds in game passed.
Action: tensor([[[-1.6548e-02,  9.4852e-01],
         [-1.5867e-03,  6.5079e-01],
         [-4.3549e-04,  4.0737e-01],
         [ 5.7213e-04,  2.9480e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009541, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.82894997557837
14.833267826586962 seconds in game passed.
Action: tensor([[[-1.6548e-02,  9.4852e-01],
         [-1.5867e-03,  6.5079e-01],
         [-4.3549e-04,  4.0737e-01],
         [ 5.7213e-04,  2.9480e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009607, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.82894997557837
+++++++++++++: 2.1547861661447274
14.85826782695949 seconds in game passed.
At 14.85826782695949 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0104,  0.9469],
         [ 0.0020,  0.6068],
         [ 0.0014,  0.3876],
         [ 0.0015,  0.2824]]])
agent 0 action: VehicleControl(throttle=0.007902, steer=-0.003774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1547861661447274
Current reward: 0.25701268293976354
Current mitigation activation: 0
#############################
Total reward: 35.085962658518135
14.88326782733202 seconds in game passed.
Action: tensor([[[-0.0104,  0.9469],
         [ 0.0020,  0.6068],
         [ 0.0014,  0.3876],
         [ 0.0015,  0.2824]]])
agent 0 action: VehicleControl(throttle=0.041240, steer=-0.004782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.085962658518135
14.908267827704549 seconds in game passed.
Action: tensor([[[-0.0104,  0.9469],
         [ 0.0020,  0.6068],
         [ 0.0014,  0.3876],
         [ 0.0015,  0.2824]]])
agent 0 action: VehicleControl(throttle=0.083444, steer=-0.004813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.085962658518135
14.933267828077078 seconds in game passed.
Action: tensor([[[-0.0104,  0.9469],
         [ 0.0020,  0.6068],
         [ 0.0014,  0.3876],
         [ 0.0015,  0.2824]]])
agent 0 action: VehicleControl(throttle=0.117006, steer=-0.004844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.085962658518135
+++++++++++++: 2.3224470179180283
14.958267828449607 seconds in game passed.
At 14.958267828449607 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.9423],
         [ 0.0031,  0.5548],
         [ 0.0016,  0.3646],
         [ 0.0022,  0.2678]]])
agent 0 action: VehicleControl(throttle=0.728735, steer=0.000348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3224470179180283
Current reward: 0.24908076140134838
Current mitigation activation: 0
#############################
Total reward: 35.33504341991949
14.983267828822136 seconds in game passed.
Action: tensor([[[-0.0010,  0.9423],
         [ 0.0031,  0.5548],
         [ 0.0016,  0.3646],
         [ 0.0022,  0.2678]]])
agent 0 action: VehicleControl(throttle=0.687147, steer=-0.000529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.33504341991949
15.008267829194665 seconds in game passed.
Action: tensor([[[-0.0010,  0.9423],
         [ 0.0031,  0.5548],
         [ 0.0016,  0.3646],
         [ 0.0022,  0.2678]]])
agent 0 action: VehicleControl(throttle=0.702993, steer=-0.000540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.33504341991949
15.033267829567194 seconds in game passed.
Action: tensor([[[-0.0010,  0.9423],
         [ 0.0031,  0.5548],
         [ 0.0016,  0.3646],
         [ 0.0022,  0.2678]]])
agent 0 action: VehicleControl(throttle=0.717979, steer=-0.000550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.33504341991949
+++++++++++++: 2.4465068942631163
15.058267829939723 seconds in game passed.
At 15.058267829939723 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.0387e-05,  9.3382e-01],
         [ 2.9352e-03,  5.2229e-01],
         [ 3.5615e-04,  3.4979e-01],
         [ 3.1666e-04,  2.5863e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4465068942631163
Current reward: 0.24506145560527343
Current mitigation activation: 0
#############################
Total reward: 35.58010487552476
15.083267830312252 seconds in game passed.
Action: tensor([[[-6.0387e-05,  9.3382e-01],
         [ 2.9352e-03,  5.2229e-01],
         [ 3.5615e-04,  3.4979e-01],
         [ 3.1666e-04,  2.5863e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.58010487552476
15.108267830684781 seconds in game passed.
Action: tensor([[[-6.0387e-05,  9.3382e-01],
         [ 2.9352e-03,  5.2229e-01],
         [ 3.5615e-04,  3.4979e-01],
         [ 3.1666e-04,  2.5863e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.58010487552476
15.13326783105731 seconds in game passed.
Action: tensor([[[-6.0387e-05,  9.3382e-01],
         [ 2.9352e-03,  5.2229e-01],
         [ 3.5615e-04,  3.4979e-01],
         [ 3.1666e-04,  2.5863e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.58010487552476
+++++++++++++: 2.4749451191128675
15.15826783142984 seconds in game passed.
At 15.15826783142984 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.0288e-03,  9.3187e-01],
         [ 3.7037e-03,  5.1381e-01],
         [ 7.7032e-05,  3.3868e-01],
         [-5.1141e-05,  2.4614e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4749451191128675
Current reward: 0.24640496106053655
Current mitigation activation: 0
#############################
Total reward: 35.826509836585295
15.183267831802368 seconds in game passed.
Action: tensor([[[ 7.0288e-03,  9.3187e-01],
         [ 3.7037e-03,  5.1381e-01],
         [ 7.7032e-05,  3.3868e-01],
         [-5.1141e-05,  2.4614e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.826509836585295
15.208267832174897 seconds in game passed.
Action: tensor([[[ 7.0288e-03,  9.3187e-01],
         [ 3.7037e-03,  5.1381e-01],
         [ 7.7032e-05,  3.3868e-01],
         [-5.1141e-05,  2.4614e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.826509836585295
15.233267832547426 seconds in game passed.
Action: tensor([[[ 7.0288e-03,  9.3187e-01],
         [ 3.7037e-03,  5.1381e-01],
         [ 7.7032e-05,  3.3868e-01],
         [-5.1141e-05,  2.4614e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.826509836585295
+++++++++++++: 2.4176168734176042
15.258267832919955 seconds in game passed.
At 15.258267832919955 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0167, 0.9206],
         [0.0056, 0.5048],
         [0.0015, 0.3357],
         [0.0012, 0.2435]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008604, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4176168734176042
Current reward: 0.2520271938566617
Current mitigation activation: 0
#############################
Total reward: 36.07853703044196
15.283267833292484 seconds in game passed.
Action: tensor([[[0.0167, 0.9206],
         [0.0056, 0.5048],
         [0.0015, 0.3357],
         [0.0012, 0.2435]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007819, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.07853703044196
15.308267833665013 seconds in game passed.
Action: tensor([[[0.0167, 0.9206],
         [0.0056, 0.5048],
         [0.0015, 0.3357],
         [0.0012, 0.2435]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.07853703044196
15.333267834037542 seconds in game passed.
Action: tensor([[[0.0167, 0.9206],
         [0.0056, 0.5048],
         [0.0015, 0.3357],
         [0.0012, 0.2435]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.07853703044196
+++++++++++++: 2.313377724168365
15.358267834410071 seconds in game passed.
At 15.358267834410071 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0185, 0.9236],
         [0.0053, 0.5087],
         [0.0021, 0.3372],
         [0.0019, 0.2433]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.313377724168365
Current reward: 0.2601267589827874
Current mitigation activation: 0
#############################
Total reward: 36.33866378942474
15.3832678347826 seconds in game passed.
Action: tensor([[[0.0185, 0.9236],
         [0.0053, 0.5087],
         [0.0021, 0.3372],
         [0.0019, 0.2433]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008818, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.33866378942474
15.40826783515513 seconds in game passed.
Action: tensor([[[0.0185, 0.9236],
         [0.0053, 0.5087],
         [0.0021, 0.3372],
         [0.0019, 0.2433]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.33866378942474
15.433267835527658 seconds in game passed.
Action: tensor([[[0.0185, 0.9236],
         [0.0053, 0.5087],
         [0.0021, 0.3372],
         [0.0019, 0.2433]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.33866378942474
+++++++++++++: 2.1944874229265774
15.458267835900187 seconds in game passed.
At 15.458267835900187 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9182e-02, 9.2189e-01],
         [3.5293e-03, 5.0041e-01],
         [7.4676e-04, 3.3201e-01],
         [1.2084e-03, 2.4098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008143, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1944874229265774
Current reward: 0.26921369704555115
Current mitigation activation: 0
#############################
Total reward: 36.607877486470294
15.483267836272717 seconds in game passed.
Action: tensor([[[1.9182e-02, 9.2189e-01],
         [3.5293e-03, 5.0041e-01],
         [7.4676e-04, 3.3201e-01],
         [1.2084e-03, 2.4098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.607877486470294
15.508267836645246 seconds in game passed.
Action: tensor([[[1.9182e-02, 9.2189e-01],
         [3.5293e-03, 5.0041e-01],
         [7.4676e-04, 3.3201e-01],
         [1.2084e-03, 2.4098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.607877486470294
15.533267837017775 seconds in game passed.
Action: tensor([[[1.9182e-02, 9.2189e-01],
         [3.5293e-03, 5.0041e-01],
         [7.4676e-04, 3.3201e-01],
         [1.2084e-03, 2.4098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.607877486470294
+++++++++++++: 2.074041394168986
15.558267837390304 seconds in game passed.
At 15.558267837390304 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0118, 0.9211],
         [0.0029, 0.4939],
         [0.0009, 0.3282],
         [0.0016, 0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.074041394168986
Current reward: 0.27862138921082946
Current mitigation activation: 0
#############################
Total reward: 36.88649887568112
15.583267837762833 seconds in game passed.
Action: tensor([[[0.0118, 0.9211],
         [0.0029, 0.4939],
         [0.0009, 0.3282],
         [0.0016, 0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.88649887568112
15.608267838135362 seconds in game passed.
Action: tensor([[[0.0118, 0.9211],
         [0.0029, 0.4939],
         [0.0009, 0.3282],
         [0.0016, 0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.88649887568112
15.63326783850789 seconds in game passed.
Action: tensor([[[0.0118, 0.9211],
         [0.0029, 0.4939],
         [0.0009, 0.3282],
         [0.0016, 0.2394]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.88649887568112
+++++++++++++: 1.9570902207349234
15.65826783888042 seconds in game passed.
At 15.65826783888042 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1872e-03,  9.3227e-01],
         [-3.7263e-04,  5.0883e-01],
         [-2.1450e-03,  3.3350e-01],
         [-1.7666e-03,  2.4303e-01]]])
agent 0 action: VehicleControl(throttle=0.884150, steer=0.000054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9570902207349234
Current reward: 0.2880251316911211
Current mitigation activation: 0
#############################
Total reward: 37.17452400737224
15.683267839252949 seconds in game passed.
Action: tensor([[[ 1.1872e-03,  9.3227e-01],
         [-3.7263e-04,  5.0883e-01],
         [-2.1450e-03,  3.3350e-01],
         [-1.7666e-03,  2.4303e-01]]])
agent 0 action: VehicleControl(throttle=0.875069, steer=0.001376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.17452400737224
15.708267839625478 seconds in game passed.
Action: tensor([[[ 1.1872e-03,  9.3227e-01],
         [-3.7263e-04,  5.0883e-01],
         [-2.1450e-03,  3.3350e-01],
         [-1.7666e-03,  2.4303e-01]]])
agent 0 action: VehicleControl(throttle=0.846182, steer=0.001566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.17452400737224
15.733267839998007 seconds in game passed.
Action: tensor([[[ 1.1872e-03,  9.3227e-01],
         [-3.7263e-04,  5.0883e-01],
         [-2.1450e-03,  3.3350e-01],
         [-1.7666e-03,  2.4303e-01]]])
agent 0 action: VehicleControl(throttle=0.816957, steer=0.001756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.17452400737224
+++++++++++++: 1.8453477322779188
15.758267840370536 seconds in game passed.
At 15.758267840370536 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.3335e-03,  9.3578e-01],
         [-8.1078e-04,  5.1890e-01],
         [-2.8388e-03,  3.4023e-01],
         [-1.9984e-03,  2.4782e-01]]])
agent 0 action: VehicleControl(throttle=0.653514, steer=0.000031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8453477322779188
Current reward: 0.2972512757470557
Current mitigation activation: 0
#############################
Total reward: 37.4717752831193
15.783267840743065 seconds in game passed.
Action: tensor([[[-2.3335e-03,  9.3578e-01],
         [-8.1078e-04,  5.1890e-01],
         [-2.8388e-03,  3.4023e-01],
         [-1.9984e-03,  2.4782e-01]]])
agent 0 action: VehicleControl(throttle=0.636938, steer=0.000411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.4717752831193
15.808267841115594 seconds in game passed.
Action: tensor([[[-2.3335e-03,  9.3578e-01],
         [-8.1078e-04,  5.1890e-01],
         [-2.8388e-03,  3.4023e-01],
         [-1.9984e-03,  2.4782e-01]]])
agent 0 action: VehicleControl(throttle=0.606841, steer=0.000491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.4717752831193
15.833267841488123 seconds in game passed.
Action: tensor([[[-2.3335e-03,  9.3578e-01],
         [-8.1078e-04,  5.1890e-01],
         [-2.8388e-03,  3.4023e-01],
         [-1.9984e-03,  2.4782e-01]]])
agent 0 action: VehicleControl(throttle=0.578710, steer=0.000570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.4717752831193
+++++++++++++: 1.7430315296424974
15.858267841860652 seconds in game passed.
At 15.858267841860652 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0046,  0.9379],
         [-0.0016,  0.5206],
         [-0.0043,  0.3359],
         [-0.0043,  0.2430]]])
agent 0 action: VehicleControl(throttle=0.537455, steer=-0.000992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7430315296424974
Current reward: 0.3058242760676842
Current mitigation activation: 0
#############################
Total reward: 37.77759955918698
15.883267842233181 seconds in game passed.
Action: tensor([[[-0.0046,  0.9379],
         [-0.0016,  0.5206],
         [-0.0043,  0.3359],
         [-0.0043,  0.2430]]])
agent 0 action: VehicleControl(throttle=0.514058, steer=-0.000729, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.77759955918698
15.90826784260571 seconds in game passed.
Action: tensor([[[-0.0046,  0.9379],
         [-0.0016,  0.5206],
         [-0.0043,  0.3359],
         [-0.0043,  0.2430]]])
agent 0 action: VehicleControl(throttle=0.490519, steer=-0.000727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.77759955918698
15.933267842978239 seconds in game passed.
Action: tensor([[[-0.0046,  0.9379],
         [-0.0016,  0.5206],
         [-0.0043,  0.3359],
         [-0.0043,  0.2430]]])
agent 0 action: VehicleControl(throttle=0.468622, steer=-0.000725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.77759955918698
+++++++++++++: 1.6621834527930384
15.958267843350768 seconds in game passed.
At 15.958267843350768 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.8818e-04,  9.3962e-01],
         [-1.2895e-03,  5.2584e-01],
         [-4.6002e-03,  3.4064e-01],
         [-4.0724e-03,  2.4779e-01]]])
agent 0 action: VehicleControl(throttle=0.374195, steer=0.001264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6621834527930384
Current reward: 0.31227985975657047
Current mitigation activation: 0
#############################
Total reward: 38.08987941894355
15.983267843723297 seconds in game passed.
Action: tensor([[[-3.8818e-04,  9.3962e-01],
         [-1.2895e-03,  5.2584e-01],
         [-4.6002e-03,  3.4064e-01],
         [-4.0724e-03,  2.4779e-01]]])
agent 0 action: VehicleControl(throttle=0.355780, steer=0.000896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.08987941894355
16.008267844095826 seconds in game passed.
Action: tensor([[[-3.8818e-04,  9.3962e-01],
         [-1.2895e-03,  5.2584e-01],
         [-4.6002e-03,  3.4064e-01],
         [-4.0724e-03,  2.4779e-01]]])
agent 0 action: VehicleControl(throttle=0.343324, steer=0.000865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.08987941894355
16.033267844468355 seconds in game passed.
Action: tensor([[[-3.8818e-04,  9.3962e-01],
         [-1.2895e-03,  5.2584e-01],
         [-4.6002e-03,  3.4064e-01],
         [-4.0724e-03,  2.4779e-01]]])
agent 0 action: VehicleControl(throttle=0.335469, steer=0.000834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.08987941894355
+++++++++++++: 1.6048148507696247
16.058267844840884 seconds in game passed.
At 16.058267844840884 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.3882e-03,  9.4226e-01],
         [ 1.5510e-04,  5.4441e-01],
         [-4.6655e-03,  3.5575e-01],
         [-4.6359e-03,  2.6104e-01]]])
agent 0 action: VehicleControl(throttle=0.322465, steer=0.003552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6048148507696247
Current reward: 0.31603545323242976
Current mitigation activation: 0
#############################
Total reward: 38.405914872175984
16.083267845213413 seconds in game passed.
Action: tensor([[[ 3.3882e-03,  9.4226e-01],
         [ 1.5510e-04,  5.4441e-01],
         [-4.6655e-03,  3.5575e-01],
         [-4.6359e-03,  2.6104e-01]]])
agent 0 action: VehicleControl(throttle=0.309461, steer=0.003091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.405914872175984
16.108267845585942 seconds in game passed.
Action: tensor([[[ 3.3882e-03,  9.4226e-01],
         [ 1.5510e-04,  5.4441e-01],
         [-4.6655e-03,  3.5575e-01],
         [-4.6359e-03,  2.6104e-01]]])
agent 0 action: VehicleControl(throttle=0.296515, steer=0.003085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.405914872175984
16.13326784595847 seconds in game passed.
Action: tensor([[[ 3.3882e-03,  9.4226e-01],
         [ 1.5510e-04,  5.4441e-01],
         [-4.6655e-03,  3.5575e-01],
         [-4.6359e-03,  2.6104e-01]]])
agent 0 action: VehicleControl(throttle=0.283691, steer=0.003079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.405914872175984
+++++++++++++: 1.569268735717498
16.158267846331 seconds in game passed.
At 16.158267846331 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.6964e-04,  9.4339e-01],
         [ 2.4547e-03,  5.5981e-01],
         [-2.1114e-03,  3.7745e-01],
         [-2.7674e-03,  2.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003027, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.569268735717498
Current reward: 0.3170720250199686
Current mitigation activation: 0
#############################
Total reward: 38.72298689719595
16.18326784670353 seconds in game passed.
Action: tensor([[[-5.6964e-04,  9.4339e-01],
         [ 2.4547e-03,  5.5981e-01],
         [-2.1114e-03,  3.7745e-01],
         [-2.7674e-03,  2.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002985, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.72298689719595
16.20826784707606 seconds in game passed.
Action: tensor([[[-5.6964e-04,  9.4339e-01],
         [ 2.4547e-03,  5.5981e-01],
         [-2.1114e-03,  3.7745e-01],
         [-2.7674e-03,  2.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002941, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.72298689719595
16.233267847448587 seconds in game passed.
Action: tensor([[[-5.6964e-04,  9.4339e-01],
         [ 2.4547e-03,  5.5981e-01],
         [-2.1114e-03,  3.7745e-01],
         [-2.7674e-03,  2.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002898, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.72298689719595
+++++++++++++: 1.5564615011895155
16.258267847821116 seconds in game passed.
At 16.258267847821116 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.4462e-04,  9.4414e-01],
         [ 5.4315e-06,  5.8417e-01],
         [-6.1533e-03,  4.0443e-01],
         [-7.8393e-03,  3.1645e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001552, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5564615011895155
Current reward: 0.3152755963512222
Current mitigation activation: 0
#############################
Total reward: 39.03826249354717
16.283267848193645 seconds in game passed.
Action: tensor([[[ 7.4462e-04,  9.4414e-01],
         [ 5.4315e-06,  5.8417e-01],
         [-6.1533e-03,  4.0443e-01],
         [-7.8393e-03,  3.1645e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001644, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.03826249354717
16.308267848566175 seconds in game passed.
Action: tensor([[[ 7.4462e-04,  9.4414e-01],
         [ 5.4315e-06,  5.8417e-01],
         [-6.1533e-03,  4.0443e-01],
         [-7.8393e-03,  3.1645e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001531, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.03826249354717
16.333267848938704 seconds in game passed.
Action: tensor([[[ 7.4462e-04,  9.4414e-01],
         [ 5.4315e-06,  5.8417e-01],
         [-6.1533e-03,  4.0443e-01],
         [-7.8393e-03,  3.1645e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001418, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.03826249354717
+++++++++++++: 1.6295938768559706
16.358267849311233 seconds in game passed.
At 16.358267849311233 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0038,  0.9447],
         [ 0.0014,  0.6253],
         [-0.0077,  0.4469],
         [-0.0113,  0.3624]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003790, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6295938768559706
Current reward: 0.30386813199901624
Current mitigation activation: 0
#############################
Total reward: 39.34213062554619
16.38326784968376 seconds in game passed.
Action: tensor([[[ 0.0038,  0.9447],
         [ 0.0014,  0.6253],
         [-0.0077,  0.4469],
         [-0.0113,  0.3624]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003286, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.34213062554619
16.40826785005629 seconds in game passed.
Action: tensor([[[ 0.0038,  0.9447],
         [ 0.0014,  0.6253],
         [-0.0077,  0.4469],
         [-0.0113,  0.3624]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003193, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.34213062554619
16.43326785042882 seconds in game passed.
Action: tensor([[[ 0.0038,  0.9447],
         [ 0.0014,  0.6253],
         [-0.0077,  0.4469],
         [-0.0113,  0.3624]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003100, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.34213062554619
+++++++++++++: 1.8470029155205225
16.45826785080135 seconds in game passed.
At 16.45826785080135 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0037,  0.9475],
         [ 0.0025,  0.6515],
         [-0.0049,  0.4458],
         [-0.0065,  0.3552]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000134, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8470029155205225
Current reward: 0.28121633200297647
Current mitigation activation: 0
#############################
Total reward: 39.62334695754917
16.483267851173878 seconds in game passed.
Action: tensor([[[-0.0037,  0.9475],
         [ 0.0025,  0.6515],
         [-0.0049,  0.4458],
         [-0.0065,  0.3552]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000499, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.62334695754917
16.508267851546407 seconds in game passed.
Action: tensor([[[-0.0037,  0.9475],
         [ 0.0025,  0.6515],
         [-0.0049,  0.4458],
         [-0.0065,  0.3552]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000388, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.62334695754917
16.533267851918936 seconds in game passed.
Action: tensor([[[-0.0037,  0.9475],
         [ 0.0025,  0.6515],
         [-0.0049,  0.4458],
         [-0.0065,  0.3552]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000277, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.62334695754917
+++++++++++++: 2.1718475341728847
16.558267852291465 seconds in game passed.
At 16.558267852291465 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.9469],
         [ 0.0038,  0.6278],
         [-0.0017,  0.4096],
         [-0.0026,  0.3045]]])
agent 0 action: VehicleControl(throttle=0.076975, steer=0.001408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1718475341728847
Current reward: 0.2580331975394489
Current mitigation activation: 0
#############################
Total reward: 39.881380155088614
16.583267852663994 seconds in game passed.
Action: tensor([[[-0.0033,  0.9469],
         [ 0.0038,  0.6278],
         [-0.0017,  0.4096],
         [-0.0026,  0.3045]]])
agent 0 action: VehicleControl(throttle=0.066464, steer=0.001148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.881380155088614
16.608267853036523 seconds in game passed.
Action: tensor([[[-0.0033,  0.9469],
         [ 0.0038,  0.6278],
         [-0.0017,  0.4096],
         [-0.0026,  0.3045]]])
agent 0 action: VehicleControl(throttle=0.135632, steer=0.001087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.881380155088614
16.633267853409052 seconds in game passed.
Action: tensor([[[-0.0033,  0.9469],
         [ 0.0038,  0.6278],
         [-0.0017,  0.4096],
         [-0.0026,  0.3045]]])
agent 0 action: VehicleControl(throttle=0.178683, steer=0.001026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.881380155088614
+++++++++++++: 2.5986715403009204
16.65826785378158 seconds in game passed.
At 16.65826785378158 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.9464],
         [ 0.0018,  0.6134],
         [-0.0047,  0.3990],
         [-0.0058,  0.2944]]])
agent 0 action: VehicleControl(throttle=0.346052, steer=0.000172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5986715403009204
Current reward: 0.23812960217752177
Current mitigation activation: 0
#############################
Total reward: 40.11950975726614
16.68326785415411 seconds in game passed.
Action: tensor([[[-0.0022,  0.9464],
         [ 0.0018,  0.6134],
         [-0.0047,  0.3990],
         [-0.0058,  0.2944]]])
agent 0 action: VehicleControl(throttle=0.334146, steer=0.000315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.11950975726614
16.70826785452664 seconds in game passed.
Action: tensor([[[-0.0022,  0.9464],
         [ 0.0018,  0.6134],
         [-0.0047,  0.3990],
         [-0.0058,  0.2944]]])
agent 0 action: VehicleControl(throttle=0.331037, steer=0.000316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.11950975726614
16.733267854899168 seconds in game passed.
Action: tensor([[[-0.0022,  0.9464],
         [ 0.0018,  0.6134],
         [-0.0047,  0.3990],
         [-0.0058,  0.2944]]])
agent 0 action: VehicleControl(throttle=0.329394, steer=0.000317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.11950975726614
+++++++++++++: 2.793036446646162
16.758267855271697 seconds in game passed.
At 16.758267855271697 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0092, 0.9376],
         [0.0059, 0.5356],
         [0.0022, 0.3559],
         [0.0017, 0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.793036446646162
Current reward: 0.23420153508152217
Current mitigation activation: 0
#############################
Total reward: 40.35371129234766
16.783267855644226 seconds in game passed.
Action: tensor([[[0.0092, 0.9376],
         [0.0059, 0.5356],
         [0.0022, 0.3559],
         [0.0017, 0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.35371129234766
16.808267856016755 seconds in game passed.
Action: tensor([[[0.0092, 0.9376],
         [0.0059, 0.5356],
         [0.0022, 0.3559],
         [0.0017, 0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.35371129234766
16.833267856389284 seconds in game passed.
Action: tensor([[[0.0092, 0.9376],
         [0.0059, 0.5356],
         [0.0022, 0.3559],
         [0.0017, 0.2609]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.35371129234766
+++++++++++++: 2.9001423613138795
16.858267856761813 seconds in game passed.
At 16.858267856761813 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0141, 0.9177],
         [0.0059, 0.4954],
         [0.0025, 0.3327],
         [0.0020, 0.2447]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9001423613138795
Current reward: 0.23504155305502367
Current mitigation activation: 0
#############################
Total reward: 40.58875284540269
16.883267857134342 seconds in game passed.
Action: tensor([[[0.0141, 0.9177],
         [0.0059, 0.4954],
         [0.0025, 0.3327],
         [0.0020, 0.2447]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.58875284540269
16.90826785750687 seconds in game passed.
Action: tensor([[[0.0141, 0.9177],
         [0.0059, 0.4954],
         [0.0025, 0.3327],
         [0.0020, 0.2447]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.58875284540269
16.9332678578794 seconds in game passed.
Action: tensor([[[0.0141, 0.9177],
         [0.0059, 0.4954],
         [0.0025, 0.3327],
         [0.0020, 0.2447]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.58875284540269
+++++++++++++: 3.0605524080521613
16.95826785825193 seconds in game passed.
At 16.95826785825193 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0382e-02,  8.7020e-01],
         [ 3.2276e-03,  4.7112e-01],
         [ 4.0342e-04,  3.1998e-01],
         [-2.5953e-04,  2.3688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0605524080521613
Current reward: 0.23474229321528534
Current mitigation activation: 0
#############################
Total reward: 40.82349513861797
16.98326785862446 seconds in game passed.
Action: tensor([[[ 2.0382e-02,  8.7020e-01],
         [ 3.2276e-03,  4.7112e-01],
         [ 4.0342e-04,  3.1998e-01],
         [-2.5953e-04,  2.3688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.82349513861797
17.008267858996987 seconds in game passed.
Action: tensor([[[ 2.0382e-02,  8.7020e-01],
         [ 3.2276e-03,  4.7112e-01],
         [ 4.0342e-04,  3.1998e-01],
         [-2.5953e-04,  2.3688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010405, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.82349513861797
17.033267859369516 seconds in game passed.
Action: tensor([[[ 2.0382e-02,  8.7020e-01],
         [ 3.2276e-03,  4.7112e-01],
         [ 4.0342e-04,  3.1998e-01],
         [-2.5953e-04,  2.3688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.82349513861797
+++++++++++++: 3.0365741968531625
17.058267859742045 seconds in game passed.
At 17.058267859742045 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.4837e-02, 8.5462e-01],
         [3.3955e-03, 4.6886e-01],
         [8.0230e-04, 3.1915e-01],
         [4.3738e-04, 2.3650e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0365741968531625
Current reward: 0.24159863513714241
Current mitigation activation: 0
#############################
Total reward: 41.065093773755116
17.083267860114574 seconds in game passed.
Action: tensor([[[2.4837e-02, 8.5462e-01],
         [3.3955e-03, 4.6886e-01],
         [8.0230e-04, 3.1915e-01],
         [4.3738e-04, 2.3650e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.065093773755116
17.108267860487103 seconds in game passed.
Action: tensor([[[2.4837e-02, 8.5462e-01],
         [3.3955e-03, 4.6886e-01],
         [8.0230e-04, 3.1915e-01],
         [4.3738e-04, 2.3650e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.065093773755116
17.133267860859632 seconds in game passed.
Action: tensor([[[2.4837e-02, 8.5462e-01],
         [3.3955e-03, 4.6886e-01],
         [8.0230e-04, 3.1915e-01],
         [4.3738e-04, 2.3650e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.065093773755116
+++++++++++++: 2.920724172433529
17.15826786123216 seconds in game passed.
At 17.15826786123216 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.5718e-02,  8.5377e-01],
         [ 2.7622e-03,  4.6535e-01],
         [ 9.6023e-05,  3.1605e-01],
         [-3.0848e-04,  2.3416e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.920724172433529
Current reward: 0.25223265211683515
Current mitigation activation: 0
#############################
Total reward: 41.317326425871954
17.18326786160469 seconds in game passed.
Action: tensor([[[ 2.5718e-02,  8.5377e-01],
         [ 2.7622e-03,  4.6535e-01],
         [ 9.6023e-05,  3.1605e-01],
         [-3.0848e-04,  2.3416e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.317326425871954
17.20826786197722 seconds in game passed.
Action: tensor([[[ 2.5718e-02,  8.5377e-01],
         [ 2.7622e-03,  4.6535e-01],
         [ 9.6023e-05,  3.1605e-01],
         [-3.0848e-04,  2.3416e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.317326425871954
17.23326786234975 seconds in game passed.
Action: tensor([[[ 2.5718e-02,  8.5377e-01],
         [ 2.7622e-03,  4.6535e-01],
         [ 9.6023e-05,  3.1605e-01],
         [-3.0848e-04,  2.3416e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.012999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.317326425871954
+++++++++++++: 2.7781985550988315
17.258267862722278 seconds in game passed.
At 17.258267862722278 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0124,  0.7817],
         [-0.0011,  0.4319],
         [-0.0029,  0.2947],
         [-0.0035,  0.2198]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7781985550988315
Current reward: 0.26458157211547784
Current mitigation activation: 0
#############################
Total reward: 41.58190799798743
17.283267863094807 seconds in game passed.
Action: tensor([[[ 0.0124,  0.7817],
         [-0.0011,  0.4319],
         [-0.0029,  0.2947],
         [-0.0035,  0.2198]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.58190799798743
17.308267863467336 seconds in game passed.
Action: tensor([[[ 0.0124,  0.7817],
         [-0.0011,  0.4319],
         [-0.0029,  0.2947],
         [-0.0035,  0.2198]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.58190799798743
17.333267863839865 seconds in game passed.
Action: tensor([[[ 0.0124,  0.7817],
         [-0.0011,  0.4319],
         [-0.0029,  0.2947],
         [-0.0035,  0.2198]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.58190799798743
+++++++++++++: 2.6359864226264533
17.358267864212394 seconds in game passed.
At 17.358267864212394 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0167,  0.7948],
         [-0.0009,  0.4367],
         [-0.0034,  0.2962],
         [-0.0042,  0.2203]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6359864226264533
Current reward: 0.2776685764714971
Current mitigation activation: 0
#############################
Total reward: 41.85957657445893
17.383267864584923 seconds in game passed.
Action: tensor([[[ 0.0167,  0.7948],
         [-0.0009,  0.4367],
         [-0.0034,  0.2962],
         [-0.0042,  0.2203]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.85957657445893
17.408267864957452 seconds in game passed.
Action: tensor([[[ 0.0167,  0.7948],
         [-0.0009,  0.4367],
         [-0.0034,  0.2962],
         [-0.0042,  0.2203]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.85957657445893
17.43326786532998 seconds in game passed.
Action: tensor([[[ 0.0167,  0.7948],
         [-0.0009,  0.4367],
         [-0.0034,  0.2962],
         [-0.0042,  0.2203]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.85957657445893
+++++++++++++: 2.5045788995860137
17.45826786570251 seconds in game passed.
At 17.45826786570251 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0126,  0.7739],
         [-0.0019,  0.4227],
         [-0.0041,  0.2869],
         [-0.0046,  0.2153]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5045788995860137
Current reward: 0.2909716982324087
Current mitigation activation: 0
#############################
Total reward: 42.15054827269134
17.48326786607504 seconds in game passed.
Action: tensor([[[ 0.0126,  0.7739],
         [-0.0019,  0.4227],
         [-0.0041,  0.2869],
         [-0.0046,  0.2153]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.15054827269134
17.508267866447568 seconds in game passed.
Action: tensor([[[ 0.0126,  0.7739],
         [-0.0019,  0.4227],
         [-0.0041,  0.2869],
         [-0.0046,  0.2153]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005957, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.15054827269134
17.533267866820097 seconds in game passed.
Action: tensor([[[ 0.0126,  0.7739],
         [-0.0019,  0.4227],
         [-0.0041,  0.2869],
         [-0.0046,  0.2153]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.15054827269134
+++++++++++++: 2.386225117535363
17.558267867192626 seconds in game passed.
At 17.558267867192626 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0118,  0.7705],
         [-0.0037,  0.4183],
         [-0.0066,  0.2824],
         [-0.0078,  0.2115]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.386225117535363
Current reward: 0.30423386644120043
Current mitigation activation: 0
#############################
Total reward: 42.45478213913254
17.583267867565155 seconds in game passed.
Action: tensor([[[ 0.0118,  0.7705],
         [-0.0037,  0.4183],
         [-0.0066,  0.2824],
         [-0.0078,  0.2115]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.45478213913254
17.608267867937684 seconds in game passed.
Action: tensor([[[ 0.0118,  0.7705],
         [-0.0037,  0.4183],
         [-0.0066,  0.2824],
         [-0.0078,  0.2115]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.45478213913254
17.633267868310213 seconds in game passed.
Action: tensor([[[ 0.0118,  0.7705],
         [-0.0037,  0.4183],
         [-0.0066,  0.2824],
         [-0.0078,  0.2115]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.45478213913254
+++++++++++++: 2.280280767816092
17.658267868682742 seconds in game passed.
At 17.658267868682742 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.7721],
         [-0.0056,  0.4093],
         [-0.0083,  0.2734],
         [-0.0094,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.280280767816092
Current reward: 0.3173201875338497
Current mitigation activation: 0
#############################
Total reward: 42.77210232666639
17.68326786905527 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7721],
         [-0.0056,  0.4093],
         [-0.0083,  0.2734],
         [-0.0094,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.77210232666639
17.7082678694278 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7721],
         [-0.0056,  0.4093],
         [-0.0083,  0.2734],
         [-0.0094,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.77210232666639
17.73326786980033 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7721],
         [-0.0056,  0.4093],
         [-0.0083,  0.2734],
         [-0.0094,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.77210232666639
+++++++++++++: 2.185469085098996
17.75826787017286 seconds in game passed.
At 17.75826787017286 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.0526e-04,  7.7693e-01],
         [-9.9832e-03,  4.0240e-01],
         [-1.2603e-02,  2.6927e-01],
         [-1.3378e-02,  2.0253e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.185469085098996
Current reward: 0.33015034016467204
Current mitigation activation: 0
#############################
Total reward: 43.10225266683106
17.783267870545387 seconds in game passed.
Action: tensor([[[ 4.0526e-04,  7.7693e-01],
         [-9.9832e-03,  4.0240e-01],
         [-1.2603e-02,  2.6927e-01],
         [-1.3378e-02,  2.0253e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.10225266683106
17.808267870917916 seconds in game passed.
Action: tensor([[[ 4.0526e-04,  7.7693e-01],
         [-9.9832e-03,  4.0240e-01],
         [-1.2603e-02,  2.6927e-01],
         [-1.3378e-02,  2.0253e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.10225266683106
17.833267871290445 seconds in game passed.
Action: tensor([[[ 4.0526e-04,  7.7693e-01],
         [-9.9832e-03,  4.0240e-01],
         [-1.2603e-02,  2.6927e-01],
         [-1.3378e-02,  2.0253e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.10225266683106
+++++++++++++: 2.1002452395763433
17.858267871662974 seconds in game passed.
At 17.858267871662974 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0031,  0.7477],
         [-0.0129,  0.3943],
         [-0.0153,  0.2673],
         [-0.0159,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1002452395763433
Current reward: 0.3426795145440803
Current mitigation activation: 0
#############################
Total reward: 43.444932181375144
17.883267872035503 seconds in game passed.
Action: tensor([[[-0.0031,  0.7477],
         [-0.0129,  0.3943],
         [-0.0153,  0.2673],
         [-0.0159,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.444932181375144
17.908267872408032 seconds in game passed.
Action: tensor([[[-0.0031,  0.7477],
         [-0.0129,  0.3943],
         [-0.0153,  0.2673],
         [-0.0159,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.444932181375144
17.93326787278056 seconds in game passed.
Action: tensor([[[-0.0031,  0.7477],
         [-0.0129,  0.3943],
         [-0.0153,  0.2673],
         [-0.0159,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.444932181375144
+++++++++++++: 2.0232507708077803
17.95826787315309 seconds in game passed.
At 17.95826787315309 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0062,  0.7396],
         [-0.0184,  0.3870],
         [-0.0216,  0.2622],
         [-0.0228,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0232507708077803
Current reward: 0.35488584292752307
Current mitigation activation: 0
#############################
Total reward: 43.79981802430267
17.98326787352562 seconds in game passed.
Action: tensor([[[-0.0062,  0.7396],
         [-0.0184,  0.3870],
         [-0.0216,  0.2622],
         [-0.0228,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012705, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.79981802430267
18.00826787389815 seconds in game passed.
Action: tensor([[[-0.0062,  0.7396],
         [-0.0184,  0.3870],
         [-0.0216,  0.2622],
         [-0.0228,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.79981802430267
18.033267874270678 seconds in game passed.
Action: tensor([[[-0.0062,  0.7396],
         [-0.0184,  0.3870],
         [-0.0216,  0.2622],
         [-0.0228,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.79981802430267
+++++++++++++: 1.9532824419966353
18.058267874643207 seconds in game passed.
At 18.058267874643207 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.7493],
         [-0.0126,  0.3862],
         [-0.0159,  0.2594],
         [-0.0173,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9532824419966353
Current reward: 0.36675541744204654
Current mitigation activation: 0
#############################
Total reward: 44.16657344174471
18.083267875015736 seconds in game passed.
Action: tensor([[[-0.0022,  0.7493],
         [-0.0126,  0.3862],
         [-0.0159,  0.2594],
         [-0.0173,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.16657344174471
18.108267875388265 seconds in game passed.
Action: tensor([[[-0.0022,  0.7493],
         [-0.0126,  0.3862],
         [-0.0159,  0.2594],
         [-0.0173,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.16657344174471
18.133267875760794 seconds in game passed.
Action: tensor([[[-0.0022,  0.7493],
         [-0.0126,  0.3862],
         [-0.0159,  0.2594],
         [-0.0173,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.16657344174471
+++++++++++++: 1.889290682339311
18.158267876133323 seconds in game passed.
At 18.158267876133323 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0053,  0.7528],
         [-0.0155,  0.3851],
         [-0.0187,  0.2587],
         [-0.0204,  0.1945]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.889290682339311
Current reward: 0.3782989874162792
Current mitigation activation: 0
#############################
Total reward: 44.54487242916099
18.18326787650585 seconds in game passed.
Action: tensor([[[-0.0053,  0.7528],
         [-0.0155,  0.3851],
         [-0.0187,  0.2587],
         [-0.0204,  0.1945]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012757, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.54487242916099
18.20826787687838 seconds in game passed.
Action: tensor([[[-0.0053,  0.7528],
         [-0.0155,  0.3851],
         [-0.0187,  0.2587],
         [-0.0204,  0.1945]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.54487242916099
18.23326787725091 seconds in game passed.
Action: tensor([[[-0.0053,  0.7528],
         [-0.0155,  0.3851],
         [-0.0187,  0.2587],
         [-0.0204,  0.1945]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.54487242916099
+++++++++++++: 1.830409547059451
18.25826787762344 seconds in game passed.
At 18.25826787762344 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.7527],
         [-0.0127,  0.3848],
         [-0.0155,  0.2568],
         [-0.0166,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010010, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.830409547059451
Current reward: 0.3895108419245718
Current mitigation activation: 0
#############################
Total reward: 44.93438327108556
18.283267877995968 seconds in game passed.
Action: tensor([[[-0.0018,  0.7527],
         [-0.0127,  0.3848],
         [-0.0155,  0.2568],
         [-0.0166,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.93438327108556
18.308267878368497 seconds in game passed.
Action: tensor([[[-0.0018,  0.7527],
         [-0.0127,  0.3848],
         [-0.0155,  0.2568],
         [-0.0166,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.93438327108556
18.333267878741026 seconds in game passed.
Action: tensor([[[-0.0018,  0.7527],
         [-0.0127,  0.3848],
         [-0.0155,  0.2568],
         [-0.0166,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.93438327108556
+++++++++++++: 1.7891972687107451
18.358267879113555 seconds in game passed.
At 18.358267879113555 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.7143],
         [-0.0046,  0.3744],
         [-0.0060,  0.2525],
         [-0.0067,  0.1907]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004746, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7891972687107451
Current reward: 0.39873590394096725
Current mitigation activation: 0
#############################
Total reward: 45.333119175026525
18.383267879486084 seconds in game passed.
Action: tensor([[[-0.0013,  0.7143],
         [-0.0046,  0.3744],
         [-0.0060,  0.2525],
         [-0.0067,  0.1907]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.333119175026525
18.408267879858613 seconds in game passed.
Action: tensor([[[-0.0013,  0.7143],
         [-0.0046,  0.3744],
         [-0.0060,  0.2525],
         [-0.0067,  0.1907]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.333119175026525
18.433267880231142 seconds in game passed.
Action: tensor([[[-0.0013,  0.7143],
         [-0.0046,  0.3744],
         [-0.0060,  0.2525],
         [-0.0067,  0.1907]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.333119175026525
+++++++++++++: 1.8056807929000283
18.45826788060367 seconds in game passed.
At 18.45826788060367 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.6761],
         [-0.0055,  0.3646],
         [-0.0066,  0.2514],
         [-0.0074,  0.1923]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8056807929000283
Current reward: 0.4007867812306642
Current mitigation activation: 0
#############################
Total reward: 45.73390595625719
18.4832678809762 seconds in game passed.
Action: tensor([[[-0.0027,  0.6761],
         [-0.0055,  0.3646],
         [-0.0066,  0.2514],
         [-0.0074,  0.1923]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.73390595625719
18.50826788134873 seconds in game passed.
Action: tensor([[[-0.0027,  0.6761],
         [-0.0055,  0.3646],
         [-0.0066,  0.2514],
         [-0.0074,  0.1923]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.73390595625719
18.533267881721258 seconds in game passed.
Action: tensor([[[-0.0027,  0.6761],
         [-0.0055,  0.3646],
         [-0.0066,  0.2514],
         [-0.0074,  0.1923]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.73390595625719
+++++++++++++: 1.829667469658861
18.558267882093787 seconds in game passed.
At 18.558267882093787 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.6700],
         [-0.0035,  0.3660],
         [-0.0047,  0.2528],
         [-0.0055,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.829667469658861
Current reward: 0.4023400944738511
Current mitigation activation: 0
#############################
Total reward: 46.13624605073104
18.583267882466316 seconds in game passed.
Action: tensor([[[-0.0008,  0.6700],
         [-0.0035,  0.3660],
         [-0.0047,  0.2528],
         [-0.0055,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005760, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.13624605073104
18.608267882838845 seconds in game passed.
Action: tensor([[[-0.0008,  0.6700],
         [-0.0035,  0.3660],
         [-0.0047,  0.2528],
         [-0.0055,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.13624605073104
18.633267883211374 seconds in game passed.
Action: tensor([[[-0.0008,  0.6700],
         [-0.0035,  0.3660],
         [-0.0047,  0.2528],
         [-0.0055,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.13624605073104
+++++++++++++: 1.8560311429883516
18.658267883583903 seconds in game passed.
At 18.658267883583903 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0034,  0.6681],
         [-0.0013,  0.3647],
         [-0.0020,  0.2519],
         [-0.0028,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8560311429883516
Current reward: 0.4040824814950146
Current mitigation activation: 0
#############################
Total reward: 46.540328532226056
18.683267883956432 seconds in game passed.
Action: tensor([[[ 0.0034,  0.6681],
         [-0.0013,  0.3647],
         [-0.0020,  0.2519],
         [-0.0028,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.540328532226056
18.70826788432896 seconds in game passed.
Action: tensor([[[ 0.0034,  0.6681],
         [-0.0013,  0.3647],
         [-0.0020,  0.2519],
         [-0.0028,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.540328532226056
18.73326788470149 seconds in game passed.
Action: tensor([[[ 0.0034,  0.6681],
         [-0.0013,  0.3647],
         [-0.0020,  0.2519],
         [-0.0028,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003011, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.540328532226056
+++++++++++++: 1.8847477934828663
18.75826788507402 seconds in game passed.
At 18.75826788507402 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0045, 0.6529],
         [0.0023, 0.3548],
         [0.0023, 0.2437],
         [0.0016, 0.1865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000128, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8847477934828663
Current reward: 0.4060150355384068
Current mitigation activation: 0
#############################
Total reward: 46.946343567764465
18.78326788544655 seconds in game passed.
Action: tensor([[[0.0045, 0.6529],
         [0.0023, 0.3548],
         [0.0023, 0.2437],
         [0.0016, 0.1865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.946343567764465
18.808267885819077 seconds in game passed.
Action: tensor([[[0.0045, 0.6529],
         [0.0023, 0.3548],
         [0.0023, 0.2437],
         [0.0016, 0.1865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.946343567764465
18.833267886191607 seconds in game passed.
Action: tensor([[[0.0045, 0.6529],
         [0.0023, 0.3548],
         [0.0023, 0.2437],
         [0.0016, 0.1865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000038, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.946343567764465
+++++++++++++: 1.9030486714960075
18.858267886564136 seconds in game passed.
At 18.858267886564136 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0057, 0.6469],
         [0.0036, 0.3433],
         [0.0034, 0.2343],
         [0.0027, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9030486714960075
Current reward: 0.4096127379078246
Current mitigation activation: 0
#############################
Total reward: 47.35595630567229
18.883267886936665 seconds in game passed.
Action: tensor([[[0.0057, 0.6469],
         [0.0036, 0.3433],
         [0.0034, 0.2343],
         [0.0027, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.35595630567229
18.908267887309194 seconds in game passed.
Action: tensor([[[0.0057, 0.6469],
         [0.0036, 0.3433],
         [0.0034, 0.2343],
         [0.0027, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001682, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.35595630567229
18.933267887681723 seconds in game passed.
Action: tensor([[[0.0057, 0.6469],
         [0.0036, 0.3433],
         [0.0034, 0.2343],
         [0.0027, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.35595630567229
+++++++++++++: 1.8350865326651418
18.95826788805425 seconds in game passed.
At 18.95826788805425 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6291],
         [0.0031, 0.3373],
         [0.0033, 0.2315],
         [0.0029, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000975, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8350865326651418
Current reward: 0.42399666034697403
Current mitigation activation: 0
#############################
Total reward: 47.77995296601926
18.98326788842678 seconds in game passed.
Action: tensor([[[0.0039, 0.6291],
         [0.0031, 0.3373],
         [0.0033, 0.2315],
         [0.0029, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.77995296601926
19.00826788879931 seconds in game passed.
Action: tensor([[[0.0039, 0.6291],
         [0.0031, 0.3373],
         [0.0033, 0.2315],
         [0.0029, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.77995296601926
19.03326788917184 seconds in game passed.
Action: tensor([[[0.0039, 0.6291],
         [0.0031, 0.3373],
         [0.0033, 0.2315],
         [0.0029, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.77995296601926
+++++++++++++: 1.7676449800475078
19.058267889544368 seconds in game passed.
At 19.058267889544368 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.6463],
         [0.0026, 0.3442],
         [0.0026, 0.2361],
         [0.0020, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7676449800475078
Current reward: 0.43850462973016424
Current mitigation activation: 0
#############################
Total reward: 48.21845759574942
19.083267889916897 seconds in game passed.
Action: tensor([[[0.0023, 0.6463],
         [0.0026, 0.3442],
         [0.0026, 0.2361],
         [0.0020, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.21845759574942
19.108267890289426 seconds in game passed.
Action: tensor([[[0.0023, 0.6463],
         [0.0026, 0.3442],
         [0.0026, 0.2361],
         [0.0020, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.21845759574942
19.133267890661955 seconds in game passed.
Action: tensor([[[0.0023, 0.6463],
         [0.0026, 0.3442],
         [0.0026, 0.2361],
         [0.0020, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.21845759574942
+++++++++++++: 1.7123724663285786
19.158267891034484 seconds in game passed.
At 19.158267891034484 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6489],
         [0.0026, 0.3457],
         [0.0019, 0.2369],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7123724663285786
Current reward: 0.4513827728560565
Current mitigation activation: 0
#############################
Total reward: 48.66984036860548
19.183267891407013 seconds in game passed.
Action: tensor([[[0.0040, 0.6489],
         [0.0026, 0.3457],
         [0.0019, 0.2369],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.66984036860548
19.208267891779542 seconds in game passed.
Action: tensor([[[0.0040, 0.6489],
         [0.0026, 0.3457],
         [0.0019, 0.2369],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.896901, steer=0.002602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.66984036860548
19.23326789215207 seconds in game passed.
Action: tensor([[[0.0040, 0.6489],
         [0.0026, 0.3457],
         [0.0019, 0.2369],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.854380, steer=0.002782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.66984036860548
+++++++++++++: 1.6646432782700928
19.2582678925246 seconds in game passed.
At 19.2582678925246 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.6568],
         [-0.0010,  0.3471],
         [-0.0020,  0.2370],
         [-0.0028,  0.1815]]])
agent 0 action: VehicleControl(throttle=0.838262, steer=-0.000503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6646432782700928
Current reward: 0.4631292531261654
Current mitigation activation: 0
#############################
Total reward: 49.13296962173164
19.28326789289713 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6568],
         [-0.0010,  0.3471],
         [-0.0020,  0.2370],
         [-0.0028,  0.1815]]])
agent 0 action: VehicleControl(throttle=0.794318, steer=0.000171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.13296962173164
19.308267893269658 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6568],
         [-0.0010,  0.3471],
         [-0.0020,  0.2370],
         [-0.0028,  0.1815]]])
agent 0 action: VehicleControl(throttle=0.754038, steer=0.000279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.13296962173164
19.333267893642187 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6568],
         [-0.0010,  0.3471],
         [-0.0020,  0.2370],
         [-0.0028,  0.1815]]])
agent 0 action: VehicleControl(throttle=0.714310, steer=0.000388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.13296962173164
+++++++++++++: 1.6223701712931455
19.358267894014716 seconds in game passed.
At 19.358267894014716 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.8253e-04,  6.7401e-01],
         [-1.0909e-03,  3.5028e-01],
         [-1.7775e-03,  2.3763e-01],
         [-2.2474e-03,  1.8203e-01]]])
agent 0 action: VehicleControl(throttle=0.725415, steer=-0.000314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6223701712931455
Current reward: 0.47396173665672375
Current mitigation activation: 0
#############################
Total reward: 49.606931358388366
19.383267894387245 seconds in game passed.
Action: tensor([[[ 4.8253e-04,  6.7401e-01],
         [-1.0909e-03,  3.5028e-01],
         [-1.7775e-03,  2.3763e-01],
         [-2.2474e-03,  1.8203e-01]]])
agent 0 action: VehicleControl(throttle=0.683041, steer=-0.000157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.606931358388366
19.408267894759774 seconds in game passed.
Action: tensor([[[ 4.8253e-04,  6.7401e-01],
         [-1.0909e-03,  3.5028e-01],
         [-1.7775e-03,  2.3763e-01],
         [-2.2474e-03,  1.8203e-01]]])
agent 0 action: VehicleControl(throttle=0.647246, steer=-0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.606931358388366
19.433267895132303 seconds in game passed.
Action: tensor([[[ 4.8253e-04,  6.7401e-01],
         [-1.0909e-03,  3.5028e-01],
         [-1.7775e-03,  2.3763e-01],
         [-2.2474e-03,  1.8203e-01]]])
agent 0 action: VehicleControl(throttle=0.612592, steer=-0.000089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.606931358388366
+++++++++++++: 1.5876997559508652
19.458267895504832 seconds in game passed.
At 19.458267895504832 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.5020e-04,  6.6196e-01],
         [-1.0981e-03,  3.4562e-01],
         [-1.5041e-03,  2.3451e-01],
         [-1.6236e-03,  1.7970e-01]]])
agent 0 action: VehicleControl(throttle=0.624950, steer=-0.000489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5876997559508652
Current reward: 0.48341600467075285
Current mitigation activation: 0
#############################
Total reward: 50.09034736305912
19.48326789587736 seconds in game passed.
Action: tensor([[[-6.5020e-04,  6.6196e-01],
         [-1.0981e-03,  3.4562e-01],
         [-1.5041e-03,  2.3451e-01],
         [-1.6236e-03,  1.7970e-01]]])
agent 0 action: VehicleControl(throttle=0.589374, steer=-0.000373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.09034736305912
19.50826789624989 seconds in game passed.
Action: tensor([[[-6.5020e-04,  6.6196e-01],
         [-1.0981e-03,  3.4562e-01],
         [-1.5041e-03,  2.3451e-01],
         [-1.6236e-03,  1.7970e-01]]])
agent 0 action: VehicleControl(throttle=0.560243, steer=-0.000331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.09034736305912
19.53326789662242 seconds in game passed.
Action: tensor([[[-6.5020e-04,  6.6196e-01],
         [-1.0981e-03,  3.4562e-01],
         [-1.5041e-03,  2.3451e-01],
         [-1.6236e-03,  1.7970e-01]]])
agent 0 action: VehicleControl(throttle=0.532546, steer=-0.000289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.09034736305912
+++++++++++++: 1.5631445297079598
19.55826789699495 seconds in game passed.
At 19.55826789699495 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6372],
         [0.0021, 0.3395],
         [0.0021, 0.2328],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.481181, steer=0.003191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5631445297079598
Current reward: 0.4909580806359096
Current mitigation activation: 0
#############################
Total reward: 50.58130544369503
19.583267897367477 seconds in game passed.
Action: tensor([[[0.0020, 0.6372],
         [0.0021, 0.3395],
         [0.0021, 0.2328],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.460397, steer=0.002675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.58130544369503
19.608267897740006 seconds in game passed.
Action: tensor([[[0.0020, 0.6372],
         [0.0021, 0.3395],
         [0.0021, 0.2328],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.438745, steer=0.002730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.58130544369503
19.633267898112535 seconds in game passed.
Action: tensor([[[0.0020, 0.6372],
         [0.0021, 0.3395],
         [0.0021, 0.2328],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.419219, steer=0.002785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.58130544369503
+++++++++++++: 1.5495075984123388
19.658267898485065 seconds in game passed.
At 19.658267898485065 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0043, 0.6384],
         [0.0021, 0.3441],
         [0.0018, 0.2375],
         [0.0013, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.272100, steer=0.003694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5495075984123388
Current reward: 0.4964103413466475
Current mitigation activation: 0
#############################
Total reward: 51.077715785041676
19.683267898857594 seconds in game passed.
Action: tensor([[[0.0043, 0.6384],
         [0.0021, 0.3441],
         [0.0018, 0.2375],
         [0.0013, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.277003, steer=0.003577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.077715785041676
19.708267899230123 seconds in game passed.
Action: tensor([[[0.0043, 0.6384],
         [0.0021, 0.3441],
         [0.0018, 0.2375],
         [0.0013, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.267041, steer=0.003606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.077715785041676
19.73326789960265 seconds in game passed.
Action: tensor([[[0.0043, 0.6384],
         [0.0021, 0.3441],
         [0.0018, 0.2375],
         [0.0013, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.257064, steer=0.003636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.077715785041676
+++++++++++++: 1.5484564523710915
19.75826789997518 seconds in game passed.
At 19.75826789997518 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0044, 0.6282],
         [0.0028, 0.3360],
         [0.0029, 0.2310],
         [0.0026, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.394256, steer=0.004157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5484564523710915
Current reward: 0.49951231988540334
Current mitigation activation: 0
#############################
Total reward: 51.57722810492708
19.78326790034771 seconds in game passed.
Action: tensor([[[0.0044, 0.6282],
         [0.0028, 0.3360],
         [0.0029, 0.2310],
         [0.0026, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.372638, steer=0.004074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.57722810492708
19.80826790072024 seconds in game passed.
Action: tensor([[[0.0044, 0.6282],
         [0.0028, 0.3360],
         [0.0029, 0.2310],
         [0.0026, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.368649, steer=0.004077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.57722810492708
19.833267901092768 seconds in game passed.
Action: tensor([[[0.0044, 0.6282],
         [0.0028, 0.3360],
         [0.0029, 0.2310],
         [0.0026, 0.1772]]])
agent 0 action: VehicleControl(throttle=0.365605, steer=0.004080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.57722810492708
+++++++++++++: 1.5622227945893934
19.858267901465297 seconds in game passed.
At 19.858267901465297 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.2964e-03,  6.3179e-01],
         [-2.9107e-04,  3.3617e-01],
         [-3.6737e-04,  2.3207e-01],
         [-3.7985e-04,  1.7875e-01]]])
agent 0 action: VehicleControl(throttle=0.389488, steer=0.001362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5622227945893934
Current reward: 0.5000150265118214
Current mitigation activation: 0
#############################
Total reward: 52.0772431314389
19.883267901837826 seconds in game passed.
Action: tensor([[[ 3.2964e-03,  6.3179e-01],
         [-2.9107e-04,  3.3617e-01],
         [-3.6737e-04,  2.3207e-01],
         [-3.7985e-04,  1.7875e-01]]])
agent 0 action: VehicleControl(throttle=0.382932, steer=0.001769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.0772431314389
19.908267902210355 seconds in game passed.
Action: tensor([[[ 3.2964e-03,  6.3179e-01],
         [-2.9107e-04,  3.3617e-01],
         [-3.6737e-04,  2.3207e-01],
         [-3.7985e-04,  1.7875e-01]]])
agent 0 action: VehicleControl(throttle=0.380592, steer=0.001729, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.0772431314389
19.933267902582884 seconds in game passed.
Action: tensor([[[ 3.2964e-03,  6.3179e-01],
         [-2.9107e-04,  3.3617e-01],
         [-3.6737e-04,  2.3207e-01],
         [-3.7985e-04,  1.7875e-01]]])
agent 0 action: VehicleControl(throttle=0.379147, steer=0.001689, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.0772431314389
+++++++++++++: 1.5844734459253371
19.958267902955413 seconds in game passed.
At 19.958267902955413 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.1726e-03,  6.1995e-01],
         [-2.9927e-04,  3.3560e-01],
         [-8.5798e-04,  2.3193e-01],
         [-1.2672e-03,  1.7888e-01]]])
agent 0 action: VehicleControl(throttle=0.279413, steer=0.001620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5844734459253371
Current reward: 0.49939549583791565
Current mitigation activation: 0
#############################
Total reward: 52.576638627276814
19.983267903327942 seconds in game passed.
Action: tensor([[[ 3.1726e-03,  6.1995e-01],
         [-2.9927e-04,  3.3560e-01],
         [-8.5798e-04,  2.3193e-01],
         [-1.2672e-03,  1.7888e-01]]])
agent 0 action: VehicleControl(throttle=0.288847, steer=0.001597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.576638627276814
20.00826790370047 seconds in game passed.
Action: tensor([[[ 3.1726e-03,  6.1995e-01],
         [-2.9927e-04,  3.3560e-01],
         [-8.5798e-04,  2.3193e-01],
         [-1.2672e-03,  1.7888e-01]]])
agent 0 action: VehicleControl(throttle=0.288981, steer=0.001568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.576638627276814
20.033267904073 seconds in game passed.
Action: tensor([[[ 3.1726e-03,  6.1995e-01],
         [-2.9927e-04,  3.3560e-01],
         [-8.5798e-04,  2.3193e-01],
         [-1.2672e-03,  1.7888e-01]]])
agent 0 action: VehicleControl(throttle=0.290981, steer=0.001539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.576638627276814
+++++++++++++: 1.6111299082966897
20.05826790444553 seconds in game passed.
At 20.05826790444553 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6192],
         [-0.0037,  0.3348],
         [-0.0042,  0.2305],
         [-0.0045,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.313933, steer=-0.002736, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6111299082966897
Current reward: 0.49856911772383183
Current mitigation activation: 0
#############################
Total reward: 53.07520774500065
20.083267904818058 seconds in game passed.
Action: tensor([[[-0.0012,  0.6192],
         [-0.0037,  0.3348],
         [-0.0042,  0.2305],
         [-0.0045,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.317736, steer=-0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.07520774500065
20.108267905190587 seconds in game passed.
Action: tensor([[[-0.0012,  0.6192],
         [-0.0037,  0.3348],
         [-0.0042,  0.2305],
         [-0.0045,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.324674, steer=-0.002159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.07520774500065
20.133267905563116 seconds in game passed.
Action: tensor([[[-0.0012,  0.6192],
         [-0.0037,  0.3348],
         [-0.0042,  0.2305],
         [-0.0045,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.332475, steer=-0.002222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.07520774500065
+++++++++++++: 1.6441278204444032
20.158267905935645 seconds in game passed.
At 20.158267905935645 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0029,  0.6276],
         [-0.0060,  0.3330],
         [-0.0069,  0.2272],
         [-0.0075,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.490017, steer=-0.004706, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6441278204444032
Current reward: 0.4972688390139002
Current mitigation activation: 0
#############################
Total reward: 53.572476584014545
20.183267906308174 seconds in game passed.
Action: tensor([[[-0.0029,  0.6276],
         [-0.0060,  0.3330],
         [-0.0069,  0.2272],
         [-0.0075,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.485406, steer=-0.004402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.572476584014545
20.208267906680703 seconds in game passed.
Action: tensor([[[-0.0029,  0.6276],
         [-0.0060,  0.3330],
         [-0.0069,  0.2272],
         [-0.0075,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.496898, steer=-0.004497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.572476584014545
20.233267907053232 seconds in game passed.
Action: tensor([[[-0.0029,  0.6276],
         [-0.0060,  0.3330],
         [-0.0069,  0.2272],
         [-0.0075,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.507424, steer=-0.004591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.572476584014545
+++++++++++++: 1.6814409055161403
20.25826790742576 seconds in game passed.
At 20.25826790742576 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6330],
         [-0.0039,  0.3342],
         [-0.0045,  0.2278],
         [-0.0049,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.530800, steer=-0.002671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6814409055161403
Current reward: 0.49595706639377424
Current mitigation activation: 0
#############################
Total reward: 54.068433650408316
20.28326790779829 seconds in game passed.
Action: tensor([[[-0.0020,  0.6330],
         [-0.0039,  0.3342],
         [-0.0045,  0.2278],
         [-0.0049,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.538087, steer=-0.003037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.068433650408316
20.30826790817082 seconds in game passed.
Action: tensor([[[-0.0020,  0.6330],
         [-0.0039,  0.3342],
         [-0.0045,  0.2278],
         [-0.0049,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.546062, steer=-0.003075, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.068433650408316
20.33326790854335 seconds in game passed.
Action: tensor([[[-0.0020,  0.6330],
         [-0.0039,  0.3342],
         [-0.0045,  0.2278],
         [-0.0049,  0.1750]]])
agent 0 action: VehicleControl(throttle=0.553199, steer=-0.003114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.068433650408316
+++++++++++++: 1.7158214254252866
20.358267908915877 seconds in game passed.
At 20.358267908915877 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1811e-03,  6.1882e-01],
         [-5.5082e-04,  3.3174e-01],
         [-1.1208e-03,  2.2830e-01],
         [-1.8830e-03,  1.7549e-01]]])
agent 0 action: VehicleControl(throttle=0.499642, steer=0.000561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7158214254252866
Current reward: 0.4958718236042514
Current mitigation activation: 0
#############################
Total reward: 54.56430547401257
20.383267909288406 seconds in game passed.
Action: tensor([[[ 1.1811e-03,  6.1882e-01],
         [-5.5082e-04,  3.3174e-01],
         [-1.1208e-03,  2.2830e-01],
         [-1.8830e-03,  1.7549e-01]]])
agent 0 action: VehicleControl(throttle=0.508463, steer=-0.000043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.56430547401257
20.408267909660935 seconds in game passed.
Action: tensor([[[ 1.1811e-03,  6.1882e-01],
         [-5.5082e-04,  3.3174e-01],
         [-1.1208e-03,  2.2830e-01],
         [-1.8830e-03,  1.7549e-01]]])
agent 0 action: VehicleControl(throttle=0.511566, steer=-0.000036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.56430547401257
20.433267910033464 seconds in game passed.
Action: tensor([[[ 1.1811e-03,  6.1882e-01],
         [-5.5082e-04,  3.3174e-01],
         [-1.1208e-03,  2.2830e-01],
         [-1.8830e-03,  1.7549e-01]]])
agent 0 action: VehicleControl(throttle=0.515018, steer=-0.000029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.56430547401257
+++++++++++++: 1.7429558562640033
20.458267910405993 seconds in game passed.
At 20.458267910405993 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0045, 0.6243],
         [0.0031, 0.3369],
         [0.0027, 0.2319],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.393980, steer=0.004036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7429558562640033
Current reward: 0.497543548821634
Current mitigation activation: 0
#############################
Total reward: 55.0618490228342
20.483267910778522 seconds in game passed.
Action: tensor([[[0.0045, 0.6243],
         [0.0031, 0.3369],
         [0.0027, 0.2319],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.409384, steer=0.003421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.0618490228342
20.50826791115105 seconds in game passed.
Action: tensor([[[0.0045, 0.6243],
         [0.0031, 0.3369],
         [0.0027, 0.2319],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.411926, steer=0.003474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.0618490228342
20.53326791152358 seconds in game passed.
Action: tensor([[[0.0045, 0.6243],
         [0.0031, 0.3369],
         [0.0027, 0.2319],
         [0.0019, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.414721, steer=0.003528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.0618490228342
+++++++++++++: 1.769411602615039
20.55826791189611 seconds in game passed.
At 20.55826791189611 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6398],
         [0.0022, 0.3416],
         [0.0018, 0.2343],
         [0.0010, 0.1800]]])
agent 0 action: VehicleControl(throttle=0.409204, steer=0.002601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.769411602615039
Current reward: 0.49971130703569466
Current mitigation activation: 0
#############################
Total reward: 55.5615603298699
20.58326791226864 seconds in game passed.
Action: tensor([[[0.0039, 0.6398],
         [0.0022, 0.3416],
         [0.0018, 0.2343],
         [0.0010, 0.1800]]])
agent 0 action: VehicleControl(throttle=0.413589, steer=0.002765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.5615603298699
20.608267912641168 seconds in game passed.
Action: tensor([[[0.0039, 0.6398],
         [0.0022, 0.3416],
         [0.0018, 0.2343],
         [0.0010, 0.1800]]])
agent 0 action: VehicleControl(throttle=0.417228, steer=0.002773, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.5615603298699
20.633267913013697 seconds in game passed.
Action: tensor([[[0.0039, 0.6398],
         [0.0022, 0.3416],
         [0.0018, 0.2343],
         [0.0010, 0.1800]]])
agent 0 action: VehicleControl(throttle=0.421033, steer=0.002781, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.5615603298699
+++++++++++++: 1.7971553660072597
20.658267913386226 seconds in game passed.
At 20.658267913386226 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6272],
         [0.0027, 0.3366],
         [0.0024, 0.2310],
         [0.0015, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.472611, steer=0.002877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7971553660072597
Current reward: 0.5020130044417552
Current mitigation activation: 0
#############################
Total reward: 56.063573334311656
20.683267913758755 seconds in game passed.
Action: tensor([[[0.0031, 0.6272],
         [0.0027, 0.3366],
         [0.0024, 0.2310],
         [0.0015, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.473617, steer=0.002861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.063573334311656
20.708267914131284 seconds in game passed.
Action: tensor([[[0.0031, 0.6272],
         [0.0027, 0.3366],
         [0.0024, 0.2310],
         [0.0015, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.479539, steer=0.002861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.063573334311656
20.733267914503813 seconds in game passed.
Action: tensor([[[0.0031, 0.6272],
         [0.0027, 0.3366],
         [0.0024, 0.2310],
         [0.0015, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.485481, steer=0.002861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.063573334311656
+++++++++++++: 1.8261483854528087
20.758267914876342 seconds in game passed.
At 20.758267914876342 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6712e-05,  6.2042e-01],
         [-1.6674e-05,  3.3284e-01],
         [-3.1786e-04,  2.2879e-01],
         [-1.1420e-03,  1.7586e-01]]])
agent 0 action: VehicleControl(throttle=0.554021, steer=-0.000429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8261483854528087
Current reward: 0.504446221086873
Current mitigation activation: 0
#############################
Total reward: 56.56801955539853
20.78326791524887 seconds in game passed.
Action: tensor([[[-1.6712e-05,  6.2042e-01],
         [-1.6674e-05,  3.3284e-01],
         [-3.1786e-04,  2.2879e-01],
         [-1.1420e-03,  1.7586e-01]]])
agent 0 action: VehicleControl(throttle=0.552214, steer=0.000073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.56801955539853
20.8082679156214 seconds in game passed.
Action: tensor([[[-1.6712e-05,  6.2042e-01],
         [-1.6674e-05,  3.3284e-01],
         [-3.1786e-04,  2.2879e-01],
         [-1.1420e-03,  1.7586e-01]]])
agent 0 action: VehicleControl(throttle=0.557158, steer=0.000034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.56801955539853
20.83326791599393 seconds in game passed.
Action: tensor([[[-1.6712e-05,  6.2042e-01],
         [-1.6674e-05,  3.3284e-01],
         [-3.1786e-04,  2.2879e-01],
         [-1.1420e-03,  1.7586e-01]]])
agent 0 action: VehicleControl(throttle=0.562041, steer=-0.000005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.56801955539853
+++++++++++++: 1.856383344221038
20.858267916366458 seconds in game passed.
At 20.858267916366458 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6287],
         [-0.0023,  0.3357],
         [-0.0027,  0.2303],
         [-0.0035,  0.1772]]])
agent 0 action: VehicleControl(throttle=0.548432, steer=-0.002645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.856383344221038
Current reward: 0.5070051784736687
Current mitigation activation: 0
#############################
Total reward: 57.0750247338722
20.883267916738987 seconds in game passed.
Action: tensor([[[-0.0024,  0.6287],
         [-0.0023,  0.3357],
         [-0.0027,  0.2303],
         [-0.0035,  0.1772]]])
agent 0 action: VehicleControl(throttle=0.534630, steer=-0.002250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.0750247338722
20.908267917111516 seconds in game passed.
Action: tensor([[[-0.0024,  0.6287],
         [-0.0023,  0.3357],
         [-0.0027,  0.2303],
         [-0.0035,  0.1772]]])
agent 0 action: VehicleControl(throttle=0.523360, steer=-0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.0750247338722
20.933267917484045 seconds in game passed.
Action: tensor([[[-0.0024,  0.6287],
         [-0.0023,  0.3357],
         [-0.0027,  0.2303],
         [-0.0035,  0.1772]]])
agent 0 action: VehicleControl(throttle=0.512901, steer=-0.002327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.0750247338722
+++++++++++++: 1.8717249339915252
20.958267917856574 seconds in game passed.
At 20.958267917856574 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6192],
         [-0.0021,  0.3329],
         [-0.0025,  0.2282],
         [-0.0031,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.508896, steer=-0.002077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8717249339915252
Current reward: 0.5120768411090637
Current mitigation activation: 0
#############################
Total reward: 57.58710157498126
20.983267918229103 seconds in game passed.
Action: tensor([[[-0.0020,  0.6192],
         [-0.0021,  0.3329],
         [-0.0025,  0.2282],
         [-0.0031,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.500771, steer=-0.002159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.58710157498126
21.008267918601632 seconds in game passed.
Action: tensor([[[-0.0020,  0.6192],
         [-0.0021,  0.3329],
         [-0.0025,  0.2282],
         [-0.0031,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.493829, steer=-0.002194, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.58710157498126
21.03326791897416 seconds in game passed.
Action: tensor([[[-0.0020,  0.6192],
         [-0.0021,  0.3329],
         [-0.0025,  0.2282],
         [-0.0031,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.487483, steer=-0.002229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.58710157498126
+++++++++++++: 1.8814944500616506
21.05826791934669 seconds in game passed.
At 21.05826791934669 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6261],
         [-0.0031,  0.3371],
         [-0.0032,  0.2317],
         [-0.0032,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.402185, steer=-0.003186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8814944500616506
Current reward: 0.5180305576617843
Current mitigation activation: 0
#############################
Total reward: 58.10513213264304
21.08326791971922 seconds in game passed.
Action: tensor([[[-0.0025,  0.6261],
         [-0.0031,  0.3371],
         [-0.0032,  0.2317],
         [-0.0032,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.404152, steer=-0.003028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.10513213264304
21.10826792009175 seconds in game passed.
Action: tensor([[[-0.0025,  0.6261],
         [-0.0031,  0.3371],
         [-0.0032,  0.2317],
         [-0.0032,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.398352, steer=-0.003029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.10513213264304
21.133267920464277 seconds in game passed.
Action: tensor([[[-0.0025,  0.6261],
         [-0.0031,  0.3371],
         [-0.0032,  0.2317],
         [-0.0032,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.393597, steer=-0.003030, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.10513213264304
+++++++++++++: 1.8974077306187245
21.158267920836806 seconds in game passed.
At 21.158267920836806 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.0342e-03,  6.1004e-01],
         [-9.1341e-04,  3.2766e-01],
         [-5.6341e-04,  2.2390e-01],
         [-3.5403e-04,  1.7117e-01]]])
agent 0 action: VehicleControl(throttle=0.559638, steer=-0.000769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8974077306187245
Current reward: 0.5230307890865559
Current mitigation activation: 0
#############################
Total reward: 58.6281629217296
21.183267921209335 seconds in game passed.
Action: tensor([[[-1.0342e-03,  6.1004e-01],
         [-9.1341e-04,  3.2766e-01],
         [-5.6341e-04,  2.2390e-01],
         [-3.5403e-04,  1.7117e-01]]])
agent 0 action: VehicleControl(throttle=0.538383, steer=-0.001091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.6281629217296
21.208267921581864 seconds in game passed.
Action: tensor([[[-1.0342e-03,  6.1004e-01],
         [-9.1341e-04,  3.2766e-01],
         [-5.6341e-04,  2.2390e-01],
         [-3.5403e-04,  1.7117e-01]]])
agent 0 action: VehicleControl(throttle=0.535658, steer=-0.001044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.6281629217296
21.233267921954393 seconds in game passed.
Action: tensor([[[-1.0342e-03,  6.1004e-01],
         [-9.1341e-04,  3.2766e-01],
         [-5.6341e-04,  2.2390e-01],
         [-3.5403e-04,  1.7117e-01]]])
agent 0 action: VehicleControl(throttle=0.532132, steer=-0.000997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.6281629217296
+++++++++++++: 1.9193889847829
21.258267922326922 seconds in game passed.
At 21.258267922326922 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6176],
         [0.0035, 0.3329],
         [0.0031, 0.2280],
         [0.0021, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.416317, steer=0.004000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9193889847829
Current reward: 0.5271734733917095
Current mitigation activation: 0
#############################
Total reward: 59.15533639512131
21.28326792269945 seconds in game passed.
Action: tensor([[[0.0032, 0.6176],
         [0.0035, 0.3329],
         [0.0031, 0.2280],
         [0.0021, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.422116, steer=0.003257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.15533639512131
21.30826792307198 seconds in game passed.
Action: tensor([[[0.0032, 0.6176],
         [0.0035, 0.3329],
         [0.0031, 0.2280],
         [0.0021, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.416059, steer=0.003335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.15533639512131
21.33326792344451 seconds in game passed.
Action: tensor([[[0.0032, 0.6176],
         [0.0035, 0.3329],
         [0.0031, 0.2280],
         [0.0021, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.410653, steer=0.003413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.15533639512131
+++++++++++++: 1.9423226176443937
21.35826792381704 seconds in game passed.
At 21.35826792381704 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6202],
         [0.0033, 0.3302],
         [0.0032, 0.2251],
         [0.0027, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.532082, steer=0.002792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9423226176443937
Current reward: 0.5313045917190425
Current mitigation activation: 0
#############################
Total reward: 59.68664098684035
21.383267924189568 seconds in game passed.
Action: tensor([[[0.0020, 0.6202],
         [0.0033, 0.3302],
         [0.0032, 0.2251],
         [0.0027, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.516279, steer=0.002934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.68664098684035
21.408267924562097 seconds in game passed.
Action: tensor([[[0.0020, 0.6202],
         [0.0033, 0.3302],
         [0.0032, 0.2251],
         [0.0027, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.513980, steer=0.002966, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.68664098684035
21.433267924934626 seconds in game passed.
Action: tensor([[[0.0020, 0.6202],
         [0.0033, 0.3302],
         [0.0032, 0.2251],
         [0.0027, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.511013, steer=0.002999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.68664098684035
+++++++++++++: 1.9673715155025355
21.458267925307155 seconds in game passed.
At 21.458267925307155 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0019, 0.6069],
         [0.0031, 0.3251],
         [0.0030, 0.2217],
         [0.0023, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.555239, steer=0.002795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9673715155025355
Current reward: 0.535254841212128
Current mitigation activation: 0
#############################
Total reward: 60.22189582805248
21.483267925679684 seconds in game passed.
Action: tensor([[[0.0019, 0.6069],
         [0.0031, 0.3251],
         [0.0030, 0.2217],
         [0.0023, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.548500, steer=0.002816, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.22189582805248
21.508267926052213 seconds in game passed.
Action: tensor([[[0.0019, 0.6069],
         [0.0031, 0.3251],
         [0.0030, 0.2217],
         [0.0023, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.546251, steer=0.002805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.22189582805248
21.53326792642474 seconds in game passed.
Action: tensor([[[0.0019, 0.6069],
         [0.0031, 0.3251],
         [0.0030, 0.2217],
         [0.0023, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.543378, steer=0.002793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.22189582805248
+++++++++++++: 1.9920391069885612
21.55826792679727 seconds in game passed.
At 21.55826792679727 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.8304e-04, 6.1219e-01],
         [3.0703e-03, 3.2685e-01],
         [2.8773e-03, 2.2226e-01],
         [1.7871e-03, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.532325, steer=0.002267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9920391069885612
Current reward: 0.5394033631474505
Current mitigation activation: 0
#############################
Total reward: 60.76129919119993
21.5832679271698 seconds in game passed.
Action: tensor([[[5.8304e-04, 6.1219e-01],
         [3.0703e-03, 3.2685e-01],
         [2.8773e-03, 2.2226e-01],
         [1.7871e-03, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.529486, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.76129919119993
21.60826792754233 seconds in game passed.
Action: tensor([[[5.8304e-04, 6.1219e-01],
         [3.0703e-03, 3.2685e-01],
         [2.8773e-03, 2.2226e-01],
         [1.7871e-03, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.525541, steer=0.002340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.76129919119993
21.633267927914858 seconds in game passed.
Action: tensor([[[5.8304e-04, 6.1219e-01],
         [3.0703e-03, 3.2685e-01],
         [2.8773e-03, 2.2226e-01],
         [1.7871e-03, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.521435, steer=0.002333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.76129919119993
+++++++++++++: 2.0144769084012553
21.658267928287387 seconds in game passed.
At 21.658267928287387 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0017, 0.6208],
         [0.0040, 0.3291],
         [0.0042, 0.2232],
         [0.0034, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.523087, steer=0.003440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0144769084012553
Current reward: 0.5439880015352977
Current mitigation activation: 0
#############################
Total reward: 61.30528719273523
21.683267928659916 seconds in game passed.
Action: tensor([[[0.0017, 0.6208],
         [0.0040, 0.3291],
         [0.0042, 0.2232],
         [0.0034, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.517651, steer=0.003259, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.30528719273523
21.708267929032445 seconds in game passed.
Action: tensor([[[0.0017, 0.6208],
         [0.0040, 0.3291],
         [0.0042, 0.2232],
         [0.0034, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.512835, steer=0.003263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.30528719273523
21.733267929404974 seconds in game passed.
Action: tensor([[[0.0017, 0.6208],
         [0.0040, 0.3291],
         [0.0042, 0.2232],
         [0.0034, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.507952, steer=0.003267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.30528719273523
+++++++++++++: 2.0361362690673594
21.758267929777503 seconds in game passed.
At 21.758267929777503 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0041, 0.6338],
         [0.0054, 0.3315],
         [0.0057, 0.2240],
         [0.0054, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.546080, steer=0.005299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0361362690673594
Current reward: 0.5487437278849927
Current mitigation activation: 0
#############################
Total reward: 61.85403092062022
21.783267930150032 seconds in game passed.
Action: tensor([[[0.0041, 0.6338],
         [0.0054, 0.3315],
         [0.0057, 0.2240],
         [0.0054, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.536341, steer=0.005028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.85403092062022
21.80826793052256 seconds in game passed.
Action: tensor([[[0.0041, 0.6338],
         [0.0054, 0.3315],
         [0.0057, 0.2240],
         [0.0054, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.531178, steer=0.005086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.85403092062022
21.83326793089509 seconds in game passed.
Action: tensor([[[0.0041, 0.6338],
         [0.0054, 0.3315],
         [0.0057, 0.2240],
         [0.0054, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.525697, steer=0.005144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.85403092062022
+++++++++++++: 2.0579500474826933
21.85826793126762 seconds in game passed.
At 21.85826793126762 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0097, 0.6457],
         [0.0142, 0.3363],
         [0.0156, 0.2257],
         [0.0149, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.466440, steer=0.014046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0579500474826933
Current reward: 0.5535061855363597
Current mitigation activation: 0
#############################
Total reward: 62.407537106156575
21.883267931640148 seconds in game passed.
Action: tensor([[[0.0097, 0.6457],
         [0.0142, 0.3363],
         [0.0156, 0.2257],
         [0.0149, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.466236, steer=0.012767, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.407537106156575
21.908267932012677 seconds in game passed.
Action: tensor([[[0.0097, 0.6457],
         [0.0142, 0.3363],
         [0.0156, 0.2257],
         [0.0149, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.460809, steer=0.012943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.407537106156575
21.933267932385206 seconds in game passed.
Action: tensor([[[0.0097, 0.6457],
         [0.0142, 0.3363],
         [0.0156, 0.2257],
         [0.0149, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.455890, steer=0.013120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.407537106156575
+++++++++++++: 2.0797277991702554
21.958267932757735 seconds in game passed.
At 21.958267932757735 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0109, 0.6537],
         [0.0126, 0.3395],
         [0.0128, 0.2283],
         [0.0114, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.414983, steer=0.012566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0797277991702554
Current reward: 0.5582874486840702
Current mitigation activation: 0
#############################
Total reward: 62.965824554840644
21.983267933130264 seconds in game passed.
Action: tensor([[[0.0109, 0.6537],
         [0.0126, 0.3395],
         [0.0128, 0.2283],
         [0.0114, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.414437, steer=0.012852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.965824554840644
22.008267933502793 seconds in game passed.
Action: tensor([[[0.0109, 0.6537],
         [0.0126, 0.3395],
         [0.0128, 0.2283],
         [0.0114, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.410560, steer=0.013017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.965824554840644
22.033267933875322 seconds in game passed.
Action: tensor([[[0.0109, 0.6537],
         [0.0126, 0.3395],
         [0.0128, 0.2283],
         [0.0114, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.407423, steer=0.013183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.965824554840644
+++++++++++++: 2.103760945887521
22.05826793424785 seconds in game passed.
At 22.05826793424785 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0047, 0.6276],
         [0.0048, 0.3331],
         [0.0046, 0.2260],
         [0.0036, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.379323, steer=0.005033, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.103760945887521
Current reward: 0.5627494363518328
Current mitigation activation: 0
#############################
Total reward: 63.528573991192474
22.08326793462038 seconds in game passed.
Action: tensor([[[0.0047, 0.6276],
         [0.0048, 0.3331],
         [0.0046, 0.2260],
         [0.0036, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.380702, steer=0.006496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.528573991192474
22.10826793499291 seconds in game passed.
Action: tensor([[[0.0047, 0.6276],
         [0.0048, 0.3331],
         [0.0046, 0.2260],
         [0.0036, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.379753, steer=0.006586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.528573991192474
22.13326793536544 seconds in game passed.
Action: tensor([[[0.0047, 0.6276],
         [0.0048, 0.3331],
         [0.0046, 0.2260],
         [0.0036, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.379476, steer=0.006676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.528573991192474
+++++++++++++: 2.1315822138112304
22.158267935737967 seconds in game passed.
At 22.158267935737967 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6358],
         [0.0050, 0.3334],
         [0.0050, 0.2254],
         [0.0041, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.445802, steer=0.006522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1315822138112304
Current reward: 0.5666912599279882
Current mitigation activation: 0
#############################
Total reward: 64.09526525112047
22.183267936110497 seconds in game passed.
Action: tensor([[[0.0037, 0.6358],
         [0.0050, 0.3334],
         [0.0050, 0.2254],
         [0.0041, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.438107, steer=0.006623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.09526525112047
22.208267936483026 seconds in game passed.
Action: tensor([[[0.0037, 0.6358],
         [0.0050, 0.3334],
         [0.0050, 0.2254],
         [0.0041, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.437777, steer=0.006688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.09526525112047
22.233267936855555 seconds in game passed.
Action: tensor([[[0.0037, 0.6358],
         [0.0050, 0.3334],
         [0.0050, 0.2254],
         [0.0041, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.437190, steer=0.006752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.09526525112047
+++++++++++++: 2.1628278674992
22.258267937228084 seconds in game passed.
At 22.258267937228084 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0041, 0.6165],
         [0.0051, 0.3268],
         [0.0049, 0.2220],
         [0.0041, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.483331, steer=0.007030, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1628278674992
Current reward: 0.5702090720586677
Current mitigation activation: 0
#############################
Total reward: 64.66547432317914
22.283267937600613 seconds in game passed.
Action: tensor([[[0.0041, 0.6165],
         [0.0051, 0.3268],
         [0.0049, 0.2220],
         [0.0041, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.479488, steer=0.007003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.66547432317914
22.30826793797314 seconds in game passed.
Action: tensor([[[0.0041, 0.6165],
         [0.0051, 0.3268],
         [0.0049, 0.2220],
         [0.0041, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.480298, steer=0.007018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.66547432317914
22.33326793834567 seconds in game passed.
Action: tensor([[[0.0041, 0.6165],
         [0.0051, 0.3268],
         [0.0049, 0.2220],
         [0.0041, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.480664, steer=0.007034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.66547432317914
+++++++++++++: 2.194201743376419
22.3582679387182 seconds in game passed.
At 22.3582679387182 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4354e-03,  6.1232e-01],
         [ 2.2173e-03,  3.2654e-01],
         [ 1.2024e-03,  2.2234e-01],
         [-5.6221e-04,  1.7020e-01]]])
agent 0 action: VehicleControl(throttle=0.444790, steer=0.003843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.194201743376419
Current reward: 0.5737928709276987
Current mitigation activation: 0
#############################
Total reward: 65.23926719410684
22.38326793909073 seconds in game passed.
Action: tensor([[[ 1.4354e-03,  6.1232e-01],
         [ 2.2173e-03,  3.2654e-01],
         [ 1.2024e-03,  2.2234e-01],
         [-5.6221e-04,  1.7020e-01]]])
agent 0 action: VehicleControl(throttle=0.446472, steer=0.004363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.23926719410684
22.408267939463258 seconds in game passed.
Action: tensor([[[ 1.4354e-03,  6.1232e-01],
         [ 2.2173e-03,  3.2654e-01],
         [ 1.2024e-03,  2.2234e-01],
         [-5.6221e-04,  1.7020e-01]]])
agent 0 action: VehicleControl(throttle=0.444346, steer=0.004352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.23926719410684
22.433267939835787 seconds in game passed.
Action: tensor([[[ 1.4354e-03,  6.1232e-01],
         [ 2.2173e-03,  3.2654e-01],
         [ 1.2024e-03,  2.2234e-01],
         [-5.6221e-04,  1.7020e-01]]])
agent 0 action: VehicleControl(throttle=0.442363, steer=0.004342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.23926719410684
+++++++++++++: 2.2237868894198596
22.458267940208316 seconds in game passed.
At 22.458267940208316 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1809e-03,  6.1621e-01],
         [ 9.8721e-04,  3.2705e-01],
         [ 4.1226e-04,  2.2263e-01],
         [-5.8415e-04,  1.7064e-01]]])
agent 0 action: VehicleControl(throttle=0.461820, steer=0.003321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2237868894198596
Current reward: 0.5776795097440147
Current mitigation activation: 0
#############################
Total reward: 65.81694670385086
22.483267940580845 seconds in game passed.
Action: tensor([[[ 1.1809e-03,  6.1621e-01],
         [ 9.8721e-04,  3.2705e-01],
         [ 4.1226e-04,  2.2263e-01],
         [-5.8415e-04,  1.7064e-01]]])
agent 0 action: VehicleControl(throttle=0.457428, steer=0.003469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.81694670385086
22.508267940953374 seconds in game passed.
Action: tensor([[[ 1.1809e-03,  6.1621e-01],
         [ 9.8721e-04,  3.2705e-01],
         [ 4.1226e-04,  2.2263e-01],
         [-5.8415e-04,  1.7064e-01]]])
agent 0 action: VehicleControl(throttle=0.455391, steer=0.003450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.81694670385086
22.533267941325903 seconds in game passed.
Action: tensor([[[ 1.1809e-03,  6.1621e-01],
         [ 9.8721e-04,  3.2705e-01],
         [ 4.1226e-04,  2.2263e-01],
         [-5.8415e-04,  1.7064e-01]]])
agent 0 action: VehicleControl(throttle=0.453290, steer=0.003431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.81694670385086
+++++++++++++: 2.2530873692344033
22.558267941698432 seconds in game passed.
At 22.558267941698432 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.6170],
         [0.0032, 0.3276],
         [0.0032, 0.2230],
         [0.0026, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.440249, steer=0.005563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2530873692344033
Current reward: 0.5816284479490108
Current mitigation activation: 0
#############################
Total reward: 66.39857515179988
22.58326794207096 seconds in game passed.
Action: tensor([[[0.0024, 0.6170],
         [0.0032, 0.3276],
         [0.0032, 0.2230],
         [0.0026, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.439320, steer=0.005218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.39857515179988
22.60826794244349 seconds in game passed.
Action: tensor([[[0.0024, 0.6170],
         [0.0032, 0.3276],
         [0.0032, 0.2230],
         [0.0026, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.437323, steer=0.005226, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.39857515179988
22.63326794281602 seconds in game passed.
Action: tensor([[[0.0024, 0.6170],
         [0.0032, 0.3276],
         [0.0032, 0.2230],
         [0.0026, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.435480, steer=0.005235, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.39857515179988
+++++++++++++: 2.282426835793194
22.658267943188548 seconds in game passed.
At 22.658267943188548 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6274],
         [0.0057, 0.3318],
         [0.0056, 0.2249],
         [0.0046, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.388005, steer=0.007730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.282426835793194
Current reward: 0.5855884648882691
Current mitigation activation: 0
#############################
Total reward: 66.98416361668815
22.683267943561077 seconds in game passed.
Action: tensor([[[0.0040, 0.6274],
         [0.0057, 0.3318],
         [0.0056, 0.2249],
         [0.0046, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.390723, steer=0.007341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.98416361668815
22.708267943933606 seconds in game passed.
Action: tensor([[[0.0040, 0.6274],
         [0.0057, 0.3318],
         [0.0056, 0.2249],
         [0.0046, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.388908, steer=0.007364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.98416361668815
22.733267944306135 seconds in game passed.
Action: tensor([[[0.0040, 0.6274],
         [0.0057, 0.3318],
         [0.0056, 0.2249],
         [0.0046, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.387617, steer=0.007386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.98416361668815
+++++++++++++: 2.3125645715505128
22.758267944678664 seconds in game passed.
At 22.758267944678664 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6093],
         [0.0052, 0.3271],
         [0.0053, 0.2230],
         [0.0045, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.369760, steer=0.007065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3125645715505128
Current reward: 0.589457923207201
Current mitigation activation: 0
#############################
Total reward: 67.57362153989536
22.783267945051193 seconds in game passed.
Action: tensor([[[0.0042, 0.6093],
         [0.0052, 0.3271],
         [0.0053, 0.2230],
         [0.0045, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.370321, steer=0.007117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.57362153989536
22.808267945423722 seconds in game passed.
Action: tensor([[[0.0042, 0.6093],
         [0.0052, 0.3271],
         [0.0053, 0.2230],
         [0.0045, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.369506, steer=0.007116, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.57362153989536
22.83326794579625 seconds in game passed.
Action: tensor([[[0.0042, 0.6093],
         [0.0052, 0.3271],
         [0.0053, 0.2230],
         [0.0045, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.369134, steer=0.007115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.57362153989536
+++++++++++++: 2.345174909313423
22.85826794616878 seconds in game passed.
At 22.85826794616878 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0486e-03, 6.0667e-01],
         [1.1245e-03, 3.2631e-01],
         [8.5434e-04, 2.2293e-01],
         [1.3636e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.370031, steer=0.002754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.345174909313423
Current reward: 0.5930278827612405
Current mitigation activation: 0
#############################
Total reward: 68.16664942265659
22.88326794654131 seconds in game passed.
Action: tensor([[[1.0486e-03, 6.0667e-01],
         [1.1245e-03, 3.2631e-01],
         [8.5434e-04, 2.2293e-01],
         [1.3636e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.370910, steer=0.003322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.16664942265659
22.90826794691384 seconds in game passed.
Action: tensor([[[1.0486e-03, 6.0667e-01],
         [1.1245e-03, 3.2631e-01],
         [8.5434e-04, 2.2293e-01],
         [1.3636e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.372077, steer=0.003186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.16664942265659
22.933267947286367 seconds in game passed.
Action: tensor([[[1.0486e-03, 6.0667e-01],
         [1.1245e-03, 3.2631e-01],
         [8.5434e-04, 2.2293e-01],
         [1.3636e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.373487, steer=0.003050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.16664942265659
+++++++++++++: 2.380446235391436
22.958267947658896 seconds in game passed.
At 22.958267947658896 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.8481e-04,  6.2410e-01],
         [-9.9689e-05,  3.3023e-01],
         [-5.5047e-04,  2.2403e-01],
         [-1.4045e-03,  1.7052e-01]]])
agent 0 action: VehicleControl(throttle=0.413399, steer=0.001331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.380446235391436
Current reward: 0.5962992205186386
Current mitigation activation: 0
#############################
Total reward: 68.76294864317524
22.983267948031425 seconds in game passed.
Action: tensor([[[-6.8481e-04,  6.2410e-01],
         [-9.9689e-05,  3.3023e-01],
         [-5.5047e-04,  2.2403e-01],
         [-1.4045e-03,  1.7052e-01]]])
agent 0 action: VehicleControl(throttle=0.411964, steer=0.001448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.76294864317524
23.008267948403955 seconds in game passed.
Action: tensor([[[-6.8481e-04,  6.2410e-01],
         [-9.9689e-05,  3.3023e-01],
         [-5.5047e-04,  2.2403e-01],
         [-1.4045e-03,  1.7052e-01]]])
agent 0 action: VehicleControl(throttle=0.414555, steer=0.001304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.76294864317524
23.033267948776484 seconds in game passed.
Action: tensor([[[-6.8481e-04,  6.2410e-01],
         [-9.9689e-05,  3.3023e-01],
         [-5.5047e-04,  2.2403e-01],
         [-1.4045e-03,  1.7052e-01]]])
agent 0 action: VehicleControl(throttle=0.416910, steer=0.001159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.76294864317524
+++++++++++++: 2.417155697986255
23.058267949149013 seconds in game passed.
At 23.058267949149013 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6186],
         [-0.0014,  0.3277],
         [-0.0018,  0.2224],
         [-0.0027,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.455199, steer=-0.000524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.417155697986255
Current reward: 0.5994542011772166
Current mitigation activation: 0
#############################
Total reward: 69.36240284435245
23.08326794952154 seconds in game passed.
Action: tensor([[[-0.0023,  0.6186],
         [-0.0014,  0.3277],
         [-0.0018,  0.2224],
         [-0.0027,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.454132, steer=-0.000332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.36240284435245
23.10826794989407 seconds in game passed.
Action: tensor([[[-0.0023,  0.6186],
         [-0.0014,  0.3277],
         [-0.0018,  0.2224],
         [-0.0027,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.456603, steer=-0.000407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.36240284435245
23.1332679502666 seconds in game passed.
Action: tensor([[[-0.0023,  0.6186],
         [-0.0014,  0.3277],
         [-0.0018,  0.2224],
         [-0.0027,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.458614, steer=-0.000483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.36240284435245
+++++++++++++: 2.452940947378903
23.15826795063913 seconds in game passed.
At 23.15826795063913 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.6080],
         [-0.0016,  0.3251],
         [-0.0020,  0.2212],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.444246, steer=-0.000394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.452940947378903
Current reward: 0.602794943136248
Current mitigation activation: 0
#############################
Total reward: 69.96519778748869
23.183267951011658 seconds in game passed.
Action: tensor([[[-0.0016,  0.6080],
         [-0.0016,  0.3251],
         [-0.0020,  0.2212],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.446284, steer=-0.000493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.96519778748869
23.208267951384187 seconds in game passed.
Action: tensor([[[-0.0016,  0.6080],
         [-0.0016,  0.3251],
         [-0.0020,  0.2212],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.446459, steer=-0.000564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.96519778748869
23.233267951756716 seconds in game passed.
Action: tensor([[[-0.0016,  0.6080],
         [-0.0016,  0.3251],
         [-0.0020,  0.2212],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.446523, steer=-0.000636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.96519778748869
+++++++++++++: 2.486282428000066
23.258267952129245 seconds in game passed.
At 23.258267952129245 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.5899e-04,  6.0772e-01],
         [-8.7464e-04,  3.2602e-01],
         [-1.1618e-03,  2.2248e-01],
         [-1.7382e-03,  1.6977e-01]]])
agent 0 action: VehicleControl(throttle=0.409340, steer=0.000265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.486282428000066
Current reward: 0.6064821902269756
Current mitigation activation: 0
#############################
Total reward: 70.57167997771566
23.283267952501774 seconds in game passed.
Action: tensor([[[-4.5899e-04,  6.0772e-01],
         [-8.7464e-04,  3.2602e-01],
         [-1.1618e-03,  2.2248e-01],
         [-1.7382e-03,  1.6977e-01]]])
agent 0 action: VehicleControl(throttle=0.412155, steer=0.000040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.57167997771566
23.308267952874303 seconds in game passed.
Action: tensor([[[-4.5899e-04,  6.0772e-01],
         [-8.7464e-04,  3.2602e-01],
         [-1.1618e-03,  2.2248e-01],
         [-1.7382e-03,  1.6977e-01]]])
agent 0 action: VehicleControl(throttle=0.411113, steer=-0.000025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.57167997771566
23.333267953246832 seconds in game passed.
Action: tensor([[[-4.5899e-04,  6.0772e-01],
         [-8.7464e-04,  3.2602e-01],
         [-1.1618e-03,  2.2248e-01],
         [-1.7382e-03,  1.6977e-01]]])
agent 0 action: VehicleControl(throttle=0.410331, steer=-0.000089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.57167997771566
+++++++++++++: 2.5183607073439904
23.35826795361936 seconds in game passed.
At 23.35826795361936 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.3179e-04,  6.0610e-01],
         [-8.4257e-04,  3.2652e-01],
         [-1.1962e-03,  2.2260e-01],
         [-1.5869e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.374527, steer=-0.000085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5183607073439904
Current reward: 0.6103397652810113
Current mitigation activation: 0
#############################
Total reward: 71.18201974299667
23.38326795399189 seconds in game passed.
Action: tensor([[[-4.3179e-04,  6.0610e-01],
         [-8.4257e-04,  3.2652e-01],
         [-1.1962e-03,  2.2260e-01],
         [-1.5869e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.377836, steer=-0.000122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.18201974299667
23.40826795436442 seconds in game passed.
Action: tensor([[[-4.3179e-04,  6.0610e-01],
         [-8.4257e-04,  3.2652e-01],
         [-1.1962e-03,  2.2260e-01],
         [-1.5869e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.377623, steer=-0.000153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.18201974299667
23.433267954736948 seconds in game passed.
Action: tensor([[[-4.3179e-04,  6.0610e-01],
         [-8.4257e-04,  3.2652e-01],
         [-1.1962e-03,  2.2260e-01],
         [-1.5869e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.377841, steer=-0.000184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.18201974299667
+++++++++++++: 2.5514932168666205
23.458267955109477 seconds in game passed.
At 23.458267955109477 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.2990e-04,  6.1395e-01],
         [ 2.7125e-04,  3.2858e-01],
         [-8.3499e-05,  2.2337e-01],
         [-8.1541e-04,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.385487, steer=0.001000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5514932168666205
Current reward: 0.6140772922265104
Current mitigation activation: 0
#############################
Total reward: 71.79609703522318
23.483267955482006 seconds in game passed.
Action: tensor([[[ 5.2990e-04,  6.1395e-01],
         [ 2.7125e-04,  3.2858e-01],
         [-8.3499e-05,  2.2337e-01],
         [-8.1541e-04,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.385338, steer=0.000793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.79609703522318
23.508267955854535 seconds in game passed.
Action: tensor([[[ 5.2990e-04,  6.1395e-01],
         [ 2.7125e-04,  3.2858e-01],
         [-8.3499e-05,  2.2337e-01],
         [-8.1541e-04,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.386171, steer=0.000785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.79609703522318
23.533267956227064 seconds in game passed.
Action: tensor([[[ 5.2990e-04,  6.1395e-01],
         [ 2.7125e-04,  3.2858e-01],
         [-8.3499e-05,  2.2337e-01],
         [-8.1541e-04,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.387128, steer=0.000777, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.79609703522318
+++++++++++++: 2.5869787490916636
23.558267956599593 seconds in game passed.
At 23.558267956599593 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.4327e-03, 6.1732e-01],
         [2.3625e-03, 3.2938e-01],
         [1.4866e-03, 2.2439e-01],
         [2.1743e-04, 1.7066e-01]]])
agent 0 action: VehicleControl(throttle=0.394176, steer=0.003050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5869787490916636
Current reward: 0.6175586833461295
Current mitigation activation: 0
#############################
Total reward: 72.41365571856932
23.583267956972122 seconds in game passed.
Action: tensor([[[2.4327e-03, 6.1732e-01],
         [2.3625e-03, 3.2938e-01],
         [1.4866e-03, 2.2439e-01],
         [2.1743e-04, 1.7066e-01]]])
agent 0 action: VehicleControl(throttle=0.394909, steer=0.002664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.41365571856932
23.60826795734465 seconds in game passed.
Action: tensor([[[2.4327e-03, 6.1732e-01],
         [2.3625e-03, 3.2938e-01],
         [1.4866e-03, 2.2439e-01],
         [2.1743e-04, 1.7066e-01]]])
agent 0 action: VehicleControl(throttle=0.396328, steer=0.002657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.41365571856932
23.63326795771718 seconds in game passed.
Action: tensor([[[2.4327e-03, 6.1732e-01],
         [2.3625e-03, 3.2938e-01],
         [1.4866e-03, 2.2439e-01],
         [2.1743e-04, 1.7066e-01]]])
agent 0 action: VehicleControl(throttle=0.397745, steer=0.002651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.41365571856932
+++++++++++++: 2.623852784991061
23.65826795808971 seconds in game passed.
At 23.65826795808971 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.8029e-03,  6.2131e-01],
         [ 4.9173e-04,  3.3014e-01],
         [ 1.0501e-04,  2.2524e-01],
         [-3.6559e-04,  1.7153e-01]]])
agent 0 action: VehicleControl(throttle=0.413089, steer=0.001376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.623852784991061
Current reward: 0.6209240854244111
Current mitigation activation: 0
#############################
Total reward: 73.03457980399372
23.68326795846224 seconds in game passed.
Action: tensor([[[ 2.8029e-03,  6.2131e-01],
         [ 4.9173e-04,  3.3014e-01],
         [ 1.0501e-04,  2.2524e-01],
         [-3.6559e-04,  1.7153e-01]]])
agent 0 action: VehicleControl(throttle=0.413737, steer=0.001536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.03457980399372
23.708267958834767 seconds in game passed.
Action: tensor([[[ 2.8029e-03,  6.2131e-01],
         [ 4.9173e-04,  3.3014e-01],
         [ 1.0501e-04,  2.2524e-01],
         [-3.6559e-04,  1.7153e-01]]])
agent 0 action: VehicleControl(throttle=0.415748, steer=0.001490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.03457980399372
23.733267959207296 seconds in game passed.
Action: tensor([[[ 2.8029e-03,  6.2131e-01],
         [ 4.9173e-04,  3.3014e-01],
         [ 1.0501e-04,  2.2524e-01],
         [-3.6559e-04,  1.7153e-01]]])
agent 0 action: VehicleControl(throttle=0.417613, steer=0.001445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.03457980399372
+++++++++++++: 2.660889265827077
23.758267959579825 seconds in game passed.
At 23.758267959579825 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.9400e-04,  6.1589e-01],
         [-1.2126e-03,  3.2730e-01],
         [-1.3357e-03,  2.2321e-01],
         [-1.6941e-03,  1.6949e-01]]])
agent 0 action: VehicleControl(throttle=0.467144, steer=-0.001123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.660889265827077
Current reward: 0.6243210226222642
Current mitigation activation: 0
#############################
Total reward: 73.65890082661599
23.783267959952354 seconds in game passed.
Action: tensor([[[-3.9400e-04,  6.1589e-01],
         [-1.2126e-03,  3.2730e-01],
         [-1.3357e-03,  2.2321e-01],
         [-1.6941e-03,  1.6949e-01]]])
agent 0 action: VehicleControl(throttle=0.464433, steer=-0.000774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.65890082661599
23.808267960324883 seconds in game passed.
Action: tensor([[[-3.9400e-04,  6.1589e-01],
         [-1.2126e-03,  3.2730e-01],
         [-1.3357e-03,  2.2321e-01],
         [-1.6941e-03,  1.6949e-01]]])
agent 0 action: VehicleControl(throttle=0.466510, steer=-0.000842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.65890082661599
23.833267960697412 seconds in game passed.
Action: tensor([[[-3.9400e-04,  6.1589e-01],
         [-1.2126e-03,  3.2730e-01],
         [-1.3357e-03,  2.2321e-01],
         [-1.6941e-03,  1.6949e-01]]])
agent 0 action: VehicleControl(throttle=0.468055, steer=-0.000910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.65890082661599
+++++++++++++: 2.6968600883373997
23.85826796106994 seconds in game passed.
At 23.85826796106994 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6158],
         [-0.0032,  0.3266],
         [-0.0035,  0.2221],
         [-0.0036,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.495993, steer=-0.002798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6968600883373997
Current reward: 0.6278773266331137
Current mitigation activation: 0
#############################
Total reward: 74.2867781532491
23.88326796144247 seconds in game passed.
Action: tensor([[[-0.0014,  0.6158],
         [-0.0032,  0.3266],
         [-0.0035,  0.2221],
         [-0.0036,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.494245, steer=-0.002534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.2867781532491
23.908267961815 seconds in game passed.
Action: tensor([[[-0.0014,  0.6158],
         [-0.0032,  0.3266],
         [-0.0035,  0.2221],
         [-0.0036,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.494952, steer=-0.002577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.2867781532491
23.93326796218753 seconds in game passed.
Action: tensor([[[-0.0014,  0.6158],
         [-0.0032,  0.3266],
         [-0.0035,  0.2221],
         [-0.0036,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.495141, steer=-0.002620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.2867781532491
+++++++++++++: 2.7297889067293535
23.958267962560058 seconds in game passed.
At 23.958267962560058 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0036,  0.6143],
         [-0.0056,  0.3277],
         [-0.0059,  0.2232],
         [-0.0060,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.435040, steer=-0.005262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7297889067293535
Current reward: 0.6317903917854484
Current mitigation activation: 0
#############################
Total reward: 74.91856854503455
23.983267962932587 seconds in game passed.
Action: tensor([[[-0.0036,  0.6143],
         [-0.0056,  0.3277],
         [-0.0059,  0.2232],
         [-0.0060,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.439701, steer=-0.004884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.91856854503455
24.008267963305116 seconds in game passed.
Action: tensor([[[-0.0036,  0.6143],
         [-0.0056,  0.3277],
         [-0.0059,  0.2232],
         [-0.0060,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.437952, steer=-0.004938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.91856854503455
24.033267963677645 seconds in game passed.
Action: tensor([[[-0.0036,  0.6143],
         [-0.0056,  0.3277],
         [-0.0059,  0.2232],
         [-0.0060,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.436453, steer=-0.004991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.91856854503455
+++++++++++++: 2.7594825724065504
24.058267964050174 seconds in game passed.
At 24.058267964050174 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.6014],
         [-0.0010,  0.3237],
         [-0.0008,  0.2210],
         [-0.0009,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.447353, steer=-0.000588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7594825724065504
Current reward: 0.6360448664915477
Current mitigation activation: 0
#############################
Total reward: 75.55461341152609
24.083267964422703 seconds in game passed.
Action: tensor([[[-0.0010,  0.6014],
         [-0.0010,  0.3237],
         [-0.0008,  0.2210],
         [-0.0009,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.444521, steer=-0.001311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.55461341152609
24.108267964795232 seconds in game passed.
Action: tensor([[[-0.0010,  0.6014],
         [-0.0010,  0.3237],
         [-0.0008,  0.2210],
         [-0.0009,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.443108, steer=-0.001302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.55461341152609
24.13326796516776 seconds in game passed.
Action: tensor([[[-0.0010,  0.6014],
         [-0.0010,  0.3237],
         [-0.0008,  0.2210],
         [-0.0009,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.441704, steer=-0.001293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.55461341152609
+++++++++++++: 2.789393471986782
24.15826796554029 seconds in game passed.
At 24.15826796554029 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.6329e-05,  5.9838e-01],
         [ 8.6544e-04,  3.2349e-01],
         [ 1.0733e-03,  2.2108e-01],
         [ 7.9499e-04,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.415071, steer=0.000433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.789393471986782
Current reward: 0.6402435930413348
Current mitigation activation: 0
#############################
Total reward: 76.19485700456742
24.18326796591282 seconds in game passed.
Action: tensor([[[-3.6329e-05,  5.9838e-01],
         [ 8.6544e-04,  3.2349e-01],
         [ 1.0733e-03,  2.2108e-01],
         [ 7.9499e-04,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.416341, steer=0.000175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.19485700456742
24.208267966285348 seconds in game passed.
Action: tensor([[[-3.6329e-05,  5.9838e-01],
         [ 8.6544e-04,  3.2349e-01],
         [ 1.0733e-03,  2.2108e-01],
         [ 7.9499e-04,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.415042, steer=0.000200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.19485700456742
24.233267966657877 seconds in game passed.
Action: tensor([[[-3.6329e-05,  5.9838e-01],
         [ 8.6544e-04,  3.2349e-01],
         [ 1.0733e-03,  2.2108e-01],
         [ 7.9499e-04,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.414016, steer=0.000225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.19485700456742
+++++++++++++: 2.8202070087579902
24.258267967030406 seconds in game passed.
At 24.258267967030406 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0008, 0.6031],
         [0.0017, 0.3255],
         [0.0019, 0.2219],
         [0.0016, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.391963, steer=0.001183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8202070087579902
Current reward: 0.6443200832108984
Current mitigation activation: 0
#############################
Total reward: 76.83917708777832
24.283267967402935 seconds in game passed.
Action: tensor([[[0.0008, 0.6031],
         [0.0017, 0.3255],
         [0.0019, 0.2219],
         [0.0016, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.393776, steer=0.001052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.83917708777832
24.308267967775464 seconds in game passed.
Action: tensor([[[0.0008, 0.6031],
         [0.0017, 0.3255],
         [0.0019, 0.2219],
         [0.0016, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.393521, steer=0.001076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.83917708777832
24.333267968147993 seconds in game passed.
Action: tensor([[[0.0008, 0.6031],
         [0.0017, 0.3255],
         [0.0019, 0.2219],
         [0.0016, 0.1685]]])
agent 0 action: VehicleControl(throttle=0.393586, steer=0.001101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.83917708777832
+++++++++++++: 2.8526937734504796
24.358267968520522 seconds in game passed.
At 24.358267968520522 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.6030],
         [0.0023, 0.3249],
         [0.0021, 0.2225],
         [0.0015, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.412753, steer=0.002234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8526937734504796
Current reward: 0.6482000884247943
Current mitigation activation: 0
#############################
Total reward: 77.48737717620313
24.38326796889305 seconds in game passed.
Action: tensor([[[0.0024, 0.6030],
         [0.0023, 0.3249],
         [0.0021, 0.2225],
         [0.0015, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.411891, steer=0.002087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.48737717620313
24.40826796926558 seconds in game passed.
Action: tensor([[[0.0024, 0.6030],
         [0.0023, 0.3249],
         [0.0021, 0.2225],
         [0.0015, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.413099, steer=0.002122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.48737717620313
24.43326796963811 seconds in game passed.
Action: tensor([[[0.0024, 0.6030],
         [0.0023, 0.3249],
         [0.0021, 0.2225],
         [0.0015, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.414271, steer=0.002158, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.48737717620313
+++++++++++++: 2.887313440643162
24.45826797001064 seconds in game passed.
At 24.45826797001064 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6142],
         [0.0023, 0.3278],
         [0.0024, 0.2235],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.429102, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.887313440643162
Current reward: 0.6518540658052578
Current mitigation activation: 0
#############################
Total reward: 78.13923124200838
24.483267970383167 seconds in game passed.
Action: tensor([[[0.0031, 0.6142],
         [0.0023, 0.3278],
         [0.0024, 0.2235],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.428847, steer=0.002426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.13923124200838
24.508267970755696 seconds in game passed.
Action: tensor([[[0.0031, 0.6142],
         [0.0023, 0.3278],
         [0.0024, 0.2235],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.429976, steer=0.002452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.13923124200838
24.533267971128225 seconds in game passed.
Action: tensor([[[0.0031, 0.6142],
         [0.0023, 0.3278],
         [0.0024, 0.2235],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.430943, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.13923124200838
+++++++++++++: 2.922468630042992
24.558267971500754 seconds in game passed.
At 24.558267971500754 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6203],
         [0.0008, 0.3293],
         [0.0009, 0.2240],
         [0.0008, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.438648, steer=0.000819, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.922468630042992
Current reward: 0.6554645387296505
Current mitigation activation: 0
#############################
Total reward: 78.79469578073802
24.583267971873283 seconds in game passed.
Action: tensor([[[0.0018, 0.6203],
         [0.0008, 0.3293],
         [0.0009, 0.2240],
         [0.0008, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.438650, steer=0.001078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.79469578073802
24.608267972245812 seconds in game passed.
Action: tensor([[[0.0018, 0.6203],
         [0.0008, 0.3293],
         [0.0009, 0.2240],
         [0.0008, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.439253, steer=0.001063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.79469578073802
24.63326797261834 seconds in game passed.
Action: tensor([[[0.0018, 0.6203],
         [0.0008, 0.3293],
         [0.0009, 0.2240],
         [0.0008, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.439697, steer=0.001048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.79469578073802
+++++++++++++: 2.9567681761050926
24.65826797299087 seconds in game passed.
At 24.65826797299087 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6172],
         [-0.0023,  0.3259],
         [-0.0026,  0.2216],
         [-0.0029,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.531729, steer=-0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9567681761050926
Current reward: 0.6591661077860247
Current mitigation activation: 0
#############################
Total reward: 79.45386188852405
24.6832679733634 seconds in game passed.
Action: tensor([[[-0.0012,  0.6172],
         [-0.0023,  0.3259],
         [-0.0026,  0.2216],
         [-0.0029,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.523054, steer=-0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.45386188852405
24.70826797373593 seconds in game passed.
Action: tensor([[[-0.0012,  0.6172],
         [-0.0023,  0.3259],
         [-0.0026,  0.2216],
         [-0.0029,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.523805, steer=-0.001882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.45386188852405
24.733267974108458 seconds in game passed.
Action: tensor([[[-0.0012,  0.6172],
         [-0.0023,  0.3259],
         [-0.0026,  0.2216],
         [-0.0029,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.523678, steer=-0.001919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.45386188852405
+++++++++++++: 2.9894076073435785
24.758267974480987 seconds in game passed.
At 24.758267974480987 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0032,  0.6125],
         [-0.0075,  0.3260],
         [-0.0083,  0.2220],
         [-0.0085,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.470249, steer=-0.006616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9894076073435785
Current reward: 0.6630015936243929
Current mitigation activation: 0
#############################
Total reward: 80.11686348214843
24.783267974853516 seconds in game passed.
Action: tensor([[[-0.0032,  0.6125],
         [-0.0075,  0.3260],
         [-0.0083,  0.2220],
         [-0.0085,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.473397, steer=-0.005903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.11686348214843
24.808267975226045 seconds in game passed.
Action: tensor([[[-0.0032,  0.6125],
         [-0.0075,  0.3260],
         [-0.0083,  0.2220],
         [-0.0085,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.470767, steer=-0.005962, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.11686348214843
24.833267975598574 seconds in game passed.
Action: tensor([[[-0.0032,  0.6125],
         [-0.0075,  0.3260],
         [-0.0083,  0.2220],
         [-0.0085,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.468192, steer=-0.006022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.11686348214843
+++++++++++++: 3.0175265000573575
24.858267975971103 seconds in game passed.
At 24.858267975971103 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0043,  0.6097],
         [-0.0065,  0.3264],
         [-0.0067,  0.2225],
         [-0.0068,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.420946, steer=-0.005727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0175265000573575
Current reward: 0.6670741987091215
Current mitigation activation: 0
#############################
Total reward: 80.78393768085755
24.88326797634363 seconds in game passed.
Action: tensor([[[-0.0043,  0.6097],
         [-0.0065,  0.3264],
         [-0.0067,  0.2225],
         [-0.0068,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.422333, steer=-0.005819, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.78393768085755
24.90826797671616 seconds in game passed.
Action: tensor([[[-0.0043,  0.6097],
         [-0.0065,  0.3264],
         [-0.0067,  0.2225],
         [-0.0068,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.419197, steer=-0.005856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.78393768085755
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:06:37 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:07:23 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 46.15s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.4s               │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.507               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 80.78, average_reward: 80.78393768085755 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00007/fi_lead_slowdown_data
