New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190053-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190053-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190053-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190053-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190053-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190053-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 29.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 29}
1.5256040766835213 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5506040770560503 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5756040774285793 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6006040778011084 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6256040781736374 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6506040785461664 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0053, 0.5907],
         [0.0027, 0.3226],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.6756040789186954 seconds in game passed.
Action: tensor([[[0.0053, 0.5907],
         [0.0027, 0.3226],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7006040792912245 seconds in game passed.
Action: tensor([[[0.0053, 0.5907],
         [0.0027, 0.3226],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7256040796637535 seconds in game passed.
Action: tensor([[[0.0053, 0.5907],
         [0.0027, 0.3226],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003738, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7506040800362825 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003128, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7756040804088116 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8006040807813406 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8256040811538696 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0021, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8506040815263987 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8756040818989277 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9006040822714567 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9256040826439857 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9506040830165148 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9756040833890438 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.000604083761573 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.025604084134102 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.050604084506631 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4129e-03, 5.9032e-01],
         [1.3098e-03, 3.2225e-01],
         [1.0854e-03, 2.2208e-01],
         [5.4699e-04, 1.6809e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.07560408487916 seconds in game passed.
Action: tensor([[[2.4129e-03, 5.9032e-01],
         [1.3098e-03, 3.2225e-01],
         [1.0854e-03, 2.2208e-01],
         [5.4699e-04, 1.6809e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.100604085251689 seconds in game passed.
Action: tensor([[[2.4129e-03, 5.9032e-01],
         [1.3098e-03, 3.2225e-01],
         [1.0854e-03, 2.2208e-01],
         [5.4699e-04, 1.6809e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.125604085624218 seconds in game passed.
Action: tensor([[[2.4129e-03, 5.9032e-01],
         [1.3098e-03, 3.2225e-01],
         [1.0854e-03, 2.2208e-01],
         [5.4699e-04, 1.6809e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.150604085996747 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5893],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.175604086369276 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.200604086741805 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.225604087114334 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.250604087486863 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.275604087859392 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002473, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.300604088231921 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3256040886044502 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.3506040889769793 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.3756040893495083 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4006040897220373 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4256040900945663 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.4506040904670954 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002746, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4756040908396244 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002767, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5006040912121534 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5256040915846825 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5506040919572115 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002619, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5756040923297405 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6006040927022696 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002619, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6256040930747986 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6506040934473276 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6756040938198566 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7006040941923857 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7256040945649147 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7506040949374437 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.7756040953099728 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.800604095682502 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.825604096055031 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002424, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.85060409642756 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.875604096800089 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.900604097172618 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.925604097545147 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.950604097917676 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.975604098290205 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.000604098662734 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002344, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.025604099035263 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.050604099407792 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.075604099780321 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.10060410015285 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.125604100525379 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.150604100897908 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.1756041012704372 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2006041016429663 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2256041020154953 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.2506041023880243 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.2756041027605534 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3006041031330824 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3256041035056114 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3506041038781404 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3756041042506695 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4006041046231985 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4256041049957275 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4506041053682566 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4756041057407856 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5006041061133146 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5256041064858437 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5506041068583727 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5756041072309017 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6006041076034307 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6256041079759598 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.650604108348489 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.675604108721018 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.700604109093547 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.725604109466076 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.750604109838605 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.775604110211134 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.800604110583663 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.825604110956192 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.850604111328721 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.87560411170125 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.900604112073779 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.925604112446308 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.950604112818837 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.975604113191366 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.000604113563895 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.025604113936424 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.050604114308953 seconds in game passed.
At 4.050604114308953 seconds, saving state-action tuples.
Action: tensor([[[1.4090e-03, 5.8609e-01],
         [1.1340e-03, 3.2069e-01],
         [9.9612e-04, 2.2102e-01],
         [3.4092e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.075604114681482 seconds in game passed.
Action: tensor([[[1.4090e-03, 5.8609e-01],
         [1.1340e-03, 3.2069e-01],
         [9.9612e-04, 2.2102e-01],
         [3.4092e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.100604115054011 seconds in game passed.
Action: tensor([[[1.4090e-03, 5.8609e-01],
         [1.1340e-03, 3.2069e-01],
         [9.9612e-04, 2.2102e-01],
         [3.4092e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.12560411542654 seconds in game passed.
Action: tensor([[[1.4090e-03, 5.8609e-01],
         [1.1340e-03, 3.2069e-01],
         [9.9612e-04, 2.2102e-01],
         [3.4092e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.88373051633521
4.150604115799069 seconds in game passed.
At 4.150604115799069 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760848520400644
Current mitigation activation: 0
#############################
Total reward: 0.6561255113146287
4.175604116171598 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
4.2006041165441275 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
4.2256041169166565 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
+++++++++++++: 8.843383940473686
4.2506041172891855 seconds in game passed.
At 4.2506041172891855 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383940473686
Current reward: 0.49259321983288007
Current mitigation activation: 0
#############################
Total reward: 1.1487187311475089
4.2756041176617146 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.300604118034244 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.325604118406773 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
+++++++++++++: 7.228541449858101
4.350604118779302 seconds in game passed.
At 4.350604118779302 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228541449858101
Current reward: 0.5118171168217831
Current mitigation activation: 0
#############################
Total reward: 1.660535847969292
4.375604119151831 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
4.40060411952436 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
4.425604119896889 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
+++++++++++++: 6.215933070986233
4.450604120269418 seconds in game passed.
At 4.450604120269418 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5897],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002768, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.215933070986233
Current reward: 0.5264941437496048
Current mitigation activation: 0
#############################
Total reward: 2.1870299917188967
4.475604120641947 seconds in game passed.
Action: tensor([[[0.0021, 0.5897],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299917188967
4.500604121014476 seconds in game passed.
Action: tensor([[[0.0021, 0.5897],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299917188967
4.525604121387005 seconds in game passed.
Action: tensor([[[0.0021, 0.5897],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299917188967
+++++++++++++: 5.508365808603482
4.550604121759534 seconds in game passed.
At 4.550604121759534 seconds, saving state-action tuples.
Action: tensor([[[-6.5334e-05,  5.8864e-01],
         [ 1.8728e-04,  3.2200e-01],
         [ 3.1266e-04,  2.2120e-01],
         [-5.7667e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508365808603482
Current reward: 0.5376234960127234
Current mitigation activation: 0
#############################
Total reward: 2.72465348773162
4.575604122132063 seconds in game passed.
Action: tensor([[[-6.5334e-05,  5.8864e-01],
         [ 1.8728e-04,  3.2200e-01],
         [ 3.1266e-04,  2.2120e-01],
         [-5.7667e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 2.72465348773162
4.600604122504592 seconds in game passed.
Action: tensor([[[-6.5334e-05,  5.8864e-01],
         [ 1.8728e-04,  3.2200e-01],
         [ 3.1266e-04,  2.2120e-01],
         [-5.7667e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.72465348773162
4.625604122877121 seconds in game passed.
Action: tensor([[[-6.5334e-05,  5.8864e-01],
         [ 1.8728e-04,  3.2200e-01],
         [ 3.1266e-04,  2.2120e-01],
         [-5.7667e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.72465348773162
+++++++++++++: 4.976130959290551
4.65060412324965 seconds in game passed.
At 4.65060412324965 seconds, saving state-action tuples.
Action: tensor([[[ 2.4582e-04,  5.8923e-01],
         [-3.6428e-04,  3.2137e-01],
         [-2.8198e-04,  2.2103e-01],
         [-4.4648e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.976130959290551
Current reward: 0.5459292534614593
Current mitigation activation: 0
#############################
Total reward: 3.2705827411930795
4.675604123622179 seconds in game passed.
Action: tensor([[[ 2.4582e-04,  5.8923e-01],
         [-3.6428e-04,  3.2137e-01],
         [-2.8198e-04,  2.2103e-01],
         [-4.4648e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705827411930795
4.700604123994708 seconds in game passed.
Action: tensor([[[ 2.4582e-04,  5.8923e-01],
         [-3.6428e-04,  3.2137e-01],
         [-2.8198e-04,  2.2103e-01],
         [-4.4648e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705827411930795
4.725604124367237 seconds in game passed.
Action: tensor([[[ 2.4582e-04,  5.8923e-01],
         [-3.6428e-04,  3.2137e-01],
         [-2.8198e-04,  2.2103e-01],
         [-4.4648e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705827411930795
+++++++++++++: 4.552589694567923
4.750604124739766 seconds in game passed.
At 4.750604124739766 seconds, saving state-action tuples.
Action: tensor([[[-2.6760e-04,  5.9093e-01],
         [-9.5139e-04,  3.2156e-01],
         [-8.3692e-04,  2.2108e-01],
         [-9.8205e-04,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552589694567923
Current reward: 0.5519988957728978
Current mitigation activation: 0
#############################
Total reward: 3.8225816369659773
4.775604125112295 seconds in game passed.
Action: tensor([[[-2.6760e-04,  5.9093e-01],
         [-9.5139e-04,  3.2156e-01],
         [-8.3692e-04,  2.2108e-01],
         [-9.8205e-04,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225816369659773
4.800604125484824 seconds in game passed.
Action: tensor([[[-2.6760e-04,  5.9093e-01],
         [-9.5139e-04,  3.2156e-01],
         [-8.3692e-04,  2.2108e-01],
         [-9.8205e-04,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225816369659773
4.825604125857353 seconds in game passed.
Action: tensor([[[-2.6760e-04,  5.9093e-01],
         [-9.5139e-04,  3.2156e-01],
         [-8.3692e-04,  2.2108e-01],
         [-9.8205e-04,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225816369659773
+++++++++++++: 4.199610891941162
4.850604126229882 seconds in game passed.
At 4.850604126229882 seconds, saving state-action tuples.
Action: tensor([[[ 5.6025e-04,  5.8994e-01],
         [-5.4444e-04,  3.2156e-01],
         [-3.9411e-04,  2.2124e-01],
         [-3.9754e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199610891941162
Current reward: 0.5563326528694177
Current mitigation activation: 0
#############################
Total reward: 4.378914289835395
4.875604126602411 seconds in game passed.
Action: tensor([[[ 5.6025e-04,  5.8994e-01],
         [-5.4444e-04,  3.2156e-01],
         [-3.9411e-04,  2.2124e-01],
         [-3.9754e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914289835395
4.90060412697494 seconds in game passed.
Action: tensor([[[ 5.6025e-04,  5.8994e-01],
         [-5.4444e-04,  3.2156e-01],
         [-3.9411e-04,  2.2124e-01],
         [-3.9754e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914289835395
4.925604127347469 seconds in game passed.
Action: tensor([[[ 5.6025e-04,  5.8994e-01],
         [-5.4444e-04,  3.2156e-01],
         [-3.9411e-04,  2.2124e-01],
         [-3.9754e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914289835395
+++++++++++++: 3.8947629063431517
4.950604127719998 seconds in game passed.
At 4.950604127719998 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.8947629063431517
Current reward: 0.5593081946876429
Current mitigation activation: 0
#############################
Total reward: 4.938222484523037
4.975604128092527 seconds in game passed.
Action: tensor([[[0.0016, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222484523037
5.000604128465056 seconds in game passed.
Action: tensor([[[0.0016, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222484523037
5.0256041288375854 seconds in game passed.
Action: tensor([[[0.0016, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222484523037
+++++++++++++: 3.624673285881896
5.0506041292101145 seconds in game passed.
At 5.0506041292101145 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2478e-03, 5.8969e-01],
         [1.0036e-03, 3.2205e-01],
         [8.6796e-04, 2.2281e-01],
         [5.0932e-04, 1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.624673285881896
Current reward: 0.5611771127197849
Current mitigation activation: 0
#############################
Total reward: 5.499399597242823
5.0756041295826435 seconds in game passed.
Action: tensor([[[1.2478e-03, 5.8969e-01],
         [1.0036e-03, 3.2205e-01],
         [8.6796e-04, 2.2281e-01],
         [5.0932e-04, 1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399597242823
5.1006041299551725 seconds in game passed.
Action: tensor([[[1.2478e-03, 5.8969e-01],
         [1.0036e-03, 3.2205e-01],
         [8.6796e-04, 2.2281e-01],
         [5.0932e-04, 1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399597242823
5.125604130327702 seconds in game passed.
Action: tensor([[[1.2478e-03, 5.8969e-01],
         [1.0036e-03, 3.2205e-01],
         [8.6796e-04, 2.2281e-01],
         [5.0932e-04, 1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399597242823
+++++++++++++: 3.380483584694243
5.150604130700231 seconds in game passed.
At 5.150604130700231 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380483584694243
Current reward: 0.5621374566377555
Current mitigation activation: 0
#############################
Total reward: 6.061537053880578
5.17560413107276 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537053880578
5.200604131445289 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537053880578
5.225604131817818 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537053880578
+++++++++++++: 3.156600867398005
5.250604132190347 seconds in game passed.
At 5.250604132190347 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.156600867398005
Current reward: 0.562310068894243
Current mitigation activation: 0
#############################
Total reward: 6.623847122774821
5.275604132562876 seconds in game passed.
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623847122774821
5.300604132935405 seconds in game passed.
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623847122774821
5.325604133307934 seconds in game passed.
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623847122774821
+++++++++++++: 2.9489482625551147
5.350604133680463 seconds in game passed.
At 5.350604133680463 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5893],
         [0.0029, 0.3215],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9489482625551147
Current reward: 0.5617968617035856
Current mitigation activation: 0
#############################
Total reward: 7.185643984478407
5.375604134052992 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0029, 0.3215],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002972, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185643984478407
5.400604134425521 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0029, 0.3215],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185643984478407
5.42560413479805 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0029, 0.3215],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185643984478407
+++++++++++++: 2.788065518321815
5.450604135170579 seconds in game passed.
At 5.450604135170579 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.7763e-04,  5.8816e-01],
         [ 1.1668e-04,  3.2090e-01],
         [-3.9190e-05,  2.2103e-01],
         [-3.4876e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.788065518321815
Current reward: 0.5575289986011362
Current mitigation activation: 0
#############################
Total reward: 7.7431729830795435
5.475604135543108 seconds in game passed.
Action: tensor([[[ 8.7763e-04,  5.8816e-01],
         [ 1.1668e-04,  3.2090e-01],
         [-3.9190e-05,  2.2103e-01],
         [-3.4876e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.7431729830795435
5.500604135915637 seconds in game passed.
Action: tensor([[[ 8.7763e-04,  5.8816e-01],
         [ 1.1668e-04,  3.2090e-01],
         [-3.9190e-05,  2.2103e-01],
         [-3.4876e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.7431729830795435
5.525604136288166 seconds in game passed.
Action: tensor([[[ 8.7763e-04,  5.8816e-01],
         [ 1.1668e-04,  3.2090e-01],
         [-3.9190e-05,  2.2103e-01],
         [-3.4876e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000755, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.7431729830795435
+++++++++++++: 2.6913236630901993
5.550604136660695 seconds in game passed.
At 5.550604136660695 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3227],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6913236630901993
Current reward: 0.5472020002123094
Current mitigation activation: 0
#############################
Total reward: 8.290374983291853
5.575604137033224 seconds in game passed.
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3227],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290374983291853
5.600604137405753 seconds in game passed.
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3227],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290374983291853
5.625604137778282 seconds in game passed.
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3227],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290374983291853
+++++++++++++: 2.59500079790311
5.650604138150811 seconds in game passed.
At 5.650604138150811 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.5917],
         [-0.0038,  0.3222],
         [-0.0045,  0.2212],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.59500079790311
Current reward: 0.5368305074867515
Current mitigation activation: 0
#############################
Total reward: 8.827205490778605
5.67560413852334 seconds in game passed.
Action: tensor([[[-0.0022,  0.5917],
         [-0.0038,  0.3222],
         [-0.0045,  0.2212],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205490778605
5.700604138895869 seconds in game passed.
Action: tensor([[[-0.0022,  0.5917],
         [-0.0038,  0.3222],
         [-0.0045,  0.2212],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002846, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205490778605
5.725604139268398 seconds in game passed.
Action: tensor([[[-0.0022,  0.5917],
         [-0.0038,  0.3222],
         [-0.0045,  0.2212],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205490778605
+++++++++++++: 2.49863226800518
5.750604139640927 seconds in game passed.
At 5.750604139640927 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.5957],
         [-0.0046,  0.3233],
         [-0.0051,  0.2220],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.49863226800518
Current reward: 0.5264623787398338
Current mitigation activation: 0
#############################
Total reward: 9.35366786951844
5.775604140013456 seconds in game passed.
Action: tensor([[[-0.0027,  0.5957],
         [-0.0046,  0.3233],
         [-0.0051,  0.2220],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.35366786951844
5.800604140385985 seconds in game passed.
Action: tensor([[[-0.0027,  0.5957],
         [-0.0046,  0.3233],
         [-0.0051,  0.2220],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003595, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.35366786951844
5.825604140758514 seconds in game passed.
Action: tensor([[[-0.0027,  0.5957],
         [-0.0046,  0.3233],
         [-0.0051,  0.2220],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.35366786951844
+++++++++++++: 2.4022175792891014
5.850604141131043 seconds in game passed.
At 5.850604141131043 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1533e-04,  5.9080e-01],
         [-6.7846e-04,  3.2182e-01],
         [-7.0756e-04,  2.2149e-01],
         [-9.2127e-04,  1.6818e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4022175792891014
Current reward: 0.5160982164832554
Current mitigation activation: 0
#############################
Total reward: 9.869766086001695
5.8756041415035725 seconds in game passed.
Action: tensor([[[-1.1533e-04,  5.9080e-01],
         [-6.7846e-04,  3.2182e-01],
         [-7.0756e-04,  2.2149e-01],
         [-9.2127e-04,  1.6818e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869766086001695
5.9006041418761015 seconds in game passed.
Action: tensor([[[-1.1533e-04,  5.9080e-01],
         [-6.7846e-04,  3.2182e-01],
         [-7.0756e-04,  2.2149e-01],
         [-9.2127e-04,  1.6818e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869766086001695
5.9256041422486305 seconds in game passed.
Action: tensor([[[-1.1533e-04,  5.9080e-01],
         [-6.7846e-04,  3.2182e-01],
         [-7.0756e-04,  2.2149e-01],
         [-9.2127e-04,  1.6818e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869766086001695
+++++++++++++: 2.273734427739386
5.9506041426211596 seconds in game passed.
At 5.9506041426211596 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.6217e-05,  5.9302e-01],
         [ 1.9962e-04,  3.2255e-01],
         [ 2.3429e-04,  2.2189e-01],
         [-1.3903e-04,  1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.273734427739386
Current reward: 0.5093358079618683
Current mitigation activation: 0
#############################
Total reward: 10.379101893963563
5.975604142993689 seconds in game passed.
Action: tensor([[[ 3.6217e-05,  5.9302e-01],
         [ 1.9962e-04,  3.2255e-01],
         [ 2.3429e-04,  2.2189e-01],
         [-1.3903e-04,  1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379101893963563
6.000604143366218 seconds in game passed.
Action: tensor([[[ 3.6217e-05,  5.9302e-01],
         [ 1.9962e-04,  3.2255e-01],
         [ 2.3429e-04,  2.2189e-01],
         [-1.3903e-04,  1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379101893963563
6.025604143738747 seconds in game passed.
Action: tensor([[[ 3.6217e-05,  5.9302e-01],
         [ 1.9962e-04,  3.2255e-01],
         [ 2.3429e-04,  2.2189e-01],
         [-1.3903e-04,  1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379101893963563
+++++++++++++: 2.0694033231804774
6.050604144111276 seconds in game passed.
At 6.050604144111276 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5975],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0694033231804774
Current reward: 0.5122397923306166
Current mitigation activation: 0
#############################
Total reward: 10.89134168629418
6.075604144483805 seconds in game passed.
Action: tensor([[[0.0031, 0.5975],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.872449, steer=0.003266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.89134168629418
6.100604144856334 seconds in game passed.
Action: tensor([[[0.0031, 0.5975],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.819626, steer=0.003294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.89134168629418
6.125604145228863 seconds in game passed.
Action: tensor([[[0.0031, 0.5975],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.767978, steer=0.003321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.89134168629418
+++++++++++++: 1.8865394609609252
6.150604145601392 seconds in game passed.
At 6.150604145601392 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6212],
         [0.0024, 0.3401],
         [0.0019, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.468048, steer=0.001981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865394609609252
Current reward: 0.513480924832929
Current mitigation activation: 0
#############################
Total reward: 11.40482261112711
6.175604145973921 seconds in game passed.
Action: tensor([[[0.0020, 0.6212],
         [0.0024, 0.3401],
         [0.0019, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.442734, steer=0.002208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.40482261112711
6.20060414634645 seconds in game passed.
Action: tensor([[[0.0020, 0.6212],
         [0.0024, 0.3401],
         [0.0019, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.393300, steer=0.002211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.40482261112711
6.225604146718979 seconds in game passed.
Action: tensor([[[0.0020, 0.6212],
         [0.0024, 0.3401],
         [0.0019, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.362959, steer=0.002214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.40482261112711
+++++++++++++: 1.7243117912230883
6.250604147091508 seconds in game passed.
At 6.250604147091508 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.9912e-04,  6.3561e-01],
         [ 3.2037e-05,  3.4393e-01],
         [-6.7821e-04,  2.3584e-01],
         [-1.7756e-03,  1.8011e-01]]])
agent 0 action: VehicleControl(throttle=0.352190, steer=-0.000065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7243117912230883
Current reward: 0.5125346598849854
Current mitigation activation: 0
#############################
Total reward: 11.917357271012094
6.275604147464037 seconds in game passed.
Action: tensor([[[ 6.9912e-04,  6.3561e-01],
         [ 3.2037e-05,  3.4393e-01],
         [-6.7821e-04,  2.3584e-01],
         [-1.7756e-03,  1.8011e-01]]])
agent 0 action: VehicleControl(throttle=0.339563, steer=0.000289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917357271012094
6.300604147836566 seconds in game passed.
Action: tensor([[[ 6.9912e-04,  6.3561e-01],
         [ 3.2037e-05,  3.4393e-01],
         [-6.7821e-04,  2.3584e-01],
         [-1.7756e-03,  1.8011e-01]]])
agent 0 action: VehicleControl(throttle=0.327354, steer=0.000267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917357271012094
6.325604148209095 seconds in game passed.
Action: tensor([[[ 6.9912e-04,  6.3561e-01],
         [ 3.2037e-05,  3.4393e-01],
         [-6.7821e-04,  2.3584e-01],
         [-1.7756e-03,  1.8011e-01]]])
agent 0 action: VehicleControl(throttle=0.315559, steer=0.000245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917357271012094
+++++++++++++: 1.5888979381058326
6.350604148581624 seconds in game passed.
At 6.350604148581624 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6537],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.304566, steer=-0.000069, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5888979381058326
Current reward: 0.5075473717855874
Current mitigation activation: 0
#############################
Total reward: 12.424904642797681
6.375604148954153 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6537],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.293983, steer=-0.000052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424904642797681
6.400604149326682 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6537],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.283353, steer=-0.000083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424904642797681
6.425604149699211 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6537],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.272696, steer=-0.000114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424904642797681
+++++++++++++: 1.477746030271146
6.45060415007174 seconds in game passed.
At 6.45060415007174 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.6665],
         [-0.0049,  0.3558],
         [-0.0063,  0.2423],
         [-0.0072,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.261926, steer=-0.004495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.477746030271146
Current reward: 0.498127472999229
Current mitigation activation: 0
#############################
Total reward: 12.92303211579691
6.475604150444269 seconds in game passed.
Action: tensor([[[-0.0017,  0.6665],
         [-0.0049,  0.3558],
         [-0.0063,  0.2423],
         [-0.0072,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.251137, steer=-0.003822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92303211579691
6.500604150816798 seconds in game passed.
Action: tensor([[[-0.0017,  0.6665],
         [-0.0049,  0.3558],
         [-0.0063,  0.2423],
         [-0.0072,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.240329, steer=-0.003872, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92303211579691
6.525604151189327 seconds in game passed.
Action: tensor([[[-0.0017,  0.6665],
         [-0.0049,  0.3558],
         [-0.0063,  0.2423],
         [-0.0072,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.229502, steer=-0.003921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92303211579691
+++++++++++++: 1.3816314883670435
6.550604151561856 seconds in game passed.
At 6.550604151561856 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.0331e-04,  6.8507e-01],
         [-4.0931e-03,  3.6634e-01],
         [-5.8710e-03,  2.5059e-01],
         [-7.1920e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.218726, steer=-0.002770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3816314883670435
Current reward: 0.4855993323850294
Current mitigation activation: 0
#############################
Total reward: 13.40863144818194
6.575604151934385 seconds in game passed.
Action: tensor([[[-3.0331e-04,  6.8507e-01],
         [-4.0931e-03,  3.6634e-01],
         [-5.8710e-03,  2.5059e-01],
         [-7.1920e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.207932, steer=-0.002977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.40863144818194
6.600604152306914 seconds in game passed.
Action: tensor([[[-3.0331e-04,  6.8507e-01],
         [-4.0931e-03,  3.6634e-01],
         [-5.8710e-03,  2.5059e-01],
         [-7.1920e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.197119, steer=-0.002990, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.40863144818194
6.625604152679443 seconds in game passed.
Action: tensor([[[-3.0331e-04,  6.8507e-01],
         [-4.0931e-03,  3.6634e-01],
         [-5.8710e-03,  2.5059e-01],
         [-7.1920e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.186287, steer=-0.003003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.40863144818194
+++++++++++++: 1.2942732280497358
6.650604153051972 seconds in game passed.
At 6.650604153051972 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.0470e-04,  1.0000e+00],
         [-4.6777e-03,  1.0000e+00],
         [-5.8893e-03,  1.0000e+00],
         [-6.4411e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002987, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2942732280497358
Current reward: 0.47108714184474343
Current mitigation activation: 1
#############################
Total reward: 13.879718590026682
6.675604153424501 seconds in game passed.
Action: tensor([[[-3.0470e-04,  1.0000e+00],
         [-4.6777e-03,  1.0000e+00],
         [-5.8893e-03,  1.0000e+00],
         [-6.4411e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002984, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879718590026682
6.7006041537970304 seconds in game passed.
Action: tensor([[[-3.0470e-04,  1.0000e+00],
         [-4.6777e-03,  1.0000e+00],
         [-5.8893e-03,  1.0000e+00],
         [-6.4411e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002978, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879718590026682
6.7256041541695595 seconds in game passed.
Action: tensor([[[-3.0470e-04,  1.0000e+00],
         [-4.6777e-03,  1.0000e+00],
         [-5.8893e-03,  1.0000e+00],
         [-6.4411e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002973, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879718590026682
+++++++++++++: 1.21461150353738
6.7506041545420885 seconds in game passed.
At 6.7506041545420885 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000791, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.21461150353738
Current reward: 0.4547241842318934
Current mitigation activation: 1
#############################
Total reward: 14.334442774258576
6.7756041549146175 seconds in game passed.
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001114, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334442774258576
6.800604155287147 seconds in game passed.
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001078, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334442774258576
6.825604155659676 seconds in game passed.
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001043, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334442774258576
+++++++++++++: 1.1618203482365979
6.850604156032205 seconds in game passed.
At 6.850604156032205 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.7002e-03,  1.0000e+00],
         [ 8.5200e-04,  1.0000e+00],
         [-1.3800e-03,  1.0000e+00],
         [-1.3817e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006034, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1618203482365979
Current reward: 0.43192430720498765
Current mitigation activation: 1
#############################
Total reward: 14.766367081463564
6.875604156404734 seconds in game passed.
Action: tensor([[[ 8.7002e-03,  1.0000e+00],
         [ 8.5200e-04,  1.0000e+00],
         [-1.3800e-03,  1.0000e+00],
         [-1.3817e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004934, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766367081463564
6.900604156777263 seconds in game passed.
Action: tensor([[[ 8.7002e-03,  1.0000e+00],
         [ 8.5200e-04,  1.0000e+00],
         [-1.3800e-03,  1.0000e+00],
         [-1.3817e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005002, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766367081463564
6.925604157149792 seconds in game passed.
Action: tensor([[[ 8.7002e-03,  1.0000e+00],
         [ 8.5200e-04,  1.0000e+00],
         [-1.3800e-03,  1.0000e+00],
         [-1.3817e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005071, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766367081463564
+++++++++++++: 1.1432893360506498
6.950604157522321 seconds in game passed.
At 6.950604157522321 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0134,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012144, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1432893360506498
Current reward: 0.40173392590968304
Current mitigation activation: 1
#############################
Total reward: 15.168101007373247
6.97560415789485 seconds in game passed.
Action: tensor([[[-0.0134,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009412, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168101007373247
7.000604158267379 seconds in game passed.
Action: tensor([[[-0.0134,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009529, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168101007373247
7.025604158639908 seconds in game passed.
Action: tensor([[[-0.0134,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009646, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168101007373247
+++++++++++++: 1.1452675775794627
7.050604159012437 seconds in game passed.
At 7.050604159012437 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0113,  1.0000],
         [-0.0064,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009910, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1452675775794627
Current reward: 0.369018361510592
Current mitigation activation: 1
#############################
Total reward: 15.53711936888384
7.075604159384966 seconds in game passed.
Action: tensor([[[-0.0113,  1.0000],
         [-0.0064,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010049, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53711936888384
7.100604159757495 seconds in game passed.
Action: tensor([[[-0.0113,  1.0000],
         [-0.0064,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010207, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53711936888384
7.125604160130024 seconds in game passed.
Action: tensor([[[-0.0113,  1.0000],
         [-0.0064,  1.0000],
         [-0.0079,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010364, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53711936888384
+++++++++++++: 1.1649494399429325
7.150604160502553 seconds in game passed.
At 7.150604160502553 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0160,  1.0000],
         [-0.0115,  1.0000],
         [-0.0090,  1.0000],
         [-0.0051,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016702, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1649494399429325
Current reward: 0.33576120910131535
Current mitigation activation: 1
#############################
Total reward: 15.872880577985155
7.175604160875082 seconds in game passed.
Action: tensor([[[-0.0160,  1.0000],
         [-0.0115,  1.0000],
         [-0.0090,  1.0000],
         [-0.0051,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015887, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872880577985155
7.200604161247611 seconds in game passed.
Action: tensor([[[-0.0160,  1.0000],
         [-0.0115,  1.0000],
         [-0.0090,  1.0000],
         [-0.0051,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016094, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872880577985155
7.22560416162014 seconds in game passed.
Action: tensor([[[-0.0160,  1.0000],
         [-0.0115,  1.0000],
         [-0.0090,  1.0000],
         [-0.0051,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016301, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872880577985155
+++++++++++++: 1.2048969602940411
7.250604161992669 seconds in game passed.
At 7.250604161992669 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0129,  1.0000],
         [-0.0160,  1.0000],
         [-0.0206,  1.0000],
         [-0.0222,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017365, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2048969602940411
Current reward: 0.30276996868299266
Current mitigation activation: 1
#############################
Total reward: 16.175650546668148
7.275604162365198 seconds in game passed.
Action: tensor([[[-0.0129,  1.0000],
         [-0.0160,  1.0000],
         [-0.0206,  1.0000],
         [-0.0222,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017412, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175650546668148
7.300604162737727 seconds in game passed.
Action: tensor([[[-0.0129,  1.0000],
         [-0.0160,  1.0000],
         [-0.0206,  1.0000],
         [-0.0222,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017605, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175650546668148
7.325604163110256 seconds in game passed.
Action: tensor([[[-0.0129,  1.0000],
         [-0.0160,  1.0000],
         [-0.0206,  1.0000],
         [-0.0222,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017798, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175650546668148
+++++++++++++: 1.2705752432529311
7.350604163482785 seconds in game passed.
At 7.350604163482785 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0043,  1.0000],
         [-0.0105,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.022225, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2705752432529311
Current reward: 0.2705414400846706
Current mitigation activation: 1
#############################
Total reward: 16.44619198675282
7.375604163855314 seconds in game passed.
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0043,  1.0000],
         [-0.0105,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015817, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.44619198675282
7.400604164227843 seconds in game passed.
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0043,  1.0000],
         [-0.0105,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016042, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.44619198675282
7.425604164600372 seconds in game passed.
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0043,  1.0000],
         [-0.0105,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016266, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.44619198675282
+++++++++++++: 1.3692303130634942
7.450604164972901 seconds in game passed.
At 7.450604164972901 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.6979e-03, 9.5602e-01],
         [1.1423e-03, 9.5437e-01],
         [4.0241e-04, 9.5377e-01],
         [7.5652e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003505, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3692303130634942
Current reward: 0.23967912979403572
Current mitigation activation: 0
#############################
Total reward: 16.685871116546856
7.47560416534543 seconds in game passed.
Action: tensor([[[1.6979e-03, 9.5602e-01],
         [1.1423e-03, 9.5437e-01],
         [4.0241e-04, 9.5377e-01],
         [7.5652e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000136, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685871116546856
7.500604165717959 seconds in game passed.
Action: tensor([[[1.6979e-03, 9.5602e-01],
         [1.1423e-03, 9.5437e-01],
         [4.0241e-04, 9.5377e-01],
         [7.5652e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000073, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685871116546856
7.525604166090488 seconds in game passed.
Action: tensor([[[1.6979e-03, 9.5602e-01],
         [1.1423e-03, 9.5437e-01],
         [4.0241e-04, 9.5377e-01],
         [7.5652e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000009, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685871116546856
+++++++++++++: 1.51227477805329
7.5506041664630175 seconds in game passed.
At 7.5506041664630175 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.4054e-04, 9.5594e-01],
         [1.0895e-03, 9.5431e-01],
         [9.8450e-04, 9.5374e-01],
         [1.4543e-03, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000594, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.51227477805329
Current reward: 0.21058344132342033
Current mitigation activation: 0
#############################
Total reward: 16.89645455787028
7.5756041668355465 seconds in game passed.
Action: tensor([[[7.4054e-04, 9.5594e-01],
         [1.0895e-03, 9.5431e-01],
         [9.8450e-04, 9.5374e-01],
         [1.4543e-03, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000445, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89645455787028
7.6006041672080755 seconds in game passed.
Action: tensor([[[7.4054e-04, 9.5594e-01],
         [1.0895e-03, 9.5431e-01],
         [9.8450e-04, 9.5374e-01],
         [1.4543e-03, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000400, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89645455787028
7.6256041675806046 seconds in game passed.
Action: tensor([[[7.4054e-04, 9.5594e-01],
         [1.0895e-03, 9.5431e-01],
         [9.8450e-04, 9.5374e-01],
         [1.4543e-03, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000355, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89645455787028
+++++++++++++: 1.7371393691996804
7.650604167953134 seconds in game passed.
At 7.650604167953134 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.6096e-04, 9.5611e-01],
         [1.5308e-03, 9.5461e-01],
         [1.8435e-03, 9.5411e-01],
         [1.9485e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000019, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7371393691996804
Current reward: 0.182425039195503
Current mitigation activation: 0
#############################
Total reward: 17.078879597065782
7.675604168325663 seconds in game passed.
Action: tensor([[[7.6096e-04, 9.5611e-01],
         [1.5308e-03, 9.5461e-01],
         [1.8435e-03, 9.5411e-01],
         [1.9485e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000020, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078879597065782
7.700604168698192 seconds in game passed.
Action: tensor([[[7.6096e-04, 9.5611e-01],
         [1.5308e-03, 9.5461e-01],
         [1.8435e-03, 9.5411e-01],
         [1.9485e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000028, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078879597065782
7.725604169070721 seconds in game passed.
Action: tensor([[[7.6096e-04, 9.5611e-01],
         [1.5308e-03, 9.5461e-01],
         [1.8435e-03, 9.5411e-01],
         [1.9485e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000075, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078879597065782
+++++++++++++: 2.1117231705808854
7.75060416944325 seconds in game passed.
At 7.75060416944325 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.7225e-04, 9.5627e-01],
         [1.5061e-03, 9.5484e-01],
         [1.7485e-03, 9.5437e-01],
         [1.8076e-03, 9.5411e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000029, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1117231705808854
Current reward: 0.1551687312315456
Current mitigation activation: 0
#############################
Total reward: 17.234048328297327
7.775604169815779 seconds in game passed.
Action: tensor([[[6.7225e-04, 9.5627e-01],
         [1.5061e-03, 9.5484e-01],
         [1.7485e-03, 9.5437e-01],
         [1.8076e-03, 9.5411e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000065, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.234048328297327
7.800604170188308 seconds in game passed.
Action: tensor([[[6.7225e-04, 9.5627e-01],
         [1.5061e-03, 9.5484e-01],
         [1.7485e-03, 9.5437e-01],
         [1.8076e-03, 9.5411e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000090, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.234048328297327
7.825604170560837 seconds in game passed.
Action: tensor([[[6.7225e-04, 9.5627e-01],
         [1.5061e-03, 9.5484e-01],
         [1.7485e-03, 9.5437e-01],
         [1.8076e-03, 9.5411e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000114, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.234048328297327
+++++++++++++: 2.8040511787245483
7.850604170933366 seconds in game passed.
At 7.850604170933366 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000540, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8040511787245483
Current reward: 0.1288110810200762
Current mitigation activation: 0
#############################
Total reward: 17.3628594093174
7.875604171305895 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000418, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.3628594093174
7.900604171678424 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000374, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.3628594093174
7.925604172050953 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000331, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.3628594093174
+++++++++++++: 4.332634871843509
7.950604172423482 seconds in game passed.
At 7.950604172423482 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000541, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.332634871843509
Current reward: 0.10380099323468894
Current mitigation activation: 0
#############################
Total reward: 17.46666040255209
7.975604172796011 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000663, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.46666040255209
8.00060417316854 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000799, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.46666040255209
8.025604173541069 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.004043, steer=0.000934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.46666040255209
+++++++++++++: 20.545550385806838
8.050604173913598 seconds in game passed.
At 8.050604173913598 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.006303, steer=0.001066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03940282765756359
Current mitigation activation: 0
#############################
Total reward: 17.506063230209655
8.075604174286127 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.006309, steer=0.001203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506063230209655
8.100604174658656 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.006471, steer=0.001340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506063230209655
8.125604175031185 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.006579, steer=0.001476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506063230209655
+++++++++++++: 1766.9606837755769
8.150604175403714 seconds in game passed.
At 8.150604175403714 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.009918, steer=0.001469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.000470444880279199
Current mitigation activation: 0
#############################
Total reward: 17.506533675089933
8.175604175776243 seconds in game passed.
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001701, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506533675089933
8.200604176148772 seconds in game passed.
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001899, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506533675089933
8.225604176521301 seconds in game passed.
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.007105, steer=0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506533675089933
+++++++++++++: 205.6077938381227
8.25060417689383 seconds in game passed.
At 8.25060417689383 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.0095e-04, 9.5630e-01],
         [1.4879e-03, 9.5487e-01],
         [1.7509e-03, 9.5441e-01],
         [1.8517e-03, 9.5415e-01]]])
agent 0 action: VehicleControl(throttle=0.007133, steer=0.001910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004191868247404315
Current mitigation activation: 0
#############################
Total reward: 17.510725543337337
8.27560417726636 seconds in game passed.
Action: tensor([[[6.0095e-04, 9.5630e-01],
         [1.4879e-03, 9.5487e-01],
         [1.7509e-03, 9.5441e-01],
         [1.8517e-03, 9.5415e-01]]])
agent 0 action: VehicleControl(throttle=0.007111, steer=0.002178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.510725543337337
8.300604177638888 seconds in game passed.
Action: tensor([[[6.0095e-04, 9.5630e-01],
         [1.4879e-03, 9.5487e-01],
         [1.7509e-03, 9.5441e-01],
         [1.8517e-03, 9.5415e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002381, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.510725543337337
8.325604178011417 seconds in game passed.
Action: tensor([[[6.0095e-04, 9.5630e-01],
         [1.4879e-03, 9.5487e-01],
         [1.7509e-03, 9.5441e-01],
         [1.8517e-03, 9.5415e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002584, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.510725543337337
+++++++++++++: 450.3894463633804
8.350604178383946 seconds in game passed.
At 8.350604178383946 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.4506e-04, 9.5604e-01],
         [1.4979e-03, 9.5451e-01],
         [1.7708e-03, 9.5401e-01],
         [1.8992e-03, 9.5373e-01]]])
agent 0 action: VehicleControl(throttle=0.007494, steer=0.002596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0019963750687220718
Current mitigation activation: 0
#############################
Total reward: 17.512721918406058
8.375604178756475 seconds in game passed.
Action: tensor([[[9.4506e-04, 9.5604e-01],
         [1.4979e-03, 9.5451e-01],
         [1.7708e-03, 9.5401e-01],
         [1.8992e-03, 9.5373e-01]]])
agent 0 action: VehicleControl(throttle=0.007107, steer=0.002350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.512721918406058
8.400604179129004 seconds in game passed.
Action: tensor([[[9.4506e-04, 9.5604e-01],
         [1.4979e-03, 9.5451e-01],
         [1.7708e-03, 9.5401e-01],
         [1.8992e-03, 9.5373e-01]]])
agent 0 action: VehicleControl(throttle=0.007138, steer=0.002141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.512721918406058
8.425604179501534 seconds in game passed.
Action: tensor([[[9.4506e-04, 9.5604e-01],
         [1.4979e-03, 9.5451e-01],
         [1.7708e-03, 9.5401e-01],
         [1.8992e-03, 9.5373e-01]]])
agent 0 action: VehicleControl(throttle=0.005155, steer=0.001932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.512721918406058
+++++++++++++: 26011.24096489344
8.450604179874063 seconds in game passed.
At 8.450604179874063 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.2573e-04, 9.5601e-01],
         [1.2807e-03, 9.5445e-01],
         [1.5094e-03, 9.5392e-01],
         [1.7404e-03, 9.5362e-01]]])
agent 0 action: VehicleControl(throttle=0.004835, steer=0.001717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.6188067710920156e-05
Current mitigation activation: 0
#############################
Total reward: 17.51275810647377
8.475604180246592 seconds in game passed.
Action: tensor([[[8.2573e-04, 9.5601e-01],
         [1.2807e-03, 9.5445e-01],
         [1.5094e-03, 9.5392e-01],
         [1.7404e-03, 9.5362e-01]]])
agent 0 action: VehicleControl(throttle=0.004510, steer=0.001747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51275810647377
8.50060418061912 seconds in game passed.
Action: tensor([[[8.2573e-04, 9.5601e-01],
         [1.2807e-03, 9.5445e-01],
         [1.5094e-03, 9.5392e-01],
         [1.7404e-03, 9.5362e-01]]])
agent 0 action: VehicleControl(throttle=0.004237, steer=0.001742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51275810647377
8.52560418099165 seconds in game passed.
Action: tensor([[[8.2573e-04, 9.5601e-01],
         [1.2807e-03, 9.5445e-01],
         [1.5094e-03, 9.5392e-01],
         [1.7404e-03, 9.5362e-01]]])
agent 0 action: VehicleControl(throttle=0.004018, steer=0.001737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51275810647377
+++++++++++++: 1221.9463908721864
8.550604181364179 seconds in game passed.
At 8.550604181364179 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.1637e-03,  9.5587e-01],
         [ 1.4672e-03,  9.5408e-01],
         [-8.3241e-04,  9.5341e-01],
         [-1.2886e-05,  9.5295e-01]]])
agent 0 action: VehicleControl(throttle=0.016046, steer=0.005219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0008082001788503072
Current mitigation activation: 0
#############################
Total reward: 17.513566306652617
8.575604181736708 seconds in game passed.
Action: tensor([[[ 6.1637e-03,  9.5587e-01],
         [ 1.4672e-03,  9.5408e-01],
         [-8.3241e-04,  9.5341e-01],
         [-1.2886e-05,  9.5295e-01]]])
agent 0 action: VehicleControl(throttle=0.014760, steer=0.004683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513566306652617
8.600604182109237 seconds in game passed.
Action: tensor([[[ 6.1637e-03,  9.5587e-01],
         [ 1.4672e-03,  9.5408e-01],
         [-8.3241e-04,  9.5341e-01],
         [-1.2886e-05,  9.5295e-01]]])
agent 0 action: VehicleControl(throttle=0.014798, steer=0.004721, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513566306652617
8.625604182481766 seconds in game passed.
Action: tensor([[[ 6.1637e-03,  9.5587e-01],
         [ 1.4672e-03,  9.5408e-01],
         [-8.3241e-04,  9.5341e-01],
         [-1.2886e-05,  9.5295e-01]]])
agent 0 action: VehicleControl(throttle=0.014856, steer=0.004758, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513566306652617
+++++++++++++: 1062.1268858423007
8.650604182854295 seconds in game passed.
At 8.650604182854295 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0015,  0.9504],
         [-0.0140,  0.9428],
         [-0.0140,  0.7508]]])
agent 0 action: VehicleControl(throttle=0.104085, steer=0.019865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0009770778281229804
Current mitigation activation: 0
#############################
Total reward: 17.51454338448074
8.675604183226824 seconds in game passed.
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0015,  0.9504],
         [-0.0140,  0.9428],
         [-0.0140,  0.7508]]])
agent 0 action: VehicleControl(throttle=0.095717, steer=0.017569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51454338448074
8.700604183599353 seconds in game passed.
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0015,  0.9504],
         [-0.0140,  0.9428],
         [-0.0140,  0.7508]]])
agent 0 action: VehicleControl(throttle=0.096781, steer=0.017759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51454338448074
8.725604183971882 seconds in game passed.
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0015,  0.9504],
         [-0.0140,  0.9428],
         [-0.0140,  0.7508]]])
agent 0 action: VehicleControl(throttle=0.097766, steer=0.017949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51454338448074
+++++++++++++: 1028.5147901848845
8.750604184344411 seconds in game passed.
At 8.750604184344411 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0195,  0.9533],
         [-0.0018,  0.9459],
         [-0.0128,  0.9011],
         [-0.0078,  0.5949]]])
agent 0 action: VehicleControl(throttle=0.076492, steer=0.009321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00106151665272916
Current mitigation activation: 0
#############################
Total reward: 17.515604901133468
8.77560418471694 seconds in game passed.
Action: tensor([[[ 0.0195,  0.9533],
         [-0.0018,  0.9459],
         [-0.0128,  0.9011],
         [-0.0078,  0.5949]]])
agent 0 action: VehicleControl(throttle=0.079492, steer=0.010876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515604901133468
8.800604185089469 seconds in game passed.
Action: tensor([[[ 0.0195,  0.9533],
         [-0.0018,  0.9459],
         [-0.0128,  0.9011],
         [-0.0078,  0.5949]]])
agent 0 action: VehicleControl(throttle=0.080111, steer=0.010976, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515604901133468
8.825604185461998 seconds in game passed.
Action: tensor([[[ 0.0195,  0.9533],
         [-0.0018,  0.9459],
         [-0.0128,  0.9011],
         [-0.0078,  0.5949]]])
agent 0 action: VehicleControl(throttle=0.080725, steer=0.011076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515604901133468
+++++++++++++: 870.258407307052
8.850604185834527 seconds in game passed.
At 8.850604185834527 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.9522],
         [-0.0085,  0.9353],
         [-0.0117,  0.8426],
         [-0.0067,  0.5935]]])
agent 0 action: VehicleControl(throttle=0.072806, steer=-0.006921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0013208644712217898
Current mitigation activation: 0
#############################
Total reward: 17.51692576560469
8.875604186207056 seconds in game passed.
Action: tensor([[[-0.0026,  0.9522],
         [-0.0085,  0.9353],
         [-0.0117,  0.8426],
         [-0.0067,  0.5935]]])
agent 0 action: VehicleControl(throttle=0.074215, steer=-0.004028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51692576560469
8.900604186579585 seconds in game passed.
Action: tensor([[[-0.0026,  0.9522],
         [-0.0085,  0.9353],
         [-0.0117,  0.8426],
         [-0.0067,  0.5935]]])
agent 0 action: VehicleControl(throttle=0.074722, steer=-0.004120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51692576560469
8.925604186952114 seconds in game passed.
Action: tensor([[[-0.0026,  0.9522],
         [-0.0085,  0.9353],
         [-0.0117,  0.8426],
         [-0.0067,  0.5935]]])
agent 0 action: VehicleControl(throttle=0.075232, steer=-0.004211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51692576560469
+++++++++++++: 724.516463693535
8.950604187324643 seconds in game passed.
At 8.950604187324643 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0361,  0.9507],
         [-0.0174,  0.8895],
         [-0.0097,  0.7046],
         [-0.0084,  0.5409]]])
agent 0 action: VehicleControl(throttle=0.289827, steer=-0.030404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0016708481806053342
Current mitigation activation: 0
#############################
Total reward: 17.518596613785295
8.975604187697172 seconds in game passed.
Action: tensor([[[-0.0361,  0.9507],
         [-0.0174,  0.8895],
         [-0.0097,  0.7046],
         [-0.0084,  0.5409]]])
agent 0 action: VehicleControl(throttle=0.270024, steer=-0.026460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518596613785295
9.000604188069701 seconds in game passed.
Action: tensor([[[-0.0361,  0.9507],
         [-0.0174,  0.8895],
         [-0.0097,  0.7046],
         [-0.0084,  0.5409]]])
agent 0 action: VehicleControl(throttle=0.272883, steer=-0.026822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518596613785295
9.02560418844223 seconds in game passed.
Action: tensor([[[-0.0361,  0.9507],
         [-0.0174,  0.8895],
         [-0.0097,  0.7046],
         [-0.0084,  0.5409]]])
agent 0 action: VehicleControl(throttle=0.275505, steer=-0.027183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518596613785295
+++++++++++++: 630.7727952961369
9.05060418881476 seconds in game passed.
At 9.05060418881476 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0407,  0.9493],
         [-0.0168,  0.8093],
         [-0.0073,  0.6013],
         [-0.0056,  0.4894]]])
agent 0 action: VehicleControl(throttle=0.706330, steer=-0.028886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0020216028226501138
Current mitigation activation: 0
#############################
Total reward: 17.520618216607946
9.075604189187288 seconds in game passed.
Action: tensor([[[-0.0407,  0.9493],
         [-0.0168,  0.8093],
         [-0.0073,  0.6013],
         [-0.0056,  0.4894]]])
agent 0 action: VehicleControl(throttle=0.667916, steer=-0.029040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520618216607946
9.100604189559817 seconds in game passed.
Action: tensor([[[-0.0407,  0.9493],
         [-0.0168,  0.8093],
         [-0.0073,  0.6013],
         [-0.0056,  0.4894]]])
agent 0 action: VehicleControl(throttle=0.674710, steer=-0.029415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520618216607946
9.125604189932346 seconds in game passed.
Action: tensor([[[-0.0407,  0.9493],
         [-0.0168,  0.8093],
         [-0.0073,  0.6013],
         [-0.0056,  0.4894]]])
agent 0 action: VehicleControl(throttle=0.681131, steer=-0.029790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520618216607946
+++++++++++++: 447.5802604827907
9.150604190304875 seconds in game passed.
At 9.150604190304875 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0309,  0.9480],
         [-0.0073,  0.7589],
         [-0.0048,  0.5722],
         [-0.0066,  0.4872]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.017633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0029996239861183483
Current mitigation activation: 0
#############################
Total reward: 17.523617840594063
9.175604190677404 seconds in game passed.
Action: tensor([[[-0.0309,  0.9480],
         [-0.0073,  0.7589],
         [-0.0048,  0.5722],
         [-0.0066,  0.4872]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.019943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.523617840594063
9.200604191049933 seconds in game passed.
Action: tensor([[[-0.0309,  0.9480],
         [-0.0073,  0.7589],
         [-0.0048,  0.5722],
         [-0.0066,  0.4872]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.020187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.523617840594063
9.225604191422462 seconds in game passed.
Action: tensor([[[-0.0309,  0.9480],
         [-0.0073,  0.7589],
         [-0.0048,  0.5722],
         [-0.0066,  0.4872]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.020431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.523617840594063
+++++++++++++: 212.12054189383218
9.250604191794991 seconds in game passed.
At 9.250604191794991 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.3040e-02,  9.4098e-01],
         [-3.3337e-03,  5.9485e-01],
         [-8.3560e-04,  4.6956e-01],
         [ 5.5514e-04,  4.1702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006654998890394319
Current mitigation activation: 0
#############################
Total reward: 17.530272839484457
9.27560419216752 seconds in game passed.
Action: tensor([[[-2.3040e-02,  9.4098e-01],
         [-3.3337e-03,  5.9485e-01],
         [-8.3560e-04,  4.6956e-01],
         [ 5.5514e-04,  4.1702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530272839484457
9.30060419254005 seconds in game passed.
Action: tensor([[[-2.3040e-02,  9.4098e-01],
         [-3.3337e-03,  5.9485e-01],
         [-8.3560e-04,  4.6956e-01],
         [ 5.5514e-04,  4.1702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530272839484457
9.325604192912579 seconds in game passed.
Action: tensor([[[-2.3040e-02,  9.4098e-01],
         [-3.3337e-03,  5.9485e-01],
         [-8.3560e-04,  4.6956e-01],
         [ 5.5514e-04,  4.1702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530272839484457
+++++++++++++: 37.35062529335302
9.350604193285108 seconds in game passed.
At 9.350604193285108 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2718e-02,  9.1972e-01],
         [-3.9436e-04,  5.3977e-01],
         [-4.8165e-04,  4.2421e-01],
         [ 1.2560e-04,  3.6975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0396056707258958
Current mitigation activation: 0
#############################
Total reward: 17.56987851021035
9.375604193657637 seconds in game passed.
Action: tensor([[[-1.2718e-02,  9.1972e-01],
         [-3.9436e-04,  5.3977e-01],
         [-4.8165e-04,  4.2421e-01],
         [ 1.2560e-04,  3.6975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.56987851021035
9.400604194030166 seconds in game passed.
Action: tensor([[[-1.2718e-02,  9.1972e-01],
         [-3.9436e-04,  5.3977e-01],
         [-4.8165e-04,  4.2421e-01],
         [ 1.2560e-04,  3.6975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.56987851021035
9.425604194402695 seconds in game passed.
Action: tensor([[[-1.2718e-02,  9.1972e-01],
         [-3.9436e-04,  5.3977e-01],
         [-4.8165e-04,  4.2421e-01],
         [ 1.2560e-04,  3.6975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.56987851021035
+++++++++++++: 17.325834306223715
9.450604194775224 seconds in game passed.
At 9.450604194775224 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0031,  0.8649],
         [-0.0041,  0.4866],
         [-0.0070,  0.3508],
         [-0.0077,  0.2792]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.08907615652167122
Current mitigation activation: 0
#############################
Total reward: 17.658954666732022
9.475604195147753 seconds in game passed.
Action: tensor([[[-0.0031,  0.8649],
         [-0.0041,  0.4866],
         [-0.0070,  0.3508],
         [-0.0077,  0.2792]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.658954666732022
9.500604195520282 seconds in game passed.
Action: tensor([[[-0.0031,  0.8649],
         [-0.0041,  0.4866],
         [-0.0070,  0.3508],
         [-0.0077,  0.2792]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.658954666732022
9.52560419589281 seconds in game passed.
Action: tensor([[[-0.0031,  0.8649],
         [-0.0041,  0.4866],
         [-0.0070,  0.3508],
         [-0.0077,  0.2792]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.658954666732022
+++++++++++++: 9.752684545101344
9.55060419626534 seconds in game passed.
At 9.55060419626534 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0041,  0.8254],
         [-0.0037,  0.4673],
         [-0.0068,  0.3334],
         [-0.0080,  0.2611]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003807, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 9.752684545101344
Current reward: 0.16096451363038905
Current mitigation activation: 0
#############################
Total reward: 17.81991918036241
9.575604196637869 seconds in game passed.
Action: tensor([[[ 0.0041,  0.8254],
         [-0.0037,  0.4673],
         [-0.0068,  0.3334],
         [-0.0080,  0.2611]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.81991918036241
9.600604197010398 seconds in game passed.
Action: tensor([[[ 0.0041,  0.8254],
         [-0.0037,  0.4673],
         [-0.0068,  0.3334],
         [-0.0080,  0.2611]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.81991918036241
9.625604197382927 seconds in game passed.
Action: tensor([[[ 0.0041,  0.8254],
         [-0.0037,  0.4673],
         [-0.0068,  0.3334],
         [-0.0080,  0.2611]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.81991918036241
+++++++++++++: 7.0413587169006755
9.650604197755456 seconds in game passed.
At 9.650604197755456 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0070,  0.8064],
         [-0.0017,  0.4528],
         [-0.0048,  0.3177],
         [-0.0066,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002067, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.0413587169006755
Current reward: 0.18029010136780443
Current mitigation activation: 0
#############################
Total reward: 18.000209281730218
9.675604198127985 seconds in game passed.
Action: tensor([[[ 0.0070,  0.8064],
         [-0.0017,  0.4528],
         [-0.0048,  0.3177],
         [-0.0066,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.000209281730218
9.700604198500514 seconds in game passed.
Action: tensor([[[ 0.0070,  0.8064],
         [-0.0017,  0.4528],
         [-0.0048,  0.3177],
         [-0.0066,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.000209281730218
9.725604198873043 seconds in game passed.
Action: tensor([[[ 0.0070,  0.8064],
         [-0.0017,  0.4528],
         [-0.0048,  0.3177],
         [-0.0066,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.000209281730218
+++++++++++++: 5.773788132876066
9.750604199245572 seconds in game passed.
At 9.750604199245572 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6636e-03,  7.9051e-01],
         [-7.6622e-04,  4.4276e-01],
         [-3.5134e-03,  3.0779e-01],
         [-5.3724e-03,  2.3508e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.773788132876066
Current reward: 0.19679517513846345
Current mitigation activation: 0
#############################
Total reward: 18.19700445686868
9.775604199618101 seconds in game passed.
Action: tensor([[[ 7.6636e-03,  7.9051e-01],
         [-7.6622e-04,  4.4276e-01],
         [-3.5134e-03,  3.0779e-01],
         [-5.3724e-03,  2.3508e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.19700445686868
9.80060419999063 seconds in game passed.
Action: tensor([[[ 7.6636e-03,  7.9051e-01],
         [-7.6622e-04,  4.4276e-01],
         [-3.5134e-03,  3.0779e-01],
         [-5.3724e-03,  2.3508e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.19700445686868
9.82560420036316 seconds in game passed.
Action: tensor([[[ 7.6636e-03,  7.9051e-01],
         [-7.6622e-04,  4.4276e-01],
         [-3.5134e-03,  3.0779e-01],
         [-5.3724e-03,  2.3508e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.19700445686868
+++++++++++++: 4.974430658574589
9.850604200735688 seconds in game passed.
At 9.850604200735688 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0051,  0.7598],
         [-0.0014,  0.4255],
         [-0.0038,  0.2961],
         [-0.0053,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.974430658574589
Current reward: 0.21202551016139973
Current mitigation activation: 0
#############################
Total reward: 18.40902996703008
9.875604201108217 seconds in game passed.
Action: tensor([[[ 0.0051,  0.7598],
         [-0.0014,  0.4255],
         [-0.0038,  0.2961],
         [-0.0053,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003760, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.40902996703008
9.900604201480746 seconds in game passed.
Action: tensor([[[ 0.0051,  0.7598],
         [-0.0014,  0.4255],
         [-0.0038,  0.2961],
         [-0.0053,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.40902996703008
9.925604201853275 seconds in game passed.
Action: tensor([[[ 0.0051,  0.7598],
         [-0.0014,  0.4255],
         [-0.0038,  0.2961],
         [-0.0053,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.40902996703008
+++++++++++++: 4.3979526035872185
9.950604202225804 seconds in game passed.
At 9.950604202225804 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0049,  0.7396],
         [-0.0015,  0.4149],
         [-0.0031,  0.2883],
         [-0.0043,  0.2216]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.3979526035872185
Current reward: 0.22652470486053491
Current mitigation activation: 0
#############################
Total reward: 18.635554671890613
9.975604202598333 seconds in game passed.
Action: tensor([[[ 0.0049,  0.7396],
         [-0.0015,  0.4149],
         [-0.0031,  0.2883],
         [-0.0043,  0.2216]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.635554671890613
10.000604202970862 seconds in game passed.
Action: tensor([[[ 0.0049,  0.7396],
         [-0.0015,  0.4149],
         [-0.0031,  0.2883],
         [-0.0043,  0.2216]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.635554671890613
10.025604203343391 seconds in game passed.
Action: tensor([[[ 0.0049,  0.7396],
         [-0.0015,  0.4149],
         [-0.0031,  0.2883],
         [-0.0043,  0.2216]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.635554671890613
+++++++++++++: 3.9513743327798063
10.05060420371592 seconds in game passed.
At 10.05060420371592 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2608e-02,  7.6140e-01],
         [ 6.2831e-04,  4.2169e-01],
         [-1.1237e-03,  2.9222e-01],
         [-1.9307e-03,  2.2395e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.9513743327798063
Current reward: 0.24049455876798748
Current mitigation activation: 0
#############################
Total reward: 18.8760492306586
10.07560420408845 seconds in game passed.
Action: tensor([[[ 1.2608e-02,  7.6140e-01],
         [ 6.2831e-04,  4.2169e-01],
         [-1.1237e-03,  2.9222e-01],
         [-1.9307e-03,  2.2395e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.8760492306586
10.100604204460979 seconds in game passed.
Action: tensor([[[ 1.2608e-02,  7.6140e-01],
         [ 6.2831e-04,  4.2169e-01],
         [-1.1237e-03,  2.9222e-01],
         [-1.9307e-03,  2.2395e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.8760492306586
10.125604204833508 seconds in game passed.
Action: tensor([[[ 1.2608e-02,  7.6140e-01],
         [ 6.2831e-04,  4.2169e-01],
         [-1.1237e-03,  2.9222e-01],
         [-1.9307e-03,  2.2395e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.8760492306586
+++++++++++++: 3.589418828850694
10.150604205206037 seconds in game passed.
At 10.150604205206037 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5659e-02,  7.5553e-01],
         [ 1.9196e-03,  4.2227e-01],
         [ 5.1720e-04,  2.9409e-01],
         [-3.6091e-05,  2.2615e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005819, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.589418828850694
Current reward: 0.25402188934087533
Current mitigation activation: 0
#############################
Total reward: 19.130071119999478
10.175604205578566 seconds in game passed.
Action: tensor([[[ 1.5659e-02,  7.5553e-01],
         [ 1.9196e-03,  4.2227e-01],
         [ 5.1720e-04,  2.9409e-01],
         [-3.6091e-05,  2.2615e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.130071119999478
10.200604205951095 seconds in game passed.
Action: tensor([[[ 1.5659e-02,  7.5553e-01],
         [ 1.9196e-03,  4.2227e-01],
         [ 5.1720e-04,  2.9409e-01],
         [-3.6091e-05,  2.2615e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006062, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.130071119999478
10.225604206323624 seconds in game passed.
Action: tensor([[[ 1.5659e-02,  7.5553e-01],
         [ 1.9196e-03,  4.2227e-01],
         [ 5.1720e-04,  2.9409e-01],
         [-3.6091e-05,  2.2615e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.130071119999478
+++++++++++++: 3.28682388911424
10.250604206696153 seconds in game passed.
At 10.250604206696153 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0135, 0.7384],
         [0.0025, 0.4161],
         [0.0014, 0.2901],
         [0.0010, 0.2232]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.28682388911424
Current reward: 0.2671356227337043
Current mitigation activation: 0
#############################
Total reward: 19.397206742733182
10.275604207068682 seconds in game passed.
Action: tensor([[[0.0135, 0.7384],
         [0.0025, 0.4161],
         [0.0014, 0.2901],
         [0.0010, 0.2232]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.397206742733182
10.30060420744121 seconds in game passed.
Action: tensor([[[0.0135, 0.7384],
         [0.0025, 0.4161],
         [0.0014, 0.2901],
         [0.0010, 0.2232]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.397206742733182
10.32560420781374 seconds in game passed.
Action: tensor([[[0.0135, 0.7384],
         [0.0025, 0.4161],
         [0.0014, 0.2901],
         [0.0010, 0.2232]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.397206742733182
+++++++++++++: 3.1758745332725415
10.350604208186269 seconds in game passed.
At 10.350604208186269 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0096, 0.7010],
         [0.0021, 0.3901],
         [0.0014, 0.2717],
         [0.0008, 0.2104]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005013, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1758745332725415
Current reward: 0.2740115415105816
Current mitigation activation: 0
#############################
Total reward: 19.671218284243764
10.375604208558798 seconds in game passed.
Action: tensor([[[0.0096, 0.7010],
         [0.0021, 0.3901],
         [0.0014, 0.2717],
         [0.0008, 0.2104]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.671218284243764
10.400604208931327 seconds in game passed.
Action: tensor([[[0.0096, 0.7010],
         [0.0021, 0.3901],
         [0.0014, 0.2717],
         [0.0008, 0.2104]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.671218284243764
10.425604209303856 seconds in game passed.
Action: tensor([[[0.0096, 0.7010],
         [0.0021, 0.3901],
         [0.0014, 0.2717],
         [0.0008, 0.2104]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.671218284243764
+++++++++++++: 3.2108908149352833
10.450604209676385 seconds in game passed.
At 10.450604209676385 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.2356e-03, 6.7341e-01],
         [1.2131e-03, 3.7249e-01],
         [7.8779e-04, 2.6016e-01],
         [3.7763e-04, 2.0304e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003719, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2108908149352833
Current reward: 0.27522771414356656
Current mitigation activation: 0
#############################
Total reward: 19.94644599838733
10.475604210048914 seconds in game passed.
Action: tensor([[[6.2356e-03, 6.7341e-01],
         [1.2131e-03, 3.7249e-01],
         [7.8779e-04, 2.6016e-01],
         [3.7763e-04, 2.0304e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004143, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.94644599838733
10.500604210421443 seconds in game passed.
Action: tensor([[[6.2356e-03, 6.7341e-01],
         [1.2131e-03, 3.7249e-01],
         [7.8779e-04, 2.6016e-01],
         [3.7763e-04, 2.0304e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.94644599838733
10.525604210793972 seconds in game passed.
Action: tensor([[[6.2356e-03, 6.7341e-01],
         [1.2131e-03, 3.7249e-01],
         [7.8779e-04, 2.6016e-01],
         [3.7763e-04, 2.0304e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.94644599838733
+++++++++++++: 3.245456843234725
10.550604211166501 seconds in game passed.
At 10.550604211166501 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.3311e-03, 6.5649e-01],
         [1.4867e-03, 3.6244e-01],
         [9.2332e-04, 2.5270e-01],
         [1.4693e-04, 1.9692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003766, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.245456843234725
Current reward: 0.27648322536136305
Current mitigation activation: 0
#############################
Total reward: 20.222929223748693
10.57560421153903 seconds in game passed.
Action: tensor([[[4.3311e-03, 6.5649e-01],
         [1.4867e-03, 3.6244e-01],
         [9.2332e-04, 2.5270e-01],
         [1.4693e-04, 1.9692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.222929223748693
10.600604211911559 seconds in game passed.
Action: tensor([[[4.3311e-03, 6.5649e-01],
         [1.4867e-03, 3.6244e-01],
         [9.2332e-04, 2.5270e-01],
         [1.4693e-04, 1.9692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.222929223748693
10.625604212284088 seconds in game passed.
Action: tensor([[[4.3311e-03, 6.5649e-01],
         [1.4867e-03, 3.6244e-01],
         [9.2332e-04, 2.5270e-01],
         [1.4693e-04, 1.9692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.222929223748693
+++++++++++++: 3.2803118422125856
10.650604212656617 seconds in game passed.
At 10.650604212656617 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.7139e-03, 6.5521e-01],
         [1.1173e-03, 3.6314e-01],
         [7.6692e-04, 2.5364e-01],
         [3.2417e-05, 1.9792e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2803118422125856
Current reward: 0.27774794322050594
Current mitigation activation: 0
#############################
Total reward: 20.5006771669692
10.675604213029146 seconds in game passed.
Action: tensor([[[2.7139e-03, 6.5521e-01],
         [1.1173e-03, 3.6314e-01],
         [7.6692e-04, 2.5364e-01],
         [3.2417e-05, 1.9792e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.5006771669692
10.700604213401675 seconds in game passed.
Action: tensor([[[2.7139e-03, 6.5521e-01],
         [1.1173e-03, 3.6314e-01],
         [7.6692e-04, 2.5364e-01],
         [3.2417e-05, 1.9792e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.5006771669692
10.725604213774204 seconds in game passed.
Action: tensor([[[2.7139e-03, 6.5521e-01],
         [1.1173e-03, 3.6314e-01],
         [7.6692e-04, 2.5364e-01],
         [3.2417e-05, 1.9792e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.5006771669692
+++++++++++++: 3.3157532219459234
10.750604214146733 seconds in game passed.
At 10.750604214146733 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7205e-03,  6.4300e-01],
         [ 6.6053e-04,  3.5684e-01],
         [ 3.0341e-04,  2.4904e-01],
         [-3.1311e-04,  1.9388e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3157532219459234
Current reward: 0.27900955856901055
Current mitigation activation: 0
#############################
Total reward: 20.779686725538212
10.775604214519262 seconds in game passed.
Action: tensor([[[ 2.7205e-03,  6.4300e-01],
         [ 6.6053e-04,  3.5684e-01],
         [ 3.0341e-04,  2.4904e-01],
         [-3.1311e-04,  1.9388e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.779686725538212
10.800604214891791 seconds in game passed.
Action: tensor([[[ 2.7205e-03,  6.4300e-01],
         [ 6.6053e-04,  3.5684e-01],
         [ 3.0341e-04,  2.4904e-01],
         [-3.1311e-04,  1.9388e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002916, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.779686725538212
10.82560421526432 seconds in game passed.
Action: tensor([[[ 2.7205e-03,  6.4300e-01],
         [ 6.6053e-04,  3.5684e-01],
         [ 3.0341e-04,  2.4904e-01],
         [-3.1311e-04,  1.9388e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.779686725538212
+++++++++++++: 3.200276932622198
10.85060421563685 seconds in game passed.
At 10.85060421563685 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1747e-03,  6.3389e-01],
         [ 3.8439e-04,  3.5281e-01],
         [-1.1803e-04,  2.4673e-01],
         [-7.7702e-04,  1.9219e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.200276932622198
Current reward: 0.2858894811042308
Current mitigation activation: 0
#############################
Total reward: 21.065576206642444
10.875604216009378 seconds in game passed.
Action: tensor([[[ 2.1747e-03,  6.3389e-01],
         [ 3.8439e-04,  3.5281e-01],
         [-1.1803e-04,  2.4673e-01],
         [-7.7702e-04,  1.9219e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.065576206642444
10.900604216381907 seconds in game passed.
Action: tensor([[[ 2.1747e-03,  6.3389e-01],
         [ 3.8439e-04,  3.5281e-01],
         [-1.1803e-04,  2.4673e-01],
         [-7.7702e-04,  1.9219e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.065576206642444
10.925604216754436 seconds in game passed.
Action: tensor([[[ 2.1747e-03,  6.3389e-01],
         [ 3.8439e-04,  3.5281e-01],
         [-1.1803e-04,  2.4673e-01],
         [-7.7702e-04,  1.9219e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.065576206642444
+++++++++++++: 2.9305625773366084
10.950604217126966 seconds in game passed.
At 10.950604217126966 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.9309e-03,  6.4183e-01],
         [ 5.2879e-04,  3.5467e-01],
         [ 1.2731e-04,  2.4601e-01],
         [-4.9201e-04,  1.9044e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9305625773366084
Current reward: 0.29959991540426556
Current mitigation activation: 0
#############################
Total reward: 21.36517612204671
10.975604217499495 seconds in game passed.
Action: tensor([[[ 1.9309e-03,  6.4183e-01],
         [ 5.2879e-04,  3.5467e-01],
         [ 1.2731e-04,  2.4601e-01],
         [-4.9201e-04,  1.9044e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.36517612204671
11.000604217872024 seconds in game passed.
Action: tensor([[[ 1.9309e-03,  6.4183e-01],
         [ 5.2879e-04,  3.5467e-01],
         [ 1.2731e-04,  2.4601e-01],
         [-4.9201e-04,  1.9044e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.36517612204671
11.025604218244553 seconds in game passed.
Action: tensor([[[ 1.9309e-03,  6.4183e-01],
         [ 5.2879e-04,  3.5467e-01],
         [ 1.2731e-04,  2.4601e-01],
         [-4.9201e-04,  1.9044e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.36517612204671
+++++++++++++: 2.7213276673861784
11.050604218617082 seconds in game passed.
At 11.050604218617082 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0009,  0.6617],
         [-0.0011,  0.3637],
         [-0.0018,  0.2508],
         [-0.0026,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7213276673861784
Current reward: 0.3115122201173983
Current mitigation activation: 0
#############################
Total reward: 21.676688342164105
11.07560421898961 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6617],
         [-0.0011,  0.3637],
         [-0.0018,  0.2508],
         [-0.0026,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.676688342164105
11.10060421936214 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6617],
         [-0.0011,  0.3637],
         [-0.0018,  0.2508],
         [-0.0026,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.676688342164105
11.125604219734669 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6617],
         [-0.0011,  0.3637],
         [-0.0018,  0.2508],
         [-0.0026,  0.1936]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.676688342164105
+++++++++++++: 2.545750596165772
11.150604220107198 seconds in game passed.
At 11.150604220107198 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0015,  0.6731],
         [-0.0015,  0.3653],
         [-0.0021,  0.2503],
         [-0.0029,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000828, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.545750596165772
Current reward: 0.3222806092083332
Current mitigation activation: 0
#############################
Total reward: 21.99896895137244
11.175604220479727 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6731],
         [-0.0015,  0.3653],
         [-0.0021,  0.2503],
         [-0.0029,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000753, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.99896895137244
11.200604220852256 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6731],
         [-0.0015,  0.3653],
         [-0.0021,  0.2503],
         [-0.0029,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000665, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.99896895137244
11.225604221224785 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6731],
         [-0.0015,  0.3653],
         [-0.0021,  0.2503],
         [-0.0029,  0.1925]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.99896895137244
+++++++++++++: 2.3908910313580654
11.250604221597314 seconds in game passed.
At 11.250604221597314 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.4810e-04,  6.7311e-01],
         [-2.1490e-03,  3.6457e-01],
         [-2.9983e-03,  2.5046e-01],
         [-3.9153e-03,  1.9312e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3908910313580654
Current reward: 0.3322783009868615
Current mitigation activation: 0
#############################
Total reward: 22.3312472523593
11.275604221969843 seconds in game passed.
Action: tensor([[[-4.4810e-04,  6.7311e-01],
         [-2.1490e-03,  3.6457e-01],
         [-2.9983e-03,  2.5046e-01],
         [-3.9153e-03,  1.9312e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.3312472523593
11.300604222342372 seconds in game passed.
Action: tensor([[[-4.4810e-04,  6.7311e-01],
         [-2.1490e-03,  3.6457e-01],
         [-2.9983e-03,  2.5046e-01],
         [-3.9153e-03,  1.9312e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.3312472523593
11.325604222714901 seconds in game passed.
Action: tensor([[[-4.4810e-04,  6.7311e-01],
         [-2.1490e-03,  3.6457e-01],
         [-2.9983e-03,  2.5046e-01],
         [-3.9153e-03,  1.9312e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.3312472523593
+++++++++++++: 2.2504502320420743
11.35060422308743 seconds in game passed.
At 11.35060422308743 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6839],
         [-0.0035,  0.3705],
         [-0.0043,  0.2555],
         [-0.0052,  0.1970]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2504502320420743
Current reward: 0.34168147023754714
Current mitigation activation: 0
#############################
Total reward: 22.672928722596847
11.375604223459959 seconds in game passed.
Action: tensor([[[-0.0020,  0.6839],
         [-0.0035,  0.3705],
         [-0.0043,  0.2555],
         [-0.0052,  0.1970]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.672928722596847
11.400604223832488 seconds in game passed.
Action: tensor([[[-0.0020,  0.6839],
         [-0.0035,  0.3705],
         [-0.0043,  0.2555],
         [-0.0052,  0.1970]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.672928722596847
11.425604224205017 seconds in game passed.
Action: tensor([[[-0.0020,  0.6839],
         [-0.0035,  0.3705],
         [-0.0043,  0.2555],
         [-0.0052,  0.1970]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.672928722596847
+++++++++++++: 2.120714750544167
11.450604224577546 seconds in game passed.
At 11.450604224577546 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.1139e-04,  6.7809e-01],
         [-3.2147e-03,  3.7137e-01],
         [-4.1530e-03,  2.5708e-01],
         [-4.9209e-03,  1.9841e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.120714750544167
Current reward: 0.3505943727742615
Current mitigation activation: 0
#############################
Total reward: 23.023523095371107
11.475604224950075 seconds in game passed.
Action: tensor([[[-6.1139e-04,  6.7809e-01],
         [-3.2147e-03,  3.7137e-01],
         [-4.1530e-03,  2.5708e-01],
         [-4.9209e-03,  1.9841e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.023523095371107
11.500604225322604 seconds in game passed.
Action: tensor([[[-6.1139e-04,  6.7809e-01],
         [-3.2147e-03,  3.7137e-01],
         [-4.1530e-03,  2.5708e-01],
         [-4.9209e-03,  1.9841e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002110, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.023523095371107
11.525604225695133 seconds in game passed.
Action: tensor([[[-6.1139e-04,  6.7809e-01],
         [-3.2147e-03,  3.7137e-01],
         [-4.1530e-03,  2.5708e-01],
         [-4.9209e-03,  1.9841e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.023523095371107
+++++++++++++: 1.9999425338355865
11.550604226067662 seconds in game passed.
At 11.550604226067662 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0023,  0.6757],
         [-0.0012,  0.3707],
         [-0.0019,  0.2566],
         [-0.0026,  0.1981]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9999425338355865
Current reward: 0.3590253097909466
Current mitigation activation: 0
#############################
Total reward: 23.382548405162055
11.575604226440191 seconds in game passed.
Action: tensor([[[ 0.0023,  0.6757],
         [-0.0012,  0.3707],
         [-0.0019,  0.2566],
         [-0.0026,  0.1981]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000015, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.382548405162055
11.60060422681272 seconds in game passed.
Action: tensor([[[ 0.0023,  0.6757],
         [-0.0012,  0.3707],
         [-0.0019,  0.2566],
         [-0.0026,  0.1981]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.382548405162055
11.62560422718525 seconds in game passed.
Action: tensor([[[ 0.0023,  0.6757],
         [-0.0012,  0.3707],
         [-0.0019,  0.2566],
         [-0.0026,  0.1981]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.382548405162055
+++++++++++++: 1.886636887424457
11.650604227557778 seconds in game passed.
At 11.650604227557778 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.6748],
         [-0.0009,  0.3766],
         [-0.0018,  0.2632],
         [-0.0025,  0.2041]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000013, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.886636887424457
Current reward: 0.3669931471150786
Current mitigation activation: 0
#############################
Total reward: 23.749541552277133
11.675604227930307 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6748],
         [-0.0009,  0.3766],
         [-0.0018,  0.2632],
         [-0.0025,  0.2041]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.749541552277133
11.700604228302836 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6748],
         [-0.0009,  0.3766],
         [-0.0018,  0.2632],
         [-0.0025,  0.2041]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.749541552277133
11.725604228675365 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6748],
         [-0.0009,  0.3766],
         [-0.0018,  0.2632],
         [-0.0025,  0.2041]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.749541552277133
+++++++++++++: 1.7797829536928016
11.750604229047894 seconds in game passed.
At 11.750604229047894 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.0064e-03,  6.8087e-01],
         [ 2.1610e-04,  3.9021e-01],
         [-5.5842e-04,  2.7654e-01],
         [-1.0592e-03,  2.1571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7797829536928016
Current reward: 0.3744924285626713
Current mitigation activation: 0
#############################
Total reward: 24.124033980839805
11.775604229420424 seconds in game passed.
Action: tensor([[[ 7.0064e-03,  6.8087e-01],
         [ 2.1610e-04,  3.9021e-01],
         [-5.5842e-04,  2.7654e-01],
         [-1.0592e-03,  2.1571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.124033980839805
11.800604229792953 seconds in game passed.
Action: tensor([[[ 7.0064e-03,  6.8087e-01],
         [ 2.1610e-04,  3.9021e-01],
         [-5.5842e-04,  2.7654e-01],
         [-1.0592e-03,  2.1571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.124033980839805
11.825604230165482 seconds in game passed.
Action: tensor([[[ 7.0064e-03,  6.8087e-01],
         [ 2.1610e-04,  3.9021e-01],
         [-5.5842e-04,  2.7654e-01],
         [-1.0592e-03,  2.1571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.124033980839805
+++++++++++++: 1.6784415181067467
11.85060423053801 seconds in game passed.
At 11.85060423053801 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.2889e-03,  7.0671e-01],
         [ 5.9387e-04,  3.9635e-01],
         [-3.0033e-04,  2.7754e-01],
         [-7.2275e-04,  2.1454e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6784415181067467
Current reward: 0.3815335012054283
Current mitigation activation: 0
#############################
Total reward: 24.505567482045233
11.87560423091054 seconds in game passed.
Action: tensor([[[ 7.2889e-03,  7.0671e-01],
         [ 5.9387e-04,  3.9635e-01],
         [-3.0033e-04,  2.7754e-01],
         [-7.2275e-04,  2.1454e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.505567482045233
11.900604231283069 seconds in game passed.
Action: tensor([[[ 7.2889e-03,  7.0671e-01],
         [ 5.9387e-04,  3.9635e-01],
         [-3.0033e-04,  2.7754e-01],
         [-7.2275e-04,  2.1454e-01]]])
agent 0 action: VehicleControl(throttle=0.898269, steer=0.002798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.505567482045233
11.925604231655598 seconds in game passed.
Action: tensor([[[ 7.2889e-03,  7.0671e-01],
         [ 5.9387e-04,  3.9635e-01],
         [-3.0033e-04,  2.7754e-01],
         [-7.2275e-04,  2.1454e-01]]])
agent 0 action: VehicleControl(throttle=0.839286, steer=0.002821, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.505567482045233
+++++++++++++: 1.5819156635967349
11.950604232028127 seconds in game passed.
At 11.950604232028127 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.6198e-03,  7.3100e-01],
         [ 6.0140e-04,  4.1157e-01],
         [-2.7848e-04,  2.8889e-01],
         [-4.1839e-04,  2.2353e-01]]])
agent 0 action: VehicleControl(throttle=0.598830, steer=0.003842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5819156635967349
Current reward: 0.38811449448016255
Current mitigation activation: 0
#############################
Total reward: 24.893681976525396
11.975604232400656 seconds in game passed.
Action: tensor([[[ 9.6198e-03,  7.3100e-01],
         [ 6.0140e-04,  4.1157e-01],
         [-2.7848e-04,  2.8889e-01],
         [-4.1839e-04,  2.2353e-01]]])
agent 0 action: VehicleControl(throttle=0.568873, steer=0.003712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.893681976525396
12.000604232773185 seconds in game passed.
Action: tensor([[[ 9.6198e-03,  7.3100e-01],
         [ 6.0140e-04,  4.1157e-01],
         [-2.7848e-04,  2.8889e-01],
         [-4.1839e-04,  2.2353e-01]]])
agent 0 action: VehicleControl(throttle=0.545545, steer=0.003745, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.893681976525396
12.025604233145714 seconds in game passed.
Action: tensor([[[ 9.6198e-03,  7.3100e-01],
         [ 6.0140e-04,  4.1157e-01],
         [-2.7848e-04,  2.8889e-01],
         [-4.1839e-04,  2.2353e-01]]])
agent 0 action: VehicleControl(throttle=0.519871, steer=0.003779, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.893681976525396
+++++++++++++: 1.4910536607845908
12.050604233518243 seconds in game passed.
At 12.050604233518243 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.7452e-03,  7.5413e-01],
         [ 1.5513e-03,  4.1674e-01],
         [ 4.0849e-04,  2.9082e-01],
         [-4.9621e-05,  2.2454e-01]]])
agent 0 action: VehicleControl(throttle=0.495697, steer=0.004555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4910536607845908
Current reward: 0.39401107366065746
Current mitigation activation: 0
#############################
Total reward: 25.287693050186054
12.075604233890772 seconds in game passed.
Action: tensor([[[ 9.7452e-03,  7.5413e-01],
         [ 1.5513e-03,  4.1674e-01],
         [ 4.0849e-04,  2.9082e-01],
         [-4.9621e-05,  2.2454e-01]]])
agent 0 action: VehicleControl(throttle=0.472012, steer=0.004494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.287693050186054
12.100604234263301 seconds in game passed.
Action: tensor([[[ 9.7452e-03,  7.5413e-01],
         [ 1.5513e-03,  4.1674e-01],
         [ 4.0849e-04,  2.9082e-01],
         [-4.9621e-05,  2.2454e-01]]])
agent 0 action: VehicleControl(throttle=0.448812, steer=0.004551, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.287693050186054
12.12560423463583 seconds in game passed.
Action: tensor([[[ 9.7452e-03,  7.5413e-01],
         [ 1.5513e-03,  4.1674e-01],
         [ 4.0849e-04,  2.9082e-01],
         [-4.9621e-05,  2.2454e-01]]])
agent 0 action: VehicleControl(throttle=0.426091, steer=0.004609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.287693050186054
+++++++++++++: 1.415765352752064
12.150604235008359 seconds in game passed.
At 12.150604235008359 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4774e-02,  7.6167e-01],
         [ 1.4072e-03,  4.2257e-01],
         [-2.7213e-04,  2.9584e-01],
         [-9.4339e-04,  2.2871e-01]]])
agent 0 action: VehicleControl(throttle=0.403268, steer=0.006661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.415765352752064
Current reward: 0.39742732976492423
Current mitigation activation: 0
#############################
Total reward: 25.685120379950977
12.175604235380888 seconds in game passed.
Action: tensor([[[ 1.4774e-02,  7.6167e-01],
         [ 1.4072e-03,  4.2257e-01],
         [-2.7213e-04,  2.9584e-01],
         [-9.4339e-04,  2.2871e-01]]])
agent 0 action: VehicleControl(throttle=0.380918, steer=0.006411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.685120379950977
12.200604235753417 seconds in game passed.
Action: tensor([[[ 1.4774e-02,  7.6167e-01],
         [ 1.4072e-03,  4.2257e-01],
         [-2.7213e-04,  2.9584e-01],
         [-9.4339e-04,  2.2871e-01]]])
agent 0 action: VehicleControl(throttle=0.359037, steer=0.006491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.685120379950977
12.225604236125946 seconds in game passed.
Action: tensor([[[ 1.4774e-02,  7.6167e-01],
         [ 1.4072e-03,  4.2257e-01],
         [-2.7213e-04,  2.9584e-01],
         [-9.4339e-04,  2.2871e-01]]])
agent 0 action: VehicleControl(throttle=0.337623, steer=0.006570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.685120379950977
+++++++++++++: 1.3576457246596723
12.250604236498475 seconds in game passed.
At 12.250604236498475 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0087,  0.7919],
         [-0.0018,  0.4280],
         [-0.0036,  0.2961],
         [-0.0045,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.316424, steer=0.001705, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3576457246596723
Current reward: 0.3977650689495461
Current mitigation activation: 0
#############################
Total reward: 26.082885448900523
12.275604236871004 seconds in game passed.
Action: tensor([[[ 0.0087,  0.7919],
         [-0.0018,  0.4280],
         [-0.0036,  0.2961],
         [-0.0045,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.295688, steer=0.002564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.082885448900523
12.300604237243533 seconds in game passed.
Action: tensor([[[ 0.0087,  0.7919],
         [-0.0018,  0.4280],
         [-0.0036,  0.2961],
         [-0.0045,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.275413, steer=0.002605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.082885448900523
12.325604237616062 seconds in game passed.
Action: tensor([[[ 0.0087,  0.7919],
         [-0.0018,  0.4280],
         [-0.0036,  0.2961],
         [-0.0045,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.255597, steer=0.002647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.082885448900523
+++++++++++++: 1.3132201830374732
12.350604237988591 seconds in game passed.
At 12.350604237988591 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0100,  0.8245],
         [-0.0014,  0.4490],
         [-0.0040,  0.3108],
         [-0.0053,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.237119, steer=0.003520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3132201830374732
Current reward: 0.39547273748035583
Current mitigation activation: 0
#############################
Total reward: 26.47835818638088
12.37560423836112 seconds in game passed.
Action: tensor([[[ 0.0100,  0.8245],
         [-0.0014,  0.4490],
         [-0.0040,  0.3108],
         [-0.0053,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.219098, steer=0.003452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.47835818638088
12.40060423873365 seconds in game passed.
Action: tensor([[[ 0.0100,  0.8245],
         [-0.0014,  0.4490],
         [-0.0040,  0.3108],
         [-0.0053,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.201531, steer=0.003518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.47835818638088
12.425604239106178 seconds in game passed.
Action: tensor([[[ 0.0100,  0.8245],
         [-0.0014,  0.4490],
         [-0.0040,  0.3108],
         [-0.0053,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.184419, steer=0.003585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.47835818638088
+++++++++++++: 1.2800518670568362
12.450604239478707 seconds in game passed.
At 12.450604239478707 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0017,  1.0000],
         [-0.0050,  1.0000],
         [-0.0092,  1.0000],
         [-0.0109,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003606, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2800518670568362
Current reward: 0.3909991742437806
Current mitigation activation: 1
#############################
Total reward: 26.86935736062466
12.475604239851236 seconds in game passed.
Action: tensor([[[-0.0017,  1.0000],
         [-0.0050,  1.0000],
         [-0.0092,  1.0000],
         [-0.0109,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002427, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.86935736062466
12.500604240223765 seconds in game passed.
Action: tensor([[[-0.0017,  1.0000],
         [-0.0050,  1.0000],
         [-0.0092,  1.0000],
         [-0.0109,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002443, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.86935736062466
12.525604240596294 seconds in game passed.
Action: tensor([[[-0.0017,  1.0000],
         [-0.0050,  1.0000],
         [-0.0092,  1.0000],
         [-0.0109,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002459, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.86935736062466
+++++++++++++: 1.259640352336026
12.550604240968823 seconds in game passed.
At 12.550604240968823 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0048,  1.0000],
         [-0.0057,  1.0000],
         [-0.0109,  1.0000],
         [-0.0126,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001138, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.259640352336026
Current reward: 0.38416183232859547
Current mitigation activation: 1
#############################
Total reward: 27.253519192953256
12.575604241341352 seconds in game passed.
Action: tensor([[[ 0.0048,  1.0000],
         [-0.0057,  1.0000],
         [-0.0109,  1.0000],
         [-0.0126,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000531, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.253519192953256
12.600604241713881 seconds in game passed.
Action: tensor([[[ 0.0048,  1.0000],
         [-0.0057,  1.0000],
         [-0.0109,  1.0000],
         [-0.0126,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000524, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.253519192953256
12.62560424208641 seconds in game passed.
Action: tensor([[[ 0.0048,  1.0000],
         [-0.0057,  1.0000],
         [-0.0109,  1.0000],
         [-0.0126,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000518, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.253519192953256
+++++++++++++: 1.2805660998933364
12.65060424245894 seconds in game passed.
At 12.65060424245894 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0074,  1.0000],
         [-0.0146,  1.0000],
         [-0.0172,  1.0000],
         [-0.0157,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003470, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2805660998933364
Current reward: 0.37005089531476865
Current mitigation activation: 1
#############################
Total reward: 27.623570088268025
12.675604242831469 seconds in game passed.
Action: tensor([[[ 0.0074,  1.0000],
         [-0.0146,  1.0000],
         [-0.0172,  1.0000],
         [-0.0157,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002862, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.623570088268025
12.700604243203998 seconds in game passed.
Action: tensor([[[ 0.0074,  1.0000],
         [-0.0146,  1.0000],
         [-0.0172,  1.0000],
         [-0.0157,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002910, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.623570088268025
12.725604243576527 seconds in game passed.
Action: tensor([[[ 0.0074,  1.0000],
         [-0.0146,  1.0000],
         [-0.0172,  1.0000],
         [-0.0157,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002959, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.623570088268025
+++++++++++++: 1.3710678676506693
12.750604243949056 seconds in game passed.
At 12.750604243949056 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0063,  0.9397],
         [-0.0096,  0.5566],
         [-0.0117,  0.3623],
         [-0.0109,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002905, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3710678676506693
Current reward: 0.34631577911774725
Current mitigation activation: 0
#############################
Total reward: 27.969885867385774
12.775604244321585 seconds in game passed.
Action: tensor([[[ 0.0063,  0.9397],
         [-0.0096,  0.5566],
         [-0.0117,  0.3623],
         [-0.0109,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003004, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.969885867385774
12.800604244694114 seconds in game passed.
Action: tensor([[[ 0.0063,  0.9397],
         [-0.0096,  0.5566],
         [-0.0117,  0.3623],
         [-0.0109,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003082, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.969885867385774
12.825604245066643 seconds in game passed.
Action: tensor([[[ 0.0063,  0.9397],
         [-0.0096,  0.5566],
         [-0.0117,  0.3623],
         [-0.0109,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003159, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.969885867385774
+++++++++++++: 1.511420376836359
12.850604245439172 seconds in game passed.
At 12.850604245439172 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0089,  0.9448],
         [-0.0155,  0.5810],
         [-0.0172,  0.3680],
         [-0.0154,  0.2701]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006297, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.511420376836359
Current reward: 0.3206728757835207
Current mitigation activation: 0
#############################
Total reward: 28.290558743169296
12.8756042458117 seconds in game passed.
Action: tensor([[[ 0.0089,  0.9448],
         [-0.0155,  0.5810],
         [-0.0172,  0.3680],
         [-0.0154,  0.2701]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005905, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.290558743169296
12.90060424618423 seconds in game passed.
Action: tensor([[[ 0.0089,  0.9448],
         [-0.0155,  0.5810],
         [-0.0172,  0.3680],
         [-0.0154,  0.2701]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006018, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.290558743169296
12.925604246556759 seconds in game passed.
Action: tensor([[[ 0.0089,  0.9448],
         [-0.0155,  0.5810],
         [-0.0172,  0.3680],
         [-0.0154,  0.2701]]])
agent 0 action: VehicleControl(throttle=0.000297, steer=-0.006131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.290558743169296
+++++++++++++: 1.7017038467926968
12.950604246929288 seconds in game passed.
At 12.950604246929288 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0068,  0.9464],
         [-0.0112,  0.6124],
         [-0.0121,  0.3782],
         [-0.0097,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003743, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7017038467926968
Current reward: 0.2959258361739936
Current mitigation activation: 0
#############################
Total reward: 28.58648457934329
12.975604247301817 seconds in game passed.
Action: tensor([[[ 0.0068,  0.9464],
         [-0.0112,  0.6124],
         [-0.0121,  0.3782],
         [-0.0097,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004254, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.58648457934329
13.000604247674346 seconds in game passed.
Action: tensor([[[ 0.0068,  0.9464],
         [-0.0112,  0.6124],
         [-0.0121,  0.3782],
         [-0.0097,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004351, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.58648457934329
13.025604248046875 seconds in game passed.
Action: tensor([[[ 0.0068,  0.9464],
         [-0.0112,  0.6124],
         [-0.0121,  0.3782],
         [-0.0097,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.58648457934329
+++++++++++++: 1.9451100466698357
13.050604248419404 seconds in game passed.
At 13.050604248419404 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0016,  0.9448],
         [-0.0112,  0.6025],
         [-0.0105,  0.3765],
         [-0.0074,  0.2725]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9451100466698357
Current reward: 0.2735338075386573
Current mitigation activation: 0
#############################
Total reward: 28.860018386881947
13.075604248791933 seconds in game passed.
Action: tensor([[[ 0.0016,  0.9448],
         [-0.0112,  0.6025],
         [-0.0105,  0.3765],
         [-0.0074,  0.2725]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.860018386881947
13.100604249164462 seconds in game passed.
Action: tensor([[[ 0.0016,  0.9448],
         [-0.0112,  0.6025],
         [-0.0105,  0.3765],
         [-0.0074,  0.2725]]])
agent 0 action: VehicleControl(throttle=0.023747, steer=-0.006918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.860018386881947
13.125604249536991 seconds in game passed.
Action: tensor([[[ 0.0016,  0.9448],
         [-0.0112,  0.6025],
         [-0.0105,  0.3765],
         [-0.0074,  0.2725]]])
agent 0 action: VehicleControl(throttle=0.057508, steer=-0.007049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.860018386881947
+++++++++++++: 2.2175490787854883
13.15060424990952 seconds in game passed.
At 13.15060424990952 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.8299e-03, 9.4431e-01],
         [2.9208e-03, 5.7693e-01],
         [1.9008e-04, 3.7099e-01],
         [1.3253e-03, 2.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.351521, steer=0.006942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2175490787854883
Current reward: 0.25581043479087767
Current mitigation activation: 0
#############################
Total reward: 29.115828821672824
13.17560425028205 seconds in game passed.
Action: tensor([[[9.8299e-03, 9.4431e-01],
         [2.9208e-03, 5.7693e-01],
         [1.9008e-04, 3.7099e-01],
         [1.3253e-03, 2.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.366976, steer=0.004604, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.115828821672824
13.200604250654578 seconds in game passed.
Action: tensor([[[9.8299e-03, 9.4431e-01],
         [2.9208e-03, 5.7693e-01],
         [1.9008e-04, 3.7099e-01],
         [1.3253e-03, 2.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.415085, steer=0.004599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.115828821672824
13.225604251027107 seconds in game passed.
Action: tensor([[[9.8299e-03, 9.4431e-01],
         [2.9208e-03, 5.7693e-01],
         [1.9008e-04, 3.7099e-01],
         [1.3253e-03, 2.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.458261, steer=0.004593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.115828821672824
+++++++++++++: 2.395988346529861
13.250604251399636 seconds in game passed.
At 13.250604251399636 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0095, 0.9398],
         [0.0060, 0.5515],
         [0.0020, 0.3617],
         [0.0015, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.789667, steer=0.006702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.395988346529861
Current reward: 0.24789481713055844
Current mitigation activation: 0
#############################
Total reward: 29.363723638803382
13.275604251772165 seconds in game passed.
Action: tensor([[[0.0095, 0.9398],
         [0.0060, 0.5515],
         [0.0020, 0.3617],
         [0.0015, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.794821, steer=0.006429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.363723638803382
13.300604252144694 seconds in game passed.
Action: tensor([[[0.0095, 0.9398],
         [0.0060, 0.5515],
         [0.0020, 0.3617],
         [0.0015, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.825799, steer=0.006496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.363723638803382
13.325604252517223 seconds in game passed.
Action: tensor([[[0.0095, 0.9398],
         [0.0060, 0.5515],
         [0.0020, 0.3617],
         [0.0015, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.850294, steer=0.006563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.363723638803382
+++++++++++++: 2.5791933216914846
13.350604252889752 seconds in game passed.
At 13.350604252889752 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0068, 0.9293],
         [0.0047, 0.5197],
         [0.0015, 0.3469],
         [0.0013, 0.2549]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5791933216914846
Current reward: 0.2416063536373184
Current mitigation activation: 0
#############################
Total reward: 29.6053299924407
13.375604253262281 seconds in game passed.
Action: tensor([[[0.0068, 0.9293],
         [0.0047, 0.5197],
         [0.0015, 0.3469],
         [0.0013, 0.2549]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.6053299924407
13.40060425363481 seconds in game passed.
Action: tensor([[[0.0068, 0.9293],
         [0.0047, 0.5197],
         [0.0015, 0.3469],
         [0.0013, 0.2549]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.6053299924407
13.42560425400734 seconds in game passed.
Action: tensor([[[0.0068, 0.9293],
         [0.0047, 0.5197],
         [0.0015, 0.3469],
         [0.0013, 0.2549]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.6053299924407
+++++++++++++: 2.630412736945642
13.450604254379869 seconds in game passed.
At 13.450604254379869 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.9204],
         [0.0044, 0.5068],
         [0.0025, 0.3412],
         [0.0026, 0.2528]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002880, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.630412736945642
Current reward: 0.24235292158121394
Current mitigation activation: 0
#############################
Total reward: 29.847682914021917
13.475604254752398 seconds in game passed.
Action: tensor([[[0.0025, 0.9204],
         [0.0044, 0.5068],
         [0.0025, 0.3412],
         [0.0026, 0.2528]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.847682914021917
13.500604255124927 seconds in game passed.
Action: tensor([[[0.0025, 0.9204],
         [0.0044, 0.5068],
         [0.0025, 0.3412],
         [0.0026, 0.2528]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.847682914021917
13.525604255497456 seconds in game passed.
Action: tensor([[[0.0025, 0.9204],
         [0.0044, 0.5068],
         [0.0025, 0.3412],
         [0.0026, 0.2528]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.847682914021917
+++++++++++++: 2.5576013340745773
13.550604255869985 seconds in game passed.
At 13.550604255869985 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.9080],
         [ 0.0010,  0.4881],
         [-0.0016,  0.3283],
         [-0.0015,  0.2436]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5576013340745773
Current reward: 0.24874855383436356
Current mitigation activation: 0
#############################
Total reward: 30.09643146785628
13.575604256242514 seconds in game passed.
Action: tensor([[[ 0.0011,  0.9080],
         [ 0.0010,  0.4881],
         [-0.0016,  0.3283],
         [-0.0015,  0.2436]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.09643146785628
13.600604256615043 seconds in game passed.
Action: tensor([[[ 0.0011,  0.9080],
         [ 0.0010,  0.4881],
         [-0.0016,  0.3283],
         [-0.0015,  0.2436]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000972, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.09643146785628
13.625604256987572 seconds in game passed.
Action: tensor([[[ 0.0011,  0.9080],
         [ 0.0010,  0.4881],
         [-0.0016,  0.3283],
         [-0.0015,  0.2436]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.09643146785628
+++++++++++++: 2.430853221433276
13.6506042573601 seconds in game passed.
At 13.6506042573601 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.3724e-03,  8.9487e-01],
         [-7.9722e-04,  4.8441e-01],
         [-2.2504e-03,  3.3168e-01],
         [-1.5686e-03,  2.4906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.430853221433276
Current reward: 0.25781308948318465
Current mitigation activation: 0
#############################
Total reward: 30.354244557339467
13.67560425773263 seconds in game passed.
Action: tensor([[[-2.3724e-03,  8.9487e-01],
         [-7.9722e-04,  4.8441e-01],
         [-2.2504e-03,  3.3168e-01],
         [-1.5686e-03,  2.4906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.354244557339467
13.700604258105159 seconds in game passed.
Action: tensor([[[-2.3724e-03,  8.9487e-01],
         [-7.9722e-04,  4.8441e-01],
         [-2.2504e-03,  3.3168e-01],
         [-1.5686e-03,  2.4906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.354244557339467
13.725604258477688 seconds in game passed.
Action: tensor([[[-2.3724e-03,  8.9487e-01],
         [-7.9722e-04,  4.8441e-01],
         [-2.2504e-03,  3.3168e-01],
         [-1.5686e-03,  2.4906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.354244557339467
+++++++++++++: 2.289162634218957
13.750604258850217 seconds in game passed.
At 13.750604258850217 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0103,  0.9020],
         [-0.0027,  0.5042],
         [-0.0041,  0.3505],
         [-0.0038,  0.2672]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006075, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.289162634218957
Current reward: 0.2679598935136068
Current mitigation activation: 0
#############################
Total reward: 30.622204450853072
13.775604259222746 seconds in game passed.
Action: tensor([[[-0.0103,  0.9020],
         [-0.0027,  0.5042],
         [-0.0041,  0.3505],
         [-0.0038,  0.2672]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.622204450853072
13.800604259595275 seconds in game passed.
Action: tensor([[[-0.0103,  0.9020],
         [-0.0027,  0.5042],
         [-0.0041,  0.3505],
         [-0.0038,  0.2672]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.622204450853072
13.825604259967804 seconds in game passed.
Action: tensor([[[-0.0103,  0.9020],
         [-0.0027,  0.5042],
         [-0.0041,  0.3505],
         [-0.0038,  0.2672]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.622204450853072
+++++++++++++: 2.149211279300686
13.850604260340333 seconds in game passed.
At 13.850604260340333 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0042,  0.8933],
         [-0.0028,  0.5120],
         [-0.0040,  0.3710],
         [-0.0031,  0.2940]]])
agent 0 action: VehicleControl(throttle=0.865999, steer=-0.002791, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.149211279300686
Current reward: 0.27838830148795257
Current mitigation activation: 0
#############################
Total reward: 30.900592752341026
13.875604260712862 seconds in game passed.
Action: tensor([[[-0.0042,  0.8933],
         [-0.0028,  0.5120],
         [-0.0040,  0.3710],
         [-0.0031,  0.2940]]])
agent 0 action: VehicleControl(throttle=0.851628, steer=-0.003172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.900592752341026
13.900604261085391 seconds in game passed.
Action: tensor([[[-0.0042,  0.8933],
         [-0.0028,  0.5120],
         [-0.0040,  0.3710],
         [-0.0031,  0.2940]]])
agent 0 action: VehicleControl(throttle=0.819848, steer=-0.003136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.900592752341026
13.92560426145792 seconds in game passed.
Action: tensor([[[-0.0042,  0.8933],
         [-0.0028,  0.5120],
         [-0.0040,  0.3710],
         [-0.0031,  0.2940]]])
agent 0 action: VehicleControl(throttle=0.787978, steer=-0.003099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.900592752341026
+++++++++++++: 2.0171494371219256
13.950604261830449 seconds in game passed.
At 13.950604261830449 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.4355e-04,  8.7673e-01],
         [-2.5290e-03,  4.9917e-01],
         [-4.3054e-03,  3.5738e-01],
         [-3.6658e-03,  2.7914e-01]]])
agent 0 action: VehicleControl(throttle=0.869443, steer=-0.001315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0171494371219256
Current reward: 0.2886803145160841
Current mitigation activation: 0
#############################
Total reward: 31.189273066857112
13.975604262202978 seconds in game passed.
Action: tensor([[[-5.4355e-04,  8.7673e-01],
         [-2.5290e-03,  4.9917e-01],
         [-4.3054e-03,  3.5738e-01],
         [-3.6658e-03,  2.7914e-01]]])
agent 0 action: VehicleControl(throttle=0.827135, steer=-0.001578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.189273066857112
14.000604262575507 seconds in game passed.
Action: tensor([[[-5.4355e-04,  8.7673e-01],
         [-2.5290e-03,  4.9917e-01],
         [-4.3054e-03,  3.5738e-01],
         [-3.6658e-03,  2.7914e-01]]])
agent 0 action: VehicleControl(throttle=0.797262, steer=-0.001549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.189273066857112
14.025604262948036 seconds in game passed.
Action: tensor([[[-5.4355e-04,  8.7673e-01],
         [-2.5290e-03,  4.9917e-01],
         [-4.3054e-03,  3.5738e-01],
         [-3.6658e-03,  2.7914e-01]]])
agent 0 action: VehicleControl(throttle=0.767028, steer=-0.001520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.189273066857112
+++++++++++++: 1.8984525419182743
14.050604263320565 seconds in game passed.
At 14.050604263320565 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.2111e-03,  8.9858e-01],
         [-8.2824e-04,  5.0034e-01],
         [-2.0383e-03,  3.5038e-01],
         [-1.8677e-03,  2.6984e-01]]])
agent 0 action: VehicleControl(throttle=0.827640, steer=-0.003010, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8984525419182743
Current reward: 0.29827647034036087
Current mitigation activation: 0
#############################
Total reward: 31.487549537197474
14.075604263693094 seconds in game passed.
Action: tensor([[[-7.2111e-03,  8.9858e-01],
         [-8.2824e-04,  5.0034e-01],
         [-2.0383e-03,  3.5038e-01],
         [-1.8677e-03,  2.6984e-01]]])
agent 0 action: VehicleControl(throttle=0.789484, steer=-0.002716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.487549537197474
14.100604264065623 seconds in game passed.
Action: tensor([[[-7.2111e-03,  8.9858e-01],
         [-8.2824e-04,  5.0034e-01],
         [-2.0383e-03,  3.5038e-01],
         [-1.8677e-03,  2.6984e-01]]])
agent 0 action: VehicleControl(throttle=0.761097, steer=-0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.487549537197474
14.125604264438152 seconds in game passed.
Action: tensor([[[-7.2111e-03,  8.9858e-01],
         [-8.2824e-04,  5.0034e-01],
         [-2.0383e-03,  3.5038e-01],
         [-1.8677e-03,  2.6984e-01]]])
agent 0 action: VehicleControl(throttle=0.732252, steer=-0.002638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.487549537197474
+++++++++++++: 1.793722589771253
14.150604264810681 seconds in game passed.
At 14.150604264810681 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0017,  0.9187],
         [-0.0030,  0.5044],
         [-0.0054,  0.3453],
         [-0.0047,  0.2606]]])
agent 0 action: VehicleControl(throttle=0.733397, steer=-0.000688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.793722589771253
Current reward: 0.30687730388359447
Current mitigation activation: 0
#############################
Total reward: 31.79442684108107
14.17560426518321 seconds in game passed.
Action: tensor([[[ 0.0017,  0.9187],
         [-0.0030,  0.5044],
         [-0.0054,  0.3453],
         [-0.0047,  0.2606]]])
agent 0 action: VehicleControl(throttle=0.698735, steer=-0.001113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.79442684108107
14.20060426555574 seconds in game passed.
Action: tensor([[[ 0.0017,  0.9187],
         [-0.0030,  0.5044],
         [-0.0054,  0.3453],
         [-0.0047,  0.2606]]])
agent 0 action: VehicleControl(throttle=0.667796, steer=-0.001198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.79442684108107
14.225604265928268 seconds in game passed.
Action: tensor([[[ 0.0017,  0.9187],
         [-0.0030,  0.5044],
         [-0.0054,  0.3453],
         [-0.0047,  0.2606]]])
agent 0 action: VehicleControl(throttle=0.637134, steer=-0.001284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.79442684108107
+++++++++++++: 1.7020145771130455
14.250604266300797 seconds in game passed.
At 14.250604266300797 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0051,  0.9327],
         [-0.0040,  0.5131],
         [-0.0064,  0.3407],
         [-0.0049,  0.2521]]])
agent 0 action: VehicleControl(throttle=0.535464, steer=-0.000704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7020145771130455
Current reward: 0.31432484365194685
Current mitigation activation: 0
#############################
Total reward: 32.108751684733015
14.275604266673326 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9327],
         [-0.0040,  0.5131],
         [-0.0064,  0.3407],
         [-0.0049,  0.2521]]])
agent 0 action: VehicleControl(throttle=0.509669, steer=-0.000917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.108751684733015
14.300604267045856 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9327],
         [-0.0040,  0.5131],
         [-0.0064,  0.3407],
         [-0.0049,  0.2521]]])
agent 0 action: VehicleControl(throttle=0.478092, steer=-0.001017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.108751684733015
14.325604267418385 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9327],
         [-0.0040,  0.5131],
         [-0.0064,  0.3407],
         [-0.0049,  0.2521]]])
agent 0 action: VehicleControl(throttle=0.448857, steer=-0.001116, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.108751684733015
+++++++++++++: 1.626173278197315
14.350604267790914 seconds in game passed.
At 14.350604267790914 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0037,  0.9400],
         [-0.0043,  0.5335],
         [-0.0059,  0.3468],
         [-0.0035,  0.2544]]])
agent 0 action: VehicleControl(throttle=0.341513, steer=-0.001974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.626173278197315
Current reward: 0.32006063418310227
Current mitigation activation: 0
#############################
Total reward: 32.428812318916115
14.375604268163443 seconds in game passed.
Action: tensor([[[ 0.0037,  0.9400],
         [-0.0043,  0.5335],
         [-0.0059,  0.3468],
         [-0.0035,  0.2544]]])
agent 0 action: VehicleControl(throttle=0.337470, steer=-0.001930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.428812318916115
14.400604268535972 seconds in game passed.
Action: tensor([[[ 0.0037,  0.9400],
         [-0.0043,  0.5335],
         [-0.0059,  0.3468],
         [-0.0035,  0.2544]]])
agent 0 action: VehicleControl(throttle=0.323262, steer=-0.002014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.428812318916115
14.4256042689085 seconds in game passed.
Action: tensor([[[ 0.0037,  0.9400],
         [-0.0043,  0.5335],
         [-0.0059,  0.3468],
         [-0.0035,  0.2544]]])
agent 0 action: VehicleControl(throttle=0.309199, steer=-0.002099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.428812318916115
+++++++++++++: 1.5737834229188663
14.45060426928103 seconds in game passed.
At 14.45060426928103 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0078,  0.9432],
         [-0.0024,  0.5593],
         [-0.0047,  0.3605],
         [-0.0026,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001220, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5737834229188663
Current reward: 0.3229299619199747
Current mitigation activation: 0
#############################
Total reward: 32.75174228083609
14.475604269653559 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9432],
         [-0.0024,  0.5593],
         [-0.0047,  0.3605],
         [-0.0026,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000634, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.75174228083609
14.500604270026088 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9432],
         [-0.0024,  0.5593],
         [-0.0047,  0.3605],
         [-0.0026,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000606, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.75174228083609
14.525604270398617 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9432],
         [-0.0024,  0.5593],
         [-0.0047,  0.3605],
         [-0.0026,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000578, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.75174228083609
+++++++++++++: 1.5536119715677688
14.550604270771146 seconds in game passed.
At 14.550604270771146 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.9423],
         [-0.0046,  0.5536],
         [-0.0067,  0.3582],
         [-0.0052,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004066, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5536119715677688
Current reward: 0.3217085563529499
Current mitigation activation: 0
#############################
Total reward: 33.07345083718904
14.575604271143675 seconds in game passed.
Action: tensor([[[ 0.0011,  0.9423],
         [-0.0046,  0.5536],
         [-0.0067,  0.3582],
         [-0.0052,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.215208, steer=-0.003343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.07345083718904
14.600604271516204 seconds in game passed.
Action: tensor([[[ 0.0011,  0.9423],
         [-0.0046,  0.5536],
         [-0.0067,  0.3582],
         [-0.0052,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.199018, steer=-0.003387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.07345083718904
14.625604271888733 seconds in game passed.
Action: tensor([[[ 0.0011,  0.9423],
         [-0.0046,  0.5536],
         [-0.0067,  0.3582],
         [-0.0052,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.183239, steer=-0.003431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.07345083718904
+++++++++++++: 1.5996528715709017
14.650604272261262 seconds in game passed.
At 14.650604272261262 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0063,  0.9415],
         [-0.0022,  0.5605],
         [-0.0033,  0.3650],
         [-0.0026,  0.2671]]])
agent 0 action: VehicleControl(throttle=0.167915, steer=-0.004910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5996528715709017
Current reward: 0.31271702361186854
Current mitigation activation: 0
#############################
Total reward: 33.38616786080091
14.675604272633791 seconds in game passed.
Action: tensor([[[-0.0063,  0.9415],
         [-0.0022,  0.5605],
         [-0.0033,  0.3650],
         [-0.0026,  0.2671]]])
agent 0 action: VehicleControl(throttle=0.153025, steer=-0.004698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.38616786080091
14.70060427300632 seconds in game passed.
Action: tensor([[[-0.0063,  0.9415],
         [-0.0022,  0.5605],
         [-0.0033,  0.3650],
         [-0.0026,  0.2671]]])
agent 0 action: VehicleControl(throttle=0.138577, steer=-0.004727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.38616786080091
14.725604273378849 seconds in game passed.
Action: tensor([[[-0.0063,  0.9415],
         [-0.0022,  0.5605],
         [-0.0033,  0.3650],
         [-0.0026,  0.2671]]])
agent 0 action: VehicleControl(throttle=0.124580, steer=-0.004757, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.38616786080091
+++++++++++++: 1.6751912289502873
14.750604273751378 seconds in game passed.
At 14.750604273751378 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0031,  0.9445],
         [ 0.0020,  0.5825],
         [ 0.0012,  0.3763],
         [ 0.0013,  0.2759]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000190, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6751912289502873
Current reward: 0.30177403860761387
Current mitigation activation: 0
#############################
Total reward: 33.68794189940852
14.775604274123907 seconds in game passed.
Action: tensor([[[-0.0031,  0.9445],
         [ 0.0020,  0.5825],
         [ 0.0012,  0.3763],
         [ 0.0013,  0.2759]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000872, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.68794189940852
14.800604274496436 seconds in game passed.
Action: tensor([[[-0.0031,  0.9445],
         [ 0.0020,  0.5825],
         [ 0.0012,  0.3763],
         [ 0.0013,  0.2759]]])
agent 0 action: VehicleControl(throttle=0.094719, steer=-0.000805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.68794189940852
14.825604274868965 seconds in game passed.
Action: tensor([[[-0.0031,  0.9445],
         [ 0.0020,  0.5825],
         [ 0.0012,  0.3763],
         [ 0.0013,  0.2759]]])
agent 0 action: VehicleControl(throttle=0.085695, steer=-0.000737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.68794189940852
+++++++++++++: 1.7513899954246774
14.850604275241494 seconds in game passed.
At 14.850604275241494 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.5879e-03,  9.4185e-01],
         [ 8.1612e-04,  5.9083e-01],
         [-9.0249e-05,  3.9874e-01],
         [-7.8131e-04,  3.0355e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003706, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7513899954246774
Current reward: 0.29247465386844707
Current mitigation activation: 0
#############################
Total reward: 33.98041655327697
14.875604275614023 seconds in game passed.
Action: tensor([[[-7.5879e-03,  9.4185e-01],
         [ 8.1612e-04,  5.9083e-01],
         [-9.0249e-05,  3.9874e-01],
         [-7.8131e-04,  3.0355e-01]]])
agent 0 action: VehicleControl(throttle=0.072599, steer=-0.003199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98041655327697
14.900604275986552 seconds in game passed.
Action: tensor([[[-7.5879e-03,  9.4185e-01],
         [ 8.1612e-04,  5.9083e-01],
         [-9.0249e-05,  3.9874e-01],
         [-7.8131e-04,  3.0355e-01]]])
agent 0 action: VehicleControl(throttle=0.066757, steer=-0.003189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98041655327697
14.925604276359081 seconds in game passed.
Action: tensor([[[-7.5879e-03,  9.4185e-01],
         [ 8.1612e-04,  5.9083e-01],
         [-9.0249e-05,  3.9874e-01],
         [-7.8131e-04,  3.0355e-01]]])
agent 0 action: VehicleControl(throttle=0.061381, steer=-0.003179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98041655327697
+++++++++++++: 1.8546932976495005
14.95060427673161 seconds in game passed.
At 14.95060427673161 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0195,  0.9427],
         [-0.0052,  0.5729],
         [-0.0044,  0.3715],
         [-0.0034,  0.2715]]])
agent 0 action: VehicleControl(throttle=0.055214, steer=-0.013009, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8546932976495005
Current reward: 0.28231909620433904
Current mitigation activation: 0
#############################
Total reward: 34.26273564948131
14.97560427710414 seconds in game passed.
Action: tensor([[[-0.0195,  0.9427],
         [-0.0052,  0.5729],
         [-0.0044,  0.3715],
         [-0.0034,  0.2715]]])
agent 0 action: VehicleControl(throttle=0.058356, steer=-0.011498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.26273564948131
15.000604277476668 seconds in game passed.
Action: tensor([[[-0.0195,  0.9427],
         [-0.0052,  0.5729],
         [-0.0044,  0.3715],
         [-0.0034,  0.2715]]])
agent 0 action: VehicleControl(throttle=0.091228, steer=-0.011607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.26273564948131
15.025604277849197 seconds in game passed.
Action: tensor([[[-0.0195,  0.9427],
         [-0.0052,  0.5729],
         [-0.0044,  0.3715],
         [-0.0034,  0.2715]]])
agent 0 action: VehicleControl(throttle=0.121414, steer=-0.011717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.26273564948131
+++++++++++++: 1.9709255865757855
15.050604278221726 seconds in game passed.
At 15.050604278221726 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0187,  0.9471],
         [-0.0052,  0.6067],
         [-0.0032,  0.3779],
         [-0.0019,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.026401, steer=-0.011722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9709255865757855
Current reward: 0.27300006709016045
Current mitigation activation: 0
#############################
Total reward: 34.535735716571466
15.075604278594255 seconds in game passed.
Action: tensor([[[-0.0187,  0.9471],
         [-0.0052,  0.6067],
         [-0.0032,  0.3779],
         [-0.0019,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.030578, steer=-0.011829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.535735716571466
15.100604278966784 seconds in game passed.
Action: tensor([[[-0.0187,  0.9471],
         [-0.0052,  0.6067],
         [-0.0032,  0.3779],
         [-0.0019,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.026004, steer=-0.011921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.535735716571466
15.125604279339314 seconds in game passed.
Action: tensor([[[-0.0187,  0.9471],
         [-0.0052,  0.6067],
         [-0.0032,  0.3779],
         [-0.0019,  0.2720]]])
agent 0 action: VehicleControl(throttle=0.021834, steer=-0.012014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.535735716571466
+++++++++++++: 2.1013328353559246
15.150604279711843 seconds in game passed.
At 15.150604279711843 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6720e-02,  9.4815e-01],
         [-1.8318e-03,  6.2179e-01],
         [ 5.0983e-04,  3.8260e-01],
         [ 1.7839e-03,  2.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.017697, steer=-0.008826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1013328353559246
Current reward: 0.2644931312430676
Current mitigation activation: 0
#############################
Total reward: 34.80022884781453
15.175604280084372 seconds in game passed.
Action: tensor([[[-1.6720e-02,  9.4815e-01],
         [-1.8318e-03,  6.2179e-01],
         [ 5.0983e-04,  3.8260e-01],
         [ 1.7839e-03,  2.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.013943, steer=-0.009450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.80022884781453
15.2006042804569 seconds in game passed.
Action: tensor([[[-1.6720e-02,  9.4815e-01],
         [-1.8318e-03,  6.2179e-01],
         [ 5.0983e-04,  3.8260e-01],
         [ 1.7839e-03,  2.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.010558, steer=-0.009530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.80022884781453
15.22560428082943 seconds in game passed.
Action: tensor([[[-1.6720e-02,  9.4815e-01],
         [-1.8318e-03,  6.2179e-01],
         [ 5.0983e-04,  3.8260e-01],
         [ 1.7839e-03,  2.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.007528, steer=-0.009609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.80022884781453
+++++++++++++: 2.2513006292273645
15.250604281201959 seconds in game passed.
At 15.250604281201959 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0102,  0.9459],
         [ 0.0015,  0.5778],
         [ 0.0013,  0.3659],
         [ 0.0018,  0.2650]]])
agent 0 action: VehicleControl(throttle=0.379919, steer=-0.003898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2513006292273645
Current reward: 0.2565332713049089
Current mitigation activation: 0
#############################
Total reward: 35.05676211911944
15.275604281574488 seconds in game passed.
Action: tensor([[[-0.0102,  0.9459],
         [ 0.0015,  0.5778],
         [ 0.0013,  0.3659],
         [ 0.0018,  0.2650]]])
agent 0 action: VehicleControl(throttle=0.379096, steer=-0.004881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.05676211911944
15.300604281947017 seconds in game passed.
Action: tensor([[[-0.0102,  0.9459],
         [ 0.0015,  0.5778],
         [ 0.0013,  0.3659],
         [ 0.0018,  0.2650]]])
agent 0 action: VehicleControl(throttle=0.414094, steer=-0.004908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.05676211911944
15.325604282319546 seconds in game passed.
Action: tensor([[[-0.0102,  0.9459],
         [ 0.0015,  0.5778],
         [ 0.0013,  0.3659],
         [ 0.0018,  0.2650]]])
agent 0 action: VehicleControl(throttle=0.447415, steer=-0.004935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.05676211911944
+++++++++++++: 2.423617876058403
15.350604282692075 seconds in game passed.
At 15.350604282692075 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9388],
         [0.0030, 0.5263],
         [0.0010, 0.3420],
         [0.0013, 0.2483]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.423617876058403
Current reward: 0.24911995860116182
Current mitigation activation: 0
#############################
Total reward: 35.305882077720604
15.375604283064604 seconds in game passed.
Action: tensor([[[0.0010, 0.9388],
         [0.0030, 0.5263],
         [0.0010, 0.3420],
         [0.0013, 0.2483]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.305882077720604
15.400604283437133 seconds in game passed.
Action: tensor([[[0.0010, 0.9388],
         [0.0030, 0.5263],
         [0.0010, 0.3420],
         [0.0013, 0.2483]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.305882077720604
15.425604283809662 seconds in game passed.
Action: tensor([[[0.0010, 0.9388],
         [0.0030, 0.5263],
         [0.0010, 0.3420],
         [0.0013, 0.2483]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.305882077720604
+++++++++++++: 2.5691822430189917
15.450604284182191 seconds in game passed.
At 15.450604284182191 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.9118e-03,  9.2191e-01],
         [ 2.8317e-03,  4.9452e-01],
         [ 7.2943e-04,  3.2903e-01],
         [ 6.2068e-04,  2.4119e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000891, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5691822430189917
Current reward: 0.24461112616393993
Current mitigation activation: 0
#############################
Total reward: 35.55049320388454
15.47560428455472 seconds in game passed.
Action: tensor([[[-1.9118e-03,  9.2191e-01],
         [ 2.8317e-03,  4.9452e-01],
         [ 7.2943e-04,  3.2903e-01],
         [ 6.2068e-04,  2.4119e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.55049320388454
15.500604284927249 seconds in game passed.
Action: tensor([[[-1.9118e-03,  9.2191e-01],
         [ 2.8317e-03,  4.9452e-01],
         [ 7.2943e-04,  3.2903e-01],
         [ 6.2068e-04,  2.4119e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.55049320388454
15.525604285299778 seconds in game passed.
Action: tensor([[[-1.9118e-03,  9.2191e-01],
         [ 2.8317e-03,  4.9452e-01],
         [ 7.2943e-04,  3.2903e-01],
         [ 6.2068e-04,  2.4119e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.55049320388454
+++++++++++++: 2.5975450201612613
15.550604285672307 seconds in game passed.
At 15.550604285672307 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0044, 0.9131],
         [0.0037, 0.4856],
         [0.0011, 0.3234],
         [0.0011, 0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5975450201612613
Current reward: 0.24622138493036183
Current mitigation activation: 0
#############################
Total reward: 35.79671458881491
15.575604286044836 seconds in game passed.
Action: tensor([[[0.0044, 0.9131],
         [0.0037, 0.4856],
         [0.0011, 0.3234],
         [0.0011, 0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.79671458881491
15.600604286417365 seconds in game passed.
Action: tensor([[[0.0044, 0.9131],
         [0.0037, 0.4856],
         [0.0011, 0.3234],
         [0.0011, 0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.79671458881491
15.625604286789894 seconds in game passed.
Action: tensor([[[0.0044, 0.9131],
         [0.0037, 0.4856],
         [0.0011, 0.3234],
         [0.0011, 0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.79671458881491
+++++++++++++: 2.515397909833804
15.650604287162423 seconds in game passed.
At 15.650604287162423 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.5450e-02, 8.9067e-01],
         [4.1197e-03, 4.7725e-01],
         [1.0858e-03, 3.1965e-01],
         [8.0739e-04, 2.3353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.515397909833804
Current reward: 0.25300582077868955
Current mitigation activation: 0
#############################
Total reward: 36.0497204095936
15.675604287534952 seconds in game passed.
Action: tensor([[[1.5450e-02, 8.9067e-01],
         [4.1197e-03, 4.7725e-01],
         [1.0858e-03, 3.1965e-01],
         [8.0739e-04, 2.3353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.0497204095936
15.700604287907481 seconds in game passed.
Action: tensor([[[1.5450e-02, 8.9067e-01],
         [4.1197e-03, 4.7725e-01],
         [1.0858e-03, 3.1965e-01],
         [8.0739e-04, 2.3353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006767, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.0497204095936
15.72560428828001 seconds in game passed.
Action: tensor([[[1.5450e-02, 8.9067e-01],
         [4.1197e-03, 4.7725e-01],
         [1.0858e-03, 3.1965e-01],
         [8.0739e-04, 2.3353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.0497204095936
+++++++++++++: 2.4218962910648267
15.75060428865254 seconds in game passed.
At 15.75060428865254 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0166, 0.8962],
         [0.0045, 0.4855],
         [0.0019, 0.3257],
         [0.0020, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4218962910648267
Current reward: 0.2603294380204674
Current mitigation activation: 0
#############################
Total reward: 36.31004984761407
15.775604289025068 seconds in game passed.
Action: tensor([[[0.0166, 0.8962],
         [0.0045, 0.4855],
         [0.0019, 0.3257],
         [0.0020, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.31004984761407
15.800604289397597 seconds in game passed.
Action: tensor([[[0.0166, 0.8962],
         [0.0045, 0.4855],
         [0.0019, 0.3257],
         [0.0020, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.31004984761407
15.825604289770126 seconds in game passed.
Action: tensor([[[0.0166, 0.8962],
         [0.0045, 0.4855],
         [0.0019, 0.3257],
         [0.0020, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.31004984761407
+++++++++++++: 2.4361279399139932
15.850604290142655 seconds in game passed.
At 15.850604290142655 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0147, 0.8941],
         [0.0035, 0.4803],
         [0.0015, 0.3222],
         [0.0017, 0.2353]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4361279399139932
Current reward: 0.26168249830259876
Current mitigation activation: 0
#############################
Total reward: 36.571732345916665
15.875604290515184 seconds in game passed.
Action: tensor([[[0.0147, 0.8941],
         [0.0035, 0.4803],
         [0.0015, 0.3222],
         [0.0017, 0.2353]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006966, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.571732345916665
15.900604290887713 seconds in game passed.
Action: tensor([[[0.0147, 0.8941],
         [0.0035, 0.4803],
         [0.0015, 0.3222],
         [0.0017, 0.2353]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.571732345916665
15.925604291260242 seconds in game passed.
Action: tensor([[[0.0147, 0.8941],
         [0.0035, 0.4803],
         [0.0015, 0.3222],
         [0.0017, 0.2353]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.571732345916665
+++++++++++++: 2.459839973362208
15.950604291632771 seconds in game passed.
At 15.950604291632771 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0159, 0.8910],
         [0.0038, 0.4757],
         [0.0023, 0.3193],
         [0.0030, 0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.459839973362208
Current reward: 0.26250643660590606
Current mitigation activation: 0
#############################
Total reward: 36.83423878252257
15.9756042920053 seconds in game passed.
Action: tensor([[[0.0159, 0.8910],
         [0.0038, 0.4757],
         [0.0023, 0.3193],
         [0.0030, 0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.83423878252257
16.00060429237783 seconds in game passed.
Action: tensor([[[0.0159, 0.8910],
         [0.0038, 0.4757],
         [0.0023, 0.3193],
         [0.0030, 0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.83423878252257
16.02560429275036 seconds in game passed.
Action: tensor([[[0.0159, 0.8910],
         [0.0038, 0.4757],
         [0.0023, 0.3193],
         [0.0030, 0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.83423878252257
+++++++++++++: 2.483641200702414
16.050604293122888 seconds in game passed.
At 16.050604293122888 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.6114e-03, 8.8743e-01],
         [1.8050e-03, 4.6719e-01],
         [6.5432e-04, 3.1266e-01],
         [1.2554e-03, 2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.483641200702414
Current reward: 0.26334392109712845
Current mitigation activation: 0
#############################
Total reward: 37.0975827036197
16.075604293495417 seconds in game passed.
Action: tensor([[[7.6114e-03, 8.8743e-01],
         [1.8050e-03, 4.6719e-01],
         [6.5432e-04, 3.1266e-01],
         [1.2554e-03, 2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.0975827036197
16.100604293867946 seconds in game passed.
Action: tensor([[[7.6114e-03, 8.8743e-01],
         [1.8050e-03, 4.6719e-01],
         [6.5432e-04, 3.1266e-01],
         [1.2554e-03, 2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.0975827036197
16.125604294240475 seconds in game passed.
Action: tensor([[[7.6114e-03, 8.8743e-01],
         [1.8050e-03, 4.6719e-01],
         [6.5432e-04, 3.1266e-01],
         [1.2554e-03, 2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.0975827036197
+++++++++++++: 2.5076234692625916
16.150604294613004 seconds in game passed.
At 16.150604294613004 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0030,  0.8770],
         [-0.0011,  0.4605],
         [-0.0022,  0.3104],
         [-0.0018,  0.2295]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5076234692625916
Current reward: 0.26418773221403014
Current mitigation activation: 0
#############################
Total reward: 37.36177043583373
16.175604294985533 seconds in game passed.
Action: tensor([[[ 0.0030,  0.8770],
         [-0.0011,  0.4605],
         [-0.0022,  0.3104],
         [-0.0018,  0.2295]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.36177043583373
16.200604295358062 seconds in game passed.
Action: tensor([[[ 0.0030,  0.8770],
         [-0.0011,  0.4605],
         [-0.0022,  0.3104],
         [-0.0018,  0.2295]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.36177043583373
16.22560429573059 seconds in game passed.
Action: tensor([[[ 0.0030,  0.8770],
         [-0.0011,  0.4605],
         [-0.0022,  0.3104],
         [-0.0018,  0.2295]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.36177043583373
+++++++++++++: 2.49819464488819
16.25060429610312 seconds in game passed.
At 16.25060429610312 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.4751e-03,  8.7665e-01],
         [-7.8590e-04,  4.6322e-01],
         [-2.5995e-03,  3.1182e-01],
         [-2.3683e-03,  2.3052e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.49819464488819
Current reward: 0.26676483513692273
Current mitigation activation: 0
#############################
Total reward: 37.62853527097066
16.27560429647565 seconds in game passed.
Action: tensor([[[ 5.4751e-03,  8.7665e-01],
         [-7.8590e-04,  4.6322e-01],
         [-2.5995e-03,  3.1182e-01],
         [-2.3683e-03,  2.3052e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.62853527097066
16.300604296848178 seconds in game passed.
Action: tensor([[[ 5.4751e-03,  8.7665e-01],
         [-7.8590e-04,  4.6322e-01],
         [-2.5995e-03,  3.1182e-01],
         [-2.3683e-03,  2.3052e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.62853527097066
16.325604297220707 seconds in game passed.
Action: tensor([[[ 5.4751e-03,  8.7665e-01],
         [-7.8590e-04,  4.6322e-01],
         [-2.5995e-03,  3.1182e-01],
         [-2.3683e-03,  2.3052e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.62853527097066
+++++++++++++: 2.3283883237713727
16.350604297593236 seconds in game passed.
At 16.350604297593236 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.3426e-03,  8.8038e-01],
         [-7.8291e-04,  4.6096e-01],
         [-3.2183e-03,  3.0745e-01],
         [-3.7796e-03,  2.2628e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003864, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3283883237713727
Current reward: 0.27827811180657536
Current mitigation activation: 0
#############################
Total reward: 37.90681338277724
16.375604297965765 seconds in game passed.
Action: tensor([[[ 6.3426e-03,  8.8038e-01],
         [-7.8291e-04,  4.6096e-01],
         [-3.2183e-03,  3.0745e-01],
         [-3.7796e-03,  2.2628e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.90681338277724
16.400604298338294 seconds in game passed.
Action: tensor([[[ 6.3426e-03,  8.8038e-01],
         [-7.8291e-04,  4.6096e-01],
         [-3.2183e-03,  3.0745e-01],
         [-3.7796e-03,  2.2628e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.90681338277724
16.425604298710823 seconds in game passed.
Action: tensor([[[ 6.3426e-03,  8.8038e-01],
         [-7.8291e-04,  4.6096e-01],
         [-3.2183e-03,  3.0745e-01],
         [-3.7796e-03,  2.2628e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.90681338277724
+++++++++++++: 2.1696758135598286
16.450604299083352 seconds in game passed.
At 16.450604299083352 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0031,  0.8685],
         [-0.0018,  0.4520],
         [-0.0040,  0.3023],
         [-0.0040,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1696758135598286
Current reward: 0.2897472797044415
Current mitigation activation: 0
#############################
Total reward: 38.19656066248168
16.47560429945588 seconds in game passed.
Action: tensor([[[ 0.0031,  0.8685],
         [-0.0018,  0.4520],
         [-0.0040,  0.3023],
         [-0.0040,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.19656066248168
16.50060429982841 seconds in game passed.
Action: tensor([[[ 0.0031,  0.8685],
         [-0.0018,  0.4520],
         [-0.0040,  0.3023],
         [-0.0040,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002010, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.19656066248168
16.52560430020094 seconds in game passed.
Action: tensor([[[ 0.0031,  0.8685],
         [-0.0018,  0.4520],
         [-0.0040,  0.3023],
         [-0.0040,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.19656066248168
+++++++++++++: 2.0328330187429646
16.550604300573468 seconds in game passed.
At 16.550604300573468 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0044,  0.8679],
         [-0.0033,  0.4503],
         [-0.0052,  0.3025],
         [-0.0047,  0.2238]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0328330187429646
Current reward: 0.300198644093284
Current mitigation activation: 0
#############################
Total reward: 38.496759306574965
16.575604300945997 seconds in game passed.
Action: tensor([[[ 0.0044,  0.8679],
         [-0.0033,  0.4503],
         [-0.0052,  0.3025],
         [-0.0047,  0.2238]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.496759306574965
16.600604301318526 seconds in game passed.
Action: tensor([[[ 0.0044,  0.8679],
         [-0.0033,  0.4503],
         [-0.0052,  0.3025],
         [-0.0047,  0.2238]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.496759306574965
16.625604301691055 seconds in game passed.
Action: tensor([[[ 0.0044,  0.8679],
         [-0.0033,  0.4503],
         [-0.0052,  0.3025],
         [-0.0047,  0.2238]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.496759306574965
+++++++++++++: 1.9097223049383272
16.650604302063584 seconds in game passed.
At 16.650604302063584 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.9342e-04,  8.8500e-01],
         [-3.2231e-03,  4.5890e-01],
         [-5.5524e-03,  3.0526e-01],
         [-5.4234e-03,  2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9097223049383272
Current reward: 0.3099418836055885
Current mitigation activation: 0
#############################
Total reward: 38.806701190180554
16.675604302436113 seconds in game passed.
Action: tensor([[[ 1.9342e-04,  8.8500e-01],
         [-3.2231e-03,  4.5890e-01],
         [-5.5524e-03,  3.0526e-01],
         [-5.4234e-03,  2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.806701190180554
16.700604302808642 seconds in game passed.
Action: tensor([[[ 1.9342e-04,  8.8500e-01],
         [-3.2231e-03,  4.5890e-01],
         [-5.5524e-03,  3.0526e-01],
         [-5.4234e-03,  2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.806701190180554
16.72560430318117 seconds in game passed.
Action: tensor([[[ 1.9342e-04,  8.8500e-01],
         [-3.2231e-03,  4.5890e-01],
         [-5.5524e-03,  3.0526e-01],
         [-5.4234e-03,  2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.806701190180554
+++++++++++++: 1.7961920262948863
16.7506043035537 seconds in game passed.
At 16.7506043035537 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.8855],
         [-0.0020,  0.4587],
         [-0.0042,  0.3081],
         [-0.0042,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7961920262948863
Current reward: 0.31913507234597766
Current mitigation activation: 0
#############################
Total reward: 39.12583626252653
16.77560430392623 seconds in game passed.
Action: tensor([[[-0.0018,  0.8855],
         [-0.0020,  0.4587],
         [-0.0042,  0.3081],
         [-0.0042,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.12583626252653
16.80060430429876 seconds in game passed.
Action: tensor([[[-0.0018,  0.8855],
         [-0.0020,  0.4587],
         [-0.0042,  0.3081],
         [-0.0042,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000872, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.12583626252653
16.825604304671288 seconds in game passed.
Action: tensor([[[-0.0018,  0.8855],
         [-0.0020,  0.4587],
         [-0.0042,  0.3081],
         [-0.0042,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.12583626252653
+++++++++++++: 1.6904056794261997
16.850604305043817 seconds in game passed.
At 16.850604305043817 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.5424e-04,  9.1135e-01],
         [ 1.5024e-04,  4.7704e-01],
         [-3.0534e-03,  3.1602e-01],
         [-4.1491e-03,  2.3208e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6904056794261997
Current reward: 0.32785176136624117
Current mitigation activation: 0
#############################
Total reward: 39.453688023892774
16.875604305416346 seconds in game passed.
Action: tensor([[[-8.5424e-04,  9.1135e-01],
         [ 1.5024e-04,  4.7704e-01],
         [-3.0534e-03,  3.1602e-01],
         [-4.1491e-03,  2.3208e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.453688023892774
16.900604305788875 seconds in game passed.
Action: tensor([[[-8.5424e-04,  9.1135e-01],
         [ 1.5024e-04,  4.7704e-01],
         [-3.0534e-03,  3.1602e-01],
         [-4.1491e-03,  2.3208e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.453688023892774
16.925604306161404 seconds in game passed.
Action: tensor([[[-8.5424e-04,  9.1135e-01],
         [ 1.5024e-04,  4.7704e-01],
         [-3.0534e-03,  3.1602e-01],
         [-4.1491e-03,  2.3208e-01]]])
agent 0 action: VehicleControl(throttle=0.883301, steer=0.000306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.453688023892774
+++++++++++++: 1.5923683544663385
16.950604306533933 seconds in game passed.
At 16.950604306533933 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0076,  0.8970],
         [ 0.0016,  0.4891],
         [-0.0026,  0.3366],
         [-0.0043,  0.2530]]])
agent 0 action: VehicleControl(throttle=0.562767, steer=0.004808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5923683544663385
Current reward: 0.33620452009352697
Current mitigation activation: 0
#############################
Total reward: 39.7898925439863
16.97560430690646 seconds in game passed.
Action: tensor([[[ 0.0076,  0.8970],
         [ 0.0016,  0.4891],
         [-0.0026,  0.3366],
         [-0.0043,  0.2530]]])
agent 0 action: VehicleControl(throttle=0.539171, steer=0.003997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.7898925439863
17.00060430727899 seconds in game passed.
Action: tensor([[[ 0.0076,  0.8970],
         [ 0.0016,  0.4891],
         [-0.0026,  0.3366],
         [-0.0043,  0.2530]]])
agent 0 action: VehicleControl(throttle=0.507359, steer=0.003944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.7898925439863
17.02560430765152 seconds in game passed.
Action: tensor([[[ 0.0076,  0.8970],
         [ 0.0016,  0.4891],
         [-0.0026,  0.3366],
         [-0.0043,  0.2530]]])
agent 0 action: VehicleControl(throttle=0.492194, steer=0.003892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.7898925439863
+++++++++++++: 1.5033240470020863
17.05060430802405 seconds in game passed.
At 17.05060430802405 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.0701e-03,  9.2388e-01],
         [ 4.5991e-03,  5.1588e-01],
         [ 4.7766e-04,  3.4690e-01],
         [-6.5265e-04,  2.5605e-01]]])
agent 0 action: VehicleControl(throttle=0.473540, steer=0.004761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5033240470020863
Current reward: 0.3440833203414989
Current mitigation activation: 0
#############################
Total reward: 40.133975864327795
17.075604308396578 seconds in game passed.
Action: tensor([[[ 4.0701e-03,  9.2388e-01],
         [ 4.5991e-03,  5.1588e-01],
         [ 4.7766e-04,  3.4690e-01],
         [-6.5265e-04,  2.5605e-01]]])
agent 0 action: VehicleControl(throttle=0.454877, steer=0.004625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.133975864327795
17.100604308769107 seconds in game passed.
Action: tensor([[[ 4.0701e-03,  9.2388e-01],
         [ 4.5991e-03,  5.1588e-01],
         [ 4.7766e-04,  3.4690e-01],
         [-6.5265e-04,  2.5605e-01]]])
agent 0 action: VehicleControl(throttle=0.436205, steer=0.004633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.133975864327795
17.125604309141636 seconds in game passed.
Action: tensor([[[ 4.0701e-03,  9.2388e-01],
         [ 4.5991e-03,  5.1588e-01],
         [ 4.7766e-04,  3.4690e-01],
         [-6.5265e-04,  2.5605e-01]]])
agent 0 action: VehicleControl(throttle=0.417525, steer=0.004641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.133975864327795
+++++++++++++: 1.4355885521433935
17.150604309514165 seconds in game passed.
At 17.150604309514165 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0089, 0.9348],
         [0.0076, 0.5280],
         [0.0034, 0.3539],
         [0.0023, 0.2596]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.009046, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4355885521433935
Current reward: 0.34960087790340666
Current mitigation activation: 0
#############################
Total reward: 40.4835767422312
17.175604309886694 seconds in game passed.
Action: tensor([[[0.0089, 0.9348],
         [0.0076, 0.5280],
         [0.0034, 0.3539],
         [0.0023, 0.2596]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008423, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.4835767422312
17.200604310259223 seconds in game passed.
Action: tensor([[[0.0089, 0.9348],
         [0.0076, 0.5280],
         [0.0034, 0.3539],
         [0.0023, 0.2596]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008518, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.4835767422312
17.225604310631752 seconds in game passed.
Action: tensor([[[0.0089, 0.9348],
         [0.0076, 0.5280],
         [0.0034, 0.3539],
         [0.0023, 0.2596]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008614, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.4835767422312
+++++++++++++: 1.3960339711224865
17.25060431100428 seconds in game passed.
At 17.25060431100428 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0224, 0.9252],
         [0.0063, 0.5151],
         [0.0023, 0.3449],
         [0.0015, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.322286, steer=0.013462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3960339711224865
Current reward: 0.3513926763711921
Current mitigation activation: 0
#############################
Total reward: 40.83496941860239
17.27560431137681 seconds in game passed.
Action: tensor([[[0.0224, 0.9252],
         [0.0063, 0.5151],
         [0.0023, 0.3449],
         [0.0015, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.305013, steer=0.012808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.83496941860239
17.30060431174934 seconds in game passed.
Action: tensor([[[0.0224, 0.9252],
         [0.0063, 0.5151],
         [0.0023, 0.3449],
         [0.0015, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.288284, steer=0.012939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.83496941860239
17.325604312121868 seconds in game passed.
Action: tensor([[[0.0224, 0.9252],
         [0.0063, 0.5151],
         [0.0023, 0.3449],
         [0.0015, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.272086, steer=0.013070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.83496941860239
+++++++++++++: 1.414258028743593
17.350604312494397 seconds in game passed.
At 17.350604312494397 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2308e-02,  9.3577e-01],
         [ 4.8250e-03,  5.4304e-01],
         [-5.3263e-04,  3.6326e-01],
         [-5.0876e-04,  2.6590e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012269, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.414258028743593
Current reward: 0.3449962935485632
Current mitigation activation: 0
#############################
Total reward: 41.17996571215095
17.375604312866926 seconds in game passed.
Action: tensor([[[ 2.2308e-02,  9.3577e-01],
         [ 4.8250e-03,  5.4304e-01],
         [-5.3263e-04,  3.6326e-01],
         [-5.0876e-04,  2.6590e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012540, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.17996571215095
17.400604313239455 seconds in game passed.
Action: tensor([[[ 2.2308e-02,  9.3577e-01],
         [ 4.8250e-03,  5.4304e-01],
         [-5.3263e-04,  3.6326e-01],
         [-5.0876e-04,  2.6590e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012659, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.17996571215095
17.425604313611984 seconds in game passed.
Action: tensor([[[ 2.2308e-02,  9.3577e-01],
         [ 4.8250e-03,  5.4304e-01],
         [-5.3263e-04,  3.6326e-01],
         [-5.0876e-04,  2.6590e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012777, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.17996571215095
+++++++++++++: 1.4390935298869887
17.450604313984513 seconds in game passed.
At 17.450604313984513 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0156,  0.9382],
         [-0.0022,  0.5647],
         [-0.0078,  0.3775],
         [-0.0078,  0.2764]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004826, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4390935298869887
Current reward: 0.33901261268855015
Current mitigation activation: 0
#############################
Total reward: 41.5189783248395
17.475604314357042 seconds in game passed.
Action: tensor([[[ 0.0156,  0.9382],
         [-0.0022,  0.5647],
         [-0.0078,  0.3775],
         [-0.0078,  0.2764]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006217, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.5189783248395
17.50060431472957 seconds in game passed.
Action: tensor([[[ 0.0156,  0.9382],
         [-0.0022,  0.5647],
         [-0.0078,  0.3775],
         [-0.0078,  0.2764]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006274, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.5189783248395
17.5256043151021 seconds in game passed.
Action: tensor([[[ 0.0156,  0.9382],
         [-0.0022,  0.5647],
         [-0.0078,  0.3775],
         [-0.0078,  0.2764]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006330, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.5189783248395
+++++++++++++: 1.5150161512519915
17.55060431547463 seconds in game passed.
At 17.55060431547463 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0113,  0.9361],
         [-0.0032,  0.5470],
         [-0.0077,  0.3668],
         [-0.0078,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.136479, steer=0.003628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5150161512519915
Current reward: 0.32770721863333946
Current mitigation activation: 0
#############################
Total reward: 41.846685543472844
17.57560431584716 seconds in game passed.
Action: tensor([[[ 0.0113,  0.9361],
         [-0.0032,  0.5470],
         [-0.0077,  0.3668],
         [-0.0078,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.122984, steer=0.004119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.846685543472844
17.600604316219687 seconds in game passed.
Action: tensor([[[ 0.0113,  0.9361],
         [-0.0032,  0.5470],
         [-0.0077,  0.3668],
         [-0.0078,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.109956, steer=0.004154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.846685543472844
17.625604316592216 seconds in game passed.
Action: tensor([[[ 0.0113,  0.9361],
         [-0.0032,  0.5470],
         [-0.0077,  0.3668],
         [-0.0078,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.097392, steer=0.004188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.846685543472844
+++++++++++++: 1.6750118807975312
17.650604316964746 seconds in game passed.
At 17.650604316964746 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0079,  0.9347],
         [-0.0060,  0.5434],
         [-0.0110,  0.3655],
         [-0.0117,  0.2731]]])
agent 0 action: VehicleControl(throttle=0.086135, steer=0.000594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6750118807975312
Current reward: 0.3098033783775027
Current mitigation activation: 0
#############################
Total reward: 42.15648892185035
17.675604317337275 seconds in game passed.
Action: tensor([[[ 0.0079,  0.9347],
         [-0.0060,  0.5434],
         [-0.0110,  0.3655],
         [-0.0117,  0.2731]]])
agent 0 action: VehicleControl(throttle=0.075929, steer=0.001209, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.15648892185035
17.700604317709804 seconds in game passed.
Action: tensor([[[ 0.0079,  0.9347],
         [-0.0060,  0.5434],
         [-0.0110,  0.3655],
         [-0.0117,  0.2731]]])
agent 0 action: VehicleControl(throttle=0.096535, steer=0.001223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.15648892185035
17.725604318082333 seconds in game passed.
Action: tensor([[[ 0.0079,  0.9347],
         [-0.0060,  0.5434],
         [-0.0110,  0.3655],
         [-0.0117,  0.2731]]])
agent 0 action: VehicleControl(throttle=0.083312, steer=0.001237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.15648892185035
+++++++++++++: 1.7997389901319838
17.75060431845486 seconds in game passed.
At 17.75060431845486 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0027,  0.9297],
         [-0.0068,  0.5223],
         [-0.0117,  0.3474],
         [-0.0126,  0.2556]]])
agent 0 action: VehicleControl(throttle=0.342986, steer=-0.001736, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7997389901319838
Current reward: 0.3002970830128562
Current mitigation activation: 0
#############################
Total reward: 42.456786004863204
17.77560431882739 seconds in game passed.
Action: tensor([[[ 0.0027,  0.9297],
         [-0.0068,  0.5223],
         [-0.0117,  0.3474],
         [-0.0126,  0.2556]]])
agent 0 action: VehicleControl(throttle=0.309184, steer=-0.001262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.456786004863204
17.80060431919992 seconds in game passed.
Action: tensor([[[ 0.0027,  0.9297],
         [-0.0068,  0.5223],
         [-0.0117,  0.3474],
         [-0.0126,  0.2556]]])
agent 0 action: VehicleControl(throttle=0.304603, steer=-0.001280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.456786004863204
17.82560431957245 seconds in game passed.
Action: tensor([[[ 0.0027,  0.9297],
         [-0.0068,  0.5223],
         [-0.0117,  0.3474],
         [-0.0126,  0.2556]]])
agent 0 action: VehicleControl(throttle=0.300613, steer=-0.001299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.456786004863204
+++++++++++++: 1.8390666144179177
17.850604319944978 seconds in game passed.
At 17.850604319944978 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.7837e-04,  9.2476e-01],
         [-6.0612e-03,  4.9020e-01],
         [-1.0153e-02,  3.2499e-01],
         [-1.1187e-02,  2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.769203, steer=-0.001819, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8390666144179177
Current reward: 0.30094646615609116
Current mitigation activation: 0
#############################
Total reward: 42.757732471019295
17.875604320317507 seconds in game passed.
Action: tensor([[[ 3.7837e-04,  9.2476e-01],
         [-6.0612e-03,  4.9020e-01],
         [-1.0153e-02,  3.2499e-01],
         [-1.1187e-02,  2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.723867, steer=-0.001784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.757732471019295
17.900604320690036 seconds in game passed.
Action: tensor([[[ 3.7837e-04,  9.2476e-01],
         [-6.0612e-03,  4.9020e-01],
         [-1.0153e-02,  3.2499e-01],
         [-1.1187e-02,  2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.728785, steer=-0.001829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.757732471019295
17.925604321062565 seconds in game passed.
Action: tensor([[[ 3.7837e-04,  9.2476e-01],
         [-6.0612e-03,  4.9020e-01],
         [-1.0153e-02,  3.2499e-01],
         [-1.1187e-02,  2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.734164, steer=-0.001873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.757732471019295
+++++++++++++: 1.873696572744318
17.950604321435094 seconds in game passed.
At 17.950604321435094 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0045,  0.9016],
         [-0.0105,  0.4756],
         [-0.0146,  0.3227],
         [-0.0157,  0.2446]]])
agent 0 action: VehicleControl(throttle=0.879602, steer=-0.007359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.873696572744318
Current reward: 0.302712236134984
Current mitigation activation: 0
#############################
Total reward: 43.06044470715428
17.975604321807623 seconds in game passed.
Action: tensor([[[-0.0045,  0.9016],
         [-0.0105,  0.4756],
         [-0.0146,  0.3227],
         [-0.0157,  0.2446]]])
agent 0 action: VehicleControl(throttle=0.875925, steer=-0.006616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.06044470715428
18.000604322180152 seconds in game passed.
Action: tensor([[[-0.0045,  0.9016],
         [-0.0105,  0.4756],
         [-0.0146,  0.3227],
         [-0.0157,  0.2446]]])
agent 0 action: VehicleControl(throttle=0.887007, steer=-0.006764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.06044470715428
18.02560432255268 seconds in game passed.
Action: tensor([[[-0.0045,  0.9016],
         [-0.0105,  0.4756],
         [-0.0146,  0.3227],
         [-0.0157,  0.2446]]])
agent 0 action: VehicleControl(throttle=0.898040, steer=-0.006911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.06044470715428
+++++++++++++: 1.9120145967624986
18.05060432292521 seconds in game passed.
At 18.05060432292521 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0052,  0.8604],
         [-0.0110,  0.4542],
         [-0.0153,  0.3110],
         [-0.0167,  0.2371]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9120145967624986
Current reward: 0.3047276100419774
Current mitigation activation: 0
#############################
Total reward: 43.36517231719626
18.07560432329774 seconds in game passed.
Action: tensor([[[-0.0052,  0.8604],
         [-0.0110,  0.4542],
         [-0.0153,  0.3110],
         [-0.0167,  0.2371]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.36517231719626
18.100604323670268 seconds in game passed.
Action: tensor([[[-0.0052,  0.8604],
         [-0.0110,  0.4542],
         [-0.0153,  0.3110],
         [-0.0167,  0.2371]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.36517231719626
18.125604324042797 seconds in game passed.
Action: tensor([[[-0.0052,  0.8604],
         [-0.0110,  0.4542],
         [-0.0153,  0.3110],
         [-0.0167,  0.2371]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.36517231719626
+++++++++++++: 1.953961340401306
18.150604324415326 seconds in game passed.
At 18.150604324415326 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0073,  0.8734],
         [-0.0126,  0.4638],
         [-0.0167,  0.3163],
         [-0.0178,  0.2393]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.953961340401306
Current reward: 0.30698931313634437
Current mitigation activation: 0
#############################
Total reward: 43.6721616303326
18.175604324787855 seconds in game passed.
Action: tensor([[[-0.0073,  0.8734],
         [-0.0126,  0.4638],
         [-0.0167,  0.3163],
         [-0.0178,  0.2393]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010249, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.6721616303326
18.200604325160384 seconds in game passed.
Action: tensor([[[-0.0073,  0.8734],
         [-0.0126,  0.4638],
         [-0.0167,  0.3163],
         [-0.0178,  0.2393]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.6721616303326
18.225604325532913 seconds in game passed.
Action: tensor([[[-0.0073,  0.8734],
         [-0.0126,  0.4638],
         [-0.0167,  0.3163],
         [-0.0178,  0.2393]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010707, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.6721616303326
+++++++++++++: 2.0110831302362286
18.250604325905442 seconds in game passed.
At 18.250604325905442 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.2207e-04,  8.3540e-01],
         [-9.0212e-03,  4.4404e-01],
         [-1.2164e-02,  3.0400e-01],
         [-1.2815e-02,  2.2958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0110831302362286
Current reward: 0.3085382007965556
Current mitigation activation: 0
#############################
Total reward: 43.98069983112916
18.27560432627797 seconds in game passed.
Action: tensor([[[-2.2207e-04,  8.3540e-01],
         [-9.0212e-03,  4.4404e-01],
         [-1.2164e-02,  3.0400e-01],
         [-1.2815e-02,  2.2958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.98069983112916
18.3006043266505 seconds in game passed.
Action: tensor([[[-2.2207e-04,  8.3540e-01],
         [-9.0212e-03,  4.4404e-01],
         [-1.2164e-02,  3.0400e-01],
         [-1.2815e-02,  2.2958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.98069983112916
18.32560432702303 seconds in game passed.
Action: tensor([[[-2.2207e-04,  8.3540e-01],
         [-9.0212e-03,  4.4404e-01],
         [-1.2164e-02,  3.0400e-01],
         [-1.2815e-02,  2.2958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.98069983112916
+++++++++++++: 2.2206497872932847
18.35060432739556 seconds in game passed.
At 18.35060432739556 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.0196e-04,  8.3938e-01],
         [-1.1008e-02,  4.3955e-01],
         [-1.5596e-02,  2.9418e-01],
         [-1.7965e-02,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2206497872932847
Current reward: 0.29946108860595466
Current mitigation activation: 0
#############################
Total reward: 44.28016091973511
18.375604327768087 seconds in game passed.
Action: tensor([[[ 8.0196e-04,  8.3938e-01],
         [-1.1008e-02,  4.3955e-01],
         [-1.5596e-02,  2.9418e-01],
         [-1.7965e-02,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.28016091973511
18.400604328140616 seconds in game passed.
Action: tensor([[[ 8.0196e-04,  8.3938e-01],
         [-1.1008e-02,  4.3955e-01],
         [-1.5596e-02,  2.9418e-01],
         [-1.7965e-02,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.28016091973511
18.425604328513145 seconds in game passed.
Action: tensor([[[ 8.0196e-04,  8.3938e-01],
         [-1.1008e-02,  4.3955e-01],
         [-1.5596e-02,  2.9418e-01],
         [-1.7965e-02,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.28016091973511
+++++++++++++: 2.382841378293331
18.450604328885674 seconds in game passed.
At 18.450604328885674 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.8265],
         [-0.0113,  0.4254],
         [-0.0150,  0.2817],
         [-0.0163,  0.2092]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.382841378293331
Current reward: 0.29663656331800786
Current mitigation activation: 0
#############################
Total reward: 44.57679748305312
18.475604329258204 seconds in game passed.
Action: tensor([[[ 0.0021,  0.8265],
         [-0.0113,  0.4254],
         [-0.0150,  0.2817],
         [-0.0163,  0.2092]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008845, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.57679748305312
18.500604329630733 seconds in game passed.
Action: tensor([[[ 0.0021,  0.8265],
         [-0.0113,  0.4254],
         [-0.0150,  0.2817],
         [-0.0163,  0.2092]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.57679748305312
18.52560433000326 seconds in game passed.
Action: tensor([[[ 0.0021,  0.8265],
         [-0.0113,  0.4254],
         [-0.0150,  0.2817],
         [-0.0163,  0.2092]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.57679748305312
+++++++++++++: 2.4337142643719876
18.55060433037579 seconds in game passed.
At 18.55060433037579 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.7906],
         [-0.0073,  0.4128],
         [-0.0100,  0.2749],
         [-0.0112,  0.2047]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4337142643719876
Current reward: 0.30204329906480587
Current mitigation activation: 0
#############################
Total reward: 44.878840782117926
18.57560433074832 seconds in game passed.
Action: tensor([[[-0.0012,  0.7906],
         [-0.0073,  0.4128],
         [-0.0100,  0.2749],
         [-0.0112,  0.2047]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.878840782117926
18.60060433112085 seconds in game passed.
Action: tensor([[[-0.0012,  0.7906],
         [-0.0073,  0.4128],
         [-0.0100,  0.2749],
         [-0.0112,  0.2047]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.878840782117926
18.625604331493378 seconds in game passed.
Action: tensor([[[-0.0012,  0.7906],
         [-0.0073,  0.4128],
         [-0.0100,  0.2749],
         [-0.0112,  0.2047]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007984, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.878840782117926
+++++++++++++: 2.4197221955143973
18.650604331865907 seconds in game passed.
At 18.650604331865907 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.7617],
         [-0.0064,  0.4007],
         [-0.0089,  0.2711],
         [-0.0105,  0.2044]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4197221955143973
Current reward: 0.31174734169107354
Current mitigation activation: 0
#############################
Total reward: 45.190588123809
18.675604332238436 seconds in game passed.
Action: tensor([[[-0.0021,  0.7617],
         [-0.0064,  0.4007],
         [-0.0089,  0.2711],
         [-0.0105,  0.2044]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007728, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.190588123809
18.700604332610965 seconds in game passed.
Action: tensor([[[-0.0021,  0.7617],
         [-0.0064,  0.4007],
         [-0.0089,  0.2711],
         [-0.0105,  0.2044]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.190588123809
18.725604332983494 seconds in game passed.
Action: tensor([[[-0.0021,  0.7617],
         [-0.0064,  0.4007],
         [-0.0089,  0.2711],
         [-0.0105,  0.2044]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007823, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.190588123809
+++++++++++++: 2.376448735887837
18.750604333356023 seconds in game passed.
At 18.750604333356023 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.7069],
         [-0.0061,  0.3791],
         [-0.0074,  0.2598],
         [-0.0082,  0.1978]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007948, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.376448735887837
Current reward: 0.3234655342028633
Current mitigation activation: 0
#############################
Total reward: 45.51405365801186
18.775604333728552 seconds in game passed.
Action: tensor([[[-0.0030,  0.7069],
         [-0.0061,  0.3791],
         [-0.0074,  0.2598],
         [-0.0082,  0.1978]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007948, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.51405365801186
18.80060433410108 seconds in game passed.
Action: tensor([[[-0.0030,  0.7069],
         [-0.0061,  0.3791],
         [-0.0074,  0.2598],
         [-0.0082,  0.1978]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007966, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.51405365801186
18.82560433447361 seconds in game passed.
Action: tensor([[[-0.0030,  0.7069],
         [-0.0061,  0.3791],
         [-0.0074,  0.2598],
         [-0.0082,  0.1978]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.51405365801186
+++++++++++++: 2.3215929110524285
18.85060433484614 seconds in game passed.
At 18.85060433484614 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.4400e-05,  6.7575e-01],
         [-4.2465e-03,  3.7426e-01],
         [-5.7215e-03,  2.6009e-01],
         [-6.6104e-03,  1.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3215929110524285
Current reward: 0.3361094456952178
Current mitigation activation: 0
#############################
Total reward: 45.850163103707075
18.875604335218668 seconds in game passed.
Action: tensor([[[ 8.4400e-05,  6.7575e-01],
         [-4.2465e-03,  3.7426e-01],
         [-5.7215e-03,  2.6009e-01],
         [-6.6104e-03,  1.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.850163103707075
18.900604335591197 seconds in game passed.
Action: tensor([[[ 8.4400e-05,  6.7575e-01],
         [-4.2465e-03,  3.7426e-01],
         [-5.7215e-03,  2.6009e-01],
         [-6.6104e-03,  1.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.850163103707075
18.925604335963726 seconds in game passed.
Action: tensor([[[ 8.4400e-05,  6.7575e-01],
         [-4.2465e-03,  3.7426e-01],
         [-5.7215e-03,  2.6009e-01],
         [-6.6104e-03,  1.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.850163103707075
+++++++++++++: 2.263192508280863
18.950604336336255 seconds in game passed.
At 18.950604336336255 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0016,  0.6887],
         [-0.0025,  0.3755],
         [-0.0035,  0.2592],
         [-0.0043,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.263192508280863
Current reward: 0.34915364765619683
Current mitigation activation: 0
#############################
Total reward: 46.19931675136327
18.975604336708784 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6887],
         [-0.0025,  0.3755],
         [-0.0035,  0.2592],
         [-0.0043,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.19931675136327
19.000604337081313 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6887],
         [-0.0025,  0.3755],
         [-0.0035,  0.2592],
         [-0.0043,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.19931675136327
19.025604337453842 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6887],
         [-0.0025,  0.3755],
         [-0.0035,  0.2592],
         [-0.0043,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.19931675136327
+++++++++++++: 2.2052902384010573
19.05060433782637 seconds in game passed.
At 19.05060433782637 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.1483e-03,  6.7787e-01],
         [ 3.7193e-04,  3.7028e-01],
         [-2.4413e-04,  2.5434e-01],
         [-1.1553e-03,  1.9457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2052902384010573
Current reward: 0.3622857271005344
Current mitigation activation: 0
#############################
Total reward: 46.561602478463804
19.0756043381989 seconds in game passed.
Action: tensor([[[ 5.1483e-03,  6.7787e-01],
         [ 3.7193e-04,  3.7028e-01],
         [-2.4413e-04,  2.5434e-01],
         [-1.1553e-03,  1.9457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.561602478463804
19.10060433857143 seconds in game passed.
Action: tensor([[[ 5.1483e-03,  6.7787e-01],
         [ 3.7193e-04,  3.7028e-01],
         [-2.4413e-04,  2.5434e-01],
         [-1.1553e-03,  1.9457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.561602478463804
19.12560433894396 seconds in game passed.
Action: tensor([[[ 5.1483e-03,  6.7787e-01],
         [ 3.7193e-04,  3.7028e-01],
         [-2.4413e-04,  2.5434e-01],
         [-1.1553e-03,  1.9457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.561602478463804
+++++++++++++: 2.1496888054027106
19.150604339316487 seconds in game passed.
At 19.150604339316487 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6557],
         [0.0019, 0.3533],
         [0.0019, 0.2415],
         [0.0012, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1496888054027106
Current reward: 0.37532698345381454
Current mitigation activation: 0
#############################
Total reward: 46.93692946191762
19.175604339689016 seconds in game passed.
Action: tensor([[[0.0037, 0.6557],
         [0.0019, 0.3533],
         [0.0019, 0.2415],
         [0.0012, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93692946191762
19.200604340061545 seconds in game passed.
Action: tensor([[[0.0037, 0.6557],
         [0.0019, 0.3533],
         [0.0019, 0.2415],
         [0.0012, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93692946191762
19.225604340434074 seconds in game passed.
Action: tensor([[[0.0037, 0.6557],
         [0.0019, 0.3533],
         [0.0019, 0.2415],
         [0.0012, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000738, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93692946191762
+++++++++++++: 2.0970437895677403
19.250604340806603 seconds in game passed.
At 19.250604340806603 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0054, 0.6384],
         [0.0040, 0.3396],
         [0.0037, 0.2319],
         [0.0029, 0.1767]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0970437895677403
Current reward: 0.38817256927683175
Current mitigation activation: 0
#############################
Total reward: 47.325102031194454
19.275604341179132 seconds in game passed.
Action: tensor([[[0.0054, 0.6384],
         [0.0040, 0.3396],
         [0.0037, 0.2319],
         [0.0029, 0.1767]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.325102031194454
19.30060434155166 seconds in game passed.
Action: tensor([[[0.0054, 0.6384],
         [0.0040, 0.3396],
         [0.0037, 0.2319],
         [0.0029, 0.1767]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.325102031194454
19.32560434192419 seconds in game passed.
Action: tensor([[[0.0054, 0.6384],
         [0.0040, 0.3396],
         [0.0037, 0.2319],
         [0.0029, 0.1767]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.325102031194454
+++++++++++++: 2.0474803471572107
19.35060434229672 seconds in game passed.
At 19.35060434229672 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6210],
         [0.0026, 0.3358],
         [0.0028, 0.2316],
         [0.0023, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001116, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0474803471572107
Current reward: 0.4007633195978386
Current mitigation activation: 0
#############################
Total reward: 47.72586535079229
19.37560434266925 seconds in game passed.
Action: tensor([[[0.0028, 0.6210],
         [0.0026, 0.3358],
         [0.0028, 0.2316],
         [0.0023, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.72586535079229
19.400604343041778 seconds in game passed.
Action: tensor([[[0.0028, 0.6210],
         [0.0026, 0.3358],
         [0.0028, 0.2316],
         [0.0023, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.72586535079229
19.425604343414307 seconds in game passed.
Action: tensor([[[0.0028, 0.6210],
         [0.0026, 0.3358],
         [0.0028, 0.2316],
         [0.0023, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.72586535079229
+++++++++++++: 2.0008739713624384
19.450604343786836 seconds in game passed.
At 19.450604343786836 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.6480],
         [0.0019, 0.3440],
         [0.0016, 0.2359],
         [0.0009, 0.1807]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0008739713624384
Current reward: 0.4130620749327223
Current mitigation activation: 0
#############################
Total reward: 48.138927425725015
19.475604344159365 seconds in game passed.
Action: tensor([[[0.0015, 0.6480],
         [0.0019, 0.3440],
         [0.0016, 0.2359],
         [0.0009, 0.1807]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.138927425725015
19.500604344531894 seconds in game passed.
Action: tensor([[[0.0015, 0.6480],
         [0.0019, 0.3440],
         [0.0016, 0.2359],
         [0.0009, 0.1807]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.138927425725015
19.525604344904423 seconds in game passed.
Action: tensor([[[0.0015, 0.6480],
         [0.0019, 0.3440],
         [0.0016, 0.2359],
         [0.0009, 0.1807]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.138927425725015
+++++++++++++: 1.9570015239011669
19.550604345276952 seconds in game passed.
At 19.550604345276952 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.6176e-03, 6.4365e-01],
         [1.3552e-03, 3.4438e-01],
         [6.8592e-04, 2.3619e-01],
         [4.4845e-05, 1.8072e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9570015239011669
Current reward: 0.4250474933904803
Current mitigation activation: 0
#############################
Total reward: 48.563974919115495
19.57560434564948 seconds in game passed.
Action: tensor([[[2.6176e-03, 6.4365e-01],
         [1.3552e-03, 3.4438e-01],
         [6.8592e-04, 2.3619e-01],
         [4.4845e-05, 1.8072e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.563974919115495
19.60060434602201 seconds in game passed.
Action: tensor([[[2.6176e-03, 6.4365e-01],
         [1.3552e-03, 3.4438e-01],
         [6.8592e-04, 2.3619e-01],
         [4.4845e-05, 1.8072e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.563974919115495
19.62560434639454 seconds in game passed.
Action: tensor([[[2.6176e-03, 6.4365e-01],
         [1.3552e-03, 3.4438e-01],
         [6.8592e-04, 2.3619e-01],
         [4.4845e-05, 1.8072e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001760, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.563974919115495
+++++++++++++: 1.9156281389689664
19.650604346767068 seconds in game passed.
At 19.650604346767068 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6473],
         [-0.0022,  0.3415],
         [-0.0031,  0.2331],
         [-0.0037,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9156281389689664
Current reward: 0.4367100096221659
Current mitigation activation: 0
#############################
Total reward: 49.00068492873766
19.675604347139597 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6473],
         [-0.0022,  0.3415],
         [-0.0031,  0.2331],
         [-0.0037,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.00068492873766
19.700604347512126 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6473],
         [-0.0022,  0.3415],
         [-0.0031,  0.2331],
         [-0.0037,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.00068492873766
19.725604347884655 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6473],
         [-0.0022,  0.3415],
         [-0.0031,  0.2331],
         [-0.0037,  0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.00068492873766
+++++++++++++: 1.8802266229791287
19.750604348257184 seconds in game passed.
At 19.750604348257184 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6657],
         [-0.0014,  0.3468],
         [-0.0026,  0.2350],
         [-0.0034,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8802266229791287
Current reward: 0.4475551934797096
Current mitigation activation: 0
#############################
Total reward: 49.44824012221737
19.775604348629713 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6657],
         [-0.0014,  0.3468],
         [-0.0026,  0.2350],
         [-0.0034,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.44824012221737
19.800604349002242 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6657],
         [-0.0014,  0.3468],
         [-0.0026,  0.2350],
         [-0.0034,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.44824012221737
19.82560434937477 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6657],
         [-0.0014,  0.3468],
         [-0.0026,  0.2350],
         [-0.0034,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.44824012221737
+++++++++++++: 1.8953235924767824
19.8506043497473 seconds in game passed.
At 19.8506043497473 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.6565],
         [-0.0029,  0.3397],
         [-0.0036,  0.2302],
         [-0.0039,  0.1763]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8953235924767824
Current reward: 0.45161704194846297
Current mitigation activation: 0
#############################
Total reward: 49.89985716416583
19.87560435011983 seconds in game passed.
Action: tensor([[[-0.0019,  0.6565],
         [-0.0029,  0.3397],
         [-0.0036,  0.2302],
         [-0.0039,  0.1763]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001964, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89985716416583
19.900604350492358 seconds in game passed.
Action: tensor([[[-0.0019,  0.6565],
         [-0.0029,  0.3397],
         [-0.0036,  0.2302],
         [-0.0039,  0.1763]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001963, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89985716416583
19.925604350864887 seconds in game passed.
Action: tensor([[[-0.0019,  0.6565],
         [-0.0029,  0.3397],
         [-0.0036,  0.2302],
         [-0.0039,  0.1763]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89985716416583
+++++++++++++: 1.9256659379225058
19.950604351237416 seconds in game passed.
At 19.950604351237416 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.0355e-04,  6.6149e-01],
         [-7.4455e-04,  3.4432e-01],
         [-1.0975e-03,  2.3406e-01],
         [-1.0935e-03,  1.7893e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9256659379225058
Current reward: 0.45391444397952785
Current mitigation activation: 0
#############################
Total reward: 50.35377160814536
19.975604351609945 seconds in game passed.
Action: tensor([[[-5.0355e-04,  6.6149e-01],
         [-7.4455e-04,  3.4432e-01],
         [-1.0975e-03,  2.3406e-01],
         [-1.0935e-03,  1.7893e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.35377160814536
20.000604351982474 seconds in game passed.
Action: tensor([[[-5.0355e-04,  6.6149e-01],
         [-7.4455e-04,  3.4432e-01],
         [-1.0975e-03,  2.3406e-01],
         [-1.0935e-03,  1.7893e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.35377160814536
20.025604352355003 seconds in game passed.
Action: tensor([[[-5.0355e-04,  6.6149e-01],
         [-7.4455e-04,  3.4432e-01],
         [-1.0975e-03,  2.3406e-01],
         [-1.0935e-03,  1.7893e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.35377160814536
+++++++++++++: 1.957725900130486
20.050604352727532 seconds in game passed.
At 20.050604352727532 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6171],
         [0.0022, 0.3339],
         [0.0021, 0.2296],
         [0.0019, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.957725900130486
Current reward: 0.45637332290432603
Current mitigation activation: 0
#############################
Total reward: 50.810144931049685
20.07560435310006 seconds in game passed.
Action: tensor([[[0.0032, 0.6171],
         [0.0022, 0.3339],
         [0.0021, 0.2296],
         [0.0019, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.810144931049685
20.10060435347259 seconds in game passed.
Action: tensor([[[0.0032, 0.6171],
         [0.0022, 0.3339],
         [0.0021, 0.2296],
         [0.0019, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.810144931049685
20.12560435384512 seconds in game passed.
Action: tensor([[[0.0032, 0.6171],
         [0.0022, 0.3339],
         [0.0021, 0.2296],
         [0.0019, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.810144931049685
+++++++++++++: 1.9915594706700737
20.15060435421765 seconds in game passed.
At 20.15060435421765 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6288],
         [0.0022, 0.3374],
         [0.0021, 0.2323],
         [0.0017, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9915594706700737
Current reward: 0.4589866857894504
Current mitigation activation: 0
#############################
Total reward: 51.26913161683913
20.175604354590178 seconds in game passed.
Action: tensor([[[0.0037, 0.6288],
         [0.0022, 0.3374],
         [0.0021, 0.2323],
         [0.0017, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.26913161683913
20.200604354962707 seconds in game passed.
Action: tensor([[[0.0037, 0.6288],
         [0.0022, 0.3374],
         [0.0021, 0.2323],
         [0.0017, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.26913161683913
20.225604355335236 seconds in game passed.
Action: tensor([[[0.0037, 0.6288],
         [0.0022, 0.3374],
         [0.0021, 0.2323],
         [0.0017, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003082, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.26913161683913
+++++++++++++: 2.025073256330197
20.250604355707765 seconds in game passed.
At 20.250604355707765 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0036, 0.6210],
         [0.0021, 0.3324],
         [0.0024, 0.2282],
         [0.0024, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.025073256330197
Current reward: 0.4619972871821745
Current mitigation activation: 0
#############################
Total reward: 51.731128904021304
20.275604356080294 seconds in game passed.
Action: tensor([[[0.0036, 0.6210],
         [0.0021, 0.3324],
         [0.0024, 0.2282],
         [0.0024, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.731128904021304
20.300604356452823 seconds in game passed.
Action: tensor([[[0.0036, 0.6210],
         [0.0021, 0.3324],
         [0.0024, 0.2282],
         [0.0024, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.731128904021304
20.32560435682535 seconds in game passed.
Action: tensor([[[0.0036, 0.6210],
         [0.0021, 0.3324],
         [0.0024, 0.2282],
         [0.0024, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002888, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.731128904021304
+++++++++++++: 1.982475281407086
20.35060435719788 seconds in game passed.
At 20.35060435719788 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2824e-03,  6.3185e-01],
         [-3.5062e-04,  3.3411e-01],
         [-2.0255e-04,  2.2941e-01],
         [-9.9674e-05,  1.7587e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.982475281407086
Current reward: 0.47474077629641964
Current mitigation activation: 0
#############################
Total reward: 52.205869680317726
20.37560435757041 seconds in game passed.
Action: tensor([[[ 2.2824e-03,  6.3185e-01],
         [-3.5062e-04,  3.3411e-01],
         [-2.0255e-04,  2.2941e-01],
         [-9.9674e-05,  1.7587e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.205869680317726
20.40060435794294 seconds in game passed.
Action: tensor([[[ 2.2824e-03,  6.3185e-01],
         [-3.5062e-04,  3.3411e-01],
         [-2.0255e-04,  2.2941e-01],
         [-9.9674e-05,  1.7587e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.205869680317726
20.425604358315468 seconds in game passed.
Action: tensor([[[ 2.2824e-03,  6.3185e-01],
         [-3.5062e-04,  3.3411e-01],
         [-2.0255e-04,  2.2941e-01],
         [-9.9674e-05,  1.7587e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.205869680317726
+++++++++++++: 1.9181977582452683
20.450604358687997 seconds in game passed.
At 20.450604358687997 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0019,  0.6087],
         [-0.0016,  0.3284],
         [-0.0019,  0.2261],
         [-0.0020,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9181977582452683
Current reward: 0.49033776299098764
Current mitigation activation: 0
#############################
Total reward: 52.696207443308715
20.475604359060526 seconds in game passed.
Action: tensor([[[ 0.0019,  0.6087],
         [-0.0016,  0.3284],
         [-0.0019,  0.2261],
         [-0.0020,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.696207443308715
20.500604359433055 seconds in game passed.
Action: tensor([[[ 0.0019,  0.6087],
         [-0.0016,  0.3284],
         [-0.0019,  0.2261],
         [-0.0020,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.696207443308715
20.525604359805584 seconds in game passed.
Action: tensor([[[ 0.0019,  0.6087],
         [-0.0016,  0.3284],
         [-0.0019,  0.2261],
         [-0.0020,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.865090, steer=-0.000134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.696207443308715
+++++++++++++: 1.8664157104830914
20.550604360178113 seconds in game passed.
At 20.550604360178113 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.6190],
         [-0.0053,  0.3342],
         [-0.0059,  0.2295],
         [-0.0063,  0.1759]]])
agent 0 action: VehicleControl(throttle=0.720389, steer=-0.004981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8664157104830914
Current reward: 0.5040950630830974
Current mitigation activation: 0
#############################
Total reward: 53.200302506391814
20.575604360550642 seconds in game passed.
Action: tensor([[[-0.0034,  0.6190],
         [-0.0053,  0.3342],
         [-0.0059,  0.2295],
         [-0.0063,  0.1759]]])
agent 0 action: VehicleControl(throttle=0.684884, steer=-0.004261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.200302506391814
20.60060436092317 seconds in game passed.
Action: tensor([[[-0.0034,  0.6190],
         [-0.0053,  0.3342],
         [-0.0059,  0.2295],
         [-0.0063,  0.1759]]])
agent 0 action: VehicleControl(throttle=0.640258, steer=-0.004336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.200302506391814
20.6256043612957 seconds in game passed.
Action: tensor([[[-0.0034,  0.6190],
         [-0.0053,  0.3342],
         [-0.0059,  0.2295],
         [-0.0063,  0.1759]]])
agent 0 action: VehicleControl(throttle=0.597926, steer=-0.004412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.200302506391814
+++++++++++++: 1.8232742609700021
20.65060436166823 seconds in game passed.
At 20.65060436166823 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.6188],
         [-0.0059,  0.3297],
         [-0.0067,  0.2250],
         [-0.0072,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.715754, steer=-0.004613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8232742609700021
Current reward: 0.5164019886753551
Current mitigation activation: 0
#############################
Total reward: 53.71670449506717
20.675604362040758 seconds in game passed.
Action: tensor([[[-0.0027,  0.6188],
         [-0.0059,  0.3297],
         [-0.0067,  0.2250],
         [-0.0072,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.662053, steer=-0.004631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.71670449506717
20.700604362413287 seconds in game passed.
Action: tensor([[[-0.0027,  0.6188],
         [-0.0059,  0.3297],
         [-0.0067,  0.2250],
         [-0.0072,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.627780, steer=-0.004676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.71670449506717
20.725604362785816 seconds in game passed.
Action: tensor([[[-0.0027,  0.6188],
         [-0.0059,  0.3297],
         [-0.0067,  0.2250],
         [-0.0072,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.595041, steer=-0.004720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.71670449506717
+++++++++++++: 1.7931142010077448
20.750604363158345 seconds in game passed.
At 20.750604363158345 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.6212],
         [-0.0055,  0.3303],
         [-0.0060,  0.2255],
         [-0.0061,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.566012, steer=-0.004925, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7931142010077448
Current reward: 0.526433464246756
Current mitigation activation: 0
#############################
Total reward: 54.24313795931393
20.775604363530874 seconds in game passed.
Action: tensor([[[-0.0039,  0.6212],
         [-0.0055,  0.3303],
         [-0.0060,  0.2255],
         [-0.0061,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.536243, steer=-0.004949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.24313795931393
20.800604363903403 seconds in game passed.
Action: tensor([[[-0.0039,  0.6212],
         [-0.0055,  0.3303],
         [-0.0060,  0.2255],
         [-0.0061,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.508475, steer=-0.004999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.24313795931393
20.825604364275932 seconds in game passed.
Action: tensor([[[-0.0039,  0.6212],
         [-0.0055,  0.3303],
         [-0.0060,  0.2255],
         [-0.0061,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.482576, steer=-0.005049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.24313795931393
+++++++++++++: 1.7758231591931501
20.85060436464846 seconds in game passed.
At 20.85060436464846 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.5362e-04,  6.0991e-01],
         [-2.0067e-03,  3.2689e-01],
         [-2.4112e-03,  2.2417e-01],
         [-2.8978e-03,  1.7166e-01]]])
agent 0 action: VehicleControl(throttle=0.464210, steer=-0.001199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7758231591931501
Current reward: 0.5341302469138416
Current mitigation activation: 0
#############################
Total reward: 54.77726820622777
20.87560436502099 seconds in game passed.
Action: tensor([[[-5.5362e-04,  6.0991e-01],
         [-2.0067e-03,  3.2689e-01],
         [-2.4112e-03,  2.2417e-01],
         [-2.8978e-03,  1.7166e-01]]])
agent 0 action: VehicleControl(throttle=0.439880, steer=-0.001826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.77726820622777
20.90060436539352 seconds in game passed.
Action: tensor([[[-5.5362e-04,  6.0991e-01],
         [-2.0067e-03,  3.2689e-01],
         [-2.4112e-03,  2.2417e-01],
         [-2.8978e-03,  1.7166e-01]]])
agent 0 action: VehicleControl(throttle=0.418348, steer=-0.001813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.77726820622777
20.92560436576605 seconds in game passed.
Action: tensor([[[-5.5362e-04,  6.0991e-01],
         [-2.0067e-03,  3.2689e-01],
         [-2.4112e-03,  2.2417e-01],
         [-2.8978e-03,  1.7166e-01]]])
agent 0 action: VehicleControl(throttle=0.398822, steer=-0.001800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.77726820622777
+++++++++++++: 1.7711401226382435
20.950604366138577 seconds in game passed.
At 20.950604366138577 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0029, 0.6120],
         [0.0027, 0.3311],
         [0.0025, 0.2279],
         [0.0017, 0.1752]]])
agent 0 action: VehicleControl(throttle=0.254523, steer=0.003062, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7711401226382435
Current reward: 0.5395515806896614
Current mitigation activation: 0
#############################
Total reward: 55.31681978691743
20.975604366511106 seconds in game passed.
Action: tensor([[[0.0029, 0.6120],
         [0.0027, 0.3311],
         [0.0025, 0.2279],
         [0.0017, 0.1752]]])
agent 0 action: VehicleControl(throttle=0.257216, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.31681978691743
21.000604366883636 seconds in game passed.
Action: tensor([[[0.0029, 0.6120],
         [0.0027, 0.3311],
         [0.0025, 0.2279],
         [0.0017, 0.1752]]])
agent 0 action: VehicleControl(throttle=0.245567, steer=0.002339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.31681978691743
21.025604367256165 seconds in game passed.
Action: tensor([[[0.0029, 0.6120],
         [0.0027, 0.3311],
         [0.0025, 0.2279],
         [0.0017, 0.1752]]])
agent 0 action: VehicleControl(throttle=0.233899, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.31681978691743
+++++++++++++: 1.7800739019961014
21.050604367628694 seconds in game passed.
At 21.050604367628694 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6233],
         [0.0022, 0.3343],
         [0.0019, 0.2295],
         [0.0012, 0.1764]]])
agent 0 action: VehicleControl(throttle=0.222990, steer=0.002150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7800739019961014
Current reward: 0.5426334553317014
Current mitigation activation: 0
#############################
Total reward: 55.85945324224913
21.075604368001223 seconds in game passed.
Action: tensor([[[0.0032, 0.6233],
         [0.0022, 0.3343],
         [0.0019, 0.2295],
         [0.0012, 0.1764]]])
agent 0 action: VehicleControl(throttle=0.217737, steer=0.002189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.85945324224913
21.10060436837375 seconds in game passed.
Action: tensor([[[0.0032, 0.6233],
         [0.0022, 0.3343],
         [0.0019, 0.2295],
         [0.0012, 0.1764]]])
agent 0 action: VehicleControl(throttle=0.216054, steer=0.002189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.85945324224913
21.12560436874628 seconds in game passed.
Action: tensor([[[0.0032, 0.6233],
         [0.0022, 0.3343],
         [0.0019, 0.2295],
         [0.0012, 0.1764]]])
agent 0 action: VehicleControl(throttle=0.216238, steer=0.002190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.85945324224913
+++++++++++++: 1.805344805701559
21.15060436911881 seconds in game passed.
At 21.15060436911881 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6143],
         [0.0029, 0.3304],
         [0.0026, 0.2267],
         [0.0017, 0.1738]]])
agent 0 action: VehicleControl(throttle=0.265599, steer=0.002383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.805344805701559
Current reward: 0.5431288464619818
Current mitigation activation: 0
#############################
Total reward: 56.402582088711114
21.17560436949134 seconds in game passed.
Action: tensor([[[0.0025, 0.6143],
         [0.0029, 0.3304],
         [0.0026, 0.2267],
         [0.0017, 0.1738]]])
agent 0 action: VehicleControl(throttle=0.264719, steer=0.002351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.402582088711114
21.200604369863868 seconds in game passed.
Action: tensor([[[0.0025, 0.6143],
         [0.0029, 0.3304],
         [0.0026, 0.2267],
         [0.0017, 0.1738]]])
agent 0 action: VehicleControl(throttle=0.270059, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.402582088711114
21.225604370236397 seconds in game passed.
Action: tensor([[[0.0025, 0.6143],
         [0.0029, 0.3304],
         [0.0026, 0.2267],
         [0.0017, 0.1738]]])
agent 0 action: VehicleControl(throttle=0.276067, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.402582088711114
+++++++++++++: 1.844367794363839
21.250604370608926 seconds in game passed.
At 21.250604370608926 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2342e-04,  6.0648e-01],
         [ 6.6963e-04,  3.2726e-01],
         [ 5.5951e-04,  2.2524e-01],
         [-1.7378e-04,  1.7300e-01]]])
agent 0 action: VehicleControl(throttle=0.313482, steer=-0.000332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.844367794363839
Current reward: 0.5418207586812495
Current mitigation activation: 0
#############################
Total reward: 56.94440284739236
21.275604370981455 seconds in game passed.
Action: tensor([[[-1.2342e-04,  6.0648e-01],
         [ 6.6963e-04,  3.2726e-01],
         [ 5.5951e-04,  2.2524e-01],
         [-1.7378e-04,  1.7300e-01]]])
agent 0 action: VehicleControl(throttle=0.317622, steer=0.000085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.94440284739236
21.300604371353984 seconds in game passed.
Action: tensor([[[-1.2342e-04,  6.0648e-01],
         [ 6.6963e-04,  3.2726e-01],
         [ 5.5951e-04,  2.2524e-01],
         [-1.7378e-04,  1.7300e-01]]])
agent 0 action: VehicleControl(throttle=0.326048, steer=0.000059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.94440284739236
21.325604371726513 seconds in game passed.
Action: tensor([[[-1.2342e-04,  6.0648e-01],
         [ 6.6963e-04,  3.2726e-01],
         [ 5.5951e-04,  2.2524e-01],
         [-1.7378e-04,  1.7300e-01]]])
agent 0 action: VehicleControl(throttle=0.335075, steer=0.000033, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.94440284739236
+++++++++++++: 1.891148694655769
21.350604372099042 seconds in game passed.
At 21.350604372099042 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6106],
         [-0.0011,  0.3274],
         [-0.0013,  0.2240],
         [-0.0020,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.382487, steer=-0.001862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.891148694655769
Current reward: 0.5399902190487711
Current mitigation activation: 0
#############################
Total reward: 57.48439306644113
21.37560437247157 seconds in game passed.
Action: tensor([[[-0.0015,  0.6106],
         [-0.0011,  0.3274],
         [-0.0013,  0.2240],
         [-0.0020,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.388391, steer=-0.001571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.48439306644113
21.4006043728441 seconds in game passed.
Action: tensor([[[-0.0015,  0.6106],
         [-0.0011,  0.3274],
         [-0.0013,  0.2240],
         [-0.0020,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.398627, steer=-0.001592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.48439306644113
21.42560437321663 seconds in game passed.
Action: tensor([[[-0.0015,  0.6106],
         [-0.0011,  0.3274],
         [-0.0013,  0.2240],
         [-0.0020,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.408776, steer=-0.001614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.48439306644113
+++++++++++++: 1.940822262690499
21.450604373589158 seconds in game passed.
At 21.450604373589158 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.6177],
         [-0.0021,  0.3297],
         [-0.0022,  0.2251],
         [-0.0025,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.410230, steer=-0.002746, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.940822262690499
Current reward: 0.5385229603211814
Current mitigation activation: 0
#############################
Total reward: 58.02291602676231
21.475604373961687 seconds in game passed.
Action: tensor([[[-0.0026,  0.6177],
         [-0.0021,  0.3297],
         [-0.0022,  0.2251],
         [-0.0025,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.421491, steer=-0.002583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.02291602676231
21.500604374334216 seconds in game passed.
Action: tensor([[[-0.0026,  0.6177],
         [-0.0021,  0.3297],
         [-0.0022,  0.2251],
         [-0.0025,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.431719, steer=-0.002605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.02291602676231
21.525604374706745 seconds in game passed.
Action: tensor([[[-0.0026,  0.6177],
         [-0.0021,  0.3297],
         [-0.0022,  0.2251],
         [-0.0025,  0.1724]]])
agent 0 action: VehicleControl(throttle=0.441902, steer=-0.002627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.02291602676231
+++++++++++++: 1.989659285613363
21.550604375079274 seconds in game passed.
At 21.550604375079274 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6086],
         [-0.0012,  0.3273],
         [-0.0011,  0.2243],
         [-0.0011,  0.1719]]])
agent 0 action: VehicleControl(throttle=0.444196, steer=-0.001521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.989659285613363
Current reward: 0.5379546976978615
Current mitigation activation: 0
#############################
Total reward: 58.56087072446017
21.575604375451803 seconds in game passed.
Action: tensor([[[-0.0014,  0.6086],
         [-0.0012,  0.3273],
         [-0.0011,  0.2243],
         [-0.0011,  0.1719]]])
agent 0 action: VehicleControl(throttle=0.456082, steer=-0.001660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.56087072446017
21.600604375824332 seconds in game passed.
Action: tensor([[[-0.0014,  0.6086],
         [-0.0012,  0.3273],
         [-0.0011,  0.2243],
         [-0.0011,  0.1719]]])
agent 0 action: VehicleControl(throttle=0.466883, steer=-0.001621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.56087072446017
21.62560437619686 seconds in game passed.
Action: tensor([[[-0.0014,  0.6086],
         [-0.0012,  0.3273],
         [-0.0011,  0.2243],
         [-0.0011,  0.1719]]])
agent 0 action: VehicleControl(throttle=0.477555, steer=-0.001582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.56087072446017
+++++++++++++: 2.036279608592976
21.65060437656939 seconds in game passed.
At 21.65060437656939 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0011, 0.6075],
         [0.0023, 0.3250],
         [0.0026, 0.2220],
         [0.0025, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.558217, steer=0.002092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.036279608592976
Current reward: 0.5383734805122685
Current mitigation activation: 0
#############################
Total reward: 59.09924420497244
21.67560437694192 seconds in game passed.
Action: tensor([[[0.0011, 0.6075],
         [0.0023, 0.3250],
         [0.0026, 0.2220],
         [0.0025, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.559817, steer=0.001571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.09924420497244
21.70060437731445 seconds in game passed.
Action: tensor([[[0.0011, 0.6075],
         [0.0023, 0.3250],
         [0.0026, 0.2220],
         [0.0025, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.568494, steer=0.001649, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.09924420497244
21.725604377686977 seconds in game passed.
Action: tensor([[[0.0011, 0.6075],
         [0.0023, 0.3250],
         [0.0026, 0.2220],
         [0.0025, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.576043, steer=0.001727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.09924420497244
+++++++++++++: 2.07958574237693
21.750604378059506 seconds in game passed.
At 21.750604378059506 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6142],
         [0.0040, 0.3304],
         [0.0036, 0.2260],
         [0.0026, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.455580, steer=0.003827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.07958574237693
Current reward: 0.5398049917503963
Current mitigation activation: 0
#############################
Total reward: 59.63904919672284
21.775604378432035 seconds in game passed.
Action: tensor([[[0.0031, 0.6142],
         [0.0040, 0.3304],
         [0.0036, 0.2260],
         [0.0026, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.472704, steer=0.003594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.63904919672284
21.800604378804564 seconds in game passed.
Action: tensor([[[0.0031, 0.6142],
         [0.0040, 0.3304],
         [0.0036, 0.2260],
         [0.0026, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.476751, steer=0.003695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.63904919672284
21.825604379177094 seconds in game passed.
Action: tensor([[[0.0031, 0.6142],
         [0.0040, 0.3304],
         [0.0036, 0.2260],
         [0.0026, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.481021, steer=0.003795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.63904919672284
+++++++++++++: 2.116132079366406
21.850604379549623 seconds in game passed.
At 21.850604379549623 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0021, 0.6154],
         [0.0033, 0.3278],
         [0.0032, 0.2236],
         [0.0026, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.592073, steer=0.002970, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.116132079366406
Current reward: 0.5425811118255572
Current mitigation activation: 0
#############################
Total reward: 60.18163030854839
21.87560437992215 seconds in game passed.
Action: tensor([[[0.0021, 0.6154],
         [0.0033, 0.3278],
         [0.0032, 0.2236],
         [0.0026, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.586522, steer=0.003167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.18163030854839
21.90060438029468 seconds in game passed.
Action: tensor([[[0.0021, 0.6154],
         [0.0033, 0.3278],
         [0.0032, 0.2236],
         [0.0026, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.592421, steer=0.003219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.18163030854839
21.92560438066721 seconds in game passed.
Action: tensor([[[0.0021, 0.6154],
         [0.0033, 0.3278],
         [0.0032, 0.2236],
         [0.0026, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.598447, steer=0.003270, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.18163030854839
+++++++++++++: 2.1519404372706394
21.95060438103974 seconds in game passed.
At 21.95060438103974 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.6032],
         [0.0036, 0.3231],
         [0.0038, 0.2205],
         [0.0031, 0.1684]]])
agent 0 action: VehicleControl(throttle=0.652208, steer=0.003282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1519404372706394
Current reward: 0.5457368631780639
Current mitigation activation: 0
#############################
Total reward: 60.727367171726456
21.975604381412268 seconds in game passed.
Action: tensor([[[0.0015, 0.6032],
         [0.0036, 0.3231],
         [0.0038, 0.2205],
         [0.0031, 0.1684]]])
agent 0 action: VehicleControl(throttle=0.655379, steer=0.003282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.727367171726456
22.000604381784797 seconds in game passed.
Action: tensor([[[0.0015, 0.6032],
         [0.0036, 0.3231],
         [0.0038, 0.2205],
         [0.0031, 0.1684]]])
agent 0 action: VehicleControl(throttle=0.663469, steer=0.003283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.727367171726456
22.025604382157326 seconds in game passed.
Action: tensor([[[0.0015, 0.6032],
         [0.0036, 0.3231],
         [0.0038, 0.2205],
         [0.0031, 0.1684]]])
agent 0 action: VehicleControl(throttle=0.671577, steer=0.003284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.727367171726456
+++++++++++++: 2.1887742207169176
22.050604382529855 seconds in game passed.
At 22.050604382529855 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0021, 0.6121],
         [0.0056, 0.3262],
         [0.0058, 0.2216],
         [0.0048, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.660057, steer=0.004994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1887742207169176
Current reward: 0.5489959143195235
Current mitigation activation: 0
#############################
Total reward: 61.27636308604598
22.075604382902384 seconds in game passed.
Action: tensor([[[0.0021, 0.6121],
         [0.0056, 0.3262],
         [0.0058, 0.2216],
         [0.0048, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.670009, steer=0.004734, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.27636308604598
22.100604383274913 seconds in game passed.
Action: tensor([[[0.0021, 0.6121],
         [0.0056, 0.3262],
         [0.0058, 0.2216],
         [0.0048, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.677802, steer=0.004755, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.27636308604598
22.125604383647442 seconds in game passed.
Action: tensor([[[0.0021, 0.6121],
         [0.0056, 0.3262],
         [0.0058, 0.2216],
         [0.0048, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.685474, steer=0.004776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.27636308604598
+++++++++++++: 2.2265483140004516
22.15060438401997 seconds in game passed.
At 22.15060438401997 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0029, 0.6207],
         [0.0059, 0.3281],
         [0.0063, 0.2224],
         [0.0055, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.709846, steer=0.005341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2265483140004516
Current reward: 0.5523526349864305
Current mitigation activation: 0
#############################
Total reward: 61.82871572103241
22.1756043843925 seconds in game passed.
Action: tensor([[[0.0029, 0.6207],
         [0.0059, 0.3281],
         [0.0063, 0.2224],
         [0.0055, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.715062, steer=0.005275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.82871572103241
22.20060438476503 seconds in game passed.
Action: tensor([[[0.0029, 0.6207],
         [0.0059, 0.3281],
         [0.0063, 0.2224],
         [0.0055, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.721956, steer=0.005300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.82871572103241
22.225604385137558 seconds in game passed.
Action: tensor([[[0.0029, 0.6207],
         [0.0059, 0.3281],
         [0.0063, 0.2224],
         [0.0055, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.728673, steer=0.005325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.82871572103241
+++++++++++++: 2.2651866430924086
22.250604385510087 seconds in game passed.
At 22.250604385510087 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0052, 0.6302],
         [0.0073, 0.3300],
         [0.0079, 0.2231],
         [0.0074, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.760961, steer=0.007350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2651866430924086
Current reward: 0.5557983444069913
Current mitigation activation: 0
#############################
Total reward: 62.384514065439404
22.275604385882616 seconds in game passed.
Action: tensor([[[0.0052, 0.6302],
         [0.0073, 0.3300],
         [0.0079, 0.2231],
         [0.0074, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.743144, steer=0.007097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.384514065439404
22.300604386255145 seconds in game passed.
Action: tensor([[[0.0052, 0.6302],
         [0.0073, 0.3300],
         [0.0079, 0.2231],
         [0.0074, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.731045, steer=0.007170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.384514065439404
22.325604386627674 seconds in game passed.
Action: tensor([[[0.0052, 0.6302],
         [0.0073, 0.3300],
         [0.0079, 0.2231],
         [0.0074, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.718188, steer=0.007243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.384514065439404
+++++++++++++: 2.2822614602728555
22.350604387000203 seconds in game passed.
At 22.350604387000203 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0104, 0.6414],
         [0.0153, 0.3343],
         [0.0169, 0.2246],
         [0.0164, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.662657, steer=0.015379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2822614602728555
Current reward: 0.5620894062039095
Current mitigation activation: 0
#############################
Total reward: 62.946603471643314
22.375604387372732 seconds in game passed.
Action: tensor([[[0.0104, 0.6414],
         [0.0153, 0.3343],
         [0.0169, 0.2246],
         [0.0164, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.652642, steer=0.014227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.946603471643314
22.40060438774526 seconds in game passed.
Action: tensor([[[0.0104, 0.6414],
         [0.0153, 0.3343],
         [0.0169, 0.2246],
         [0.0164, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.638319, steer=0.014403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.946603471643314
22.42560438811779 seconds in game passed.
Action: tensor([[[0.0104, 0.6414],
         [0.0153, 0.3343],
         [0.0169, 0.2246],
         [0.0164, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.624125, steer=0.014578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.946603471643314
+++++++++++++: 2.283261990003905
22.45060438849032 seconds in game passed.
At 22.45060438849032 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0090, 0.6387],
         [0.0111, 0.3339],
         [0.0116, 0.2252],
         [0.0107, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.598395, steer=0.011054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.283261990003905
Current reward: 0.5702985292494559
Current mitigation activation: 0
#############################
Total reward: 63.51690200089277
22.47560438886285 seconds in game passed.
Action: tensor([[[0.0090, 0.6387],
         [0.0111, 0.3339],
         [0.0116, 0.2252],
         [0.0107, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.585994, steer=0.011815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.51690200089277
22.500604389235377 seconds in game passed.
Action: tensor([[[0.0090, 0.6387],
         [0.0111, 0.3339],
         [0.0116, 0.2252],
         [0.0107, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.572640, steer=0.011963, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.51690200089277
22.525604389607906 seconds in game passed.
Action: tensor([[[0.0090, 0.6387],
         [0.0111, 0.3339],
         [0.0116, 0.2252],
         [0.0107, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.559827, steer=0.012112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.51690200089277
+++++++++++++: 2.287197652588735
22.550604389980435 seconds in game passed.
At 22.550604389980435 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6228],
         [0.0047, 0.3307],
         [0.0046, 0.2246],
         [0.0037, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.502236, steer=0.005474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.287197652588735
Current reward: 0.5778894247408211
Current mitigation activation: 0
#############################
Total reward: 64.09479142563359
22.575604390352964 seconds in game passed.
Action: tensor([[[0.0040, 0.6228],
         [0.0047, 0.3307],
         [0.0046, 0.2246],
         [0.0037, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.494829, steer=0.006660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.09479142563359
22.600604390725493 seconds in game passed.
Action: tensor([[[0.0040, 0.6228],
         [0.0047, 0.3307],
         [0.0046, 0.2246],
         [0.0037, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.483190, steer=0.006727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.09479142563359
22.625604391098022 seconds in game passed.
Action: tensor([[[0.0040, 0.6228],
         [0.0047, 0.3307],
         [0.0046, 0.2246],
         [0.0037, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.472498, steer=0.006795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.09479142563359
+++++++++++++: 2.2963140043564
22.65060439147055 seconds in game passed.
At 22.65060439147055 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6224],
         [0.0045, 0.3292],
         [0.0046, 0.2235],
         [0.0037, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.510838, steer=0.006377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2963140043564
Current reward: 0.5845812397245794
Current mitigation activation: 0
#############################
Total reward: 64.67937266535817
22.67560439184308 seconds in game passed.
Action: tensor([[[0.0032, 0.6224],
         [0.0045, 0.3292],
         [0.0046, 0.2235],
         [0.0037, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.496254, steer=0.006477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.67937266535817
22.70060439221561 seconds in game passed.
Action: tensor([[[0.0032, 0.6224],
         [0.0045, 0.3292],
         [0.0046, 0.2235],
         [0.0037, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.487442, steer=0.006502, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.67937266535817
22.72560439258814 seconds in game passed.
Action: tensor([[[0.0032, 0.6224],
         [0.0045, 0.3292],
         [0.0046, 0.2235],
         [0.0037, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.478896, steer=0.006528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.67937266535817
+++++++++++++: 2.3119676583966364
22.750604392960668 seconds in game passed.
At 22.750604392960668 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6078],
         [0.0046, 0.3245],
         [0.0045, 0.2212],
         [0.0038, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.493007, steer=0.006924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3119676583966364
Current reward: 0.5902409529655346
Current mitigation activation: 0
#############################
Total reward: 65.2696136183237
22.775604393333197 seconds in game passed.
Action: tensor([[[0.0040, 0.6078],
         [0.0046, 0.3245],
         [0.0045, 0.2212],
         [0.0038, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.484651, steer=0.006868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.2696136183237
22.800604393705726 seconds in game passed.
Action: tensor([[[0.0040, 0.6078],
         [0.0046, 0.3245],
         [0.0045, 0.2212],
         [0.0038, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.478844, steer=0.006877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.2696136183237
22.825604394078255 seconds in game passed.
Action: tensor([[[0.0040, 0.6078],
         [0.0046, 0.3245],
         [0.0045, 0.2212],
         [0.0038, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.473225, steer=0.006885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.2696136183237
+++++++++++++: 2.331930622497687
22.850604394450784 seconds in game passed.
At 22.850604394450784 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0015,  0.6127],
         [ 0.0021,  0.3264],
         [ 0.0009,  0.2222],
         [-0.0010,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.449992, steer=0.004043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.331930622497687
Current reward: 0.595223382083572
Current mitigation activation: 0
#############################
Total reward: 65.86483700040728
22.875604394823313 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6127],
         [ 0.0021,  0.3264],
         [ 0.0009,  0.2222],
         [-0.0010,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.445250, steer=0.004503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.86483700040728
22.900604395195842 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6127],
         [ 0.0021,  0.3264],
         [ 0.0009,  0.2222],
         [-0.0010,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.439010, steer=0.004491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.86483700040728
22.92560439556837 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6127],
         [ 0.0021,  0.3264],
         [ 0.0009,  0.2222],
         [-0.0010,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.433177, steer=0.004480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.86483700040728
+++++++++++++: 2.354464814044647
22.9506043959409 seconds in game passed.
At 22.9506043959409 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.6551e-03, 6.1570e-01],
         [1.8248e-03, 3.2661e-01],
         [1.2497e-03, 2.2239e-01],
         [1.4170e-04, 1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.450523, steer=0.004323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.354464814044647
Current reward: 0.5997960165284058
Current mitigation activation: 0
#############################
Total reward: 66.46463301693568
22.97560439631343 seconds in game passed.
Action: tensor([[[1.6551e-03, 6.1570e-01],
         [1.8248e-03, 3.2661e-01],
         [1.2497e-03, 2.2239e-01],
         [1.4170e-04, 1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.442665, steer=0.004334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.46463301693568
23.000604396685958 seconds in game passed.
Action: tensor([[[1.6551e-03, 6.1570e-01],
         [1.8248e-03, 3.2661e-01],
         [1.2497e-03, 2.2239e-01],
         [1.4170e-04, 1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.437545, steer=0.004320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.46463301693568
23.025604397058487 seconds in game passed.
Action: tensor([[[1.6551e-03, 6.1570e-01],
         [1.8248e-03, 3.2661e-01],
         [1.2497e-03, 2.2239e-01],
         [1.4170e-04, 1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.432546, steer=0.004307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.46463301693568
+++++++++++++: 2.3797684358651043
23.050604397431016 seconds in game passed.
At 23.050604397431016 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.6105],
         [0.0030, 0.3261],
         [0.0030, 0.2224],
         [0.0025, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.393239, steer=0.005397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3797684358651043
Current reward: 0.6039615745484282
Current mitigation activation: 0
#############################
Total reward: 67.0685945914841
23.075604397803545 seconds in game passed.
Action: tensor([[[0.0023, 0.6105],
         [0.0030, 0.3261],
         [0.0030, 0.2224],
         [0.0025, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.392114, steer=0.005193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.0685945914841
23.100604398176074 seconds in game passed.
Action: tensor([[[0.0023, 0.6105],
         [0.0030, 0.3261],
         [0.0030, 0.2224],
         [0.0025, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.387610, steer=0.005173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.0685945914841
23.125604398548603 seconds in game passed.
Action: tensor([[[0.0023, 0.6105],
         [0.0030, 0.3261],
         [0.0030, 0.2224],
         [0.0025, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.383595, steer=0.005154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.0685945914841
+++++++++++++: 2.407308214777109
23.150604398921132 seconds in game passed.
At 23.150604398921132 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6279],
         [0.0057, 0.3315],
         [0.0056, 0.2246],
         [0.0045, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.361946, steer=0.007712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.407308214777109
Current reward: 0.6078234986092075
Current mitigation activation: 0
#############################
Total reward: 67.6764180900933
23.17560439929366 seconds in game passed.
Action: tensor([[[0.0037, 0.6279],
         [0.0057, 0.3315],
         [0.0056, 0.2246],
         [0.0045, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.360193, steer=0.007288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.6764180900933
23.20060439966619 seconds in game passed.
Action: tensor([[[0.0037, 0.6279],
         [0.0057, 0.3315],
         [0.0056, 0.2246],
         [0.0045, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.356968, steer=0.007290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.6764180900933
23.22560440003872 seconds in game passed.
Action: tensor([[[0.0037, 0.6279],
         [0.0057, 0.3315],
         [0.0056, 0.2246],
         [0.0045, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.354190, steer=0.007291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.6764180900933
+++++++++++++: 2.4380799085286284
23.250604400411248 seconds in game passed.
At 23.250604400411248 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6097],
         [0.0051, 0.3271],
         [0.0052, 0.2230],
         [0.0044, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.322635, steer=0.006855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4380799085286284
Current reward: 0.6112869262476393
Current mitigation activation: 0
#############################
Total reward: 68.28770501634095
23.275604400783777 seconds in game passed.
Action: tensor([[[0.0039, 0.6097],
         [0.0051, 0.3271],
         [0.0052, 0.2230],
         [0.0044, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.323280, steer=0.006901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.28770501634095
23.300604401156306 seconds in game passed.
Action: tensor([[[0.0039, 0.6097],
         [0.0051, 0.3271],
         [0.0052, 0.2230],
         [0.0044, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.321481, steer=0.006878, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.28770501634095
23.325604401528835 seconds in game passed.
Action: tensor([[[0.0039, 0.6097],
         [0.0051, 0.3271],
         [0.0052, 0.2230],
         [0.0044, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.320441, steer=0.006855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.28770501634095
+++++++++++++: 2.472552200595679
23.350604401901364 seconds in game passed.
At 23.350604401901364 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3384e-03, 6.0213e-01],
         [1.4087e-03, 3.2511e-01],
         [1.0869e-03, 2.2230e-01],
         [2.6791e-04, 1.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.313565, steer=0.003029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.472552200595679
Current reward: 0.6143349225441189
Current mitigation activation: 0
#############################
Total reward: 68.90203993888507
23.375604402273893 seconds in game passed.
Action: tensor([[[1.3384e-03, 6.0213e-01],
         [1.4087e-03, 3.2511e-01],
         [1.0869e-03, 2.2230e-01],
         [2.6791e-04, 1.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.314872, steer=0.003498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.90203993888507
23.400604402646422 seconds in game passed.
Action: tensor([[[1.3384e-03, 6.0213e-01],
         [1.4087e-03, 3.2511e-01],
         [1.0869e-03, 2.2230e-01],
         [2.6791e-04, 1.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.315973, steer=0.003354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.90203993888507
23.42560440301895 seconds in game passed.
Action: tensor([[[1.3384e-03, 6.0213e-01],
         [1.4087e-03, 3.2511e-01],
         [1.0869e-03, 2.2230e-01],
         [2.6791e-04, 1.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.317615, steer=0.003210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.90203993888507
+++++++++++++: 2.510828497315343
23.45060440339148 seconds in game passed.
At 23.45060440339148 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2256e-03,  6.1889e-01],
         [-3.2412e-04,  3.2889e-01],
         [-6.6112e-04,  2.2342e-01],
         [-1.4790e-03,  1.6999e-01]]])
agent 0 action: VehicleControl(throttle=0.357606, steer=0.000808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.510828497315343
Current reward: 0.616996082702506
Current mitigation activation: 0
#############################
Total reward: 69.51903602158757
23.47560440376401 seconds in game passed.
Action: tensor([[[-1.2256e-03,  6.1889e-01],
         [-3.2412e-04,  3.2889e-01],
         [-6.6112e-04,  2.2342e-01],
         [-1.4790e-03,  1.6999e-01]]])
agent 0 action: VehicleControl(throttle=0.356651, steer=0.001057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.51903602158757
23.50060440413654 seconds in game passed.
Action: tensor([[[-1.2256e-03,  6.1889e-01],
         [-3.2412e-04,  3.2889e-01],
         [-6.6112e-04,  2.2342e-01],
         [-1.4790e-03,  1.6999e-01]]])
agent 0 action: VehicleControl(throttle=0.359932, steer=0.000928, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.51903602158757
23.525604404509068 seconds in game passed.
Action: tensor([[[-1.2256e-03,  6.1889e-01],
         [-3.2412e-04,  3.2889e-01],
         [-6.6112e-04,  2.2342e-01],
         [-1.4790e-03,  1.6999e-01]]])
agent 0 action: VehicleControl(throttle=0.363192, steer=0.000798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.51903602158757
+++++++++++++: 2.551758430322377
23.550604404881597 seconds in game passed.
At 23.550604404881597 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6146],
         [-0.0018,  0.3266],
         [-0.0023,  0.2219],
         [-0.0032,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.408188, steer=-0.000877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.551758430322377
Current reward: 0.6194515415699007
Current mitigation activation: 0
#############################
Total reward: 70.13848756315747
23.575604405254126 seconds in game passed.
Action: tensor([[[-0.0025,  0.6146],
         [-0.0018,  0.3266],
         [-0.0023,  0.2219],
         [-0.0032,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.408098, steer=-0.000687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.13848756315747
23.600604405626655 seconds in game passed.
Action: tensor([[[-0.0025,  0.6146],
         [-0.0018,  0.3266],
         [-0.0023,  0.2219],
         [-0.0032,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.412265, steer=-0.000763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.13848756315747
23.625604405999184 seconds in game passed.
Action: tensor([[[-0.0025,  0.6146],
         [-0.0018,  0.3266],
         [-0.0023,  0.2219],
         [-0.0032,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.416071, steer=-0.000840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.13848756315747
+++++++++++++: 2.5925503489720776
23.650604406371713 seconds in game passed.
At 23.650604406371713 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.6102],
         [-0.0016,  0.3260],
         [-0.0019,  0.2218],
         [-0.0027,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.391640, steer=-0.000433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5925503489720776
Current reward: 0.6220555675454134
Current mitigation activation: 0
#############################
Total reward: 70.76054313070289
23.67560440674424 seconds in game passed.
Action: tensor([[[-0.0018,  0.6102],
         [-0.0016,  0.3260],
         [-0.0019,  0.2218],
         [-0.0027,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.397002, steer=-0.000579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.76054313070289
23.70060440711677 seconds in game passed.
Action: tensor([[[-0.0018,  0.6102],
         [-0.0016,  0.3260],
         [-0.0019,  0.2218],
         [-0.0027,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.399308, steer=-0.000646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.76054313070289
23.7256044074893 seconds in game passed.
Action: tensor([[[-0.0018,  0.6102],
         [-0.0016,  0.3260],
         [-0.0019,  0.2218],
         [-0.0027,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.401649, steer=-0.000713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.76054313070289
+++++++++++++: 2.630928475422274
23.75060440786183 seconds in game passed.
At 23.75060440786183 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.6087],
         [-0.0010,  0.3260],
         [-0.0012,  0.2222],
         [-0.0017,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.388883, steer=-0.000016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.630928475422274
Current reward: 0.6250540301513225
Current mitigation activation: 0
#############################
Total reward: 71.3855971608542
23.775604408234358 seconds in game passed.
Action: tensor([[[-0.0008,  0.6087],
         [-0.0010,  0.3260],
         [-0.0012,  0.2222],
         [-0.0017,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.392345, steer=-0.000205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.3855971608542
23.800604408606887 seconds in game passed.
Action: tensor([[[-0.0008,  0.6087],
         [-0.0010,  0.3260],
         [-0.0012,  0.2222],
         [-0.0017,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.394240, steer=-0.000268, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.3855971608542
23.825604408979416 seconds in game passed.
Action: tensor([[[-0.0008,  0.6087],
         [-0.0010,  0.3260],
         [-0.0012,  0.2222],
         [-0.0017,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.396226, steer=-0.000331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.3855971608542
+++++++++++++: 2.6680790181208107
23.850604409351945 seconds in game passed.
At 23.850604409351945 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.6072],
         [-0.0009,  0.3264],
         [-0.0014,  0.2224],
         [-0.0020,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.366864, steer=-0.000250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6680790181208107
Current reward: 0.6282726637676777
Current mitigation activation: 0
#############################
Total reward: 72.01386982462188
23.875604409724474 seconds in game passed.
Action: tensor([[[-0.0008,  0.6072],
         [-0.0009,  0.3264],
         [-0.0014,  0.2224],
         [-0.0020,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.372101, steer=-0.000301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.01386982462188
23.900604410097003 seconds in game passed.
Action: tensor([[[-0.0008,  0.6072],
         [-0.0009,  0.3264],
         [-0.0014,  0.2224],
         [-0.0020,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.374097, steer=-0.000334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.01386982462188
23.925604410469532 seconds in game passed.
Action: tensor([[[-0.0008,  0.6072],
         [-0.0009,  0.3264],
         [-0.0014,  0.2224],
         [-0.0020,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.376361, steer=-0.000366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.01386982462188
+++++++++++++: 2.705236533092291
23.95060441084206 seconds in game passed.
At 23.95060441084206 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.8877e-04,  6.1657e-01],
         [ 2.2897e-04,  3.2915e-01],
         [-3.5417e-04,  2.2347e-01],
         [-1.2675e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.377873, steer=0.000946, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.705236533092291
Current reward: 0.631551134731976
Current mitigation activation: 0
#############################
Total reward: 72.64542095935386
23.97560441121459 seconds in game passed.
Action: tensor([[[ 4.8877e-04,  6.1657e-01],
         [ 2.2897e-04,  3.2915e-01],
         [-3.5417e-04,  2.2347e-01],
         [-1.2675e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.380223, steer=0.000707, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.64542095935386
24.00060441158712 seconds in game passed.
Action: tensor([[[ 4.8877e-04,  6.1657e-01],
         [ 2.2897e-04,  3.2915e-01],
         [-3.5417e-04,  2.2347e-01],
         [-1.2675e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.382596, steer=0.000690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.64542095935386
24.025604411959648 seconds in game passed.
Action: tensor([[[ 4.8877e-04,  6.1657e-01],
         [ 2.2897e-04,  3.2915e-01],
         [-3.5417e-04,  2.2347e-01],
         [-1.2675e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.385033, steer=0.000673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.64542095935386
+++++++++++++: 2.743370819274751
24.050604412332177 seconds in game passed.
At 24.050604412332177 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.8612e-03,  6.2151e-01],
         [ 1.7467e-03,  3.3035e-01],
         [ 9.7313e-04,  2.2473e-01],
         [-1.7674e-04,  1.7076e-01]]])
agent 0 action: VehicleControl(throttle=0.395280, steer=0.002709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.743370819274751
Current reward: 0.6347806841780338
Current mitigation activation: 0
#############################
Total reward: 73.2802016435319
24.075604412704706 seconds in game passed.
Action: tensor([[[ 2.8612e-03,  6.2151e-01],
         [ 1.7467e-03,  3.3035e-01],
         [ 9.7313e-04,  2.2473e-01],
         [-1.7674e-04,  1.7076e-01]]])
agent 0 action: VehicleControl(throttle=0.397454, steer=0.002361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.2802016435319
24.100604413077235 seconds in game passed.
Action: tensor([[[ 2.8612e-03,  6.2151e-01],
         [ 1.7467e-03,  3.3035e-01],
         [ 9.7313e-04,  2.2473e-01],
         [-1.7674e-04,  1.7076e-01]]])
agent 0 action: VehicleControl(throttle=0.400391, steer=0.002354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.2802016435319
24.125604413449764 seconds in game passed.
Action: tensor([[[ 2.8612e-03,  6.2151e-01],
         [ 1.7467e-03,  3.3035e-01],
         [ 9.7313e-04,  2.2473e-01],
         [-1.7674e-04,  1.7076e-01]]])
agent 0 action: VehicleControl(throttle=0.403229, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.2802016435319
+++++++++++++: 2.7820410215354974
24.150604413822293 seconds in game passed.
At 24.150604413822293 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.9123e-03,  6.1384e-01],
         [-2.9819e-04,  3.2724e-01],
         [-7.5328e-04,  2.2359e-01],
         [-1.2196e-03,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.440070, steer=0.000420, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7820410215354974
Current reward: 0.6380171862840568
Current mitigation activation: 0
#############################
Total reward: 73.91821882981596
24.175604414194822 seconds in game passed.
Action: tensor([[[ 1.9123e-03,  6.1384e-01],
         [-2.9819e-04,  3.2724e-01],
         [-7.5328e-04,  2.2359e-01],
         [-1.2196e-03,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.439691, steer=0.000679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.91821882981596
24.20060441456735 seconds in game passed.
Action: tensor([[[ 1.9123e-03,  6.1384e-01],
         [-2.9819e-04,  3.2724e-01],
         [-7.5328e-04,  2.2359e-01],
         [-1.2196e-03,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.442689, steer=0.000626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.91821882981596
24.22560441493988 seconds in game passed.
Action: tensor([[[ 1.9123e-03,  6.1384e-01],
         [-2.9819e-04,  3.2724e-01],
         [-7.5328e-04,  2.2359e-01],
         [-1.2196e-03,  1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.445271, steer=0.000573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.91821882981596
+++++++++++++: 2.8198944514533935
24.25060441531241 seconds in game passed.
At 24.25060441531241 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6682e-04,  6.1978e-01],
         [-1.5941e-03,  3.2891e-01],
         [-1.8655e-03,  2.2403e-01],
         [-2.2798e-03,  1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.448518, steer=-0.001261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8198944514533935
Current reward: 0.6414001019261283
Current mitigation activation: 0
#############################
Total reward: 74.55961893174208
24.27560441568494 seconds in game passed.
Action: tensor([[[-1.6682e-04,  6.1978e-01],
         [-1.5941e-03,  3.2891e-01],
         [-1.8655e-03,  2.2403e-01],
         [-2.2798e-03,  1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.450727, steer=-0.001034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.55961893174208
24.300604416057467 seconds in game passed.
Action: tensor([[[-1.6682e-04,  6.1978e-01],
         [-1.5941e-03,  3.2891e-01],
         [-1.8655e-03,  2.2403e-01],
         [-2.2798e-03,  1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.452725, steer=-0.001102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.55961893174208
24.325604416429996 seconds in game passed.
Action: tensor([[[-1.6682e-04,  6.1978e-01],
         [-1.5941e-03,  3.2891e-01],
         [-1.8655e-03,  2.2403e-01],
         [-2.2798e-03,  1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.454444, steer=-0.001169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.55961893174208
+++++++++++++: 2.8553489779015995
24.350604416802526 seconds in game passed.
At 24.350604416802526 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6144],
         [-0.0030,  0.3267],
         [-0.0034,  0.2224],
         [-0.0037,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.480404, steer=-0.002686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8553489779015995
Current reward: 0.6450755540474377
Current mitigation activation: 0
#############################
Total reward: 75.20469448578952
24.375604417175055 seconds in game passed.
Action: tensor([[[-0.0012,  0.6144],
         [-0.0030,  0.3267],
         [-0.0034,  0.2224],
         [-0.0037,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.479379, steer=-0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.20469448578952
24.400604417547584 seconds in game passed.
Action: tensor([[[-0.0012,  0.6144],
         [-0.0030,  0.3267],
         [-0.0034,  0.2224],
         [-0.0037,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.480648, steer=-0.002530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.20469448578952
24.425604417920113 seconds in game passed.
Action: tensor([[[-0.0012,  0.6144],
         [-0.0030,  0.3267],
         [-0.0034,  0.2224],
         [-0.0037,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.481482, steer=-0.002574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.20469448578952
+++++++++++++: 2.8882538894841687
24.45060441829264 seconds in game passed.
At 24.45060441829264 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.6247],
         [-0.0068,  0.3317],
         [-0.0075,  0.2249],
         [-0.0077,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.407183, steer=-0.006477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8882538894841687
Current reward: 0.649029575217215
Current mitigation activation: 0
#############################
Total reward: 75.85372406100673
24.47560441866517 seconds in game passed.
Action: tensor([[[-0.0039,  0.6247],
         [-0.0068,  0.3317],
         [-0.0075,  0.2249],
         [-0.0077,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.414002, steer=-0.005898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.85372406100673
24.5006044190377 seconds in game passed.
Action: tensor([[[-0.0039,  0.6247],
         [-0.0068,  0.3317],
         [-0.0075,  0.2249],
         [-0.0077,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.412912, steer=-0.005958, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.85372406100673
24.52560441941023 seconds in game passed.
Action: tensor([[[-0.0039,  0.6247],
         [-0.0068,  0.3317],
         [-0.0075,  0.2249],
         [-0.0077,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.412197, steer=-0.006019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.85372406100673
+++++++++++++: 2.9188999879040636
24.550604419782758 seconds in game passed.
At 24.550604419782758 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.6006],
         [-0.0027,  0.3243],
         [-0.0031,  0.2212],
         [-0.0039,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.429522, steer=-0.002494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9188999879040636
Current reward: 0.6532032565019728
Current mitigation activation: 0
#############################
Total reward: 76.5069273175087
24.575604420155287 seconds in game passed.
Action: tensor([[[-0.0026,  0.6006],
         [-0.0027,  0.3243],
         [-0.0031,  0.2212],
         [-0.0039,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.427017, steer=-0.003090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.5069273175087
24.600604420527816 seconds in game passed.
Action: tensor([[[-0.0026,  0.6006],
         [-0.0027,  0.3243],
         [-0.0031,  0.2212],
         [-0.0039,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.426537, steer=-0.003098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.5069273175087
24.625604420900345 seconds in game passed.
Action: tensor([[[-0.0026,  0.6006],
         [-0.0027,  0.3243],
         [-0.0031,  0.2212],
         [-0.0039,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.426047, steer=-0.003105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.5069273175087
+++++++++++++: 2.9507701401816178
24.650604421272874 seconds in game passed.
At 24.650604421272874 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.1067e-04,  6.0065e-01],
         [ 4.0816e-04,  3.2454e-01],
         [ 4.5840e-04,  2.2160e-01],
         [-7.7471e-05,  1.6811e-01]]])
agent 0 action: VehicleControl(throttle=0.416205, steer=-0.000088, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9507701401816178
Current reward: 0.6572289277707859
Current mitigation activation: 0
#############################
Total reward: 77.16415624527949
24.675604421645403 seconds in game passed.
Action: tensor([[[-8.1067e-04,  6.0065e-01],
         [ 4.0816e-04,  3.2454e-01],
         [ 4.5840e-04,  2.2160e-01],
         [-7.7471e-05,  1.6811e-01]]])
agent 0 action: VehicleControl(throttle=0.416970, steer=-0.000569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.16415624527949
24.700604422017932 seconds in game passed.
Action: tensor([[[-8.1067e-04,  6.0065e-01],
         [ 4.0816e-04,  3.2454e-01],
         [ 4.5840e-04,  2.2160e-01],
         [-7.7471e-05,  1.6811e-01]]])
agent 0 action: VehicleControl(throttle=0.416750, steer=-0.000550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.16415624527949
24.72560442239046 seconds in game passed.
Action: tensor([[[-8.1067e-04,  6.0065e-01],
         [ 4.0816e-04,  3.2454e-01],
         [ 4.5840e-04,  2.2160e-01],
         [-7.7471e-05,  1.6811e-01]]])
agent 0 action: VehicleControl(throttle=0.416622, steer=-0.000531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.16415624527949
+++++++++++++: 2.9838078149677862
24.75060442276299 seconds in game passed.
At 24.75060442276299 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0011, 0.6059],
         [0.0019, 0.3264],
         [0.0022, 0.2224],
         [0.0019, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.406076, steer=0.001372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9838078149677862
Current reward: 0.6611295246993142
Current mitigation activation: 0
#############################
Total reward: 77.8252857699788
24.77560442313552 seconds in game passed.
Action: tensor([[[0.0011, 0.6059],
         [0.0019, 0.3264],
         [0.0022, 0.2224],
         [0.0019, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.407234, steer=0.001090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.8252857699788
24.800604423508048 seconds in game passed.
Action: tensor([[[0.0011, 0.6059],
         [0.0019, 0.3264],
         [0.0022, 0.2224],
         [0.0019, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.407340, steer=0.001121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.8252857699788
24.825604423880577 seconds in game passed.
Action: tensor([[[0.0011, 0.6059],
         [0.0019, 0.3264],
         [0.0022, 0.2224],
         [0.0019, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.407564, steer=0.001151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.8252857699788
+++++++++++++: 3.0177377337654154
24.850604424253106 seconds in game passed.
At 24.850604424253106 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6040],
         [0.0027, 0.3253],
         [0.0025, 0.2227],
         [0.0019, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.428401, steer=0.002503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0177377337654154
Current reward: 0.6649399176393341
Current mitigation activation: 0
#############################
Total reward: 78.49022568761814
24.875604424625635 seconds in game passed.
Action: tensor([[[0.0031, 0.6040],
         [0.0027, 0.3253],
         [0.0025, 0.2227],
         [0.0019, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.427202, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.49022568761814
24.900604424998164 seconds in game passed.
Action: tensor([[[0.0031, 0.6040],
         [0.0027, 0.3253],
         [0.0025, 0.2227],
         [0.0019, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.428136, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.49022568761814
24.925604425370693 seconds in game passed.
Action: tensor([[[0.0031, 0.6040],
         [0.0027, 0.3253],
         [0.0025, 0.2227],
         [0.0019, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.428921, steer=0.002414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.49022568761814
+++++++++++++: 3.0526316824025908
24.950604425743222 seconds in game passed.
At 24.950604425743222 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0030, 0.6111],
         [0.0025, 0.3267],
         [0.0025, 0.2230],
         [0.0022, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.452486, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0526316824025908
Current reward: 0.6686597901162226
Current mitigation activation: 0
#############################
Total reward: 79.15888547773436
24.97560442611575 seconds in game passed.
Action: tensor([[[0.0030, 0.6111],
         [0.0025, 0.3267],
         [0.0025, 0.2230],
         [0.0022, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.450907, steer=0.002338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.15888547773436
25.00060442648828 seconds in game passed.
Action: tensor([[[0.0030, 0.6111],
         [0.0025, 0.3267],
         [0.0025, 0.2230],
         [0.0022, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.451589, steer=0.002366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.15888547773436
25.02560442686081 seconds in game passed.
Action: tensor([[[0.0030, 0.6111],
         [0.0025, 0.3267],
         [0.0025, 0.2230],
         [0.0022, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.451987, steer=0.002393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.15888547773436
+++++++++++++: 3.0869951576841896
25.05060442723334 seconds in game passed.
At 25.05060442723334 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4399e-03, 6.1759e-01],
         [2.9444e-04, 3.2878e-01],
         [2.7066e-04, 2.2379e-01],
         [1.1215e-04, 1.6986e-01]]])
agent 0 action: VehicleControl(throttle=0.443150, steer=0.000154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0869951576841896
Current reward: 0.6724371852956681
Current mitigation activation: 0
#############################
Total reward: 79.83132266303002
25.075604427605867 seconds in game passed.
Action: tensor([[[1.4399e-03, 6.1759e-01],
         [2.9444e-04, 3.2878e-01],
         [2.7066e-04, 2.2379e-01],
         [1.1215e-04, 1.6986e-01]]])
agent 0 action: VehicleControl(throttle=0.443910, steer=0.000507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.83132266303002
25.100604427978396 seconds in game passed.
Action: tensor([[[1.4399e-03, 6.1759e-01],
         [2.9444e-04, 3.2878e-01],
         [2.7066e-04, 2.2379e-01],
         [1.1215e-04, 1.6986e-01]]])
agent 0 action: VehicleControl(throttle=0.443582, steer=0.000490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.83132266303002
25.125604428350925 seconds in game passed.
Action: tensor([[[1.4399e-03, 6.1759e-01],
         [2.9444e-04, 3.2878e-01],
         [2.7066e-04, 2.2379e-01],
         [1.1215e-04, 1.6986e-01]]])
agent 0 action: VehicleControl(throttle=0.443186, steer=0.000473, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.83132266303002
+++++++++++++: 3.1197284187640646
25.150604428723454 seconds in game passed.
At 25.150604428723454 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6105],
         [-0.0025,  0.3247],
         [-0.0030,  0.2212],
         [-0.0035,  0.1675]]])
agent 0 action: VehicleControl(throttle=0.520789, steer=-0.002658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1197284187640646
Current reward: 0.6763602186829738
Current mitigation activation: 0
#############################
Total reward: 80.507682881713
25.175604429095984 seconds in game passed.
Action: tensor([[[-0.0012,  0.6105],
         [-0.0025,  0.3247],
         [-0.0030,  0.2212],
         [-0.0035,  0.1675]]])
agent 0 action: VehicleControl(throttle=0.512443, steer=-0.002170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.507682881713
25.200604429468513 seconds in game passed.
Action: tensor([[[-0.0012,  0.6105],
         [-0.0025,  0.3247],
         [-0.0030,  0.2212],
         [-0.0035,  0.1675]]])
agent 0 action: VehicleControl(throttle=0.512155, steer=-0.002200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.507682881713
25.22560442984104 seconds in game passed.
Action: tensor([[[-0.0012,  0.6105],
         [-0.0025,  0.3247],
         [-0.0030,  0.2212],
         [-0.0035,  0.1675]]])
agent 0 action: VehicleControl(throttle=0.511148, steer=-0.002230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.507682881713
+++++++++++++: 3.1511144959882627
25.25060443021357 seconds in game passed.
At 25.25060443021357 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6129],
         [-0.0075,  0.3261],
         [-0.0082,  0.2221],
         [-0.0086,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.482094, steer=-0.006743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1511144959882627
Current reward: 0.6803554856698144
Current mitigation activation: 0
#############################
Total reward: 81.18803836738282
25.2756044305861 seconds in game passed.
Action: tensor([[[-0.0033,  0.6129],
         [-0.0075,  0.3261],
         [-0.0082,  0.2221],
         [-0.0086,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.482826, steer=-0.006058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.18803836738282
25.30060443095863 seconds in game passed.
Action: tensor([[[-0.0033,  0.6129],
         [-0.0075,  0.3261],
         [-0.0082,  0.2221],
         [-0.0086,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.480434, steer=-0.006116, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.18803836738282
25.325604431331158 seconds in game passed.
Action: tensor([[[-0.0033,  0.6129],
         [-0.0075,  0.3261],
         [-0.0082,  0.2221],
         [-0.0086,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.477984, steer=-0.006173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.18803836738282
+++++++++++++: 3.178771031754507
25.350604431703687 seconds in game passed.
At 25.350604431703687 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.6079],
         [-0.0056,  0.3259],
         [-0.0058,  0.2225],
         [-0.0058,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.427399, steer=-0.004874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.178771031754507
Current reward: 0.6844138399486985
Current mitigation activation: 0
#############################
Total reward: 81.87245220733152
25.375604432076216 seconds in game passed.
Action: tensor([[[-0.0035,  0.6079],
         [-0.0056,  0.3259],
         [-0.0058,  0.2225],
         [-0.0058,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.429146, steer=-0.005124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.87245220733152
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:00:59 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:01:46 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 46.99s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.88s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.508               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 81.87, average_reward: 81.87245220733152 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00002/fi_lead_slowdown_data
