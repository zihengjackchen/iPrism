New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190526-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190526-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190526-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190526-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190526-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190526-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 37.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 37}
1.5124585144221783 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5374585147947073 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5624585151672363 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5874585155397654 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6124585159122944 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6374585162848234 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.6624585166573524 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003740, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6874585170298815 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7124585174024105 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7374585177749395 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7624585181474686 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7874585185199976 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8124585188925266 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8374585192650557 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8624585196375847 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8874585200101137 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9124585203826427 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9374585207551718 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9624585211277008 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9874585215002298 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.012458521872759 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.037458522245288 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4606e-03, 5.9042e-01],
         [1.3564e-03, 3.2228e-01],
         [1.1262e-03, 2.2209e-01],
         [5.7985e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.062458522617817 seconds in game passed.
Action: tensor([[[2.4606e-03, 5.9042e-01],
         [1.3564e-03, 3.2228e-01],
         [1.1262e-03, 2.2209e-01],
         [5.7985e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.087458522990346 seconds in game passed.
Action: tensor([[[2.4606e-03, 5.9042e-01],
         [1.3564e-03, 3.2228e-01],
         [1.1262e-03, 2.2209e-01],
         [5.7985e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.112458523362875 seconds in game passed.
Action: tensor([[[2.4606e-03, 5.9042e-01],
         [1.3564e-03, 3.2228e-01],
         [1.1262e-03, 2.2209e-01],
         [5.7985e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.137458523735404 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.162458524107933 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.187458524480462 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.212458524852991 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.23745852522552 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.262458525598049 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.287458525970578 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002505, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3124585263431072 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.3374585267156363 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.3624585270881653 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3874585274606943 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002721, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4124585278332233 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.4374585282057524 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4624585285782814 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4874585289508104 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5124585293233395 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5374585296958685 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5624585300683975 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002652, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5874585304409266 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6124585308134556 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6374585311859846 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6624585315585136 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6874585319310427 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002618, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7124585323035717 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002595, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7374585326761007 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.7624585330486298 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.787458533421159 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.812458533793688 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.837458534166217 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.862458534538746 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.887458534911275 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.912458535283804 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.937458535656333 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.962458536028862 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.987458536401391 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.01245853677392 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.037458537146449 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.062458537518978 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.087458537891507 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.112458538264036 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.137458538636565 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.1624585390090942 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1874585393816233 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2124585397541523 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.2374585401266813 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.2624585404992104 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2874585408717394 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3124585412442684 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3374585416167974 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3624585419893265 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3874585423618555 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4124585427343845 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0014, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4374585431069136 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4624585434794426 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4874585438519716 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5124585442245007 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5374585445970297 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5624585449695587 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5874585453420877 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6124585457146168 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.637458546087146 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.662458546459675 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.687458546832204 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002390, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.712458547204733 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002389, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.737458547577262 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.762458547949791 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.78745854832232 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.812458548694849 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.837458549067378 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.862458549439907 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.887458549812436 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.912458550184965 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.937458550557494 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.962458550930023 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9874585513025522 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.012458551675081 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.03745855204761 seconds in game passed.
At 4.03745855204761 seconds, saving state-action tuples.
Action: tensor([[[1.4048e-03, 5.8613e-01],
         [1.1300e-03, 3.2070e-01],
         [9.9434e-04, 2.2101e-01],
         [3.4169e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.062458552420139 seconds in game passed.
Action: tensor([[[1.4048e-03, 5.8613e-01],
         [1.1300e-03, 3.2070e-01],
         [9.9434e-04, 2.2101e-01],
         [3.4169e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.087458552792668 seconds in game passed.
Action: tensor([[[1.4048e-03, 5.8613e-01],
         [1.1300e-03, 3.2070e-01],
         [9.9434e-04, 2.2101e-01],
         [3.4169e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.112458553165197 seconds in game passed.
Action: tensor([[[1.4048e-03, 5.8613e-01],
         [1.1300e-03, 3.2070e-01],
         [9.9434e-04, 2.2101e-01],
         [3.4169e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.88373051633521
4.137458553537726 seconds in game passed.
At 4.137458553537726 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760848520400644
Current mitigation activation: 0
#############################
Total reward: 0.6561255113146287
4.162458553910255 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
4.1874585542827845 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 0.6561255113146287
4.2124585546553135 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
+++++++++++++: 8.843383940473686
4.2374585550278425 seconds in game passed.
At 4.2374585550278425 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383940473686
Current reward: 0.49259321983288007
Current mitigation activation: 0
#############################
Total reward: 1.1487187311475089
4.2624585554003716 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.287458555772901 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.31245855614543 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002946, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
+++++++++++++: 7.228541449858101
4.337458556517959 seconds in game passed.
At 4.337458556517959 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5863],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228541449858101
Current reward: 0.5118171168217831
Current mitigation activation: 0
#############################
Total reward: 1.660535847969292
4.362458556890488 seconds in game passed.
Action: tensor([[[0.0028, 0.5863],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
4.387458557263017 seconds in game passed.
Action: tensor([[[0.0028, 0.5863],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
4.412458557635546 seconds in game passed.
Action: tensor([[[0.0028, 0.5863],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
+++++++++++++: 6.2159354823880735
4.437458558008075 seconds in game passed.
At 4.437458558008075 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.2159354823880735
Current reward: 0.5264941485050963
Current mitigation activation: 0
#############################
Total reward: 2.1870299964743882
4.462458558380604 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299964743882
4.487458558753133 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299964743882
4.512458559125662 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299964743882
+++++++++++++: 5.508365853638963
4.537458559498191 seconds in game passed.
At 4.537458559498191 seconds, saving state-action tuples.
Action: tensor([[[-9.5583e-05,  5.8866e-01],
         [ 1.5390e-04,  3.2201e-01],
         [ 2.7554e-04,  2.2121e-01],
         [-9.6522e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508365853638963
Current reward: 0.537623498978236
Current mitigation activation: 0
#############################
Total reward: 2.7246534954526243
4.56245855987072 seconds in game passed.
Action: tensor([[[-9.5583e-05,  5.8866e-01],
         [ 1.5390e-04,  3.2201e-01],
         [ 2.7554e-04,  2.2121e-01],
         [-9.6522e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000888, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.7246534954526243
4.587458560243249 seconds in game passed.
Action: tensor([[[-9.5583e-05,  5.8866e-01],
         [ 1.5390e-04,  3.2201e-01],
         [ 2.7554e-04,  2.2121e-01],
         [-9.6522e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.7246534954526243
4.612458560615778 seconds in game passed.
Action: tensor([[[-9.5583e-05,  5.8866e-01],
         [ 1.5390e-04,  3.2201e-01],
         [ 2.7554e-04,  2.2121e-01],
         [-9.6522e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.7246534954526243
+++++++++++++: 4.9761342678197185
4.637458560988307 seconds in game passed.
At 4.637458560988307 seconds, saving state-action tuples.
Action: tensor([[[ 2.1085e-04,  5.8918e-01],
         [-3.9367e-04,  3.2135e-01],
         [-3.1104e-04,  2.2101e-01],
         [-4.7505e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.9761342678197185
Current reward: 0.5459292659195056
Current mitigation activation: 0
#############################
Total reward: 3.27058276137213
4.662458561360836 seconds in game passed.
Action: tensor([[[ 2.1085e-04,  5.8918e-01],
         [-3.9367e-04,  3.2135e-01],
         [-3.1104e-04,  2.2101e-01],
         [-4.7505e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.27058276137213
4.687458561733365 seconds in game passed.
Action: tensor([[[ 2.1085e-04,  5.8918e-01],
         [-3.9367e-04,  3.2135e-01],
         [-3.1104e-04,  2.2101e-01],
         [-4.7505e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.27058276137213
4.712458562105894 seconds in game passed.
Action: tensor([[[ 2.1085e-04,  5.8918e-01],
         [-3.9367e-04,  3.2135e-01],
         [-3.1104e-04,  2.2101e-01],
         [-4.7505e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.27058276137213
+++++++++++++: 4.552585584603673
4.737458562478423 seconds in game passed.
At 4.737458562478423 seconds, saving state-action tuples.
Action: tensor([[[-3.0444e-04,  5.9097e-01],
         [-9.8665e-04,  3.2154e-01],
         [-8.6290e-04,  2.2106e-01],
         [-1.0009e-03,  1.6743e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552585584603673
Current reward: 0.5519989036455549
Current mitigation activation: 0
#############################
Total reward: 3.822581665017685
4.762458562850952 seconds in game passed.
Action: tensor([[[-3.0444e-04,  5.9097e-01],
         [-9.8665e-04,  3.2154e-01],
         [-8.6290e-04,  2.2106e-01],
         [-1.0009e-03,  1.6743e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.822581665017685
4.787458563223481 seconds in game passed.
Action: tensor([[[-3.0444e-04,  5.9097e-01],
         [-9.8665e-04,  3.2154e-01],
         [-8.6290e-04,  2.2106e-01],
         [-1.0009e-03,  1.6743e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.822581665017685
4.81245856359601 seconds in game passed.
Action: tensor([[[-3.0444e-04,  5.9097e-01],
         [-9.8665e-04,  3.2154e-01],
         [-8.6290e-04,  2.2106e-01],
         [-1.0009e-03,  1.6743e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000111, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.822581665017685
+++++++++++++: 4.199609653749305
4.837458563968539 seconds in game passed.
At 4.837458563968539 seconds, saving state-action tuples.
Action: tensor([[[ 5.0516e-04,  5.8997e-01],
         [-5.4154e-04,  3.2157e-01],
         [-4.0066e-04,  2.2124e-01],
         [-4.1717e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199609653749305
Current reward: 0.5563326550427872
Current mitigation activation: 0
#############################
Total reward: 4.378914320060472
4.862458564341068 seconds in game passed.
Action: tensor([[[ 5.0516e-04,  5.8997e-01],
         [-5.4154e-04,  3.2157e-01],
         [-4.0066e-04,  2.2124e-01],
         [-4.1717e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914320060472
4.887458564713597 seconds in game passed.
Action: tensor([[[ 5.0516e-04,  5.8997e-01],
         [-5.4154e-04,  3.2157e-01],
         [-4.0066e-04,  2.2124e-01],
         [-4.1717e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914320060472
4.912458565086126 seconds in game passed.
Action: tensor([[[ 5.0516e-04,  5.8997e-01],
         [-5.4154e-04,  3.2157e-01],
         [-4.0066e-04,  2.2124e-01],
         [-4.1717e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914320060472
+++++++++++++: 3.89475956116383
4.937458565458655 seconds in game passed.
At 4.937458565458655 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5878],
         [0.0007, 0.3214],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.89475956116383
Current reward: 0.5593082003948288
Current mitigation activation: 0
#############################
Total reward: 4.938222520455301
4.962458565831184 seconds in game passed.
Action: tensor([[[0.0016, 0.5878],
         [0.0007, 0.3214],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222520455301
4.987458566203713 seconds in game passed.
Action: tensor([[[0.0016, 0.5878],
         [0.0007, 0.3214],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222520455301
5.0124585665762424 seconds in game passed.
Action: tensor([[[0.0016, 0.5878],
         [0.0007, 0.3214],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222520455301
+++++++++++++: 3.6246731449700413
5.0374585669487715 seconds in game passed.
At 5.0374585669487715 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2841e-03, 5.8979e-01],
         [1.0572e-03, 3.2206e-01],
         [9.2343e-04, 2.2278e-01],
         [5.6685e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6246731449700413
Current reward: 0.561177100124197
Current mitigation activation: 0
#############################
Total reward: 5.4993996205794975
5.0624585673213005 seconds in game passed.
Action: tensor([[[1.2841e-03, 5.8979e-01],
         [1.0572e-03, 3.2206e-01],
         [9.2343e-04, 2.2278e-01],
         [5.6685e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993996205794975
5.0874585676938295 seconds in game passed.
Action: tensor([[[1.2841e-03, 5.8979e-01],
         [1.0572e-03, 3.2206e-01],
         [9.2343e-04, 2.2278e-01],
         [5.6685e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993996205794975
5.112458568066359 seconds in game passed.
Action: tensor([[[1.2841e-03, 5.8979e-01],
         [1.0572e-03, 3.2206e-01],
         [9.2343e-04, 2.2278e-01],
         [5.6685e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993996205794975
+++++++++++++: 3.380481635661648
5.137458568438888 seconds in game passed.
At 5.137458568438888 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380481635661648
Current reward: 0.5621374409795563
Current mitigation activation: 0
#############################
Total reward: 6.061537061559054
5.162458568811417 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537061559054
5.187458569183946 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537061559054
5.212458569556475 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537061559054
+++++++++++++: 3.1565690354276614
5.237458569929004 seconds in game passed.
At 5.237458569929004 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1565690354276614
Current reward: 0.5623125805421682
Current mitigation activation: 0
#############################
Total reward: 6.623849642101223
5.262458570301533 seconds in game passed.
Action: tensor([[[0.0026, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849642101223
5.287458570674062 seconds in game passed.
Action: tensor([[[0.0026, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849642101223
5.312458571046591 seconds in game passed.
Action: tensor([[[0.0026, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849642101223
+++++++++++++: 2.948947878048687
5.33745857141912 seconds in game passed.
At 5.33745857141912 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.948947878048687
Current reward: 0.5617967569567601
Current mitigation activation: 0
#############################
Total reward: 7.185646399057983
5.362458571791649 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646399057983
5.387458572164178 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646399057983
5.412458572536707 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002916, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646399057983
+++++++++++++: 2.7880636939703614
5.437458572909236 seconds in game passed.
At 5.437458572909236 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.8508e-04,  5.8798e-01],
         [ 1.3338e-04,  3.2087e-01],
         [-1.7643e-05,  2.2103e-01],
         [-3.2684e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7880636939703614
Current reward: 0.5575288765619892
Current mitigation activation: 0
#############################
Total reward: 7.743175275619972
5.462458573281765 seconds in game passed.
Action: tensor([[[ 8.8508e-04,  5.8798e-01],
         [ 1.3338e-04,  3.2087e-01],
         [-1.7643e-05,  2.2103e-01],
         [-3.2684e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175275619972
5.487458573654294 seconds in game passed.
Action: tensor([[[ 8.8508e-04,  5.8798e-01],
         [ 1.3338e-04,  3.2087e-01],
         [-1.7643e-05,  2.2103e-01],
         [-3.2684e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175275619972
5.512458574026823 seconds in game passed.
Action: tensor([[[ 8.8508e-04,  5.8798e-01],
         [ 1.3338e-04,  3.2087e-01],
         [-1.7643e-05,  2.2103e-01],
         [-3.2684e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000766, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175275619972
+++++++++++++: 2.6913210746399905
5.537458574399352 seconds in game passed.
At 5.537458574399352 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6913210746399905
Current reward: 0.5472018565255001
Current mitigation activation: 0
#############################
Total reward: 8.290377132145473
5.562458574771881 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377132145473
5.58745857514441 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377132145473
5.612458575516939 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377132145473
+++++++++++++: 2.5950228899318244
5.637458575889468 seconds in game passed.
At 5.637458575889468 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.5915],
         [-0.0038,  0.3221],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5950228899318244
Current reward: 0.5368278198229042
Current mitigation activation: 0
#############################
Total reward: 8.827204951968376
5.662458576261997 seconds in game passed.
Action: tensor([[[-0.0022,  0.5915],
         [-0.0038,  0.3221],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204951968376
5.687458576634526 seconds in game passed.
Action: tensor([[[-0.0022,  0.5915],
         [-0.0038,  0.3221],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204951968376
5.712458577007055 seconds in game passed.
Action: tensor([[[-0.0022,  0.5915],
         [-0.0038,  0.3221],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002883, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204951968376
+++++++++++++: 2.4986311585026875
5.737458577379584 seconds in game passed.
At 5.737458577379584 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4986311585026875
Current reward: 0.5264623301165912
Current mitigation activation: 0
#############################
Total reward: 9.353667282084967
5.762458577752113 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667282084967
5.787458578124642 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667282084967
5.812458578497171 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667282084967
+++++++++++++: 2.402194123407245
5.8374585788697 seconds in game passed.
At 5.8374585788697 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5703e-04,  5.9078e-01],
         [-7.3373e-04,  3.2180e-01],
         [-7.6127e-04,  2.2148e-01],
         [-9.7106e-04,  1.6817e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.402194123407245
Current reward: 0.5161007027607518
Current mitigation activation: 0
#############################
Total reward: 9.86976798484572
5.8624585792422295 seconds in game passed.
Action: tensor([[[-1.5703e-04,  5.9078e-01],
         [-7.3373e-04,  3.2180e-01],
         [-7.6127e-04,  2.2148e-01],
         [-9.7106e-04,  1.6817e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.86976798484572
5.8874585796147585 seconds in game passed.
Action: tensor([[[-1.5703e-04,  5.9078e-01],
         [-7.3373e-04,  3.2180e-01],
         [-7.6127e-04,  2.2148e-01],
         [-9.7106e-04,  1.6817e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.86976798484572
5.9124585799872875 seconds in game passed.
Action: tensor([[[-1.5703e-04,  5.9078e-01],
         [-7.3373e-04,  3.2180e-01],
         [-7.6127e-04,  2.2148e-01],
         [-9.7106e-04,  1.6817e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.86976798484572
+++++++++++++: 2.273732438467082
5.9374585803598166 seconds in game passed.
At 5.9374585803598166 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.9766e-05,  5.9321e-01],
         [ 2.3416e-04,  3.2269e-01],
         [ 2.6772e-04,  2.2199e-01],
         [-1.2748e-04,  1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.273732438467082
Current reward: 0.5093356726632455
Current mitigation activation: 0
#############################
Total reward: 10.379103657508965
5.962458580732346 seconds in game passed.
Action: tensor([[[ 1.9766e-05,  5.9321e-01],
         [ 2.3416e-04,  3.2269e-01],
         [ 2.6772e-04,  2.2199e-01],
         [-1.2748e-04,  1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103657508965
5.987458581104875 seconds in game passed.
Action: tensor([[[ 1.9766e-05,  5.9321e-01],
         [ 2.3416e-04,  3.2269e-01],
         [ 2.6772e-04,  2.2199e-01],
         [-1.2748e-04,  1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103657508965
6.012458581477404 seconds in game passed.
Action: tensor([[[ 1.9766e-05,  5.9321e-01],
         [ 2.3416e-04,  3.2269e-01],
         [ 2.6772e-04,  2.2199e-01],
         [-1.2748e-04,  1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000111, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103657508965
+++++++++++++: 2.0694019964787183
6.037458581849933 seconds in game passed.
At 6.037458581849933 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5974],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0694019964787183
Current reward: 0.5122396514902974
Current mitigation activation: 0
#############################
Total reward: 10.891343308999263
6.062458582222462 seconds in game passed.
Action: tensor([[[0.0031, 0.5974],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.871755, steer=0.003259, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343308999263
6.087458582594991 seconds in game passed.
Action: tensor([[[0.0031, 0.5974],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.818912, steer=0.003286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343308999263
6.11245858296752 seconds in game passed.
Action: tensor([[[0.0031, 0.5974],
         [0.0037, 0.3260],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.767247, steer=0.003313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343308999263
+++++++++++++: 1.8865370881791312
6.137458583340049 seconds in game passed.
At 6.137458583340049 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.465270, steer=0.002025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865370881791312
Current reward: 0.5134807762285818
Current mitigation activation: 0
#############################
Total reward: 11.404824085227844
6.162458583712578 seconds in game passed.
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.440152, steer=0.002244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824085227844
6.187458584085107 seconds in game passed.
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.390704, steer=0.002248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824085227844
6.212458584457636 seconds in game passed.
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.363208, steer=0.002251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824085227844
+++++++++++++: 1.7243265235501732
6.237458584830165 seconds in game passed.
At 6.237458584830165 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.7259e-04,  6.3454e-01],
         [ 3.5256e-05,  3.4367e-01],
         [-6.6649e-04,  2.3583e-01],
         [-1.7716e-03,  1.8018e-01]]])
agent 0 action: VehicleControl(throttle=0.352147, steer=-0.000119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7243265235501732
Current reward: 0.5125319848221034
Current mitigation activation: 0
#############################
Total reward: 11.917356070049948
6.262458585202694 seconds in game passed.
Action: tensor([[[ 5.7259e-04,  6.3454e-01],
         [ 3.5256e-05,  3.4367e-01],
         [-6.6649e-04,  2.3583e-01],
         [-1.7716e-03,  1.8018e-01]]])
agent 0 action: VehicleControl(throttle=0.339532, steer=0.000249, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917356070049948
6.287458585575223 seconds in game passed.
Action: tensor([[[ 5.7259e-04,  6.3454e-01],
         [ 3.5256e-05,  3.4367e-01],
         [-6.6649e-04,  2.3583e-01],
         [-1.7716e-03,  1.8018e-01]]])
agent 0 action: VehicleControl(throttle=0.327336, steer=0.000226, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917356070049948
6.312458585947752 seconds in game passed.
Action: tensor([[[ 5.7259e-04,  6.3454e-01],
         [ 3.5256e-05,  3.4367e-01],
         [-6.6649e-04,  2.3583e-01],
         [-1.7716e-03,  1.8018e-01]]])
agent 0 action: VehicleControl(throttle=0.315553, steer=0.000202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917356070049948
+++++++++++++: 1.588992061159879
6.337458586320281 seconds in game passed.
At 6.337458586320281 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3493e-03,  6.5381e-01],
         [-6.1244e-04,  3.5218e-01],
         [-1.7502e-03,  2.4164e-01],
         [-2.9641e-03,  1.8443e-01]]])
agent 0 action: VehicleControl(throttle=0.304539, steer=0.000004, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.588992061159879
Current reward: 0.5075296025039664
Current mitigation activation: 0
#############################
Total reward: 12.424885672553915
6.36245858669281 seconds in game passed.
Action: tensor([[[ 1.3493e-03,  6.5381e-01],
         [-6.1244e-04,  3.5218e-01],
         [-1.7502e-03,  2.4164e-01],
         [-2.9641e-03,  1.8443e-01]]])
agent 0 action: VehicleControl(throttle=0.293934, steer=0.000002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424885672553915
6.387458587065339 seconds in game passed.
Action: tensor([[[ 1.3493e-03,  6.5381e-01],
         [-6.1244e-04,  3.5218e-01],
         [-1.7502e-03,  2.4164e-01],
         [-2.9641e-03,  1.8443e-01]]])
agent 0 action: VehicleControl(throttle=0.283282, steer=-0.000027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424885672553915
6.412458587437868 seconds in game passed.
Action: tensor([[[ 1.3493e-03,  6.5381e-01],
         [-6.1244e-04,  3.5218e-01],
         [-1.7502e-03,  2.4164e-01],
         [-2.9641e-03,  1.8443e-01]]])
agent 0 action: VehicleControl(throttle=0.272605, steer=-0.000057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424885672553915
+++++++++++++: 1.477890995651544
6.437458587810397 seconds in game passed.
At 6.437458587810397 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6674],
         [-0.0048,  0.3561],
         [-0.0062,  0.2425],
         [-0.0071,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.261847, steer=-0.004342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.477890995651544
Current reward: 0.4981002501425966
Current mitigation activation: 0
#############################
Total reward: 12.922985922696512
6.462458588182926 seconds in game passed.
Action: tensor([[[-0.0015,  0.6674],
         [-0.0048,  0.3561],
         [-0.0062,  0.2425],
         [-0.0071,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.251069, steer=-0.003683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.922985922696512
6.487458588555455 seconds in game passed.
Action: tensor([[[-0.0015,  0.6674],
         [-0.0048,  0.3561],
         [-0.0062,  0.2425],
         [-0.0071,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.240273, steer=-0.003731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.922985922696512
6.512458588927984 seconds in game passed.
Action: tensor([[[-0.0015,  0.6674],
         [-0.0048,  0.3561],
         [-0.0062,  0.2425],
         [-0.0071,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.229458, steer=-0.003779, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.922985922696512
+++++++++++++: 1.3817794044191845
6.537458589300513 seconds in game passed.
At 6.537458589300513 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.1377e-04,  6.8456e-01],
         [-4.0347e-03,  3.6653e-01],
         [-5.8223e-03,  2.5085e-01],
         [-7.1526e-03,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.218685, steer=-0.002747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3817794044191845
Current reward: 0.4855731618625416
Current mitigation activation: 0
#############################
Total reward: 13.408559084559053
6.562458589673042 seconds in game passed.
Action: tensor([[[-3.1377e-04,  6.8456e-01],
         [-4.0347e-03,  3.6653e-01],
         [-5.8223e-03,  2.5085e-01],
         [-7.1526e-03,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.207892, steer=-0.002933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408559084559053
6.587458590045571 seconds in game passed.
Action: tensor([[[-3.1377e-04,  6.8456e-01],
         [-4.0347e-03,  3.6653e-01],
         [-5.8223e-03,  2.5085e-01],
         [-7.1526e-03,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.197082, steer=-0.002945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408559084559053
6.6124585904181 seconds in game passed.
Action: tensor([[[-3.1377e-04,  6.8456e-01],
         [-4.0347e-03,  3.6653e-01],
         [-5.8223e-03,  2.5085e-01],
         [-7.1526e-03,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.186253, steer=-0.002958, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408559084559053
+++++++++++++: 1.294456623867185
6.637458590790629 seconds in game passed.
At 6.637458590790629 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.4344e-04,  1.0000e+00],
         [-4.7308e-03,  1.0000e+00],
         [-5.9383e-03,  1.0000e+00],
         [-6.4876e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003041, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.294456623867185
Current reward: 0.47105443631609784
Current mitigation activation: 1
#############################
Total reward: 13.879613520875152
6.662458591163158 seconds in game passed.
Action: tensor([[[-3.4344e-04,  1.0000e+00],
         [-4.7308e-03,  1.0000e+00],
         [-5.9383e-03,  1.0000e+00],
         [-6.4876e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003021, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879613520875152
6.6874585915356874 seconds in game passed.
Action: tensor([[[-3.4344e-04,  1.0000e+00],
         [-4.7308e-03,  1.0000e+00],
         [-5.9383e-03,  1.0000e+00],
         [-6.4876e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003017, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879613520875152
6.7124585919082165 seconds in game passed.
Action: tensor([[[-3.4344e-04,  1.0000e+00],
         [-4.7308e-03,  1.0000e+00],
         [-5.9383e-03,  1.0000e+00],
         [-6.4876e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003012, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879613520875152
+++++++++++++: 1.2148228961423335
6.7374585922807455 seconds in game passed.
At 6.7374585922807455 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000816, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2148228961423335
Current reward: 0.4546877483491408
Current mitigation activation: 1
#############################
Total reward: 14.334301269224293
6.7624585926532745 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001142, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334301269224293
6.787458593025804 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001108, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334301269224293
6.812458593398333 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0053,  1.0000],
         [-0.0058,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001074, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334301269224293
+++++++++++++: 1.1620570686145348
6.837458593770862 seconds in game passed.
At 6.837458593770862 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.7343e-03,  1.0000e+00],
         [ 9.5351e-04,  1.0000e+00],
         [-1.3386e-03,  1.0000e+00],
         [-1.3919e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006133, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1620570686145348
Current reward: 0.4318868765720502
Current mitigation activation: 1
#############################
Total reward: 14.766188145796344
6.862458594143391 seconds in game passed.
Action: tensor([[[ 8.7343e-03,  1.0000e+00],
         [ 9.5351e-04,  1.0000e+00],
         [-1.3386e-03,  1.0000e+00],
         [-1.3919e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005013, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766188145796344
6.88745859451592 seconds in game passed.
Action: tensor([[[ 8.7343e-03,  1.0000e+00],
         [ 9.5351e-04,  1.0000e+00],
         [-1.3386e-03,  1.0000e+00],
         [-1.3919e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005083, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766188145796344
6.912458594888449 seconds in game passed.
Action: tensor([[[ 8.7343e-03,  1.0000e+00],
         [ 9.5351e-04,  1.0000e+00],
         [-1.3386e-03,  1.0000e+00],
         [-1.3919e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005152, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766188145796344
+++++++++++++: 1.1435337637547938
6.937458595260978 seconds in game passed.
At 6.937458595260978 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0133,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012082, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1435337637547938
Current reward: 0.4017031952580754
Current mitigation activation: 1
#############################
Total reward: 15.16789134105442
6.962458595633507 seconds in game passed.
Action: tensor([[[-0.0133,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009345, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.16789134105442
6.987458596006036 seconds in game passed.
Action: tensor([[[-0.0133,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009462, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.16789134105442
7.012458596378565 seconds in game passed.
Action: tensor([[[-0.0133,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009578, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.16789134105442
+++++++++++++: 1.1455672096838225
7.037458596751094 seconds in game passed.
At 7.037458596751094 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0125,  1.0000],
         [-0.0070,  1.0000],
         [-0.0084,  1.0000],
         [-0.0079,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011004, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1455672096838225
Current reward: 0.36898527963851135
Current mitigation activation: 1
#############################
Total reward: 15.536876620692931
7.062458597123623 seconds in game passed.
Action: tensor([[[-0.0125,  1.0000],
         [-0.0070,  1.0000],
         [-0.0084,  1.0000],
         [-0.0079,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010963, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.536876620692931
7.087458597496152 seconds in game passed.
Action: tensor([[[-0.0125,  1.0000],
         [-0.0070,  1.0000],
         [-0.0084,  1.0000],
         [-0.0079,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011131, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.536876620692931
7.112458597868681 seconds in game passed.
Action: tensor([[[-0.0125,  1.0000],
         [-0.0070,  1.0000],
         [-0.0084,  1.0000],
         [-0.0079,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011300, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.536876620692931
+++++++++++++: 1.1653091400974251
7.13745859824121 seconds in game passed.
At 7.13745859824121 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0156,  1.0000],
         [-0.0113,  1.0000],
         [-0.0090,  1.0000],
         [-0.0053,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016181, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1653091400974251
Current reward: 0.3357271970880975
Current mitigation activation: 1
#############################
Total reward: 15.872603817781028
7.162458598613739 seconds in game passed.
Action: tensor([[[-0.0156,  1.0000],
         [-0.0113,  1.0000],
         [-0.0090,  1.0000],
         [-0.0053,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015605, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872603817781028
7.187458598986268 seconds in game passed.
Action: tensor([[[-0.0156,  1.0000],
         [-0.0113,  1.0000],
         [-0.0090,  1.0000],
         [-0.0053,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015808, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872603817781028
7.212458599358797 seconds in game passed.
Action: tensor([[[-0.0156,  1.0000],
         [-0.0113,  1.0000],
         [-0.0090,  1.0000],
         [-0.0053,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016012, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872603817781028
+++++++++++++: 1.2052897019858158
7.237458599731326 seconds in game passed.
At 7.237458599731326 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0124,  1.0000],
         [-0.0159,  1.0000],
         [-0.0205,  1.0000],
         [-0.0215,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017053, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2052897019858158
Current reward: 0.3027439339576992
Current mitigation activation: 1
#############################
Total reward: 16.175347751738727
7.262458600103855 seconds in game passed.
Action: tensor([[[-0.0124,  1.0000],
         [-0.0159,  1.0000],
         [-0.0205,  1.0000],
         [-0.0215,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017099, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175347751738727
7.287458600476384 seconds in game passed.
Action: tensor([[[-0.0124,  1.0000],
         [-0.0159,  1.0000],
         [-0.0205,  1.0000],
         [-0.0215,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017287, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175347751738727
7.312458600848913 seconds in game passed.
Action: tensor([[[-0.0124,  1.0000],
         [-0.0159,  1.0000],
         [-0.0205,  1.0000],
         [-0.0215,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017475, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175347751738727
+++++++++++++: 1.2710628739824101
7.337458601221442 seconds in game passed.
At 7.337458601221442 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0104,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021978, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2710628739824101
Current reward: 0.2705166988464703
Current mitigation activation: 1
#############################
Total reward: 16.445864450585198
7.362458601593971 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0104,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015662, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.445864450585198
7.3874586019665 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0104,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015885, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.445864450585198
7.412458602339029 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0104,  1.0000],
         [-0.0095,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016107, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.445864450585198
+++++++++++++: 1.3698462279224324
7.437458602711558 seconds in game passed.
At 7.437458602711558 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.7856e-03, 9.5603e-01],
         [1.1555e-03, 9.5437e-01],
         [3.8870e-04, 9.5377e-01],
         [7.3190e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003424, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3698462279224324
Current reward: 0.23965576511748868
Current mitigation activation: 0
#############################
Total reward: 16.685520215702688
7.462458603084087 seconds in game passed.
Action: tensor([[[1.7856e-03, 9.5603e-01],
         [1.1555e-03, 9.5437e-01],
         [3.8870e-04, 9.5377e-01],
         [7.3190e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000096, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685520215702688
7.487458603456616 seconds in game passed.
Action: tensor([[[1.7856e-03, 9.5603e-01],
         [1.1555e-03, 9.5437e-01],
         [3.8870e-04, 9.5377e-01],
         [7.3190e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000034, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685520215702688
7.512458603829145 seconds in game passed.
Action: tensor([[[1.7856e-03, 9.5603e-01],
         [1.1555e-03, 9.5437e-01],
         [3.8870e-04, 9.5377e-01],
         [7.3190e-04, 9.5339e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000029, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685520215702688
+++++++++++++: 1.5130801554964959
7.5374586042016745 seconds in game passed.
At 7.5374586042016745 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.0511e-04, 9.5595e-01],
         [1.0816e-03, 9.5433e-01],
         [9.9685e-04, 9.5376e-01],
         [1.4674e-03, 9.5342e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000647, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5130801554964959
Current reward: 0.2105602624047501
Current mitigation activation: 0
#############################
Total reward: 16.89608047810744
7.5624586045742035 seconds in game passed.
Action: tensor([[[7.0511e-04, 9.5595e-01],
         [1.0816e-03, 9.5433e-01],
         [9.9685e-04, 9.5376e-01],
         [1.4674e-03, 9.5342e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000483, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89608047810744
7.5874586049467325 seconds in game passed.
Action: tensor([[[7.0511e-04, 9.5595e-01],
         [1.0816e-03, 9.5433e-01],
         [9.9685e-04, 9.5376e-01],
         [1.4674e-03, 9.5342e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000439, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89608047810744
7.6124586053192616 seconds in game passed.
Action: tensor([[[7.0511e-04, 9.5595e-01],
         [1.0816e-03, 9.5433e-01],
         [9.9685e-04, 9.5376e-01],
         [1.4674e-03, 9.5342e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000395, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89608047810744
+++++++++++++: 1.7424888155056562
7.637458605691791 seconds in game passed.
At 7.637458605691791 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.1220e-04, 9.5609e-01],
         [1.5209e-03, 9.5458e-01],
         [1.8218e-03, 9.5407e-01],
         [1.9224e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000006, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7424888155056562
Current reward: 0.18258136677793685
Current mitigation activation: 0
#############################
Total reward: 17.078661844885378
7.66245860606432 seconds in game passed.
Action: tensor([[[8.1220e-04, 9.5609e-01],
         [1.5209e-03, 9.5458e-01],
         [1.8218e-03, 9.5407e-01],
         [1.9224e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000014, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078661844885378
7.687458606436849 seconds in game passed.
Action: tensor([[[8.1220e-04, 9.5609e-01],
         [1.5209e-03, 9.5458e-01],
         [1.8218e-03, 9.5407e-01],
         [1.9224e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000034, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078661844885378
7.712458606809378 seconds in game passed.
Action: tensor([[[8.1220e-04, 9.5609e-01],
         [1.5209e-03, 9.5458e-01],
         [1.8218e-03, 9.5407e-01],
         [1.9224e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000083, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078661844885378
+++++++++++++: 2.1633757099319006
7.737458607181907 seconds in game passed.
At 7.737458607181907 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.9947e-04, 9.5622e-01],
         [1.5012e-03, 9.5477e-01],
         [1.7738e-03, 9.5430e-01],
         [1.8583e-03, 9.5404e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000025, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1633757099319006
Current reward: 0.15674036008640668
Current mitigation activation: 0
#############################
Total reward: 17.235402204971784
7.762458607554436 seconds in game passed.
Action: tensor([[[6.9947e-04, 9.5622e-01],
         [1.5012e-03, 9.5477e-01],
         [1.7738e-03, 9.5430e-01],
         [1.8583e-03, 9.5404e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000064, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235402204971784
7.787458607926965 seconds in game passed.
Action: tensor([[[6.9947e-04, 9.5622e-01],
         [1.5012e-03, 9.5477e-01],
         [1.7738e-03, 9.5430e-01],
         [1.8583e-03, 9.5404e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000089, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235402204971784
7.812458608299494 seconds in game passed.
Action: tensor([[[6.9947e-04, 9.5622e-01],
         [1.5012e-03, 9.5477e-01],
         [1.7738e-03, 9.5430e-01],
         [1.8583e-03, 9.5404e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000114, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235402204971784
+++++++++++++: 2.974764819256679
7.837458608672023 seconds in game passed.
At 7.837458608672023 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.4796e-04, 9.5620e-01],
         [1.5023e-03, 9.5474e-01],
         [1.7766e-03, 9.5427e-01],
         [1.8859e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000097, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.974764819256679
Current reward: 0.1326638633943712
Current mitigation activation: 0
#############################
Total reward: 17.368066068366154
7.862458609044552 seconds in game passed.
Action: tensor([[[7.4796e-04, 9.5620e-01],
         [1.5023e-03, 9.5474e-01],
         [1.7766e-03, 9.5427e-01],
         [1.8859e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000042, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.368066068366154
7.887458609417081 seconds in game passed.
Action: tensor([[[7.4796e-04, 9.5620e-01],
         [1.5023e-03, 9.5474e-01],
         [1.7766e-03, 9.5427e-01],
         [1.8859e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000007, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.368066068366154
7.91245860978961 seconds in game passed.
Action: tensor([[[7.4796e-04, 9.5620e-01],
         [1.5023e-03, 9.5474e-01],
         [1.7766e-03, 9.5427e-01],
         [1.8859e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000055, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.368066068366154
+++++++++++++: 4.796749230286383
7.937458610162139 seconds in game passed.
At 7.937458610162139 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.3558e-04, 9.5606e-01],
         [1.4941e-03, 9.5454e-01],
         [1.7724e-03, 9.5405e-01],
         [1.8975e-03, 9.5377e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000187, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.796749230286383
Current reward: 0.11047659137225542
Current mitigation activation: 0
#############################
Total reward: 17.47854265973841
7.962458610534668 seconds in game passed.
Action: tensor([[[9.3558e-04, 9.5606e-01],
         [1.4941e-03, 9.5454e-01],
         [1.7724e-03, 9.5405e-01],
         [1.8975e-03, 9.5377e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000299, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.47854265973841
7.987458610907197 seconds in game passed.
Action: tensor([[[9.3558e-04, 9.5606e-01],
         [1.4941e-03, 9.5454e-01],
         [1.7724e-03, 9.5405e-01],
         [1.8975e-03, 9.5377e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000429, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.47854265973841
8.012458611279726 seconds in game passed.
Action: tensor([[[9.3558e-04, 9.5606e-01],
         [1.4941e-03, 9.5454e-01],
         [1.7724e-03, 9.5405e-01],
         [1.8975e-03, 9.5377e-01]]])
agent 0 action: VehicleControl(throttle=0.004391, steer=0.000560, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.47854265973841
+++++++++++++: 23.68706829470585
8.037458611652255 seconds in game passed.
At 8.037458611652255 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.4210e-04, 9.5597e-01],
         [1.3515e-03, 9.5440e-01],
         [1.6286e-03, 9.5388e-01],
         [1.8027e-03, 9.5358e-01]]])
agent 0 action: VehicleControl(throttle=0.006661, steer=0.000618, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.039306338825315104
Current mitigation activation: 0
#############################
Total reward: 17.517848998563725
8.062458612024784 seconds in game passed.
Action: tensor([[[9.4210e-04, 9.5597e-01],
         [1.3515e-03, 9.5440e-01],
         [1.6286e-03, 9.5388e-01],
         [1.8027e-03, 9.5358e-01]]])
agent 0 action: VehicleControl(throttle=0.006666, steer=0.000775, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517848998563725
8.087458612397313 seconds in game passed.
Action: tensor([[[9.4210e-04, 9.5597e-01],
         [1.3515e-03, 9.5440e-01],
         [1.6286e-03, 9.5388e-01],
         [1.8027e-03, 9.5358e-01]]])
agent 0 action: VehicleControl(throttle=0.006832, steer=0.000917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517848998563725
8.112458612769842 seconds in game passed.
Action: tensor([[[9.4210e-04, 9.5597e-01],
         [1.3515e-03, 9.5440e-01],
         [1.6286e-03, 9.5388e-01],
         [1.8027e-03, 9.5358e-01]]])
agent 0 action: VehicleControl(throttle=0.006944, steer=0.001060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517848998563725
+++++++++++++: 2075.940196945568
8.137458613142371 seconds in game passed.
At 8.137458613142371 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.6698e-03,  9.5574e-01],
         [ 1.7432e-03,  9.5382e-01],
         [-1.7818e-03,  9.5307e-01],
         [-4.2002e-04,  9.5252e-01]]])
agent 0 action: VehicleControl(throttle=0.033850, steer=0.006996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00047044488075502467
Current mitigation activation: 0
#############################
Total reward: 17.51831944344448
8.1624586135149 seconds in game passed.
Action: tensor([[[ 9.6698e-03,  9.5574e-01],
         [ 1.7432e-03,  9.5382e-01],
         [-1.7818e-03,  9.5307e-01],
         [-4.2002e-04,  9.5252e-01]]])
agent 0 action: VehicleControl(throttle=0.008305, steer=0.006299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51831944344448
8.18745861388743 seconds in game passed.
Action: tensor([[[ 9.6698e-03,  9.5574e-01],
         [ 1.7432e-03,  9.5382e-01],
         [-1.7818e-03,  9.5307e-01],
         [-4.2002e-04,  9.5252e-01]]])
agent 0 action: VehicleControl(throttle=0.011531, steer=0.006550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51831944344448
8.212458614259958 seconds in game passed.
Action: tensor([[[ 9.6698e-03,  9.5574e-01],
         [ 1.7432e-03,  9.5382e-01],
         [-1.7818e-03,  9.5307e-01],
         [-4.2002e-04,  9.5252e-01]]])
agent 0 action: VehicleControl(throttle=0.012302, steer=0.006800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51831944344448
+++++++++++++: 166.00090714394304
8.237458614632487 seconds in game passed.
At 8.237458614632487 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0025,  0.9521],
         [-0.0081,  0.9504],
         [-0.0030,  0.9419]]])
agent 0 action: VehicleControl(throttle=0.067033, steer=0.017107, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006176163172432327
Current mitigation activation: 0
#############################
Total reward: 17.524495606616913
8.262458615005016 seconds in game passed.
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0025,  0.9521],
         [-0.0081,  0.9504],
         [-0.0030,  0.9419]]])
agent 0 action: VehicleControl(throttle=0.062629, steer=0.015813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.524495606616913
8.287458615377545 seconds in game passed.
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0025,  0.9521],
         [-0.0081,  0.9504],
         [-0.0030,  0.9419]]])
agent 0 action: VehicleControl(throttle=0.063885, steer=0.016176, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.524495606616913
8.312458615750074 seconds in game passed.
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0025,  0.9521],
         [-0.0081,  0.9504],
         [-0.0030,  0.9419]]])
agent 0 action: VehicleControl(throttle=0.065054, steer=0.016539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.524495606616913
+++++++++++++: 207.34266633945668
8.337458616122603 seconds in game passed.
At 8.337458616122603 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.5636e-02,  9.5370e-01],
         [ 8.6195e-04,  9.4757e-01],
         [-1.2725e-02,  9.1525e-01],
         [-7.9692e-03,  6.0021e-01]]])
agent 0 action: VehicleControl(throttle=0.077907, steer=0.015897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.005199019065291354
Current mitigation activation: 0
#############################
Total reward: 17.529694625682204
8.362458616495132 seconds in game passed.
Action: tensor([[[ 2.5636e-02,  9.5370e-01],
         [ 8.6195e-04,  9.4757e-01],
         [-1.2725e-02,  9.1525e-01],
         [-7.9692e-03,  6.0021e-01]]])
agent 0 action: VehicleControl(throttle=0.077841, steer=0.015944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.529694625682204
8.387458616867661 seconds in game passed.
Action: tensor([[[ 2.5636e-02,  9.5370e-01],
         [ 8.6195e-04,  9.4757e-01],
         [-1.2725e-02,  9.1525e-01],
         [-7.9692e-03,  6.0021e-01]]])
agent 0 action: VehicleControl(throttle=0.078969, steer=0.015892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.529694625682204
8.41245861724019 seconds in game passed.
Action: tensor([[[ 2.5636e-02,  9.5370e-01],
         [ 8.6195e-04,  9.4757e-01],
         [-1.2725e-02,  9.1525e-01],
         [-7.9692e-03,  6.0021e-01]]])
agent 0 action: VehicleControl(throttle=0.080048, steer=0.015840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.529694625682204
+++++++++++++: 245.84012179779262
8.43745861761272 seconds in game passed.
At 8.43745861761272 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0098,  0.9526],
         [-0.0039,  0.9410],
         [-0.0105,  0.8724],
         [-0.0049,  0.6051]]])
agent 0 action: VehicleControl(throttle=0.056950, steer=0.003006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004614057399397095
Current mitigation activation: 0
#############################
Total reward: 17.5343086830816
8.462458617985249 seconds in game passed.
Action: tensor([[[ 0.0098,  0.9526],
         [-0.0039,  0.9410],
         [-0.0105,  0.8724],
         [-0.0049,  0.6051]]])
agent 0 action: VehicleControl(throttle=0.060248, steer=0.005167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5343086830816
8.487458618357778 seconds in game passed.
Action: tensor([[[ 0.0098,  0.9526],
         [-0.0039,  0.9410],
         [-0.0105,  0.8724],
         [-0.0049,  0.6051]]])
agent 0 action: VehicleControl(throttle=0.060974, steer=0.005185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5343086830816
8.512458618730307 seconds in game passed.
Action: tensor([[[ 0.0098,  0.9526],
         [-0.0039,  0.9410],
         [-0.0105,  0.8724],
         [-0.0049,  0.6051]]])
agent 0 action: VehicleControl(throttle=0.061704, steer=0.005204, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5343086830816
+++++++++++++: 274.3249827488965
8.537458619102836 seconds in game passed.
At 8.537458619102836 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0326,  0.9511],
         [-0.0182,  0.9016],
         [-0.0116,  0.7274],
         [-0.0083,  0.5433]]])
agent 0 action: VehicleControl(throttle=0.221837, steer=-0.030026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004354630817191462
Current mitigation activation: 0
#############################
Total reward: 17.53866331389879
8.562458619475365 seconds in game passed.
Action: tensor([[[-0.0326,  0.9511],
         [-0.0182,  0.9016],
         [-0.0116,  0.7274],
         [-0.0083,  0.5433]]])
agent 0 action: VehicleControl(throttle=0.207435, steer=-0.024548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53866331389879
8.587458619847894 seconds in game passed.
Action: tensor([[[-0.0326,  0.9511],
         [-0.0182,  0.9016],
         [-0.0116,  0.7274],
         [-0.0083,  0.5433]]])
agent 0 action: VehicleControl(throttle=0.209879, steer=-0.024885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53866331389879
8.612458620220423 seconds in game passed.
Action: tensor([[[-0.0326,  0.9511],
         [-0.0182,  0.9016],
         [-0.0116,  0.7274],
         [-0.0083,  0.5433]]])
agent 0 action: VehicleControl(throttle=0.212163, steer=-0.025223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53866331389879
+++++++++++++: 296.1777778784971
8.637458620592952 seconds in game passed.
At 8.637458620592952 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0395,  0.9496],
         [-0.0174,  0.8201],
         [-0.0072,  0.6114],
         [-0.0045,  0.4922]]])
agent 0 action: VehicleControl(throttle=0.639164, steer=-0.028225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004247042322960063
Current mitigation activation: 0
#############################
Total reward: 17.54291035622175
8.66245862096548 seconds in game passed.
Action: tensor([[[-0.0395,  0.9496],
         [-0.0174,  0.8201],
         [-0.0072,  0.6114],
         [-0.0045,  0.4922]]])
agent 0 action: VehicleControl(throttle=0.600861, steer=-0.028154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54291035622175
8.68745862133801 seconds in game passed.
Action: tensor([[[-0.0395,  0.9496],
         [-0.0174,  0.8201],
         [-0.0072,  0.6114],
         [-0.0045,  0.4922]]])
agent 0 action: VehicleControl(throttle=0.607428, steer=-0.028523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54291035622175
8.712458621710539 seconds in game passed.
Action: tensor([[[-0.0395,  0.9496],
         [-0.0174,  0.8201],
         [-0.0072,  0.6114],
         [-0.0045,  0.4922]]])
agent 0 action: VehicleControl(throttle=0.613665, steer=-0.028891, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54291035622175
+++++++++++++: 282.18961823506754
8.737458622083068 seconds in game passed.
At 8.737458622083068 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0338,  0.9490],
         [-0.0099,  0.8000],
         [-0.0051,  0.5900],
         [-0.0069,  0.4839]]])
agent 0 action: VehicleControl(throttle=0.737890, steer=-0.020781, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0046932802174906064
Current mitigation activation: 0
#############################
Total reward: 17.54760363643924
8.762458622455597 seconds in game passed.
Action: tensor([[[-0.0338,  0.9490],
         [-0.0099,  0.8000],
         [-0.0051,  0.5900],
         [-0.0069,  0.4839]]])
agent 0 action: VehicleControl(throttle=0.731632, steer=-0.022459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54760363643924
8.787458622828126 seconds in game passed.
Action: tensor([[[-0.0338,  0.9490],
         [-0.0099,  0.8000],
         [-0.0051,  0.5900],
         [-0.0069,  0.4839]]])
agent 0 action: VehicleControl(throttle=0.737048, steer=-0.022739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54760363643924
8.812458623200655 seconds in game passed.
Action: tensor([[[-0.0338,  0.9490],
         [-0.0099,  0.8000],
         [-0.0051,  0.5900],
         [-0.0069,  0.4839]]])
agent 0 action: VehicleControl(throttle=0.740907, steer=-0.023020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54760363643924
+++++++++++++: 185.28348985006977
8.837458623573184 seconds in game passed.
At 8.837458623573184 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.5977e-02,  9.4310e-01],
         [-4.7722e-03,  6.0490e-01],
         [-1.8049e-03,  4.7176e-01],
         [-4.5291e-04,  4.1688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013269, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.007518379176559365
Current mitigation activation: 0
#############################
Total reward: 17.5551220156158
8.862458623945713 seconds in game passed.
Action: tensor([[[-2.5977e-02,  9.4310e-01],
         [-4.7722e-03,  6.0490e-01],
         [-1.8049e-03,  4.7176e-01],
         [-4.5291e-04,  4.1688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5551220156158
8.887458624318242 seconds in game passed.
Action: tensor([[[-2.5977e-02,  9.4310e-01],
         [-4.7722e-03,  6.0490e-01],
         [-1.8049e-03,  4.7176e-01],
         [-4.5291e-04,  4.1688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5551220156158
8.912458624690771 seconds in game passed.
Action: tensor([[[-2.5977e-02,  9.4310e-01],
         [-4.7722e-03,  6.0490e-01],
         [-1.8049e-03,  4.7176e-01],
         [-4.5291e-04,  4.1688e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5551220156158
+++++++++++++: 44.555465452613255
8.9374586250633 seconds in game passed.
At 8.9374586250633 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1051e-02,  9.3239e-01],
         [ 6.5774e-05,  5.5837e-01],
         [ 1.9637e-04,  4.3381e-01],
         [ 1.1238e-03,  3.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03279310041910389
Current mitigation activation: 0
#############################
Total reward: 17.587915116034903
8.96245862543583 seconds in game passed.
Action: tensor([[[-1.1051e-02,  9.3239e-01],
         [ 6.5774e-05,  5.5837e-01],
         [ 1.9637e-04,  4.3381e-01],
         [ 1.1238e-03,  3.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.587915116034903
8.987458625808358 seconds in game passed.
Action: tensor([[[-1.1051e-02,  9.3239e-01],
         [ 6.5774e-05,  5.5837e-01],
         [ 1.9637e-04,  4.3381e-01],
         [ 1.1238e-03,  3.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006708, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.587915116034903
9.012458626180887 seconds in game passed.
Action: tensor([[[-1.1051e-02,  9.3239e-01],
         [ 6.5774e-05,  5.5837e-01],
         [ 1.9637e-04,  4.3381e-01],
         [ 1.1238e-03,  3.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.587915116034903
+++++++++++++: 20.244896093317454
9.037458626553416 seconds in game passed.
At 9.037458626553416 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0038,  0.8806],
         [-0.0022,  0.4925],
         [-0.0044,  0.3550],
         [-0.0047,  0.2831]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.07538085623788338
Current mitigation activation: 0
#############################
Total reward: 17.66329597227279
9.062458626925945 seconds in game passed.
Action: tensor([[[-0.0038,  0.8806],
         [-0.0022,  0.4925],
         [-0.0044,  0.3550],
         [-0.0047,  0.2831]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66329597227279
9.087458627298474 seconds in game passed.
Action: tensor([[[-0.0038,  0.8806],
         [-0.0022,  0.4925],
         [-0.0044,  0.3550],
         [-0.0047,  0.2831]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66329597227279
9.112458627671003 seconds in game passed.
Action: tensor([[[-0.0038,  0.8806],
         [-0.0022,  0.4925],
         [-0.0044,  0.3550],
         [-0.0047,  0.2831]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66329597227279
+++++++++++++: 10.312120636045021
9.137458628043532 seconds in game passed.
At 9.137458628043532 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0064,  0.8363],
         [-0.0021,  0.4709],
         [-0.0053,  0.3362],
         [-0.0064,  0.2637]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.15364079323716662
Current mitigation activation: 0
#############################
Total reward: 17.816936765509954
9.162458628416061 seconds in game passed.
Action: tensor([[[ 0.0064,  0.8363],
         [-0.0021,  0.4709],
         [-0.0053,  0.3362],
         [-0.0064,  0.2637]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.816936765509954
9.18745862878859 seconds in game passed.
Action: tensor([[[ 0.0064,  0.8363],
         [-0.0021,  0.4709],
         [-0.0053,  0.3362],
         [-0.0064,  0.2637]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.816936765509954
9.21245862916112 seconds in game passed.
Action: tensor([[[ 0.0064,  0.8363],
         [-0.0021,  0.4709],
         [-0.0053,  0.3362],
         [-0.0064,  0.2637]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.816936765509954
+++++++++++++: 7.268414350047847
9.237458629533648 seconds in game passed.
At 9.237458629533648 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0074,  0.8146],
         [-0.0018,  0.4583],
         [-0.0051,  0.3232],
         [-0.0068,  0.2503]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.268414350047847
Current reward: 0.17700128348182323
Current mitigation activation: 0
#############################
Total reward: 17.993938048991776
9.262458629906178 seconds in game passed.
Action: tensor([[[ 0.0074,  0.8146],
         [-0.0018,  0.4583],
         [-0.0051,  0.3232],
         [-0.0068,  0.2503]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.993938048991776
9.287458630278707 seconds in game passed.
Action: tensor([[[ 0.0074,  0.8146],
         [-0.0018,  0.4583],
         [-0.0051,  0.3232],
         [-0.0068,  0.2503]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.993938048991776
9.312458630651236 seconds in game passed.
Action: tensor([[[ 0.0074,  0.8146],
         [-0.0018,  0.4583],
         [-0.0051,  0.3232],
         [-0.0068,  0.2503]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.993938048991776
+++++++++++++: 5.9100393962932145
9.337458631023765 seconds in game passed.
At 9.337458631023765 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.1101e-03,  8.0511e-01],
         [-3.9016e-04,  4.4810e-01],
         [-3.4093e-03,  3.1043e-01],
         [-5.3644e-03,  2.3673e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.9100393962932145
Current reward: 0.19361055171686892
Current mitigation activation: 0
#############################
Total reward: 18.187548600708645
9.362458631396294 seconds in game passed.
Action: tensor([[[ 8.1101e-03,  8.0511e-01],
         [-3.9016e-04,  4.4810e-01],
         [-3.4093e-03,  3.1043e-01],
         [-5.3644e-03,  2.3673e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.187548600708645
9.387458631768823 seconds in game passed.
Action: tensor([[[ 8.1101e-03,  8.0511e-01],
         [-3.9016e-04,  4.4810e-01],
         [-3.4093e-03,  3.1043e-01],
         [-5.3644e-03,  2.3673e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.187548600708645
9.412458632141352 seconds in game passed.
Action: tensor([[[ 8.1101e-03,  8.0511e-01],
         [-3.9016e-04,  4.4810e-01],
         [-3.4093e-03,  3.1043e-01],
         [-5.3644e-03,  2.3673e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001816, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.187548600708645
+++++++++++++: 5.06856530720803
9.43745863251388 seconds in game passed.
At 9.43745863251388 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.5315e-03,  7.7500e-01],
         [-4.6543e-04,  4.3181e-01],
         [-2.8916e-03,  3.0001e-01],
         [-4.6017e-03,  2.2996e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.06856530720803
Current reward: 0.20891402144183824
Current mitigation activation: 0
#############################
Total reward: 18.396462622150484
9.46245863288641 seconds in game passed.
Action: tensor([[[ 6.5315e-03,  7.7500e-01],
         [-4.6543e-04,  4.3181e-01],
         [-2.8916e-03,  3.0001e-01],
         [-4.6017e-03,  2.2996e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.396462622150484
9.487458633258939 seconds in game passed.
Action: tensor([[[ 6.5315e-03,  7.7500e-01],
         [-4.6543e-04,  4.3181e-01],
         [-2.8916e-03,  3.0001e-01],
         [-4.6017e-03,  2.2996e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.396462622150484
9.512458633631468 seconds in game passed.
Action: tensor([[[ 6.5315e-03,  7.7500e-01],
         [-4.6543e-04,  4.3181e-01],
         [-2.8916e-03,  3.0001e-01],
         [-4.6017e-03,  2.2996e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.396462622150484
+++++++++++++: 4.46797188172208
9.537458634003997 seconds in game passed.
At 9.537458634003997 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.8703e-03,  7.4663e-01],
         [ 8.2664e-05,  4.1842e-01],
         [-1.8567e-03,  2.9090e-01],
         [-3.3677e-03,  2.2342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.46797188172208
Current reward: 0.22347820805830326
Current mitigation activation: 0
#############################
Total reward: 18.619940830208787
9.562458634376526 seconds in game passed.
Action: tensor([[[ 7.8703e-03,  7.4663e-01],
         [ 8.2664e-05,  4.1842e-01],
         [-1.8567e-03,  2.9090e-01],
         [-3.3677e-03,  2.2342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.619940830208787
9.587458634749055 seconds in game passed.
Action: tensor([[[ 7.8703e-03,  7.4663e-01],
         [ 8.2664e-05,  4.1842e-01],
         [-1.8567e-03,  2.9090e-01],
         [-3.3677e-03,  2.2342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.619940830208787
9.612458635121584 seconds in game passed.
Action: tensor([[[ 7.8703e-03,  7.4663e-01],
         [ 8.2664e-05,  4.1842e-01],
         [-1.8567e-03,  2.9090e-01],
         [-3.3677e-03,  2.2342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000226, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.619940830208787
+++++++++++++: 4.0061842182746705
9.637458635494113 seconds in game passed.
At 9.637458635494113 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5216e-02,  7.6032e-01],
         [ 1.6638e-03,  4.2374e-01],
         [-6.4693e-05,  2.9458e-01],
         [-8.6639e-04,  2.2591e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004389, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.0061842182746705
Current reward: 0.23750740234476836
Current mitigation activation: 0
#############################
Total reward: 18.857448232553555
9.662458635866642 seconds in game passed.
Action: tensor([[[ 1.5216e-02,  7.6032e-01],
         [ 1.6638e-03,  4.2374e-01],
         [-6.4693e-05,  2.9458e-01],
         [-8.6639e-04,  2.2591e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.857448232553555
9.687458636239171 seconds in game passed.
Action: tensor([[[ 1.5216e-02,  7.6032e-01],
         [ 1.6638e-03,  4.2374e-01],
         [-6.4693e-05,  2.9458e-01],
         [-8.6639e-04,  2.2591e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.857448232553555
9.7124586366117 seconds in game passed.
Action: tensor([[[ 1.5216e-02,  7.6032e-01],
         [ 1.6638e-03,  4.2374e-01],
         [-6.4693e-05,  2.9458e-01],
         [-8.6639e-04,  2.2591e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.857448232553555
+++++++++++++: 3.6337442530835813
9.737458636984229 seconds in game passed.
At 9.737458636984229 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5750e-02,  7.5151e-01],
         [ 1.5706e-03,  4.1994e-01],
         [ 5.9783e-05,  2.9277e-01],
         [-4.9917e-04,  2.2527e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6337442530835813
Current reward: 0.25109664144282784
Current mitigation activation: 0
#############################
Total reward: 19.108544873996383
9.762458637356758 seconds in game passed.
Action: tensor([[[ 1.5750e-02,  7.5151e-01],
         [ 1.5706e-03,  4.1994e-01],
         [ 5.9783e-05,  2.9277e-01],
         [-4.9917e-04,  2.2527e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.108544873996383
9.787458637729287 seconds in game passed.
Action: tensor([[[ 1.5750e-02,  7.5151e-01],
         [ 1.5706e-03,  4.1994e-01],
         [ 5.9783e-05,  2.9277e-01],
         [-4.9917e-04,  2.2527e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.108544873996383
9.812458638101816 seconds in game passed.
Action: tensor([[[ 1.5750e-02,  7.5151e-01],
         [ 1.5706e-03,  4.1994e-01],
         [ 5.9783e-05,  2.9277e-01],
         [-4.9917e-04,  2.2527e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.108544873996383
+++++++++++++: 3.3235771328451795
9.837458638474345 seconds in game passed.
At 9.837458638474345 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0148, 0.7430],
         [0.0028, 0.4207],
         [0.0015, 0.2942],
         [0.0009, 0.2264]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3235771328451795
Current reward: 0.26427533173764717
Current mitigation activation: 0
#############################
Total reward: 19.37282020573403
9.862458638846874 seconds in game passed.
Action: tensor([[[0.0148, 0.7430],
         [0.0028, 0.4207],
         [0.0015, 0.2942],
         [0.0009, 0.2264]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.37282020573403
9.887458639219403 seconds in game passed.
Action: tensor([[[0.0148, 0.7430],
         [0.0028, 0.4207],
         [0.0015, 0.2942],
         [0.0009, 0.2264]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.37282020573403
9.912458639591932 seconds in game passed.
Action: tensor([[[0.0148, 0.7430],
         [0.0028, 0.4207],
         [0.0015, 0.2942],
         [0.0009, 0.2264]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.37282020573403
+++++++++++++: 3.17443903478482
9.937458639964461 seconds in game passed.
At 9.937458639964461 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0111, 0.7086],
         [0.0020, 0.3987],
         [0.0012, 0.2790],
         [0.0008, 0.2162]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.17443903478482
Current reward: 0.27257017546411516
Current mitigation activation: 0
#############################
Total reward: 19.645390381198144
9.96245864033699 seconds in game passed.
Action: tensor([[[0.0111, 0.7086],
         [0.0020, 0.3987],
         [0.0012, 0.2790],
         [0.0008, 0.2162]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006344, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.645390381198144
9.98745864070952 seconds in game passed.
Action: tensor([[[0.0111, 0.7086],
         [0.0020, 0.3987],
         [0.0012, 0.2790],
         [0.0008, 0.2162]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.645390381198144
10.012458641082048 seconds in game passed.
Action: tensor([[[0.0111, 0.7086],
         [0.0020, 0.3987],
         [0.0012, 0.2790],
         [0.0008, 0.2162]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.645390381198144
+++++++++++++: 3.2085068467745095
10.037458641454577 seconds in game passed.
At 10.037458641454577 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.4060e-03, 6.7606e-01],
         [1.1242e-03, 3.7624e-01],
         [6.9725e-04, 2.6347e-01],
         [3.5854e-04, 2.0584e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2085068467745095
Current reward: 0.2738674802012573
Current mitigation activation: 0
#############################
Total reward: 19.9192578613994
10.062458641827106 seconds in game passed.
Action: tensor([[[6.4060e-03, 6.7606e-01],
         [1.1242e-03, 3.7624e-01],
         [6.9725e-04, 2.6347e-01],
         [3.5854e-04, 2.0584e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.9192578613994
10.087458642199636 seconds in game passed.
Action: tensor([[[6.4060e-03, 6.7606e-01],
         [1.1242e-03, 3.7624e-01],
         [6.9725e-04, 2.6347e-01],
         [3.5854e-04, 2.0584e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.9192578613994
10.112458642572165 seconds in game passed.
Action: tensor([[[6.4060e-03, 6.7606e-01],
         [1.1242e-03, 3.7624e-01],
         [6.9725e-04, 2.6347e-01],
         [3.5854e-04, 2.0584e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.9192578613994
+++++++++++++: 3.243586412959509
10.137458642944694 seconds in game passed.
At 10.137458642944694 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.8990e-03, 6.5959e-01],
         [1.4172e-03, 3.6502e-01],
         [1.0223e-03, 2.5443e-01],
         [3.1818e-04, 1.9842e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003900, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.243586412959509
Current reward: 0.2751453851820981
Current mitigation activation: 0
#############################
Total reward: 20.1944032465815
10.162458643317223 seconds in game passed.
Action: tensor([[[3.8990e-03, 6.5959e-01],
         [1.4172e-03, 3.6502e-01],
         [1.0223e-03, 2.5443e-01],
         [3.1818e-04, 1.9842e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.1944032465815
10.187458643689752 seconds in game passed.
Action: tensor([[[3.8990e-03, 6.5959e-01],
         [1.4172e-03, 3.6502e-01],
         [1.0223e-03, 2.5443e-01],
         [3.1818e-04, 1.9842e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.1944032465815
10.21245864406228 seconds in game passed.
Action: tensor([[[3.8990e-03, 6.5959e-01],
         [1.4172e-03, 3.6502e-01],
         [1.0223e-03, 2.5443e-01],
         [3.1818e-04, 1.9842e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.1944032465815
+++++++++++++: 3.27907388277999
10.23745864443481 seconds in game passed.
At 10.23745864443481 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.3441e-03, 6.5639e-01],
         [1.2025e-03, 3.6425e-01],
         [9.1556e-04, 2.5428e-01],
         [3.2151e-04, 1.9836e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.27907388277999
Current reward: 0.2764287190560676
Current mitigation activation: 0
#############################
Total reward: 20.47083196563757
10.262458644807339 seconds in game passed.
Action: tensor([[[3.3441e-03, 6.5639e-01],
         [1.2025e-03, 3.6425e-01],
         [9.1556e-04, 2.5428e-01],
         [3.2151e-04, 1.9836e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47083196563757
10.287458645179868 seconds in game passed.
Action: tensor([[[3.3441e-03, 6.5639e-01],
         [1.2025e-03, 3.6425e-01],
         [9.1556e-04, 2.5428e-01],
         [3.2151e-04, 1.9836e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47083196563757
10.312458645552397 seconds in game passed.
Action: tensor([[[3.3441e-03, 6.5639e-01],
         [1.2025e-03, 3.6425e-01],
         [9.1556e-04, 2.5428e-01],
         [3.2151e-04, 1.9836e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47083196563757
+++++++++++++: 3.315015432465669
10.337458645924926 seconds in game passed.
At 10.337458645924926 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9179e-03,  6.4604e-01],
         [ 5.1974e-04,  3.6003e-01],
         [ 1.7051e-04,  2.5227e-01],
         [-3.8772e-04,  1.9686e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.315015432465669
Current reward: 0.2777143109271464
Current mitigation activation: 0
#############################
Total reward: 20.748546276564714
10.362458646297455 seconds in game passed.
Action: tensor([[[ 2.9179e-03,  6.4604e-01],
         [ 5.1974e-04,  3.6003e-01],
         [ 1.7051e-04,  2.5227e-01],
         [-3.8772e-04,  1.9686e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.748546276564714
10.387458646669984 seconds in game passed.
Action: tensor([[[ 2.9179e-03,  6.4604e-01],
         [ 5.1974e-04,  3.6003e-01],
         [ 1.7051e-04,  2.5227e-01],
         [-3.8772e-04,  1.9686e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.748546276564714
10.412458647042513 seconds in game passed.
Action: tensor([[[ 2.9179e-03,  6.4604e-01],
         [ 5.1974e-04,  3.6003e-01],
         [ 1.7051e-04,  2.5227e-01],
         [-3.8772e-04,  1.9686e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.748546276564714
+++++++++++++: 3.236898348504916
10.437458647415042 seconds in game passed.
At 10.437458647415042 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2961e-03,  6.3963e-01],
         [ 3.6548e-04,  3.5501e-01],
         [-1.8079e-04,  2.4772e-01],
         [-8.5062e-04,  1.9270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.236898348504916
Current reward: 0.2831847470516058
Current mitigation activation: 0
#############################
Total reward: 21.03173102361632
10.462458647787571 seconds in game passed.
Action: tensor([[[ 2.2961e-03,  6.3963e-01],
         [ 3.6548e-04,  3.5501e-01],
         [-1.8079e-04,  2.4772e-01],
         [-8.5062e-04,  1.9270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.03173102361632
10.4874586481601 seconds in game passed.
Action: tensor([[[ 2.2961e-03,  6.3963e-01],
         [ 3.6548e-04,  3.5501e-01],
         [-1.8079e-04,  2.4772e-01],
         [-8.5062e-04,  1.9270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.03173102361632
10.512458648532629 seconds in game passed.
Action: tensor([[[ 2.2961e-03,  6.3963e-01],
         [ 3.6548e-04,  3.5501e-01],
         [-1.8079e-04,  2.4772e-01],
         [-8.5062e-04,  1.9270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.03173102361632
+++++++++++++: 2.963265817280016
10.537458648905158 seconds in game passed.
At 10.537458648905158 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.3187e-03,  6.4168e-01],
         [ 6.6258e-04,  3.5411e-01],
         [ 1.3653e-04,  2.4554e-01],
         [-5.6846e-04,  1.9006e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.963265817280016
Current reward: 0.2968863980203861
Current mitigation activation: 0
#############################
Total reward: 21.328617421636707
10.562458649277687 seconds in game passed.
Action: tensor([[[ 2.3187e-03,  6.4168e-01],
         [ 6.6258e-04,  3.5411e-01],
         [ 1.3653e-04,  2.4554e-01],
         [-5.6846e-04,  1.9006e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.328617421636707
10.587458649650216 seconds in game passed.
Action: tensor([[[ 2.3187e-03,  6.4168e-01],
         [ 6.6258e-04,  3.5411e-01],
         [ 1.3653e-04,  2.4554e-01],
         [-5.6846e-04,  1.9006e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.328617421636707
10.612458650022745 seconds in game passed.
Action: tensor([[[ 2.3187e-03,  6.4168e-01],
         [ 6.6258e-04,  3.5411e-01],
         [ 1.3653e-04,  2.4554e-01],
         [-5.6846e-04,  1.9006e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.328617421636707
+++++++++++++: 2.7478127207357237
10.637458650395274 seconds in game passed.
At 10.637458650395274 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5791e-03,  6.6138e-01],
         [-2.3067e-04,  3.6216e-01],
         [-7.6985e-04,  2.5012e-01],
         [-1.4575e-03,  1.9326e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7478127207357237
Current reward: 0.30899424216932353
Current mitigation activation: 0
#############################
Total reward: 21.63761166380603
10.662458650767803 seconds in game passed.
Action: tensor([[[ 1.5791e-03,  6.6138e-01],
         [-2.3067e-04,  3.6216e-01],
         [-7.6985e-04,  2.5012e-01],
         [-1.4575e-03,  1.9326e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63761166380603
10.687458651140332 seconds in game passed.
Action: tensor([[[ 1.5791e-03,  6.6138e-01],
         [-2.3067e-04,  3.6216e-01],
         [-7.6985e-04,  2.5012e-01],
         [-1.4575e-03,  1.9326e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63761166380603
10.712458651512861 seconds in game passed.
Action: tensor([[[ 1.5791e-03,  6.6138e-01],
         [-2.3067e-04,  3.6216e-01],
         [-7.6985e-04,  2.5012e-01],
         [-1.4575e-03,  1.9326e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63761166380603
+++++++++++++: 2.5686072182677773
10.73745865188539 seconds in game passed.
At 10.73745865188539 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6717],
         [-0.0011,  0.3649],
         [-0.0017,  0.2504],
         [-0.0025,  0.1928]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5686072182677773
Current reward: 0.3198943236259563
Current mitigation activation: 0
#############################
Total reward: 21.957505987431986
10.76245865225792 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6717],
         [-0.0011,  0.3649],
         [-0.0017,  0.2504],
         [-0.0025,  0.1928]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.957505987431986
10.787458652630448 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6717],
         [-0.0011,  0.3649],
         [-0.0017,  0.2504],
         [-0.0025,  0.1928]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.957505987431986
10.812458653002977 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6717],
         [-0.0011,  0.3649],
         [-0.0017,  0.2504],
         [-0.0025,  0.1928]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000775, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.957505987431986
+++++++++++++: 2.4113777663574014
10.837458653375506 seconds in game passed.
At 10.837458653375506 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.3330e-05,  6.7558e-01],
         [-1.6864e-03,  3.6599e-01],
         [-2.6376e-03,  2.5128e-01],
         [-3.5676e-03,  1.9352e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4113777663574014
Current reward: 0.3299899990541898
Current mitigation activation: 0
#############################
Total reward: 22.287495986486174
10.862458653748035 seconds in game passed.
Action: tensor([[[ 6.3330e-05,  6.7558e-01],
         [-1.6864e-03,  3.6599e-01],
         [-2.6376e-03,  2.5128e-01],
         [-3.5676e-03,  1.9352e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.287495986486174
10.887458654120564 seconds in game passed.
Action: tensor([[[ 6.3330e-05,  6.7558e-01],
         [-1.6864e-03,  3.6599e-01],
         [-2.6376e-03,  2.5128e-01],
         [-3.5676e-03,  1.9352e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.287495986486174
10.912458654493093 seconds in game passed.
Action: tensor([[[ 6.3330e-05,  6.7558e-01],
         [-1.6864e-03,  3.6599e-01],
         [-2.6376e-03,  2.5128e-01],
         [-3.5676e-03,  1.9352e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.287495986486174
+++++++++++++: 2.269132173019186
10.937458654865623 seconds in game passed.
At 10.937458654865623 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6904],
         [-0.0027,  0.3702],
         [-0.0035,  0.2551],
         [-0.0046,  0.1969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.269132173019186
Current reward: 0.3394824910837705
Current mitigation activation: 0
#############################
Total reward: 22.626978477569946
10.962458655238152 seconds in game passed.
Action: tensor([[[-0.0015,  0.6904],
         [-0.0027,  0.3702],
         [-0.0035,  0.2551],
         [-0.0046,  0.1969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.626978477569946
10.98745865561068 seconds in game passed.
Action: tensor([[[-0.0015,  0.6904],
         [-0.0027,  0.3702],
         [-0.0035,  0.2551],
         [-0.0046,  0.1969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.626978477569946
11.01245865598321 seconds in game passed.
Action: tensor([[[-0.0015,  0.6904],
         [-0.0027,  0.3702],
         [-0.0035,  0.2551],
         [-0.0046,  0.1969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.626978477569946
+++++++++++++: 2.1380107964251978
11.037458656355739 seconds in game passed.
At 11.037458656355739 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.6854],
         [-0.0036,  0.3733],
         [-0.0044,  0.2584],
         [-0.0049,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1380107964251978
Current reward: 0.34847641715372624
Current mitigation activation: 0
#############################
Total reward: 22.975454894723672
11.062458656728268 seconds in game passed.
Action: tensor([[[-0.0009,  0.6854],
         [-0.0036,  0.3733],
         [-0.0044,  0.2584],
         [-0.0049,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.975454894723672
11.087458657100797 seconds in game passed.
Action: tensor([[[-0.0009,  0.6854],
         [-0.0036,  0.3733],
         [-0.0044,  0.2584],
         [-0.0049,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.975454894723672
11.112458657473326 seconds in game passed.
Action: tensor([[[-0.0009,  0.6854],
         [-0.0036,  0.3733],
         [-0.0044,  0.2584],
         [-0.0049,  0.1994]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.975454894723672
+++++++++++++: 2.0160370435932715
11.137458657845855 seconds in game passed.
At 11.137458657845855 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0029,  0.6770],
         [-0.0009,  0.3724],
         [-0.0017,  0.2580],
         [-0.0025,  0.1993]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0160370435932715
Current reward: 0.35699172149402714
Current mitigation activation: 0
#############################
Total reward: 23.332446616217698
11.162458658218384 seconds in game passed.
Action: tensor([[[ 0.0029,  0.6770],
         [-0.0009,  0.3724],
         [-0.0017,  0.2580],
         [-0.0025,  0.1993]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000502, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.332446616217698
11.187458658590913 seconds in game passed.
Action: tensor([[[ 0.0029,  0.6770],
         [-0.0009,  0.3724],
         [-0.0017,  0.2580],
         [-0.0025,  0.1993]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.332446616217698
11.212458658963442 seconds in game passed.
Action: tensor([[[ 0.0029,  0.6770],
         [-0.0009,  0.3724],
         [-0.0017,  0.2580],
         [-0.0025,  0.1993]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.332446616217698
+++++++++++++: 1.9016902354851504
11.23745865933597 seconds in game passed.
At 11.23745865933597 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6863],
         [-0.0012,  0.3778],
         [-0.0021,  0.2621],
         [-0.0027,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9016902354851504
Current reward: 0.3650471422935556
Current mitigation activation: 0
#############################
Total reward: 23.697493758511254
11.2624586597085 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6863],
         [-0.0012,  0.3778],
         [-0.0021,  0.2621],
         [-0.0027,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.697493758511254
11.287458660081029 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6863],
         [-0.0012,  0.3778],
         [-0.0021,  0.2621],
         [-0.0027,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.697493758511254
11.312458660453558 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6863],
         [-0.0012,  0.3778],
         [-0.0021,  0.2621],
         [-0.0027,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.697493758511254
+++++++++++++: 1.793988662433909
11.337458660826087 seconds in game passed.
At 11.337458660826087 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.3798e-03,  6.7922e-01],
         [-7.5415e-05,  3.8803e-01],
         [-9.0176e-04,  2.7423e-01],
         [-1.4274e-03,  2.1373e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.793988662433909
Current reward: 0.37262949785832766
Current mitigation activation: 0
#############################
Total reward: 24.07012325636958
11.362458661198616 seconds in game passed.
Action: tensor([[[ 6.3798e-03,  6.7922e-01],
         [-7.5415e-05,  3.8803e-01],
         [-9.0176e-04,  2.7423e-01],
         [-1.4274e-03,  2.1373e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.07012325636958
11.387458661571145 seconds in game passed.
Action: tensor([[[ 6.3798e-03,  6.7922e-01],
         [-7.5415e-05,  3.8803e-01],
         [-9.0176e-04,  2.7423e-01],
         [-1.4274e-03,  2.1373e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.07012325636958
11.412458661943674 seconds in game passed.
Action: tensor([[[ 6.3798e-03,  6.7922e-01],
         [-7.5415e-05,  3.8803e-01],
         [-9.0176e-04,  2.7423e-01],
         [-1.4274e-03,  2.1373e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.07012325636958
+++++++++++++: 1.6918607511641854
11.437458662316203 seconds in game passed.
At 11.437458662316203 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.1565e-03,  7.0028e-01],
         [ 2.1964e-05,  3.9284e-01],
         [-8.9277e-04,  2.7526e-01],
         [-1.3390e-03,  2.1303e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6918607511641854
Current reward: 0.3797608163348394
Current mitigation activation: 0
#############################
Total reward: 24.44988407270442
11.462458662688732 seconds in game passed.
Action: tensor([[[ 6.1565e-03,  7.0028e-01],
         [ 2.1964e-05,  3.9284e-01],
         [-8.9277e-04,  2.7526e-01],
         [-1.3390e-03,  2.1303e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.44988407270442
11.487458663061261 seconds in game passed.
Action: tensor([[[ 6.1565e-03,  7.0028e-01],
         [ 2.1964e-05,  3.9284e-01],
         [-8.9277e-04,  2.7526e-01],
         [-1.3390e-03,  2.1303e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.44988407270442
11.51245866343379 seconds in game passed.
Action: tensor([[[ 6.1565e-03,  7.0028e-01],
         [ 2.1964e-05,  3.9284e-01],
         [-8.9277e-04,  2.7526e-01],
         [-1.3390e-03,  2.1303e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.44988407270442
+++++++++++++: 1.5947026644142495
11.53745866380632 seconds in game passed.
At 11.53745866380632 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.5817e-03,  7.3025e-01],
         [ 6.7268e-04,  4.0843e-01],
         [-1.1142e-04,  2.8518e-01],
         [-1.8608e-04,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.711786, steer=0.004037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5947026644142495
Current reward: 0.38642583311825707
Current mitigation activation: 0
#############################
Total reward: 24.836309905822677
11.562458664178848 seconds in game passed.
Action: tensor([[[ 9.5817e-03,  7.3025e-01],
         [ 6.7268e-04,  4.0843e-01],
         [-1.1142e-04,  2.8518e-01],
         [-1.8608e-04,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.667465, steer=0.003754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.836309905822677
11.587458664551377 seconds in game passed.
Action: tensor([[[ 9.5817e-03,  7.3025e-01],
         [ 6.7268e-04,  4.0843e-01],
         [-1.1142e-04,  2.8518e-01],
         [-1.8608e-04,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.607702, steer=0.003785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.836309905822677
11.612458664923906 seconds in game passed.
Action: tensor([[[ 9.5817e-03,  7.3025e-01],
         [ 6.7268e-04,  4.0843e-01],
         [-1.1142e-04,  2.8518e-01],
         [-1.8608e-04,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.550064, steer=0.003817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.836309905822677
+++++++++++++: 1.5025084780629665
11.637458665296435 seconds in game passed.
At 11.637458665296435 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1614e-02, 7.4423e-01],
         [2.1200e-03, 4.1432e-01],
         [1.0150e-03, 2.9120e-01],
         [5.8878e-04, 2.2607e-01]]])
agent 0 action: VehicleControl(throttle=0.517424, steer=0.005775, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5025084780629665
Current reward: 0.3925295907914535
Current mitigation activation: 0
#############################
Total reward: 25.228839496614132
11.662458665668964 seconds in game passed.
Action: tensor([[[1.1614e-02, 7.4423e-01],
         [2.1200e-03, 4.1432e-01],
         [1.0150e-03, 2.9120e-01],
         [5.8878e-04, 2.2607e-01]]])
agent 0 action: VehicleControl(throttle=0.494134, steer=0.005519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.228839496614132
11.687458666041493 seconds in game passed.
Action: tensor([[[1.1614e-02, 7.4423e-01],
         [2.1200e-03, 4.1432e-01],
         [1.0150e-03, 2.9120e-01],
         [5.8878e-04, 2.2607e-01]]])
agent 0 action: VehicleControl(throttle=0.470105, steer=0.005581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.228839496614132
11.712458666414022 seconds in game passed.
Action: tensor([[[1.1614e-02, 7.4423e-01],
         [2.1200e-03, 4.1432e-01],
         [1.0150e-03, 2.9120e-01],
         [5.8878e-04, 2.2607e-01]]])
agent 0 action: VehicleControl(throttle=0.446557, steer=0.005642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.228839496614132
+++++++++++++: 1.4234904343574575
11.737458666786551 seconds in game passed.
At 11.737458666786551 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4765e-02,  7.6637e-01],
         [ 1.7261e-03,  4.2382e-01],
         [ 5.3033e-05,  2.9618e-01],
         [-5.7276e-04,  2.2840e-01]]])
agent 0 action: VehicleControl(throttle=0.423366, steer=0.006721, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4234904343574575
Current reward: 0.39659873700865544
Current mitigation activation: 0
#############################
Total reward: 25.625438233622788
11.76245866715908 seconds in game passed.
Action: tensor([[[ 1.4765e-02,  7.6637e-01],
         [ 1.7261e-03,  4.2382e-01],
         [ 5.3033e-05,  2.9618e-01],
         [-5.7276e-04,  2.2840e-01]]])
agent 0 action: VehicleControl(throttle=0.400651, steer=0.006635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.625438233622788
11.78745866753161 seconds in game passed.
Action: tensor([[[ 1.4765e-02,  7.6637e-01],
         [ 1.7261e-03,  4.2382e-01],
         [ 5.3033e-05,  2.9618e-01],
         [-5.7276e-04,  2.2840e-01]]])
agent 0 action: VehicleControl(throttle=0.378405, steer=0.006716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.625438233622788
11.812458667904139 seconds in game passed.
Action: tensor([[[ 1.4765e-02,  7.6637e-01],
         [ 1.7261e-03,  4.2382e-01],
         [ 5.3033e-05,  2.9618e-01],
         [-5.7276e-04,  2.2840e-01]]])
agent 0 action: VehicleControl(throttle=0.356627, steer=0.006796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.625438233622788
+++++++++++++: 1.361834862201783
11.837458668276668 seconds in game passed.
At 11.837458668276668 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0098,  0.7941],
         [-0.0012,  0.4286],
         [-0.0031,  0.2976],
         [-0.0039,  0.2292]]])
agent 0 action: VehicleControl(throttle=0.335307, steer=0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.361834862201783
Current reward: 0.39760286015855284
Current mitigation activation: 0
#############################
Total reward: 26.02304109378134
11.862458668649197 seconds in game passed.
Action: tensor([[[ 0.0098,  0.7941],
         [-0.0012,  0.4286],
         [-0.0031,  0.2976],
         [-0.0039,  0.2292]]])
agent 0 action: VehicleControl(throttle=0.314450, steer=0.003316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.02304109378134
11.887458669021726 seconds in game passed.
Action: tensor([[[ 0.0098,  0.7941],
         [-0.0012,  0.4286],
         [-0.0031,  0.2976],
         [-0.0039,  0.2292]]])
agent 0 action: VehicleControl(throttle=0.294054, steer=0.003360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.02304109378134
11.912458669394255 seconds in game passed.
Action: tensor([[[ 0.0098,  0.7941],
         [-0.0012,  0.4286],
         [-0.0031,  0.2976],
         [-0.0039,  0.2292]]])
agent 0 action: VehicleControl(throttle=0.274118, steer=0.003404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.02304109378134
+++++++++++++: 1.3145072145200467
11.937458669766784 seconds in game passed.
At 11.937458669766784 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1406e-02,  8.2832e-01],
         [ 1.6773e-04,  4.4881e-01],
         [-2.1881e-03,  3.1080e-01],
         [-3.2404e-03,  2.3807e-01]]])
agent 0 action: VehicleControl(throttle=0.254603, steer=0.005206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3145072145200467
Current reward: 0.39586511622826903
Current mitigation activation: 0
#############################
Total reward: 26.41890621000961
11.962458670139313 seconds in game passed.
Action: tensor([[[ 1.1406e-02,  8.2832e-01],
         [ 1.6773e-04,  4.4881e-01],
         [-2.1881e-03,  3.1080e-01],
         [-3.2404e-03,  2.3807e-01]]])
agent 0 action: VehicleControl(throttle=0.235546, steer=0.004995, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.41890621000961
11.987458670511842 seconds in game passed.
Action: tensor([[[ 1.1406e-02,  8.2832e-01],
         [ 1.6773e-04,  4.4881e-01],
         [-2.1881e-03,  3.1080e-01],
         [-3.2404e-03,  2.3807e-01]]])
agent 0 action: VehicleControl(throttle=0.216944, steer=0.005072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.41890621000961
12.01245867088437 seconds in game passed.
Action: tensor([[[ 1.1406e-02,  8.2832e-01],
         [ 1.6773e-04,  4.4881e-01],
         [-2.1881e-03,  3.1080e-01],
         [-3.2404e-03,  2.3807e-01]]])
agent 0 action: VehicleControl(throttle=0.198797, steer=0.005148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.41890621000961
+++++++++++++: 1.278899980141607
12.0374586712569 seconds in game passed.
At 12.0374586712569 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0022,  1.0000],
         [-0.0051,  1.0000],
         [-0.0089,  1.0000],
         [-0.0104,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004235, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.278899980141607
Current reward: 0.3918364066172122
Current mitigation activation: 1
#############################
Total reward: 26.810742616626822
12.062458671629429 seconds in game passed.
Action: tensor([[[-0.0022,  1.0000],
         [-0.0051,  1.0000],
         [-0.0089,  1.0000],
         [-0.0104,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002690, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.810742616626822
12.087458672001958 seconds in game passed.
Action: tensor([[[-0.0022,  1.0000],
         [-0.0051,  1.0000],
         [-0.0089,  1.0000],
         [-0.0104,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002707, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.810742616626822
12.112458672374487 seconds in game passed.
Action: tensor([[[-0.0022,  1.0000],
         [-0.0051,  1.0000],
         [-0.0089,  1.0000],
         [-0.0104,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002723, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.810742616626822
+++++++++++++: 1.2563874376128925
12.137458672747016 seconds in game passed.
At 12.137458672747016 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0026,  1.0000],
         [-0.0037,  1.0000],
         [-0.0083,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001175, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2563874376128925
Current reward: 0.3853322736063229
Current mitigation activation: 1
#############################
Total reward: 27.196074890233145
12.162458673119545 seconds in game passed.
Action: tensor([[[ 0.0026,  1.0000],
         [-0.0037,  1.0000],
         [-0.0083,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000510, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.196074890233145
12.187458673492074 seconds in game passed.
Action: tensor([[[ 0.0026,  1.0000],
         [-0.0037,  1.0000],
         [-0.0083,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000498, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.196074890233145
12.212458673864603 seconds in game passed.
Action: tensor([[[ 0.0026,  1.0000],
         [-0.0037,  1.0000],
         [-0.0083,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000485, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.196074890233145
+++++++++++++: 1.275422440078896
12.237458674237132 seconds in game passed.
At 12.237458674237132 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0049,  1.0000],
         [-0.0181,  1.0000],
         [-0.0216,  1.0000],
         [-0.0201,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007227, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.275422440078896
Current reward: 0.37140967385367074
Current mitigation activation: 1
#############################
Total reward: 27.567484564086815
12.262458674609661 seconds in game passed.
Action: tensor([[[ 0.0049,  1.0000],
         [-0.0181,  1.0000],
         [-0.0216,  1.0000],
         [-0.0201,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006038, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.567484564086815
12.28745867498219 seconds in game passed.
Action: tensor([[[ 0.0049,  1.0000],
         [-0.0181,  1.0000],
         [-0.0216,  1.0000],
         [-0.0201,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006121, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.567484564086815
12.31245867535472 seconds in game passed.
Action: tensor([[[ 0.0049,  1.0000],
         [-0.0181,  1.0000],
         [-0.0216,  1.0000],
         [-0.0201,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006203, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.567484564086815
+++++++++++++: 1.3608276582762835
12.337458675727248 seconds in game passed.
At 12.337458675727248 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0062,  0.9409],
         [-0.0141,  0.5644],
         [-0.0155,  0.3687],
         [-0.0138,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005673, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3608276582762835
Current reward: 0.3481804106224436
Current mitigation activation: 0
#############################
Total reward: 27.91566497470926
12.362458676099777 seconds in game passed.
Action: tensor([[[ 0.0062,  0.9409],
         [-0.0141,  0.5644],
         [-0.0155,  0.3687],
         [-0.0138,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005886, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.91566497470926
12.387458676472306 seconds in game passed.
Action: tensor([[[ 0.0062,  0.9409],
         [-0.0141,  0.5644],
         [-0.0155,  0.3687],
         [-0.0138,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005993, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.91566497470926
12.412458676844835 seconds in game passed.
Action: tensor([[[ 0.0062,  0.9409],
         [-0.0141,  0.5644],
         [-0.0155,  0.3687],
         [-0.0138,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006100, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.91566497470926
+++++++++++++: 1.4980750814306167
12.437458677217364 seconds in game passed.
At 12.437458677217364 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0033,  0.9447],
         [-0.0160,  0.5816],
         [-0.0167,  0.3675],
         [-0.0150,  0.2690]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008816, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4980750814306167
Current reward: 0.3224447972647399
Current mitigation activation: 0
#############################
Total reward: 28.238109771974
12.462458677589893 seconds in game passed.
Action: tensor([[[ 0.0033,  0.9447],
         [-0.0160,  0.5816],
         [-0.0167,  0.3675],
         [-0.0150,  0.2690]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008519, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.238109771974
12.487458677962422 seconds in game passed.
Action: tensor([[[ 0.0033,  0.9447],
         [-0.0160,  0.5816],
         [-0.0167,  0.3675],
         [-0.0150,  0.2690]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008652, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.238109771974
12.512458678334951 seconds in game passed.
Action: tensor([[[ 0.0033,  0.9447],
         [-0.0160,  0.5816],
         [-0.0167,  0.3675],
         [-0.0150,  0.2690]]])
agent 0 action: VehicleControl(throttle=0.002968, steer=-0.008786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.238109771974
+++++++++++++: 1.683787286122171
12.53745867870748 seconds in game passed.
At 12.53745867870748 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0095,  0.9459],
         [-0.0139,  0.6078],
         [-0.0159,  0.3797],
         [-0.0133,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004325, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.683787286122171
Current reward: 0.29763150747127476
Current mitigation activation: 0
#############################
Total reward: 28.535741279445276
12.56245867908001 seconds in game passed.
Action: tensor([[[ 0.0095,  0.9459],
         [-0.0139,  0.6078],
         [-0.0159,  0.3797],
         [-0.0133,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005191, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.535741279445276
12.587458679452538 seconds in game passed.
Action: tensor([[[ 0.0095,  0.9459],
         [-0.0139,  0.6078],
         [-0.0159,  0.3797],
         [-0.0133,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005297, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.535741279445276
12.612458679825068 seconds in game passed.
Action: tensor([[[ 0.0095,  0.9459],
         [-0.0139,  0.6078],
         [-0.0159,  0.3797],
         [-0.0133,  0.2747]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.535741279445276
+++++++++++++: 1.9209520375966884
12.637458680197597 seconds in game passed.
At 12.637458680197597 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0066,  0.9458],
         [-0.0094,  0.6088],
         [-0.0099,  0.3766],
         [-0.0071,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9209520375966884
Current reward: 0.2751708315345004
Current mitigation activation: 0
#############################
Total reward: 28.810912110979775
12.662458680570126 seconds in game passed.
Action: tensor([[[ 0.0066,  0.9458],
         [-0.0094,  0.6088],
         [-0.0099,  0.3766],
         [-0.0071,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.810912110979775
12.687458680942655 seconds in game passed.
Action: tensor([[[ 0.0066,  0.9458],
         [-0.0094,  0.6088],
         [-0.0099,  0.3766],
         [-0.0071,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.810912110979775
12.712458681315184 seconds in game passed.
Action: tensor([[[ 0.0066,  0.9458],
         [-0.0094,  0.6088],
         [-0.0099,  0.3766],
         [-0.0071,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.810912110979775
+++++++++++++: 2.1857872881043634
12.737458681687713 seconds in game passed.
At 12.737458681687713 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0128, 0.9417],
         [0.0036, 0.5620],
         [0.0015, 0.3652],
         [0.0034, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.497393, steer=0.007920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1857872881043634
Current reward: 0.2573765291579473
Current mitigation activation: 0
#############################
Total reward: 29.068288640137723
12.762458682060242 seconds in game passed.
Action: tensor([[[0.0128, 0.9417],
         [0.0036, 0.5620],
         [0.0015, 0.3652],
         [0.0034, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.469160, steer=0.005919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.068288640137723
12.78745868243277 seconds in game passed.
Action: tensor([[[0.0128, 0.9417],
         [0.0036, 0.5620],
         [0.0015, 0.3652],
         [0.0034, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.525714, steer=0.005930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.068288640137723
12.8124586828053 seconds in game passed.
Action: tensor([[[0.0128, 0.9417],
         [0.0036, 0.5620],
         [0.0015, 0.3652],
         [0.0034, 0.2622]]])
agent 0 action: VehicleControl(throttle=0.574610, steer=0.005940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.068288640137723
+++++++++++++: 2.3396948490414142
12.837458683177829 seconds in game passed.
At 12.837458683177829 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0101, 0.9389],
         [0.0055, 0.5491],
         [0.0016, 0.3611],
         [0.0014, 0.2618]]])
agent 0 action: VehicleControl(throttle=0.769424, steer=0.006166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3396948490414142
Current reward: 0.2503937642577978
Current mitigation activation: 0
#############################
Total reward: 29.31868240439552
12.862458683550358 seconds in game passed.
Action: tensor([[[0.0101, 0.9389],
         [0.0055, 0.5491],
         [0.0016, 0.3611],
         [0.0014, 0.2618]]])
agent 0 action: VehicleControl(throttle=0.792829, steer=0.006195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.31868240439552
12.887458683922887 seconds in game passed.
Action: tensor([[[0.0101, 0.9389],
         [0.0055, 0.5491],
         [0.0016, 0.3611],
         [0.0014, 0.2618]]])
agent 0 action: VehicleControl(throttle=0.825218, steer=0.006253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.31868240439552
12.912458684295416 seconds in game passed.
Action: tensor([[[0.0101, 0.9389],
         [0.0055, 0.5491],
         [0.0016, 0.3611],
         [0.0014, 0.2618]]])
agent 0 action: VehicleControl(throttle=0.849668, steer=0.006310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.31868240439552
+++++++++++++: 2.528868082422393
12.937458684667945 seconds in game passed.
At 12.937458684667945 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.9171e-03, 9.3032e-01],
         [4.1196e-03, 5.1754e-01],
         [8.7529e-04, 3.4290e-01],
         [9.5539e-04, 2.5031e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.528868082422393
Current reward: 0.2432675814165096
Current mitigation activation: 0
#############################
Total reward: 29.56194998581203
12.962458685040474 seconds in game passed.
Action: tensor([[[7.9171e-03, 9.3032e-01],
         [4.1196e-03, 5.1754e-01],
         [8.7529e-04, 3.4290e-01],
         [9.5539e-04, 2.5031e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.56194998581203
12.987458685413003 seconds in game passed.
Action: tensor([[[7.9171e-03, 9.3032e-01],
         [4.1196e-03, 5.1754e-01],
         [8.7529e-04, 3.4290e-01],
         [9.5539e-04, 2.5031e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.56194998581203
13.012458685785532 seconds in game passed.
Action: tensor([[[7.9171e-03, 9.3032e-01],
         [4.1196e-03, 5.1754e-01],
         [8.7529e-04, 3.4290e-01],
         [9.5539e-04, 2.5031e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.56194998581203
+++++++++++++: 2.5780960232387486
13.037458686158061 seconds in game passed.
At 13.037458686158061 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.9261],
         [0.0049, 0.5119],
         [0.0028, 0.3418],
         [0.0028, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5780960232387486
Current reward: 0.2439029752759712
Current mitigation activation: 0
#############################
Total reward: 29.805852961088004
13.06245868653059 seconds in game passed.
Action: tensor([[[0.0033, 0.9261],
         [0.0049, 0.5119],
         [0.0028, 0.3418],
         [0.0028, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.805852961088004
13.087458686903119 seconds in game passed.
Action: tensor([[[0.0033, 0.9261],
         [0.0049, 0.5119],
         [0.0028, 0.3418],
         [0.0028, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.805852961088004
13.112458687275648 seconds in game passed.
Action: tensor([[[0.0033, 0.9261],
         [0.0049, 0.5119],
         [0.0028, 0.3418],
         [0.0028, 0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.805852961088004
+++++++++++++: 2.507397887741517
13.137458687648177 seconds in game passed.
At 13.137458687648177 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.5294e-03, 9.1016e-01],
         [3.5903e-03, 4.9222e-01],
         [9.0808e-04, 3.3087e-01],
         [7.4278e-04, 2.4504e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.507397887741517
Current reward: 0.2502007766289328
Current mitigation activation: 0
#############################
Total reward: 30.056053737716937
13.162458688020706 seconds in game passed.
Action: tensor([[[4.5294e-03, 9.1016e-01],
         [3.5903e-03, 4.9222e-01],
         [9.0808e-04, 3.3087e-01],
         [7.4278e-04, 2.4504e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.056053737716937
13.187458688393235 seconds in game passed.
Action: tensor([[[4.5294e-03, 9.1016e-01],
         [3.5903e-03, 4.9222e-01],
         [9.0808e-04, 3.3087e-01],
         [7.4278e-04, 2.4504e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.056053737716937
13.212458688765764 seconds in game passed.
Action: tensor([[[4.5294e-03, 9.1016e-01],
         [3.5903e-03, 4.9222e-01],
         [9.0808e-04, 3.3087e-01],
         [7.4278e-04, 2.4504e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.056053737716937
+++++++++++++: 2.3845564762408658
13.237458689138293 seconds in game passed.
At 13.237458689138293 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.7607e-04,  8.9967e-01],
         [ 4.2349e-05,  4.8572e-01],
         [-1.4925e-03,  3.3214e-01],
         [-7.8538e-04,  2.4950e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3845564762408658
Current reward: 0.2591615205167106
Current mitigation activation: 0
#############################
Total reward: 30.315215258233646
13.262458689510822 seconds in game passed.
Action: tensor([[[-1.7607e-04,  8.9967e-01],
         [ 4.2349e-05,  4.8572e-01],
         [-1.4925e-03,  3.3214e-01],
         [-7.8538e-04,  2.4950e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.315215258233646
13.287458689883351 seconds in game passed.
Action: tensor([[[-1.7607e-04,  8.9967e-01],
         [ 4.2349e-05,  4.8572e-01],
         [-1.4925e-03,  3.3214e-01],
         [-7.8538e-04,  2.4950e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.315215258233646
13.31245869025588 seconds in game passed.
Action: tensor([[[-1.7607e-04,  8.9967e-01],
         [ 4.2349e-05,  4.8572e-01],
         [-1.4925e-03,  3.3214e-01],
         [-7.8538e-04,  2.4950e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.315215258233646
+++++++++++++: 2.2471194543326773
13.33745869062841 seconds in game passed.
At 13.33745869062841 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0107,  0.9063],
         [-0.0017,  0.5055],
         [-0.0024,  0.3510],
         [-0.0019,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2471194543326773
Current reward: 0.26919131485849407
Current mitigation activation: 0
#############################
Total reward: 30.58440657309214
13.362458691000938 seconds in game passed.
Action: tensor([[[-0.0107,  0.9063],
         [-0.0017,  0.5055],
         [-0.0024,  0.3510],
         [-0.0019,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.58440657309214
13.387458691373467 seconds in game passed.
Action: tensor([[[-0.0107,  0.9063],
         [-0.0017,  0.5055],
         [-0.0024,  0.3510],
         [-0.0019,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.58440657309214
13.412458691745996 seconds in game passed.
Action: tensor([[[-0.0107,  0.9063],
         [-0.0017,  0.5055],
         [-0.0024,  0.3510],
         [-0.0019,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.58440657309214
+++++++++++++: 2.1109733611933774
13.437458692118526 seconds in game passed.
At 13.437458692118526 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0064,  0.9060],
         [-0.0029,  0.5183],
         [-0.0036,  0.3734],
         [-0.0024,  0.2955]]])
agent 0 action: VehicleControl(throttle=0.800846, steer=-0.003589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1109733611933774
Current reward: 0.279504013869731
Current mitigation activation: 0
#############################
Total reward: 30.863910586961868
13.462458692491055 seconds in game passed.
Action: tensor([[[-0.0064,  0.9060],
         [-0.0029,  0.5183],
         [-0.0036,  0.3734],
         [-0.0024,  0.2955]]])
agent 0 action: VehicleControl(throttle=0.789367, steer=-0.003676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.863910586961868
13.487458692863584 seconds in game passed.
Action: tensor([[[-0.0064,  0.9060],
         [-0.0029,  0.5183],
         [-0.0036,  0.3734],
         [-0.0024,  0.2955]]])
agent 0 action: VehicleControl(throttle=0.757370, steer=-0.003621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.863910586961868
13.512458693236113 seconds in game passed.
Action: tensor([[[-0.0064,  0.9060],
         [-0.0029,  0.5183],
         [-0.0036,  0.3734],
         [-0.0024,  0.2955]]])
agent 0 action: VehicleControl(throttle=0.725957, steer=-0.003565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.863910586961868
+++++++++++++: 1.9827937787616259
13.537458693608642 seconds in game passed.
At 13.537458693608642 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.8813],
         [-0.0018,  0.5067],
         [-0.0034,  0.3692],
         [-0.0026,  0.2936]]])
agent 0 action: VehicleControl(throttle=0.747247, steer=0.000501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9827937787616259
Current reward: 0.28963414449344804
Current mitigation activation: 0
#############################
Total reward: 31.153544731455316
13.56245869398117 seconds in game passed.
Action: tensor([[[ 0.0011,  0.8813],
         [-0.0018,  0.5067],
         [-0.0034,  0.3692],
         [-0.0026,  0.2936]]])
agent 0 action: VehicleControl(throttle=0.712339, steer=-0.000118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.153544731455316
13.5874586943537 seconds in game passed.
Action: tensor([[[ 0.0011,  0.8813],
         [-0.0018,  0.5067],
         [-0.0034,  0.3692],
         [-0.0026,  0.2936]]])
agent 0 action: VehicleControl(throttle=0.683892, steer=-0.000068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.153544731455316
13.612458694726229 seconds in game passed.
Action: tensor([[[ 0.0011,  0.8813],
         [-0.0018,  0.5067],
         [-0.0034,  0.3692],
         [-0.0026,  0.2936]]])
agent 0 action: VehicleControl(throttle=0.656177, steer=-0.000018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.153544731455316
+++++++++++++: 1.8723859953511799
13.637458695098758 seconds in game passed.
At 13.637458695098758 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0046,  0.8968],
         [-0.0009,  0.5043],
         [-0.0023,  0.3582],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.743042, steer=-0.001741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8723859953511799
Current reward: 0.29862592405591254
Current mitigation activation: 0
#############################
Total reward: 31.452170655511228
13.662458695471287 seconds in game passed.
Action: tensor([[[-0.0046,  0.8968],
         [-0.0009,  0.5043],
         [-0.0023,  0.3582],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.706873, steer=-0.001441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.452170655511228
13.687458695843816 seconds in game passed.
Action: tensor([[[-0.0046,  0.8968],
         [-0.0009,  0.5043],
         [-0.0023,  0.3582],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.683789, steer=-0.001430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.452170655511228
13.712458696216345 seconds in game passed.
Action: tensor([[[-0.0046,  0.8968],
         [-0.0009,  0.5043],
         [-0.0023,  0.3582],
         [-0.0022,  0.2796]]])
agent 0 action: VehicleControl(throttle=0.660951, steer=-0.001419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.452170655511228
+++++++++++++: 1.7822799498362139
13.737458696588874 seconds in game passed.
At 13.737458696588874 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.9277],
         [-0.0027,  0.5166],
         [-0.0046,  0.3532],
         [-0.0040,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.593860, steer=-0.002400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7822799498362139
Current reward: 0.30590709492280355
Current mitigation activation: 0
#############################
Total reward: 31.758077750434033
13.762458696961403 seconds in game passed.
Action: tensor([[[-0.0034,  0.9277],
         [-0.0027,  0.5166],
         [-0.0046,  0.3532],
         [-0.0040,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.570594, steer=-0.002381, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.758077750434033
13.787458697333932 seconds in game passed.
Action: tensor([[[-0.0034,  0.9277],
         [-0.0027,  0.5166],
         [-0.0046,  0.3532],
         [-0.0040,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.543731, steer=-0.002504, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.758077750434033
13.812458697706461 seconds in game passed.
Action: tensor([[[-0.0034,  0.9277],
         [-0.0027,  0.5166],
         [-0.0046,  0.3532],
         [-0.0040,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.518027, steer=-0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.758077750434033
+++++++++++++: 1.7075095533810392
13.83745869807899 seconds in game passed.
At 13.83745869807899 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0039,  0.9363],
         [-0.0059,  0.5221],
         [-0.0083,  0.3463],
         [-0.0067,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.450858, steer=-0.002047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7075095533810392
Current reward: 0.3116500400203932
Current mitigation activation: 0
#############################
Total reward: 32.06972779045443
13.862458698451519 seconds in game passed.
Action: tensor([[[ 0.0039,  0.9363],
         [-0.0059,  0.5221],
         [-0.0083,  0.3463],
         [-0.0067,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.430152, steer=-0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.06972779045443
13.887458698824048 seconds in game passed.
Action: tensor([[[ 0.0039,  0.9363],
         [-0.0059,  0.5221],
         [-0.0083,  0.3463],
         [-0.0067,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.406939, steer=-0.002399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.06972779045443
13.912458699196577 seconds in game passed.
Action: tensor([[[ 0.0039,  0.9363],
         [-0.0059,  0.5221],
         [-0.0083,  0.3463],
         [-0.0067,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.386131, steer=-0.002517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.06972779045443
+++++++++++++: 1.6513988210028492
13.937458699569106 seconds in game passed.
At 13.937458699569106 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0040,  0.9420],
         [-0.0048,  0.5467],
         [-0.0067,  0.3537],
         [-0.0043,  0.2595]]])
agent 0 action: VehicleControl(throttle=0.316824, steer=-0.001647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6513988210028492
Current reward: 0.31528357992804334
Current mitigation activation: 0
#############################
Total reward: 32.38501137038247
13.962458699941635 seconds in game passed.
Action: tensor([[[ 0.0040,  0.9420],
         [-0.0048,  0.5467],
         [-0.0067,  0.3537],
         [-0.0043,  0.2595]]])
agent 0 action: VehicleControl(throttle=0.308558, steer=-0.001893, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.38501137038247
13.987458700314164 seconds in game passed.
Action: tensor([[[ 0.0040,  0.9420],
         [-0.0048,  0.5467],
         [-0.0067,  0.3537],
         [-0.0043,  0.2595]]])
agent 0 action: VehicleControl(throttle=0.294318, steer=-0.001979, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.38501137038247
14.012458700686693 seconds in game passed.
Action: tensor([[[ 0.0040,  0.9420],
         [-0.0048,  0.5467],
         [-0.0067,  0.3537],
         [-0.0043,  0.2595]]])
agent 0 action: VehicleControl(throttle=0.280223, steer=-0.002066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.38501137038247
+++++++++++++: 1.618985889511975
14.037458701059222 seconds in game passed.
At 14.037458701059222 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0093,  0.9434],
         [-0.0011,  0.5625],
         [-0.0038,  0.3634],
         [-0.0021,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003038, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.618985889511975
Current reward: 0.31609013449541257
Current mitigation activation: 0
#############################
Total reward: 32.70110150487788
14.062458701431751 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9434],
         [-0.0011,  0.5625],
         [-0.0038,  0.3634],
         [-0.0021,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002166, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.70110150487788
14.08745870180428 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9434],
         [-0.0011,  0.5625],
         [-0.0038,  0.3634],
         [-0.0021,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002147, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.70110150487788
14.11245870217681 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9434],
         [-0.0011,  0.5625],
         [-0.0038,  0.3634],
         [-0.0021,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002128, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.70110150487788
+++++++++++++: 1.6162273256828716
14.137458702549338 seconds in game passed.
At 14.137458702549338 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0048,  0.9430],
         [-0.0051,  0.5623],
         [-0.0071,  0.3618],
         [-0.0051,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.207461, steer=-0.002856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6162273256828716
Current reward: 0.31343223013958255
Current mitigation activation: 0
#############################
Total reward: 33.014533735017466
14.162458702921867 seconds in game passed.
Action: tensor([[[ 0.0048,  0.9430],
         [-0.0051,  0.5623],
         [-0.0071,  0.3618],
         [-0.0051,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.191875, steer=-0.002101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.014533735017466
14.187458703294396 seconds in game passed.
Action: tensor([[[ 0.0048,  0.9430],
         [-0.0051,  0.5623],
         [-0.0071,  0.3618],
         [-0.0051,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.176681, steer=-0.002166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.014533735017466
14.212458703666925 seconds in game passed.
Action: tensor([[[ 0.0048,  0.9430],
         [-0.0051,  0.5623],
         [-0.0071,  0.3618],
         [-0.0051,  0.2631]]])
agent 0 action: VehicleControl(throttle=0.161895, steer=-0.002231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.014533735017466
+++++++++++++: 1.6738769493174823
14.237458704039454 seconds in game passed.
At 14.237458704039454 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.9419],
         [-0.0013,  0.5586],
         [-0.0035,  0.3632],
         [-0.0030,  0.2669]]])
agent 0 action: VehicleControl(throttle=0.146907, steer=-0.002197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6738769493174823
Current reward: 0.30445322848662804
Current mitigation activation: 0
#############################
Total reward: 33.318986963504095
14.262458704411983 seconds in game passed.
Action: tensor([[[-0.0014,  0.9419],
         [-0.0013,  0.5586],
         [-0.0035,  0.3632],
         [-0.0030,  0.2669]]])
agent 0 action: VehicleControl(throttle=0.132351, steer=-0.002221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.318986963504095
14.287458704784513 seconds in game passed.
Action: tensor([[[-0.0014,  0.9419],
         [-0.0013,  0.5586],
         [-0.0035,  0.3632],
         [-0.0030,  0.2669]]])
agent 0 action: VehicleControl(throttle=0.118235, steer=-0.002237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.318986963504095
14.312458705157042 seconds in game passed.
Action: tensor([[[-0.0014,  0.9419],
         [-0.0013,  0.5586],
         [-0.0035,  0.3632],
         [-0.0030,  0.2669]]])
agent 0 action: VehicleControl(throttle=0.104567, steer=-0.002253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.318986963504095
+++++++++++++: 1.743839430214337
14.33745870552957 seconds in game passed.
At 14.33745870552957 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.0168e-03,  9.4293e-01],
         [ 3.1412e-04,  5.6150e-01],
         [-5.7247e-04,  3.5970e-01],
         [-7.8917e-05,  2.6008e-01]]])
agent 0 action: VehicleControl(throttle=0.094495, steer=-0.002166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.743839430214337
Current reward: 0.2955139290285791
Current mitigation activation: 0
#############################
Total reward: 33.614500892532675
14.3624587059021 seconds in game passed.
Action: tensor([[[-4.0168e-03,  9.4293e-01],
         [ 3.1412e-04,  5.6150e-01],
         [-5.7247e-04,  3.5970e-01],
         [-7.8917e-05,  2.6008e-01]]])
agent 0 action: VehicleControl(throttle=0.084881, steer=-0.002129, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.614500892532675
14.387458706274629 seconds in game passed.
Action: tensor([[[-4.0168e-03,  9.4293e-01],
         [ 3.1412e-04,  5.6150e-01],
         [-5.7247e-04,  3.5970e-01],
         [-7.8917e-05,  2.6008e-01]]])
agent 0 action: VehicleControl(throttle=0.075728, steer=-0.002085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.614500892532675
14.412458706647158 seconds in game passed.
Action: tensor([[[-4.0168e-03,  9.4293e-01],
         [ 3.1412e-04,  5.6150e-01],
         [-5.7247e-04,  3.5970e-01],
         [-7.8917e-05,  2.6008e-01]]])
agent 0 action: VehicleControl(throttle=0.067040, steer=-0.002041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.614500892532675
+++++++++++++: 1.8211868345941402
14.437458707019687 seconds in game passed.
At 14.437458707019687 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.6860e-03,  9.4221e-01],
         [ 2.0185e-03,  5.7386e-01],
         [ 3.8965e-04,  3.7531e-01],
         [-2.0728e-04,  2.7711e-01]]])
agent 0 action: VehicleControl(throttle=0.060946, steer=-0.001523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8211868345941402
Current reward: 0.2872536070500129
Current mitigation activation: 0
#############################
Total reward: 33.90175449958269
14.462458707392216 seconds in game passed.
Action: tensor([[[-5.6860e-03,  9.4221e-01],
         [ 2.0185e-03,  5.7386e-01],
         [ 3.8965e-04,  3.7531e-01],
         [-2.0728e-04,  2.7711e-01]]])
agent 0 action: VehicleControl(throttle=0.055321, steer=-0.001563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.90175449958269
14.487458707764745 seconds in game passed.
Action: tensor([[[-5.6860e-03,  9.4221e-01],
         [ 2.0185e-03,  5.7386e-01],
         [ 3.8965e-04,  3.7531e-01],
         [-2.0728e-04,  2.7711e-01]]])
agent 0 action: VehicleControl(throttle=0.050161, steer=-0.001522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.90175449958269
14.512458708137274 seconds in game passed.
Action: tensor([[[-5.6860e-03,  9.4221e-01],
         [ 2.0185e-03,  5.7386e-01],
         [ 3.8965e-04,  3.7531e-01],
         [-2.0728e-04,  2.7711e-01]]])
agent 0 action: VehicleControl(throttle=0.045454, steer=-0.001482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.90175449958269
+++++++++++++: 1.9159067579640858
14.537458708509803 seconds in game passed.
At 14.537458708509803 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0125,  0.9428],
         [-0.0032,  0.5703],
         [-0.0032,  0.3643],
         [-0.0028,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.103986, steer=-0.008434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9159067579640858
Current reward: 0.27888844811023994
Current mitigation activation: 0
#############################
Total reward: 34.180642947692924
14.562458708882332 seconds in game passed.
Action: tensor([[[-0.0125,  0.9428],
         [-0.0032,  0.5703],
         [-0.0032,  0.3643],
         [-0.0028,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.129867, steer=-0.007361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.180642947692924
14.58745870925486 seconds in game passed.
Action: tensor([[[-0.0125,  0.9428],
         [-0.0032,  0.5703],
         [-0.0032,  0.3643],
         [-0.0028,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.159338, steer=-0.007434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.180642947692924
14.61245870962739 seconds in game passed.
Action: tensor([[[-0.0125,  0.9428],
         [-0.0032,  0.5703],
         [-0.0032,  0.3643],
         [-0.0028,  0.2647]]])
agent 0 action: VehicleControl(throttle=0.188839, steer=-0.007508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.180642947692924
+++++++++++++: 2.0298015767392443
14.637458709999919 seconds in game passed.
At 14.637458709999919 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0163,  0.9449],
         [-0.0035,  0.5800],
         [-0.0029,  0.3645],
         [-0.0021,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.111296, steer=-0.009596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0298015767392443
Current reward: 0.27057083609500643
Current mitigation activation: 0
#############################
Total reward: 34.45121378378793
14.662458710372448 seconds in game passed.
Action: tensor([[[-0.0163,  0.9449],
         [-0.0035,  0.5800],
         [-0.0029,  0.3645],
         [-0.0021,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.148841, steer=-0.009337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.45121378378793
14.687458710744977 seconds in game passed.
Action: tensor([[[-0.0163,  0.9449],
         [-0.0035,  0.5800],
         [-0.0029,  0.3645],
         [-0.0021,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.175044, steer=-0.009413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.45121378378793
14.712458711117506 seconds in game passed.
Action: tensor([[[-0.0163,  0.9449],
         [-0.0035,  0.5800],
         [-0.0029,  0.3645],
         [-0.0021,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.201463, steer=-0.009489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.45121378378793
+++++++++++++: 2.15402065589047
14.737458711490035 seconds in game passed.
At 14.737458711490035 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0161,  0.9478],
         [-0.0051,  0.6129],
         [-0.0034,  0.3749],
         [-0.0020,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.000869, steer=-0.010868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.15402065589047
Current reward: 0.2631351791079368
Current mitigation activation: 0
#############################
Total reward: 34.71434896289586
14.762458711862564 seconds in game passed.
Action: tensor([[[-0.0161,  0.9478],
         [-0.0051,  0.6129],
         [-0.0034,  0.3749],
         [-0.0020,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.019300, steer=-0.010733, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71434896289586
14.787458712235093 seconds in game passed.
Action: tensor([[[-0.0161,  0.9478],
         [-0.0051,  0.6129],
         [-0.0034,  0.3749],
         [-0.0020,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.017173, steer=-0.010814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71434896289586
14.812458712607622 seconds in game passed.
Action: tensor([[[-0.0161,  0.9478],
         [-0.0051,  0.6129],
         [-0.0034,  0.3749],
         [-0.0020,  0.2682]]])
agent 0 action: VehicleControl(throttle=0.015308, steer=-0.010894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71434896289586
+++++++++++++: 2.284562216373476
14.837458712980151 seconds in game passed.
At 14.837458712980151 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.3215e-02,  9.4604e-01],
         [-1.3820e-03,  5.8175e-01],
         [-4.7928e-04,  3.6518e-01],
         [ 6.2246e-04,  2.6248e-01]]])
agent 0 action: VehicleControl(throttle=0.344433, steer=-0.006690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.284562216373476
Current reward: 0.2567808844673744
Current mitigation activation: 0
#############################
Total reward: 34.97112984736324
14.86245871335268 seconds in game passed.
Action: tensor([[[-1.3215e-02,  9.4604e-01],
         [-1.3820e-03,  5.8175e-01],
         [-4.7928e-04,  3.6518e-01],
         [ 6.2246e-04,  2.6248e-01]]])
agent 0 action: VehicleControl(throttle=0.343572, steer=-0.007442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.97112984736324
14.88745871372521 seconds in game passed.
Action: tensor([[[-1.3215e-02,  9.4604e-01],
         [-1.3820e-03,  5.8175e-01],
         [-4.7928e-04,  3.6518e-01],
         [ 6.2246e-04,  2.6248e-01]]])
agent 0 action: VehicleControl(throttle=0.374905, steer=-0.007485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.97112984736324
14.912458714097738 seconds in game passed.
Action: tensor([[[-1.3215e-02,  9.4604e-01],
         [-1.3820e-03,  5.8175e-01],
         [-4.7928e-04,  3.6518e-01],
         [ 6.2246e-04,  2.6248e-01]]])
agent 0 action: VehicleControl(throttle=0.404886, steer=-0.007529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.97112984736324
+++++++++++++: 2.4363726723746297
14.937458714470267 seconds in game passed.
At 14.937458714470267 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.8002e-03,  9.3990e-01],
         [ 9.2709e-04,  5.3353e-01],
         [-4.4819e-04,  3.4684e-01],
         [-1.2841e-04,  2.5287e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001871, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4363726723746297
Current reward: 0.25061639103491185
Current mitigation activation: 0
#############################
Total reward: 35.22174623839815
14.962458714842796 seconds in game passed.
Action: tensor([[[-4.8002e-03,  9.3990e-01],
         [ 9.2709e-04,  5.3353e-01],
         [-4.4819e-04,  3.4684e-01],
         [-1.2841e-04,  2.5287e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.22174623839815
14.987458715215325 seconds in game passed.
Action: tensor([[[-4.8002e-03,  9.3990e-01],
         [ 9.2709e-04,  5.3353e-01],
         [-4.4819e-04,  3.4684e-01],
         [-1.2841e-04,  2.5287e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.22174623839815
15.012458715587854 seconds in game passed.
Action: tensor([[[-4.8002e-03,  9.3990e-01],
         [ 9.2709e-04,  5.3353e-01],
         [-4.4819e-04,  3.4684e-01],
         [-1.2841e-04,  2.5287e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.22174623839815
+++++++++++++: 2.5704671423826317
15.037458715960383 seconds in game passed.
At 15.037458715960383 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0411e-03, 9.2279e-01],
         [2.6364e-03, 4.9406e-01],
         [7.1163e-04, 3.2558e-01],
         [8.3717e-04, 2.3684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5704671423826317
Current reward: 0.2466034185563986
Current mitigation activation: 0
#############################
Total reward: 35.468349656954544
15.062458716332912 seconds in game passed.
Action: tensor([[[1.0411e-03, 9.2279e-01],
         [2.6364e-03, 4.9406e-01],
         [7.1163e-04, 3.2558e-01],
         [8.3717e-04, 2.3684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.468349656954544
15.087458716705441 seconds in game passed.
Action: tensor([[[1.0411e-03, 9.2279e-01],
         [2.6364e-03, 4.9406e-01],
         [7.1163e-04, 3.2558e-01],
         [8.3717e-04, 2.3684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.468349656954544
15.11245871707797 seconds in game passed.
Action: tensor([[[1.0411e-03, 9.2279e-01],
         [2.6364e-03, 4.9406e-01],
         [7.1163e-04, 3.2558e-01],
         [8.3717e-04, 2.3684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.468349656954544
+++++++++++++: 2.599435602109017
15.1374587174505 seconds in game passed.
At 15.1374587174505 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.4464e-04,  9.0950e-01],
         [ 2.4712e-03,  4.8378e-01],
         [-1.3031e-04,  3.2389e-01],
         [-4.9908e-04,  2.3813e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.599435602109017
Current reward: 0.2481048378344336
Current mitigation activation: 0
#############################
Total reward: 35.71645449478898
15.162458717823029 seconds in game passed.
Action: tensor([[[-5.4464e-04,  9.0950e-01],
         [ 2.4712e-03,  4.8378e-01],
         [-1.3031e-04,  3.2389e-01],
         [-4.9908e-04,  2.3813e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.71645449478898
15.187458718195558 seconds in game passed.
Action: tensor([[[-5.4464e-04,  9.0950e-01],
         [ 2.4712e-03,  4.8378e-01],
         [-1.3031e-04,  3.2389e-01],
         [-4.9908e-04,  2.3813e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.71645449478898
15.212458718568087 seconds in game passed.
Action: tensor([[[-5.4464e-04,  9.0950e-01],
         [ 2.4712e-03,  4.8378e-01],
         [-1.3031e-04,  3.2389e-01],
         [-4.9908e-04,  2.3813e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.71645449478898
+++++++++++++: 2.5191782241150293
15.237458718940616 seconds in game passed.
At 15.237458718940616 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0072,  0.9013],
         [ 0.0018,  0.4756],
         [-0.0011,  0.3164],
         [-0.0011,  0.2310]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5191782241150293
Current reward: 0.25475244524067
Current mitigation activation: 0
#############################
Total reward: 35.971206940029646
15.262458719313145 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9013],
         [ 0.0018,  0.4756],
         [-0.0011,  0.3164],
         [-0.0011,  0.2310]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002152, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.971206940029646
15.287458719685674 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9013],
         [ 0.0018,  0.4756],
         [-0.0011,  0.3164],
         [-0.0011,  0.2310]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.971206940029646
15.312458720058203 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9013],
         [ 0.0018,  0.4756],
         [-0.0011,  0.3164],
         [-0.0011,  0.2310]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.971206940029646
+++++++++++++: 2.426403091042007
15.337458720430732 seconds in game passed.
At 15.337458720430732 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4008e-02, 8.8917e-01],
         [3.5138e-03, 4.7793e-01],
         [8.4747e-04, 3.1983e-01],
         [8.0941e-04, 2.3306e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.426403091042007
Current reward: 0.2619945399668142
Current mitigation activation: 0
#############################
Total reward: 36.23320147999646
15.36245872080326 seconds in game passed.
Action: tensor([[[1.4008e-02, 8.8917e-01],
         [3.5138e-03, 4.7793e-01],
         [8.4747e-04, 3.1983e-01],
         [8.0941e-04, 2.3306e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.23320147999646
15.38745872117579 seconds in game passed.
Action: tensor([[[1.4008e-02, 8.8917e-01],
         [3.5138e-03, 4.7793e-01],
         [8.4747e-04, 3.1983e-01],
         [8.0941e-04, 2.3306e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005976, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.23320147999646
15.412458721548319 seconds in game passed.
Action: tensor([[[1.4008e-02, 8.8917e-01],
         [3.5138e-03, 4.7793e-01],
         [8.4747e-04, 3.1983e-01],
         [8.0941e-04, 2.3306e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.23320147999646
+++++++++++++: 2.4399911185013496
15.437458721920848 seconds in game passed.
At 15.437458721920848 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0139, 0.8962],
         [0.0037, 0.4833],
         [0.0016, 0.3233],
         [0.0016, 0.2354]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4399911185013496
Current reward: 0.26331986591621015
Current mitigation activation: 0
#############################
Total reward: 36.49652134591267
15.462458722293377 seconds in game passed.
Action: tensor([[[0.0139, 0.8962],
         [0.0037, 0.4833],
         [0.0016, 0.3233],
         [0.0016, 0.2354]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.49652134591267
15.487458722665906 seconds in game passed.
Action: tensor([[[0.0139, 0.8962],
         [0.0037, 0.4833],
         [0.0016, 0.3233],
         [0.0016, 0.2354]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.49652134591267
15.512458723038435 seconds in game passed.
Action: tensor([[[0.0139, 0.8962],
         [0.0037, 0.4833],
         [0.0016, 0.3233],
         [0.0016, 0.2354]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.49652134591267
+++++++++++++: 2.4631228663410654
15.537458723410964 seconds in game passed.
At 15.537458723410964 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0153, 0.8883],
         [0.0036, 0.4746],
         [0.0018, 0.3185],
         [0.0021, 0.2336]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4631228663410654
Current reward: 0.26411208871442843
Current mitigation activation: 0
#############################
Total reward: 36.760633434627096
15.562458723783493 seconds in game passed.
Action: tensor([[[0.0153, 0.8883],
         [0.0036, 0.4746],
         [0.0018, 0.3185],
         [0.0021, 0.2336]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.760633434627096
15.587458724156022 seconds in game passed.
Action: tensor([[[0.0153, 0.8883],
         [0.0036, 0.4746],
         [0.0018, 0.3185],
         [0.0021, 0.2336]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.760633434627096
15.612458724528551 seconds in game passed.
Action: tensor([[[0.0153, 0.8883],
         [0.0036, 0.4746],
         [0.0018, 0.3185],
         [0.0021, 0.2336]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.760633434627096
+++++++++++++: 2.4862090360379767
15.63745872490108 seconds in game passed.
At 15.63745872490108 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0098, 0.8767],
         [0.0032, 0.4622],
         [0.0024, 0.3107],
         [0.0030, 0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4862090360379767
Current reward: 0.2649245426298166
Current mitigation activation: 0
#############################
Total reward: 37.02555797725691
15.66245872527361 seconds in game passed.
Action: tensor([[[0.0098, 0.8767],
         [0.0032, 0.4622],
         [0.0024, 0.3107],
         [0.0030, 0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.02555797725691
15.687458725646138 seconds in game passed.
Action: tensor([[[0.0098, 0.8767],
         [0.0032, 0.4622],
         [0.0024, 0.3107],
         [0.0030, 0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.02555797725691
15.712458726018667 seconds in game passed.
Action: tensor([[[0.0098, 0.8767],
         [0.0032, 0.4622],
         [0.0024, 0.3107],
         [0.0030, 0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006209, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.02555797725691
+++++++++++++: 2.509562713728032
15.737458726391196 seconds in game passed.
At 15.737458726391196 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.5814e-03,  8.7972e-01],
         [ 4.4037e-04,  4.6304e-01],
         [-1.1030e-03,  3.1114e-01],
         [-9.4344e-04,  2.2945e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.509562713728032
Current reward: 0.26573884558446303
Current mitigation activation: 0
#############################
Total reward: 37.291296822841375
15.762458726763725 seconds in game passed.
Action: tensor([[[ 6.5814e-03,  8.7972e-01],
         [ 4.4037e-04,  4.6304e-01],
         [-1.1030e-03,  3.1114e-01],
         [-9.4344e-04,  2.2945e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.291296822841375
15.787458727136254 seconds in game passed.
Action: tensor([[[ 6.5814e-03,  8.7972e-01],
         [ 4.4037e-04,  4.6304e-01],
         [-1.1030e-03,  3.1114e-01],
         [-9.4344e-04,  2.2945e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.291296822841375
15.812458727508783 seconds in game passed.
Action: tensor([[[ 6.5814e-03,  8.7972e-01],
         [ 4.4037e-04,  4.6304e-01],
         [-1.1030e-03,  3.1114e-01],
         [-9.4344e-04,  2.2945e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.291296822841375
+++++++++++++: 2.4996671545469304
15.837458727881312 seconds in game passed.
At 15.837458727881312 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.7661e-03,  8.7127e-01],
         [-5.3497e-04,  4.6035e-01],
         [-2.2691e-03,  3.0931e-01],
         [-2.1612e-03,  2.2833e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4996671545469304
Current reward: 0.2682878625733882
Current mitigation activation: 0
#############################
Total reward: 37.55958468541476
15.862458728253841 seconds in game passed.
Action: tensor([[[ 4.7661e-03,  8.7127e-01],
         [-5.3497e-04,  4.6035e-01],
         [-2.2691e-03,  3.0931e-01],
         [-2.1612e-03,  2.2833e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.55958468541476
15.88745872862637 seconds in game passed.
Action: tensor([[[ 4.7661e-03,  8.7127e-01],
         [-5.3497e-04,  4.6035e-01],
         [-2.2691e-03,  3.0931e-01],
         [-2.1612e-03,  2.2833e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.55958468541476
15.9124587289989 seconds in game passed.
Action: tensor([[[ 4.7661e-03,  8.7127e-01],
         [-5.3497e-04,  4.6035e-01],
         [-2.2691e-03,  3.0931e-01],
         [-2.1612e-03,  2.2833e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003081, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.55958468541476
+++++++++++++: 2.3303866085246008
15.937458729371428 seconds in game passed.
At 15.937458729371428 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0031,  0.8738],
         [-0.0014,  0.4616],
         [-0.0031,  0.3103],
         [-0.0032,  0.2291]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3303866085246008
Current reward: 0.27975603757040046
Current mitigation activation: 0
#############################
Total reward: 37.83934072298516
15.962458729743958 seconds in game passed.
Action: tensor([[[ 0.0031,  0.8738],
         [-0.0014,  0.4616],
         [-0.0031,  0.3103],
         [-0.0032,  0.2291]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.83934072298516
15.987458730116487 seconds in game passed.
Action: tensor([[[ 0.0031,  0.8738],
         [-0.0014,  0.4616],
         [-0.0031,  0.3103],
         [-0.0032,  0.2291]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.83934072298516
16.012458730489016 seconds in game passed.
Action: tensor([[[ 0.0031,  0.8738],
         [-0.0014,  0.4616],
         [-0.0031,  0.3103],
         [-0.0032,  0.2291]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.83934072298516
+++++++++++++: 2.171897948658741
16.037458730861545 seconds in game passed.
At 16.037458730861545 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.5763e-04,  8.5802e-01],
         [-2.1499e-03,  4.4777e-01],
         [-3.9382e-03,  2.9993e-01],
         [-3.9408e-03,  2.2153e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.171897948658741
Current reward: 0.29119017724872753
Current mitigation activation: 0
#############################
Total reward: 38.13053090023389
16.062458731234074 seconds in game passed.
Action: tensor([[[ 4.5763e-04,  8.5802e-01],
         [-2.1499e-03,  4.4777e-01],
         [-3.9382e-03,  2.9993e-01],
         [-3.9408e-03,  2.2153e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.13053090023389
16.087458731606603 seconds in game passed.
Action: tensor([[[ 4.5763e-04,  8.5802e-01],
         [-2.1499e-03,  4.4777e-01],
         [-3.9382e-03,  2.9993e-01],
         [-3.9408e-03,  2.2153e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.13053090023389
16.11245873197913 seconds in game passed.
Action: tensor([[[ 4.5763e-04,  8.5802e-01],
         [-2.1499e-03,  4.4777e-01],
         [-3.9382e-03,  2.9993e-01],
         [-3.9408e-03,  2.2153e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.13053090023389
+++++++++++++: 2.0350430528320915
16.13745873235166 seconds in game passed.
At 16.13745873235166 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0038,  0.8764],
         [-0.0030,  0.4519],
         [-0.0049,  0.3027],
         [-0.0046,  0.2235]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0350430528320915
Current reward: 0.3016162099862896
Current mitigation activation: 0
#############################
Total reward: 38.432147110220185
16.16245873272419 seconds in game passed.
Action: tensor([[[ 0.0038,  0.8764],
         [-0.0030,  0.4519],
         [-0.0049,  0.3027],
         [-0.0046,  0.2235]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001042, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.432147110220185
16.18745873309672 seconds in game passed.
Action: tensor([[[ 0.0038,  0.8764],
         [-0.0030,  0.4519],
         [-0.0049,  0.3027],
         [-0.0046,  0.2235]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.432147110220185
16.212458733469248 seconds in game passed.
Action: tensor([[[ 0.0038,  0.8764],
         [-0.0030,  0.4519],
         [-0.0049,  0.3027],
         [-0.0046,  0.2235]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.432147110220185
+++++++++++++: 1.9118938956892138
16.237458733841777 seconds in game passed.
At 16.237458733841777 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0019,  0.8841],
         [-0.0035,  0.4577],
         [-0.0060,  0.3049],
         [-0.0059,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9118938956892138
Current reward: 0.3113334453609818
Current mitigation activation: 0
#############################
Total reward: 38.743480555581165
16.262458734214306 seconds in game passed.
Action: tensor([[[ 0.0019,  0.8841],
         [-0.0035,  0.4577],
         [-0.0060,  0.3049],
         [-0.0059,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.743480555581165
16.287458734586835 seconds in game passed.
Action: tensor([[[ 0.0019,  0.8841],
         [-0.0035,  0.4577],
         [-0.0060,  0.3049],
         [-0.0059,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.743480555581165
16.312458734959364 seconds in game passed.
Action: tensor([[[ 0.0019,  0.8841],
         [-0.0035,  0.4577],
         [-0.0060,  0.3049],
         [-0.0059,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.743480555581165
+++++++++++++: 1.7983236108207195
16.337458735331893 seconds in game passed.
At 16.337458735331893 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0028,  0.8809],
         [-0.0016,  0.4574],
         [-0.0036,  0.3075],
         [-0.0038,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7983236108207195
Current reward: 0.3204987398051937
Current mitigation activation: 0
#############################
Total reward: 39.06397929538636
16.362458735704422 seconds in game passed.
Action: tensor([[[-0.0028,  0.8809],
         [-0.0016,  0.4574],
         [-0.0036,  0.3075],
         [-0.0038,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.06397929538636
16.38745873607695 seconds in game passed.
Action: tensor([[[-0.0028,  0.8809],
         [-0.0016,  0.4574],
         [-0.0036,  0.3075],
         [-0.0038,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.06397929538636
16.41245873644948 seconds in game passed.
Action: tensor([[[-0.0028,  0.8809],
         [-0.0016,  0.4574],
         [-0.0036,  0.3075],
         [-0.0038,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001024, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.06397929538636
+++++++++++++: 1.6923390194453907
16.43745873682201 seconds in game passed.
At 16.43745873682201 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.9889e-03,  8.9940e-01],
         [ 1.4415e-04,  4.6294e-01],
         [-2.6961e-03,  3.0836e-01],
         [-3.4827e-03,  2.2798e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6923390194453907
Current reward: 0.3291739481786415
Current mitigation activation: 0
#############################
Total reward: 39.393153243565
16.462458737194538 seconds in game passed.
Action: tensor([[[-1.9889e-03,  8.9940e-01],
         [ 1.4415e-04,  4.6294e-01],
         [-2.6961e-03,  3.0836e-01],
         [-3.4827e-03,  2.2798e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.393153243565
16.487458737567067 seconds in game passed.
Action: tensor([[[-1.9889e-03,  8.9940e-01],
         [ 1.4415e-04,  4.6294e-01],
         [-2.6961e-03,  3.0836e-01],
         [-3.4827e-03,  2.2798e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.393153243565
16.512458737939596 seconds in game passed.
Action: tensor([[[-1.9889e-03,  8.9940e-01],
         [ 1.4415e-04,  4.6294e-01],
         [-2.6961e-03,  3.0836e-01],
         [-3.4827e-03,  2.2798e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.393153243565
+++++++++++++: 1.593759857488893
16.537458738312125 seconds in game passed.
At 16.537458738312125 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.3659e-03,  8.9170e-01],
         [ 5.9579e-04,  4.8116e-01],
         [-3.5126e-03,  3.2999e-01],
         [-5.2496e-03,  2.4754e-01]]])
agent 0 action: VehicleControl(throttle=0.642971, steer=0.003232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.593759857488893
Current reward: 0.3374539019311845
Current mitigation activation: 0
#############################
Total reward: 39.73060714549619
16.562458738684654 seconds in game passed.
Action: tensor([[[ 5.3659e-03,  8.9170e-01],
         [ 5.9579e-04,  4.8116e-01],
         [-3.5126e-03,  3.2999e-01],
         [-5.2496e-03,  2.4754e-01]]])
agent 0 action: VehicleControl(throttle=0.629715, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.73060714549619
16.587458739057183 seconds in game passed.
Action: tensor([[[ 5.3659e-03,  8.9170e-01],
         [ 5.9579e-04,  4.8116e-01],
         [-3.5126e-03,  3.2999e-01],
         [-5.2496e-03,  2.4754e-01]]])
agent 0 action: VehicleControl(throttle=0.578505, steer=0.002547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.73060714549619
16.612458739429712 seconds in game passed.
Action: tensor([[[ 5.3659e-03,  8.9170e-01],
         [ 5.9579e-04,  4.8116e-01],
         [-3.5126e-03,  3.2999e-01],
         [-5.2496e-03,  2.4754e-01]]])
agent 0 action: VehicleControl(throttle=0.529432, steer=0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.73060714549619
+++++++++++++: 1.5036659259485792
16.63745873980224 seconds in game passed.
At 16.63745873980224 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9188e-03,  9.1745e-01],
         [ 3.4447e-03,  5.0662e-01],
         [ 3.3014e-05,  3.4413e-01],
         [-8.2611e-04,  2.5742e-01]]])
agent 0 action: VehicleControl(throttle=0.478214, steer=0.003632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5036659259485792
Current reward: 0.34529291179292226
Current mitigation activation: 0
#############################
Total reward: 40.07590005728911
16.66245874017477 seconds in game passed.
Action: tensor([[[ 2.9188e-03,  9.1745e-01],
         [ 3.4447e-03,  5.0662e-01],
         [ 3.3014e-05,  3.4413e-01],
         [-8.2611e-04,  2.5742e-01]]])
agent 0 action: VehicleControl(throttle=0.463173, steer=0.003409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.07590005728911
16.6874587405473 seconds in game passed.
Action: tensor([[[ 2.9188e-03,  9.1745e-01],
         [ 3.4447e-03,  5.0662e-01],
         [ 3.3014e-05,  3.4413e-01],
         [-8.2611e-04,  2.5742e-01]]])
agent 0 action: VehicleControl(throttle=0.444242, steer=0.003383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.07590005728911
16.71245874091983 seconds in game passed.
Action: tensor([[[ 2.9188e-03,  9.1745e-01],
         [ 3.4447e-03,  5.0662e-01],
         [ 3.3014e-05,  3.4413e-01],
         [-8.2611e-04,  2.5742e-01]]])
agent 0 action: VehicleControl(throttle=0.425302, steer=0.003356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.07590005728911
+++++++++++++: 1.4326011434896027
16.737458741292357 seconds in game passed.
At 16.737458741292357 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.4879e-03, 9.3538e-01],
         [5.6185e-03, 5.3542e-01],
         [1.4871e-03, 3.6347e-01],
         [1.9685e-04, 2.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005277, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4326011434896027
Current reward: 0.35108542568586065
Current mitigation activation: 0
#############################
Total reward: 40.42698548297497
16.762458741664886 seconds in game passed.
Action: tensor([[[3.4879e-03, 9.3538e-01],
         [5.6185e-03, 5.3542e-01],
         [1.4871e-03, 3.6347e-01],
         [1.9685e-04, 2.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004990, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.42698548297497
16.787458742037416 seconds in game passed.
Action: tensor([[[3.4879e-03, 9.3538e-01],
         [5.6185e-03, 5.3542e-01],
         [1.4871e-03, 3.6347e-01],
         [1.9685e-04, 2.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005019, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.42698548297497
16.812458742409945 seconds in game passed.
Action: tensor([[[3.4879e-03, 9.3538e-01],
         [5.6185e-03, 5.3542e-01],
         [1.4871e-03, 3.6347e-01],
         [1.9685e-04, 2.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005048, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.42698548297497
+++++++++++++: 1.389509979990066
16.837458742782474 seconds in game passed.
At 16.837458742782474 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0166, 0.9306],
         [0.0075, 0.5231],
         [0.0042, 0.3515],
         [0.0036, 0.2577]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012102, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.389509979990066
Current reward: 0.35315789079536575
Current mitigation activation: 0
#############################
Total reward: 40.780143373770336
16.862458743155003 seconds in game passed.
Action: tensor([[[0.0166, 0.9306],
         [0.0075, 0.5231],
         [0.0042, 0.3515],
         [0.0036, 0.2577]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.011062, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.780143373770336
16.88745874352753 seconds in game passed.
Action: tensor([[[0.0166, 0.9306],
         [0.0075, 0.5231],
         [0.0042, 0.3515],
         [0.0036, 0.2577]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.011178, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.780143373770336
16.91245874390006 seconds in game passed.
Action: tensor([[[0.0166, 0.9306],
         [0.0075, 0.5231],
         [0.0042, 0.3515],
         [0.0036, 0.2577]]])
agent 0 action: VehicleControl(throttle=0.281327, steer=0.011294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.780143373770336
+++++++++++++: 1.4150483090864037
16.93745874427259 seconds in game passed.
At 16.93745874427259 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0288, 0.9305],
         [0.0077, 0.5312],
         [0.0023, 0.3560],
         [0.0023, 0.2603]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016919, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4150483090864037
Current reward: 0.34531651441193467
Current mitigation activation: 0
#############################
Total reward: 41.12545988818227
16.96245874464512 seconds in game passed.
Action: tensor([[[0.0288, 0.9305],
         [0.0077, 0.5312],
         [0.0023, 0.3560],
         [0.0023, 0.2603]]])
agent 0 action: VehicleControl(throttle=0.250420, steer=0.016199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.12545988818227
16.987458745017648 seconds in game passed.
Action: tensor([[[0.0288, 0.9305],
         [0.0077, 0.5312],
         [0.0023, 0.3560],
         [0.0023, 0.2603]]])
agent 0 action: VehicleControl(throttle=0.235723, steer=0.016385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.12545988818227
17.012458745390177 seconds in game passed.
Action: tensor([[[0.0288, 0.9305],
         [0.0077, 0.5312],
         [0.0023, 0.3560],
         [0.0023, 0.2603]]])
agent 0 action: VehicleControl(throttle=0.221522, steer=0.016571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.12545988818227
+++++++++++++: 1.5187150416178787
17.037458745762706 seconds in game passed.
At 17.037458745762706 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4043e-02,  9.3712e-01],
         [-5.6516e-04,  5.5534e-01],
         [-4.9925e-03,  3.7269e-01],
         [-4.4799e-03,  2.7362e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004320, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5187150416178787
Current reward: 0.32865795498283723
Current mitigation activation: 0
#############################
Total reward: 41.45411784316511
17.062458746135235 seconds in game passed.
Action: tensor([[[ 1.4043e-02,  9.3712e-01],
         [-5.6516e-04,  5.5534e-01],
         [-4.9925e-03,  3.7269e-01],
         [-4.4799e-03,  2.7362e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006450, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.45411784316511
17.087458746507764 seconds in game passed.
Action: tensor([[[ 1.4043e-02,  9.3712e-01],
         [-5.6516e-04,  5.5534e-01],
         [-4.9925e-03,  3.7269e-01],
         [-4.4799e-03,  2.7362e-01]]])
agent 0 action: VehicleControl(throttle=0.175865, steer=0.006525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.45411784316511
17.112458746880293 seconds in game passed.
Action: tensor([[[ 1.4043e-02,  9.3712e-01],
         [-5.6516e-04,  5.5534e-01],
         [-4.9925e-03,  3.7269e-01],
         [-4.4799e-03,  2.7362e-01]]])
agent 0 action: VehicleControl(throttle=0.161602, steer=0.006601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.45411784316511
+++++++++++++: 1.6253246857689592
17.137458747252822 seconds in game passed.
At 17.137458747252822 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0195,  0.9352],
         [ 0.0019,  0.5319],
         [-0.0041,  0.3498],
         [-0.0051,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.147637, steer=0.010755, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6253246857689592
Current reward: 0.31569818889527707
Current mitigation activation: 0
#############################
Total reward: 41.76981603206038
17.16245874762535 seconds in game passed.
Action: tensor([[[ 0.0195,  0.9352],
         [ 0.0019,  0.5319],
         [-0.0041,  0.3498],
         [-0.0051,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.153733, steer=0.010191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.76981603206038
17.18745874799788 seconds in game passed.
Action: tensor([[[ 0.0195,  0.9352],
         [ 0.0019,  0.5319],
         [-0.0041,  0.3498],
         [-0.0051,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.165559, steer=0.010302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.76981603206038
17.21245874837041 seconds in game passed.
Action: tensor([[[ 0.0195,  0.9352],
         [ 0.0019,  0.5319],
         [-0.0041,  0.3498],
         [-0.0051,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.175685, steer=0.010412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.76981603206038
+++++++++++++: 1.7162679821273388
17.237458748742938 seconds in game passed.
At 17.237458748742938 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2315e-02,  9.3412e-01],
         [-3.9080e-04,  5.3022e-01],
         [-5.3546e-03,  3.5232e-01],
         [-6.1484e-03,  2.5981e-01]]])
agent 0 action: VehicleControl(throttle=0.204376, steer=0.005636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7162679821273388
Current reward: 0.3075986601182703
Current mitigation activation: 0
#############################
Total reward: 42.07741469217866
17.262458749115467 seconds in game passed.
Action: tensor([[[ 1.2315e-02,  9.3412e-01],
         [-3.9080e-04,  5.3022e-01],
         [-5.3546e-03,  3.5232e-01],
         [-6.1484e-03,  2.5981e-01]]])
agent 0 action: VehicleControl(throttle=0.212132, steer=0.006516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.07741469217866
17.287458749487996 seconds in game passed.
Action: tensor([[[ 1.2315e-02,  9.3412e-01],
         [-3.9080e-04,  5.3022e-01],
         [-5.3546e-03,  3.5232e-01],
         [-6.1484e-03,  2.5981e-01]]])
agent 0 action: VehicleControl(throttle=0.221180, steer=0.006588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.07741469217866
17.312458749860525 seconds in game passed.
Action: tensor([[[ 1.2315e-02,  9.3412e-01],
         [-3.9080e-04,  5.3022e-01],
         [-5.3546e-03,  3.5232e-01],
         [-6.1484e-03,  2.5981e-01]]])
agent 0 action: VehicleControl(throttle=0.210459, steer=0.006660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.07741469217866
+++++++++++++: 1.7816113741495982
17.337458750233054 seconds in game passed.
At 17.337458750233054 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0052,  0.9152],
         [-0.0070,  0.5027],
         [-0.0111,  0.3345],
         [-0.0112,  0.2449]]])
agent 0 action: VehicleControl(throttle=0.520999, steer=-0.001447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7816113741495982
Current reward: 0.30411042519561093
Current mitigation activation: 0
#############################
Total reward: 42.38152511737427
17.362458750605583 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9152],
         [-0.0070,  0.5027],
         [-0.0111,  0.3345],
         [-0.0112,  0.2449]]])
agent 0 action: VehicleControl(throttle=0.483618, steer=-0.000105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.38152511737427
17.387458750978112 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9152],
         [-0.0070,  0.5027],
         [-0.0111,  0.3345],
         [-0.0112,  0.2449]]])
agent 0 action: VehicleControl(throttle=0.480792, steer=-0.000114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.38152511737427
17.41245875135064 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9152],
         [-0.0070,  0.5027],
         [-0.0111,  0.3345],
         [-0.0112,  0.2449]]])
agent 0 action: VehicleControl(throttle=0.478611, steer=-0.000122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.38152511737427
+++++++++++++: 1.8144098336744758
17.43745875172317 seconds in game passed.
At 17.43745875172317 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.9254],
         [-0.0059,  0.4951],
         [-0.0105,  0.3262],
         [-0.0115,  0.2401]]])
agent 0 action: VehicleControl(throttle=0.644065, steer=-0.002584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8144098336744758
Current reward: 0.30488694028934854
Current mitigation activation: 0
#############################
Total reward: 42.68641205766362
17.4624587520957 seconds in game passed.
Action: tensor([[[-0.0025,  0.9254],
         [-0.0059,  0.4951],
         [-0.0105,  0.3262],
         [-0.0115,  0.2401]]])
agent 0 action: VehicleControl(throttle=0.627335, steer=-0.002233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.68641205766362
17.48745875246823 seconds in game passed.
Action: tensor([[[-0.0025,  0.9254],
         [-0.0059,  0.4951],
         [-0.0105,  0.3262],
         [-0.0115,  0.2401]]])
agent 0 action: VehicleControl(throttle=0.628803, steer=-0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.68641205766362
17.512458752840757 seconds in game passed.
Action: tensor([[[-0.0025,  0.9254],
         [-0.0059,  0.4951],
         [-0.0105,  0.3262],
         [-0.0115,  0.2401]]])
agent 0 action: VehicleControl(throttle=0.630736, steer=-0.002334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.68641205766362
+++++++++++++: 1.8457211740245631
17.537458753213286 seconds in game passed.
At 17.537458753213286 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.9180],
         [-0.0090,  0.4805],
         [-0.0130,  0.3216],
         [-0.0136,  0.2420]]])
agent 0 action: VehicleControl(throttle=0.844518, steer=-0.004810, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8457211740245631
Current reward: 0.3064630113794169
Current mitigation activation: 0
#############################
Total reward: 42.99287506904303
17.562458753585815 seconds in game passed.
Action: tensor([[[-0.0025,  0.9180],
         [-0.0090,  0.4805],
         [-0.0130,  0.3216],
         [-0.0136,  0.2420]]])
agent 0 action: VehicleControl(throttle=0.831648, steer=-0.004525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.99287506904303
17.587458753958344 seconds in game passed.
Action: tensor([[[-0.0025,  0.9180],
         [-0.0090,  0.4805],
         [-0.0130,  0.3216],
         [-0.0136,  0.2420]]])
agent 0 action: VehicleControl(throttle=0.841227, steer=-0.004635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.99287506904303
17.612458754330873 seconds in game passed.
Action: tensor([[[-0.0025,  0.9180],
         [-0.0090,  0.4805],
         [-0.0130,  0.3216],
         [-0.0136,  0.2420]]])
agent 0 action: VehicleControl(throttle=0.851210, steer=-0.004745, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.99287506904303
+++++++++++++: 1.8805902886706287
17.637458754703403 seconds in game passed.
At 17.637458754703403 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0063,  0.8611],
         [-0.0115,  0.4563],
         [-0.0158,  0.3134],
         [-0.0170,  0.2397]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8805902886706287
Current reward: 0.3083043253940003
Current mitigation activation: 0
#############################
Total reward: 43.30117939443703
17.66245875507593 seconds in game passed.
Action: tensor([[[-0.0063,  0.8611],
         [-0.0115,  0.4563],
         [-0.0158,  0.3134],
         [-0.0170,  0.2397]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.30117939443703
17.68745875544846 seconds in game passed.
Action: tensor([[[-0.0063,  0.8611],
         [-0.0115,  0.4563],
         [-0.0158,  0.3134],
         [-0.0170,  0.2397]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.30117939443703
17.71245875582099 seconds in game passed.
Action: tensor([[[-0.0063,  0.8611],
         [-0.0115,  0.4563],
         [-0.0158,  0.3134],
         [-0.0170,  0.2397]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.30117939443703
+++++++++++++: 1.919053273015211
17.73745875619352 seconds in game passed.
At 17.73745875619352 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0065,  0.8446],
         [-0.0162,  0.4472],
         [-0.0203,  0.3049],
         [-0.0211,  0.2317]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.919053273015211
Current reward: 0.3103901672838516
Current mitigation activation: 0
#############################
Total reward: 43.61156956172088
17.762458756566048 seconds in game passed.
Action: tensor([[[-0.0065,  0.8446],
         [-0.0162,  0.4472],
         [-0.0203,  0.3049],
         [-0.0211,  0.2317]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.61156956172088
17.787458756938577 seconds in game passed.
Action: tensor([[[-0.0065,  0.8446],
         [-0.0162,  0.4472],
         [-0.0203,  0.3049],
         [-0.0211,  0.2317]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.61156956172088
17.812458757311106 seconds in game passed.
Action: tensor([[[-0.0065,  0.8446],
         [-0.0162,  0.4472],
         [-0.0203,  0.3049],
         [-0.0211,  0.2317]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.61156956172088
+++++++++++++: 1.9713504172134406
17.837458757683635 seconds in game passed.
At 17.837458757683635 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.8441],
         [-0.0096,  0.4497],
         [-0.0126,  0.3093],
         [-0.0132,  0.2346]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9713504172134406
Current reward: 0.31183297316737735
Current mitigation activation: 0
#############################
Total reward: 43.923402534888254
17.862458758056164 seconds in game passed.
Action: tensor([[[-0.0017,  0.8441],
         [-0.0096,  0.4497],
         [-0.0126,  0.3093],
         [-0.0132,  0.2346]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.923402534888254
17.887458758428693 seconds in game passed.
Action: tensor([[[-0.0017,  0.8441],
         [-0.0096,  0.4497],
         [-0.0126,  0.3093],
         [-0.0132,  0.2346]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.923402534888254
17.912458758801222 seconds in game passed.
Action: tensor([[[-0.0017,  0.8441],
         [-0.0096,  0.4497],
         [-0.0126,  0.3093],
         [-0.0132,  0.2346]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.923402534888254
+++++++++++++: 2.156588049943986
17.93745875917375 seconds in game passed.
At 17.93745875917375 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.2209e-04,  8.2727e-01],
         [-1.5523e-02,  4.3388e-01],
         [-2.0092e-02,  2.9335e-01],
         [-2.2326e-02,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.156588049943986
Current reward: 0.30361431795450045
Current mitigation activation: 0
#############################
Total reward: 44.22701685284275
17.96245875954628 seconds in game passed.
Action: tensor([[[-6.2209e-04,  8.2727e-01],
         [-1.5523e-02,  4.3388e-01],
         [-2.0092e-02,  2.9335e-01],
         [-2.2326e-02,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.22701685284275
17.98745875991881 seconds in game passed.
Action: tensor([[[-6.2209e-04,  8.2727e-01],
         [-1.5523e-02,  4.3388e-01],
         [-2.0092e-02,  2.9335e-01],
         [-2.2326e-02,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.22701685284275
18.012458760291338 seconds in game passed.
Action: tensor([[[-6.2209e-04,  8.2727e-01],
         [-1.5523e-02,  4.3388e-01],
         [-2.0092e-02,  2.9335e-01],
         [-2.2326e-02,  2.1997e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.22701685284275
+++++++++++++: 2.2933713834249696
18.037458760663867 seconds in game passed.
At 18.037458760663867 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0010,  0.8392],
         [-0.0133,  0.4323],
         [-0.0179,  0.2862],
         [-0.0201,  0.2123]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2933713834249696
Current reward: 0.3015437612722065
Current mitigation activation: 0
#############################
Total reward: 44.52856061411496
18.062458761036396 seconds in game passed.
Action: tensor([[[ 0.0010,  0.8392],
         [-0.0133,  0.4323],
         [-0.0179,  0.2862],
         [-0.0201,  0.2123]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.52856061411496
18.087458761408925 seconds in game passed.
Action: tensor([[[ 0.0010,  0.8392],
         [-0.0133,  0.4323],
         [-0.0179,  0.2862],
         [-0.0201,  0.2123]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.52856061411496
18.112458761781454 seconds in game passed.
Action: tensor([[[ 0.0010,  0.8392],
         [-0.0133,  0.4323],
         [-0.0179,  0.2862],
         [-0.0201,  0.2123]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.52856061411496
+++++++++++++: 2.332309079837714
18.137458762153983 seconds in game passed.
At 18.137458762153983 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.8013],
         [-0.0087,  0.4191],
         [-0.0116,  0.2785],
         [-0.0125,  0.2075]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.332309079837714
Current reward: 0.30714731065748185
Current mitigation activation: 0
#############################
Total reward: 44.83570792477244
18.162458762526512 seconds in game passed.
Action: tensor([[[-0.0009,  0.8013],
         [-0.0087,  0.4191],
         [-0.0116,  0.2785],
         [-0.0125,  0.2075]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.83570792477244
18.18745876289904 seconds in game passed.
Action: tensor([[[-0.0009,  0.8013],
         [-0.0087,  0.4191],
         [-0.0116,  0.2785],
         [-0.0125,  0.2075]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.83570792477244
18.21245876327157 seconds in game passed.
Action: tensor([[[-0.0009,  0.8013],
         [-0.0087,  0.4191],
         [-0.0116,  0.2785],
         [-0.0125,  0.2075]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.83570792477244
+++++++++++++: 2.316236206897693
18.2374587636441 seconds in game passed.
At 18.2374587636441 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.7692],
         [-0.0056,  0.4038],
         [-0.0081,  0.2719],
         [-0.0095,  0.2045]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.316236206897693
Current reward: 0.3166971469699094
Current mitigation activation: 0
#############################
Total reward: 45.15240507174235
18.26245876401663 seconds in game passed.
Action: tensor([[[-0.0009,  0.7692],
         [-0.0056,  0.4038],
         [-0.0081,  0.2719],
         [-0.0095,  0.2045]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.15240507174235
18.287458764389157 seconds in game passed.
Action: tensor([[[-0.0009,  0.7692],
         [-0.0056,  0.4038],
         [-0.0081,  0.2719],
         [-0.0095,  0.2045]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.15240507174235
18.312458764761686 seconds in game passed.
Action: tensor([[[-0.0009,  0.7692],
         [-0.0056,  0.4038],
         [-0.0081,  0.2719],
         [-0.0095,  0.2045]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.15240507174235
+++++++++++++: 2.2753695894387485
18.337458765134215 seconds in game passed.
At 18.337458765134215 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0028,  0.7198],
         [-0.0060,  0.3861],
         [-0.0073,  0.2645],
         [-0.0080,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2753695894387485
Current reward: 0.328101575875959
Current mitigation activation: 0
#############################
Total reward: 45.48050664761831
18.362458765506744 seconds in game passed.
Action: tensor([[[-0.0028,  0.7198],
         [-0.0060,  0.3861],
         [-0.0073,  0.2645],
         [-0.0080,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.48050664761831
18.387458765879273 seconds in game passed.
Action: tensor([[[-0.0028,  0.7198],
         [-0.0060,  0.3861],
         [-0.0073,  0.2645],
         [-0.0080,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.48050664761831
18.412458766251802 seconds in game passed.
Action: tensor([[[-0.0028,  0.7198],
         [-0.0060,  0.3861],
         [-0.0073,  0.2645],
         [-0.0080,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.48050664761831
+++++++++++++: 2.224000680760183
18.43745876662433 seconds in game passed.
At 18.43745876662433 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.3166e-04,  6.7607e-01],
         [-4.6318e-03,  3.7547e-01],
         [-6.1569e-03,  2.6155e-01],
         [-7.0865e-03,  2.0139e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.224000680760183
Current reward: 0.3404058335910718
Current mitigation activation: 0
#############################
Total reward: 45.82091248120938
18.46245876699686 seconds in game passed.
Action: tensor([[[-3.3166e-04,  6.7607e-01],
         [-4.6318e-03,  3.7547e-01],
         [-6.1569e-03,  2.6155e-01],
         [-7.0865e-03,  2.0139e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.82091248120938
18.48745876736939 seconds in game passed.
Action: tensor([[[-3.3166e-04,  6.7607e-01],
         [-4.6318e-03,  3.7547e-01],
         [-6.1569e-03,  2.6155e-01],
         [-7.0865e-03,  2.0139e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.82091248120938
18.51245876774192 seconds in game passed.
Action: tensor([[[-3.3166e-04,  6.7607e-01],
         [-4.6318e-03,  3.7547e-01],
         [-6.1569e-03,  2.6155e-01],
         [-7.0865e-03,  2.0139e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.82091248120938
+++++++++++++: 2.169475732821194
18.537458768114448 seconds in game passed.
At 18.537458768114448 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6855],
         [-0.0021,  0.3769],
         [-0.0030,  0.2612],
         [-0.0039,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.169475732821194
Current reward: 0.35308635105984093
Current mitigation activation: 0
#############################
Total reward: 46.17399883226923
18.562458768486977 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6855],
         [-0.0021,  0.3769],
         [-0.0030,  0.2612],
         [-0.0039,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.17399883226923
18.587458768859506 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6855],
         [-0.0021,  0.3769],
         [-0.0030,  0.2612],
         [-0.0039,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.17399883226923
18.612458769232035 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6855],
         [-0.0021,  0.3769],
         [-0.0030,  0.2612],
         [-0.0039,  0.2008]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.17399883226923
+++++++++++++: 2.115336683593478
18.637458769604564 seconds in game passed.
At 18.637458769604564 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.0486e-03,  6.8308e-01],
         [ 4.6960e-04,  3.7605e-01],
         [-2.9077e-04,  2.5910e-01],
         [-1.2639e-03,  1.9838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.115336683593478
Current reward: 0.3658485972618035
Current mitigation activation: 0
#############################
Total reward: 46.53984742953103
18.662458769977093 seconds in game passed.
Action: tensor([[[ 6.0486e-03,  6.8308e-01],
         [ 4.6960e-04,  3.7605e-01],
         [-2.9077e-04,  2.5910e-01],
         [-1.2639e-03,  1.9838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.53984742953103
18.68745877034962 seconds in game passed.
Action: tensor([[[ 6.0486e-03,  6.8308e-01],
         [ 4.6960e-04,  3.7605e-01],
         [-2.9077e-04,  2.5910e-01],
         [-1.2639e-03,  1.9838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.53984742953103
18.71245877072215 seconds in game passed.
Action: tensor([[[ 6.0486e-03,  6.8308e-01],
         [ 4.6960e-04,  3.7605e-01],
         [-2.9077e-04,  2.5910e-01],
         [-1.2639e-03,  1.9838e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.53984742953103
+++++++++++++: 2.063164347416167
18.73745877109468 seconds in game passed.
At 18.73745877109468 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6554],
         [0.0021, 0.3554],
         [0.0022, 0.2432],
         [0.0016, 0.1858]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.063164347416167
Current reward: 0.3785238920434814
Current mitigation activation: 0
#############################
Total reward: 46.91837132157451
18.76245877146721 seconds in game passed.
Action: tensor([[[0.0034, 0.6554],
         [0.0021, 0.3554],
         [0.0022, 0.2432],
         [0.0016, 0.1858]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.91837132157451
18.787458771839738 seconds in game passed.
Action: tensor([[[0.0034, 0.6554],
         [0.0021, 0.3554],
         [0.0022, 0.2432],
         [0.0016, 0.1858]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.91837132157451
18.812458772212267 seconds in game passed.
Action: tensor([[[0.0034, 0.6554],
         [0.0021, 0.3554],
         [0.0022, 0.2432],
         [0.0016, 0.1858]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.91837132157451
+++++++++++++: 2.0135748277940757
18.837458772584796 seconds in game passed.
At 18.837458772584796 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0058, 0.6435],
         [0.0042, 0.3428],
         [0.0040, 0.2342],
         [0.0034, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0135748277940757
Current reward: 0.39100971557726427
Current mitigation activation: 0
#############################
Total reward: 47.30938103715177
18.862458772957325 seconds in game passed.
Action: tensor([[[0.0058, 0.6435],
         [0.0042, 0.3428],
         [0.0040, 0.2342],
         [0.0034, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002867, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.30938103715177
18.887458773329854 seconds in game passed.
Action: tensor([[[0.0058, 0.6435],
         [0.0042, 0.3428],
         [0.0040, 0.2342],
         [0.0034, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.30938103715177
18.912458773702383 seconds in game passed.
Action: tensor([[[0.0058, 0.6435],
         [0.0042, 0.3428],
         [0.0040, 0.2342],
         [0.0034, 0.1785]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003143, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.30938103715177
+++++++++++++: 1.9667021094784158
18.937458774074912 seconds in game passed.
At 18.937458774074912 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6310],
         [0.0022, 0.3414],
         [0.0025, 0.2352],
         [0.0021, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000659, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9667021094784158
Current reward: 0.4032490095773161
Current mitigation activation: 0
#############################
Total reward: 47.71263004672909
18.96245877444744 seconds in game passed.
Action: tensor([[[0.0028, 0.6310],
         [0.0022, 0.3414],
         [0.0025, 0.2352],
         [0.0021, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.71263004672909
18.98745877481997 seconds in game passed.
Action: tensor([[[0.0028, 0.6310],
         [0.0022, 0.3414],
         [0.0025, 0.2352],
         [0.0021, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.71263004672909
19.0124587751925 seconds in game passed.
Action: tensor([[[0.0028, 0.6310],
         [0.0022, 0.3414],
         [0.0025, 0.2352],
         [0.0021, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001560, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.71263004672909
+++++++++++++: 1.9224733847546842
19.037458775565028 seconds in game passed.
At 19.037458775565028 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.6553],
         [0.0020, 0.3479],
         [0.0018, 0.2384],
         [0.0011, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9224733847546842
Current reward: 0.4152029661603728
Current mitigation activation: 0
#############################
Total reward: 48.12783301288946
19.062458775937557 seconds in game passed.
Action: tensor([[[0.0014, 0.6553],
         [0.0020, 0.3479],
         [0.0018, 0.2384],
         [0.0011, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001217, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.12783301288946
19.087458776310086 seconds in game passed.
Action: tensor([[[0.0014, 0.6553],
         [0.0020, 0.3479],
         [0.0018, 0.2384],
         [0.0011, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.12783301288946
19.112458776682615 seconds in game passed.
Action: tensor([[[0.0014, 0.6553],
         [0.0020, 0.3479],
         [0.0018, 0.2384],
         [0.0011, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.12783301288946
+++++++++++++: 1.8806978686025937
19.137458777055144 seconds in game passed.
At 19.137458777055144 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.8520e-03, 6.5561e-01],
         [1.9177e-03, 3.4877e-01],
         [1.0709e-03, 2.3890e-01],
         [2.5950e-04, 1.8270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8806978686025937
Current reward: 0.42685220732488427
Current mitigation activation: 0
#############################
Total reward: 48.554685220214346
19.162458777427673 seconds in game passed.
Action: tensor([[[3.8520e-03, 6.5561e-01],
         [1.9177e-03, 3.4877e-01],
         [1.0709e-03, 2.3890e-01],
         [2.5950e-04, 1.8270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.554685220214346
19.187458777800202 seconds in game passed.
Action: tensor([[[3.8520e-03, 6.5561e-01],
         [1.9177e-03, 3.4877e-01],
         [1.0709e-03, 2.3890e-01],
         [2.5950e-04, 1.8270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.554685220214346
19.21245877817273 seconds in game passed.
Action: tensor([[[3.8520e-03, 6.5561e-01],
         [1.9177e-03, 3.4877e-01],
         [1.0709e-03, 2.3890e-01],
         [2.5950e-04, 1.8270e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.554685220214346
+++++++++++++: 1.84117679377087
19.23745877854526 seconds in game passed.
At 19.23745877854526 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6517],
         [-0.0018,  0.3434],
         [-0.0028,  0.2344],
         [-0.0036,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.84117679377087
Current reward: 0.43818695610814684
Current mitigation activation: 0
#############################
Total reward: 48.99287217632249
19.26245877891779 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6517],
         [-0.0018,  0.3434],
         [-0.0028,  0.2344],
         [-0.0036,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.99287217632249
19.28745877929032 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6517],
         [-0.0018,  0.3434],
         [-0.0028,  0.2344],
         [-0.0036,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.99287217632249
19.312458779662848 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6517],
         [-0.0018,  0.3434],
         [-0.0028,  0.2344],
         [-0.0036,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.99287217632249
+++++++++++++: 1.8071558104478276
19.337458780035377 seconds in game passed.
At 19.337458780035377 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.9982e-04,  6.7420e-01],
         [-8.7659e-04,  3.5028e-01],
         [-1.9362e-03,  2.3750e-01],
         [-2.6403e-03,  1.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8071558104478276
Current reward: 0.448720568863454
Current mitigation activation: 0
#############################
Total reward: 49.44159274518595
19.362458780407906 seconds in game passed.
Action: tensor([[[ 3.9982e-04,  6.7420e-01],
         [-8.7659e-04,  3.5028e-01],
         [-1.9362e-03,  2.3750e-01],
         [-2.6403e-03,  1.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.44159274518595
19.387458780780435 seconds in game passed.
Action: tensor([[[ 3.9982e-04,  6.7420e-01],
         [-8.7659e-04,  3.5028e-01],
         [-1.9362e-03,  2.3750e-01],
         [-2.6403e-03,  1.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.44159274518595
19.412458781152964 seconds in game passed.
Action: tensor([[[ 3.9982e-04,  6.7420e-01],
         [-8.7659e-04,  3.5028e-01],
         [-1.9362e-03,  2.3750e-01],
         [-2.6403e-03,  1.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.44159274518595
+++++++++++++: 1.8203218452663115
19.437458781525493 seconds in game passed.
At 19.437458781525493 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6574],
         [-0.0023,  0.3412],
         [-0.0028,  0.2317],
         [-0.0028,  0.1774]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8203218452663115
Current reward: 0.4525492495250653
Current mitigation activation: 0
#############################
Total reward: 49.89414199471101
19.46245878189802 seconds in game passed.
Action: tensor([[[-0.0014,  0.6574],
         [-0.0023,  0.3412],
         [-0.0028,  0.2317],
         [-0.0028,  0.1774]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89414199471101
19.48745878227055 seconds in game passed.
Action: tensor([[[-0.0014,  0.6574],
         [-0.0023,  0.3412],
         [-0.0028,  0.2317],
         [-0.0028,  0.1774]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89414199471101
19.51245878264308 seconds in game passed.
Action: tensor([[[-0.0014,  0.6574],
         [-0.0023,  0.3412],
         [-0.0028,  0.2317],
         [-0.0028,  0.1774]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89414199471101
+++++++++++++: 1.8478865348002154
19.53745878301561 seconds in game passed.
At 19.53745878301561 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.7337e-05,  6.5265e-01],
         [-2.7040e-04,  3.4241e-01],
         [-6.0688e-04,  2.3326e-01],
         [-6.8531e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8478865348002154
Current reward: 0.4546235943292897
Current mitigation activation: 0
#############################
Total reward: 50.348765589040305
19.562458783388138 seconds in game passed.
Action: tensor([[[ 7.7337e-05,  6.5265e-01],
         [-2.7040e-04,  3.4241e-01],
         [-6.0688e-04,  2.3326e-01],
         [-6.8531e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.348765589040305
19.587458783760667 seconds in game passed.
Action: tensor([[[ 7.7337e-05,  6.5265e-01],
         [-2.7040e-04,  3.4241e-01],
         [-6.0688e-04,  2.3326e-01],
         [-6.8531e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.348765589040305
19.612458784133196 seconds in game passed.
Action: tensor([[[ 7.7337e-05,  6.5265e-01],
         [-2.7040e-04,  3.4241e-01],
         [-6.0688e-04,  2.3326e-01],
         [-6.8531e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.348765589040305
+++++++++++++: 1.877141106379836
19.637458784505725 seconds in game passed.
At 19.637458784505725 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6189],
         [0.0024, 0.3360],
         [0.0023, 0.2313],
         [0.0020, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.877141106379836
Current reward: 0.45686239288107
Current mitigation activation: 0
#############################
Total reward: 50.805627981921376
19.662458784878254 seconds in game passed.
Action: tensor([[[0.0034, 0.6189],
         [0.0024, 0.3360],
         [0.0023, 0.2313],
         [0.0020, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.805627981921376
19.687458785250783 seconds in game passed.
Action: tensor([[[0.0034, 0.6189],
         [0.0024, 0.3360],
         [0.0023, 0.2313],
         [0.0020, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.805627981921376
19.712458785623312 seconds in game passed.
Action: tensor([[[0.0034, 0.6189],
         [0.0024, 0.3360],
         [0.0023, 0.2313],
         [0.0020, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.805627981921376
+++++++++++++: 1.908140910583735
19.73745878599584 seconds in game passed.
At 19.73745878599584 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6241],
         [0.0021, 0.3365],
         [0.0021, 0.2324],
         [0.0018, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.908140910583735
Current reward: 0.4592552836231848
Current mitigation activation: 0
#############################
Total reward: 51.26488326554456
19.76245878636837 seconds in game passed.
Action: tensor([[[0.0033, 0.6241],
         [0.0021, 0.3365],
         [0.0021, 0.2324],
         [0.0018, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.26488326554456
19.7874587867409 seconds in game passed.
Action: tensor([[[0.0033, 0.6241],
         [0.0021, 0.3365],
         [0.0021, 0.2324],
         [0.0018, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.26488326554456
19.812458787113428 seconds in game passed.
Action: tensor([[[0.0033, 0.6241],
         [0.0021, 0.3365],
         [0.0021, 0.2324],
         [0.0018, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.26488326554456
+++++++++++++: 1.9389194397116747
19.837458787485957 seconds in game passed.
At 19.837458787485957 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6245],
         [0.0017, 0.3340],
         [0.0019, 0.2296],
         [0.0017, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9389194397116747
Current reward: 0.4620450781779355
Current mitigation activation: 0
#############################
Total reward: 51.7269283437225
19.862458787858486 seconds in game passed.
Action: tensor([[[0.0026, 0.6245],
         [0.0017, 0.3340],
         [0.0019, 0.2296],
         [0.0017, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.7269283437225
19.887458788231015 seconds in game passed.
Action: tensor([[[0.0026, 0.6245],
         [0.0017, 0.3340],
         [0.0019, 0.2296],
         [0.0017, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.7269283437225
19.912458788603544 seconds in game passed.
Action: tensor([[[0.0026, 0.6245],
         [0.0017, 0.3340],
         [0.0019, 0.2296],
         [0.0017, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.7269283437225
+++++++++++++: 1.898177380757904
19.937458788976073 seconds in game passed.
At 19.937458788976073 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.6924e-03,  6.1938e-01],
         [-7.6521e-04,  3.3075e-01],
         [-6.0000e-04,  2.2741e-01],
         [-4.5746e-04,  1.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.898177380757904
Current reward: 0.4745521493832262
Current mitigation activation: 0
#############################
Total reward: 52.20148049310573
19.962458789348602 seconds in game passed.
Action: tensor([[[ 1.6924e-03,  6.1938e-01],
         [-7.6521e-04,  3.3075e-01],
         [-6.0000e-04,  2.2741e-01],
         [-4.5746e-04,  1.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.20148049310573
19.98745878972113 seconds in game passed.
Action: tensor([[[ 1.6924e-03,  6.1938e-01],
         [-7.6521e-04,  3.3075e-01],
         [-6.0000e-04,  2.2741e-01],
         [-4.5746e-04,  1.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.20148049310573
20.01245879009366 seconds in game passed.
Action: tensor([[[ 1.6924e-03,  6.1938e-01],
         [-7.6521e-04,  3.3075e-01],
         [-6.0000e-04,  2.2741e-01],
         [-4.5746e-04,  1.7438e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.20148049310573
+++++++++++++: 1.8368435662778013
20.03745879046619 seconds in game passed.
At 20.03745879046619 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0014,  0.6087],
         [-0.0010,  0.3293],
         [-0.0013,  0.2270],
         [-0.0015,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.854590, steer=0.000141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8368435662778013
Current reward: 0.48992075809835717
Current mitigation activation: 0
#############################
Total reward: 52.691401251204084
20.06245879083872 seconds in game passed.
Action: tensor([[[ 0.0014,  0.6087],
         [-0.0010,  0.3293],
         [-0.0013,  0.2270],
         [-0.0015,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.812440, steer=0.000170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.691401251204084
20.087458791211247 seconds in game passed.
Action: tensor([[[ 0.0014,  0.6087],
         [-0.0010,  0.3293],
         [-0.0013,  0.2270],
         [-0.0015,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.764993, steer=0.000146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.691401251204084
20.112458791583776 seconds in game passed.
Action: tensor([[[ 0.0014,  0.6087],
         [-0.0010,  0.3293],
         [-0.0013,  0.2270],
         [-0.0015,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.718962, steer=0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.691401251204084
+++++++++++++: 1.7874071552045276
20.137458791956306 seconds in game passed.
At 20.137458791956306 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6160],
         [-0.0041,  0.3334],
         [-0.0045,  0.2292],
         [-0.0049,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.606223, steer=-0.003674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7874071552045276
Current reward: 0.5034155220750738
Current mitigation activation: 0
#############################
Total reward: 53.19481677327916
20.162458792328835 seconds in game passed.
Action: tensor([[[-0.0024,  0.6160],
         [-0.0041,  0.3334],
         [-0.0045,  0.2292],
         [-0.0049,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.570646, steer=-0.003124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19481677327916
20.187458792701364 seconds in game passed.
Action: tensor([[[-0.0024,  0.6160],
         [-0.0041,  0.3334],
         [-0.0045,  0.2292],
         [-0.0049,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.530243, steer=-0.003196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19481677327916
20.212458793073893 seconds in game passed.
Action: tensor([[[-0.0024,  0.6160],
         [-0.0041,  0.3334],
         [-0.0045,  0.2292],
         [-0.0049,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.492951, steer=-0.003267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19481677327916
+++++++++++++: 1.7494887563683454
20.23745879344642 seconds in game passed.
At 20.23745879344642 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6185],
         [-0.0066,  0.3300],
         [-0.0073,  0.2254],
         [-0.0077,  0.1726]]])
agent 0 action: VehicleControl(throttle=0.603288, steer=-0.005519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7494887563683454
Current reward: 0.5148925057578202
Current mitigation activation: 0
#############################
Total reward: 53.70970927903698
20.26245879381895 seconds in game passed.
Action: tensor([[[-0.0033,  0.6185],
         [-0.0066,  0.3300],
         [-0.0073,  0.2254],
         [-0.0077,  0.1726]]])
agent 0 action: VehicleControl(throttle=0.557087, steer=-0.005208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.70970927903698
20.28745879419148 seconds in game passed.
Action: tensor([[[-0.0033,  0.6185],
         [-0.0066,  0.3300],
         [-0.0073,  0.2254],
         [-0.0077,  0.1726]]])
agent 0 action: VehicleControl(throttle=0.529460, steer=-0.005263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.70970927903698
20.31245879456401 seconds in game passed.
Action: tensor([[[-0.0033,  0.6185],
         [-0.0066,  0.3300],
         [-0.0073,  0.2254],
         [-0.0077,  0.1726]]])
agent 0 action: VehicleControl(throttle=0.503824, steer=-0.005319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.70970927903698
+++++++++++++: 1.7284049010512132
20.337458794936538 seconds in game passed.
At 20.337458794936538 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6276],
         [-0.0042,  0.3318],
         [-0.0048,  0.2260],
         [-0.0052,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.509087, steer=-0.003294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7284049010512132
Current reward: 0.5233128391493522
Current mitigation activation: 0
#############################
Total reward: 54.233022118186334
20.362458795309067 seconds in game passed.
Action: tensor([[[-0.0025,  0.6276],
         [-0.0042,  0.3318],
         [-0.0048,  0.2260],
         [-0.0052,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.484735, steer=-0.003675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.233022118186334
20.387458795681596 seconds in game passed.
Action: tensor([[[-0.0025,  0.6276],
         [-0.0042,  0.3318],
         [-0.0048,  0.2260],
         [-0.0052,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.465293, steer=-0.003712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.233022118186334
20.412458796054125 seconds in game passed.
Action: tensor([[[-0.0025,  0.6276],
         [-0.0042,  0.3318],
         [-0.0048,  0.2260],
         [-0.0052,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.447523, steer=-0.003749, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.233022118186334
+++++++++++++: 1.7216879238848428
20.437458796426654 seconds in game passed.
At 20.437458796426654 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.2565e-04,  6.0938e-01],
         [-6.5599e-04,  3.2770e-01],
         [-1.2249e-03,  2.2532e-01],
         [-1.9844e-03,  1.7282e-01]]])
agent 0 action: VehicleControl(throttle=0.390130, steer=0.000071, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7216879238848428
Current reward: 0.5290881884387647
Current mitigation activation: 0
#############################
Total reward: 54.7621103066251
20.462458796799183 seconds in game passed.
Action: tensor([[[ 5.2565e-04,  6.0938e-01],
         [-6.5599e-04,  3.2770e-01],
         [-1.2249e-03,  2.2532e-01],
         [-1.9844e-03,  1.7282e-01]]])
agent 0 action: VehicleControl(throttle=0.377955, steer=-0.000542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.7621103066251
20.487458797171712 seconds in game passed.
Action: tensor([[[ 5.2565e-04,  6.0938e-01],
         [-6.5599e-04,  3.2770e-01],
         [-1.2249e-03,  2.2532e-01],
         [-1.9844e-03,  1.7282e-01]]])
agent 0 action: VehicleControl(throttle=0.363408, steer=-0.000521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.7621103066251
20.51245879754424 seconds in game passed.
Action: tensor([[[ 5.2565e-04,  6.0938e-01],
         [-6.5599e-04,  3.2770e-01],
         [-1.2249e-03,  2.2532e-01],
         [-1.9844e-03,  1.7282e-01]]])
agent 0 action: VehicleControl(throttle=0.350976, steer=-0.000500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.7621103066251
+++++++++++++: 1.7266741901476295
20.53745879791677 seconds in game passed.
At 20.53745879791677 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6162],
         [0.0031, 0.3324],
         [0.0027, 0.2285],
         [0.0018, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.245413, steer=0.003541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7266741901476295
Current reward: 0.532788905424994
Current mitigation activation: 0
#############################
Total reward: 55.29489921205009
20.5624587982893 seconds in game passed.
Action: tensor([[[0.0037, 0.6162],
         [0.0031, 0.3324],
         [0.0027, 0.2285],
         [0.0018, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.246834, steer=0.002915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.29489921205009
20.587458798661828 seconds in game passed.
Action: tensor([[[0.0037, 0.6162],
         [0.0031, 0.3324],
         [0.0027, 0.2285],
         [0.0018, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.240160, steer=0.002956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.29489921205009
20.612458799034357 seconds in game passed.
Action: tensor([[[0.0037, 0.6162],
         [0.0031, 0.3324],
         [0.0027, 0.2285],
         [0.0018, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.236108, steer=0.002996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.29489921205009
+++++++++++++: 1.7441800959875091
20.637458799406886 seconds in game passed.
At 20.637458799406886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0041, 0.6235],
         [0.0026, 0.3351],
         [0.0021, 0.2303],
         [0.0012, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.211661, steer=0.002748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7441800959875091
Current reward: 0.5344390052373564
Current mitigation activation: 0
#############################
Total reward: 55.82933821728745
20.662458799779415 seconds in game passed.
Action: tensor([[[0.0041, 0.6235],
         [0.0026, 0.3351],
         [0.0021, 0.2303],
         [0.0012, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.215162, steer=0.002794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.82933821728745
20.687458800151944 seconds in game passed.
Action: tensor([[[0.0041, 0.6235],
         [0.0026, 0.3351],
         [0.0021, 0.2303],
         [0.0012, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.217922, steer=0.002798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.82933821728745
20.712458800524473 seconds in game passed.
Action: tensor([[[0.0041, 0.6235],
         [0.0026, 0.3351],
         [0.0021, 0.2303],
         [0.0012, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.222404, steer=0.002802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.82933821728745
+++++++++++++: 1.7756063548198204
20.737458800897002 seconds in game passed.
At 20.737458800897002 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6206],
         [0.0024, 0.3330],
         [0.0022, 0.2287],
         [0.0015, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.274221, steer=0.001938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7756063548198204
Current reward: 0.5340471857098096
Current mitigation activation: 0
#############################
Total reward: 56.36338540299726
20.76245880126953 seconds in game passed.
Action: tensor([[[0.0022, 0.6206],
         [0.0024, 0.3330],
         [0.0022, 0.2287],
         [0.0015, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.276553, steer=0.002079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.36338540299726
20.78745880164206 seconds in game passed.
Action: tensor([[[0.0022, 0.6206],
         [0.0024, 0.3330],
         [0.0022, 0.2287],
         [0.0015, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.284650, steer=0.002077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.36338540299726
20.81245880201459 seconds in game passed.
Action: tensor([[[0.0022, 0.6206],
         [0.0024, 0.3330],
         [0.0022, 0.2287],
         [0.0015, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.293096, steer=0.002075, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.36338540299726
+++++++++++++: 1.8184905292532874
20.83745880238712 seconds in game passed.
At 20.83745880238712 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.3592e-04,  6.1419e-01],
         [ 1.3413e-04,  3.3032e-01],
         [-1.0091e-04,  2.2713e-01],
         [-9.8573e-04,  1.7462e-01]]])
agent 0 action: VehicleControl(throttle=0.330355, steer=-0.000516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8184905292532874
Current reward: 0.5323542145014958
Current mitigation activation: 0
#############################
Total reward: 56.895739617498755
20.862458802759647 seconds in game passed.
Action: tensor([[[-1.3592e-04,  6.1419e-01],
         [ 1.3413e-04,  3.3032e-01],
         [-1.0091e-04,  2.2713e-01],
         [-9.8573e-04,  1.7462e-01]]])
agent 0 action: VehicleControl(throttle=0.336610, steer=-0.000111, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.895739617498755
20.887458803132176 seconds in game passed.
Action: tensor([[[-1.3592e-04,  6.1419e-01],
         [ 1.3413e-04,  3.3032e-01],
         [-1.0091e-04,  2.2713e-01],
         [-9.8573e-04,  1.7462e-01]]])
agent 0 action: VehicleControl(throttle=0.346631, steer=-0.000134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.895739617498755
20.912458803504705 seconds in game passed.
Action: tensor([[[-1.3592e-04,  6.1419e-01],
         [ 1.3413e-04,  3.3032e-01],
         [-1.0091e-04,  2.2713e-01],
         [-9.8573e-04,  1.7462e-01]]])
agent 0 action: VehicleControl(throttle=0.357013, steer=-0.000157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.895739617498755
+++++++++++++: 1.8673162875734934
20.937458803877234 seconds in game passed.
At 20.937458803877234 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.6194],
         [-0.0016,  0.3304],
         [-0.0020,  0.2258],
         [-0.0029,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.417032, steer=-0.002112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8673162875734934
Current reward: 0.5305065651568341
Current mitigation activation: 0
#############################
Total reward: 57.42624618265559
20.962458804249763 seconds in game passed.
Action: tensor([[[-0.0019,  0.6194],
         [-0.0016,  0.3304],
         [-0.0020,  0.2258],
         [-0.0029,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.422583, steer=-0.001811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.42624618265559
20.987458804622293 seconds in game passed.
Action: tensor([[[-0.0019,  0.6194],
         [-0.0016,  0.3304],
         [-0.0020,  0.2258],
         [-0.0029,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.433460, steer=-0.001831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.42624618265559
21.01245880499482 seconds in game passed.
Action: tensor([[[-0.0019,  0.6194],
         [-0.0016,  0.3304],
         [-0.0020,  0.2258],
         [-0.0029,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.443937, steer=-0.001852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.42624618265559
+++++++++++++: 1.917425414601888
21.03745880536735 seconds in game passed.
At 21.03745880536735 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0036,  0.6268],
         [-0.0029,  0.3328],
         [-0.0029,  0.2268],
         [-0.0030,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.443948, steer=-0.003538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.917425414601888
Current reward: 0.5292969338293075
Current mitigation activation: 0
#############################
Total reward: 57.9555431164849
21.06245880573988 seconds in game passed.
Action: tensor([[[-0.0036,  0.6268],
         [-0.0029,  0.3328],
         [-0.0029,  0.2268],
         [-0.0030,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.455509, steer=-0.003297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.9555431164849
21.08745880611241 seconds in game passed.
Action: tensor([[[-0.0036,  0.6268],
         [-0.0029,  0.3328],
         [-0.0029,  0.2268],
         [-0.0030,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.465646, steer=-0.003332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.9555431164849
21.112458806484938 seconds in game passed.
Action: tensor([[[-0.0036,  0.6268],
         [-0.0029,  0.3328],
         [-0.0029,  0.2268],
         [-0.0030,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.475564, steer=-0.003366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.9555431164849
+++++++++++++: 1.9649729087728118
21.137458806857467 seconds in game passed.
At 21.137458806857467 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.0280e-04,  6.0557e-01],
         [-2.5594e-04,  3.2707e-01],
         [-3.1769e-05,  2.2466e-01],
         [ 4.6104e-05,  1.7244e-01]]])
agent 0 action: VehicleControl(throttle=0.473754, steer=-0.000174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9649729087728118
Current reward: 0.5292253812803206
Current mitigation activation: 0
#############################
Total reward: 58.48476849776522
21.162458807229996 seconds in game passed.
Action: tensor([[[-5.0280e-04,  6.0557e-01],
         [-2.5594e-04,  3.2707e-01],
         [-3.1769e-05,  2.2466e-01],
         [ 4.6104e-05,  1.7244e-01]]])
agent 0 action: VehicleControl(throttle=0.485025, steer=-0.000663, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.48476849776522
21.187458807602525 seconds in game passed.
Action: tensor([[[-5.0280e-04,  6.0557e-01],
         [-2.5594e-04,  3.2707e-01],
         [-3.1769e-05,  2.2466e-01],
         [ 4.6104e-05,  1.7244e-01]]])
agent 0 action: VehicleControl(throttle=0.494710, steer=-0.000626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.48476849776522
21.212458807975054 seconds in game passed.
Action: tensor([[[-5.0280e-04,  6.0557e-01],
         [-2.5594e-04,  3.2707e-01],
         [-3.1769e-05,  2.2466e-01],
         [ 4.6104e-05,  1.7244e-01]]])
agent 0 action: VehicleControl(throttle=0.504162, steer=-0.000589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.48476849776522
+++++++++++++: 2.008939740408168
21.237458808347583 seconds in game passed.
At 21.237458808347583 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0007, 0.6050],
         [0.0015, 0.3250],
         [0.0018, 0.2222],
         [0.0018, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.582417, steer=0.001265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.008939740408168
Current reward: 0.5302869035935676
Current mitigation activation: 0
#############################
Total reward: 59.01505540135879
21.262458808720112 seconds in game passed.
Action: tensor([[[0.0007, 0.6050],
         [0.0015, 0.3250],
         [0.0018, 0.2222],
         [0.0018, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.582851, steer=0.001047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01505540135879
21.28745880909264 seconds in game passed.
Action: tensor([[[0.0007, 0.6050],
         [0.0015, 0.3250],
         [0.0018, 0.2222],
         [0.0018, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.590131, steer=0.001125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01505540135879
21.31245880946517 seconds in game passed.
Action: tensor([[[0.0007, 0.6050],
         [0.0015, 0.3250],
         [0.0018, 0.2222],
         [0.0018, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.596201, steer=0.001204, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01505540135879
+++++++++++++: 2.04903141145341
21.3374588098377 seconds in game passed.
At 21.3374588098377 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6144],
         [0.0036, 0.3296],
         [0.0032, 0.2250],
         [0.0022, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.532816, steer=0.003519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.04903141145341
Current reward: 0.5323728726876366
Current mitigation activation: 0
#############################
Total reward: 59.547428274046425
21.362458810210228 seconds in game passed.
Action: tensor([[[0.0025, 0.6144],
         [0.0036, 0.3296],
         [0.0032, 0.2250],
         [0.0022, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.544709, steer=0.003227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.547428274046425
21.387458810582757 seconds in game passed.
Action: tensor([[[0.0025, 0.6144],
         [0.0036, 0.3296],
         [0.0032, 0.2250],
         [0.0022, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.549529, steer=0.003307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.547428274046425
21.412458810955286 seconds in game passed.
Action: tensor([[[0.0025, 0.6144],
         [0.0036, 0.3296],
         [0.0032, 0.2250],
         [0.0022, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.554490, steer=0.003387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.547428274046425
+++++++++++++: 2.0850428117717574
21.437458811327815 seconds in game passed.
At 21.437458811327815 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6137],
         [0.0039, 0.3270],
         [0.0037, 0.2230],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.647760, steer=0.003616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0850428117717574
Current reward: 0.5353811368933714
Current mitigation activation: 0
#############################
Total reward: 60.082809410939795
21.462458811700344 seconds in game passed.
Action: tensor([[[0.0025, 0.6137],
         [0.0039, 0.3270],
         [0.0037, 0.2230],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.645058, steer=0.003628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.082809410939795
21.487458812072873 seconds in game passed.
Action: tensor([[[0.0025, 0.6137],
         [0.0039, 0.3270],
         [0.0037, 0.2230],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.651731, steer=0.003670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.082809410939795
21.512458812445402 seconds in game passed.
Action: tensor([[[0.0025, 0.6137],
         [0.0039, 0.3270],
         [0.0037, 0.2230],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.658457, steer=0.003713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.082809410939795
+++++++++++++: 2.121518829191266
21.53745881281793 seconds in game passed.
At 21.53745881281793 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.6062],
         [0.0038, 0.3237],
         [0.0039, 0.2206],
         [0.0031, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.706919, steer=0.003212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.121518829191266
Current reward: 0.5385959458602033
Current mitigation activation: 0
#############################
Total reward: 60.6214053568
21.56245881319046 seconds in game passed.
Action: tensor([[[0.0014, 0.6062],
         [0.0038, 0.3237],
         [0.0039, 0.2206],
         [0.0031, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.710875, steer=0.003291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.6214053568
21.58745881356299 seconds in game passed.
Action: tensor([[[0.0014, 0.6062],
         [0.0038, 0.3237],
         [0.0039, 0.2206],
         [0.0031, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.719114, steer=0.003287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.6214053568
21.61245881393552 seconds in game passed.
Action: tensor([[[0.0014, 0.6062],
         [0.0038, 0.3237],
         [0.0039, 0.2206],
         [0.0031, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.727302, steer=0.003282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.6214053568
+++++++++++++: 2.159045194174737
21.637458814308047 seconds in game passed.
At 21.637458814308047 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.8328e-04, 6.1552e-01],
         [3.2396e-03, 3.2801e-01],
         [3.1876e-03, 2.2292e-01],
         [2.1110e-03, 1.7044e-01]]])
agent 0 action: VehicleControl(throttle=0.675264, steer=0.002524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.159045194174737
Current reward: 0.5419153390791499
Current mitigation activation: 0
#############################
Total reward: 61.16332069587914
21.662458814680576 seconds in game passed.
Action: tensor([[[4.8328e-04, 6.1552e-01],
         [3.2396e-03, 3.2801e-01],
         [3.1876e-03, 2.2292e-01],
         [2.1110e-03, 1.7044e-01]]])
agent 0 action: VehicleControl(throttle=0.689265, steer=0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.16332069587914
21.687458815053105 seconds in game passed.
Action: tensor([[[4.8328e-04, 6.1552e-01],
         [3.2396e-03, 3.2801e-01],
         [3.1876e-03, 2.2292e-01],
         [2.1110e-03, 1.7044e-01]]])
agent 0 action: VehicleControl(throttle=0.696738, steer=0.002630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.16332069587914
21.712458815425634 seconds in game passed.
Action: tensor([[[4.8328e-04, 6.1552e-01],
         [3.2396e-03, 3.2801e-01],
         [3.1876e-03, 2.2292e-01],
         [2.1110e-03, 1.7044e-01]]])
agent 0 action: VehicleControl(throttle=0.704070, steer=0.002620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.16332069587914
+++++++++++++: 2.197536476631553
21.737458815798163 seconds in game passed.
At 21.737458815798163 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6212],
         [0.0053, 0.3279],
         [0.0057, 0.2223],
         [0.0051, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.773183, steer=0.005027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.197536476631553
Current reward: 0.5453338418244016
Current mitigation activation: 0
#############################
Total reward: 61.708654537703545
21.762458816170692 seconds in game passed.
Action: tensor([[[0.0026, 0.6212],
         [0.0053, 0.3279],
         [0.0057, 0.2223],
         [0.0051, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.773742, steer=0.004654, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.708654537703545
21.78745881654322 seconds in game passed.
Action: tensor([[[0.0026, 0.6212],
         [0.0053, 0.3279],
         [0.0057, 0.2223],
         [0.0051, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.780753, steer=0.004679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.708654537703545
21.81245881691575 seconds in game passed.
Action: tensor([[[0.0026, 0.6212],
         [0.0053, 0.3279],
         [0.0057, 0.2223],
         [0.0051, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.787567, steer=0.004703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.708654537703545
+++++++++++++: 2.236944203801915
21.83745881728828 seconds in game passed.
At 21.83745881728828 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0049, 0.6318],
         [0.0069, 0.3306],
         [0.0074, 0.2233],
         [0.0070, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.802633, steer=0.006859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.236944203801915
Current reward: 0.5488404730559328
Current mitigation activation: 0
#############################
Total reward: 62.25749501075948
21.86245881766081 seconds in game passed.
Action: tensor([[[0.0049, 0.6318],
         [0.0069, 0.3306],
         [0.0074, 0.2233],
         [0.0070, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.784779, steer=0.006584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.25749501075948
21.887458818033338 seconds in game passed.
Action: tensor([[[0.0049, 0.6318],
         [0.0069, 0.3306],
         [0.0074, 0.2233],
         [0.0070, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.770774, steer=0.006657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.25749501075948
21.912458818405867 seconds in game passed.
Action: tensor([[[0.0049, 0.6318],
         [0.0069, 0.3306],
         [0.0074, 0.2233],
         [0.0070, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.755908, steer=0.006730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.25749501075948
+++++++++++++: 2.2528397219662684
21.937458818778396 seconds in game passed.
At 21.937458818778396 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0095, 0.6443],
         [0.0140, 0.3352],
         [0.0156, 0.2251],
         [0.0152, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.698398, steer=0.013914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2528397219662684
Current reward: 0.5554555093535156
Current mitigation activation: 0
#############################
Total reward: 62.81295052011299
21.962458819150925 seconds in game passed.
Action: tensor([[[0.0095, 0.6443],
         [0.0140, 0.3352],
         [0.0156, 0.2251],
         [0.0152, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.686060, steer=0.012910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.81295052011299
21.987458819523454 seconds in game passed.
Action: tensor([[[0.0095, 0.6443],
         [0.0140, 0.3352],
         [0.0156, 0.2251],
         [0.0152, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.669365, steer=0.013076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.81295052011299
22.012458819895983 seconds in game passed.
Action: tensor([[[0.0095, 0.6443],
         [0.0140, 0.3352],
         [0.0156, 0.2251],
         [0.0152, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.652814, steer=0.013242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.81295052011299
+++++++++++++: 2.2506959111382208
22.03745882026851 seconds in game passed.
At 22.03745882026851 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0092, 0.6327],
         [0.0095, 0.3324],
         [0.0098, 0.2246],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.623257, steer=0.009938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2506959111382208
Current reward: 0.5642363952083793
Current mitigation activation: 0
#############################
Total reward: 63.377186915321374
22.06245882064104 seconds in game passed.
Action: tensor([[[0.0092, 0.6327],
         [0.0095, 0.3324],
         [0.0098, 0.2246],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.608716, steer=0.010660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.377186915321374
22.08745882101357 seconds in game passed.
Action: tensor([[[0.0092, 0.6327],
         [0.0095, 0.3324],
         [0.0098, 0.2246],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.593134, steer=0.010808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.377186915321374
22.1124588213861 seconds in game passed.
Action: tensor([[[0.0092, 0.6327],
         [0.0095, 0.3324],
         [0.0098, 0.2246],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.578169, steer=0.010955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.377186915321374
+++++++++++++: 2.2513867070348046
22.137458821758628 seconds in game passed.
At 22.137458821758628 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6207],
         [0.0043, 0.3297],
         [0.0043, 0.2240],
         [0.0035, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.538488, steer=0.004929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2513867070348046
Current reward: 0.5723789323464055
Current mitigation activation: 0
#############################
Total reward: 63.94956584766778
22.162458822131157 seconds in game passed.
Action: tensor([[[0.0034, 0.6207],
         [0.0043, 0.3297],
         [0.0043, 0.2240],
         [0.0035, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.527272, steer=0.005993, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.94956584766778
22.187458822503686 seconds in game passed.
Action: tensor([[[0.0034, 0.6207],
         [0.0043, 0.3297],
         [0.0043, 0.2240],
         [0.0035, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.514004, steer=0.006044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.94956584766778
22.212458822876215 seconds in game passed.
Action: tensor([[[0.0034, 0.6207],
         [0.0043, 0.3297],
         [0.0043, 0.2240],
         [0.0035, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.501615, steer=0.006095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.94956584766778
+++++++++++++: 2.2576013014374414
22.237458823248744 seconds in game passed.
At 22.237458823248744 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6280],
         [0.0046, 0.3309],
         [0.0046, 0.2243],
         [0.0038, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.520727, steer=0.006346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2576013014374414
Current reward: 0.5795370985923498
Current mitigation activation: 0
#############################
Total reward: 64.52910294626012
22.262458823621273 seconds in game passed.
Action: tensor([[[0.0035, 0.6280],
         [0.0046, 0.3309],
         [0.0046, 0.2243],
         [0.0038, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.506139, steer=0.006345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.52910294626012
22.287458823993802 seconds in game passed.
Action: tensor([[[0.0035, 0.6280],
         [0.0046, 0.3309],
         [0.0046, 0.2243],
         [0.0038, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.495552, steer=0.006380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.52910294626012
22.31245882436633 seconds in game passed.
Action: tensor([[[0.0035, 0.6280],
         [0.0046, 0.3309],
         [0.0046, 0.2243],
         [0.0038, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.485424, steer=0.006415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.52910294626012
+++++++++++++: 2.270355285643433
22.33745882473886 seconds in game passed.
At 22.33745882473886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0043, 0.6095],
         [0.0056, 0.3249],
         [0.0055, 0.2213],
         [0.0047, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.506532, steer=0.007488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.270355285643433
Current reward: 0.5856185684286784
Current mitigation activation: 0
#############################
Total reward: 65.1147215146888
22.36245882511139 seconds in game passed.
Action: tensor([[[0.0043, 0.6095],
         [0.0056, 0.3249],
         [0.0055, 0.2213],
         [0.0047, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.495369, steer=0.007335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.1147215146888
22.387458825483918 seconds in game passed.
Action: tensor([[[0.0043, 0.6095],
         [0.0056, 0.3249],
         [0.0055, 0.2213],
         [0.0047, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.487821, steer=0.007358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.1147215146888
22.412458825856447 seconds in game passed.
Action: tensor([[[0.0043, 0.6095],
         [0.0056, 0.3249],
         [0.0055, 0.2213],
         [0.0047, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.480493, steer=0.007380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.1147215146888
+++++++++++++: 2.2880302032979434
22.437458826228976 seconds in game passed.
At 22.437458826228976 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0030, 0.6093],
         [0.0042, 0.3254],
         [0.0037, 0.2219],
         [0.0023, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.449637, steer=0.005843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2880302032979434
Current reward: 0.5909002938684043
Current mitigation activation: 0
#############################
Total reward: 65.7056218085572
22.462458826601505 seconds in game passed.
Action: tensor([[[0.0030, 0.6093],
         [0.0042, 0.3254],
         [0.0037, 0.2219],
         [0.0023, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.444111, steer=0.006105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.7056218085572
22.487458826974034 seconds in game passed.
Action: tensor([[[0.0030, 0.6093],
         [0.0042, 0.3254],
         [0.0037, 0.2219],
         [0.0023, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.436519, steer=0.006109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.7056218085572
22.512458827346563 seconds in game passed.
Action: tensor([[[0.0030, 0.6093],
         [0.0042, 0.3254],
         [0.0037, 0.2219],
         [0.0023, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.429457, steer=0.006114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.7056218085572
+++++++++++++: 2.308886280603404
22.537458827719092 seconds in game passed.
At 22.537458827719092 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8773e-03,  6.1335e-01],
         [ 1.8868e-03,  3.2609e-01],
         [ 1.1955e-03,  2.2210e-01],
         [-5.4419e-05,  1.7004e-01]]])
agent 0 action: VehicleControl(throttle=0.441117, steer=0.003973, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.308886280603404
Current reward: 0.595661824035996
Current mitigation activation: 0
#############################
Total reward: 66.3012836325932
22.56245882809162 seconds in game passed.
Action: tensor([[[ 1.8773e-03,  6.1335e-01],
         [ 1.8868e-03,  3.2609e-01],
         [ 1.1955e-03,  2.2210e-01],
         [-5.4419e-05,  1.7004e-01]]])
agent 0 action: VehicleControl(throttle=0.432735, steer=0.004315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.3012836325932
22.58745882846415 seconds in game passed.
Action: tensor([[[ 1.8773e-03,  6.1335e-01],
         [ 1.8868e-03,  3.2609e-01],
         [ 1.1955e-03,  2.2210e-01],
         [-5.4419e-05,  1.7004e-01]]])
agent 0 action: VehicleControl(throttle=0.426696, steer=0.004303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.3012836325932
22.61245882883668 seconds in game passed.
Action: tensor([[[ 1.8773e-03,  6.1335e-01],
         [ 1.8868e-03,  3.2609e-01],
         [ 1.1955e-03,  2.2210e-01],
         [-5.4419e-05,  1.7004e-01]]])
agent 0 action: VehicleControl(throttle=0.420912, steer=0.004291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.3012836325932
+++++++++++++: 2.333212496028642
22.63745882920921 seconds in game passed.
At 22.63745882920921 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6087],
         [0.0041, 0.3258],
         [0.0041, 0.2223],
         [0.0033, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.378096, steer=0.006412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.333212496028642
Current reward: 0.5999001274464324
Current mitigation activation: 0
#############################
Total reward: 66.90118376003963
22.662458829581738 seconds in game passed.
Action: tensor([[[0.0032, 0.6087],
         [0.0041, 0.3258],
         [0.0041, 0.2223],
         [0.0033, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.377157, steer=0.006079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.90118376003963
22.687458829954267 seconds in game passed.
Action: tensor([[[0.0032, 0.6087],
         [0.0041, 0.3258],
         [0.0041, 0.2223],
         [0.0033, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.372602, steer=0.006096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.90118376003963
22.712458830326796 seconds in game passed.
Action: tensor([[[0.0032, 0.6087],
         [0.0041, 0.3258],
         [0.0041, 0.2223],
         [0.0033, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.368632, steer=0.006113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.90118376003963
+++++++++++++: 2.360607876310709
22.737458830699325 seconds in game passed.
At 22.737458830699325 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6215],
         [0.0061, 0.3300],
         [0.0060, 0.2239],
         [0.0049, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.343797, steer=0.008020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.360607876310709
Current reward: 0.6037134406713047
Current mitigation activation: 0
#############################
Total reward: 67.50489720071093
22.762458831071854 seconds in game passed.
Action: tensor([[[0.0042, 0.6215],
         [0.0061, 0.3300],
         [0.0060, 0.2239],
         [0.0049, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.342012, steer=0.007716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.50489720071093
22.787458831444383 seconds in game passed.
Action: tensor([[[0.0042, 0.6215],
         [0.0061, 0.3300],
         [0.0060, 0.2239],
         [0.0049, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.338517, steer=0.007728, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.50489720071093
22.81245883181691 seconds in game passed.
Action: tensor([[[0.0042, 0.6215],
         [0.0061, 0.3300],
         [0.0060, 0.2239],
         [0.0049, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.335550, steer=0.007740, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.50489720071093
+++++++++++++: 2.3918990616628646
22.83745883218944 seconds in game passed.
At 22.83745883218944 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0038, 0.6132],
         [0.0047, 0.3281],
         [0.0046, 0.2234],
         [0.0037, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.314694, steer=0.006566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3918990616628646
Current reward: 0.6070405369482612
Current mitigation activation: 0
#############################
Total reward: 68.11193773765919
22.86245883256197 seconds in game passed.
Action: tensor([[[0.0038, 0.6132],
         [0.0047, 0.3281],
         [0.0046, 0.2234],
         [0.0037, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.314470, steer=0.006737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.11193773765919
22.8874588329345 seconds in game passed.
Action: tensor([[[0.0038, 0.6132],
         [0.0047, 0.3281],
         [0.0046, 0.2234],
         [0.0037, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.312961, steer=0.006715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.11193773765919
22.912458833307028 seconds in game passed.
Action: tensor([[[0.0038, 0.6132],
         [0.0047, 0.3281],
         [0.0046, 0.2234],
         [0.0037, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.312186, steer=0.006694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.11193773765919
+++++++++++++: 2.4273302425309713
22.937458833679557 seconds in game passed.
At 22.937458833679557 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.5098e-04,  6.0537e-01],
         [ 7.4954e-04,  3.2580e-01],
         [ 4.3140e-04,  2.2248e-01],
         [-2.7193e-04,  1.6878e-01]]])
agent 0 action: VehicleControl(throttle=0.315690, steer=0.002515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4273302425309713
Current reward: 0.6098995155073768
Current mitigation activation: 0
#############################
Total reward: 68.72183725316657
22.962458834052086 seconds in game passed.
Action: tensor([[[ 9.5098e-04,  6.0537e-01],
         [ 7.4954e-04,  3.2580e-01],
         [ 4.3140e-04,  2.2248e-01],
         [-2.7193e-04,  1.6878e-01]]])
agent 0 action: VehicleControl(throttle=0.316296, steer=0.003052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72183725316657
22.987458834424615 seconds in game passed.
Action: tensor([[[ 9.5098e-04,  6.0537e-01],
         [ 7.4954e-04,  3.2580e-01],
         [ 4.3140e-04,  2.2248e-01],
         [-2.7193e-04,  1.6878e-01]]])
agent 0 action: VehicleControl(throttle=0.317743, steer=0.002915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72183725316657
23.012458834797144 seconds in game passed.
Action: tensor([[[ 9.5098e-04,  6.0537e-01],
         [ 7.4954e-04,  3.2580e-01],
         [ 4.3140e-04,  2.2248e-01],
         [-2.7193e-04,  1.6878e-01]]])
agent 0 action: VehicleControl(throttle=0.319651, steer=0.002778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72183725316657
+++++++++++++: 2.4664526987538093
23.037458835169673 seconds in game passed.
At 23.037458835169673 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6249],
         [-0.0008,  0.3299],
         [-0.0011,  0.2235],
         [-0.0019,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.376007, steer=0.000608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4664526987538093
Current reward: 0.6123947260823139
Current mitigation activation: 0
#############################
Total reward: 69.33423197924888
23.062458835542202 seconds in game passed.
Action: tensor([[[-0.0015,  0.6249],
         [-0.0008,  0.3299],
         [-0.0011,  0.2235],
         [-0.0019,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.373713, steer=0.000827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.33423197924888
23.08745883591473 seconds in game passed.
Action: tensor([[[-0.0015,  0.6249],
         [-0.0008,  0.3299],
         [-0.0011,  0.2235],
         [-0.0019,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.377288, steer=0.000705, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.33423197924888
23.11245883628726 seconds in game passed.
Action: tensor([[[-0.0015,  0.6249],
         [-0.0008,  0.3299],
         [-0.0011,  0.2235],
         [-0.0019,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.380682, steer=0.000583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.33423197924888
+++++++++++++: 2.50758544894591
23.13745883665979 seconds in game passed.
At 23.13745883665979 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6127],
         [-0.0017,  0.3258],
         [-0.0021,  0.2214],
         [-0.0030,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.408587, steer=-0.000573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.50758544894591
Current reward: 0.6147747657625797
Current mitigation activation: 0
#############################
Total reward: 69.94900674501146
23.162458837032318 seconds in game passed.
Action: tensor([[[-0.0025,  0.6127],
         [-0.0017,  0.3258],
         [-0.0021,  0.2214],
         [-0.0030,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.409811, steer=-0.000462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.94900674501146
23.187458837404847 seconds in game passed.
Action: tensor([[[-0.0025,  0.6127],
         [-0.0017,  0.3258],
         [-0.0021,  0.2214],
         [-0.0030,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.413474, steer=-0.000532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.94900674501146
23.212458837777376 seconds in game passed.
Action: tensor([[[-0.0025,  0.6127],
         [-0.0017,  0.3258],
         [-0.0021,  0.2214],
         [-0.0030,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.416860, steer=-0.000603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.94900674501146
+++++++++++++: 2.547663276246445
23.237458838149905 seconds in game passed.
At 23.237458838149905 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6099],
         [-0.0011,  0.3260],
         [-0.0014,  0.2218],
         [-0.0021,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.383466, steer=0.000260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.547663276246445
Current reward: 0.6174202597277691
Current mitigation activation: 0
#############################
Total reward: 70.56642700473923
23.262458838522434 seconds in game passed.
Action: tensor([[[-0.0013,  0.6099],
         [-0.0011,  0.3260],
         [-0.0014,  0.2218],
         [-0.0021,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.389539, steer=0.000043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.56642700473923
23.287458838894963 seconds in game passed.
Action: tensor([[[-0.0013,  0.6099],
         [-0.0011,  0.3260],
         [-0.0014,  0.2218],
         [-0.0021,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.391698, steer=-0.000020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.56642700473923
23.312458839267492 seconds in game passed.
Action: tensor([[[-0.0013,  0.6099],
         [-0.0011,  0.3260],
         [-0.0014,  0.2218],
         [-0.0021,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.394008, steer=-0.000083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.56642700473923
+++++++++++++: 2.5853944236014375
23.33745883964002 seconds in game passed.
At 23.33745883964002 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0380e-04,  6.0848e-01],
         [ 1.4484e-05,  3.2616e-01],
         [-1.5577e-04,  2.2214e-01],
         [-7.0149e-04,  1.6928e-01]]])
agent 0 action: VehicleControl(throttle=0.373896, steer=0.001235, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5853944236014375
Current reward: 0.6204549556780578
Current mitigation activation: 0
#############################
Total reward: 71.18688196041728
23.36245884001255 seconds in game passed.
Action: tensor([[[ 2.0380e-04,  6.0848e-01],
         [ 1.4484e-05,  3.2616e-01],
         [-1.5577e-04,  2.2214e-01],
         [-7.0149e-04,  1.6928e-01]]])
agent 0 action: VehicleControl(throttle=0.378083, steer=0.000947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.18688196041728
23.38745884038508 seconds in game passed.
Action: tensor([[[ 2.0380e-04,  6.0848e-01],
         [ 1.4484e-05,  3.2616e-01],
         [-1.5577e-04,  2.2214e-01],
         [-7.0149e-04,  1.6928e-01]]])
agent 0 action: VehicleControl(throttle=0.380015, steer=0.000887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.18688196041728
23.41245884075761 seconds in game passed.
Action: tensor([[[ 2.0380e-04,  6.0848e-01],
         [ 1.4484e-05,  3.2616e-01],
         [-1.5577e-04,  2.2214e-01],
         [-7.0149e-04,  1.6928e-01]]])
agent 0 action: VehicleControl(throttle=0.382153, steer=0.000828, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.18688196041728
+++++++++++++: 2.6224889396910496
23.437458841130137 seconds in game passed.
At 23.437458841130137 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.9049e-04,  6.0844e-01],
         [-4.5401e-04,  3.2686e-01],
         [-9.5746e-04,  2.2267e-01],
         [-1.5871e-03,  1.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.358445, steer=0.000242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6224889396910496
Current reward: 0.6236419091200475
Current mitigation activation: 0
#############################
Total reward: 71.81052386953733
23.462458841502666 seconds in game passed.
Action: tensor([[[-2.9049e-04,  6.0844e-01],
         [-4.5401e-04,  3.2686e-01],
         [-9.5746e-04,  2.2267e-01],
         [-1.5871e-03,  1.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.363559, steer=0.000283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.81052386953733
23.487458841875196 seconds in game passed.
Action: tensor([[[-2.9049e-04,  6.0844e-01],
         [-4.5401e-04,  3.2686e-01],
         [-9.5746e-04,  2.2267e-01],
         [-1.5871e-03,  1.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.366045, steer=0.000234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.81052386953733
23.512458842247725 seconds in game passed.
Action: tensor([[[-2.9049e-04,  6.0844e-01],
         [-4.5401e-04,  3.2686e-01],
         [-9.5746e-04,  2.2267e-01],
         [-1.5871e-03,  1.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.368800, steer=0.000185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.81052386953733
+++++++++++++: 2.660265330850067
23.537458842620254 seconds in game passed.
At 23.537458842620254 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1521e-03,  6.1654e-01],
         [ 1.0895e-03,  3.2901e-01],
         [ 7.2992e-04,  2.2344e-01],
         [-4.7505e-05,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.377640, steer=0.001873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.660265330850067
Current reward: 0.6268161231793725
Current mitigation activation: 0
#############################
Total reward: 72.4373399927167
23.562458842992783 seconds in game passed.
Action: tensor([[[ 1.1521e-03,  6.1654e-01],
         [ 1.0895e-03,  3.2901e-01],
         [ 7.2992e-04,  2.2344e-01],
         [-4.7505e-05,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.379900, steer=0.001581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.4373399927167
23.58745884336531 seconds in game passed.
Action: tensor([[[ 1.1521e-03,  6.1654e-01],
         [ 1.0895e-03,  3.2901e-01],
         [ 7.2992e-04,  2.2344e-01],
         [-4.7505e-05,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.382879, steer=0.001572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.4373399927167
23.61245884373784 seconds in game passed.
Action: tensor([[[ 1.1521e-03,  6.1654e-01],
         [ 1.0895e-03,  3.2901e-01],
         [ 7.2992e-04,  2.2344e-01],
         [-4.7505e-05,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.385858, steer=0.001563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.4373399927167
+++++++++++++: 2.6991859234090763
23.63745884411037 seconds in game passed.
At 23.63745884411037 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.4605e-03, 6.2060e-01],
         [2.2232e-03, 3.3025e-01],
         [1.5061e-03, 2.2494e-01],
         [4.0899e-04, 1.7099e-01]]])
agent 0 action: VehicleControl(throttle=0.386268, steer=0.003286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6991859234090763
Current reward: 0.6299308915297983
Current mitigation activation: 0
#############################
Total reward: 73.0672708842465
23.6624588444829 seconds in game passed.
Action: tensor([[[3.4605e-03, 6.2060e-01],
         [2.2232e-03, 3.3025e-01],
         [1.5061e-03, 2.2494e-01],
         [4.0899e-04, 1.7099e-01]]])
agent 0 action: VehicleControl(throttle=0.389907, steer=0.002984, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.0672708842465
23.687458844855428 seconds in game passed.
Action: tensor([[[3.4605e-03, 6.2060e-01],
         [2.2232e-03, 3.3025e-01],
         [1.5061e-03, 2.2494e-01],
         [4.0899e-04, 1.7099e-01]]])
agent 0 action: VehicleControl(throttle=0.393195, steer=0.002971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.0672708842465
23.712458845227957 seconds in game passed.
Action: tensor([[[3.4605e-03, 6.2060e-01],
         [2.2232e-03, 3.3025e-01],
         [1.5061e-03, 2.2494e-01],
         [4.0899e-04, 1.7099e-01]]])
agent 0 action: VehicleControl(throttle=0.396431, steer=0.002958, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.0672708842465
+++++++++++++: 2.738336776139563
23.737458845600486 seconds in game passed.
At 23.737458845600486 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5807e-03,  6.1006e-01],
         [-2.2034e-04,  3.2551e-01],
         [-5.2900e-04,  2.2248e-01],
         [-9.3643e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.463776, steer=0.000369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.738336776139563
Current reward: 0.6330979023118009
Current mitigation activation: 0
#############################
Total reward: 73.7003687865583
23.762458845973015 seconds in game passed.
Action: tensor([[[ 1.5807e-03,  6.1006e-01],
         [-2.2034e-04,  3.2551e-01],
         [-5.2900e-04,  2.2248e-01],
         [-9.3643e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.461000, steer=0.000732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.7003687865583
23.787458846345544 seconds in game passed.
Action: tensor([[[ 1.5807e-03,  6.1006e-01],
         [-2.2034e-04,  3.2551e-01],
         [-5.2900e-04,  2.2248e-01],
         [-9.3643e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.464702, steer=0.000673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.7003687865583
23.812458846718073 seconds in game passed.
Action: tensor([[[ 1.5807e-03,  6.1006e-01],
         [-2.2034e-04,  3.2551e-01],
         [-5.2900e-04,  2.2248e-01],
         [-9.3643e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.467728, steer=0.000614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.7003687865583
+++++++++++++: 2.7765938821945517
23.837458847090602 seconds in game passed.
At 23.837458847090602 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.3817e-04,  6.1983e-01],
         [-2.0217e-03,  3.2968e-01],
         [-2.3961e-03,  2.2455e-01],
         [-2.9093e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.419435, steer=-0.001529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7765938821945517
Current reward: 0.6364263564784689
Current mitigation activation: 0
#############################
Total reward: 74.33679514303677
23.86245884746313 seconds in game passed.
Action: tensor([[[-3.3817e-04,  6.1983e-01],
         [-2.0217e-03,  3.2968e-01],
         [-2.3961e-03,  2.2455e-01],
         [-2.9093e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.426543, steer=-0.001252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.33679514303677
23.88745884783566 seconds in game passed.
Action: tensor([[[-3.3817e-04,  6.1983e-01],
         [-2.0217e-03,  3.2968e-01],
         [-2.3961e-03,  2.2455e-01],
         [-2.9093e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.427976, steer=-0.001320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.33679514303677
23.91245884820819 seconds in game passed.
Action: tensor([[[-3.3817e-04,  6.1983e-01],
         [-2.0217e-03,  3.2968e-01],
         [-2.3961e-03,  2.2455e-01],
         [-2.9093e-03,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.429459, steer=-0.001389, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.33679514303677
+++++++++++++: 2.8115439776597873
23.937458848580718 seconds in game passed.
At 23.937458848580718 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.6131],
         [-0.0026,  0.3272],
         [-0.0031,  0.2227],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.452838, steer=-0.002016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8115439776597873
Current reward: 0.6401516550144268
Current mitigation activation: 0
#############################
Total reward: 74.97694679805119
23.962458848953247 seconds in game passed.
Action: tensor([[[-0.0008,  0.6131],
         [-0.0026,  0.3272],
         [-0.0031,  0.2227],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.452062, steer=-0.001950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.97694679805119
23.987458849325776 seconds in game passed.
Action: tensor([[[-0.0008,  0.6131],
         [-0.0026,  0.3272],
         [-0.0031,  0.2227],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.453470, steer=-0.001983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.97694679805119
24.012458849698305 seconds in game passed.
Action: tensor([[[-0.0008,  0.6131],
         [-0.0026,  0.3272],
         [-0.0031,  0.2227],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.454594, steer=-0.002015, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.97694679805119
+++++++++++++: 2.8451683358591
24.037458850070834 seconds in game passed.
At 24.037458850070834 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0041,  0.6189],
         [-0.0073,  0.3298],
         [-0.0080,  0.2240],
         [-0.0083,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.419047, steer=-0.006829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8451683358591
Current reward: 0.6440280779082501
Current mitigation activation: 0
#############################
Total reward: 75.62097487595943
24.062458850443363 seconds in game passed.
Action: tensor([[[-0.0041,  0.6189],
         [-0.0073,  0.3298],
         [-0.0080,  0.2240],
         [-0.0083,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.422541, steer=-0.006098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.62097487595943
24.087458850815892 seconds in game passed.
Action: tensor([[[-0.0041,  0.6189],
         [-0.0073,  0.3298],
         [-0.0080,  0.2240],
         [-0.0083,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.422190, steer=-0.006158, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.62097487595943
24.11245885118842 seconds in game passed.
Action: tensor([[[-0.0041,  0.6189],
         [-0.0073,  0.3298],
         [-0.0080,  0.2240],
         [-0.0083,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.421945, steer=-0.006219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.62097487595943
+++++++++++++: 2.877721120827758
24.13745885156095 seconds in game passed.
At 24.13745885156095 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.5981],
         [-0.0028,  0.3238],
         [-0.0031,  0.2211],
         [-0.0038,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.421855, steer=-0.002373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.877721120827758
Current reward: 0.648011107909293
Current mitigation activation: 0
#############################
Total reward: 76.26898598386873
24.16245885193348 seconds in game passed.
Action: tensor([[[-0.0027,  0.5981],
         [-0.0028,  0.3238],
         [-0.0031,  0.2211],
         [-0.0038,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.421402, steer=-0.003025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26898598386873
24.18745885230601 seconds in game passed.
Action: tensor([[[-0.0027,  0.5981],
         [-0.0028,  0.3238],
         [-0.0031,  0.2211],
         [-0.0038,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.421006, steer=-0.003034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26898598386873
24.212458852678537 seconds in game passed.
Action: tensor([[[-0.0027,  0.5981],
         [-0.0028,  0.3238],
         [-0.0031,  0.2211],
         [-0.0038,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.420647, steer=-0.003043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26898598386873
+++++++++++++: 2.910651226874581
24.237458853051066 seconds in game passed.
At 24.237458853051066 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.1789e-04,  6.0162e-01],
         [ 9.9957e-05,  3.2473e-01],
         [ 1.2775e-04,  2.2164e-01],
         [-3.1169e-04,  1.6822e-01]]])
agent 0 action: VehicleControl(throttle=0.423816, steer=-0.000212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.910651226874581
Current reward: 0.6519479003392141
Current mitigation activation: 0
#############################
Total reward: 76.92093388420794
24.262458853423595 seconds in game passed.
Action: tensor([[[-9.1789e-04,  6.0162e-01],
         [ 9.9957e-05,  3.2473e-01],
         [ 1.2775e-04,  2.2164e-01],
         [-3.1169e-04,  1.6822e-01]]])
agent 0 action: VehicleControl(throttle=0.423621, steer=-0.000672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.92093388420794
24.287458853796124 seconds in game passed.
Action: tensor([[[-9.1789e-04,  6.0162e-01],
         [ 9.9957e-05,  3.2473e-01],
         [ 1.2775e-04,  2.2164e-01],
         [-3.1169e-04,  1.6822e-01]]])
agent 0 action: VehicleControl(throttle=0.423766, steer=-0.000662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.92093388420794
24.312458854168653 seconds in game passed.
Action: tensor([[[-9.1789e-04,  6.0162e-01],
         [ 9.9957e-05,  3.2473e-01],
         [ 1.2775e-04,  2.2164e-01],
         [-3.1169e-04,  1.6822e-01]]])
agent 0 action: VehicleControl(throttle=0.423895, steer=-0.000651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.92093388420794
+++++++++++++: 2.944336846855388
24.337458854541183 seconds in game passed.
At 24.337458854541183 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.6066],
         [0.0020, 0.3265],
         [0.0021, 0.2226],
         [0.0016, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.412226, steer=0.001634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.944336846855388
Current reward: 0.6558082951724298
Current mitigation activation: 0
#############################
Total reward: 77.57674217938037
24.36245885491371 seconds in game passed.
Action: tensor([[[0.0013, 0.6066],
         [0.0020, 0.3265],
         [0.0021, 0.2226],
         [0.0016, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.413718, steer=0.001276, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.57674217938037
24.38745885528624 seconds in game passed.
Action: tensor([[[0.0013, 0.6066],
         [0.0020, 0.3265],
         [0.0021, 0.2226],
         [0.0016, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.413957, steer=0.001295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.57674217938037
24.41245885565877 seconds in game passed.
Action: tensor([[[0.0013, 0.6066],
         [0.0020, 0.3265],
         [0.0021, 0.2226],
         [0.0016, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.414273, steer=0.001315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.57674217938037
+++++++++++++: 2.9783947661110033
24.4374588560313 seconds in game passed.
At 24.4374588560313 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6053],
         [0.0029, 0.3258],
         [0.0028, 0.2230],
         [0.0023, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.426956, steer=0.002848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9783947661110033
Current reward: 0.6596341311124978
Current mitigation activation: 0
#############################
Total reward: 78.23637631049287
24.462458856403828 seconds in game passed.
Action: tensor([[[0.0033, 0.6053],
         [0.0029, 0.3258],
         [0.0028, 0.2230],
         [0.0023, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.426489, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.23637631049287
24.487458856776357 seconds in game passed.
Action: tensor([[[0.0033, 0.6053],
         [0.0029, 0.3258],
         [0.0028, 0.2230],
         [0.0023, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.427286, steer=0.002681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.23637631049287
24.512458857148886 seconds in game passed.
Action: tensor([[[0.0033, 0.6053],
         [0.0029, 0.3258],
         [0.0028, 0.2230],
         [0.0023, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.427975, steer=0.002722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.23637631049287
+++++++++++++: 3.012944229548572
24.537458857521415 seconds in game passed.
At 24.537458857521415 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6093],
         [0.0023, 0.3265],
         [0.0025, 0.2229],
         [0.0024, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.447280, steer=0.002141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.012944229548572
Current reward: 0.663413712520821
Current mitigation activation: 0
#############################
Total reward: 78.8997900230137
24.562458857893944 seconds in game passed.
Action: tensor([[[0.0031, 0.6093],
         [0.0023, 0.3265],
         [0.0025, 0.2229],
         [0.0024, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.445962, steer=0.002258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.8997900230137
24.587458858266473 seconds in game passed.
Action: tensor([[[0.0031, 0.6093],
         [0.0023, 0.3265],
         [0.0025, 0.2229],
         [0.0024, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.446500, steer=0.002274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.8997900230137
24.612458858639002 seconds in game passed.
Action: tensor([[[0.0031, 0.6093],
         [0.0023, 0.3265],
         [0.0025, 0.2229],
         [0.0024, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.446803, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.8997900230137
+++++++++++++: 3.0472451413374344
24.63745885901153 seconds in game passed.
At 24.63745885901153 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.2677e-04,  6.1618e-01],
         [-5.6421e-04,  3.2817e-01],
         [-5.4519e-04,  2.2352e-01],
         [-4.5840e-04,  1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.455809, steer=-0.000663, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0472451413374344
Current reward: 0.6672166261630337
Current mitigation activation: 0
#############################
Total reward: 79.56700664917673
24.66245885938406 seconds in game passed.
Action: tensor([[[ 9.2677e-04,  6.1618e-01],
         [-5.6421e-04,  3.2817e-01],
         [-5.4519e-04,  2.2352e-01],
         [-4.5840e-04,  1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.454971, steer=-0.000208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.56700664917673
24.68745885975659 seconds in game passed.
Action: tensor([[[ 9.2677e-04,  6.1618e-01],
         [-5.6421e-04,  3.2817e-01],
         [-5.4519e-04,  2.2352e-01],
         [-4.5840e-04,  1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.454910, steer=-0.000240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.56700664917673
24.712458860129118 seconds in game passed.
Action: tensor([[[ 9.2677e-04,  6.1618e-01],
         [-5.6421e-04,  3.2817e-01],
         [-5.4519e-04,  2.2352e-01],
         [-4.5840e-04,  1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.454647, steer=-0.000271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.56700664917673
+++++++++++++: 3.0801634293745757
24.737458860501647 seconds in game passed.
At 24.737458860501647 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6114],
         [-0.0041,  0.3252],
         [-0.0048,  0.2213],
         [-0.0051,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.513621, steer=-0.004125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0801634293745757
Current reward: 0.6711341642825348
Current mitigation activation: 0
#############################
Total reward: 80.23814081345927
24.762458860874176 seconds in game passed.
Action: tensor([[[-0.0022,  0.6114],
         [-0.0041,  0.3252],
         [-0.0048,  0.2213],
         [-0.0051,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.506656, steer=-0.003535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.23814081345927
24.787458861246705 seconds in game passed.
Action: tensor([[[-0.0022,  0.6114],
         [-0.0041,  0.3252],
         [-0.0048,  0.2213],
         [-0.0051,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.505800, steer=-0.003580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.23814081345927
24.812458861619234 seconds in game passed.
Action: tensor([[[-0.0022,  0.6114],
         [-0.0041,  0.3252],
         [-0.0048,  0.2213],
         [-0.0051,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.504324, steer=-0.003625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.23814081345927
+++++++++++++: 3.111215098643885
24.837458861991763 seconds in game passed.
At 24.837458861991763 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0051,  0.6128],
         [-0.0094,  0.3266],
         [-0.0101,  0.2227],
         [-0.0103,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.464328, steer=-0.008741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.111215098643885
Current reward: 0.6751544525359174
Current mitigation activation: 0
#############################
Total reward: 80.91329526599519
24.862458862364292 seconds in game passed.
Action: tensor([[[-0.0051,  0.6128],
         [-0.0094,  0.3266],
         [-0.0101,  0.2227],
         [-0.0103,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.466355, steer=-0.007977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.91329526599519
24.88745886273682 seconds in game passed.
Action: tensor([[[-0.0051,  0.6128],
         [-0.0094,  0.3266],
         [-0.0101,  0.2227],
         [-0.0103,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.464193, steer=-0.008053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.91329526599519
24.91245886310935 seconds in game passed.
Action: tensor([[[-0.0051,  0.6128],
         [-0.0094,  0.3266],
         [-0.0101,  0.2227],
         [-0.0103,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.462101, steer=-0.008129, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.91329526599519
+++++++++++++: 3.139021519699392
24.93745886348188 seconds in game passed.
At 24.93745886348188 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0038,  0.6146],
         [-0.0064,  0.3271],
         [-0.0068,  0.2228],
         [-0.0070,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.460460, steer=-0.005428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.139021519699392
Current reward: 0.6790295059529443
Current mitigation activation: 0
#############################
Total reward: 81.59232477194813
24.96245886385441 seconds in game passed.
Action: tensor([[[-0.0038,  0.6146],
         [-0.0064,  0.3271],
         [-0.0068,  0.2228],
         [-0.0070,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.458168, steer=-0.005926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.59232477194813
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:05:31 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:06:16 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 44.59s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.48s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.526               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 81.59, average_reward: 81.59232477194813 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00006/fi_lead_slowdown_data
