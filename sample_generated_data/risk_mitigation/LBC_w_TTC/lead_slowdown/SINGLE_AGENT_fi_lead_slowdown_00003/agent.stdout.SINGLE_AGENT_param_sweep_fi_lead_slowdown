New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190202-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190202-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190202-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190202-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190202-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190202-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 31.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 31}
1.5173983611166477 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5423983614891768 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5673983618617058 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5923983622342348 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002719, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6173983626067638 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6423983629792929 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0053, 0.5910],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.667398363351822 seconds in game passed.
Action: tensor([[[0.0053, 0.5910],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.692398363724351 seconds in game passed.
Action: tensor([[[0.0053, 0.5910],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.71739836409688 seconds in game passed.
Action: tensor([[[0.0053, 0.5910],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.742398364469409 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0047, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2236],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.767398364841938 seconds in game passed.
Action: tensor([[[0.0047, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2236],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.792398365214467 seconds in game passed.
Action: tensor([[[0.0047, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2236],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.817398365586996 seconds in game passed.
Action: tensor([[[0.0047, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2236],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.842398365959525 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5931],
         [0.0015, 0.3235],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8673983663320541 seconds in game passed.
Action: tensor([[[0.0035, 0.5931],
         [0.0015, 0.3235],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8923983667045832 seconds in game passed.
Action: tensor([[[0.0035, 0.5931],
         [0.0015, 0.3235],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9173983670771122 seconds in game passed.
Action: tensor([[[0.0035, 0.5931],
         [0.0015, 0.3235],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9423983674496412 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3226],
         [0.0012, 0.2223],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9673983678221703 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3226],
         [0.0012, 0.2223],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9923983681946993 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3226],
         [0.0012, 0.2223],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0173983685672283 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3226],
         [0.0012, 0.2223],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0423983689397573 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4281e-03, 5.9036e-01],
         [1.3231e-03, 3.2226e-01],
         [1.0938e-03, 2.2208e-01],
         [5.5093e-04, 1.6808e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0673983693122864 seconds in game passed.
Action: tensor([[[2.4281e-03, 5.9036e-01],
         [1.3231e-03, 3.2226e-01],
         [1.0938e-03, 2.2208e-01],
         [5.5093e-04, 1.6808e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0923983696848154 seconds in game passed.
Action: tensor([[[2.4281e-03, 5.9036e-01],
         [1.3231e-03, 3.2226e-01],
         [1.0938e-03, 2.2208e-01],
         [5.5093e-04, 1.6808e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1173983700573444 seconds in game passed.
Action: tensor([[[2.4281e-03, 5.9036e-01],
         [1.3231e-03, 3.2226e-01],
         [1.0938e-03, 2.2208e-01],
         [5.5093e-04, 1.6808e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.1423983704298735 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.1673983708024025 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1923983711749315 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2173983715474606 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.2423983719199896 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.2673983722925186 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2923983726650476 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3173983730375767 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.3423983734101057 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.3673983737826347 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3923983741551638 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.417398374527693 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.442398374900222 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002750, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.467398375272751 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.49239837564528 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002791, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.517398376017809 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.542398376390338 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.567398376762867 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.592398377135396 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002612, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.617398377507925 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.642398377880454 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002656, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.667398378252983 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.692398378625512 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.717398378998041 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.74239837937057 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.767398379743099 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7923983801156282 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8173983804881573 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.8423983808606863 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.8673983812332153 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8923983816057444 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9173983819782734 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.9423983823508024 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.9673983827233315 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9923983830958605 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0173983834683895 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.0423983838409185 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.0673983842134476 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0923983845859766 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1173983849585056 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.1423983853310347 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.1673983857035637 seconds in game passed.
Action: tensor([[[0.0016, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1923983860760927 seconds in game passed.
Action: tensor([[[0.0016, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2173983864486217 seconds in game passed.
Action: tensor([[[0.0016, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.242398386821151 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.26739838719368 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002435, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.292398387566209 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.317398387938738 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.342398388311267 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.367398388683796 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.392398389056325 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.417398389428854 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.442398389801383 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.467398390173912 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.492398390546441 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.51739839091897 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.542398391291499 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.567398391664028 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.592398392036557 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6173983924090862 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6423983927816153 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6673983931541443 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6923983935266733 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7173983938992023 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7423983942717314 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7673983946442604 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7923983950167894 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8173983953893185 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8423983957618475 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8673983961343765 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8923983965069056 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9173983968794346 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.9423983972519636 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.9673983976244926 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9923983979970217 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.017398398369551 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.04239839874208 seconds in game passed.
At 4.04239839874208 seconds, saving state-action tuples.
Action: tensor([[[1.4048e-03, 5.8609e-01],
         [1.1295e-03, 3.2068e-01],
         [9.9523e-04, 2.2101e-01],
         [3.4399e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.067398399114609 seconds in game passed.
Action: tensor([[[1.4048e-03, 5.8609e-01],
         [1.1295e-03, 3.2068e-01],
         [9.9523e-04, 2.2101e-01],
         [3.4399e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.092398399487138 seconds in game passed.
Action: tensor([[[1.4048e-03, 5.8609e-01],
         [1.1295e-03, 3.2068e-01],
         [9.9523e-04, 2.2101e-01],
         [3.4399e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.117398399859667 seconds in game passed.
Action: tensor([[[1.4048e-03, 5.8609e-01],
         [1.1295e-03, 3.2068e-01],
         [9.9523e-04, 2.2101e-01],
         [3.4399e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.88373051633521
4.142398400232196 seconds in game passed.
At 4.142398400232196 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760848520400644
Current mitigation activation: 0
#############################
Total reward: 0.6561255113146287
4.167398400604725 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
4.192398400977254 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 0.6561255113146287
4.217398401349783 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
+++++++++++++: 8.843383940473686
4.242398401722312 seconds in game passed.
At 4.242398401722312 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383940473686
Current reward: 0.49259321983288007
Current mitigation activation: 0
#############################
Total reward: 1.1487187311475089
4.267398402094841 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002928, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.29239840246737 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.317398402839899 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
+++++++++++++: 7.228541449858101
4.342398403212428 seconds in game passed.
At 4.342398403212428 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228541449858101
Current reward: 0.5118171168217831
Current mitigation activation: 0
#############################
Total reward: 1.660535847969292
4.367398403584957 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
4.392398403957486 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
4.417398404330015 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535847969292
+++++++++++++: 6.215933070986233
4.442398404702544 seconds in game passed.
At 4.442398404702544 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002767, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.215933070986233
Current reward: 0.5264941437496048
Current mitigation activation: 0
#############################
Total reward: 2.1870299917188967
4.467398405075073 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299917188967
4.492398405447602 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299917188967
4.517398405820131 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3220],
         [0.0025, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870299917188967
+++++++++++++: 5.508365808603482
4.54239840619266 seconds in game passed.
At 4.54239840619266 seconds, saving state-action tuples.
Action: tensor([[[-8.1539e-05,  5.8861e-01],
         [ 1.6968e-04,  3.2200e-01],
         [ 2.9274e-04,  2.2120e-01],
         [-8.0109e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508365808603482
Current reward: 0.5376234960127234
Current mitigation activation: 0
#############################
Total reward: 2.72465348773162
4.567398406565189 seconds in game passed.
Action: tensor([[[-8.1539e-05,  5.8861e-01],
         [ 1.6968e-04,  3.2200e-01],
         [ 2.9274e-04,  2.2120e-01],
         [-8.0109e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.72465348773162
4.592398406937718 seconds in game passed.
Action: tensor([[[-8.1539e-05,  5.8861e-01],
         [ 1.6968e-04,  3.2200e-01],
         [ 2.9274e-04,  2.2120e-01],
         [-8.0109e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.72465348773162
4.617398407310247 seconds in game passed.
Action: tensor([[[-8.1539e-05,  5.8861e-01],
         [ 1.6968e-04,  3.2200e-01],
         [ 2.9274e-04,  2.2120e-01],
         [-8.0109e-05,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.72465348773162
+++++++++++++: 4.976134225995408
4.6423984076827765 seconds in game passed.
At 4.6423984076827765 seconds, saving state-action tuples.
Action: tensor([[[ 2.3423e-04,  5.8921e-01],
         [-3.6270e-04,  3.2137e-01],
         [-2.7773e-04,  2.2103e-01],
         [-4.4185e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.976134225995408
Current reward: 0.5459292629265821
Current mitigation activation: 0
#############################
Total reward: 3.270582750658202
4.6673984080553055 seconds in game passed.
Action: tensor([[[ 2.3423e-04,  5.8921e-01],
         [-3.6270e-04,  3.2137e-01],
         [-2.7773e-04,  2.2103e-01],
         [-4.4185e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.270582750658202
4.6923984084278345 seconds in game passed.
Action: tensor([[[ 2.3423e-04,  5.8921e-01],
         [-3.6270e-04,  3.2137e-01],
         [-2.7773e-04,  2.2103e-01],
         [-4.4185e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.270582750658202
4.7173984088003635 seconds in game passed.
Action: tensor([[[ 2.3423e-04,  5.8921e-01],
         [-3.6270e-04,  3.2137e-01],
         [-2.7773e-04,  2.2103e-01],
         [-4.4185e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.270582750658202
+++++++++++++: 4.552586954590932
4.742398409172893 seconds in game passed.
At 4.742398409172893 seconds, saving state-action tuples.
Action: tensor([[[-2.8174e-04,  5.9095e-01],
         [-9.5262e-04,  3.2155e-01],
         [-8.3892e-04,  2.2107e-01],
         [-9.8476e-04,  1.6745e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552586954590932
Current reward: 0.5519989008058146
Current mitigation activation: 0
#############################
Total reward: 3.8225816514640165
4.767398409545422 seconds in game passed.
Action: tensor([[[-2.8174e-04,  5.9095e-01],
         [-9.5262e-04,  3.2155e-01],
         [-8.3892e-04,  2.2107e-01],
         [-9.8476e-04,  1.6745e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225816514640165
4.792398409917951 seconds in game passed.
Action: tensor([[[-2.8174e-04,  5.9095e-01],
         [-9.5262e-04,  3.2155e-01],
         [-8.3892e-04,  2.2107e-01],
         [-9.8476e-04,  1.6745e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225816514640165
4.81739841029048 seconds in game passed.
Action: tensor([[[-2.8174e-04,  5.9095e-01],
         [-9.5262e-04,  3.2155e-01],
         [-8.3892e-04,  2.2107e-01],
         [-9.8476e-04,  1.6745e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225816514640165
+++++++++++++: 4.199610891941162
4.842398410663009 seconds in game passed.
At 4.842398410663009 seconds, saving state-action tuples.
Action: tensor([[[ 5.3538e-04,  5.9008e-01],
         [-5.6589e-04,  3.2163e-01],
         [-4.3674e-04,  2.2128e-01],
         [-4.5858e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000504, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199610891941162
Current reward: 0.5563326528694177
Current mitigation activation: 0
#############################
Total reward: 4.378914304333434
4.867398411035538 seconds in game passed.
Action: tensor([[[ 5.3538e-04,  5.9008e-01],
         [-5.6589e-04,  3.2163e-01],
         [-4.3674e-04,  2.2128e-01],
         [-4.5858e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914304333434
4.892398411408067 seconds in game passed.
Action: tensor([[[ 5.3538e-04,  5.9008e-01],
         [-5.6589e-04,  3.2163e-01],
         [-4.3674e-04,  2.2128e-01],
         [-4.5858e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914304333434
4.917398411780596 seconds in game passed.
Action: tensor([[[ 5.3538e-04,  5.9008e-01],
         [-5.6589e-04,  3.2163e-01],
         [-4.3674e-04,  2.2128e-01],
         [-4.5858e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914304333434
+++++++++++++: 3.8947618029768414
4.942398412153125 seconds in game passed.
At 4.942398412153125 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001708, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.8947618029768414
Current reward: 0.5593081974291114
Current mitigation activation: 0
#############################
Total reward: 4.938222501762546
4.967398412525654 seconds in game passed.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222501762546
4.992398412898183 seconds in game passed.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222501762546
5.017398413270712 seconds in game passed.
Action: tensor([[[0.0016, 0.5882],
         [0.0007, 0.3216],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222501762546
+++++++++++++: 3.6246722565637404
5.042398413643241 seconds in game passed.
At 5.042398413643241 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2750e-03, 5.8982e-01],
         [1.0668e-03, 3.2207e-01],
         [9.3511e-04, 2.2279e-01],
         [5.7215e-04, 1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6246722565637404
Current reward: 0.5611771108271344
Current mitigation activation: 0
#############################
Total reward: 5.499399612589681
5.06739841401577 seconds in game passed.
Action: tensor([[[1.2750e-03, 5.8982e-01],
         [1.0668e-03, 3.2207e-01],
         [9.3511e-04, 2.2279e-01],
         [5.7215e-04, 1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399612589681
5.092398414388299 seconds in game passed.
Action: tensor([[[1.2750e-03, 5.8982e-01],
         [1.0668e-03, 3.2207e-01],
         [9.3511e-04, 2.2279e-01],
         [5.7215e-04, 1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399612589681
5.117398414760828 seconds in game passed.
Action: tensor([[[1.2750e-03, 5.8982e-01],
         [1.0668e-03, 3.2207e-01],
         [9.3511e-04, 2.2279e-01],
         [5.7215e-04, 1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399612589681
+++++++++++++: 3.380483513702236
5.142398415133357 seconds in game passed.
At 5.142398415133357 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0017, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380483513702236
Current reward: 0.5621374500618734
Current mitigation activation: 0
#############################
Total reward: 6.061537062651555
5.167398415505886 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537062651555
5.192398415878415 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537062651555
5.217398416250944 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002381, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537062651555
+++++++++++++: 3.1565700079003944
5.242398416623473 seconds in game passed.
At 5.242398416623473 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.5944],
         [0.0019, 0.3220],
         [0.0018, 0.2214],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1565700079003944
Current reward: 0.5623125988421122
Current mitigation activation: 0
#############################
Total reward: 6.623849661493667
5.267398416996002 seconds in game passed.
Action: tensor([[[0.0025, 0.5944],
         [0.0019, 0.3220],
         [0.0018, 0.2214],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849661493667
5.292398417368531 seconds in game passed.
Action: tensor([[[0.0025, 0.5944],
         [0.0019, 0.3220],
         [0.0018, 0.2214],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849661493667
5.31739841774106 seconds in game passed.
Action: tensor([[[0.0025, 0.5944],
         [0.0019, 0.3220],
         [0.0018, 0.2214],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849661493667
+++++++++++++: 2.9489480642305397
5.342398418113589 seconds in game passed.
At 5.342398418113589 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9489480642305397
Current reward: 0.5617967752431887
Current mitigation activation: 0
#############################
Total reward: 7.185646436736856
5.367398418486118 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646436736856
5.392398418858647 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646436736856
5.417398419231176 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646436736856
+++++++++++++: 2.788063163487529
5.442398419603705 seconds in game passed.
At 5.442398419603705 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.8479e-04,  5.8810e-01],
         [ 1.3877e-04,  3.2092e-01],
         [-1.4633e-05,  2.2106e-01],
         [-3.2760e-04,  1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.788063163487529
Current reward: 0.5575288840029324
Current mitigation activation: 0
#############################
Total reward: 7.743175320739788
5.467398419976234 seconds in game passed.
Action: tensor([[[ 8.8479e-04,  5.8810e-01],
         [ 1.3877e-04,  3.2092e-01],
         [-1.4633e-05,  2.2106e-01],
         [-3.2760e-04,  1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175320739788
5.4923984203487635 seconds in game passed.
Action: tensor([[[ 8.8479e-04,  5.8810e-01],
         [ 1.3877e-04,  3.2092e-01],
         [-1.4633e-05,  2.2106e-01],
         [-3.2760e-04,  1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175320739788
5.5173984207212925 seconds in game passed.
Action: tensor([[[ 8.8479e-04,  5.8810e-01],
         [ 1.3877e-04,  3.2092e-01],
         [-1.4633e-05,  2.2106e-01],
         [-3.2760e-04,  1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175320739788
+++++++++++++: 2.691321958608183
5.5423984210938215 seconds in game passed.
At 5.5423984210938215 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.691321958608183
Current reward: 0.5472018872151442
Current mitigation activation: 0
#############################
Total reward: 8.290377207954933
5.5673984214663506 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377207954933
5.59239842183888 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377207954933
5.617398422211409 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377207954933
+++++++++++++: 2.5950245201237956
5.642398422583938 seconds in game passed.
At 5.642398422583938 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5950245201237956
Current reward: 0.5368278645922685
Current mitigation activation: 0
#############################
Total reward: 8.827205072547201
5.667398422956467 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205072547201
5.692398423328996 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205072547201
5.717398423701525 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827205072547201
+++++++++++++: 2.4986314442006936
5.742398424074054 seconds in game passed.
At 5.742398424074054 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.5957],
         [-0.0045,  0.3233],
         [-0.0051,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4986314442006936
Current reward: 0.5264623586761527
Current mitigation activation: 0
#############################
Total reward: 9.353667431223354
5.767398424446583 seconds in game passed.
Action: tensor([[[-0.0026,  0.5957],
         [-0.0045,  0.3233],
         [-0.0051,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667431223354
5.792398424819112 seconds in game passed.
Action: tensor([[[-0.0026,  0.5957],
         [-0.0045,  0.3233],
         [-0.0051,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667431223354
5.817398425191641 seconds in game passed.
Action: tensor([[[-0.0026,  0.5957],
         [-0.0045,  0.3233],
         [-0.0051,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667431223354
+++++++++++++: 2.402191651103614
5.84239842556417 seconds in game passed.
At 5.84239842556417 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.7258e-04,  5.9070e-01],
         [-7.5015e-04,  3.2177e-01],
         [-7.7739e-04,  2.2148e-01],
         [-9.8501e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.402191651103614
Current reward: 0.516100722047981
Current mitigation activation: 0
#############################
Total reward: 9.869768153271334
5.867398425936699 seconds in game passed.
Action: tensor([[[-1.7258e-04,  5.9070e-01],
         [-7.5015e-04,  3.2177e-01],
         [-7.7739e-04,  2.2148e-01],
         [-9.8501e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869768153271334
5.892398426309228 seconds in game passed.
Action: tensor([[[-1.7258e-04,  5.9070e-01],
         [-7.5015e-04,  3.2177e-01],
         [-7.7739e-04,  2.2148e-01],
         [-9.8501e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869768153271334
5.917398426681757 seconds in game passed.
Action: tensor([[[-1.7258e-04,  5.9070e-01],
         [-7.5015e-04,  3.2177e-01],
         [-7.7739e-04,  2.2148e-01],
         [-9.8501e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869768153271334
+++++++++++++: 2.2737318997764735
5.942398427054286 seconds in game passed.
At 5.942398427054286 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.6767e-05,  5.9334e-01],
         [ 2.5707e-04,  3.2277e-01],
         [ 2.8992e-04,  2.2206e-01],
         [-9.9681e-05,  1.6862e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2737318997764735
Current reward: 0.5093356845353414
Current mitigation activation: 0
#############################
Total reward: 10.379103837806674
5.967398427426815 seconds in game passed.
Action: tensor([[[ 4.6767e-05,  5.9334e-01],
         [ 2.5707e-04,  3.2277e-01],
         [ 2.8992e-04,  2.2206e-01],
         [-9.9681e-05,  1.6862e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103837806674
5.992398427799344 seconds in game passed.
Action: tensor([[[ 4.6767e-05,  5.9334e-01],
         [ 2.5707e-04,  3.2277e-01],
         [ 2.8992e-04,  2.2206e-01],
         [-9.9681e-05,  1.6862e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103837806674
6.017398428171873 seconds in game passed.
Action: tensor([[[ 4.6767e-05,  5.9334e-01],
         [ 2.5707e-04,  3.2277e-01],
         [ 2.8992e-04,  2.2206e-01],
         [-9.9681e-05,  1.6862e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103837806674
+++++++++++++: 2.069400311137692
6.042398428544402 seconds in game passed.
At 6.042398428544402 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5971],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003867, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.069400311137692
Current reward: 0.5122396591704776
Current mitigation activation: 0
#############################
Total reward: 10.891343496977152
6.067398428916931 seconds in game passed.
Action: tensor([[[0.0031, 0.5971],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.873873, steer=0.003275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343496977152
6.09239842928946 seconds in game passed.
Action: tensor([[[0.0031, 0.5971],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.821059, steer=0.003303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343496977152
6.117398429661989 seconds in game passed.
Action: tensor([[[0.0031, 0.5971],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.769417, steer=0.003330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343496977152
+++++++++++++: 1.886535445083526
6.142398430034518 seconds in game passed.
At 6.142398430034518 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6203],
         [0.0025, 0.3397],
         [0.0020, 0.2340],
         [0.0009, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.470442, steer=0.002035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.886535445083526
Current reward: 0.5134807651710416
Current mitigation activation: 0
#############################
Total reward: 11.404824262148193
6.167398430407047 seconds in game passed.
Action: tensor([[[0.0020, 0.6203],
         [0.0025, 0.3397],
         [0.0020, 0.2340],
         [0.0009, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.445009, steer=0.002255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824262148193
6.192398430779576 seconds in game passed.
Action: tensor([[[0.0020, 0.6203],
         [0.0025, 0.3397],
         [0.0020, 0.2340],
         [0.0009, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.395547, steer=0.002259, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824262148193
6.217398431152105 seconds in game passed.
Action: tensor([[[0.0020, 0.6203],
         [0.0025, 0.3397],
         [0.0020, 0.2340],
         [0.0009, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.362783, steer=0.002263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824262148193
+++++++++++++: 1.7242653523673268
6.242398431524634 seconds in game passed.
At 6.242398431524634 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.1119e-04,  6.3374e-01],
         [-2.0526e-05,  3.4342e-01],
         [-7.1926e-04,  2.3569e-01],
         [-1.8221e-03,  1.8007e-01]]])
agent 0 action: VehicleControl(throttle=0.352265, steer=-0.000191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7242653523673268
Current reward: 0.5125420721984696
Current mitigation activation: 0
#############################
Total reward: 11.917366334346662
6.267398431897163 seconds in game passed.
Action: tensor([[[ 5.1119e-04,  6.3374e-01],
         [-2.0526e-05,  3.4342e-01],
         [-7.1926e-04,  2.3569e-01],
         [-1.8221e-03,  1.8007e-01]]])
agent 0 action: VehicleControl(throttle=0.339630, steer=0.000191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917366334346662
6.292398432269692 seconds in game passed.
Action: tensor([[[ 5.1119e-04,  6.3374e-01],
         [-2.0526e-05,  3.4342e-01],
         [-7.1926e-04,  2.3569e-01],
         [-1.8221e-03,  1.8007e-01]]])
agent 0 action: VehicleControl(throttle=0.327414, steer=0.000168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917366334346662
6.3173984326422215 seconds in game passed.
Action: tensor([[[ 5.1119e-04,  6.3374e-01],
         [-2.0526e-05,  3.4342e-01],
         [-7.1926e-04,  2.3569e-01],
         [-1.8221e-03,  1.8007e-01]]])
agent 0 action: VehicleControl(throttle=0.315611, steer=0.000145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917366334346662
+++++++++++++: 1.5887946932370665
6.3423984330147505 seconds in game passed.
At 6.3423984330147505 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3890e-03,  6.5352e-01],
         [-5.9682e-04,  3.5223e-01],
         [-1.7387e-03,  2.4170e-01],
         [-2.9497e-03,  1.8449e-01]]])
agent 0 action: VehicleControl(throttle=0.304612, steer=0.000039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5887946932370665
Current reward: 0.5075645696844308
Current mitigation activation: 0
#############################
Total reward: 12.424930904031093
6.3673984333872795 seconds in game passed.
Action: tensor([[[ 1.3890e-03,  6.5352e-01],
         [-5.9682e-04,  3.5223e-01],
         [-1.7387e-03,  2.4170e-01],
         [-2.9497e-03,  1.8449e-01]]])
agent 0 action: VehicleControl(throttle=0.294022, steer=0.000023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424930904031093
6.3923984337598085 seconds in game passed.
Action: tensor([[[ 1.3890e-03,  6.5352e-01],
         [-5.9682e-04,  3.5223e-01],
         [-1.7387e-03,  2.4170e-01],
         [-2.9497e-03,  1.8449e-01]]])
agent 0 action: VehicleControl(throttle=0.283385, steer=-0.000007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424930904031093
6.417398434132338 seconds in game passed.
Action: tensor([[[ 1.3890e-03,  6.5352e-01],
         [-5.9682e-04,  3.5223e-01],
         [-1.7387e-03,  2.4170e-01],
         [-2.9497e-03,  1.8449e-01]]])
agent 0 action: VehicleControl(throttle=0.272723, steer=-0.000037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424930904031093
+++++++++++++: 1.4775443626987133
6.442398434504867 seconds in game passed.
At 6.442398434504867 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6674],
         [-0.0047,  0.3563],
         [-0.0060,  0.2428],
         [-0.0070,  0.1850]]])
agent 0 action: VehicleControl(throttle=0.261971, steer=-0.004149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4775443626987133
Current reward: 0.4981642201611044
Current mitigation activation: 0
#############################
Total reward: 12.923095124192198
6.467398434877396 seconds in game passed.
Action: tensor([[[-0.0013,  0.6674],
         [-0.0047,  0.3563],
         [-0.0060,  0.2428],
         [-0.0070,  0.1850]]])
agent 0 action: VehicleControl(throttle=0.251200, steer=-0.003518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923095124192198
6.492398435249925 seconds in game passed.
Action: tensor([[[-0.0013,  0.6674],
         [-0.0047,  0.3563],
         [-0.0060,  0.2428],
         [-0.0070,  0.1850]]])
agent 0 action: VehicleControl(throttle=0.240410, steer=-0.003563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923095124192198
6.517398435622454 seconds in game passed.
Action: tensor([[[-0.0013,  0.6674],
         [-0.0047,  0.3563],
         [-0.0060,  0.2428],
         [-0.0070,  0.1850]]])
agent 0 action: VehicleControl(throttle=0.229602, steer=-0.003609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923095124192198
+++++++++++++: 1.3813715306458616
6.542398435994983 seconds in game passed.
At 6.542398435994983 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.0433e-04,  6.8521e-01],
         [-4.1300e-03,  3.6664e-01],
         [-5.9053e-03,  2.5088e-01],
         [-7.2138e-03,  1.9108e-01]]])
agent 0 action: VehicleControl(throttle=0.218822, steer=-0.002843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3813715306458616
Current reward: 0.485647312876764
Current mitigation activation: 0
#############################
Total reward: 13.408742437068963
6.567398436367512 seconds in game passed.
Action: tensor([[[-3.0433e-04,  6.8521e-01],
         [-4.1300e-03,  3.6664e-01],
         [-5.9053e-03,  2.5088e-01],
         [-7.2138e-03,  1.9108e-01]]])
agent 0 action: VehicleControl(throttle=0.208024, steer=-0.002986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408742437068963
6.592398436740041 seconds in game passed.
Action: tensor([[[-3.0433e-04,  6.8521e-01],
         [-4.1300e-03,  3.6664e-01],
         [-5.9053e-03,  2.5088e-01],
         [-7.2138e-03,  1.9108e-01]]])
agent 0 action: VehicleControl(throttle=0.197207, steer=-0.002999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408742437068963
6.61739843711257 seconds in game passed.
Action: tensor([[[-3.0433e-04,  6.8521e-01],
         [-4.1300e-03,  3.6664e-01],
         [-5.9053e-03,  2.5088e-01],
         [-7.2138e-03,  1.9108e-01]]])
agent 0 action: VehicleControl(throttle=0.186372, steer=-0.003012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408742437068963
+++++++++++++: 1.2939980548131456
6.642398437485099 seconds in game passed.
At 6.642398437485099 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.1818e-04,  1.0000e+00],
         [-4.6845e-03,  1.0000e+00],
         [-5.8828e-03,  1.0000e+00],
         [-6.4305e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002982, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2939980548131456
Current reward: 0.4711357723244184
Current mitigation activation: 1
#############################
Total reward: 13.87987820939338
6.667398437857628 seconds in game passed.
Action: tensor([[[-3.1818e-04,  1.0000e+00],
         [-4.6845e-03,  1.0000e+00],
         [-5.8828e-03,  1.0000e+00],
         [-6.4305e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002980, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87987820939338
6.692398438230157 seconds in game passed.
Action: tensor([[[-3.1818e-04,  1.0000e+00],
         [-4.6845e-03,  1.0000e+00],
         [-5.8828e-03,  1.0000e+00],
         [-6.4305e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002974, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87987820939338
6.717398438602686 seconds in game passed.
Action: tensor([[[-3.1818e-04,  1.0000e+00],
         [-4.6845e-03,  1.0000e+00],
         [-5.8828e-03,  1.0000e+00],
         [-6.4305e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002968, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87987820939338
+++++++++++++: 1.2143400035709309
6.742398438975215 seconds in game passed.
At 6.742398438975215 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000848, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2143400035709309
Current reward: 0.45476832152025504
Current mitigation activation: 1
#############################
Total reward: 14.334646530913636
6.767398439347744 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001161, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334646530913636
6.792398439720273 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001127, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334646530913636
6.817398440092802 seconds in game passed.
Action: tensor([[[ 0.0022,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001093, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334646530913636
+++++++++++++: 1.1615290959949074
6.842398440465331 seconds in game passed.
At 6.842398440465331 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0091,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0013,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006456, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1615290959949074
Current reward: 0.4319665932135567
Current mitigation activation: 1
#############################
Total reward: 14.766613124127193
6.86739844083786 seconds in game passed.
Action: tensor([[[ 0.0091,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0013,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005283, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766613124127193
6.892398441210389 seconds in game passed.
Action: tensor([[[ 0.0091,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0013,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005356, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766613124127193
6.917398441582918 seconds in game passed.
Action: tensor([[[ 0.0091,  1.0000],
         [ 0.0011,  1.0000],
         [-0.0012,  1.0000],
         [-0.0013,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005429, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766613124127193
+++++++++++++: 1.1429191458996222
6.942398441955447 seconds in game passed.
At 6.942398441955447 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012341, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1429191458996222
Current reward: 0.40178448132079725
Current mitigation activation: 1
#############################
Total reward: 15.168397605447991
6.967398442327976 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009518, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168397605447991
6.992398442700505 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009638, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168397605447991
7.017398443073034 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0043,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009757, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168397605447991
+++++++++++++: 1.1448643097696298
7.042398443445563 seconds in game passed.
At 7.042398443445563 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0135,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012036, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1448643097696298
Current reward: 0.36906163485492227
Current mitigation activation: 1
#############################
Total reward: 15.537459240302914
7.067398443818092 seconds in game passed.
Action: tensor([[[-0.0135,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011866, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537459240302914
7.092398444190621 seconds in game passed.
Action: tensor([[[-0.0135,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012046, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537459240302914
7.11739844456315 seconds in game passed.
Action: tensor([[[-0.0135,  1.0000],
         [-0.0077,  1.0000],
         [-0.0089,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012226, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537459240302914
+++++++++++++: 1.1644898939393382
7.142398444935679 seconds in game passed.
At 7.142398444935679 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0152,  1.0000],
         [-0.0110,  1.0000],
         [-0.0085,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015542, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1644898939393382
Current reward: 0.33579743180580535
Current mitigation activation: 1
#############################
Total reward: 15.873256672108718
7.1673984453082085 seconds in game passed.
Action: tensor([[[-0.0152,  1.0000],
         [-0.0110,  1.0000],
         [-0.0085,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015221, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.873256672108718
7.1923984456807375 seconds in game passed.
Action: tensor([[[-0.0152,  1.0000],
         [-0.0110,  1.0000],
         [-0.0085,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015420, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.873256672108718
7.2173984460532665 seconds in game passed.
Action: tensor([[[-0.0152,  1.0000],
         [-0.0110,  1.0000],
         [-0.0085,  1.0000],
         [-0.0046,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015619, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.873256672108718
+++++++++++++: 1.204323237001435
7.2423984464257956 seconds in game passed.
At 7.2423984464257956 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0202,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015920, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.204323237001435
Current reward: 0.30280810751544446
Current mitigation activation: 1
#############################
Total reward: 16.176064779624163
7.267398446798325 seconds in game passed.
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0202,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016074, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176064779624163
7.292398447170854 seconds in game passed.
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0202,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016249, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176064779624163
7.317398447543383 seconds in game passed.
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0202,  1.0000],
         [-0.0220,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016423, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176064779624163
+++++++++++++: 1.2698729745604773
7.342398447915912 seconds in game passed.
At 7.342398447915912 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0106,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021898, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2698729745604773
Current reward: 0.27057960322969365
Current mitigation activation: 1
#############################
Total reward: 16.446644382853858
7.367398448288441 seconds in game passed.
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0106,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015771, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446644382853858
7.39239844866097 seconds in game passed.
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0106,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015994, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446644382853858
7.417398449033499 seconds in game passed.
Action: tensor([[[ 0.0300,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0106,  1.0000],
         [-0.0094,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016217, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446644382853858
+++++++++++++: 1.368335071010945
7.442398449406028 seconds in game passed.
At 7.442398449406028 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.8436e-03, 9.5603e-01],
         [1.1294e-03, 9.5439e-01],
         [3.5023e-04, 9.5378e-01],
         [6.8389e-04, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003381, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.368335071010945
Current reward: 0.23971662815422468
Current mitigation activation: 0
#############################
Total reward: 16.68636101100808
7.467398449778557 seconds in game passed.
Action: tensor([[[1.8436e-03, 9.5603e-01],
         [1.1294e-03, 9.5439e-01],
         [3.5023e-04, 9.5378e-01],
         [6.8389e-04, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000044, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.68636101100808
7.492398450151086 seconds in game passed.
Action: tensor([[[1.8436e-03, 9.5603e-01],
         [1.1294e-03, 9.5439e-01],
         [3.5023e-04, 9.5378e-01],
         [6.8389e-04, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000017, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.68636101100808
7.517398450523615 seconds in game passed.
Action: tensor([[[1.8436e-03, 9.5603e-01],
         [1.1294e-03, 9.5439e-01],
         [3.5023e-04, 9.5378e-01],
         [6.8389e-04, 9.5340e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000077, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.68636101100808
+++++++++++++: 1.511154913348119
7.542398450896144 seconds in game passed.
At 7.542398450896144 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.2038e-04, 9.5592e-01],
         [1.0995e-03, 9.5428e-01],
         [9.0972e-04, 9.5370e-01],
         [1.4041e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000534, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.511154913348119
Current reward: 0.2106151628805552
Current mitigation activation: 0
#############################
Total reward: 16.896976173888635
7.567398451268673 seconds in game passed.
Action: tensor([[[8.2038e-04, 9.5592e-01],
         [1.0995e-03, 9.5428e-01],
         [9.0972e-04, 9.5370e-01],
         [1.4041e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000379, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.896976173888635
7.592398451641202 seconds in game passed.
Action: tensor([[[8.2038e-04, 9.5592e-01],
         [1.0995e-03, 9.5428e-01],
         [9.0972e-04, 9.5370e-01],
         [1.4041e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000333, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.896976173888635
7.617398452013731 seconds in game passed.
Action: tensor([[[8.2038e-04, 9.5592e-01],
         [1.0995e-03, 9.5428e-01],
         [9.0972e-04, 9.5370e-01],
         [1.4041e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000288, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.896976173888635
+++++++++++++: 1.7398662102691949
7.64239845238626 seconds in game passed.
At 7.64239845238626 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.9536e-04, 9.5609e-01],
         [1.5216e-03, 9.5458e-01],
         [1.8217e-03, 9.5407e-01],
         [1.9286e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000008, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7398662102691949
Current reward: 0.18263279433735385
Current mitigation activation: 0
#############################
Total reward: 17.07960896822599
7.667398452758789 seconds in game passed.
Action: tensor([[[7.9536e-04, 9.5609e-01],
         [1.5216e-03, 9.5458e-01],
         [1.8217e-03, 9.5407e-01],
         [1.9286e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000015, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.07960896822599
7.692398453131318 seconds in game passed.
Action: tensor([[[7.9536e-04, 9.5609e-01],
         [1.5216e-03, 9.5458e-01],
         [1.8217e-03, 9.5407e-01],
         [1.9286e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000063, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.07960896822599
7.717398453503847 seconds in game passed.
Action: tensor([[[7.9536e-04, 9.5609e-01],
         [1.5216e-03, 9.5458e-01],
         [1.8217e-03, 9.5407e-01],
         [1.9286e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000111, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.07960896822599
+++++++++++++: 2.1591629560020973
7.742398453876376 seconds in game passed.
At 7.742398453876376 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.1829e-04, 9.5622e-01],
         [1.5057e-03, 9.5477e-01],
         [1.7740e-03, 9.5430e-01],
         [1.8643e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000078, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1591629560020973
Current reward: 0.15679972675303264
Current mitigation activation: 0
#############################
Total reward: 17.236408694979023
7.767398454248905 seconds in game passed.
Action: tensor([[[7.1829e-04, 9.5622e-01],
         [1.5057e-03, 9.5477e-01],
         [1.7740e-03, 9.5430e-01],
         [1.8643e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000113, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.236408694979023
7.792398454621434 seconds in game passed.
Action: tensor([[[7.1829e-04, 9.5622e-01],
         [1.5057e-03, 9.5477e-01],
         [1.7740e-03, 9.5430e-01],
         [1.8643e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000139, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.236408694979023
7.817398454993963 seconds in game passed.
Action: tensor([[[7.1829e-04, 9.5622e-01],
         [1.5057e-03, 9.5477e-01],
         [1.7740e-03, 9.5430e-01],
         [1.8643e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000165, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.236408694979023
+++++++++++++: 2.9677231233339088
7.842398455366492 seconds in game passed.
At 7.842398455366492 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.7433e-04, 9.5620e-01],
         [1.5152e-03, 9.5474e-01],
         [1.7851e-03, 9.5427e-01],
         [1.9005e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000154, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9677231233339088
Current reward: 0.13271298353855493
Current mitigation activation: 0
#############################
Total reward: 17.369121678517576
7.867398455739021 seconds in game passed.
Action: tensor([[[7.7433e-04, 9.5620e-01],
         [1.5152e-03, 9.5474e-01],
         [1.7851e-03, 9.5427e-01],
         [1.9005e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000095, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369121678517576
7.89239845611155 seconds in game passed.
Action: tensor([[[7.7433e-04, 9.5620e-01],
         [1.5152e-03, 9.5474e-01],
         [1.7851e-03, 9.5427e-01],
         [1.9005e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000043, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369121678517576
7.917398456484079 seconds in game passed.
Action: tensor([[[7.7433e-04, 9.5620e-01],
         [1.5152e-03, 9.5474e-01],
         [1.7851e-03, 9.5427e-01],
         [1.9005e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000009, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369121678517576
+++++++++++++: 4.782205171278287
7.942398456856608 seconds in game passed.
At 7.942398456856608 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.0587e-04, 9.5606e-01],
         [1.5046e-03, 9.5455e-01],
         [1.7879e-03, 9.5406e-01],
         [1.9136e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000199, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.782205171278287
Current reward: 0.11051065851016863
Current mitigation activation: 0
#############################
Total reward: 17.479632337027745
7.967398457229137 seconds in game passed.
Action: tensor([[[9.0587e-04, 9.5606e-01],
         [1.5046e-03, 9.5455e-01],
         [1.7879e-03, 9.5406e-01],
         [1.9136e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000319, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.479632337027745
7.9923984576016665 seconds in game passed.
Action: tensor([[[9.0587e-04, 9.5606e-01],
         [1.5046e-03, 9.5455e-01],
         [1.7879e-03, 9.5406e-01],
         [1.9136e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000452, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.479632337027745
8.017398457974195 seconds in game passed.
Action: tensor([[[9.0587e-04, 9.5606e-01],
         [1.5046e-03, 9.5455e-01],
         [1.7879e-03, 9.5406e-01],
         [1.9136e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.004367, steer=0.000585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.479632337027745
+++++++++++++: 23.54970608569119
8.042398458346725 seconds in game passed.
At 8.042398458346725 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006663, steer=0.000693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.039504619654206055
Current mitigation activation: 0
#############################
Total reward: 17.51913695668195
8.067398458719254 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006667, steer=0.000855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51913695668195
8.092398459091783 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006833, steer=0.001009, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51913695668195
8.117398459464312 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006945, steer=0.001163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51913695668195
+++++++++++++: 2074.367222261466
8.14239845983684 seconds in game passed.
At 8.14239845983684 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0076e-02,  9.5572e-01],
         [ 1.7767e-03,  9.5379e-01],
         [-1.8762e-03,  9.5302e-01],
         [-4.1967e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.035210, steer=0.007344, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0004704448791098863
Current mitigation activation: 0
#############################
Total reward: 17.51960740156106
8.16739846020937 seconds in game passed.
Action: tensor([[[ 1.0076e-02,  9.5572e-01],
         [ 1.7767e-03,  9.5379e-01],
         [-1.8762e-03,  9.5302e-01],
         [-4.1967e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.009532, steer=0.006603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51960740156106
8.192398460581899 seconds in game passed.
Action: tensor([[[ 1.0076e-02,  9.5572e-01],
         [ 1.7767e-03,  9.5379e-01],
         [-1.8762e-03,  9.5302e-01],
         [-4.1967e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.012772, steer=0.006852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51960740156106
8.217398460954428 seconds in game passed.
Action: tensor([[[ 1.0076e-02,  9.5572e-01],
         [ 1.7767e-03,  9.5379e-01],
         [-1.8762e-03,  9.5302e-01],
         [-4.1967e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.013555, steer=0.007100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51960740156106
+++++++++++++: 165.8810521713496
8.242398461326957 seconds in game passed.
At 8.242398461326957 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0235,  0.9551],
         [ 0.0026,  0.9523],
         [-0.0071,  0.9508],
         [-0.0024,  0.9469]]])
agent 0 action: VehicleControl(throttle=0.061029, steer=0.016293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006176163165880044
Current mitigation activation: 0
#############################
Total reward: 17.52578356472694
8.267398461699486 seconds in game passed.
Action: tensor([[[ 0.0235,  0.9551],
         [ 0.0026,  0.9523],
         [-0.0071,  0.9508],
         [-0.0024,  0.9469]]])
agent 0 action: VehicleControl(throttle=0.057326, steer=0.015160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52578356472694
8.292398462072015 seconds in game passed.
Action: tensor([[[ 0.0235,  0.9551],
         [ 0.0026,  0.9523],
         [-0.0071,  0.9508],
         [-0.0024,  0.9469]]])
agent 0 action: VehicleControl(throttle=0.058516, steer=0.015501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52578356472694
8.317398462444544 seconds in game passed.
Action: tensor([[[ 0.0235,  0.9551],
         [ 0.0026,  0.9523],
         [-0.0071,  0.9508],
         [-0.0024,  0.9469]]])
agent 0 action: VehicleControl(throttle=0.059626, steer=0.015843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52578356472694
+++++++++++++: 206.93849891113734
8.342398462817073 seconds in game passed.
At 8.342398462817073 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.5058e-02,  9.5369e-01],
         [ 2.1363e-04,  9.4753e-01],
         [-1.3297e-02,  9.1528e-01],
         [-8.2917e-03,  6.0200e-01]]])
agent 0 action: VehicleControl(throttle=0.078629, steer=0.015246, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00520512356422262
Current mitigation activation: 0
#############################
Total reward: 17.530988688291163
8.367398463189602 seconds in game passed.
Action: tensor([[[ 2.5058e-02,  9.5369e-01],
         [ 2.1363e-04,  9.4753e-01],
         [-1.3297e-02,  9.1528e-01],
         [-8.2917e-03,  6.0200e-01]]])
agent 0 action: VehicleControl(throttle=0.077924, steer=0.015275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530988688291163
8.392398463562131 seconds in game passed.
Action: tensor([[[ 2.5058e-02,  9.5369e-01],
         [ 2.1363e-04,  9.4753e-01],
         [-1.3297e-02,  9.1528e-01],
         [-8.2917e-03,  6.0200e-01]]])
agent 0 action: VehicleControl(throttle=0.079071, steer=0.015215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530988688291163
8.41739846393466 seconds in game passed.
Action: tensor([[[ 2.5058e-02,  9.5369e-01],
         [ 2.1363e-04,  9.4753e-01],
         [-1.3297e-02,  9.1528e-01],
         [-8.2917e-03,  6.0200e-01]]])
agent 0 action: VehicleControl(throttle=0.080165, steer=0.015154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530988688291163
+++++++++++++: 245.38683086444198
8.442398464307189 seconds in game passed.
At 8.442398464307189 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0103,  0.9527],
         [-0.0038,  0.9418],
         [-0.0104,  0.8766],
         [-0.0038,  0.6075]]])
agent 0 action: VehicleControl(throttle=0.055831, steer=0.003468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004620009965233972
Current mitigation activation: 0
#############################
Total reward: 17.535608698256397
8.467398464679718 seconds in game passed.
Action: tensor([[[ 0.0103,  0.9527],
         [-0.0038,  0.9418],
         [-0.0104,  0.8766],
         [-0.0038,  0.6075]]])
agent 0 action: VehicleControl(throttle=0.059259, steer=0.005441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.535608698256397
8.492398465052247 seconds in game passed.
Action: tensor([[[ 0.0103,  0.9527],
         [-0.0038,  0.9418],
         [-0.0104,  0.8766],
         [-0.0038,  0.6075]]])
agent 0 action: VehicleControl(throttle=0.059981, steer=0.005464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.535608698256397
8.517398465424776 seconds in game passed.
Action: tensor([[[ 0.0103,  0.9527],
         [-0.0038,  0.9418],
         [-0.0104,  0.8766],
         [-0.0038,  0.6075]]])
agent 0 action: VehicleControl(throttle=0.060706, steer=0.005486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.535608698256397
+++++++++++++: 275.6166971959023
8.542398465797305 seconds in game passed.
At 8.542398465797305 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0313,  0.9512],
         [-0.0183,  0.9072],
         [-0.0121,  0.7384],
         [-0.0084,  0.5456]]])
agent 0 action: VehicleControl(throttle=0.195410, steer=-0.029412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004330774620942151
Current mitigation activation: 0
#############################
Total reward: 17.53993947287734
8.567398466169834 seconds in game passed.
Action: tensor([[[-0.0313,  0.9512],
         [-0.0183,  0.9072],
         [-0.0121,  0.7384],
         [-0.0084,  0.5456]]])
agent 0 action: VehicleControl(throttle=0.183416, steer=-0.023982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53993947287734
8.592398466542363 seconds in game passed.
Action: tensor([[[-0.0313,  0.9512],
         [-0.0183,  0.9072],
         [-0.0121,  0.7384],
         [-0.0084,  0.5456]]])
agent 0 action: VehicleControl(throttle=0.185576, steer=-0.024313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53993947287734
8.617398466914892 seconds in game passed.
Action: tensor([[[-0.0313,  0.9512],
         [-0.0183,  0.9072],
         [-0.0121,  0.7384],
         [-0.0084,  0.5456]]])
agent 0 action: VehicleControl(throttle=0.187597, steer=-0.024643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53993947287734
+++++++++++++: 298.1919770671321
8.642398467287421 seconds in game passed.
At 8.642398467287421 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0392,  0.9497],
         [-0.0174,  0.8223],
         [-0.0073,  0.6115],
         [-0.0046,  0.4914]]])
agent 0 action: VehicleControl(throttle=0.628411, steer=-0.028253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004216184790379337
Current mitigation activation: 0
#############################
Total reward: 17.54415565766772
8.66739846765995 seconds in game passed.
Action: tensor([[[-0.0392,  0.9497],
         [-0.0174,  0.8223],
         [-0.0073,  0.6115],
         [-0.0046,  0.4914]]])
agent 0 action: VehicleControl(throttle=0.588558, steer=-0.028080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54415565766772
8.69239846803248 seconds in game passed.
Action: tensor([[[-0.0392,  0.9497],
         [-0.0174,  0.8223],
         [-0.0073,  0.6115],
         [-0.0046,  0.4914]]])
agent 0 action: VehicleControl(throttle=0.595084, steer=-0.028447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54415565766772
8.717398468405008 seconds in game passed.
Action: tensor([[[-0.0392,  0.9497],
         [-0.0174,  0.8223],
         [-0.0073,  0.6115],
         [-0.0046,  0.4914]]])
agent 0 action: VehicleControl(throttle=0.601305, steer=-0.028815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54415565766772
+++++++++++++: 289.0921044750603
8.742398468777537 seconds in game passed.
At 8.742398468777537 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0331,  0.9491],
         [-0.0101,  0.7991],
         [-0.0053,  0.5860],
         [-0.0066,  0.4795]]])
agent 0 action: VehicleControl(throttle=0.743115, steer=-0.020567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004578704147610954
Current mitigation activation: 0
#############################
Total reward: 17.54873436181533
8.767398469150066 seconds in game passed.
Action: tensor([[[-0.0331,  0.9491],
         [-0.0101,  0.7991],
         [-0.0053,  0.5860],
         [-0.0066,  0.4795]]])
agent 0 action: VehicleControl(throttle=0.735256, steer=-0.022266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54873436181533
8.792398469522595 seconds in game passed.
Action: tensor([[[-0.0331,  0.9491],
         [-0.0101,  0.7991],
         [-0.0053,  0.5860],
         [-0.0066,  0.4795]]])
agent 0 action: VehicleControl(throttle=0.741002, steer=-0.022543, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54873436181533
8.817398469895124 seconds in game passed.
Action: tensor([[[-0.0331,  0.9491],
         [-0.0101,  0.7991],
         [-0.0053,  0.5860],
         [-0.0066,  0.4795]]])
agent 0 action: VehicleControl(throttle=0.745345, steer=-0.022821, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54873436181533
+++++++++++++: 197.90438017592342
8.842398470267653 seconds in game passed.
At 8.842398470267653 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.4721e-02,  9.4336e-01],
         [-4.7681e-03,  6.0852e-01],
         [-1.7748e-03,  4.7555e-01],
         [-2.2238e-04,  4.2099e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0070354350924482145
Current mitigation activation: 0
#############################
Total reward: 17.55576979690778
8.867398470640182 seconds in game passed.
Action: tensor([[[-2.4721e-02,  9.4336e-01],
         [-4.7681e-03,  6.0852e-01],
         [-1.7748e-03,  4.7555e-01],
         [-2.2238e-04,  4.2099e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55576979690778
8.892398471012712 seconds in game passed.
Action: tensor([[[-2.4721e-02,  9.4336e-01],
         [-4.7681e-03,  6.0852e-01],
         [-1.7748e-03,  4.7555e-01],
         [-2.2238e-04,  4.2099e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014799, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55576979690778
8.91739847138524 seconds in game passed.
Action: tensor([[[-2.4721e-02,  9.4336e-01],
         [-4.7681e-03,  6.0852e-01],
         [-1.7748e-03,  4.7555e-01],
         [-2.2238e-04,  4.2099e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014970, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55576979690778
+++++++++++++: 43.80276391792086
8.94239847175777 seconds in game passed.
At 8.94239847175777 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2724e-02,  9.3188e-01],
         [-4.0253e-04,  5.5871e-01],
         [ 2.2421e-04,  4.3748e-01],
         [ 1.2864e-03,  3.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005954, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03333646678546401
Current mitigation activation: 0
#############################
Total reward: 17.589106263693242
8.967398472130299 seconds in game passed.
Action: tensor([[[-1.2724e-02,  9.3188e-01],
         [-4.0253e-04,  5.5871e-01],
         [ 2.2421e-04,  4.3748e-01],
         [ 1.2864e-03,  3.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.589106263693242
8.992398472502828 seconds in game passed.
Action: tensor([[[-1.2724e-02,  9.3188e-01],
         [-4.0253e-04,  5.5871e-01],
         [ 2.2421e-04,  4.3748e-01],
         [ 1.2864e-03,  3.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.589106263693242
9.017398472875357 seconds in game passed.
Action: tensor([[[-1.2724e-02,  9.3188e-01],
         [-4.0253e-04,  5.5871e-01],
         [ 2.2421e-04,  4.3748e-01],
         [ 1.2864e-03,  3.8169e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.589106263693242
+++++++++++++: 18.19569510301065
9.042398473247886 seconds in game passed.
At 9.042398473247886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0101,  0.8852],
         [-0.0034,  0.4974],
         [-0.0055,  0.3630],
         [-0.0058,  0.2935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.08378124814659908
Current mitigation activation: 0
#############################
Total reward: 17.672887511839843
9.067398473620415 seconds in game passed.
Action: tensor([[[-0.0101,  0.8852],
         [-0.0034,  0.4974],
         [-0.0055,  0.3630],
         [-0.0058,  0.2935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.672887511839843
9.092398473992944 seconds in game passed.
Action: tensor([[[-0.0101,  0.8852],
         [-0.0034,  0.4974],
         [-0.0055,  0.3630],
         [-0.0058,  0.2935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.672887511839843
9.117398474365473 seconds in game passed.
Action: tensor([[[-0.0101,  0.8852],
         [-0.0034,  0.4974],
         [-0.0055,  0.3630],
         [-0.0058,  0.2935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.672887511839843
+++++++++++++: 10.336450038927177
9.142398474738002 seconds in game passed.
At 9.142398474738002 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0017,  0.8361],
         [-0.0034,  0.4727],
         [-0.0063,  0.3381],
         [-0.0073,  0.2656]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.15313202152525462
Current mitigation activation: 0
#############################
Total reward: 17.8260195333651
9.16739847511053 seconds in game passed.
Action: tensor([[[ 0.0017,  0.8361],
         [-0.0034,  0.4727],
         [-0.0063,  0.3381],
         [-0.0073,  0.2656]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.8260195333651
9.19239847548306 seconds in game passed.
Action: tensor([[[ 0.0017,  0.8361],
         [-0.0034,  0.4727],
         [-0.0063,  0.3381],
         [-0.0073,  0.2656]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.8260195333651
9.217398475855589 seconds in game passed.
Action: tensor([[[ 0.0017,  0.8361],
         [-0.0034,  0.4727],
         [-0.0063,  0.3381],
         [-0.0073,  0.2656]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.8260195333651
+++++++++++++: 7.313758413865513
9.242398476228118 seconds in game passed.
At 9.242398476228118 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0058,  0.8113],
         [-0.0020,  0.4579],
         [-0.0050,  0.3242],
         [-0.0065,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.313758413865513
Current reward: 0.1765507977644014
Current mitigation activation: 0
#############################
Total reward: 18.0025703311295
9.267398476600647 seconds in game passed.
Action: tensor([[[ 0.0058,  0.8113],
         [-0.0020,  0.4579],
         [-0.0050,  0.3242],
         [-0.0065,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003004, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.0025703311295
9.292398476973176 seconds in game passed.
Action: tensor([[[ 0.0058,  0.8113],
         [-0.0020,  0.4579],
         [-0.0050,  0.3242],
         [-0.0065,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.0025703311295
9.317398477345705 seconds in game passed.
Action: tensor([[[ 0.0058,  0.8113],
         [-0.0020,  0.4579],
         [-0.0050,  0.3242],
         [-0.0065,  0.2520]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.0025703311295
+++++++++++++: 5.946484603965469
9.342398477718234 seconds in game passed.
At 9.342398477718234 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0072,  0.8047],
         [-0.0008,  0.4510],
         [-0.0038,  0.3145],
         [-0.0056,  0.2409]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.946484603965469
Current reward: 0.19309745507051107
Current mitigation activation: 0
#############################
Total reward: 18.195667786200012
9.367398478090763 seconds in game passed.
Action: tensor([[[ 0.0072,  0.8047],
         [-0.0008,  0.4510],
         [-0.0038,  0.3145],
         [-0.0056,  0.2409]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.195667786200012
9.392398478463292 seconds in game passed.
Action: tensor([[[ 0.0072,  0.8047],
         [-0.0008,  0.4510],
         [-0.0038,  0.3145],
         [-0.0056,  0.2409]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.195667786200012
9.417398478835821 seconds in game passed.
Action: tensor([[[ 0.0072,  0.8047],
         [-0.0008,  0.4510],
         [-0.0038,  0.3145],
         [-0.0056,  0.2409]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.195667786200012
+++++++++++++: 5.097954083159293
9.44239847920835 seconds in game passed.
At 9.44239847920835 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.7646],
         [-0.0009,  0.4288],
         [-0.0034,  0.2983],
         [-0.0051,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.097954083159293
Current reward: 0.20837298644355962
Current mitigation activation: 0
#############################
Total reward: 18.404040772643572
9.46739847958088 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7646],
         [-0.0009,  0.4288],
         [-0.0034,  0.2983],
         [-0.0051,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.404040772643572
9.492398479953408 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7646],
         [-0.0009,  0.4288],
         [-0.0034,  0.2983],
         [-0.0051,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.404040772643572
9.517398480325937 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7646],
         [-0.0009,  0.4288],
         [-0.0034,  0.2983],
         [-0.0051,  0.2289]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.404040772643572
+++++++++++++: 4.49187567115306
9.542398480698466 seconds in game passed.
At 9.542398480698466 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.7517],
         [-0.0013,  0.4213],
         [-0.0035,  0.2932],
         [-0.0050,  0.2255]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.49187567115306
Current reward: 0.22293083931874114
Current mitigation activation: 0
#############################
Total reward: 18.626971611962315
9.567398481070995 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7517],
         [-0.0013,  0.4213],
         [-0.0035,  0.2932],
         [-0.0050,  0.2255]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002946, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.626971611962315
9.592398481443524 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7517],
         [-0.0013,  0.4213],
         [-0.0035,  0.2932],
         [-0.0050,  0.2255]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.626971611962315
9.617398481816053 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7517],
         [-0.0013,  0.4213],
         [-0.0035,  0.2932],
         [-0.0050,  0.2255]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.626971611962315
+++++++++++++: 4.025917832948461
9.642398482188582 seconds in game passed.
At 9.642398482188582 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1734e-02,  7.5584e-01],
         [ 3.3230e-04,  4.1945e-01],
         [-1.3030e-03,  2.9195e-01],
         [-2.0733e-03,  2.2484e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.025917832948461
Current reward: 0.23696550342063832
Current mitigation activation: 0
#############################
Total reward: 18.863937115382953
9.667398482561111 seconds in game passed.
Action: tensor([[[ 1.1734e-02,  7.5584e-01],
         [ 3.3230e-04,  4.1945e-01],
         [-1.3030e-03,  2.9195e-01],
         [-2.0733e-03,  2.2484e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.863937115382953
9.69239848293364 seconds in game passed.
Action: tensor([[[ 1.1734e-02,  7.5584e-01],
         [ 3.3230e-04,  4.1945e-01],
         [-1.3030e-03,  2.9195e-01],
         [-2.0733e-03,  2.2484e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.863937115382953
9.71739848330617 seconds in game passed.
Action: tensor([[[ 1.1734e-02,  7.5584e-01],
         [ 3.3230e-04,  4.1945e-01],
         [-1.3030e-03,  2.9195e-01],
         [-2.0733e-03,  2.2484e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.863937115382953
+++++++++++++: 3.650464605745036
9.742398483678699 seconds in game passed.
At 9.742398483678699 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5466e-02,  7.5319e-01],
         [ 1.2004e-03,  4.2175e-01],
         [-1.7269e-04,  2.9437e-01],
         [-5.9964e-04,  2.2668e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.650464605745036
Current reward: 0.25056236199522364
Current mitigation activation: 0
#############################
Total reward: 19.11449947737818
9.767398484051228 seconds in game passed.
Action: tensor([[[ 1.5466e-02,  7.5319e-01],
         [ 1.2004e-03,  4.2175e-01],
         [-1.7269e-04,  2.9437e-01],
         [-5.9964e-04,  2.2668e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.11449947737818
9.792398484423757 seconds in game passed.
Action: tensor([[[ 1.5466e-02,  7.5319e-01],
         [ 1.2004e-03,  4.2175e-01],
         [-1.7269e-04,  2.9437e-01],
         [-5.9964e-04,  2.2668e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.11449947737818
9.817398484796286 seconds in game passed.
Action: tensor([[[ 1.5466e-02,  7.5319e-01],
         [ 1.2004e-03,  4.2175e-01],
         [-1.7269e-04,  2.9437e-01],
         [-5.9964e-04,  2.2668e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.11449947737818
+++++++++++++: 3.337769847672915
9.842398485168815 seconds in game passed.
At 9.842398485168815 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3554e-02, 7.4518e-01],
         [2.2992e-03, 4.2022e-01],
         [9.7005e-04, 2.9314e-01],
         [5.2124e-04, 2.2538e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005867, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.337769847672915
Current reward: 0.2637605727617579
Current mitigation activation: 0
#############################
Total reward: 19.378260050139936
9.867398485541344 seconds in game passed.
Action: tensor([[[1.3554e-02, 7.4518e-01],
         [2.2992e-03, 4.2022e-01],
         [9.7005e-04, 2.9314e-01],
         [5.2124e-04, 2.2538e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.378260050139936
9.892398485913873 seconds in game passed.
Action: tensor([[[1.3554e-02, 7.4518e-01],
         [2.2992e-03, 4.2022e-01],
         [9.7005e-04, 2.9314e-01],
         [5.2124e-04, 2.2538e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.378260050139936
9.917398486286402 seconds in game passed.
Action: tensor([[[1.3554e-02, 7.4518e-01],
         [2.2992e-03, 4.2022e-01],
         [9.7005e-04, 2.9314e-01],
         [5.2124e-04, 2.2538e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.378260050139936
+++++++++++++: 3.187795423288411
9.94239848665893 seconds in game passed.
At 9.94239848665893 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0747e-02, 7.0978e-01],
         [1.6190e-03, 3.9716e-01],
         [8.0118e-04, 2.7708e-01],
         [4.6154e-04, 2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.187795423288411
Current reward: 0.2720689197451557
Current mitigation activation: 0
#############################
Total reward: 19.65032896988509
9.96739848703146 seconds in game passed.
Action: tensor([[[1.0747e-02, 7.0978e-01],
         [1.6190e-03, 3.9716e-01],
         [8.0118e-04, 2.7708e-01],
         [4.6154e-04, 2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.65032896988509
9.992398487403989 seconds in game passed.
Action: tensor([[[1.0747e-02, 7.0978e-01],
         [1.6190e-03, 3.9716e-01],
         [8.0118e-04, 2.7708e-01],
         [4.6154e-04, 2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.65032896988509
10.017398487776518 seconds in game passed.
Action: tensor([[[1.0747e-02, 7.0978e-01],
         [1.6190e-03, 3.9716e-01],
         [8.0118e-04, 2.7708e-01],
         [4.6154e-04, 2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.65032896988509
+++++++++++++: 3.2223886814398743
10.042398488149047 seconds in game passed.
At 10.042398488149047 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.1319e-03, 6.8053e-01],
         [1.2547e-03, 3.7859e-01],
         [7.0819e-04, 2.6502e-01],
         [3.2139e-04, 2.0684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2223886814398743
Current reward: 0.2733861934428109
Current mitigation activation: 0
#############################
Total reward: 19.923715163327902
10.067398488521576 seconds in game passed.
Action: tensor([[[7.1319e-03, 6.8053e-01],
         [1.2547e-03, 3.7859e-01],
         [7.0819e-04, 2.6502e-01],
         [3.2139e-04, 2.0684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.923715163327902
10.092398488894105 seconds in game passed.
Action: tensor([[[7.1319e-03, 6.8053e-01],
         [1.2547e-03, 3.7859e-01],
         [7.0819e-04, 2.6502e-01],
         [3.2139e-04, 2.0684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.923715163327902
10.117398489266634 seconds in game passed.
Action: tensor([[[7.1319e-03, 6.8053e-01],
         [1.2547e-03, 3.7859e-01],
         [7.0819e-04, 2.6502e-01],
         [3.2139e-04, 2.0684e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.923715163327902
+++++++++++++: 3.2580439597393474
10.142398489639163 seconds in game passed.
At 10.142398489639163 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.7078e-03, 6.6092e-01],
         [1.3159e-03, 3.6583e-01],
         [9.1176e-04, 2.5515e-01],
         [2.0960e-04, 1.9906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2580439597393474
Current reward: 0.2746826771025459
Current mitigation activation: 0
#############################
Total reward: 20.19839784043045
10.167398490011692 seconds in game passed.
Action: tensor([[[3.7078e-03, 6.6092e-01],
         [1.3159e-03, 3.6583e-01],
         [9.1176e-04, 2.5515e-01],
         [2.0960e-04, 1.9906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.19839784043045
10.192398490384221 seconds in game passed.
Action: tensor([[[3.7078e-03, 6.6092e-01],
         [1.3159e-03, 3.6583e-01],
         [9.1176e-04, 2.5515e-01],
         [2.0960e-04, 1.9906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.19839784043045
10.21739849075675 seconds in game passed.
Action: tensor([[[3.7078e-03, 6.6092e-01],
         [1.3159e-03, 3.6583e-01],
         [9.1176e-04, 2.5515e-01],
         [2.0960e-04, 1.9906e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.19839784043045
+++++++++++++: 3.2940689681797637
10.24239849112928 seconds in game passed.
At 10.24239849112928 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.1052e-03, 6.5860e-01],
         [9.6509e-04, 3.6466e-01],
         [6.8103e-04, 2.5422e-01],
         [1.0313e-04, 1.9810e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2940689681797637
Current reward: 0.27598591002941086
Current mitigation activation: 0
#############################
Total reward: 20.47438375045986
10.267398491501808 seconds in game passed.
Action: tensor([[[3.1052e-03, 6.5860e-01],
         [9.6509e-04, 3.6466e-01],
         [6.8103e-04, 2.5422e-01],
         [1.0313e-04, 1.9810e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47438375045986
10.292398491874337 seconds in game passed.
Action: tensor([[[3.1052e-03, 6.5860e-01],
         [9.6509e-04, 3.6466e-01],
         [6.8103e-04, 2.5422e-01],
         [1.0313e-04, 1.9810e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47438375045986
10.317398492246866 seconds in game passed.
Action: tensor([[[3.1052e-03, 6.5860e-01],
         [9.6509e-04, 3.6466e-01],
         [6.8103e-04, 2.5422e-01],
         [1.0313e-04, 1.9810e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47438375045986
+++++++++++++: 3.330579044140966
10.342398492619395 seconds in game passed.
At 10.342398492619395 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7508e-03,  6.4331e-01],
         [ 5.4121e-04,  3.5771e-01],
         [ 2.0565e-04,  2.5043e-01],
         [-3.9004e-04,  1.9530e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.330579044140966
Current reward: 0.27729011352672794
Current mitigation activation: 0
#############################
Total reward: 20.75167386398659
10.367398492991924 seconds in game passed.
Action: tensor([[[ 2.7508e-03,  6.4331e-01],
         [ 5.4121e-04,  3.5771e-01],
         [ 2.0565e-04,  2.5043e-01],
         [-3.9004e-04,  1.9530e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.75167386398659
10.392398493364453 seconds in game passed.
Action: tensor([[[ 2.7508e-03,  6.4331e-01],
         [ 5.4121e-04,  3.5771e-01],
         [ 2.0565e-04,  2.5043e-01],
         [-3.9004e-04,  1.9530e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.75167386398659
10.417398493736982 seconds in game passed.
Action: tensor([[[ 2.7508e-03,  6.4331e-01],
         [ 5.4121e-04,  3.5771e-01],
         [ 2.0565e-04,  2.5043e-01],
         [-3.9004e-04,  1.9530e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002839, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.75167386398659
+++++++++++++: 3.2521852196035654
10.442398494109511 seconds in game passed.
At 10.442398494109511 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8953e-03,  6.3988e-01],
         [ 6.2019e-05,  3.5515e-01],
         [-4.4311e-04,  2.4794e-01],
         [-1.0771e-03,  1.9299e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2521852196035654
Current reward: 0.2827740613902617
Current mitigation activation: 0
#############################
Total reward: 21.034447925376853
10.46739849448204 seconds in game passed.
Action: tensor([[[ 1.8953e-03,  6.3988e-01],
         [ 6.2019e-05,  3.5515e-01],
         [-4.4311e-04,  2.4794e-01],
         [-1.0771e-03,  1.9299e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.034447925376853
10.49239849485457 seconds in game passed.
Action: tensor([[[ 1.8953e-03,  6.3988e-01],
         [ 6.2019e-05,  3.5515e-01],
         [-4.4311e-04,  2.4794e-01],
         [-1.0771e-03,  1.9299e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.034447925376853
10.517398495227098 seconds in game passed.
Action: tensor([[[ 1.8953e-03,  6.3988e-01],
         [ 6.2019e-05,  3.5515e-01],
         [-4.4311e-04,  2.4794e-01],
         [-1.0771e-03,  1.9299e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.034447925376853
+++++++++++++: 2.9767688306732043
10.542398495599627 seconds in game passed.
At 10.542398495599627 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2551e-03,  6.4293e-01],
         [ 5.2998e-04,  3.5520e-01],
         [ 6.7353e-06,  2.4640e-01],
         [-7.0104e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002706, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9767688306732043
Current reward: 0.2964843720619952
Current mitigation activation: 0
#############################
Total reward: 21.33093229743885
10.567398495972157 seconds in game passed.
Action: tensor([[[ 2.2551e-03,  6.4293e-01],
         [ 5.2998e-04,  3.5520e-01],
         [ 6.7353e-06,  2.4640e-01],
         [-7.0104e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.33093229743885
10.592398496344686 seconds in game passed.
Action: tensor([[[ 2.2551e-03,  6.4293e-01],
         [ 5.2998e-04,  3.5520e-01],
         [ 6.7353e-06,  2.4640e-01],
         [-7.0104e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.33093229743885
10.617398496717215 seconds in game passed.
Action: tensor([[[ 2.2551e-03,  6.4293e-01],
         [ 5.2998e-04,  3.5520e-01],
         [ 6.7353e-06,  2.4640e-01],
         [-7.0104e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.33093229743885
+++++++++++++: 2.7600424206866134
10.642398497089744 seconds in game passed.
At 10.642398497089744 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.6055e-04,  6.6224e-01],
         [-1.2409e-03,  3.6302e-01],
         [-1.9000e-03,  2.5053e-01],
         [-2.6180e-03,  1.9345e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000504, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7600424206866134
Current reward: 0.30860377737809974
Current mitigation activation: 0
#############################
Total reward: 21.63953607481695
10.667398497462273 seconds in game passed.
Action: tensor([[[ 3.6055e-04,  6.6224e-01],
         [-1.2409e-03,  3.6302e-01],
         [-1.9000e-03,  2.5053e-01],
         [-2.6180e-03,  1.9345e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63953607481695
10.692398497834802 seconds in game passed.
Action: tensor([[[ 3.6055e-04,  6.6224e-01],
         [-1.2409e-03,  3.6302e-01],
         [-1.9000e-03,  2.5053e-01],
         [-2.6180e-03,  1.9345e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63953607481695
10.71739849820733 seconds in game passed.
Action: tensor([[[ 3.6055e-04,  6.6224e-01],
         [-1.2409e-03,  3.6302e-01],
         [-1.9000e-03,  2.5053e-01],
         [-2.6180e-03,  1.9345e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000665, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.63953607481695
+++++++++++++: 2.579913137575906
10.74239849857986 seconds in game passed.
At 10.74239849857986 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6698],
         [-0.0013,  0.3648],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.579913137575906
Current reward: 0.31951448072950184
Current mitigation activation: 0
#############################
Total reward: 21.95905055554645
10.767398498952389 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6698],
         [-0.0013,  0.3648],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.95905055554645
10.792398499324918 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6698],
         [-0.0013,  0.3648],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000618, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.95905055554645
10.817398499697447 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6698],
         [-0.0013,  0.3648],
         [-0.0019,  0.2505],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.95905055554645
+++++++++++++: 2.4219257195283523
10.842398500069976 seconds in game passed.
At 10.842398500069976 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2863e-04,  6.7831e-01],
         [-1.6336e-03,  3.6684e-01],
         [-2.5968e-03,  2.5171e-01],
         [-3.5402e-03,  1.9382e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4219257195283523
Current reward: 0.3296235733987869
Current mitigation activation: 0
#############################
Total reward: 22.28867412894524
10.867398500442505 seconds in game passed.
Action: tensor([[[ 2.2863e-04,  6.7831e-01],
         [-1.6336e-03,  3.6684e-01],
         [-2.5968e-03,  2.5171e-01],
         [-3.5402e-03,  1.9382e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.28867412894524
10.892398500815034 seconds in game passed.
Action: tensor([[[ 2.2863e-04,  6.7831e-01],
         [-1.6336e-03,  3.6684e-01],
         [-2.5968e-03,  2.5171e-01],
         [-3.5402e-03,  1.9382e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.28867412894524
10.917398501187563 seconds in game passed.
Action: tensor([[[ 2.2863e-04,  6.7831e-01],
         [-1.6336e-03,  3.6684e-01],
         [-2.5968e-03,  2.5171e-01],
         [-3.5402e-03,  1.9382e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.28867412894524
+++++++++++++: 2.278966346371807
10.942398501560092 seconds in game passed.
At 10.942398501560092 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6827],
         [-0.0025,  0.3675],
         [-0.0034,  0.2530],
         [-0.0045,  0.1950]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.278966346371807
Current reward: 0.33913720646013007
Current mitigation activation: 0
#############################
Total reward: 22.62781133540537
10.967398501932621 seconds in game passed.
Action: tensor([[[-0.0011,  0.6827],
         [-0.0025,  0.3675],
         [-0.0034,  0.2530],
         [-0.0045,  0.1950]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.62781133540537
10.99239850230515 seconds in game passed.
Action: tensor([[[-0.0011,  0.6827],
         [-0.0025,  0.3675],
         [-0.0034,  0.2530],
         [-0.0045,  0.1950]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.62781133540537
11.017398502677679 seconds in game passed.
Action: tensor([[[-0.0011,  0.6827],
         [-0.0025,  0.3675],
         [-0.0034,  0.2530],
         [-0.0045,  0.1950]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001612, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.62781133540537
+++++++++++++: 2.147299979683538
11.042398503050208 seconds in game passed.
At 11.042398503050208 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6877],
         [-0.0036,  0.3737],
         [-0.0045,  0.2578],
         [-0.0050,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.147299979683538
Current reward: 0.3481472256793358
Current mitigation activation: 0
#############################
Total reward: 22.975958561084706
11.067398503422737 seconds in game passed.
Action: tensor([[[-0.0013,  0.6877],
         [-0.0036,  0.3737],
         [-0.0045,  0.2578],
         [-0.0050,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.975958561084706
11.092398503795266 seconds in game passed.
Action: tensor([[[-0.0013,  0.6877],
         [-0.0036,  0.3737],
         [-0.0045,  0.2578],
         [-0.0050,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.975958561084706
11.117398504167795 seconds in game passed.
Action: tensor([[[-0.0013,  0.6877],
         [-0.0036,  0.3737],
         [-0.0045,  0.2578],
         [-0.0050,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.975958561084706
+++++++++++++: 2.0247498123315792
11.142398504540324 seconds in game passed.
At 11.142398504540324 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0028,  0.6767],
         [-0.0009,  0.3712],
         [-0.0018,  0.2570],
         [-0.0027,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0247498123315792
Current reward: 0.35668894426411557
Current mitigation activation: 0
#############################
Total reward: 23.33264750534882
11.167398504912853 seconds in game passed.
Action: tensor([[[ 0.0028,  0.6767],
         [-0.0009,  0.3712],
         [-0.0018,  0.2570],
         [-0.0027,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.33264750534882
11.192398505285382 seconds in game passed.
Action: tensor([[[ 0.0028,  0.6767],
         [-0.0009,  0.3712],
         [-0.0018,  0.2570],
         [-0.0027,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.33264750534882
11.217398505657911 seconds in game passed.
Action: tensor([[[ 0.0028,  0.6767],
         [-0.0009,  0.3712],
         [-0.0018,  0.2570],
         [-0.0027,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.33264750534882
+++++++++++++: 1.9099784048694206
11.24239850603044 seconds in game passed.
At 11.24239850603044 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6850],
         [-0.0014,  0.3774],
         [-0.0023,  0.2618],
         [-0.0030,  0.2019]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9099784048694206
Current reward: 0.3647629938294997
Current mitigation activation: 0
#############################
Total reward: 23.69741049917832
11.26739850640297 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6850],
         [-0.0014,  0.3774],
         [-0.0023,  0.2618],
         [-0.0030,  0.2019]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.69741049917832
11.292398506775498 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6850],
         [-0.0014,  0.3774],
         [-0.0023,  0.2618],
         [-0.0030,  0.2019]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.69741049917832
11.317398507148027 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6850],
         [-0.0014,  0.3774],
         [-0.0023,  0.2618],
         [-0.0030,  0.2019]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.69741049917832
+++++++++++++: 1.8018133488202521
11.342398507520556 seconds in game passed.
At 11.342398507520556 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.5648e-03,  6.7978e-01],
         [ 1.8436e-04,  3.8723e-01],
         [-6.1203e-04,  2.7345e-01],
         [-1.1136e-03,  2.1295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8018133488202521
Current reward: 0.3723752901723186
Current mitigation activation: 0
#############################
Total reward: 24.06978578935064
11.367398507893085 seconds in game passed.
Action: tensor([[[ 6.5648e-03,  6.7978e-01],
         [ 1.8436e-04,  3.8723e-01],
         [-6.1203e-04,  2.7345e-01],
         [-1.1136e-03,  2.1295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.06978578935064
11.392398508265615 seconds in game passed.
Action: tensor([[[ 6.5648e-03,  6.7978e-01],
         [ 1.8436e-04,  3.8723e-01],
         [-6.1203e-04,  2.7345e-01],
         [-1.1136e-03,  2.1295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.06978578935064
11.417398508638144 seconds in game passed.
Action: tensor([[[ 6.5648e-03,  6.7978e-01],
         [ 1.8436e-04,  3.8723e-01],
         [-6.1203e-04,  2.7345e-01],
         [-1.1136e-03,  2.1295e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.06978578935064
+++++++++++++: 1.6993820322807405
11.442398509010673 seconds in game passed.
At 11.442398509010673 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.7523e-03,  7.0122e-01],
         [ 3.7208e-04,  3.9415e-01],
         [-5.0794e-04,  2.7621e-01],
         [-9.6495e-04,  2.1356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6993820322807405
Current reward: 0.379523506139657
Current mitigation activation: 0
#############################
Total reward: 24.449309295490295
11.467398509383202 seconds in game passed.
Action: tensor([[[ 6.7523e-03,  7.0122e-01],
         [ 3.7208e-04,  3.9415e-01],
         [-5.0794e-04,  2.7621e-01],
         [-9.6495e-04,  2.1356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.449309295490295
11.49239850975573 seconds in game passed.
Action: tensor([[[ 6.7523e-03,  7.0122e-01],
         [ 3.7208e-04,  3.9415e-01],
         [-5.0794e-04,  2.7621e-01],
         [-9.6495e-04,  2.1356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.449309295490295
11.51739851012826 seconds in game passed.
Action: tensor([[[ 6.7523e-03,  7.0122e-01],
         [ 3.7208e-04,  3.9415e-01],
         [-5.0794e-04,  2.7621e-01],
         [-9.6495e-04,  2.1356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.449309295490295
+++++++++++++: 1.601867999716485
11.542398510500789 seconds in game passed.
At 11.542398510500789 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.4656e-03,  7.2703e-01],
         [ 5.6780e-04,  4.0664e-01],
         [-2.7310e-04,  2.8407e-01],
         [-4.2132e-04,  2.1927e-01]]])
agent 0 action: VehicleControl(throttle=0.744676, steer=0.003797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.601867999716485
Current reward: 0.38621812070411277
Current mitigation activation: 0
#############################
Total reward: 24.835527416194406
11.567398510873318 seconds in game passed.
Action: tensor([[[ 9.4656e-03,  7.2703e-01],
         [ 5.6780e-04,  4.0664e-01],
         [-2.7310e-04,  2.8407e-01],
         [-4.2132e-04,  2.1927e-01]]])
agent 0 action: VehicleControl(throttle=0.696117, steer=0.003619, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.835527416194406
11.592398511245847 seconds in game passed.
Action: tensor([[[ 9.4656e-03,  7.2703e-01],
         [ 5.6780e-04,  4.0664e-01],
         [-2.7310e-04,  2.8407e-01],
         [-4.2132e-04,  2.1927e-01]]])
agent 0 action: VehicleControl(throttle=0.636771, steer=0.003650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.835527416194406
11.617398511618376 seconds in game passed.
Action: tensor([[[ 9.4656e-03,  7.2703e-01],
         [ 5.6780e-04,  4.0664e-01],
         [-2.7310e-04,  2.8407e-01],
         [-4.2132e-04,  2.1927e-01]]])
agent 0 action: VehicleControl(throttle=0.579289, steer=0.003681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.835527416194406
+++++++++++++: 1.5093381380597526
11.642398511990905 seconds in game passed.
At 11.642398511990905 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1915e-02, 7.4180e-01],
         [2.1358e-03, 4.1293e-01],
         [9.2772e-04, 2.8987e-01],
         [4.0714e-04, 2.2473e-01]]])
agent 0 action: VehicleControl(throttle=0.520229, steer=0.005913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5093381380597526
Current reward: 0.39235494590533987
Current mitigation activation: 0
#############################
Total reward: 25.227882362099745
11.667398512363434 seconds in game passed.
Action: tensor([[[1.1915e-02, 7.4180e-01],
         [2.1358e-03, 4.1293e-01],
         [9.2772e-04, 2.8987e-01],
         [4.0714e-04, 2.2473e-01]]])
agent 0 action: VehicleControl(throttle=0.499880, steer=0.005629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.227882362099745
11.692398512735963 seconds in game passed.
Action: tensor([[[1.1915e-02, 7.4180e-01],
         [2.1358e-03, 4.1293e-01],
         [9.2772e-04, 2.8987e-01],
         [4.0714e-04, 2.2473e-01]]])
agent 0 action: VehicleControl(throttle=0.475947, steer=0.005704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.227882362099745
11.717398513108492 seconds in game passed.
Action: tensor([[[1.1915e-02, 7.4180e-01],
         [2.1358e-03, 4.1293e-01],
         [9.2772e-04, 2.8987e-01],
         [4.0714e-04, 2.2473e-01]]])
agent 0 action: VehicleControl(throttle=0.452496, steer=0.005779, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.227882362099745
+++++++++++++: 1.4291790943150442
11.742398513481021 seconds in game passed.
At 11.742398513481021 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4675e-02,  7.6275e-01],
         [ 1.4604e-03,  4.2449e-01],
         [-1.7732e-04,  2.9746e-01],
         [-7.7590e-04,  2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.429372, steer=0.006513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4291790943150442
Current reward: 0.3966057662257738
Current mitigation activation: 0
#############################
Total reward: 25.62448812832552
11.76739851385355 seconds in game passed.
Action: tensor([[[ 1.4675e-02,  7.6275e-01],
         [ 1.4604e-03,  4.2449e-01],
         [-1.7732e-04,  2.9746e-01],
         [-7.7590e-04,  2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.406721, steer=0.006483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.62448812832552
11.792398514226079 seconds in game passed.
Action: tensor([[[ 1.4675e-02,  7.6275e-01],
         [ 1.4604e-03,  4.2449e-01],
         [-1.7732e-04,  2.9746e-01],
         [-7.7590e-04,  2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.384541, steer=0.006563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.62448812832552
11.817398514598608 seconds in game passed.
Action: tensor([[[ 1.4675e-02,  7.6275e-01],
         [ 1.4604e-03,  4.2449e-01],
         [-1.7732e-04,  2.9746e-01],
         [-7.7590e-04,  2.2974e-01]]])
agent 0 action: VehicleControl(throttle=0.362829, steer=0.006643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.62448812832552
+++++++++++++: 1.3663336167938112
11.842398514971137 seconds in game passed.
At 11.842398514971137 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0101,  0.7912],
         [-0.0010,  0.4281],
         [-0.0028,  0.2975],
         [-0.0036,  0.2290]]])
agent 0 action: VehicleControl(throttle=0.341425, steer=0.002916, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3663336167938112
Current reward: 0.39782214475788946
Current mitigation activation: 0
#############################
Total reward: 26.02231027308341
11.867398515343666 seconds in game passed.
Action: tensor([[[ 0.0101,  0.7912],
         [-0.0010,  0.4281],
         [-0.0028,  0.2975],
         [-0.0036,  0.2290]]])
agent 0 action: VehicleControl(throttle=0.320485, steer=0.003591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.02231027308341
11.892398515716195 seconds in game passed.
Action: tensor([[[ 0.0101,  0.7912],
         [-0.0010,  0.4281],
         [-0.0028,  0.2975],
         [-0.0036,  0.2290]]])
agent 0 action: VehicleControl(throttle=0.300005, steer=0.003638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.02231027308341
11.917398516088724 seconds in game passed.
Action: tensor([[[ 0.0101,  0.7912],
         [-0.0010,  0.4281],
         [-0.0028,  0.2975],
         [-0.0036,  0.2290]]])
agent 0 action: VehicleControl(throttle=0.279985, steer=0.003684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.02231027308341
+++++++++++++: 1.318097498022874
11.942398516461253 seconds in game passed.
At 11.942398516461253 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2344e-02,  8.2643e-01],
         [-4.0025e-05,  4.4916e-01],
         [-2.5539e-03,  3.1181e-01],
         [-3.6269e-03,  2.3919e-01]]])
agent 0 action: VehicleControl(throttle=0.260224, steer=0.005423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.318097498022874
Current reward: 0.3962550730684907
Current mitigation activation: 0
#############################
Total reward: 26.4185653461519
11.967398516833782 seconds in game passed.
Action: tensor([[[ 1.2344e-02,  8.2643e-01],
         [-4.0025e-05,  4.4916e-01],
         [-2.5539e-03,  3.1181e-01],
         [-3.6269e-03,  2.3919e-01]]])
agent 0 action: VehicleControl(throttle=0.240919, steer=0.005222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.4185653461519
11.992398517206311 seconds in game passed.
Action: tensor([[[ 1.2344e-02,  8.2643e-01],
         [-4.0025e-05,  4.4916e-01],
         [-2.5539e-03,  3.1181e-01],
         [-3.6269e-03,  2.3919e-01]]])
agent 0 action: VehicleControl(throttle=0.222071, steer=0.005298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.4185653461519
12.01739851757884 seconds in game passed.
Action: tensor([[[ 1.2344e-02,  8.2643e-01],
         [-4.0025e-05,  4.4916e-01],
         [-2.5539e-03,  3.1181e-01],
         [-3.6269e-03,  2.3919e-01]]])
agent 0 action: VehicleControl(throttle=0.203677, steer=0.005374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.4185653461519
+++++++++++++: 1.2817337317516564
12.04239851795137 seconds in game passed.
At 12.04239851795137 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 9.6732e-04,  1.0000e+00],
         [-5.0247e-03,  1.0000e+00],
         [-8.5887e-03,  1.0000e+00],
         [-9.8737e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002181, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2817337317516564
Current reward: 0.392366883054621
Current mitigation activation: 1
#############################
Total reward: 26.81093222920652
12.067398518323898 seconds in game passed.
Action: tensor([[[ 9.6732e-04,  1.0000e+00],
         [-5.0247e-03,  1.0000e+00],
         [-8.5887e-03,  1.0000e+00],
         [-9.8737e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000914, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.81093222920652
12.092398518696427 seconds in game passed.
Action: tensor([[[ 9.6732e-04,  1.0000e+00],
         [-5.0247e-03,  1.0000e+00],
         [-8.5887e-03,  1.0000e+00],
         [-9.8737e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000908, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.81093222920652
12.117398519068956 seconds in game passed.
Action: tensor([[[ 9.6732e-04,  1.0000e+00],
         [-5.0247e-03,  1.0000e+00],
         [-8.5887e-03,  1.0000e+00],
         [-9.8737e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000901, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.81093222920652
+++++++++++++: 1.2585494238612984
12.142398519441485 seconds in game passed.
At 12.142398519441485 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0035,  1.0000],
         [-0.0080,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000866, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2585494238612984
Current reward: 0.38598180720673536
Current mitigation activation: 1
#############################
Total reward: 27.196914036413258
12.167398519814014 seconds in game passed.
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0035,  1.0000],
         [-0.0080,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000556, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.196914036413258
12.192398520186543 seconds in game passed.
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0035,  1.0000],
         [-0.0080,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000543, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.196914036413258
12.217398520559072 seconds in game passed.
Action: tensor([[[ 0.0023,  1.0000],
         [-0.0035,  1.0000],
         [-0.0080,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000530, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.196914036413258
+++++++++++++: 1.2771766344599627
12.242398520931602 seconds in game passed.
At 12.242398520931602 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0041,  1.0000],
         [-0.0182,  1.0000],
         [-0.0215,  1.0000],
         [-0.0199,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007622, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2771766344599627
Current reward: 0.37211287809894933
Current mitigation activation: 1
#############################
Total reward: 27.569026914512207
12.26739852130413 seconds in game passed.
Action: tensor([[[ 0.0041,  1.0000],
         [-0.0182,  1.0000],
         [-0.0215,  1.0000],
         [-0.0199,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006364, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.569026914512207
12.29239852167666 seconds in game passed.
Action: tensor([[[ 0.0041,  1.0000],
         [-0.0182,  1.0000],
         [-0.0215,  1.0000],
         [-0.0199,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006450, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.569026914512207
12.317398522049189 seconds in game passed.
Action: tensor([[[ 0.0041,  1.0000],
         [-0.0182,  1.0000],
         [-0.0215,  1.0000],
         [-0.0199,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006536, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.569026914512207
+++++++++++++: 1.3622510962137298
12.342398522421718 seconds in game passed.
At 12.342398522421718 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0067,  0.9400],
         [-0.0102,  0.5588],
         [-0.0122,  0.3656],
         [-0.0113,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002385, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3622510962137298
Current reward: 0.348899326282873
Current mitigation activation: 0
#############################
Total reward: 27.91792624079508
12.367398522794247 seconds in game passed.
Action: tensor([[[ 0.0067,  0.9400],
         [-0.0102,  0.5588],
         [-0.0122,  0.3656],
         [-0.0113,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003168, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.91792624079508
12.392398523166776 seconds in game passed.
Action: tensor([[[ 0.0067,  0.9400],
         [-0.0102,  0.5588],
         [-0.0122,  0.3656],
         [-0.0113,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003245, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.91792624079508
12.417398523539305 seconds in game passed.
Action: tensor([[[ 0.0067,  0.9400],
         [-0.0102,  0.5588],
         [-0.0122,  0.3656],
         [-0.0113,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003323, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.91792624079508
+++++++++++++: 1.499220415363626
12.442398523911834 seconds in game passed.
At 12.442398523911834 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0042,  0.9439],
         [-0.0147,  0.5762],
         [-0.0160,  0.3661],
         [-0.0149,  0.2684]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007789, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.499220415363626
Current reward: 0.3231507633007824
Current mitigation activation: 0
#############################
Total reward: 28.24107700409586
12.467398524284363 seconds in game passed.
Action: tensor([[[ 0.0042,  0.9439],
         [-0.0147,  0.5762],
         [-0.0160,  0.3661],
         [-0.0149,  0.2684]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007191, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.24107700409586
12.492398524656892 seconds in game passed.
Action: tensor([[[ 0.0042,  0.9439],
         [-0.0147,  0.5762],
         [-0.0160,  0.3661],
         [-0.0149,  0.2684]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007316, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.24107700409586
12.51739852502942 seconds in game passed.
Action: tensor([[[ 0.0042,  0.9439],
         [-0.0147,  0.5762],
         [-0.0160,  0.3661],
         [-0.0149,  0.2684]]])
agent 0 action: VehicleControl(throttle=0.004164, steer=-0.007441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.24107700409586
+++++++++++++: 1.6844842608371027
12.54239852540195 seconds in game passed.
At 12.54239852540195 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0087,  0.9463],
         [-0.0144,  0.6095],
         [-0.0160,  0.3783],
         [-0.0132,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004959, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6844842608371027
Current reward: 0.2983231307819269
Current mitigation activation: 0
#############################
Total reward: 28.539400134877788
12.567398525774479 seconds in game passed.
Action: tensor([[[ 0.0087,  0.9463],
         [-0.0144,  0.6095],
         [-0.0160,  0.3783],
         [-0.0132,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005502, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.539400134877788
12.592398526147008 seconds in game passed.
Action: tensor([[[ 0.0087,  0.9463],
         [-0.0144,  0.6095],
         [-0.0160,  0.3783],
         [-0.0132,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005613, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.539400134877788
12.617398526519537 seconds in game passed.
Action: tensor([[[ 0.0087,  0.9463],
         [-0.0144,  0.6095],
         [-0.0160,  0.3783],
         [-0.0132,  0.2734]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.539400134877788
+++++++++++++: 1.9209335556285534
12.642398526892066 seconds in game passed.
At 12.642398526892066 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0107,  0.9441],
         [-0.0102,  0.5878],
         [-0.0106,  0.3695],
         [-0.0076,  0.2680]]])
agent 0 action: VehicleControl(throttle=0.001339, steer=-0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9209335556285534
Current reward: 0.2758454348078285
Current mitigation activation: 0
#############################
Total reward: 28.815245569685615
12.667398527264595 seconds in game passed.
Action: tensor([[[ 0.0107,  0.9441],
         [-0.0102,  0.5878],
         [-0.0106,  0.3695],
         [-0.0076,  0.2680]]])
agent 0 action: VehicleControl(throttle=0.087657, steer=-0.002810, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.815245569685615
12.692398527637124 seconds in game passed.
Action: tensor([[[ 0.0107,  0.9441],
         [-0.0102,  0.5878],
         [-0.0106,  0.3695],
         [-0.0076,  0.2680]]])
agent 0 action: VehicleControl(throttle=0.140646, steer=-0.002905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.815245569685615
12.717398528009653 seconds in game passed.
Action: tensor([[[ 0.0107,  0.9441],
         [-0.0102,  0.5878],
         [-0.0106,  0.3695],
         [-0.0076,  0.2680]]])
agent 0 action: VehicleControl(throttle=0.171895, steer=-0.003000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.815245569685615
+++++++++++++: 2.1847417791065316
12.742398528382182 seconds in game passed.
At 12.742398528382182 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0036,  0.9429],
         [-0.0090,  0.5925],
         [-0.0074,  0.3770],
         [-0.0044,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.121259, steer=-0.008770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1847417791065316
Current reward: 0.25803825042254136
Current mitigation activation: 0
#############################
Total reward: 29.073283820108156
12.767398528754711 seconds in game passed.
Action: tensor([[[-0.0036,  0.9429],
         [-0.0090,  0.5925],
         [-0.0074,  0.3770],
         [-0.0044,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.146911, steer=-0.007995, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.073283820108156
12.79239852912724 seconds in game passed.
Action: tensor([[[-0.0036,  0.9429],
         [-0.0090,  0.5925],
         [-0.0074,  0.3770],
         [-0.0044,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.199325, steer=-0.008155, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.073283820108156
12.81739852949977 seconds in game passed.
Action: tensor([[[-0.0036,  0.9429],
         [-0.0090,  0.5925],
         [-0.0074,  0.3770],
         [-0.0044,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.244666, steer=-0.008315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.073283820108156
+++++++++++++: 2.338368434349948
12.842398529872298 seconds in game passed.
At 12.842398529872298 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0105, 0.9387],
         [0.0051, 0.5472],
         [0.0015, 0.3609],
         [0.0014, 0.2631]]])
agent 0 action: VehicleControl(throttle=0.816350, steer=0.008379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.338368434349948
Current reward: 0.25100115272593915
Current mitigation activation: 0
#############################
Total reward: 29.324284972834096
12.867398530244827 seconds in game passed.
Action: tensor([[[0.0105, 0.9387],
         [0.0051, 0.5472],
         [0.0015, 0.3609],
         [0.0014, 0.2631]]])
agent 0 action: VehicleControl(throttle=0.804912, steer=0.005658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.324284972834096
12.892398530617356 seconds in game passed.
Action: tensor([[[0.0105, 0.9387],
         [0.0051, 0.5472],
         [0.0015, 0.3609],
         [0.0014, 0.2631]]])
agent 0 action: VehicleControl(throttle=0.845934, steer=0.005711, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.324284972834096
12.917398530989885 seconds in game passed.
Action: tensor([[[0.0105, 0.9387],
         [0.0051, 0.5472],
         [0.0015, 0.3609],
         [0.0014, 0.2631]]])
agent 0 action: VehicleControl(throttle=0.881914, steer=0.005764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.324284972834096
+++++++++++++: 2.55320809281276
12.942398531362414 seconds in game passed.
At 12.942398531362414 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.3458e-03, 9.3084e-01],
         [4.7497e-03, 5.1833e-01],
         [1.2265e-03, 3.4298e-01],
         [8.5560e-04, 2.5022e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.55320809281276
Current reward: 0.24262533298090802
Current mitigation activation: 0
#############################
Total reward: 29.566910305815004
12.967398531734943 seconds in game passed.
Action: tensor([[[9.3458e-03, 9.3084e-01],
         [4.7497e-03, 5.1833e-01],
         [1.2265e-03, 3.4298e-01],
         [8.5560e-04, 2.5022e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.566910305815004
12.992398532107472 seconds in game passed.
Action: tensor([[[9.3458e-03, 9.3084e-01],
         [4.7497e-03, 5.1833e-01],
         [1.2265e-03, 3.4298e-01],
         [8.5560e-04, 2.5022e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.566910305815004
13.017398532480001 seconds in game passed.
Action: tensor([[[9.3458e-03, 9.3084e-01],
         [4.7497e-03, 5.1833e-01],
         [1.2265e-03, 3.4298e-01],
         [8.5560e-04, 2.5022e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.566910305815004
+++++++++++++: 2.6671452237618682
13.04239853285253 seconds in game passed.
At 13.04239853285253 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0043, 0.9164],
         [0.0039, 0.5017],
         [0.0018, 0.3372],
         [0.0020, 0.2492]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6671452237618682
Current reward: 0.24052400722981448
Current mitigation activation: 0
#############################
Total reward: 29.80743431304482
13.06739853322506 seconds in game passed.
Action: tensor([[[0.0043, 0.9164],
         [0.0039, 0.5017],
         [0.0018, 0.3372],
         [0.0020, 0.2492]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003010, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.80743431304482
13.092398533597589 seconds in game passed.
Action: tensor([[[0.0043, 0.9164],
         [0.0039, 0.5017],
         [0.0018, 0.3372],
         [0.0020, 0.2492]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.80743431304482
13.117398533970118 seconds in game passed.
Action: tensor([[[0.0043, 0.9164],
         [0.0039, 0.5017],
         [0.0018, 0.3372],
         [0.0020, 0.2492]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.80743431304482
+++++++++++++: 2.6287067535382977
13.142398534342647 seconds in game passed.
At 13.142398534342647 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.8342e-03, 9.0832e-01],
         [2.9666e-03, 4.9021e-01],
         [8.8613e-04, 3.2901e-01],
         [8.9920e-04, 2.4342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6287067535382977
Current reward: 0.2453845472645929
Current mitigation activation: 0
#############################
Total reward: 30.05281886030941
13.167398534715176 seconds in game passed.
Action: tensor([[[1.8342e-03, 9.0832e-01],
         [2.9666e-03, 4.9021e-01],
         [8.8613e-04, 3.2901e-01],
         [8.9920e-04, 2.4342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.05281886030941
13.192398535087705 seconds in game passed.
Action: tensor([[[1.8342e-03, 9.0832e-01],
         [2.9666e-03, 4.9021e-01],
         [8.8613e-04, 3.2901e-01],
         [8.9920e-04, 2.4342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.05281886030941
13.217398535460234 seconds in game passed.
Action: tensor([[[1.8342e-03, 9.0832e-01],
         [2.9666e-03, 4.9021e-01],
         [8.8613e-04, 3.2901e-01],
         [8.9920e-04, 2.4342e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.05281886030941
+++++++++++++: 2.512034512914553
13.242398535832763 seconds in game passed.
At 13.242398535832763 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.5994e-05,  8.8648e-01],
         [ 4.8746e-04,  4.7657e-01],
         [-4.4687e-04,  3.2537e-01],
         [ 3.2797e-04,  2.4421e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.512034512914553
Current reward: 0.25383065685421075
Current mitigation activation: 0
#############################
Total reward: 30.30664951716362
13.267398536205292 seconds in game passed.
Action: tensor([[[ 3.5994e-05,  8.8648e-01],
         [ 4.8746e-04,  4.7657e-01],
         [-4.4687e-04,  3.2537e-01],
         [ 3.2797e-04,  2.4421e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.30664951716362
13.29239853657782 seconds in game passed.
Action: tensor([[[ 3.5994e-05,  8.8648e-01],
         [ 4.8746e-04,  4.7657e-01],
         [-4.4687e-04,  3.2537e-01],
         [ 3.2797e-04,  2.4421e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.30664951716362
13.31739853695035 seconds in game passed.
Action: tensor([[[ 3.5994e-05,  8.8648e-01],
         [ 4.8746e-04,  4.7657e-01],
         [-4.4687e-04,  3.2537e-01],
         [ 3.2797e-04,  2.4421e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.30664951716362
+++++++++++++: 2.369867003703268
13.342398537322879 seconds in game passed.
At 13.342398537322879 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.7983e-03,  8.8645e-01],
         [-1.7942e-04,  4.9012e-01],
         [-1.0553e-03,  3.3985e-01],
         [-4.1495e-04,  2.5778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.369867003703268
Current reward: 0.2637903266733701
Current mitigation activation: 0
#############################
Total reward: 30.57043984383699
13.367398537695408 seconds in game passed.
Action: tensor([[[-4.7983e-03,  8.8645e-01],
         [-1.7942e-04,  4.9012e-01],
         [-1.0553e-03,  3.3985e-01],
         [-4.1495e-04,  2.5778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.57043984383699
13.392398538067937 seconds in game passed.
Action: tensor([[[-4.7983e-03,  8.8645e-01],
         [-1.7942e-04,  4.9012e-01],
         [-1.0553e-03,  3.3985e-01],
         [-4.1495e-04,  2.5778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.57043984383699
13.417398538440466 seconds in game passed.
Action: tensor([[[-4.7983e-03,  8.8645e-01],
         [-1.7942e-04,  4.9012e-01],
         [-1.0553e-03,  3.3985e-01],
         [-4.1495e-04,  2.5778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001954, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.57043984383699
+++++++++++++: 2.225490770840776
13.442398538812995 seconds in game passed.
At 13.442398538812995 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0063,  0.8921],
         [-0.0026,  0.5006],
         [-0.0032,  0.3556],
         [-0.0020,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.225490770840776
Current reward: 0.27425293457151806
Current mitigation activation: 0
#############################
Total reward: 30.844692778408508
13.467398539185524 seconds in game passed.
Action: tensor([[[-0.0063,  0.8921],
         [-0.0026,  0.5006],
         [-0.0032,  0.3556],
         [-0.0020,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.844692778408508
13.492398539558053 seconds in game passed.
Action: tensor([[[-0.0063,  0.8921],
         [-0.0026,  0.5006],
         [-0.0032,  0.3556],
         [-0.0020,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.844692778408508
13.517398539930582 seconds in game passed.
Action: tensor([[[-0.0063,  0.8921],
         [-0.0026,  0.5006],
         [-0.0032,  0.3556],
         [-0.0020,  0.2768]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.844692778408508
+++++++++++++: 2.087638126438974
13.542398540303111 seconds in game passed.
At 13.542398540303111 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2243e-03,  8.6766e-01],
         [-2.2236e-04,  4.9597e-01],
         [-2.0956e-03,  3.5725e-01],
         [-1.7848e-03,  2.8029e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.087638126438974
Current reward: 0.28471625793423977
Current mitigation activation: 0
#############################
Total reward: 31.129409036342746
13.56739854067564 seconds in game passed.
Action: tensor([[[ 2.2243e-03,  8.6766e-01],
         [-2.2236e-04,  4.9597e-01],
         [-2.0956e-03,  3.5725e-01],
         [-1.7848e-03,  2.8029e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.129409036342746
13.59239854104817 seconds in game passed.
Action: tensor([[[ 2.2243e-03,  8.6766e-01],
         [-2.2236e-04,  4.9597e-01],
         [-2.0956e-03,  3.5725e-01],
         [-1.7848e-03,  2.8029e-01]]])
agent 0 action: VehicleControl(throttle=0.896517, steer=0.000879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.129409036342746
13.617398541420698 seconds in game passed.
Action: tensor([[[ 2.2243e-03,  8.6766e-01],
         [-2.2236e-04,  4.9597e-01],
         [-2.0956e-03,  3.5725e-01],
         [-1.7848e-03,  2.8029e-01]]])
agent 0 action: VehicleControl(throttle=0.864114, steer=0.000953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.129409036342746
+++++++++++++: 1.95887793198584
13.642398541793227 seconds in game passed.
At 13.642398541793227 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0044,  0.8807],
         [-0.0016,  0.4959],
         [-0.0024,  0.3512],
         [-0.0018,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.95887793198584
Current reward: 0.29492476363488074
Current mitigation activation: 0
#############################
Total reward: 31.424333799977628
13.667398542165756 seconds in game passed.
Action: tensor([[[-0.0044,  0.8807],
         [-0.0016,  0.4959],
         [-0.0024,  0.3512],
         [-0.0018,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.859916, steer=-0.002279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.424333799977628
13.692398542538285 seconds in game passed.
Action: tensor([[[-0.0044,  0.8807],
         [-0.0016,  0.4959],
         [-0.0024,  0.3512],
         [-0.0018,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.825925, steer=-0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.424333799977628
13.717398542910814 seconds in game passed.
Action: tensor([[[-0.0044,  0.8807],
         [-0.0016,  0.4959],
         [-0.0024,  0.3512],
         [-0.0018,  0.2724]]])
agent 0 action: VehicleControl(throttle=0.791180, steer=-0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.424333799977628
+++++++++++++: 1.8397109683193638
13.742398543283343 seconds in game passed.
At 13.742398543283343 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.5244e-03,  9.1448e-01],
         [-3.6093e-04,  5.0159e-01],
         [-2.2373e-03,  3.4075e-01],
         [-1.8355e-03,  2.5515e-01]]])
agent 0 action: VehicleControl(throttle=0.831176, steer=-0.001292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8397109683193638
Current reward: 0.30469790772843186
Current mitigation activation: 0
#############################
Total reward: 31.72903170770606
13.767398543655872 seconds in game passed.
Action: tensor([[[-4.5244e-03,  9.1448e-01],
         [-3.6093e-04,  5.0159e-01],
         [-2.2373e-03,  3.4075e-01],
         [-1.8355e-03,  2.5515e-01]]])
agent 0 action: VehicleControl(throttle=0.790318, steer=-0.001384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.72903170770606
13.792398544028401 seconds in game passed.
Action: tensor([[[-4.5244e-03,  9.1448e-01],
         [-3.6093e-04,  5.0159e-01],
         [-2.2373e-03,  3.4075e-01],
         [-1.8355e-03,  2.5515e-01]]])
agent 0 action: VehicleControl(throttle=0.757225, steer=-0.001321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.72903170770606
13.81739854440093 seconds in game passed.
Action: tensor([[[-4.5244e-03,  9.1448e-01],
         [-3.6093e-04,  5.0159e-01],
         [-2.2373e-03,  3.4075e-01],
         [-1.8355e-03,  2.5515e-01]]])
agent 0 action: VehicleControl(throttle=0.723797, steer=-0.001257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.72903170770606
+++++++++++++: 1.7324775524267517
13.84239854477346 seconds in game passed.
At 13.84239854477346 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0046,  0.9249],
         [-0.0034,  0.4997],
         [-0.0064,  0.3337],
         [-0.0057,  0.2469]]])
agent 0 action: VehicleControl(throttle=0.762730, steer=0.000104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7324775524267517
Current reward: 0.3136333672449378
Current mitigation activation: 0
#############################
Total reward: 32.042665074950996
13.867398545145988 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9249],
         [-0.0034,  0.4997],
         [-0.0064,  0.3337],
         [-0.0057,  0.2469]]])
agent 0 action: VehicleControl(throttle=0.716657, steer=-0.000234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.042665074950996
13.892398545518517 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9249],
         [-0.0034,  0.4997],
         [-0.0064,  0.3337],
         [-0.0057,  0.2469]]])
agent 0 action: VehicleControl(throttle=0.679378, steer=-0.000328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.042665074950996
13.917398545891047 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9249],
         [-0.0034,  0.4997],
         [-0.0064,  0.3337],
         [-0.0057,  0.2469]]])
agent 0 action: VehicleControl(throttle=0.642372, steer=-0.000423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.042665074950996
+++++++++++++: 1.6395735594343877
13.942398546263576 seconds in game passed.
At 13.942398546263576 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.4013e-03,  9.3437e-01],
         [-9.0537e-04,  5.1614e-01],
         [-2.9575e-03,  3.3952e-01],
         [-1.1475e-03,  2.4959e-01]]])
agent 0 action: VehicleControl(throttle=0.394982, steer=0.002636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6395735594343877
Current reward: 0.3212305782768199
Current mitigation activation: 0
#############################
Total reward: 32.363895653227814
13.967398546636105 seconds in game passed.
Action: tensor([[[ 7.4013e-03,  9.3437e-01],
         [-9.0537e-04,  5.1614e-01],
         [-2.9575e-03,  3.3952e-01],
         [-1.1475e-03,  2.4959e-01]]])
agent 0 action: VehicleControl(throttle=0.386816, steer=0.002064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.363895653227814
13.992398547008634 seconds in game passed.
Action: tensor([[[ 7.4013e-03,  9.3437e-01],
         [-9.0537e-04,  5.1614e-01],
         [-2.9575e-03,  3.3952e-01],
         [-1.1475e-03,  2.4959e-01]]])
agent 0 action: VehicleControl(throttle=0.374014, steer=0.002010, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.363895653227814
14.017398547381163 seconds in game passed.
Action: tensor([[[ 7.4013e-03,  9.3437e-01],
         [-9.0537e-04,  5.1614e-01],
         [-2.9575e-03,  3.3952e-01],
         [-1.1475e-03,  2.4959e-01]]])
agent 0 action: VehicleControl(throttle=0.359244, steer=0.001957, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.363895653227814
+++++++++++++: 1.5631820631503464
14.042398547753692 seconds in game passed.
At 14.042398547753692 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0063,  0.9394],
         [-0.0019,  0.5354],
         [-0.0035,  0.3513],
         [-0.0014,  0.2583]]])
agent 0 action: VehicleControl(throttle=0.342561, steer=0.000812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5631820631503464
Current reward: 0.3269335180335287
Current mitigation activation: 0
#############################
Total reward: 32.69082917126134
14.06739854812622 seconds in game passed.
Action: tensor([[[ 0.0063,  0.9394],
         [-0.0019,  0.5354],
         [-0.0035,  0.3513],
         [-0.0014,  0.2583]]])
agent 0 action: VehicleControl(throttle=0.326060, steer=0.000960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.69082917126134
14.09239854849875 seconds in game passed.
Action: tensor([[[ 0.0063,  0.9394],
         [-0.0019,  0.5354],
         [-0.0035,  0.3513],
         [-0.0014,  0.2583]]])
agent 0 action: VehicleControl(throttle=0.309793, steer=0.000924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.69082917126134
14.117398548871279 seconds in game passed.
Action: tensor([[[ 0.0063,  0.9394],
         [-0.0019,  0.5354],
         [-0.0035,  0.3513],
         [-0.0014,  0.2583]]])
agent 0 action: VehicleControl(throttle=0.293802, steer=0.000888, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.69082917126134
+++++++++++++: 1.5147030898016143
14.142398549243808 seconds in game passed.
At 14.142398549243808 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0051,  0.9403],
         [-0.0038,  0.5467],
         [-0.0057,  0.3538],
         [-0.0040,  0.2572]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001107, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5147030898016143
Current reward: 0.3289972235212716
Current mitigation activation: 0
#############################
Total reward: 33.01982639478261
14.167398549616337 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9403],
         [-0.0038,  0.5467],
         [-0.0057,  0.3538],
         [-0.0040,  0.2572]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000819, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.01982639478261
14.192398549988866 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9403],
         [-0.0038,  0.5467],
         [-0.0057,  0.3538],
         [-0.0040,  0.2572]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000857, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.01982639478261
14.217398550361395 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9403],
         [-0.0038,  0.5467],
         [-0.0057,  0.3538],
         [-0.0040,  0.2572]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000895, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.01982639478261
+++++++++++++: 1.4978524798819774
14.242398550733924 seconds in game passed.
At 14.242398550733924 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.4246e-04,  9.4209e-01],
         [-9.8095e-04,  5.5963e-01],
         [-3.1115e-03,  3.6298e-01],
         [-2.4806e-03,  2.6540e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001182, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4978524798819774
Current reward: 0.326784110813172
Current mitigation activation: 0
#############################
Total reward: 33.346610505595784
14.267398551106453 seconds in game passed.
Action: tensor([[[-4.4246e-04,  9.4209e-01],
         [-9.8095e-04,  5.5963e-01],
         [-3.1115e-03,  3.6298e-01],
         [-2.4806e-03,  2.6540e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001150, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.346610505595784
14.292398551478982 seconds in game passed.
Action: tensor([[[-4.4246e-04,  9.4209e-01],
         [-9.8095e-04,  5.5963e-01],
         [-3.1115e-03,  3.6298e-01],
         [-2.4806e-03,  2.6540e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001164, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.346610505595784
14.317398551851511 seconds in game passed.
Action: tensor([[[-4.4246e-04,  9.4209e-01],
         [-9.8095e-04,  5.5963e-01],
         [-3.1115e-03,  3.6298e-01],
         [-2.4806e-03,  2.6540e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001177, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.346610505595784
+++++++++++++: 1.5437021485579396
14.34239855222404 seconds in game passed.
At 14.34239855222404 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.4740e-03,  9.4352e-01],
         [ 3.4674e-04,  5.7084e-01],
         [-4.2444e-04,  3.6637e-01],
         [-1.0237e-04,  2.6518e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002447, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5437021485579396
Current reward: 0.31683015306616524
Current mitigation activation: 0
#############################
Total reward: 33.66344065866195
14.367398552596569 seconds in game passed.
Action: tensor([[[-5.4740e-03,  9.4352e-01],
         [ 3.4674e-04,  5.7084e-01],
         [-4.2444e-04,  3.6637e-01],
         [-1.0237e-04,  2.6518e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002237, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.66344065866195
14.392398552969098 seconds in game passed.
Action: tensor([[[-5.4740e-03,  9.4352e-01],
         [ 3.4674e-04,  5.7084e-01],
         [-4.2444e-04,  3.6637e-01],
         [-1.0237e-04,  2.6518e-01]]])
agent 0 action: VehicleControl(throttle=0.123536, steer=-0.002237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.66344065866195
14.417398553341627 seconds in game passed.
Action: tensor([[[-5.4740e-03,  9.4352e-01],
         [ 3.4674e-04,  5.7084e-01],
         [-4.2444e-04,  3.6637e-01],
         [-1.0237e-04,  2.6518e-01]]])
agent 0 action: VehicleControl(throttle=0.112032, steer=-0.002238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.66344065866195
+++++++++++++: 1.6725588115383887
14.442398553714156 seconds in game passed.
At 14.442398553714156 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1480e-02,  9.4392e-01],
         [-4.6638e-04,  6.1107e-01],
         [-9.8214e-04,  4.0754e-01],
         [-1.6585e-03,  3.0761e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005785, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6725588115383887
Current reward: 0.2992861706484847
Current mitigation activation: 0
#############################
Total reward: 33.962726829310434
14.467398554086685 seconds in game passed.
Action: tensor([[[-1.1480e-02,  9.4392e-01],
         [-4.6638e-04,  6.1107e-01],
         [-9.8214e-04,  4.0754e-01],
         [-1.6585e-03,  3.0761e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005208, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.962726829310434
14.492398554459214 seconds in game passed.
Action: tensor([[[-1.1480e-02,  9.4392e-01],
         [-4.6638e-04,  6.1107e-01],
         [-9.8214e-04,  4.0754e-01],
         [-1.6585e-03,  3.0761e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005219, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.962726829310434
14.517398554831743 seconds in game passed.
Action: tensor([[[-1.1480e-02,  9.4392e-01],
         [-4.6638e-04,  6.1107e-01],
         [-9.8214e-04,  4.0754e-01],
         [-1.6585e-03,  3.0761e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005231, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.962726829310434
+++++++++++++: 1.8582340950180616
14.542398555204272 seconds in game passed.
At 14.542398555204272 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0211,  0.9444],
         [-0.0056,  0.6109],
         [-0.0040,  0.3955],
         [-0.0034,  0.2876]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013609, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8582340950180616
Current reward: 0.2805585370135318
Current mitigation activation: 0
#############################
Total reward: 34.24328536632397
14.567398555576801 seconds in game passed.
Action: tensor([[[-0.0211,  0.9444],
         [-0.0056,  0.6109],
         [-0.0040,  0.3955],
         [-0.0034,  0.2876]]])
agent 0 action: VehicleControl(throttle=0.063272, steer=-0.012392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.24328536632397
14.59239855594933 seconds in game passed.
Action: tensor([[[-0.0211,  0.9444],
         [-0.0056,  0.6109],
         [-0.0040,  0.3955],
         [-0.0034,  0.2876]]])
agent 0 action: VehicleControl(throttle=0.057173, steer=-0.012546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.24328536632397
14.61739855632186 seconds in game passed.
Action: tensor([[[-0.0211,  0.9444],
         [-0.0056,  0.6109],
         [-0.0040,  0.3955],
         [-0.0034,  0.2876]]])
agent 0 action: VehicleControl(throttle=0.051549, steer=-0.012699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.24328536632397
+++++++++++++: 2.1297552120954726
14.642398556694388 seconds in game passed.
At 14.642398556694388 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0185,  0.9462],
         [-0.0054,  0.6040],
         [-0.0038,  0.3764],
         [-0.0025,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.111383, steer=-0.011364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1297552120954726
Current reward: 0.2607650913852602
Current mitigation activation: 0
#############################
Total reward: 34.504050457709226
14.667398557066917 seconds in game passed.
Action: tensor([[[-0.0185,  0.9462],
         [-0.0054,  0.6040],
         [-0.0038,  0.3764],
         [-0.0025,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.168156, steer=-0.011701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.504050457709226
14.692398557439446 seconds in game passed.
Action: tensor([[[-0.0185,  0.9462],
         [-0.0054,  0.6040],
         [-0.0038,  0.3764],
         [-0.0025,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.214070, steer=-0.011800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.504050457709226
14.717398557811975 seconds in game passed.
Action: tensor([[[-0.0185,  0.9462],
         [-0.0054,  0.6040],
         [-0.0038,  0.3764],
         [-0.0025,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.254252, steer=-0.011898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.504050457709226
+++++++++++++: 2.433879932853194
14.742398558184505 seconds in game passed.
At 14.742398558184505 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0156,  0.9477],
         [-0.0042,  0.6087],
         [-0.0029,  0.3747],
         [-0.0015,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.246810, steer=-0.009865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.433879932853194
Current reward: 0.2451527456561152
Current mitigation activation: 0
#############################
Total reward: 34.74920320336534
14.767398558557034 seconds in game passed.
Action: tensor([[[-0.0156,  0.9477],
         [-0.0042,  0.6087],
         [-0.0029,  0.3747],
         [-0.0015,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.284408, steer=-0.010304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.74920320336534
14.792398558929563 seconds in game passed.
Action: tensor([[[-0.0156,  0.9477],
         [-0.0042,  0.6087],
         [-0.0029,  0.3747],
         [-0.0015,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.314369, steer=-0.010390, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.74920320336534
14.817398559302092 seconds in game passed.
Action: tensor([[[-0.0156,  0.9477],
         [-0.0042,  0.6087],
         [-0.0029,  0.3747],
         [-0.0015,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.341701, steer=-0.010476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.74920320336534
+++++++++++++: 2.67292667140738
14.84239855967462 seconds in game passed.
At 14.84239855967462 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.4547e-02,  9.4614e-01],
         [-1.9740e-03,  5.8289e-01],
         [-5.3356e-04,  3.6312e-01],
         [ 7.4991e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.644239, steer=-0.008205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.67292667140738
Current reward: 0.23689703896091224
Current mitigation activation: 0
#############################
Total reward: 34.98610024232625
14.86739856004715 seconds in game passed.
Action: tensor([[[-1.4547e-02,  9.4614e-01],
         [-1.9740e-03,  5.8289e-01],
         [-5.3356e-04,  3.6312e-01],
         [ 7.4991e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.638944, steer=-0.008673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.98610024232625
14.892398560419679 seconds in game passed.
Action: tensor([[[-1.4547e-02,  9.4614e-01],
         [-1.9740e-03,  5.8289e-01],
         [-5.3356e-04,  3.6312e-01],
         [ 7.4991e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.660226, steer=-0.008749, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.98610024232625
14.917398560792208 seconds in game passed.
Action: tensor([[[-1.4547e-02,  9.4614e-01],
         [-1.9740e-03,  5.8289e-01],
         [-5.3356e-04,  3.6312e-01],
         [ 7.4991e-04,  2.5993e-01]]])
agent 0 action: VehicleControl(throttle=0.677122, steer=-0.008826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.98610024232625
+++++++++++++: 2.854384658124808
14.942398561164737 seconds in game passed.
At 14.942398561164737 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.5970e-03,  9.3918e-01],
         [ 9.2740e-04,  5.2832e-01],
         [-9.1836e-05,  3.4053e-01],
         [ 3.1672e-04,  2.4618e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.854384658124808
Current reward: 0.2329565652022753
Current mitigation activation: 0
#############################
Total reward: 35.219056807528524
14.967398561537266 seconds in game passed.
Action: tensor([[[-7.5970e-03,  9.3918e-01],
         [ 9.2740e-04,  5.2832e-01],
         [-9.1836e-05,  3.4053e-01],
         [ 3.1672e-04,  2.4618e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.219056807528524
14.992398561909795 seconds in game passed.
Action: tensor([[[-7.5970e-03,  9.3918e-01],
         [ 9.2740e-04,  5.2832e-01],
         [-9.1836e-05,  3.4053e-01],
         [ 3.1672e-04,  2.4618e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.219056807528524
15.017398562282324 seconds in game passed.
Action: tensor([[[-7.5970e-03,  9.3918e-01],
         [ 9.2740e-04,  5.2832e-01],
         [-9.1836e-05,  3.4053e-01],
         [ 3.1672e-04,  2.4618e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.219056807528524
+++++++++++++: 2.9218051151589695
15.042398562654853 seconds in game passed.
At 15.042398562654853 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.5089e-03,  9.1609e-01],
         [ 1.5926e-03,  4.8270e-01],
         [ 8.8170e-05,  3.1661e-01],
         [ 3.6828e-04,  2.3001e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9218051151589695
Current reward: 0.2340561595788442
Current mitigation activation: 0
#############################
Total reward: 35.453112967107366
15.067398563027382 seconds in game passed.
Action: tensor([[[-2.5089e-03,  9.1609e-01],
         [ 1.5926e-03,  4.8270e-01],
         [ 8.8170e-05,  3.1661e-01],
         [ 3.6828e-04,  2.3001e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.453112967107366
15.092398563399911 seconds in game passed.
Action: tensor([[[-2.5089e-03,  9.1609e-01],
         [ 1.5926e-03,  4.8270e-01],
         [ 8.8170e-05,  3.1661e-01],
         [ 3.6828e-04,  2.3001e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.453112967107366
15.11739856377244 seconds in game passed.
Action: tensor([[[-2.5089e-03,  9.1609e-01],
         [ 1.5926e-03,  4.8270e-01],
         [ 8.8170e-05,  3.1661e-01],
         [ 3.6828e-04,  2.3001e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002192, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.453112967107366
+++++++++++++: 2.8498904380091945
15.142398564144969 seconds in game passed.
At 15.142398564144969 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.9673e-03,  8.9055e-01],
         [ 1.3849e-03,  4.6654e-01],
         [-2.5728e-04,  3.1221e-01],
         [-3.9282e-04,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8498904380091945
Current reward: 0.2404049370566685
Current mitigation activation: 0
#############################
Total reward: 35.69351790416403
15.167398564517498 seconds in game passed.
Action: tensor([[[-1.9673e-03,  8.9055e-01],
         [ 1.3849e-03,  4.6654e-01],
         [-2.5728e-04,  3.1221e-01],
         [-3.9282e-04,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.69351790416403
15.192398564890027 seconds in game passed.
Action: tensor([[[-1.9673e-03,  8.9055e-01],
         [ 1.3849e-03,  4.6654e-01],
         [-2.5728e-04,  3.1221e-01],
         [-3.9282e-04,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002110, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.69351790416403
15.217398565262556 seconds in game passed.
Action: tensor([[[-1.9673e-03,  8.9055e-01],
         [ 1.3849e-03,  4.6654e-01],
         [-2.5728e-04,  3.1221e-01],
         [-3.9282e-04,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.69351790416403
+++++++++++++: 2.7046717662086355
15.242398565635085 seconds in game passed.
At 15.242398565635085 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.3693e-03,  8.8790e-01],
         [ 2.4469e-03,  4.6662e-01],
         [ 2.0304e-04,  3.1118e-01],
         [-1.7587e-04,  2.2821e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7046717662086355
Current reward: 0.24976197159190025
Current mitigation activation: 0
#############################
Total reward: 35.943279875755934
15.267398566007614 seconds in game passed.
Action: tensor([[[ 5.3693e-03,  8.8790e-01],
         [ 2.4469e-03,  4.6662e-01],
         [ 2.0304e-04,  3.1118e-01],
         [-1.7587e-04,  2.2821e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.943279875755934
15.292398566380143 seconds in game passed.
Action: tensor([[[ 5.3693e-03,  8.8790e-01],
         [ 2.4469e-03,  4.6662e-01],
         [ 2.0304e-04,  3.1118e-01],
         [-1.7587e-04,  2.2821e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001182, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.943279875755934
15.317398566752672 seconds in game passed.
Action: tensor([[[ 5.3693e-03,  8.8790e-01],
         [ 2.4469e-03,  4.6662e-01],
         [ 2.0304e-04,  3.1118e-01],
         [-1.7587e-04,  2.2821e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.943279875755934
+++++++++++++: 2.5803820663531307
15.342398567125201 seconds in game passed.
At 15.342398567125201 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4787e-02,  8.7468e-01],
         [ 2.6356e-03,  4.6733e-01],
         [-7.5638e-05,  3.1203e-01],
         [-2.3179e-04,  2.2773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5803820663531307
Current reward: 0.25836433111412943
Current mitigation activation: 0
#############################
Total reward: 36.201644206870064
15.36739856749773 seconds in game passed.
Action: tensor([[[ 1.4787e-02,  8.7468e-01],
         [ 2.6356e-03,  4.6733e-01],
         [-7.5638e-05,  3.1203e-01],
         [-2.3179e-04,  2.2773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.201644206870064
15.39239856787026 seconds in game passed.
Action: tensor([[[ 1.4787e-02,  8.7468e-01],
         [ 2.6356e-03,  4.6733e-01],
         [-7.5638e-05,  3.1203e-01],
         [-2.3179e-04,  2.2773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.201644206870064
15.417398568242788 seconds in game passed.
Action: tensor([[[ 1.4787e-02,  8.7468e-01],
         [ 2.6356e-03,  4.6733e-01],
         [-7.5638e-05,  3.1203e-01],
         [-2.3179e-04,  2.2773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.201644206870064
+++++++++++++: 2.5970251311796018
15.442398568615317 seconds in game passed.
At 15.442398568615317 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0135, 0.8880],
         [0.0036, 0.4764],
         [0.0011, 0.3185],
         [0.0009, 0.2324]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5970251311796018
Current reward: 0.2599756144517926
Current mitigation activation: 0
#############################
Total reward: 36.461619821321854
15.467398568987846 seconds in game passed.
Action: tensor([[[0.0135, 0.8880],
         [0.0036, 0.4764],
         [0.0011, 0.3185],
         [0.0009, 0.2324]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.461619821321854
15.492398569360375 seconds in game passed.
Action: tensor([[[0.0135, 0.8880],
         [0.0036, 0.4764],
         [0.0011, 0.3185],
         [0.0009, 0.2324]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.461619821321854
15.517398569732904 seconds in game passed.
Action: tensor([[[0.0135, 0.8880],
         [0.0036, 0.4764],
         [0.0011, 0.3185],
         [0.0009, 0.2324]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.461619821321854
+++++++++++++: 2.625386337238527
15.542398570105433 seconds in game passed.
At 15.542398570105433 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0144, 0.8787],
         [0.0033, 0.4703],
         [0.0014, 0.3155],
         [0.0014, 0.2313]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.625386337238527
Current reward: 0.260993504058633
Current mitigation activation: 0
#############################
Total reward: 36.722613325380486
15.567398570477962 seconds in game passed.
Action: tensor([[[0.0144, 0.8787],
         [0.0033, 0.4703],
         [0.0014, 0.3155],
         [0.0014, 0.2313]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.722613325380486
15.592398570850492 seconds in game passed.
Action: tensor([[[0.0144, 0.8787],
         [0.0033, 0.4703],
         [0.0014, 0.3155],
         [0.0014, 0.2313]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.722613325380486
15.61739857122302 seconds in game passed.
Action: tensor([[[0.0144, 0.8787],
         [0.0033, 0.4703],
         [0.0014, 0.3155],
         [0.0014, 0.2313]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.722613325380486
+++++++++++++: 2.653832862325545
15.64239857159555 seconds in game passed.
At 15.64239857159555 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0150, 0.8777],
         [0.0039, 0.4662],
         [0.0024, 0.3126],
         [0.0025, 0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.653832862325545
Current reward: 0.26202350161113863
Current mitigation activation: 0
#############################
Total reward: 36.984636826991625
15.667398571968079 seconds in game passed.
Action: tensor([[[0.0150, 0.8777],
         [0.0039, 0.4662],
         [0.0024, 0.3126],
         [0.0025, 0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.984636826991625
15.692398572340608 seconds in game passed.
Action: tensor([[[0.0150, 0.8777],
         [0.0039, 0.4662],
         [0.0024, 0.3126],
         [0.0025, 0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.984636826991625
15.717398572713137 seconds in game passed.
Action: tensor([[[0.0150, 0.8777],
         [0.0039, 0.4662],
         [0.0024, 0.3126],
         [0.0025, 0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.984636826991625
+++++++++++++: 2.682500675346207
15.742398573085666 seconds in game passed.
At 15.742398573085666 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0109, 0.8618],
         [0.0031, 0.4550],
         [0.0017, 0.3059],
         [0.0017, 0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.682500675346207
Current reward: 0.2630600344269841
Current mitigation activation: 0
#############################
Total reward: 37.24769686141861
15.767398573458195 seconds in game passed.
Action: tensor([[[0.0109, 0.8618],
         [0.0031, 0.4550],
         [0.0017, 0.3059],
         [0.0017, 0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.24769686141861
15.792398573830724 seconds in game passed.
Action: tensor([[[0.0109, 0.8618],
         [0.0031, 0.4550],
         [0.0017, 0.3059],
         [0.0017, 0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.24769686141861
15.817398574203253 seconds in game passed.
Action: tensor([[[0.0109, 0.8618],
         [0.0031, 0.4550],
         [0.0017, 0.3059],
         [0.0017, 0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.24769686141861
+++++++++++++: 2.6725266236078613
15.842398574575782 seconds in game passed.
At 15.842398574575782 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.2880e-03,  8.4844e-01],
         [ 6.0038e-04,  4.4984e-01],
         [-9.6887e-04,  3.0418e-01],
         [-1.2924e-03,  2.2602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6725266236078613
Current reward: 0.2659076185460059
Current mitigation activation: 0
#############################
Total reward: 37.51360447996462
15.86739857494831 seconds in game passed.
Action: tensor([[[ 8.2880e-03,  8.4844e-01],
         [ 6.0038e-04,  4.4984e-01],
         [-9.6887e-04,  3.0418e-01],
         [-1.2924e-03,  2.2602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.51360447996462
15.89239857532084 seconds in game passed.
Action: tensor([[[ 8.2880e-03,  8.4844e-01],
         [ 6.0038e-04,  4.4984e-01],
         [-9.6887e-04,  3.0418e-01],
         [-1.2924e-03,  2.2602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.51360447996462
15.917398575693369 seconds in game passed.
Action: tensor([[[ 8.2880e-03,  8.4844e-01],
         [ 6.0038e-04,  4.4984e-01],
         [-9.6887e-04,  3.0418e-01],
         [-1.2924e-03,  2.2602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.51360447996462
+++++++++++++: 2.4799051626862507
15.942398576065898 seconds in game passed.
At 15.942398576065898 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6551e-03,  8.3860e-01],
         [-8.5175e-05,  4.4747e-01],
         [-1.6746e-03,  3.0173e-01],
         [-1.8747e-03,  2.2376e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4799051626862507
Current reward: 0.2780060705887512
Current mitigation activation: 0
#############################
Total reward: 37.79161055055337
15.967398576438427 seconds in game passed.
Action: tensor([[[ 7.6551e-03,  8.3860e-01],
         [-8.5175e-05,  4.4747e-01],
         [-1.6746e-03,  3.0173e-01],
         [-1.8747e-03,  2.2376e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004553, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.79161055055337
15.992398576810956 seconds in game passed.
Action: tensor([[[ 7.6551e-03,  8.3860e-01],
         [-8.5175e-05,  4.4747e-01],
         [-1.6746e-03,  3.0173e-01],
         [-1.8747e-03,  2.2376e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.79161055055337
16.017398577183485 seconds in game passed.
Action: tensor([[[ 7.6551e-03,  8.3860e-01],
         [-8.5175e-05,  4.4747e-01],
         [-1.6746e-03,  3.0173e-01],
         [-1.8747e-03,  2.2376e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004669, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.79161055055337
+++++++++++++: 2.304635261217222
16.042398577556014 seconds in game passed.
At 16.042398577556014 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.8887e-03,  8.5537e-01],
         [-4.4839e-04,  4.4867e-01],
         [-2.6245e-03,  3.0002e-01],
         [-3.4692e-03,  2.2147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.304635261217222
Current reward: 0.2898940890264825
Current mitigation activation: 0
#############################
Total reward: 38.081504639579855
16.067398577928543 seconds in game passed.
Action: tensor([[[ 7.8887e-03,  8.5537e-01],
         [-4.4839e-04,  4.4867e-01],
         [-2.6245e-03,  3.0002e-01],
         [-3.4692e-03,  2.2147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.081504639579855
16.092398578301072 seconds in game passed.
Action: tensor([[[ 7.8887e-03,  8.5537e-01],
         [-4.4839e-04,  4.4867e-01],
         [-2.6245e-03,  3.0002e-01],
         [-3.4692e-03,  2.2147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.081504639579855
16.1173985786736 seconds in game passed.
Action: tensor([[[ 7.8887e-03,  8.5537e-01],
         [-4.4839e-04,  4.4867e-01],
         [-2.6245e-03,  3.0002e-01],
         [-3.4692e-03,  2.2147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.081504639579855
+++++++++++++: 2.1565080181403355
16.14239857904613 seconds in game passed.
At 16.14239857904613 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0083,  0.8241],
         [-0.0010,  0.4359],
         [-0.0030,  0.2926],
         [-0.0034,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1565080181403355
Current reward: 0.30063345269955155
Current mitigation activation: 0
#############################
Total reward: 38.382138092279405
16.16739857941866 seconds in game passed.
Action: tensor([[[ 0.0083,  0.8241],
         [-0.0010,  0.4359],
         [-0.0030,  0.2926],
         [-0.0034,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.382138092279405
16.19239857979119 seconds in game passed.
Action: tensor([[[ 0.0083,  0.8241],
         [-0.0010,  0.4359],
         [-0.0030,  0.2926],
         [-0.0034,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.382138092279405
16.217398580163717 seconds in game passed.
Action: tensor([[[ 0.0083,  0.8241],
         [-0.0010,  0.4359],
         [-0.0030,  0.2926],
         [-0.0034,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.382138092279405
+++++++++++++: 2.0248071503615974
16.242398580536246 seconds in game passed.
At 16.242398580536246 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0083,  0.8502],
         [-0.0026,  0.4444],
         [-0.0044,  0.2990],
         [-0.0041,  0.2215]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0248071503615974
Current reward: 0.3106042182795713
Current mitigation activation: 0
#############################
Total reward: 38.69274231055898
16.267398580908775 seconds in game passed.
Action: tensor([[[ 0.0083,  0.8502],
         [-0.0026,  0.4444],
         [-0.0044,  0.2990],
         [-0.0041,  0.2215]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.69274231055898
16.292398581281304 seconds in game passed.
Action: tensor([[[ 0.0083,  0.8502],
         [-0.0026,  0.4444],
         [-0.0044,  0.2990],
         [-0.0041,  0.2215]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.69274231055898
16.317398581653833 seconds in game passed.
Action: tensor([[[ 0.0083,  0.8502],
         [-0.0026,  0.4444],
         [-0.0044,  0.2990],
         [-0.0041,  0.2215]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.69274231055898
+++++++++++++: 1.9044076167733321
16.342398582026362 seconds in game passed.
At 16.342398582026362 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0055,  0.8574],
         [-0.0020,  0.4511],
         [-0.0042,  0.3017],
         [-0.0043,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9044076167733321
Current reward: 0.31998481533380563
Current mitigation activation: 0
#############################
Total reward: 39.01272712589278
16.36739858239889 seconds in game passed.
Action: tensor([[[ 0.0055,  0.8574],
         [-0.0020,  0.4511],
         [-0.0042,  0.3017],
         [-0.0043,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.01272712589278
16.39239858277142 seconds in game passed.
Action: tensor([[[ 0.0055,  0.8574],
         [-0.0020,  0.4511],
         [-0.0042,  0.3017],
         [-0.0043,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.01272712589278
16.41739858314395 seconds in game passed.
Action: tensor([[[ 0.0055,  0.8574],
         [-0.0020,  0.4511],
         [-0.0042,  0.3017],
         [-0.0043,  0.2231]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.01272712589278
+++++++++++++: 1.7925547984222465
16.44239858351648 seconds in game passed.
At 16.44239858351648 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.8546],
         [-0.0018,  0.4448],
         [-0.0039,  0.2985],
         [-0.0045,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000030, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7925547984222465
Current reward: 0.328875018568616
Current mitigation activation: 0
#############################
Total reward: 39.3416021444614
16.467398583889008 seconds in game passed.
Action: tensor([[[-0.0009,  0.8546],
         [-0.0018,  0.4448],
         [-0.0039,  0.2985],
         [-0.0045,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.3416021444614
16.492398584261537 seconds in game passed.
Action: tensor([[[-0.0009,  0.8546],
         [-0.0018,  0.4448],
         [-0.0039,  0.2985],
         [-0.0045,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.3416021444614
16.517398584634066 seconds in game passed.
Action: tensor([[[-0.0009,  0.8546],
         [-0.0018,  0.4448],
         [-0.0039,  0.2985],
         [-0.0045,  0.2219]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.3416021444614
+++++++++++++: 1.688852125562051
16.542398585006595 seconds in game passed.
At 16.542398585006595 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.6898e-04,  8.8845e-01],
         [-1.1510e-03,  4.6402e-01],
         [-4.1881e-03,  3.1219e-01],
         [-5.2449e-03,  2.3147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.688852125562051
Current reward: 0.3373732900032659
Current mitigation activation: 0
#############################
Total reward: 39.67897543446466
16.567398585379124 seconds in game passed.
Action: tensor([[[ 8.6898e-04,  8.8845e-01],
         [-1.1510e-03,  4.6402e-01],
         [-4.1881e-03,  3.1219e-01],
         [-5.2449e-03,  2.3147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.67897543446466
16.592398585751653 seconds in game passed.
Action: tensor([[[ 8.6898e-04,  8.8845e-01],
         [-1.1510e-03,  4.6402e-01],
         [-4.1881e-03,  3.1219e-01],
         [-5.2449e-03,  2.3147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000799, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.67897543446466
16.61739858612418 seconds in game passed.
Action: tensor([[[ 8.6898e-04,  8.8845e-01],
         [-1.1510e-03,  4.6402e-01],
         [-4.1881e-03,  3.1219e-01],
         [-5.2449e-03,  2.3147e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000707, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.67897543446466
+++++++++++++: 1.5932226318974343
16.64239858649671 seconds in game passed.
At 16.64239858649671 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0027,  0.8767],
         [-0.0014,  0.4671],
         [-0.0046,  0.3182],
         [-0.0056,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.742481, steer=0.001176, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5932226318974343
Current reward: 0.34557409763805547
Current mitigation activation: 0
#############################
Total reward: 40.02454953210272
16.66739858686924 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8767],
         [-0.0014,  0.4671],
         [-0.0046,  0.3182],
         [-0.0056,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.702501, steer=0.000988, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.02454953210272
16.69239858724177 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8767],
         [-0.0014,  0.4671],
         [-0.0046,  0.3182],
         [-0.0056,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.650310, steer=0.000894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.02454953210272
16.717398587614298 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8767],
         [-0.0014,  0.4671],
         [-0.0046,  0.3182],
         [-0.0056,  0.2379]]])
agent 0 action: VehicleControl(throttle=0.599503, steer=0.000801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.02454953210272
+++++++++++++: 1.5058268458444206
16.742398587986827 seconds in game passed.
At 16.742398587986827 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0040,  0.9039],
         [ 0.0010,  0.4896],
         [-0.0025,  0.3308],
         [-0.0035,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.462711, steer=0.003112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5058268458444206
Current reward: 0.35341922866140174
Current mitigation activation: 0
#############################
Total reward: 40.37796876076412
16.767398588359356 seconds in game passed.
Action: tensor([[[ 0.0040,  0.9039],
         [ 0.0010,  0.4896],
         [-0.0025,  0.3308],
         [-0.0035,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.454927, steer=0.002674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.37796876076412
16.792398588731885 seconds in game passed.
Action: tensor([[[ 0.0040,  0.9039],
         [ 0.0010,  0.4896],
         [-0.0025,  0.3308],
         [-0.0035,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.434266, steer=0.002629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.37796876076412
16.817398589104414 seconds in game passed.
Action: tensor([[[ 0.0040,  0.9039],
         [ 0.0010,  0.4896],
         [-0.0025,  0.3308],
         [-0.0035,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.414118, steer=0.002584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.37796876076412
+++++++++++++: 1.4346916369752836
16.842398589476943 seconds in game passed.
At 16.842398589476943 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2466e-02, 9.0024e-01],
         [4.9295e-03, 4.8578e-01],
         [1.5124e-03, 3.2930e-01],
         [3.6044e-04, 2.4297e-01]]])
agent 0 action: VehicleControl(throttle=0.394282, steer=0.009105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4346916369752836
Current reward: 0.3595949131937742
Current mitigation activation: 0
#############################
Total reward: 40.737563673957894
16.867398589849472 seconds in game passed.
Action: tensor([[[1.2466e-02, 9.0024e-01],
         [4.9295e-03, 4.8578e-01],
         [1.5124e-03, 3.2930e-01],
         [3.6044e-04, 2.4297e-01]]])
agent 0 action: VehicleControl(throttle=0.375027, steer=0.008080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.737563673957894
16.892398590222 seconds in game passed.
Action: tensor([[[1.2466e-02, 9.0024e-01],
         [4.9295e-03, 4.8578e-01],
         [1.5124e-03, 3.2930e-01],
         [3.6044e-04, 2.4297e-01]]])
agent 0 action: VehicleControl(throttle=0.356335, steer=0.008132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.737563673957894
16.91739859059453 seconds in game passed.
Action: tensor([[[1.2466e-02, 9.0024e-01],
         [4.9295e-03, 4.8578e-01],
         [1.5124e-03, 3.2930e-01],
         [3.6044e-04, 2.4297e-01]]])
agent 0 action: VehicleControl(throttle=0.338190, steer=0.008185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.737563673957894
+++++++++++++: 1.3868300505083642
16.94239859096706 seconds in game passed.
At 16.94239859096706 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.4271e-02, 8.9463e-01],
         [3.7229e-03, 4.8726e-01],
         [6.0630e-04, 3.2948e-01],
         [3.5168e-04, 2.4236e-01]]])
agent 0 action: VehicleControl(throttle=0.320667, steer=0.012260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3868300505083642
Current reward: 0.36271354390886645
Current mitigation activation: 0
#############################
Total reward: 41.10027721786676
16.967398591339588 seconds in game passed.
Action: tensor([[[2.4271e-02, 8.9463e-01],
         [3.7229e-03, 4.8726e-01],
         [6.0630e-04, 3.2948e-01],
         [3.5168e-04, 2.4236e-01]]])
agent 0 action: VehicleControl(throttle=0.303666, steer=0.011700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.10027721786676
16.992398591712117 seconds in game passed.
Action: tensor([[[2.4271e-02, 8.9463e-01],
         [3.7229e-03, 4.8726e-01],
         [6.0630e-04, 3.2948e-01],
         [3.5168e-04, 2.4236e-01]]])
agent 0 action: VehicleControl(throttle=0.287178, steer=0.011802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.10027721786676
17.017398592084646 seconds in game passed.
Action: tensor([[[2.4271e-02, 8.9463e-01],
         [3.7229e-03, 4.8726e-01],
         [6.0630e-04, 3.2948e-01],
         [3.5168e-04, 2.4236e-01]]])
agent 0 action: VehicleControl(throttle=0.271192, steer=0.011904, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.10027721786676
+++++++++++++: 1.3586586016116269
17.042398592457175 seconds in game passed.
At 17.042398592457175 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1118e-02,  9.1871e-01],
         [ 3.0393e-04,  5.1157e-01],
         [-3.0754e-03,  3.4722e-01],
         [-2.5338e-03,  2.5619e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008251, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3586586016116269
Current reward: 0.36316262919476444
Current mitigation activation: 0
#############################
Total reward: 41.46343984706152
17.067398592829704 seconds in game passed.
Action: tensor([[[ 2.1118e-02,  9.1871e-01],
         [ 3.0393e-04,  5.1157e-01],
         [-3.0754e-03,  3.4722e-01],
         [-2.5338e-03,  2.5619e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008937, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.46343984706152
17.092398593202233 seconds in game passed.
Action: tensor([[[ 2.1118e-02,  9.1871e-01],
         [ 3.0393e-04,  5.1157e-01],
         [-3.0754e-03,  3.4722e-01],
         [-2.5338e-03,  2.5619e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.009002, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.46343984706152
17.117398593574762 seconds in game passed.
Action: tensor([[[ 2.1118e-02,  9.1871e-01],
         [ 3.0393e-04,  5.1157e-01],
         [-3.0754e-03,  3.4722e-01],
         [-2.5338e-03,  2.5619e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.009068, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.46343984706152
+++++++++++++: 1.3504992992948006
17.14239859394729 seconds in game passed.
At 17.14239859394729 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.6761e-02,  9.3649e-01],
         [ 8.8334e-05,  5.3961e-01],
         [-5.1443e-03,  3.5851e-01],
         [-5.5757e-03,  2.6242e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.007317, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3504992992948006
Current reward: 0.360937311669437
Current mitigation activation: 0
#############################
Total reward: 41.82437715873096
17.16739859431982 seconds in game passed.
Action: tensor([[[ 1.6761e-02,  9.3649e-01],
         [ 8.8334e-05,  5.3961e-01],
         [-5.1443e-03,  3.5851e-01],
         [-5.5757e-03,  2.6242e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.007667, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.82437715873096
17.19239859469235 seconds in game passed.
Action: tensor([[[ 1.6761e-02,  9.3649e-01],
         [ 8.8334e-05,  5.3961e-01],
         [-5.1443e-03,  3.5851e-01],
         [-5.5757e-03,  2.6242e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.007716, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.82437715873096
17.21739859506488 seconds in game passed.
Action: tensor([[[ 1.6761e-02,  9.3649e-01],
         [ 8.8334e-05,  5.3961e-01],
         [-5.1443e-03,  3.5851e-01],
         [-5.5757e-03,  2.6242e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.007766, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.82437715873096
+++++++++++++: 1.3991103773018252
17.242398595437407 seconds in game passed.
At 17.242398595437407 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0116,  0.9308],
         [-0.0032,  0.5279],
         [-0.0083,  0.3544],
         [-0.0090,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003009, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3991103773018252
Current reward: 0.35067217359096886
Current mitigation activation: 0
#############################
Total reward: 42.17504933232193
17.267398595809937 seconds in game passed.
Action: tensor([[[ 0.0116,  0.9308],
         [-0.0032,  0.5279],
         [-0.0083,  0.3544],
         [-0.0090,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.125429, steer=0.003817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.17504933232193
17.292398596182466 seconds in game passed.
Action: tensor([[[ 0.0116,  0.9308],
         [-0.0032,  0.5279],
         [-0.0083,  0.3544],
         [-0.0090,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.113291, steer=0.003830, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.17504933232193
17.317398596554995 seconds in game passed.
Action: tensor([[[ 0.0116,  0.9308],
         [-0.0032,  0.5279],
         [-0.0083,  0.3544],
         [-0.0090,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.101612, steer=0.003843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.17504933232193
+++++++++++++: 1.5248476346096465
17.342398596927524 seconds in game passed.
At 17.342398596927524 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0018,  0.9238],
         [-0.0097,  0.5295],
         [-0.0150,  0.3575],
         [-0.0157,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.091403, steer=-0.005238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5248476346096465
Current reward: 0.3323091080753391
Current mitigation activation: 0
#############################
Total reward: 42.50735844039727
17.367398597300053 seconds in game passed.
Action: tensor([[[ 0.0018,  0.9238],
         [-0.0097,  0.5295],
         [-0.0150,  0.3575],
         [-0.0157,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.081651, steer=-0.003811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.50735844039727
17.39239859767258 seconds in game passed.
Action: tensor([[[ 0.0018,  0.9238],
         [-0.0097,  0.5295],
         [-0.0150,  0.3575],
         [-0.0157,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.072354, steer=-0.003886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.50735844039727
17.41739859804511 seconds in game passed.
Action: tensor([[[ 0.0018,  0.9238],
         [-0.0097,  0.5295],
         [-0.0150,  0.3575],
         [-0.0157,  0.2653]]])
agent 0 action: VehicleControl(throttle=0.063511, steer=-0.003960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.50735844039727
+++++++++++++: 1.6174191821262498
17.44239859841764 seconds in game passed.
At 17.44239859841764 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0024,  0.9347],
         [-0.0053,  0.5140],
         [-0.0100,  0.3404],
         [-0.0115,  0.2536]]])
agent 0 action: VehicleControl(throttle=0.142400, steer=-0.000498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6174191821262498
Current reward: 0.32255513851127643
Current mitigation activation: 0
#############################
Total reward: 42.829913578908545
17.46739859879017 seconds in game passed.
Action: tensor([[[ 0.0024,  0.9347],
         [-0.0053,  0.5140],
         [-0.0100,  0.3404],
         [-0.0115,  0.2536]]])
agent 0 action: VehicleControl(throttle=0.126287, steer=-0.001091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.829913578908545
17.492398599162698 seconds in game passed.
Action: tensor([[[ 0.0024,  0.9347],
         [-0.0053,  0.5140],
         [-0.0100,  0.3404],
         [-0.0115,  0.2536]]])
agent 0 action: VehicleControl(throttle=0.119843, steer=-0.001105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.829913578908545
17.517398599535227 seconds in game passed.
Action: tensor([[[ 0.0024,  0.9347],
         [-0.0053,  0.5140],
         [-0.0100,  0.3404],
         [-0.0115,  0.2536]]])
agent 0 action: VehicleControl(throttle=0.113862, steer=-0.001118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.829913578908545
+++++++++++++: 1.6377713594985057
17.542398599907756 seconds in game passed.
At 17.542398599907756 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.9179],
         [-0.0111,  0.4938],
         [-0.0166,  0.3383],
         [-0.0184,  0.2605]]])
agent 0 action: VehicleControl(throttle=0.346760, steer=-0.007613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6377713594985057
Current reward: 0.3232238069578972
Current mitigation activation: 0
#############################
Total reward: 43.153137385866444
17.567398600280285 seconds in game passed.
Action: tensor([[[-0.0023,  0.9179],
         [-0.0111,  0.4938],
         [-0.0166,  0.3383],
         [-0.0184,  0.2605]]])
agent 0 action: VehicleControl(throttle=0.321335, steer=-0.006638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.153137385866444
17.592398600652814 seconds in game passed.
Action: tensor([[[-0.0023,  0.9179],
         [-0.0111,  0.4938],
         [-0.0166,  0.3383],
         [-0.0184,  0.2605]]])
agent 0 action: VehicleControl(throttle=0.321429, steer=-0.006731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.153137385866444
17.617398601025343 seconds in game passed.
Action: tensor([[[-0.0023,  0.9179],
         [-0.0111,  0.4938],
         [-0.0166,  0.3383],
         [-0.0184,  0.2605]]])
agent 0 action: VehicleControl(throttle=0.321953, steer=-0.006823, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.153137385866444
+++++++++++++: 1.6599131609923012
17.642398601397872 seconds in game passed.
At 17.642398601397872 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0063,  0.8807],
         [-0.0162,  0.4717],
         [-0.0224,  0.3248],
         [-0.0244,  0.2493]]])
agent 0 action: VehicleControl(throttle=0.517148, steer=-0.012437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6599131609923012
Current reward: 0.3243384816817005
Current mitigation activation: 0
#############################
Total reward: 43.477475867548144
17.6673986017704 seconds in game passed.
Action: tensor([[[-0.0063,  0.8807],
         [-0.0162,  0.4717],
         [-0.0224,  0.3248],
         [-0.0244,  0.2493]]])
agent 0 action: VehicleControl(throttle=0.501514, steer=-0.011682, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.477475867548144
17.69239860214293 seconds in game passed.
Action: tensor([[[-0.0063,  0.8807],
         [-0.0162,  0.4717],
         [-0.0224,  0.3248],
         [-0.0244,  0.2493]]])
agent 0 action: VehicleControl(throttle=0.506819, steer=-0.011837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.477475867548144
17.71739860251546 seconds in game passed.
Action: tensor([[[-0.0063,  0.8807],
         [-0.0162,  0.4717],
         [-0.0224,  0.3248],
         [-0.0244,  0.2493]]])
agent 0 action: VehicleControl(throttle=0.512506, steer=-0.011992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.477475867548144
+++++++++++++: 1.6853167493659897
17.742398602887988 seconds in game passed.
At 17.742398602887988 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0073,  0.8975],
         [-0.0118,  0.4871],
         [-0.0162,  0.3316],
         [-0.0174,  0.2496]]])
agent 0 action: VehicleControl(throttle=0.339645, steer=-0.009225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6853167493659897
Current reward: 0.32568740059100265
Current mitigation activation: 0
#############################
Total reward: 43.803163268139144
17.767398603260517 seconds in game passed.
Action: tensor([[[-0.0073,  0.8975],
         [-0.0118,  0.4871],
         [-0.0162,  0.3316],
         [-0.0174,  0.2496]]])
agent 0 action: VehicleControl(throttle=0.363751, steer=-0.009860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.803163268139144
17.792398603633046 seconds in game passed.
Action: tensor([[[-0.0073,  0.8975],
         [-0.0118,  0.4871],
         [-0.0162,  0.3316],
         [-0.0174,  0.2496]]])
agent 0 action: VehicleControl(throttle=0.368766, steer=-0.010010, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.803163268139144
17.817398604005575 seconds in game passed.
Action: tensor([[[-0.0073,  0.8975],
         [-0.0118,  0.4871],
         [-0.0162,  0.3316],
         [-0.0174,  0.2496]]])
agent 0 action: VehicleControl(throttle=0.373815, steer=-0.010159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.803163268139144
+++++++++++++: 1.7249262593985888
17.842398604378104 seconds in game passed.
At 17.842398604378104 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.8938],
         [-0.0100,  0.4748],
         [-0.0137,  0.3248],
         [-0.0142,  0.2454]]])
agent 0 action: VehicleControl(throttle=0.665412, steer=-0.007387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7249262593985888
Current reward: 0.32610847544272353
Current mitigation activation: 0
#############################
Total reward: 44.12927174358187
17.867398604750633 seconds in game passed.
Action: tensor([[[-0.0034,  0.8938],
         [-0.0100,  0.4748],
         [-0.0137,  0.3248],
         [-0.0142,  0.2454]]])
agent 0 action: VehicleControl(throttle=0.726568, steer=-0.008066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.12927174358187
17.892398605123162 seconds in game passed.
Action: tensor([[[-0.0034,  0.8938],
         [-0.0100,  0.4748],
         [-0.0137,  0.3248],
         [-0.0142,  0.2454]]])
agent 0 action: VehicleControl(throttle=0.803240, steer=-0.008252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.12927174358187
17.91739860549569 seconds in game passed.
Action: tensor([[[-0.0034,  0.8938],
         [-0.0100,  0.4748],
         [-0.0137,  0.3248],
         [-0.0142,  0.2454]]])
agent 0 action: VehicleControl(throttle=0.872818, steer=-0.008438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.12927174358187
+++++++++++++: 1.9123409616891578
17.94239860586822 seconds in game passed.
At 17.94239860586822 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0048,  0.8950],
         [-0.0077,  0.4687],
         [-0.0122,  0.3138],
         [-0.0138,  0.2339]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9123409616891578
Current reward: 0.31309340155811716
Current mitigation activation: 0
#############################
Total reward: 44.44236514513999
17.96739860624075 seconds in game passed.
Action: tensor([[[ 0.0048,  0.8950],
         [-0.0077,  0.4687],
         [-0.0122,  0.3138],
         [-0.0138,  0.2339]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.44236514513999
17.99239860661328 seconds in game passed.
Action: tensor([[[ 0.0048,  0.8950],
         [-0.0077,  0.4687],
         [-0.0122,  0.3138],
         [-0.0138,  0.2339]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.44236514513999
18.017398606985807 seconds in game passed.
Action: tensor([[[ 0.0048,  0.8950],
         [-0.0077,  0.4687],
         [-0.0122,  0.3138],
         [-0.0138,  0.2339]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.44236514513999
+++++++++++++: 2.09998453006265
18.042398607358336 seconds in game passed.
At 18.042398607358336 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.8456],
         [-0.0100,  0.4442],
         [-0.0135,  0.2973],
         [-0.0147,  0.2220]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009818, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.09998453006265
Current reward: 0.30438200457167525
Current mitigation activation: 0
#############################
Total reward: 44.746747149711666
18.067398607730865 seconds in game passed.
Action: tensor([[[-0.0026,  0.8456],
         [-0.0100,  0.4442],
         [-0.0135,  0.2973],
         [-0.0147,  0.2220]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.746747149711666
18.092398608103395 seconds in game passed.
Action: tensor([[[-0.0026,  0.8456],
         [-0.0100,  0.4442],
         [-0.0135,  0.2973],
         [-0.0147,  0.2220]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.746747149711666
18.117398608475924 seconds in game passed.
Action: tensor([[[-0.0026,  0.8456],
         [-0.0100,  0.4442],
         [-0.0135,  0.2973],
         [-0.0147,  0.2220]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.746747149711666
+++++++++++++: 2.192223087118226
18.142398608848453 seconds in game passed.
At 18.142398608848453 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.8824e-04,  7.9562e-01],
         [-5.4167e-03,  4.2134e-01],
         [-8.0856e-03,  2.8448e-01],
         [-9.4100e-03,  2.1419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.192223087118226
Current reward: 0.3054372937106885
Current mitigation activation: 0
#############################
Total reward: 45.052184443422355
18.16739860922098 seconds in game passed.
Action: tensor([[[-2.8824e-04,  7.9562e-01],
         [-5.4167e-03,  4.2134e-01],
         [-8.0856e-03,  2.8448e-01],
         [-9.4100e-03,  2.1419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.052184443422355
18.19239860959351 seconds in game passed.
Action: tensor([[[-2.8824e-04,  7.9562e-01],
         [-5.4167e-03,  4.2134e-01],
         [-8.0856e-03,  2.8448e-01],
         [-9.4100e-03,  2.1419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.052184443422355
18.21739860996604 seconds in game passed.
Action: tensor([[[-2.8824e-04,  7.9562e-01],
         [-5.4167e-03,  4.2134e-01],
         [-8.0856e-03,  2.8448e-01],
         [-9.4100e-03,  2.1419e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.052184443422355
+++++++++++++: 2.2097995261127807
18.24239861033857 seconds in game passed.
At 18.24239861033857 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0046,  0.7531],
         [-0.0075,  0.4071],
         [-0.0092,  0.2810],
         [-0.0098,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2097995261127807
Current reward: 0.31257639889758904
Current mitigation activation: 0
#############################
Total reward: 45.364760842319946
18.267398610711098 seconds in game passed.
Action: tensor([[[-0.0046,  0.7531],
         [-0.0075,  0.4071],
         [-0.0092,  0.2810],
         [-0.0098,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.364760842319946
18.292398611083627 seconds in game passed.
Action: tensor([[[-0.0046,  0.7531],
         [-0.0075,  0.4071],
         [-0.0092,  0.2810],
         [-0.0098,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.364760842319946
18.317398611456156 seconds in game passed.
Action: tensor([[[-0.0046,  0.7531],
         [-0.0075,  0.4071],
         [-0.0092,  0.2810],
         [-0.0098,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.364760842319946
+++++++++++++: 2.1890480791557936
18.342398611828685 seconds in game passed.
At 18.342398611828685 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.8066e-04,  7.2245e-01],
         [-6.6977e-03,  4.0278e-01],
         [-8.7561e-03,  2.8087e-01],
         [-9.6100e-03,  2.1602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1890480791557936
Current reward: 0.32269629580080983
Current mitigation activation: 0
#############################
Total reward: 45.687457138120756
18.367398612201214 seconds in game passed.
Action: tensor([[[-3.8066e-04,  7.2245e-01],
         [-6.6977e-03,  4.0278e-01],
         [-8.7561e-03,  2.8087e-01],
         [-9.6100e-03,  2.1602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.687457138120756
18.392398612573743 seconds in game passed.
Action: tensor([[[-3.8066e-04,  7.2245e-01],
         [-6.6977e-03,  4.0278e-01],
         [-8.7561e-03,  2.8087e-01],
         [-9.6100e-03,  2.1602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.687457138120756
18.417398612946272 seconds in game passed.
Action: tensor([[[-3.8066e-04,  7.2245e-01],
         [-6.6977e-03,  4.0278e-01],
         [-8.7561e-03,  2.8087e-01],
         [-9.6100e-03,  2.1602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.687457138120756
+++++++++++++: 2.1502633507577613
18.4423986133188 seconds in game passed.
At 18.4423986133188 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0035,  0.7336],
         [-0.0018,  0.4003],
         [-0.0035,  0.2761],
         [-0.0045,  0.2108]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1502633507577613
Current reward: 0.33429401393302344
Current mitigation activation: 0
#############################
Total reward: 46.02175115205378
18.46739861369133 seconds in game passed.
Action: tensor([[[ 0.0035,  0.7336],
         [-0.0018,  0.4003],
         [-0.0035,  0.2761],
         [-0.0045,  0.2108]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.02175115205378
18.49239861406386 seconds in game passed.
Action: tensor([[[ 0.0035,  0.7336],
         [-0.0018,  0.4003],
         [-0.0035,  0.2761],
         [-0.0045,  0.2108]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003082, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.02175115205378
18.517398614436388 seconds in game passed.
Action: tensor([[[ 0.0035,  0.7336],
         [-0.0018,  0.4003],
         [-0.0035,  0.2761],
         [-0.0045,  0.2108]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.02175115205378
+++++++++++++: 2.1041208898150097
18.542398614808917 seconds in game passed.
At 18.542398614808917 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.4413e-03,  7.0675e-01],
         [-2.0429e-04,  3.9039e-01],
         [-1.7235e-03,  2.6890e-01],
         [-2.9931e-03,  2.0536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1041208898150097
Current reward: 0.3465861634995505
Current mitigation activation: 0
#############################
Total reward: 46.36833731555333
18.567398615181446 seconds in game passed.
Action: tensor([[[ 6.4413e-03,  7.0675e-01],
         [-2.0429e-04,  3.9039e-01],
         [-1.7235e-03,  2.6890e-01],
         [-2.9931e-03,  2.0536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.36833731555333
18.592398615553975 seconds in game passed.
Action: tensor([[[ 6.4413e-03,  7.0675e-01],
         [-2.0429e-04,  3.9039e-01],
         [-1.7235e-03,  2.6890e-01],
         [-2.9931e-03,  2.0536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.36833731555333
18.617398615926504 seconds in game passed.
Action: tensor([[[ 6.4413e-03,  7.0675e-01],
         [-2.0429e-04,  3.9039e-01],
         [-1.7235e-03,  2.6890e-01],
         [-2.9931e-03,  2.0536e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.36833731555333
+++++++++++++: 2.055899574049949
18.642398616299033 seconds in game passed.
At 18.642398616299033 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.8375e-03,  6.8029e-01],
         [-5.8033e-05,  3.7332e-01],
         [-1.6721e-04,  2.5576e-01],
         [-4.1252e-04,  1.9518e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.055899574049949
Current reward: 0.3591415183595024
Current mitigation activation: 0
#############################
Total reward: 46.72747883391283
18.667398616671562 seconds in game passed.
Action: tensor([[[ 4.8375e-03,  6.8029e-01],
         [-5.8033e-05,  3.7332e-01],
         [-1.6721e-04,  2.5576e-01],
         [-4.1252e-04,  1.9518e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.72747883391283
18.69239861704409 seconds in game passed.
Action: tensor([[[ 4.8375e-03,  6.8029e-01],
         [-5.8033e-05,  3.7332e-01],
         [-1.6721e-04,  2.5576e-01],
         [-4.1252e-04,  1.9518e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.72747883391283
18.71739861741662 seconds in game passed.
Action: tensor([[[ 4.8375e-03,  6.8029e-01],
         [-5.8033e-05,  3.7332e-01],
         [-1.6721e-04,  2.5576e-01],
         [-4.1252e-04,  1.9518e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.72747883391283
+++++++++++++: 2.0081227699600643
18.74239861778915 seconds in game passed.
At 18.74239861778915 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0048, 0.6689],
         [0.0021, 0.3571],
         [0.0017, 0.2438],
         [0.0010, 0.1859]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0081227699600643
Current reward: 0.3717163085853754
Current mitigation activation: 0
#############################
Total reward: 47.09919514249821
18.76739861816168 seconds in game passed.
Action: tensor([[[0.0048, 0.6689],
         [0.0021, 0.3571],
         [0.0017, 0.2438],
         [0.0010, 0.1859]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.09919514249821
18.792398618534207 seconds in game passed.
Action: tensor([[[0.0048, 0.6689],
         [0.0021, 0.3571],
         [0.0017, 0.2438],
         [0.0010, 0.1859]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.09919514249821
18.817398618906736 seconds in game passed.
Action: tensor([[[0.0048, 0.6689],
         [0.0021, 0.3571],
         [0.0017, 0.2438],
         [0.0010, 0.1859]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.09919514249821
+++++++++++++: 1.961990310461917
18.842398619279265 seconds in game passed.
At 18.842398619279265 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6554],
         [0.0024, 0.3531],
         [0.0024, 0.2421],
         [0.0017, 0.1856]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.961990310461917
Current reward: 0.38416884362493897
Current mitigation activation: 0
#############################
Total reward: 47.48336398612315
18.867398619651794 seconds in game passed.
Action: tensor([[[0.0037, 0.6554],
         [0.0024, 0.3531],
         [0.0024, 0.2421],
         [0.0017, 0.1856]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.48336398612315
18.892398620024323 seconds in game passed.
Action: tensor([[[0.0037, 0.6554],
         [0.0024, 0.3531],
         [0.0024, 0.2421],
         [0.0017, 0.1856]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001853, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.48336398612315
18.917398620396852 seconds in game passed.
Action: tensor([[[0.0037, 0.6554],
         [0.0024, 0.3531],
         [0.0024, 0.2421],
         [0.0017, 0.1856]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.48336398612315
+++++++++++++: 1.9179452182357597
18.94239862076938 seconds in game passed.
At 18.94239862076938 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.5274e-03, 6.5130e-01],
         [5.1048e-04, 3.4894e-01],
         [5.8894e-04, 2.4001e-01],
         [8.7693e-05, 1.8417e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9179452182357597
Current reward: 0.39641763206422
Current mitigation activation: 0
#############################
Total reward: 47.87978161818737
18.96739862114191 seconds in game passed.
Action: tensor([[[1.5274e-03, 6.5130e-01],
         [5.1048e-04, 3.4894e-01],
         [5.8894e-04, 2.4001e-01],
         [8.7693e-05, 1.8417e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000161, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.87978161818737
18.99239862151444 seconds in game passed.
Action: tensor([[[1.5274e-03, 6.5130e-01],
         [5.1048e-04, 3.4894e-01],
         [5.8894e-04, 2.4001e-01],
         [8.7693e-05, 1.8417e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.87978161818737
19.01739862188697 seconds in game passed.
Action: tensor([[[1.5274e-03, 6.5130e-01],
         [5.1048e-04, 3.4894e-01],
         [5.8894e-04, 2.4001e-01],
         [8.7693e-05, 1.8417e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.87978161818737
+++++++++++++: 1.8761003956589075
19.042398622259498 seconds in game passed.
At 19.042398622259498 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.4330e-03, 6.5795e-01],
         [1.3676e-03, 3.5177e-01],
         [6.8939e-04, 2.4131e-01],
         [6.3665e-05, 1.8481e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8761003956589075
Current reward: 0.4084073005098447
Current mitigation activation: 0
#############################
Total reward: 48.288188918697216
19.067398622632027 seconds in game passed.
Action: tensor([[[3.4330e-03, 6.5795e-01],
         [1.3676e-03, 3.5177e-01],
         [6.8939e-04, 2.4131e-01],
         [6.3665e-05, 1.8481e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.288188918697216
19.092398623004556 seconds in game passed.
Action: tensor([[[3.4330e-03, 6.5795e-01],
         [1.3676e-03, 3.5177e-01],
         [6.8939e-04, 2.4131e-01],
         [6.3665e-05, 1.8481e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001760, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.288188918697216
19.117398623377085 seconds in game passed.
Action: tensor([[[3.4330e-03, 6.5795e-01],
         [1.3676e-03, 3.5177e-01],
         [6.8939e-04, 2.4131e-01],
         [6.3665e-05, 1.8481e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001875, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.288188918697216
+++++++++++++: 1.8364138150614364
19.142398623749614 seconds in game passed.
At 19.142398623749614 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6798],
         [-0.0021,  0.3568],
         [-0.0032,  0.2428],
         [-0.0039,  0.1853]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8364138150614364
Current reward: 0.42011008040641923
Current mitigation activation: 0
#############################
Total reward: 48.70829899910363
19.167398624122143 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6798],
         [-0.0021,  0.3568],
         [-0.0032,  0.2428],
         [-0.0039,  0.1853]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000975, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.70829899910363
19.192398624494672 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6798],
         [-0.0021,  0.3568],
         [-0.0032,  0.2428],
         [-0.0039,  0.1853]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.70829899910363
19.2173986248672 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6798],
         [-0.0021,  0.3568],
         [-0.0032,  0.2428],
         [-0.0039,  0.1853]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.70829899910363
+++++++++++++: 1.7987309936502127
19.24239862523973 seconds in game passed.
At 19.24239862523973 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0024,  0.6859],
         [-0.0025,  0.3556],
         [-0.0040,  0.2411],
         [-0.0048,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7987309936502127
Current reward: 0.43150707764322493
Current mitigation activation: 0
#############################
Total reward: 49.13980607674686
19.26739862561226 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6859],
         [-0.0025,  0.3556],
         [-0.0040,  0.2411],
         [-0.0048,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.13980607674686
19.292398625984788 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6859],
         [-0.0025,  0.3556],
         [-0.0040,  0.2411],
         [-0.0048,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.13980607674686
19.317398626357317 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6859],
         [-0.0025,  0.3556],
         [-0.0040,  0.2411],
         [-0.0048,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.13980607674686
+++++++++++++: 1.7663174237049741
19.342398626729846 seconds in game passed.
At 19.342398626729846 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.6793],
         [-0.0022,  0.3513],
         [-0.0028,  0.2383],
         [-0.0030,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7663174237049741
Current reward: 0.4421091135541869
Current mitigation activation: 0
#############################
Total reward: 49.581915190301046
19.367398627102375 seconds in game passed.
Action: tensor([[[-0.0009,  0.6793],
         [-0.0022,  0.3513],
         [-0.0028,  0.2383],
         [-0.0030,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.581915190301046
19.392398627474904 seconds in game passed.
Action: tensor([[[-0.0009,  0.6793],
         [-0.0022,  0.3513],
         [-0.0028,  0.2383],
         [-0.0030,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.581915190301046
19.417398627847433 seconds in game passed.
Action: tensor([[[-0.0009,  0.6793],
         [-0.0022,  0.3513],
         [-0.0028,  0.2383],
         [-0.0030,  0.1827]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.581915190301046
+++++++++++++: 1.7803639998089111
19.442398628219962 seconds in game passed.
At 19.442398628219962 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.6674],
         [-0.0016,  0.3455],
         [-0.0022,  0.2348],
         [-0.0023,  0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7803639998089111
Current reward: 0.44599669430076916
Current mitigation activation: 0
#############################
Total reward: 50.027911884601814
19.46739862859249 seconds in game passed.
Action: tensor([[[-0.0018,  0.6674],
         [-0.0016,  0.3455],
         [-0.0022,  0.2348],
         [-0.0023,  0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.027911884601814
19.49239862896502 seconds in game passed.
Action: tensor([[[-0.0018,  0.6674],
         [-0.0016,  0.3455],
         [-0.0022,  0.2348],
         [-0.0023,  0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001236, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.027911884601814
19.51739862933755 seconds in game passed.
Action: tensor([[[-0.0018,  0.6674],
         [-0.0016,  0.3455],
         [-0.0022,  0.2348],
         [-0.0023,  0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.027911884601814
+++++++++++++: 1.808599967833607
19.54239862971008 seconds in game passed.
At 19.54239862971008 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6323],
         [0.0020, 0.3389],
         [0.0020, 0.2326],
         [0.0019, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.808599967833607
Current reward: 0.44813042135375186
Current mitigation activation: 0
#############################
Total reward: 50.476042305955566
19.567398630082607 seconds in game passed.
Action: tensor([[[0.0026, 0.6323],
         [0.0020, 0.3389],
         [0.0020, 0.2326],
         [0.0019, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.476042305955566
19.592398630455136 seconds in game passed.
Action: tensor([[[0.0026, 0.6323],
         [0.0020, 0.3389],
         [0.0020, 0.2326],
         [0.0019, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.476042305955566
19.617398630827665 seconds in game passed.
Action: tensor([[[0.0026, 0.6323],
         [0.0020, 0.3389],
         [0.0020, 0.2326],
         [0.0019, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.476042305955566
+++++++++++++: 1.838550138309534
19.642398631200194 seconds in game passed.
At 19.642398631200194 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0051, 0.6388],
         [0.0021, 0.3447],
         [0.0018, 0.2377],
         [0.0014, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.838550138309534
Current reward: 0.45043097414973376
Current mitigation activation: 0
#############################
Total reward: 50.9264732801053
19.667398631572723 seconds in game passed.
Action: tensor([[[0.0051, 0.6388],
         [0.0021, 0.3447],
         [0.0018, 0.2377],
         [0.0014, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.9264732801053
19.692398631945252 seconds in game passed.
Action: tensor([[[0.0051, 0.6388],
         [0.0021, 0.3447],
         [0.0018, 0.2377],
         [0.0014, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.9264732801053
19.71739863231778 seconds in game passed.
Action: tensor([[[0.0051, 0.6388],
         [0.0021, 0.3447],
         [0.0018, 0.2377],
         [0.0014, 0.1830]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.9264732801053
+++++++++++++: 1.8702474048308726
19.74239863269031 seconds in game passed.
At 19.74239863269031 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0044, 0.6291],
         [0.0022, 0.3409],
         [0.0022, 0.2363],
         [0.0020, 0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003180, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8702474048308726
Current reward: 0.4528853160723261
Current mitigation activation: 0
#############################
Total reward: 51.379358596177624
19.76739863306284 seconds in game passed.
Action: tensor([[[0.0044, 0.6291],
         [0.0022, 0.3409],
         [0.0022, 0.2363],
         [0.0020, 0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.379358596177624
19.79239863343537 seconds in game passed.
Action: tensor([[[0.0044, 0.6291],
         [0.0022, 0.3409],
         [0.0022, 0.2363],
         [0.0020, 0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.379358596177624
19.817398633807898 seconds in game passed.
Action: tensor([[[0.0044, 0.6291],
         [0.0022, 0.3409],
         [0.0022, 0.2363],
         [0.0020, 0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.379358596177624
+++++++++++++: 1.90175489752821
19.842398634180427 seconds in game passed.
At 19.842398634180427 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.3387e-03, 6.3420e-01],
         [4.5425e-04, 3.3622e-01],
         [5.1573e-04, 2.3091e-01],
         [6.7417e-04, 1.7707e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.90175489752821
Current reward: 0.4557348647644207
Current mitigation activation: 0
#############################
Total reward: 51.83509346094205
19.867398634552956 seconds in game passed.
Action: tensor([[[3.3387e-03, 6.3420e-01],
         [4.5425e-04, 3.3622e-01],
         [5.1573e-04, 2.3091e-01],
         [6.7417e-04, 1.7707e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.83509346094205
19.892398634925485 seconds in game passed.
Action: tensor([[[3.3387e-03, 6.3420e-01],
         [4.5425e-04, 3.3622e-01],
         [5.1573e-04, 2.3091e-01],
         [6.7417e-04, 1.7707e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.83509346094205
19.917398635298014 seconds in game passed.
Action: tensor([[[3.3387e-03, 6.3420e-01],
         [4.5425e-04, 3.3622e-01],
         [5.1573e-04, 2.3091e-01],
         [6.7417e-04, 1.7707e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.83509346094205
+++++++++++++: 1.8626296106346423
19.942398635670543 seconds in game passed.
At 19.942398635670543 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.7542e-03,  6.1594e-01],
         [-5.9361e-04,  3.3068e-01],
         [-7.3838e-04,  2.2787e-01],
         [-8.4241e-04,  1.7522e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8626296106346423
Current reward: 0.4683007329766906
Current mitigation activation: 0
#############################
Total reward: 52.30339419391874
19.96739863604307 seconds in game passed.
Action: tensor([[[ 1.7542e-03,  6.1594e-01],
         [-5.9361e-04,  3.3068e-01],
         [-7.3838e-04,  2.2787e-01],
         [-8.4241e-04,  1.7522e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.30339419391874
19.9923986364156 seconds in game passed.
Action: tensor([[[ 1.7542e-03,  6.1594e-01],
         [-5.9361e-04,  3.3068e-01],
         [-7.3838e-04,  2.2787e-01],
         [-8.4241e-04,  1.7522e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.30339419391874
20.01739863678813 seconds in game passed.
Action: tensor([[[ 1.7542e-03,  6.1594e-01],
         [-5.9361e-04,  3.3068e-01],
         [-7.3838e-04,  2.2787e-01],
         [-8.4241e-04,  1.7522e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.30339419391874
+++++++++++++: 1.8030869047394364
20.04239863716066 seconds in game passed.
At 20.04239863716066 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6129],
         [-0.0040,  0.3304],
         [-0.0047,  0.2279],
         [-0.0052,  0.1755]]])
agent 0 action: VehicleControl(throttle=0.876026, steer=-0.003490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8030869047394364
Current reward: 0.4837246166975453
Current mitigation activation: 0
#############################
Total reward: 52.787118810616285
20.067398637533188 seconds in game passed.
Action: tensor([[[-0.0020,  0.6129],
         [-0.0040,  0.3304],
         [-0.0047,  0.2279],
         [-0.0052,  0.1755]]])
agent 0 action: VehicleControl(throttle=0.830759, steer=-0.002894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.787118810616285
20.092398637905717 seconds in game passed.
Action: tensor([[[-0.0020,  0.6129],
         [-0.0040,  0.3304],
         [-0.0047,  0.2279],
         [-0.0052,  0.1755]]])
agent 0 action: VehicleControl(throttle=0.784438, steer=-0.002957, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.787118810616285
20.117398638278246 seconds in game passed.
Action: tensor([[[-0.0020,  0.6129],
         [-0.0040,  0.3304],
         [-0.0047,  0.2279],
         [-0.0052,  0.1755]]])
agent 0 action: VehicleControl(throttle=0.739312, steer=-0.003020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.787118810616285
+++++++++++++: 1.7550888988077933
20.142398638650775 seconds in game passed.
At 20.142398638650775 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6178],
         [-0.0057,  0.3323],
         [-0.0067,  0.2276],
         [-0.0072,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.677035, steer=-0.004393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7550888988077933
Current reward: 0.49728526788685534
Current mitigation activation: 0
#############################
Total reward: 53.28440407850314
20.167398639023304 seconds in game passed.
Action: tensor([[[-0.0021,  0.6178],
         [-0.0057,  0.3323],
         [-0.0067,  0.2276],
         [-0.0072,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.636625, steer=-0.004211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.28440407850314
20.192398639395833 seconds in game passed.
Action: tensor([[[-0.0021,  0.6178],
         [-0.0057,  0.3323],
         [-0.0067,  0.2276],
         [-0.0072,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.596430, steer=-0.004252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.28440407850314
20.217398639768362 seconds in game passed.
Action: tensor([[[-0.0021,  0.6178],
         [-0.0057,  0.3323],
         [-0.0067,  0.2276],
         [-0.0072,  0.1741]]])
agent 0 action: VehicleControl(throttle=0.558735, steer=-0.004293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.28440407850314
+++++++++++++: 1.717505459617831
20.24239864014089 seconds in game passed.
At 20.24239864014089 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0047,  0.6259],
         [-0.0073,  0.3326],
         [-0.0080,  0.2269],
         [-0.0083,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.595538, steer=-0.006538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.717505459617831
Current reward: 0.5089740913613113
Current mitigation activation: 0
#############################
Total reward: 53.79337816986445
20.26739864051342 seconds in game passed.
Action: tensor([[[-0.0047,  0.6259],
         [-0.0073,  0.3326],
         [-0.0080,  0.2269],
         [-0.0083,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.555495, steer=-0.006240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.79337816986445
20.29239864088595 seconds in game passed.
Action: tensor([[[-0.0047,  0.6259],
         [-0.0073,  0.3326],
         [-0.0080,  0.2269],
         [-0.0083,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.525945, steer=-0.006305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.79337816986445
20.317398641258478 seconds in game passed.
Action: tensor([[[-0.0047,  0.6259],
         [-0.0073,  0.3326],
         [-0.0080,  0.2269],
         [-0.0083,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.498681, steer=-0.006370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.79337816986445
+++++++++++++: 1.6943612477017913
20.342398641631007 seconds in game passed.
At 20.342398641631007 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6330],
         [-0.0044,  0.3336],
         [-0.0050,  0.2271],
         [-0.0053,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.507612, steer=-0.003365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6943612477017913
Current reward: 0.5179729615468343
Current mitigation activation: 0
#############################
Total reward: 54.31135113141128
20.367398642003536 seconds in game passed.
Action: tensor([[[-0.0023,  0.6330],
         [-0.0044,  0.3336],
         [-0.0050,  0.2271],
         [-0.0053,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.480395, steer=-0.003892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.31135113141128
20.392398642376065 seconds in game passed.
Action: tensor([[[-0.0023,  0.6330],
         [-0.0044,  0.3336],
         [-0.0050,  0.2271],
         [-0.0053,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.458967, steer=-0.003915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.31135113141128
20.417398642748594 seconds in game passed.
Action: tensor([[[-0.0023,  0.6330],
         [-0.0044,  0.3336],
         [-0.0050,  0.2271],
         [-0.0053,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.439400, steer=-0.003938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.31135113141128
+++++++++++++: 1.6854708847909583
20.442398643121123 seconds in game passed.
At 20.442398643121123 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6072],
         [0.0021, 0.3294],
         [0.0017, 0.2270],
         [0.0009, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.305177, steer=0.002940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6854708847909583
Current reward: 0.5242771195463674
Current mitigation activation: 0
#############################
Total reward: 54.83562825095765
20.467398643493652 seconds in game passed.
Action: tensor([[[0.0028, 0.6072],
         [0.0021, 0.3294],
         [0.0017, 0.2270],
         [0.0009, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.299508, steer=0.001850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.83562825095765
20.49239864386618 seconds in game passed.
Action: tensor([[[0.0028, 0.6072],
         [0.0021, 0.3294],
         [0.0017, 0.2270],
         [0.0009, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.283867, steer=0.001897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.83562825095765
20.51739864423871 seconds in game passed.
Action: tensor([[[0.0028, 0.6072],
         [0.0021, 0.3294],
         [0.0017, 0.2270],
         [0.0009, 0.1744]]])
agent 0 action: VehicleControl(throttle=0.271319, steer=0.001945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.83562825095765
+++++++++++++: 1.6896142685613862
20.54239864461124 seconds in game passed.
At 20.54239864461124 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0043, 0.6291],
         [0.0028, 0.3379],
         [0.0022, 0.2316],
         [0.0012, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.225606, steer=0.003025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6896142685613862
Current reward: 0.5281984551500539
Current mitigation activation: 0
#############################
Total reward: 55.3638267061077
20.56739864498377 seconds in game passed.
Action: tensor([[[0.0043, 0.6291],
         [0.0028, 0.3379],
         [0.0022, 0.2316],
         [0.0012, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.219425, steer=0.002860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.3638267061077
20.592398645356297 seconds in game passed.
Action: tensor([[[0.0043, 0.6291],
         [0.0028, 0.3379],
         [0.0022, 0.2316],
         [0.0012, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.209373, steer=0.002873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.3638267061077
20.617398645728827 seconds in game passed.
Action: tensor([[[0.0043, 0.6291],
         [0.0028, 0.3379],
         [0.0022, 0.2316],
         [0.0012, 0.1779]]])
agent 0 action: VehicleControl(throttle=0.199303, steer=0.002886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.3638267061077
+++++++++++++: 1.7092752368941706
20.642398646101356 seconds in game passed.
At 20.642398646101356 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6250],
         [0.0023, 0.3351],
         [0.0017, 0.2295],
         [0.0008, 0.1761]]])
agent 0 action: VehicleControl(throttle=0.241061, steer=0.002127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7092752368941706
Current reward: 0.529480535562418
Current mitigation activation: 0
#############################
Total reward: 55.89330724167012
20.667398646473885 seconds in game passed.
Action: tensor([[[0.0033, 0.6250],
         [0.0023, 0.3351],
         [0.0017, 0.2295],
         [0.0008, 0.1761]]])
agent 0 action: VehicleControl(throttle=0.241135, steer=0.002246, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.89330724167012
20.692398646846414 seconds in game passed.
Action: tensor([[[0.0033, 0.6250],
         [0.0023, 0.3351],
         [0.0017, 0.2295],
         [0.0008, 0.1761]]])
agent 0 action: VehicleControl(throttle=0.246986, steer=0.002240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.89330724167012
20.717398647218943 seconds in game passed.
Action: tensor([[[0.0033, 0.6250],
         [0.0023, 0.3351],
         [0.0017, 0.2295],
         [0.0008, 0.1761]]])
agent 0 action: VehicleControl(throttle=0.253927, steer=0.002234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.89330724167012
+++++++++++++: 1.7436457744393263
20.74239864759147 seconds in game passed.
At 20.74239864759147 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.6195],
         [0.0018, 0.3335],
         [0.0016, 0.2290],
         [0.0007, 0.1758]]])
agent 0 action: VehicleControl(throttle=0.262276, steer=0.001213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7436457744393263
Current reward: 0.5285947136213802
Current mitigation activation: 0
#############################
Total reward: 56.4219019552915
20.767398647964 seconds in game passed.
Action: tensor([[[0.0016, 0.6195],
         [0.0018, 0.3335],
         [0.0016, 0.2290],
         [0.0007, 0.1758]]])
agent 0 action: VehicleControl(throttle=0.270566, steer=0.001366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.4219019552915
20.79239864833653 seconds in game passed.
Action: tensor([[[0.0016, 0.6195],
         [0.0018, 0.3335],
         [0.0016, 0.2290],
         [0.0007, 0.1758]]])
agent 0 action: VehicleControl(throttle=0.279553, steer=0.001352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.4219019552915
20.81739864870906 seconds in game passed.
Action: tensor([[[0.0016, 0.6195],
         [0.0018, 0.3335],
         [0.0016, 0.2290],
         [0.0007, 0.1758]]])
agent 0 action: VehicleControl(throttle=0.289003, steer=0.001337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.4219019552915
+++++++++++++: 1.7877210725481711
20.842398649081588 seconds in game passed.
At 20.842398649081588 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.3965e-03,  6.1931e-01],
         [-5.0980e-04,  3.3112e-01],
         [-6.3261e-04,  2.2679e-01],
         [-1.3616e-03,  1.7426e-01]]])
agent 0 action: VehicleControl(throttle=0.377985, steer=-0.001564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7877210725481711
Current reward: 0.5267528892015161
Current mitigation activation: 0
#############################
Total reward: 56.94865484449302
20.867398649454117 seconds in game passed.
Action: tensor([[[-1.3965e-03,  6.1931e-01],
         [-5.0980e-04,  3.3112e-01],
         [-6.3261e-04,  2.2679e-01],
         [-1.3616e-03,  1.7426e-01]]])
agent 0 action: VehicleControl(throttle=0.378982, steer=-0.001112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.94865484449302
20.892398649826646 seconds in game passed.
Action: tensor([[[-1.3965e-03,  6.1931e-01],
         [-5.0980e-04,  3.3112e-01],
         [-6.3261e-04,  2.2679e-01],
         [-1.3616e-03,  1.7426e-01]]])
agent 0 action: VehicleControl(throttle=0.389133, steer=-0.001139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.94865484449302
20.917398650199175 seconds in game passed.
Action: tensor([[[-1.3965e-03,  6.1931e-01],
         [-5.0980e-04,  3.3112e-01],
         [-6.3261e-04,  2.2679e-01],
         [-1.3616e-03,  1.7426e-01]]])
agent 0 action: VehicleControl(throttle=0.399122, steer=-0.001165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.94865484449302
+++++++++++++: 1.8368790581717922
20.942398650571704 seconds in game passed.
At 20.942398650571704 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6179],
         [-0.0017,  0.3328],
         [-0.0022,  0.2283],
         [-0.0030,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.335027, steer=-0.002323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8368790581717922
Current reward: 0.5249195660008276
Current mitigation activation: 0
#############################
Total reward: 57.473574410493846
20.967398650944233 seconds in game passed.
Action: tensor([[[-0.0021,  0.6179],
         [-0.0017,  0.3328],
         [-0.0022,  0.2283],
         [-0.0030,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.351767, steer=-0.002158, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.473574410493846
20.992398651316762 seconds in game passed.
Action: tensor([[[-0.0021,  0.6179],
         [-0.0017,  0.3328],
         [-0.0022,  0.2283],
         [-0.0030,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.360817, steer=-0.002182, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.473574410493846
21.01739865168929 seconds in game passed.
Action: tensor([[[-0.0021,  0.6179],
         [-0.0017,  0.3328],
         [-0.0022,  0.2283],
         [-0.0030,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.370528, steer=-0.002206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.473574410493846
+++++++++++++: 1.8861525091740332
21.04239865206182 seconds in game passed.
At 21.04239865206182 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6178],
         [-0.0017,  0.3306],
         [-0.0015,  0.2263],
         [-0.0014,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.458297, steer=-0.002169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8861525091740332
Current reward: 0.5239137041771376
Current mitigation activation: 0
#############################
Total reward: 57.997488114670986
21.06739865243435 seconds in game passed.
Action: tensor([[[-0.0020,  0.6178],
         [-0.0017,  0.3306],
         [-0.0015,  0.2263],
         [-0.0014,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.461608, steer=-0.002155, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.997488114670986
21.092398652806878 seconds in game passed.
Action: tensor([[[-0.0020,  0.6178],
         [-0.0017,  0.3306],
         [-0.0015,  0.2263],
         [-0.0014,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.473153, steer=-0.002138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.997488114670986
21.117398653179407 seconds in game passed.
Action: tensor([[[-0.0020,  0.6178],
         [-0.0017,  0.3306],
         [-0.0015,  0.2263],
         [-0.0014,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.484053, steer=-0.002120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.997488114670986
+++++++++++++: 1.9354137390324764
21.142398653551936 seconds in game passed.
At 21.142398653551936 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.2473e-04, 6.0556e-01],
         [6.5709e-04, 3.2625e-01],
         [1.1408e-03, 2.2328e-01],
         [1.5281e-03, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.524185, steer=0.000542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9354137390324764
Current reward: 0.5236630133789499
Current mitigation activation: 0
#############################
Total reward: 58.52115112804994
21.167398653924465 seconds in game passed.
Action: tensor([[[2.2473e-04, 6.0556e-01],
         [6.5709e-04, 3.2625e-01],
         [1.1408e-03, 2.2328e-01],
         [1.5281e-03, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.531461, steer=0.000166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.52115112804994
21.192398654296994 seconds in game passed.
Action: tensor([[[2.2473e-04, 6.0556e-01],
         [6.5709e-04, 3.2625e-01],
         [1.1408e-03, 2.2328e-01],
         [1.5281e-03, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.541236, steer=0.000225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.52115112804994
21.217398654669523 seconds in game passed.
Action: tensor([[[2.2473e-04, 6.0556e-01],
         [6.5709e-04, 3.2625e-01],
         [1.1408e-03, 2.2328e-01],
         [1.5281e-03, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.550151, steer=0.000283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.52115112804994
+++++++++++++: 1.9811422153965232
21.242398655042052 seconds in game passed.
At 21.242398655042052 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0030, 0.6053],
         [0.0036, 0.3266],
         [0.0039, 0.2234],
         [0.0037, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.543576, steer=0.003693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9811422153965232
Current reward: 0.5245825619439934
Current mitigation activation: 0
#############################
Total reward: 59.04573368999393
21.26739865541458 seconds in game passed.
Action: tensor([[[0.0030, 0.6053],
         [0.0036, 0.3266],
         [0.0039, 0.2234],
         [0.0037, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.551471, steer=0.003260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.04573368999393
21.29239865578711 seconds in game passed.
Action: tensor([[[0.0030, 0.6053],
         [0.0036, 0.3266],
         [0.0039, 0.2234],
         [0.0037, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.557215, steer=0.003375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.04573368999393
21.31739865615964 seconds in game passed.
Action: tensor([[[0.0030, 0.6053],
         [0.0036, 0.3266],
         [0.0039, 0.2234],
         [0.0037, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.562403, steer=0.003490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.04573368999393
+++++++++++++: 2.020512512025534
21.34239865653217 seconds in game passed.
At 21.34239865653217 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.6252],
         [0.0026, 0.3324],
         [0.0025, 0.2266],
         [0.0018, 0.1730]]])
agent 0 action: VehicleControl(throttle=0.563161, steer=0.002214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.020512512025534
Current reward: 0.5269053776691297
Current mitigation activation: 0
#############################
Total reward: 59.57263906766306
21.367398656904697 seconds in game passed.
Action: tensor([[[0.0015, 0.6252],
         [0.0026, 0.3324],
         [0.0025, 0.2266],
         [0.0018, 0.1730]]])
agent 0 action: VehicleControl(throttle=0.568568, steer=0.002508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.57263906766306
21.392398657277226 seconds in game passed.
Action: tensor([[[0.0015, 0.6252],
         [0.0026, 0.3324],
         [0.0025, 0.2266],
         [0.0018, 0.1730]]])
agent 0 action: VehicleControl(throttle=0.573749, steer=0.002578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.57263906766306
21.417398657649755 seconds in game passed.
Action: tensor([[[0.0015, 0.6252],
         [0.0026, 0.3324],
         [0.0025, 0.2266],
         [0.0018, 0.1730]]])
agent 0 action: VehicleControl(throttle=0.579099, steer=0.002648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.57263906766306
+++++++++++++: 2.056651989620189
21.442398658022285 seconds in game passed.
At 21.442398658022285 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6079],
         [0.0032, 0.3259],
         [0.0031, 0.2224],
         [0.0024, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.642913, steer=0.003216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.056651989620189
Current reward: 0.5300198107649867
Current mitigation activation: 0
#############################
Total reward: 60.102658878428045
21.467398658394814 seconds in game passed.
Action: tensor([[[0.0020, 0.6079],
         [0.0032, 0.3259],
         [0.0031, 0.2224],
         [0.0024, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.644378, steer=0.003127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.102658878428045
21.492398658767343 seconds in game passed.
Action: tensor([[[0.0020, 0.6079],
         [0.0032, 0.3259],
         [0.0031, 0.2224],
         [0.0024, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.651976, steer=0.003131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.102658878428045
21.51739865913987 seconds in game passed.
Action: tensor([[[0.0020, 0.6079],
         [0.0032, 0.3259],
         [0.0031, 0.2224],
         [0.0024, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.659619, steer=0.003136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.102658878428045
+++++++++++++: 2.0936596572611528
21.5423986595124 seconds in game passed.
At 21.5423986595124 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0021, 0.6096],
         [0.0055, 0.3246],
         [0.0057, 0.2207],
         [0.0049, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.731108, steer=0.004950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0936596572611528
Current reward: 0.5332808401152783
Current mitigation activation: 0
#############################
Total reward: 60.63593971854333
21.56739865988493 seconds in game passed.
Action: tensor([[[0.0021, 0.6096],
         [0.0055, 0.3246],
         [0.0057, 0.2207],
         [0.0049, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.733171, steer=0.004662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.63593971854333
21.59239866025746 seconds in game passed.
Action: tensor([[[0.0021, 0.6096],
         [0.0055, 0.3246],
         [0.0057, 0.2207],
         [0.0049, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.741987, steer=0.004674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.63593971854333
21.617398660629988 seconds in game passed.
Action: tensor([[[0.0021, 0.6096],
         [0.0055, 0.3246],
         [0.0057, 0.2207],
         [0.0049, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.750814, steer=0.004686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.63593971854333
+++++++++++++: 2.1317085007656424
21.642398661002517 seconds in game passed.
At 21.642398661002517 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6217],
         [0.0049, 0.3286],
         [0.0051, 0.2226],
         [0.0042, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.739392, steer=0.004184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1317085007656424
Current reward: 0.5366493360842192
Current mitigation activation: 0
#############################
Total reward: 61.172589054627544
21.667398661375046 seconds in game passed.
Action: tensor([[[0.0020, 0.6217],
         [0.0049, 0.3286],
         [0.0051, 0.2226],
         [0.0042, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.749424, steer=0.004285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.172589054627544
21.692398661747575 seconds in game passed.
Action: tensor([[[0.0020, 0.6217],
         [0.0049, 0.3286],
         [0.0051, 0.2226],
         [0.0042, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.757214, steer=0.004299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.172589054627544
21.717398662120104 seconds in game passed.
Action: tensor([[[0.0020, 0.6217],
         [0.0049, 0.3286],
         [0.0051, 0.2226],
         [0.0042, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.764845, steer=0.004314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.172589054627544
+++++++++++++: 2.170722197113793
21.742398662492633 seconds in game passed.
At 21.742398662492633 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6314],
         [0.0051, 0.3307],
         [0.0050, 0.2238],
         [0.0041, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.791491, steer=0.005046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.170722197113793
Current reward: 0.5401176552402492
Current mitigation activation: 0
#############################
Total reward: 61.712706709867795
21.767398662865162 seconds in game passed.
Action: tensor([[[0.0034, 0.6314],
         [0.0051, 0.3307],
         [0.0050, 0.2238],
         [0.0041, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.796942, steer=0.004961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.712706709867795
21.79239866323769 seconds in game passed.
Action: tensor([[[0.0034, 0.6314],
         [0.0051, 0.3307],
         [0.0050, 0.2238],
         [0.0041, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.804248, steer=0.004994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.712706709867795
21.81739866361022 seconds in game passed.
Action: tensor([[[0.0034, 0.6314],
         [0.0051, 0.3307],
         [0.0050, 0.2238],
         [0.0041, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.811362, steer=0.005026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.712706709867795
+++++++++++++: 2.210655433320663
21.84239866398275 seconds in game passed.
At 21.84239866398275 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0072, 0.6365],
         [0.0105, 0.3325],
         [0.0111, 0.2241],
         [0.0101, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.803904, steer=0.010597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.210655433320663
Current reward: 0.5436733941159106
Current mitigation activation: 0
#############################
Total reward: 62.25638010398371
21.867398664355278 seconds in game passed.
Action: tensor([[[0.0072, 0.6365],
         [0.0105, 0.3325],
         [0.0111, 0.2241],
         [0.0101, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.787687, steer=0.009808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.25638010398371
21.892398664727807 seconds in game passed.
Action: tensor([[[0.0072, 0.6365],
         [0.0105, 0.3325],
         [0.0111, 0.2241],
         [0.0101, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.772931, steer=0.009927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.25638010398371
21.917398665100336 seconds in game passed.
Action: tensor([[[0.0072, 0.6365],
         [0.0105, 0.3325],
         [0.0111, 0.2241],
         [0.0101, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.757300, steer=0.010046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.25638010398371
+++++++++++++: 2.2269894515174604
21.942398665472865 seconds in game passed.
At 21.942398665472865 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0119, 0.6445],
         [0.0179, 0.3359],
         [0.0196, 0.2257],
         [0.0188, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.701052, steer=0.017601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2269894515174604
Current reward: 0.5503700752492616
Current mitigation activation: 0
#############################
Total reward: 62.80675017923297
21.967398665845394 seconds in game passed.
Action: tensor([[[0.0119, 0.6445],
         [0.0179, 0.3359],
         [0.0196, 0.2257],
         [0.0188, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.689299, steer=0.016584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.80675017923297
21.992398666217923 seconds in game passed.
Action: tensor([[[0.0119, 0.6445],
         [0.0179, 0.3359],
         [0.0196, 0.2257],
         [0.0188, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.673335, steer=0.016792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.80675017923297
22.017398666590452 seconds in game passed.
Action: tensor([[[0.0119, 0.6445],
         [0.0179, 0.3359],
         [0.0196, 0.2257],
         [0.0188, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.657480, steer=0.016999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.80675017923297
+++++++++++++: 2.2251988045658218
22.04239866696298 seconds in game passed.
At 22.04239866696298 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0079, 0.6299],
         [0.0078, 0.3316],
         [0.0079, 0.2246],
         [0.0073, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.650518, steer=0.008046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2251988045658218
Current reward: 0.5592566110317485
Current mitigation activation: 0
#############################
Total reward: 63.36600679026472
22.06739866733551 seconds in game passed.
Action: tensor([[[0.0079, 0.6299],
         [0.0078, 0.3316],
         [0.0079, 0.2246],
         [0.0073, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.633479, steer=0.009670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.36600679026472
22.09239866770804 seconds in game passed.
Action: tensor([[[0.0079, 0.6299],
         [0.0078, 0.3316],
         [0.0079, 0.2246],
         [0.0073, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.617655, steer=0.009783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.36600679026472
22.11739866808057 seconds in game passed.
Action: tensor([[[0.0079, 0.6299],
         [0.0078, 0.3316],
         [0.0079, 0.2246],
         [0.0073, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.602248, steer=0.009896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.36600679026472
+++++++++++++: 2.2260966440272303
22.142398668453097 seconds in game passed.
At 22.142398668453097 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6266],
         [0.0049, 0.3306],
         [0.0049, 0.2240],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.588522, steer=0.006204, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2260966440272303
Current reward: 0.56751316881791
Current mitigation activation: 0
#############################
Total reward: 63.93351995908263
22.167398668825626 seconds in game passed.
Action: tensor([[[0.0037, 0.6266],
         [0.0049, 0.3306],
         [0.0049, 0.2240],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.573567, steer=0.006874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.93351995908263
22.192398669198155 seconds in game passed.
Action: tensor([[[0.0037, 0.6266],
         [0.0049, 0.3306],
         [0.0049, 0.2240],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.559259, steer=0.006920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.93351995908263
22.217398669570684 seconds in game passed.
Action: tensor([[[0.0037, 0.6266],
         [0.0049, 0.3306],
         [0.0049, 0.2240],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.545517, steer=0.006967, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.93351995908263
+++++++++++++: 2.231472663594991
22.242398669943213 seconds in game passed.
At 22.242398669943213 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0045, 0.6215],
         [0.0057, 0.3288],
         [0.0056, 0.2231],
         [0.0047, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.547808, steer=0.007861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.231472663594991
Current reward: 0.5749080744815347
Current mitigation activation: 0
#############################
Total reward: 64.50842803356417
22.267398670315742 seconds in game passed.
Action: tensor([[[0.0045, 0.6215],
         [0.0057, 0.3288],
         [0.0056, 0.2231],
         [0.0047, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.533956, steer=0.007737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.50842803356417
22.29239867068827 seconds in game passed.
Action: tensor([[[0.0045, 0.6215],
         [0.0057, 0.3288],
         [0.0056, 0.2231],
         [0.0047, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.522314, steer=0.007759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.50842803356417
22.3173986710608 seconds in game passed.
Action: tensor([[[0.0045, 0.6215],
         [0.0057, 0.3288],
         [0.0056, 0.2231],
         [0.0047, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.511157, steer=0.007780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.50842803356417
+++++++++++++: 2.2418987592543584
22.34239867143333 seconds in game passed.
At 22.34239867143333 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6171],
         [0.0027, 0.3269],
         [0.0021, 0.2222],
         [0.0008, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.523038, steer=0.004533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2418987592543584
Current reward: 0.581402384578882
Current mitigation activation: 0
#############################
Total reward: 65.08983041814305
22.36739867180586 seconds in game passed.
Action: tensor([[[0.0018, 0.6171],
         [0.0027, 0.3269],
         [0.0021, 0.2222],
         [0.0008, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.510860, steer=0.005076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.08983041814305
22.392398672178388 seconds in game passed.
Action: tensor([[[0.0018, 0.6171],
         [0.0027, 0.3269],
         [0.0021, 0.2222],
         [0.0008, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.501505, steer=0.005078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.08983041814305
22.417398672550917 seconds in game passed.
Action: tensor([[[0.0018, 0.6171],
         [0.0027, 0.3269],
         [0.0021, 0.2222],
         [0.0008, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.492492, steer=0.005080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.08983041814305
+++++++++++++: 2.256841238747506
22.442398672923446 seconds in game passed.
At 22.442398672923446 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.6424e-03, 6.1524e-01],
         [2.0275e-03, 3.2706e-01],
         [1.4837e-03, 2.2265e-01],
         [3.8089e-04, 1.7061e-01]]])
agent 0 action: VehicleControl(throttle=0.458953, steer=0.004517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.256841238747506
Current reward: 0.5871096323254388
Current mitigation activation: 0
#############################
Total reward: 65.67694005046849
22.467398673295975 seconds in game passed.
Action: tensor([[[1.6424e-03, 6.1524e-01],
         [2.0275e-03, 3.2706e-01],
         [1.4837e-03, 2.2265e-01],
         [3.8089e-04, 1.7061e-01]]])
agent 0 action: VehicleControl(throttle=0.452390, steer=0.004599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.67694005046849
22.492398673668504 seconds in game passed.
Action: tensor([[[1.6424e-03, 6.1524e-01],
         [2.0275e-03, 3.2706e-01],
         [1.4837e-03, 2.2265e-01],
         [3.8089e-04, 1.7061e-01]]])
agent 0 action: VehicleControl(throttle=0.443713, steer=0.004589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.67694005046849
22.517398674041033 seconds in game passed.
Action: tensor([[[1.6424e-03, 6.1524e-01],
         [2.0275e-03, 3.2706e-01],
         [1.4837e-03, 2.2265e-01],
         [3.8089e-04, 1.7061e-01]]])
agent 0 action: VehicleControl(throttle=0.435653, steer=0.004579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.67694005046849
+++++++++++++: 2.2754230826822304
22.542398674413562 seconds in game passed.
At 22.542398674413562 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.1067e-03, 6.1170e-01],
         [2.1668e-03, 3.2591e-01],
         [1.6731e-03, 2.2227e-01],
         [5.5890e-04, 1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.432897, steer=0.004836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2754230826822304
Current reward: 0.5921927764504598
Current mitigation activation: 0
#############################
Total reward: 66.26913282691895
22.56739867478609 seconds in game passed.
Action: tensor([[[2.1067e-03, 6.1170e-01],
         [2.1668e-03, 3.2591e-01],
         [1.6731e-03, 2.2227e-01],
         [5.5890e-04, 1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.424690, steer=0.004764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.26913282691895
22.59239867515862 seconds in game passed.
Action: tensor([[[2.1067e-03, 6.1170e-01],
         [2.1668e-03, 3.2591e-01],
         [1.6731e-03, 2.2227e-01],
         [5.5890e-04, 1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.417552, steer=0.004738, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.26913282691895
22.61739867553115 seconds in game passed.
Action: tensor([[[2.1067e-03, 6.1170e-01],
         [2.1668e-03, 3.2591e-01],
         [1.6731e-03, 2.2227e-01],
         [5.5890e-04, 1.7013e-01]]])
agent 0 action: VehicleControl(throttle=0.410849, steer=0.004712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.26913282691895
+++++++++++++: 2.2981483798092697
22.642398675903678 seconds in game passed.
At 22.642398675903678 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0029, 0.6231],
         [0.0042, 0.3297],
         [0.0041, 0.2241],
         [0.0032, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.383380, steer=0.006482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2981483798092697
Current reward: 0.5966313114714099
Current mitigation activation: 0
#############################
Total reward: 66.86576413839036
22.667398676276207 seconds in game passed.
Action: tensor([[[0.0029, 0.6231],
         [0.0042, 0.3297],
         [0.0041, 0.2241],
         [0.0032, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.379779, steer=0.006185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.86576413839036
22.692398676648736 seconds in game passed.
Action: tensor([[[0.0029, 0.6231],
         [0.0042, 0.3297],
         [0.0041, 0.2241],
         [0.0032, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.374386, steer=0.006183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.86576413839036
22.717398677021265 seconds in game passed.
Action: tensor([[[0.0029, 0.6231],
         [0.0042, 0.3297],
         [0.0041, 0.2241],
         [0.0032, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.369548, steer=0.006181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.86576413839036
+++++++++++++: 2.324838611766337
22.742398677393794 seconds in game passed.
At 22.742398677393794 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6253],
         [0.0058, 0.3310],
         [0.0060, 0.2245],
         [0.0053, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.340216, steer=0.007795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.324838611766337
Current reward: 0.600503006417173
Current mitigation activation: 0
#############################
Total reward: 67.46626714480753
22.767398677766323 seconds in game passed.
Action: tensor([[[0.0039, 0.6253],
         [0.0058, 0.3310],
         [0.0060, 0.2245],
         [0.0053, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.338449, steer=0.007535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.46626714480753
22.792398678138852 seconds in game passed.
Action: tensor([[[0.0039, 0.6253],
         [0.0058, 0.3310],
         [0.0060, 0.2245],
         [0.0053, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.334561, steer=0.007542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.46626714480753
22.81739867851138 seconds in game passed.
Action: tensor([[[0.0039, 0.6253],
         [0.0058, 0.3310],
         [0.0060, 0.2245],
         [0.0053, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.331256, steer=0.007550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.46626714480753
+++++++++++++: 2.355710347378674
22.84239867888391 seconds in game passed.
At 22.84239867888391 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6066],
         [0.0023, 0.3271],
         [0.0018, 0.2235],
         [0.0009, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.276571, steer=0.004213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.355710347378674
Current reward: 0.6038356130037112
Current mitigation activation: 0
#############################
Total reward: 68.07010275781124
22.86739867925644 seconds in game passed.
Action: tensor([[[0.0022, 0.6066],
         [0.0023, 0.3271],
         [0.0018, 0.2235],
         [0.0009, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.279538, steer=0.004672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.07010275781124
22.89239867962897 seconds in game passed.
Action: tensor([[[0.0022, 0.6066],
         [0.0023, 0.3271],
         [0.0018, 0.2235],
         [0.0009, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.277762, steer=0.004589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.07010275781124
22.917398680001497 seconds in game passed.
Action: tensor([[[0.0022, 0.6066],
         [0.0023, 0.3271],
         [0.0018, 0.2235],
         [0.0009, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.277041, steer=0.004506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.07010275781124
+++++++++++++: 2.3910421380529443
22.942398680374026 seconds in game passed.
At 22.942398680374026 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0304e-03, 6.1440e-01],
         [1.6696e-03, 3.2740e-01],
         [1.3034e-03, 2.2277e-01],
         [3.2584e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.349415, steer=0.003428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3910421380529443
Current reward: 0.6066459699625086
Current mitigation activation: 0
#############################
Total reward: 68.67674872777376
22.967398680746555 seconds in game passed.
Action: tensor([[[1.0304e-03, 6.1440e-01],
         [1.6696e-03, 3.2740e-01],
         [1.3034e-03, 2.2277e-01],
         [3.2584e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.343951, steer=0.003410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.67674872777376
22.992398681119084 seconds in game passed.
Action: tensor([[[1.0304e-03, 6.1440e-01],
         [1.6696e-03, 3.2740e-01],
         [1.3034e-03, 2.2277e-01],
         [3.2584e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.346571, steer=0.003241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.67674872777376
23.017398681491613 seconds in game passed.
Action: tensor([[[1.0304e-03, 6.1440e-01],
         [1.6696e-03, 3.2740e-01],
         [1.3034e-03, 2.2277e-01],
         [3.2584e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.349192, steer=0.003072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.67674872777376
+++++++++++++: 2.4310590692966727
23.042398681864142 seconds in game passed.
At 23.042398681864142 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.6244],
         [-0.0007,  0.3303],
         [-0.0012,  0.2239],
         [-0.0022,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.348510, steer=0.000143, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4310590692966727
Current reward: 0.6089672113797795
Current mitigation activation: 0
#############################
Total reward: 69.28571593915353
23.06739868223667 seconds in game passed.
Action: tensor([[[-0.0018,  0.6244],
         [-0.0007,  0.3303],
         [-0.0012,  0.2239],
         [-0.0022,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.351588, steer=0.000510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.28571593915353
23.0923986826092 seconds in game passed.
Action: tensor([[[-0.0018,  0.6244],
         [-0.0007,  0.3303],
         [-0.0012,  0.2239],
         [-0.0022,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.354426, steer=0.000406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.28571593915353
23.11739868298173 seconds in game passed.
Action: tensor([[[-0.0018,  0.6244],
         [-0.0007,  0.3303],
         [-0.0012,  0.2239],
         [-0.0022,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.357394, steer=0.000302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.28571593915353
+++++++++++++: 2.472073294389387
23.14239868335426 seconds in game passed.
At 23.14239868335426 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6071],
         [-0.0016,  0.3249],
         [-0.0022,  0.2211],
         [-0.0033,  0.1683]]])
agent 0 action: VehicleControl(throttle=0.381178, steer=-0.000533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.472073294389387
Current reward: 0.6113122292319075
Current mitigation activation: 0
#############################
Total reward: 69.89702816838545
23.167398683726788 seconds in game passed.
Action: tensor([[[-0.0020,  0.6071],
         [-0.0016,  0.3249],
         [-0.0022,  0.2211],
         [-0.0033,  0.1683]]])
agent 0 action: VehicleControl(throttle=0.382358, steer=-0.000479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.89702816838545
23.192398684099317 seconds in game passed.
Action: tensor([[[-0.0020,  0.6071],
         [-0.0016,  0.3249],
         [-0.0022,  0.2211],
         [-0.0033,  0.1683]]])
agent 0 action: VehicleControl(throttle=0.385752, steer=-0.000552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.89702816838545
23.217398684471846 seconds in game passed.
Action: tensor([[[-0.0020,  0.6071],
         [-0.0016,  0.3249],
         [-0.0022,  0.2211],
         [-0.0033,  0.1683]]])
agent 0 action: VehicleControl(throttle=0.389032, steer=-0.000625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.89702816838545
+++++++++++++: 2.512592036884929
23.242398684844375 seconds in game passed.
At 23.242398684844375 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6171],
         [-0.0037,  0.3285],
         [-0.0041,  0.2232],
         [-0.0048,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.363911, steer=-0.002766, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.512592036884929
Current reward: 0.6138602951354719
Current mitigation activation: 0
#############################
Total reward: 70.51088846352091
23.267398685216904 seconds in game passed.
Action: tensor([[[-0.0033,  0.6171],
         [-0.0037,  0.3285],
         [-0.0041,  0.2232],
         [-0.0048,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.369555, steer=-0.002530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.51088846352091
23.292398685589433 seconds in game passed.
Action: tensor([[[-0.0033,  0.6171],
         [-0.0037,  0.3285],
         [-0.0041,  0.2232],
         [-0.0048,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.372235, steer=-0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.51088846352091
23.31739868596196 seconds in game passed.
Action: tensor([[[-0.0033,  0.6171],
         [-0.0037,  0.3285],
         [-0.0041,  0.2232],
         [-0.0048,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.375086, steer=-0.002737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.51088846352091
+++++++++++++: 2.551933543004432
23.34239868633449 seconds in game passed.
At 23.34239868633449 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6046],
         [-0.0018,  0.3254],
         [-0.0021,  0.2219],
         [-0.0026,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.359083, steer=-0.000559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.551933543004432
Current reward: 0.6166710878526305
Current mitigation activation: 0
#############################
Total reward: 71.12755955137355
23.36739868670702 seconds in game passed.
Action: tensor([[[-0.0011,  0.6046],
         [-0.0018,  0.3254],
         [-0.0021,  0.2219],
         [-0.0026,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.363626, steer=-0.000976, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.12755955137355
23.39239868707955 seconds in game passed.
Action: tensor([[[-0.0011,  0.6046],
         [-0.0018,  0.3254],
         [-0.0021,  0.2219],
         [-0.0026,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.366287, steer=-0.001022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.12755955137355
23.417398687452078 seconds in game passed.
Action: tensor([[[-0.0011,  0.6046],
         [-0.0018,  0.3254],
         [-0.0021,  0.2219],
         [-0.0026,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.369143, steer=-0.001069, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.12755955137355
+++++++++++++: 2.591007549164248
23.442398687824607 seconds in game passed.
At 23.442398687824607 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.6604e-04,  6.1196e-01],
         [-6.4232e-04,  3.2839e-01],
         [-1.0627e-03,  2.2344e-01],
         [-1.7667e-03,  1.7015e-01]]])
agent 0 action: VehicleControl(throttle=0.340103, steer=0.000020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.591007549164248
Current reward: 0.6196142433638501
Current mitigation activation: 0
#############################
Total reward: 71.7471737947374
23.467398688197136 seconds in game passed.
Action: tensor([[[-4.6604e-04,  6.1196e-01],
         [-6.4232e-04,  3.2839e-01],
         [-1.0627e-03,  2.2344e-01],
         [-1.7667e-03,  1.7015e-01]]])
agent 0 action: VehicleControl(throttle=0.346505, steer=-0.000196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.7471737947374
23.492398688569665 seconds in game passed.
Action: tensor([[[-4.6604e-04,  6.1196e-01],
         [-6.4232e-04,  3.2839e-01],
         [-1.0627e-03,  2.2344e-01],
         [-1.7667e-03,  1.7015e-01]]])
agent 0 action: VehicleControl(throttle=0.349641, steer=-0.000225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.7471737947374
23.517398688942194 seconds in game passed.
Action: tensor([[[-4.6604e-04,  6.1196e-01],
         [-6.4232e-04,  3.2839e-01],
         [-1.0627e-03,  2.2344e-01],
         [-1.7667e-03,  1.7015e-01]]])
agent 0 action: VehicleControl(throttle=0.353083, steer=-0.000254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.7471737947374
+++++++++++++: 2.6307058857194265
23.542398689314723 seconds in game passed.
At 23.542398689314723 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.4553e-04,  6.1459e-01],
         [-3.5856e-04,  3.2949e-01],
         [-1.1309e-03,  2.2415e-01],
         [-2.1827e-03,  1.7054e-01]]])
agent 0 action: VehicleControl(throttle=0.344164, steer=-0.000187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6307058857194265
Current reward: 0.6225793643729329
Current mitigation activation: 0
#############################
Total reward: 72.36975315911035
23.567398689687252 seconds in game passed.
Action: tensor([[[-7.4553e-04,  6.1459e-01],
         [-3.5856e-04,  3.2949e-01],
         [-1.1309e-03,  2.2415e-01],
         [-2.1827e-03,  1.7054e-01]]])
agent 0 action: VehicleControl(throttle=0.349051, steer=-0.000234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.36975315911035
23.59239869005978 seconds in game passed.
Action: tensor([[[-7.4553e-04,  6.1459e-01],
         [-3.5856e-04,  3.2949e-01],
         [-1.1309e-03,  2.2415e-01],
         [-2.1827e-03,  1.7054e-01]]])
agent 0 action: VehicleControl(throttle=0.352741, steer=-0.000265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.36975315911035
23.61739869043231 seconds in game passed.
Action: tensor([[[-7.4553e-04,  6.1459e-01],
         [-3.5856e-04,  3.2949e-01],
         [-1.1309e-03,  2.2415e-01],
         [-2.1827e-03,  1.7054e-01]]])
agent 0 action: VehicleControl(throttle=0.356587, steer=-0.000296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.36975315911035
+++++++++++++: 2.6716591912952734
23.64239869080484 seconds in game passed.
At 23.64239869080484 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.8558e-03,  6.2329e-01],
         [ 1.3702e-03,  3.3136e-01],
         [ 6.3764e-04,  2.2590e-01],
         [-2.1989e-04,  1.7173e-01]]])
agent 0 action: VehicleControl(throttle=0.382786, steer=0.002757, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6716591912952734
Current reward: 0.6254943738950676
Current mitigation activation: 0
#############################
Total reward: 72.99524753300541
23.667398691177368 seconds in game passed.
Action: tensor([[[ 3.8558e-03,  6.2329e-01],
         [ 1.3702e-03,  3.3136e-01],
         [ 6.3764e-04,  2.2590e-01],
         [-2.1989e-04,  1.7173e-01]]])
agent 0 action: VehicleControl(throttle=0.384905, steer=0.002228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.99524753300541
23.692398691549897 seconds in game passed.
Action: tensor([[[ 3.8558e-03,  6.2329e-01],
         [ 1.3702e-03,  3.3136e-01],
         [ 6.3764e-04,  2.2590e-01],
         [-2.1989e-04,  1.7173e-01]]])
agent 0 action: VehicleControl(throttle=0.389310, steer=0.002210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.99524753300541
23.717398691922426 seconds in game passed.
Action: tensor([[[ 3.8558e-03,  6.2329e-01],
         [ 1.3702e-03,  3.3136e-01],
         [ 6.3764e-04,  2.2590e-01],
         [-2.1989e-04,  1.7173e-01]]])
agent 0 action: VehicleControl(throttle=0.393492, steer=0.002193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.99524753300541
+++++++++++++: 2.7133774255835936
23.742398692294955 seconds in game passed.
At 23.742398692294955 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4095e-03,  6.1987e-01],
         [-1.6112e-04,  3.2884e-01],
         [-5.2925e-04,  2.2431e-01],
         [-8.6012e-04,  1.7047e-01]]])
agent 0 action: VehicleControl(throttle=0.453709, steer=0.000448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7133774255835936
Current reward: 0.6284249742471173
Current mitigation activation: 0
#############################
Total reward: 73.62367250725252
23.767398692667484 seconds in game passed.
Action: tensor([[[ 2.4095e-03,  6.1987e-01],
         [-1.6112e-04,  3.2884e-01],
         [-5.2925e-04,  2.2431e-01],
         [-8.6012e-04,  1.7047e-01]]])
agent 0 action: VehicleControl(throttle=0.452477, steer=0.000679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.62367250725252
23.792398693040013 seconds in game passed.
Action: tensor([[[ 2.4095e-03,  6.1987e-01],
         [-1.6112e-04,  3.2884e-01],
         [-5.2925e-04,  2.2431e-01],
         [-8.6012e-04,  1.7047e-01]]])
agent 0 action: VehicleControl(throttle=0.456808, steer=0.000627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.62367250725252
23.817398693412542 seconds in game passed.
Action: tensor([[[ 2.4095e-03,  6.1987e-01],
         [-1.6112e-04,  3.2884e-01],
         [-5.2925e-04,  2.2431e-01],
         [-8.6012e-04,  1.7047e-01]]])
agent 0 action: VehicleControl(throttle=0.460452, steer=0.000575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.62367250725252
+++++++++++++: 2.7537846836839366
23.84239869378507 seconds in game passed.
At 23.84239869378507 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.1238e-04,  6.1738e-01],
         [-3.0952e-03,  3.2865e-01],
         [-3.5295e-03,  2.2405e-01],
         [-3.8497e-03,  1.7012e-01]]])
agent 0 action: VehicleControl(throttle=0.445541, steer=-0.002693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7537846836839366
Current reward: 0.631593269948673
Current mitigation activation: 0
#############################
Total reward: 74.25526577720119
23.8673986941576 seconds in game passed.
Action: tensor([[[-3.1238e-04,  6.1738e-01],
         [-3.0952e-03,  3.2865e-01],
         [-3.5295e-03,  2.2405e-01],
         [-3.8497e-03,  1.7012e-01]]])
agent 0 action: VehicleControl(throttle=0.450504, steer=-0.002208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.25526577720119
23.89239869453013 seconds in game passed.
Action: tensor([[[-3.1238e-04,  6.1738e-01],
         [-3.0952e-03,  3.2865e-01],
         [-3.5295e-03,  2.2405e-01],
         [-3.8497e-03,  1.7012e-01]]])
agent 0 action: VehicleControl(throttle=0.453113, steer=-0.002260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.25526577720119
23.91739869490266 seconds in game passed.
Action: tensor([[[-3.1238e-04,  6.1738e-01],
         [-3.0952e-03,  3.2865e-01],
         [-3.5295e-03,  2.2405e-01],
         [-3.8497e-03,  1.7012e-01]]])
agent 0 action: VehicleControl(throttle=0.455449, steer=-0.002311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.25526577720119
+++++++++++++: 2.7902502425552482
23.942398695275187 seconds in game passed.
At 23.942398695275187 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.6145],
         [-0.0033,  0.3282],
         [-0.0039,  0.2233],
         [-0.0046,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.444017, steer=-0.002752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7902502425552482
Current reward: 0.6352457953587916
Current mitigation activation: 0
#############################
Total reward: 74.89051157255997
23.967398695647717 seconds in game passed.
Action: tensor([[[-0.0010,  0.6145],
         [-0.0033,  0.3282],
         [-0.0039,  0.2233],
         [-0.0046,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.446197, steer=-0.002732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.89051157255997
23.992398696020246 seconds in game passed.
Action: tensor([[[-0.0010,  0.6145],
         [-0.0033,  0.3282],
         [-0.0039,  0.2233],
         [-0.0046,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.446809, steer=-0.002778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.89051157255997
24.017398696392775 seconds in game passed.
Action: tensor([[[-0.0010,  0.6145],
         [-0.0033,  0.3282],
         [-0.0039,  0.2233],
         [-0.0046,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.447294, steer=-0.002824, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.89051157255997
+++++++++++++: 2.823887205451917
24.042398696765304 seconds in game passed.
At 24.042398696765304 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0043,  0.6106],
         [-0.0067,  0.3272],
         [-0.0072,  0.2227],
         [-0.0077,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.444559, steer=-0.006693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.823887205451917
Current reward: 0.6392176899193256
Current mitigation activation: 0
#############################
Total reward: 75.5297292624793
24.067398697137833 seconds in game passed.
Action: tensor([[[-0.0043,  0.6106],
         [-0.0067,  0.3272],
         [-0.0072,  0.2227],
         [-0.0077,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.445100, steer=-0.006114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.5297292624793
24.09239869751036 seconds in game passed.
Action: tensor([[[-0.0043,  0.6106],
         [-0.0067,  0.3272],
         [-0.0072,  0.2227],
         [-0.0077,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.445236, steer=-0.006170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.5297292624793
24.11739869788289 seconds in game passed.
Action: tensor([[[-0.0043,  0.6106],
         [-0.0067,  0.3272],
         [-0.0072,  0.2227],
         [-0.0077,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.445258, steer=-0.006226, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.5297292624793
+++++++++++++: 2.856410938652771
24.14239869825542 seconds in game passed.
At 24.14239869825542 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.4972e-04,  6.0538e-01],
         [-7.7076e-05,  3.2531e-01],
         [ 4.0675e-04,  2.2192e-01],
         [ 6.2178e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.457299, steer=0.000240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.856410938652771
Current reward: 0.6432986257802111
Current mitigation activation: 0
#############################
Total reward: 76.1730278882595
24.16739869862795 seconds in game passed.
Action: tensor([[[-2.4972e-04,  6.0538e-01],
         [-7.7076e-05,  3.2531e-01],
         [ 4.0675e-04,  2.2192e-01],
         [ 6.2178e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.455744, steer=-0.000815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.1730278882595
24.192398699000478 seconds in game passed.
Action: tensor([[[-2.4972e-04,  6.0538e-01],
         [-7.7076e-05,  3.2531e-01],
         [ 4.0675e-04,  2.2192e-01],
         [ 6.2178e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.455376, steer=-0.000797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.1730278882595
24.217398699373007 seconds in game passed.
Action: tensor([[[-2.4972e-04,  6.0538e-01],
         [-7.7076e-05,  3.2531e-01],
         [ 4.0675e-04,  2.2192e-01],
         [ 6.2178e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.454829, steer=-0.000778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.1730278882595
+++++++++++++: 2.888430434444321
24.242398699745536 seconds in game passed.
At 24.242398699745536 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.3094e-04, 6.0309e-01],
         [1.1947e-03, 3.2549e-01],
         [1.4634e-03, 2.2209e-01],
         [1.2027e-03, 1.6845e-01]]])
agent 0 action: VehicleControl(throttle=0.423147, steer=0.000391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.888430434444321
Current reward: 0.6474209200533776
Current mitigation activation: 0
#############################
Total reward: 76.82044880831288
24.267398700118065 seconds in game passed.
Action: tensor([[[2.3094e-04, 6.0309e-01],
         [1.1947e-03, 3.2549e-01],
         [1.4634e-03, 2.2209e-01],
         [1.2027e-03, 1.6845e-01]]])
agent 0 action: VehicleControl(throttle=0.425649, steer=0.000257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.82044880831288
24.292398700490594 seconds in game passed.
Action: tensor([[[2.3094e-04, 6.0309e-01],
         [1.1947e-03, 3.2549e-01],
         [1.4634e-03, 2.2209e-01],
         [1.2027e-03, 1.6845e-01]]])
agent 0 action: VehicleControl(throttle=0.424830, steer=0.000308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.82044880831288
24.317398700863123 seconds in game passed.
Action: tensor([[[2.3094e-04, 6.0309e-01],
         [1.1947e-03, 3.2549e-01],
         [1.4634e-03, 2.2209e-01],
         [1.2027e-03, 1.6845e-01]]])
agent 0 action: VehicleControl(throttle=0.424196, steer=0.000360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.82044880831288
+++++++++++++: 2.919891008595545
24.342398701235652 seconds in game passed.
At 24.342398701235652 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.6028],
         [0.0015, 0.3254],
         [0.0013, 0.2223],
         [0.0008, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.424718, steer=0.000905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.919891008595545
Current reward: 0.6515857284607015
Current mitigation activation: 0
#############################
Total reward: 77.47203453677358
24.36739870160818 seconds in game passed.
Action: tensor([[[0.0010, 0.6028],
         [0.0015, 0.3254],
         [0.0013, 0.2223],
         [0.0008, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.424408, steer=0.000854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.47203453677358
24.39239870198071 seconds in game passed.
Action: tensor([[[0.0010, 0.6028],
         [0.0015, 0.3254],
         [0.0013, 0.2223],
         [0.0008, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.424260, steer=0.000887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.47203453677358
24.41739870235324 seconds in game passed.
Action: tensor([[[0.0010, 0.6028],
         [0.0015, 0.3254],
         [0.0013, 0.2223],
         [0.0008, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.424161, steer=0.000921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.47203453677358
+++++++++++++: 2.952223755899205
24.442398702725768 seconds in game passed.
At 24.442398702725768 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.6078],
         [0.0025, 0.3261],
         [0.0026, 0.2229],
         [0.0021, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.451854, steer=0.002393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.952223755899205
Current reward: 0.6556387809978501
Current mitigation activation: 0
#############################
Total reward: 78.12767331777142
24.467398703098297 seconds in game passed.
Action: tensor([[[0.0027, 0.6078],
         [0.0025, 0.3261],
         [0.0026, 0.2229],
         [0.0021, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.449576, steer=0.002191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.12767331777142
24.492398703470826 seconds in game passed.
Action: tensor([[[0.0027, 0.6078],
         [0.0025, 0.3261],
         [0.0026, 0.2229],
         [0.0021, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.450141, steer=0.002228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.12767331777142
24.517398703843355 seconds in game passed.
Action: tensor([[[0.0027, 0.6078],
         [0.0025, 0.3261],
         [0.0026, 0.2229],
         [0.0021, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.450466, steer=0.002266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.12767331777142
+++++++++++++: 2.985356490079209
24.542398704215884 seconds in game passed.
At 24.542398704215884 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6100],
         [0.0018, 0.3266],
         [0.0020, 0.2228],
         [0.0021, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.455502, steer=0.001709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.985356490079209
Current reward: 0.6595966718471938
Current mitigation activation: 0
#############################
Total reward: 78.78726998961862
24.567398704588413 seconds in game passed.
Action: tensor([[[0.0026, 0.6100],
         [0.0018, 0.3266],
         [0.0020, 0.2228],
         [0.0021, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.455194, steer=0.001837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.78726998961862
24.592398704960942 seconds in game passed.
Action: tensor([[[0.0026, 0.6100],
         [0.0018, 0.3266],
         [0.0020, 0.2228],
         [0.0021, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.455232, steer=0.001867, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.78726998961862
24.61739870533347 seconds in game passed.
Action: tensor([[[0.0026, 0.6100],
         [0.0018, 0.3266],
         [0.0020, 0.2228],
         [0.0021, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.455100, steer=0.001897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.78726998961862
+++++++++++++: 3.0176784246627735
24.642398705706 seconds in game passed.
At 24.642398705706 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3679e-04,  6.2397e-01],
         [-4.6826e-04,  3.2824e-01],
         [-6.2983e-04,  2.2295e-01],
         [-7.3913e-04,  1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.538430, steer=-0.000748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0176784246627735
Current reward: 0.6636204958473177
Current mitigation activation: 0
#############################
Total reward: 79.45089048546593
24.66739870607853 seconds in game passed.
Action: tensor([[[ 1.3679e-04,  6.2397e-01],
         [-4.6826e-04,  3.2824e-01],
         [-6.2983e-04,  2.2295e-01],
         [-7.3913e-04,  1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.529820, steer=-0.000341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.45089048546593
24.69239870645106 seconds in game passed.
Action: tensor([[[ 1.3679e-04,  6.2397e-01],
         [-4.6826e-04,  3.2824e-01],
         [-6.2983e-04,  2.2295e-01],
         [-7.3913e-04,  1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.529766, steer=-0.000370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.45089048546593
24.717398706823587 seconds in game passed.
Action: tensor([[[ 1.3679e-04,  6.2397e-01],
         [-4.6826e-04,  3.2824e-01],
         [-6.2983e-04,  2.2295e-01],
         [-7.3913e-04,  1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.528894, steer=-0.000400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.45089048546593
+++++++++++++: 3.048325421227874
24.742398707196116 seconds in game passed.
At 24.742398707196116 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6119],
         [-0.0032,  0.3256],
         [-0.0038,  0.2219],
         [-0.0041,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.499816, steer=-0.002922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.048325421227874
Current reward: 0.6677727688308126
Current mitigation activation: 0
#############################
Total reward: 80.11866325429675
24.767398707568645 seconds in game passed.
Action: tensor([[[-0.0011,  0.6119],
         [-0.0032,  0.3256],
         [-0.0038,  0.2219],
         [-0.0041,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.499831, steer=-0.002546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.11866325429675
24.792398707941175 seconds in game passed.
Action: tensor([[[-0.0011,  0.6119],
         [-0.0032,  0.3256],
         [-0.0038,  0.2219],
         [-0.0041,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.496663, steer=-0.002583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.11866325429675
24.817398708313704 seconds in game passed.
Action: tensor([[[-0.0011,  0.6119],
         [-0.0032,  0.3256],
         [-0.0038,  0.2219],
         [-0.0041,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.493396, steer=-0.002621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.11866325429675
+++++++++++++: 3.0747697633736104
24.842398708686233 seconds in game passed.
At 24.842398708686233 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.6199],
         [-0.0072,  0.3285],
         [-0.0079,  0.2231],
         [-0.0079,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.467831, steer=-0.006498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0747697633736104
Current reward: 0.6722295181242365
Current mitigation activation: 0
#############################
Total reward: 80.79089277242099
24.86739870905876 seconds in game passed.
Action: tensor([[[-0.0034,  0.6199],
         [-0.0072,  0.3285],
         [-0.0079,  0.2231],
         [-0.0079,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.466744, steer=-0.005903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.79089277242099
24.89239870943129 seconds in game passed.
Action: tensor([[[-0.0034,  0.6199],
         [-0.0072,  0.3285],
         [-0.0079,  0.2231],
         [-0.0079,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.463367, steer=-0.005947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.79089277242099
24.91739870980382 seconds in game passed.
Action: tensor([[[-0.0034,  0.6199],
         [-0.0072,  0.3285],
         [-0.0079,  0.2231],
         [-0.0079,  0.1694]]])
agent 0 action: VehicleControl(throttle=0.460163, steer=-0.005991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.79089277242099
+++++++++++++: 3.0992697086984076
24.94239871017635 seconds in game passed.
At 24.94239871017635 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.6131],
         [-0.0050,  0.3267],
         [-0.0050,  0.2224],
         [-0.0047,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.450915, steer=-0.004111, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0992697086984076
Current reward: 0.6760036171789333
Current mitigation activation: 0
#############################
Total reward: 81.46689638959992
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:02:07 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:02:54 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 46.94s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.45s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.5                 │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 81.47, average_reward: 81.46689638959992 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00003/fi_lead_slowdown_data
