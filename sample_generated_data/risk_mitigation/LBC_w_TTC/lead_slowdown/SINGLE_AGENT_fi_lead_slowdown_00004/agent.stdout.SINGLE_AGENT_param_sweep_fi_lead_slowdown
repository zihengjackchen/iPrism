New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190310-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190310-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190310-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190310-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190310-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190310-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 33.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 33}
1.5863693170249462 seconds in game passed.
Action: tensor([[[0.0034, 0.5920],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003161, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6113693173974752 seconds in game passed.
Action: tensor([[[0.0034, 0.5920],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6363693177700043 seconds in game passed.
Action: tensor([[[0.0034, 0.5920],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002705, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6613693181425333 seconds in game passed.
Action: tensor([[[0.0034, 0.5920],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6863693185150623 seconds in game passed.
Action: tensor([[[0.0034, 0.5920],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7113693188875914 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003970, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7363693192601204 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7613693196326494 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7863693200051785 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8113693203777075 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.8363693207502365 seconds in game passed.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8613693211227655 seconds in game passed.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8863693214952946 seconds in game passed.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9113693218678236 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9363693222403526 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9613693226128817 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002659, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9863693229854107 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0113693233579397 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0363693237304688 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.061369324102998 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.086369324475527 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.111369324848056 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4306e-03, 5.9057e-01],
         [1.3304e-03, 3.2232e-01],
         [1.1062e-03, 2.2211e-01],
         [5.6431e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.136369325220585 seconds in game passed.
Action: tensor([[[2.4306e-03, 5.9057e-01],
         [1.3304e-03, 3.2232e-01],
         [1.1062e-03, 2.2211e-01],
         [5.6431e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.161369325593114 seconds in game passed.
Action: tensor([[[2.4306e-03, 5.9057e-01],
         [1.3304e-03, 3.2232e-01],
         [1.1062e-03, 2.2211e-01],
         [5.6431e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.186369325965643 seconds in game passed.
Action: tensor([[[2.4306e-03, 5.9057e-01],
         [1.3304e-03, 3.2232e-01],
         [1.1062e-03, 2.2211e-01],
         [5.6431e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.211369326338172 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.236369326710701 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.26136932708323 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002502, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.286369327455759 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.311369327828288 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.336369328200817 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.361369328573346 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.386369328945875 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.411369329318404 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4363693296909332 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4613693300634623 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4863693304359913 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5113693308085203 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002766, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5363693311810493 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5613693315535784 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002807, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5863693319261074 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6113693322986364 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6363693326711655 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6613693330436945 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6863693334162235 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7113693337887526 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.7363693341612816 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7613693345338106 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7863693349063396 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.8113693352788687 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.8363693356513977 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8613693360239267 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8863693363964558 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.911369336768985 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.936369337141514 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.961369337514043 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.986369337886572 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.011369338259101 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.03636933863163 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.061369339004159 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.086369339376688 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.111369339749217 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.136369340121746 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.161369340494275 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.186369340866804 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.211369341239333 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.236369341611862 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.261369341984391 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2863693423569202 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3113693427294493 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3363693431019783 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3613693434745073 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3863693438470364 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4113693442195654 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4363693445920944 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4613693449646235 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4863693453371525 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5113693457096815 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5363693460822105 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5613693464547396 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5863693468272686 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6113693471997976 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6363693475723267 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6613693479448557 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6863693483173847 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7113693486899137 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.736369349062443 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.761369349434972 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.786369349807501 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.81136935018003 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.836369350552559 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.861369350925088 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.886369351297617 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.911369351670146 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.936369352042675 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.961369352415204 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.986369352787733 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
4.011369353160262 seconds in game passed.
At 4.011369353160262 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0.06602266588708589
4.036369353532791 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.06136935390532 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.086369354277849 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
+++++++++++++: 19.655274201662667
4.111369354650378 seconds in game passed.
At 4.111369354650378 seconds, saving state-action tuples.
Action: tensor([[[1.4123e-03, 5.8600e-01],
         [1.1414e-03, 3.2064e-01],
         [1.0107e-03, 2.2099e-01],
         [3.6184e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.3145396919977081
4.136369355022907 seconds in game passed.
Action: tensor([[[1.4123e-03, 5.8600e-01],
         [1.1414e-03, 3.2064e-01],
         [1.0107e-03, 2.2099e-01],
         [3.6184e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001925, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.161369355395436 seconds in game passed.
Action: tensor([[[1.4123e-03, 5.8600e-01],
         [1.1414e-03, 3.2064e-01],
         [1.0107e-03, 2.2099e-01],
         [3.6184e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.186369355767965 seconds in game passed.
Action: tensor([[[1.4123e-03, 5.8600e-01],
         [1.1414e-03, 3.2064e-01],
         [1.0107e-03, 2.2099e-01],
         [3.6184e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
+++++++++++++: 11.883738821806649
4.211369356140494 seconds in game passed.
At 4.211369356140494 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002143, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.7221479506394559
4.236369356513023 seconds in game passed.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.261369356885552 seconds in game passed.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 0.7221479506394559
4.286369357258081 seconds in game passed.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
+++++++++++++: 8.843383999601484
4.3113693576306105 seconds in game passed.
At 4.3113693576306105 seconds, saving state-action tuples.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003069, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383999601484
Current reward: 0.49259322239340864
Current mitigation activation: 0
#############################
Total reward: 1.2147411730328646
4.3363693580031395 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2147411730328646
4.3613693583756685 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2147411730328646
4.3863693587481976 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002928, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2147411730328646
+++++++++++++: 7.228541501275198
4.411369359120727 seconds in game passed.
At 4.411369359120727 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228541501275198
Current reward: 0.5118171195076244
Current mitigation activation: 0
#############################
Total reward: 1.726558292540489
4.436369359493256 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003560, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.726558292540489
4.461369359865785 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003576, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.726558292540489
4.486369360238314 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.726558292540489
+++++++++++++: 6.2159331184388575
4.511369360610843 seconds in game passed.
At 4.511369360610843 seconds, saving state-action tuples.
Action: tensor([[[0.0020, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002733, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.2159331184388575
Current reward: 0.5264941465786098
Current mitigation activation: 0
#############################
Total reward: 2.2530524391190987
4.536369360983372 seconds in game passed.
Action: tensor([[[0.0020, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002883, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.2530524391190987
4.561369361355901 seconds in game passed.
Action: tensor([[[0.0020, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.2530524391190987
4.58636936172843 seconds in game passed.
Action: tensor([[[0.0020, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.2530524391190987
+++++++++++++: 5.508365853638963
4.611369362100959 seconds in game passed.
At 4.611369362100959 seconds, saving state-action tuples.
Action: tensor([[[-9.5218e-05,  5.8865e-01],
         [ 1.5736e-04,  3.2203e-01],
         [ 2.7962e-04,  2.2122e-01],
         [-9.2529e-05,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508365853638963
Current reward: 0.537623498978236
Current mitigation activation: 0
#############################
Total reward: 2.7906759380973347
4.636369362473488 seconds in game passed.
Action: tensor([[[-9.5218e-05,  5.8865e-01],
         [ 1.5736e-04,  3.2203e-01],
         [ 2.7962e-04,  2.2122e-01],
         [-9.2529e-05,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000890, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.7906759380973347
4.661369362846017 seconds in game passed.
Action: tensor([[[-9.5218e-05,  5.8865e-01],
         [ 1.5736e-04,  3.2203e-01],
         [ 2.7962e-04,  2.2122e-01],
         [-9.2529e-05,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000872, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.7906759380973347
4.686369363218546 seconds in game passed.
Action: tensor([[[-9.5218e-05,  5.8865e-01],
         [ 1.5736e-04,  3.2203e-01],
         [ 2.7962e-04,  2.2122e-01],
         [-9.2529e-05,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.7906759380973347
+++++++++++++: 4.9761342678197185
4.711369363591075 seconds in game passed.
At 4.711369363591075 seconds, saving state-action tuples.
Action: tensor([[[ 2.0875e-04,  5.8928e-01],
         [-3.9624e-04,  3.2138e-01],
         [-3.0982e-04,  2.2103e-01],
         [-4.7089e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.9761342678197185
Current reward: 0.5459292659195056
Current mitigation activation: 0
#############################
Total reward: 3.3366052040168404
4.736369363963604 seconds in game passed.
Action: tensor([[[ 2.0875e-04,  5.8928e-01],
         [-3.9624e-04,  3.2138e-01],
         [-3.0982e-04,  2.2103e-01],
         [-4.7089e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.3366052040168404
4.761369364336133 seconds in game passed.
Action: tensor([[[ 2.0875e-04,  5.8928e-01],
         [-3.9624e-04,  3.2138e-01],
         [-3.0982e-04,  2.2103e-01],
         [-4.7089e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.3366052040168404
4.786369364708662 seconds in game passed.
Action: tensor([[[ 2.0875e-04,  5.8928e-01],
         [-3.9624e-04,  3.2138e-01],
         [-3.0982e-04,  2.2103e-01],
         [-4.7089e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.3366052040168404
+++++++++++++: 4.552585584603673
4.811369365081191 seconds in game passed.
At 4.811369365081191 seconds, saving state-action tuples.
Action: tensor([[[-3.1729e-04,  5.9104e-01],
         [-9.9905e-04,  3.2157e-01],
         [-8.8266e-04,  2.2107e-01],
         [-1.0276e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552585584603673
Current reward: 0.5519989036455549
Current mitigation activation: 0
#############################
Total reward: 3.8886041076623954
4.83636936545372 seconds in game passed.
Action: tensor([[[-3.1729e-04,  5.9104e-01],
         [-9.9905e-04,  3.2157e-01],
         [-8.8266e-04,  2.2107e-01],
         [-1.0276e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8886041076623954
4.861369365826249 seconds in game passed.
Action: tensor([[[-3.1729e-04,  5.9104e-01],
         [-9.9905e-04,  3.2157e-01],
         [-8.8266e-04,  2.2107e-01],
         [-1.0276e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8886041076623954
4.886369366198778 seconds in game passed.
Action: tensor([[[-3.1729e-04,  5.9104e-01],
         [-9.9905e-04,  3.2157e-01],
         [-8.8266e-04,  2.2107e-01],
         [-1.0276e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8886041076623954
+++++++++++++: 4.199609653749305
4.911369366571307 seconds in game passed.
At 4.911369366571307 seconds, saving state-action tuples.
Action: tensor([[[ 4.8500e-04,  5.9001e-01],
         [-5.6238e-04,  3.2160e-01],
         [-4.3240e-04,  2.2125e-01],
         [-4.6244e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199609653749305
Current reward: 0.5563326550427872
Current mitigation activation: 0
#############################
Total reward: 4.444936762705183
4.936369366943836 seconds in game passed.
Action: tensor([[[ 4.8500e-04,  5.9001e-01],
         [-5.6238e-04,  3.2160e-01],
         [-4.3240e-04,  2.2125e-01],
         [-4.6244e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.444936762705183
4.961369367316365 seconds in game passed.
Action: tensor([[[ 4.8500e-04,  5.9001e-01],
         [-5.6238e-04,  3.2160e-01],
         [-4.3240e-04,  2.2125e-01],
         [-4.6244e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.444936762705183
4.986369367688894 seconds in game passed.
Action: tensor([[[ 4.8500e-04,  5.9001e-01],
         [-5.6238e-04,  3.2160e-01],
         [-4.3240e-04,  2.2125e-01],
         [-4.6244e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.444936762705183
+++++++++++++: 3.89475956116383
5.011369368061423 seconds in game passed.
At 5.011369368061423 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5877],
         [0.0007, 0.3214],
         [0.0010, 0.2217],
         [0.0012, 0.1683]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.89475956116383
Current reward: 0.5593082003948288
Current mitigation activation: 0
#############################
Total reward: 5.004244963100011
5.036369368433952 seconds in game passed.
Action: tensor([[[0.0016, 0.5877],
         [0.0007, 0.3214],
         [0.0010, 0.2217],
         [0.0012, 0.1683]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.004244963100011
5.061369368806481 seconds in game passed.
Action: tensor([[[0.0016, 0.5877],
         [0.0007, 0.3214],
         [0.0010, 0.2217],
         [0.0012, 0.1683]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.004244963100011
5.08636936917901 seconds in game passed.
Action: tensor([[[0.0016, 0.5877],
         [0.0007, 0.3214],
         [0.0010, 0.2217],
         [0.0012, 0.1683]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.004244963100011
+++++++++++++: 3.624670163439329
5.111369369551539 seconds in game passed.
At 5.111369369551539 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2492e-03, 5.8990e-01],
         [1.0427e-03, 3.2213e-01],
         [9.2157e-04, 2.2284e-01],
         [5.8303e-04, 1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.624670163439329
Current reward: 0.5611771043902933
Current mitigation activation: 0
#############################
Total reward: 5.565422067490305
5.1363693699240685 seconds in game passed.
Action: tensor([[[1.2492e-03, 5.8990e-01],
         [1.0427e-03, 3.2213e-01],
         [9.2157e-04, 2.2284e-01],
         [5.8303e-04, 1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.565422067490305
5.1613693702965975 seconds in game passed.
Action: tensor([[[1.2492e-03, 5.8990e-01],
         [1.0427e-03, 3.2213e-01],
         [9.2157e-04, 2.2284e-01],
         [5.8303e-04, 1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.565422067490305
5.1863693706691265 seconds in game passed.
Action: tensor([[[1.2492e-03, 5.8990e-01],
         [1.0427e-03, 3.2213e-01],
         [9.2157e-04, 2.2284e-01],
         [5.8303e-04, 1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.565422067490305
+++++++++++++: 3.380482432828839
5.2113693710416555 seconds in game passed.
At 5.2113693710416555 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380482432828839
Current reward: 0.5621374323135557
Current mitigation activation: 0
#############################
Total reward: 6.12755949980386
5.236369371414185 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.12755949980386
5.261369371786714 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.12755949980386
5.286369372159243 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2210],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.12755949980386
+++++++++++++: 3.156565653379174
5.311369372531772 seconds in game passed.
At 5.311369372531772 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.5950],
         [0.0020, 0.3223],
         [0.0019, 0.2217],
         [0.0016, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.156565653379174
Current reward: 0.5623125570334453
Current mitigation activation: 0
#############################
Total reward: 6.689872056837306
5.336369372904301 seconds in game passed.
Action: tensor([[[0.0025, 0.5950],
         [0.0020, 0.3223],
         [0.0019, 0.2217],
         [0.0016, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.689872056837306
5.36136937327683 seconds in game passed.
Action: tensor([[[0.0025, 0.5950],
         [0.0020, 0.3223],
         [0.0019, 0.2217],
         [0.0016, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.689872056837306
5.386369373649359 seconds in game passed.
Action: tensor([[[0.0025, 0.5950],
         [0.0020, 0.3223],
         [0.0019, 0.2217],
         [0.0016, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.689872056837306
+++++++++++++: 2.948947654713361
5.411369374021888 seconds in game passed.
At 5.411369374021888 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.948947654713361
Current reward: 0.56179673502104
Current mitigation activation: 0
#############################
Total reward: 7.251668791858346
5.436369374394417 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.251668791858346
5.461369374766946 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.251668791858346
5.486369375139475 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.251668791858346
+++++++++++++: 2.7880612838129433
5.511369375512004 seconds in game passed.
At 5.511369375512004 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.1157e-04,  5.8834e-01],
         [ 1.2030e-04,  3.2090e-01],
         [-3.5577e-05,  2.2100e-01],
         [-3.3929e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7880612838129433
Current reward: 0.5575288176718334
Current mitigation activation: 0
#############################
Total reward: 7.8091976095301785
5.536369375884533 seconds in game passed.
Action: tensor([[[ 9.1157e-04,  5.8834e-01],
         [ 1.2030e-04,  3.2090e-01],
         [-3.5577e-05,  2.2100e-01],
         [-3.3929e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.8091976095301785
5.561369376257062 seconds in game passed.
Action: tensor([[[ 9.1157e-04,  5.8834e-01],
         [ 1.2030e-04,  3.2090e-01],
         [-3.5577e-05,  2.2100e-01],
         [-3.3929e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.8091976095301785
5.586369376629591 seconds in game passed.
Action: tensor([[[ 9.1157e-04,  5.8834e-01],
         [ 1.2030e-04,  3.2090e-01],
         [-3.5577e-05,  2.2100e-01],
         [-3.3929e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.8091976095301785
+++++++++++++: 2.691319986360875
5.61136937700212 seconds in game passed.
At 5.61136937700212 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5927],
         [-0.0021,  0.3224],
         [-0.0025,  0.2215],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.691319986360875
Current reward: 0.5472018056778344
Current mitigation activation: 0
#############################
Total reward: 8.356399415208013
5.636369377374649 seconds in game passed.
Action: tensor([[[-0.0010,  0.5927],
         [-0.0021,  0.3224],
         [-0.0025,  0.2215],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.356399415208013
5.661369377747178 seconds in game passed.
Action: tensor([[[-0.0010,  0.5927],
         [-0.0021,  0.3224],
         [-0.0025,  0.2215],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.356399415208013
5.686369378119707 seconds in game passed.
Action: tensor([[[-0.0010,  0.5927],
         [-0.0021,  0.3224],
         [-0.0025,  0.2215],
         [-0.0029,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.356399415208013
+++++++++++++: 2.595023188270808
5.711369378492236 seconds in game passed.
At 5.711369378492236 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.5913],
         [-0.0038,  0.3220],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.595023188270808
Current reward: 0.5368277908297125
Current mitigation activation: 0
#############################
Total reward: 8.893227206037725
5.736369378864765 seconds in game passed.
Action: tensor([[[-0.0022,  0.5913],
         [-0.0038,  0.3220],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.893227206037725
5.761369379237294 seconds in game passed.
Action: tensor([[[-0.0022,  0.5913],
         [-0.0038,  0.3220],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002832, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.893227206037725
5.786369379609823 seconds in game passed.
Action: tensor([[[-0.0022,  0.5913],
         [-0.0038,  0.3220],
         [-0.0044,  0.2211],
         [-0.0049,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.893227206037725
+++++++++++++: 2.4986293904385843
5.811369379982352 seconds in game passed.
At 5.811369379982352 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.5951],
         [-0.0045,  0.3231],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4986293904385843
Current reward: 0.5264622781854061
Current mitigation activation: 0
#############################
Total reward: 9.419689484223131
5.836369380354881 seconds in game passed.
Action: tensor([[[-0.0026,  0.5951],
         [-0.0045,  0.3231],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.419689484223131
5.86136938072741 seconds in game passed.
Action: tensor([[[-0.0026,  0.5951],
         [-0.0045,  0.3231],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.419689484223131
5.886369381099939 seconds in game passed.
Action: tensor([[[-0.0026,  0.5951],
         [-0.0045,  0.3231],
         [-0.0051,  0.2218],
         [-0.0055,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.419689484223131
+++++++++++++: 2.4021916260252656
5.911369381472468 seconds in game passed.
At 5.911369381472468 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.8033e-04,  5.9073e-01],
         [-7.4309e-04,  3.2177e-01],
         [-7.6167e-04,  2.2147e-01],
         [-9.5865e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4021916260252656
Current reward: 0.5161006521920084
Current mitigation activation: 0
#############################
Total reward: 9.93579013641514
5.936369381844997 seconds in game passed.
Action: tensor([[[-1.8033e-04,  5.9073e-01],
         [-7.4309e-04,  3.2177e-01],
         [-7.6167e-04,  2.2147e-01],
         [-9.5865e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.93579013641514
5.961369382217526 seconds in game passed.
Action: tensor([[[-1.8033e-04,  5.9073e-01],
         [-7.4309e-04,  3.2177e-01],
         [-7.6167e-04,  2.2147e-01],
         [-9.5865e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000504, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.93579013641514
5.9863693825900555 seconds in game passed.
Action: tensor([[[-1.8033e-04,  5.9073e-01],
         [-7.4309e-04,  3.2177e-01],
         [-7.6167e-04,  2.2147e-01],
         [-9.5865e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.93579013641514
+++++++++++++: 2.2737286027037285
6.0113693829625845 seconds in game passed.
At 6.0113693829625845 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.9883e-05,  5.9323e-01],
         [ 2.5281e-04,  3.2267e-01],
         [ 2.9034e-04,  2.2197e-01],
         [-1.0292e-04,  1.6853e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2737286027037285
Current reward: 0.5093356157109812
Current mitigation activation: 0
#############################
Total reward: 10.44512575212612
6.0363693833351135 seconds in game passed.
Action: tensor([[[ 3.9883e-05,  5.9323e-01],
         [ 2.5281e-04,  3.2267e-01],
         [ 2.9034e-04,  2.2197e-01],
         [-1.0292e-04,  1.6853e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.44512575212612
6.0613693837076426 seconds in game passed.
Action: tensor([[[ 3.9883e-05,  5.9323e-01],
         [ 2.5281e-04,  3.2267e-01],
         [ 2.9034e-04,  2.2197e-01],
         [-1.0292e-04,  1.6853e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.44512575212612
6.086369384080172 seconds in game passed.
Action: tensor([[[ 3.9883e-05,  5.9323e-01],
         [ 2.5281e-04,  3.2267e-01],
         [ 2.9034e-04,  2.2197e-01],
         [-1.0292e-04,  1.6853e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000129, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.44512575212612
+++++++++++++: 2.0693994865544294
6.111369384452701 seconds in game passed.
At 6.111369384452701 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5969],
         [0.0037, 0.3257],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003853, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0693994865544294
Current reward: 0.5122395707686843
Current mitigation activation: 0
#############################
Total reward: 10.957365322894805
6.13636938482523 seconds in game passed.
Action: tensor([[[0.0031, 0.5969],
         [0.0037, 0.3257],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.874754, steer=0.003264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.957365322894805
6.161369385197759 seconds in game passed.
Action: tensor([[[0.0031, 0.5969],
         [0.0037, 0.3257],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.821963, steer=0.003292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.957365322894805
6.186369385570288 seconds in game passed.
Action: tensor([[[0.0031, 0.5969],
         [0.0037, 0.3257],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.770341, steer=0.003319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.957365322894805
+++++++++++++: 1.886535130337359
6.211369385942817 seconds in game passed.
At 6.211369385942817 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6201],
         [0.0025, 0.3395],
         [0.0020, 0.2339],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.475303, steer=0.002023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.886535130337359
Current reward: 0.5134806731464032
Current mitigation activation: 0
#############################
Total reward: 11.47084599604121
6.236369386315346 seconds in game passed.
Action: tensor([[[0.0020, 0.6201],
         [0.0025, 0.3395],
         [0.0020, 0.2339],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.449486, steer=0.002243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.47084599604121
6.261369386687875 seconds in game passed.
Action: tensor([[[0.0020, 0.6201],
         [0.0025, 0.3395],
         [0.0020, 0.2339],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.400053, steer=0.002246, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.47084599604121
6.286369387060404 seconds in game passed.
Action: tensor([[[0.0020, 0.6201],
         [0.0025, 0.3395],
         [0.0020, 0.2339],
         [0.0008, 0.1790]]])
agent 0 action: VehicleControl(throttle=0.362649, steer=0.002250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.47084599604121
+++++++++++++: 1.7242186289371546
6.311369387432933 seconds in game passed.
At 6.311369387432933 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.6940e-04,  6.3370e-01],
         [ 3.6955e-06,  3.4330e-01],
         [-6.8911e-04,  2.3556e-01],
         [-1.8000e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.352671, steer=-0.000182, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7242186289371546
Current reward: 0.5125495541953293
Current mitigation activation: 0
#############################
Total reward: 11.983395550236539
6.336369387805462 seconds in game passed.
Action: tensor([[[ 4.6940e-04,  6.3370e-01],
         [ 3.6955e-06,  3.4330e-01],
         [-6.8911e-04,  2.3556e-01],
         [-1.8000e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.340079, steer=0.000196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.983395550236539
6.361369388177991 seconds in game passed.
Action: tensor([[[ 4.6940e-04,  6.3370e-01],
         [ 3.6955e-06,  3.4330e-01],
         [-6.8911e-04,  2.3556e-01],
         [-1.8000e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.327905, steer=0.000172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.983395550236539
6.38636938855052 seconds in game passed.
Action: tensor([[[ 4.6940e-04,  6.3370e-01],
         [ 3.6955e-06,  3.4330e-01],
         [-6.8911e-04,  2.3556e-01],
         [-1.8000e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.316146, steer=0.000148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.983395550236539
+++++++++++++: 1.588654198089891
6.411369388923049 seconds in game passed.
At 6.411369388923049 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4217e-03,  6.5352e-01],
         [-6.0364e-04,  3.5229e-01],
         [-1.7510e-03,  2.4175e-01],
         [-2.9703e-03,  1.8451e-01]]])
agent 0 action: VehicleControl(throttle=0.305152, steer=0.000049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.588654198089891
Current reward: 0.5075894592006913
Current mitigation activation: 0
#############################
Total reward: 12.49098500943723
6.436369389295578 seconds in game passed.
Action: tensor([[[ 1.4217e-03,  6.5352e-01],
         [-6.0364e-04,  3.5229e-01],
         [-1.7510e-03,  2.4175e-01],
         [-2.9703e-03,  1.8451e-01]]])
agent 0 action: VehicleControl(throttle=0.294568, steer=0.000031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.49098500943723
6.461369389668107 seconds in game passed.
Action: tensor([[[ 1.4217e-03,  6.5352e-01],
         [-6.0364e-04,  3.5229e-01],
         [-1.7510e-03,  2.4175e-01],
         [-2.9703e-03,  1.8451e-01]]])
agent 0 action: VehicleControl(throttle=0.283936, steer=0.000002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.49098500943723
6.486369390040636 seconds in game passed.
Action: tensor([[[ 1.4217e-03,  6.5352e-01],
         [-6.0364e-04,  3.5229e-01],
         [-1.7510e-03,  2.4175e-01],
         [-2.9703e-03,  1.8451e-01]]])
agent 0 action: VehicleControl(throttle=0.273279, steer=-0.000028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.49098500943723
+++++++++++++: 1.477303078767528
6.511369390413165 seconds in game passed.
At 6.511369390413165 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6675],
         [-0.0048,  0.3564],
         [-0.0062,  0.2429],
         [-0.0071,  0.1851]]])
agent 0 action: VehicleControl(throttle=0.262489, steer=-0.004271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.477303078767528
Current reward: 0.4982083739629086
Current mitigation activation: 0
#############################
Total reward: 12.989193383400139
6.536369390785694 seconds in game passed.
Action: tensor([[[-0.0013,  0.6675],
         [-0.0048,  0.3564],
         [-0.0062,  0.2429],
         [-0.0071,  0.1851]]])
agent 0 action: VehicleControl(throttle=0.251681, steer=-0.003619, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.989193383400139
6.561369391158223 seconds in game passed.
Action: tensor([[[-0.0013,  0.6675],
         [-0.0048,  0.3564],
         [-0.0062,  0.2429],
         [-0.0071,  0.1851]]])
agent 0 action: VehicleControl(throttle=0.240853, steer=-0.003666, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.989193383400139
6.586369391530752 seconds in game passed.
Action: tensor([[[-0.0013,  0.6675],
         [-0.0048,  0.3564],
         [-0.0062,  0.2429],
         [-0.0071,  0.1851]]])
agent 0 action: VehicleControl(throttle=0.230008, steer=-0.003713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.989193383400139
+++++++++++++: 1.38104561704747
6.611369391903281 seconds in game passed.
At 6.611369391903281 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.6267e-04,  6.8525e-01],
         [-4.2309e-03,  3.6652e-01],
         [-5.9916e-03,  2.5079e-01],
         [-7.2982e-03,  1.9102e-01]]])
agent 0 action: VehicleControl(throttle=0.219224, steer=-0.002965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.38104561704747
Current reward: 0.485707456263875
Current mitigation activation: 0
#############################
Total reward: 13.474900839664013
6.63636939227581 seconds in game passed.
Action: tensor([[[-4.6267e-04,  6.8525e-01],
         [-4.2309e-03,  3.6652e-01],
         [-5.9916e-03,  2.5079e-01],
         [-7.2982e-03,  1.9102e-01]]])
agent 0 action: VehicleControl(throttle=0.208422, steer=-0.003106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.474900839664013
6.661369392648339 seconds in game passed.
Action: tensor([[[-4.6267e-04,  6.8525e-01],
         [-4.2309e-03,  3.6652e-01],
         [-5.9916e-03,  2.5079e-01],
         [-7.2982e-03,  1.9102e-01]]])
agent 0 action: VehicleControl(throttle=0.197601, steer=-0.003121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.474900839664013
6.686369393020868 seconds in game passed.
Action: tensor([[[-4.6267e-04,  6.8525e-01],
         [-4.2309e-03,  3.6652e-01],
         [-5.9916e-03,  2.5079e-01],
         [-7.2982e-03,  1.9102e-01]]])
agent 0 action: VehicleControl(throttle=0.186762, steer=-0.003136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.474900839664013
+++++++++++++: 1.2936184210537633
6.711369393393397 seconds in game passed.
At 6.711369393393397 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-2.6571e-04,  1.0000e+00],
         [-4.6891e-03,  1.0000e+00],
         [-5.8923e-03,  1.0000e+00],
         [-6.4426e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002938, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2936184210537633
Current reward: 0.4712036607728083
Current mitigation activation: 1
#############################
Total reward: 13.946104500436821
6.736369393765926 seconds in game passed.
Action: tensor([[[-2.6571e-04,  1.0000e+00],
         [-4.6891e-03,  1.0000e+00],
         [-5.8923e-03,  1.0000e+00],
         [-6.4426e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002964, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.946104500436821
6.761369394138455 seconds in game passed.
Action: tensor([[[-2.6571e-04,  1.0000e+00],
         [-4.6891e-03,  1.0000e+00],
         [-5.8923e-03,  1.0000e+00],
         [-6.4426e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002959, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.946104500436821
6.786369394510984 seconds in game passed.
Action: tensor([[[-2.6571e-04,  1.0000e+00],
         [-4.6891e-03,  1.0000e+00],
         [-5.8923e-03,  1.0000e+00],
         [-6.4426e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002954, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.946104500436821
+++++++++++++: 1.2139165432889356
6.8113693948835135 seconds in game passed.
At 6.8113693948835135 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0025,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000707, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2139165432889356
Current reward: 0.45484102373848023
Current mitigation activation: 1
#############################
Total reward: 14.4009455241753
6.8363693952560425 seconds in game passed.
Action: tensor([[[ 0.0025,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001040, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.4009455241753
6.8613693956285715 seconds in game passed.
Action: tensor([[[ 0.0025,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001004, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.4009455241753
6.8863693960011005 seconds in game passed.
Action: tensor([[[ 0.0025,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000968, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.4009455241753
+++++++++++++: 1.161034654146955
6.91136939637363 seconds in game passed.
At 6.91136939637363 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.7465e-03,  1.0000e+00],
         [ 9.3567e-04,  1.0000e+00],
         [-1.3501e-03,  1.0000e+00],
         [-1.3874e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006111, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.161034654146955
Current reward: 0.4320463322874477
Current mitigation activation: 1
#############################
Total reward: 14.832991856462748
6.936369396746159 seconds in game passed.
Action: tensor([[[ 8.7465e-03,  1.0000e+00],
         [ 9.3567e-04,  1.0000e+00],
         [-1.3501e-03,  1.0000e+00],
         [-1.3874e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005012, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.832991856462748
6.961369397118688 seconds in game passed.
Action: tensor([[[ 8.7465e-03,  1.0000e+00],
         [ 9.3567e-04,  1.0000e+00],
         [-1.3501e-03,  1.0000e+00],
         [-1.3874e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005082, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.832991856462748
6.986369397491217 seconds in game passed.
Action: tensor([[[ 8.7465e-03,  1.0000e+00],
         [ 9.3567e-04,  1.0000e+00],
         [-1.3501e-03,  1.0000e+00],
         [-1.3874e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005152, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.832991856462748
+++++++++++++: 1.142361175051572
7.011369397863746 seconds in game passed.
At 7.011369397863746 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0144,  1.0000],
         [-0.0044,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012931, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.142361175051572
Current reward: 0.40186076888848826
Current mitigation activation: 1
#############################
Total reward: 15.234852625351236
7.036369398236275 seconds in game passed.
Action: tensor([[[-0.0144,  1.0000],
         [-0.0044,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010064, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.234852625351236
7.061369398608804 seconds in game passed.
Action: tensor([[[-0.0144,  1.0000],
         [-0.0044,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010189, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.234852625351236
7.086369398981333 seconds in game passed.
Action: tensor([[[-0.0144,  1.0000],
         [-0.0044,  1.0000],
         [-0.0062,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010315, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.234852625351236
+++++++++++++: 1.1442015073904572
7.111369399353862 seconds in game passed.
At 7.111369399353862 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0122,  1.0000],
         [-0.0064,  1.0000],
         [-0.0077,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010284, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1442015073904572
Current reward: 0.3691369886408881
Current mitigation activation: 1
#############################
Total reward: 15.603989613992123
7.136369399726391 seconds in game passed.
Action: tensor([[[-0.0122,  1.0000],
         [-0.0064,  1.0000],
         [-0.0077,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010479, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.603989613992123
7.16136940009892 seconds in game passed.
Action: tensor([[[-0.0122,  1.0000],
         [-0.0064,  1.0000],
         [-0.0077,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010641, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.603989613992123
7.186369400471449 seconds in game passed.
Action: tensor([[[-0.0122,  1.0000],
         [-0.0064,  1.0000],
         [-0.0077,  1.0000],
         [-0.0074,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010803, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.603989613992123
+++++++++++++: 1.1637115765391286
7.211369400843978 seconds in game passed.
At 7.211369400843978 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0166,  1.0000],
         [-0.0111,  1.0000],
         [-0.0086,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016794, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1637115765391286
Current reward: 0.33587052275785206
Current mitigation activation: 1
#############################
Total reward: 15.939860136749976
7.236369401216507 seconds in game passed.
Action: tensor([[[-0.0166,  1.0000],
         [-0.0111,  1.0000],
         [-0.0086,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016039, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.939860136749976
7.261369401589036 seconds in game passed.
Action: tensor([[[-0.0166,  1.0000],
         [-0.0111,  1.0000],
         [-0.0086,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016248, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.939860136749976
7.286369401961565 seconds in game passed.
Action: tensor([[[-0.0166,  1.0000],
         [-0.0111,  1.0000],
         [-0.0086,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016457, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.939860136749976
+++++++++++++: 1.2034098656988057
7.311369402334094 seconds in game passed.
At 7.311369402334094 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0113,  1.0000],
         [-0.0152,  1.0000],
         [-0.0203,  1.0000],
         [-0.0224,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015878, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2034098656988057
Current reward: 0.3028739209734963
Current mitigation activation: 1
#############################
Total reward: 16.24273405772347
7.336369402706623 seconds in game passed.
Action: tensor([[[-0.0113,  1.0000],
         [-0.0152,  1.0000],
         [-0.0203,  1.0000],
         [-0.0224,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016180, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.24273405772347
7.361369403079152 seconds in game passed.
Action: tensor([[[-0.0113,  1.0000],
         [-0.0152,  1.0000],
         [-0.0203,  1.0000],
         [-0.0224,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016356, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.24273405772347
7.386369403451681 seconds in game passed.
Action: tensor([[[-0.0113,  1.0000],
         [-0.0152,  1.0000],
         [-0.0203,  1.0000],
         [-0.0224,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016532, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.24273405772347
+++++++++++++: 1.268758163514395
7.41136940382421 seconds in game passed.
At 7.41136940382421 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0044,  1.0000],
         [-0.0104,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.022102, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.268758163514395
Current reward: 0.27063985143625896
Current mitigation activation: 1
#############################
Total reward: 16.51337390915973
7.436369404196739 seconds in game passed.
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0044,  1.0000],
         [-0.0104,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015926, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.51337390915973
7.461369404569268 seconds in game passed.
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0044,  1.0000],
         [-0.0104,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016151, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.51337390915973
7.486369404941797 seconds in game passed.
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0044,  1.0000],
         [-0.0104,  1.0000],
         [-0.0093,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016376, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.51337390915973
+++++++++++++: 1.3669419409896943
7.511369405314326 seconds in game passed.
At 7.511369405314326 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.8524e-03, 9.5602e-01],
         [1.1357e-03, 9.5437e-01],
         [3.5057e-04, 9.5376e-01],
         [7.0212e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003413, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3669419409896943
Current reward: 0.23977314913947573
Current mitigation activation: 0
#############################
Total reward: 16.753147058299206
7.536369405686855 seconds in game passed.
Action: tensor([[[1.8524e-03, 9.5602e-01],
         [1.1357e-03, 9.5437e-01],
         [3.5057e-04, 9.5376e-01],
         [7.0212e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000042, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.753147058299206
7.561369406059384 seconds in game passed.
Action: tensor([[[1.8524e-03, 9.5602e-01],
         [1.1357e-03, 9.5437e-01],
         [3.5057e-04, 9.5376e-01],
         [7.0212e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000019, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.753147058299206
7.586369406431913 seconds in game passed.
Action: tensor([[[1.8524e-03, 9.5602e-01],
         [1.1357e-03, 9.5437e-01],
         [3.5057e-04, 9.5376e-01],
         [7.0212e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000081, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.753147058299206
+++++++++++++: 1.509368167294087
7.611369406804442 seconds in game passed.
At 7.611369406804442 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.1082e-04, 9.5595e-01],
         [1.1374e-03, 9.5432e-01],
         [1.0569e-03, 9.5375e-01],
         [1.5034e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000520, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.509368167294087
Current reward: 0.21066703082218574
Current mitigation activation: 0
#############################
Total reward: 16.963814089121392
7.636369407176971 seconds in game passed.
Action: tensor([[[8.1082e-04, 9.5595e-01],
         [1.1374e-03, 9.5432e-01],
         [1.0569e-03, 9.5375e-01],
         [1.5034e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000365, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.963814089121392
7.6613694075495005 seconds in game passed.
Action: tensor([[[8.1082e-04, 9.5595e-01],
         [1.1374e-03, 9.5432e-01],
         [1.0569e-03, 9.5375e-01],
         [1.5034e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000317, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.963814089121392
7.6863694079220295 seconds in game passed.
Action: tensor([[[8.1082e-04, 9.5595e-01],
         [1.1374e-03, 9.5432e-01],
         [1.0569e-03, 9.5375e-01],
         [1.5034e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000270, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.963814089121392
+++++++++++++: 1.7373784950513194
7.7113694082945585 seconds in game passed.
At 7.7113694082945585 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.2286e-04, 9.5609e-01],
         [1.5303e-03, 9.5458e-01],
         [1.8304e-03, 9.5408e-01],
         [1.9410e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000030, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7373784950513194
Current reward: 0.18268394213172348
Current mitigation activation: 0
#############################
Total reward: 17.146498031253117
7.7363694086670876 seconds in game passed.
Action: tensor([[[8.2286e-04, 9.5609e-01],
         [1.5303e-03, 9.5458e-01],
         [1.8304e-03, 9.5408e-01],
         [1.9410e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000036, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.146498031253117
7.761369409039617 seconds in game passed.
Action: tensor([[[8.2286e-04, 9.5609e-01],
         [1.5303e-03, 9.5458e-01],
         [1.8304e-03, 9.5408e-01],
         [1.9410e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000084, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.146498031253117
7.786369409412146 seconds in game passed.
Action: tensor([[[8.2286e-04, 9.5609e-01],
         [1.5303e-03, 9.5458e-01],
         [1.8304e-03, 9.5408e-01],
         [1.9410e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000132, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.146498031253117
+++++++++++++: 2.155784083485191
7.811369409784675 seconds in game passed.
At 7.811369409784675 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.0410e-04, 9.5623e-01],
         [1.5018e-03, 9.5478e-01],
         [1.7751e-03, 9.5431e-01],
         [1.8680e-03, 9.5405e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000064, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.155784083485191
Current reward: 0.15683483770927698
Current mitigation activation: 0
#############################
Total reward: 17.303332868962393
7.836369410157204 seconds in game passed.
Action: tensor([[[7.0410e-04, 9.5623e-01],
         [1.5018e-03, 9.5478e-01],
         [1.7751e-03, 9.5431e-01],
         [1.8680e-03, 9.5405e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000103, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.303332868962393
7.861369410529733 seconds in game passed.
Action: tensor([[[7.0410e-04, 9.5623e-01],
         [1.5018e-03, 9.5478e-01],
         [1.7751e-03, 9.5431e-01],
         [1.8680e-03, 9.5405e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000127, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.303332868962393
7.886369410902262 seconds in game passed.
Action: tensor([[[7.0410e-04, 9.5623e-01],
         [1.5018e-03, 9.5478e-01],
         [1.7751e-03, 9.5431e-01],
         [1.8680e-03, 9.5405e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000151, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.303332868962393
+++++++++++++: 2.961341245695314
7.911369411274791 seconds in game passed.
At 7.911369411274791 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.9723e-04, 9.5621e-01],
         [1.5147e-03, 9.5475e-01],
         [1.7811e-03, 9.5428e-01],
         [1.8961e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000168, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.961341245695314
Current reward: 0.1327578792310153
Current mitigation activation: 0
#############################
Total reward: 17.436090748193408
7.93636941164732 seconds in game passed.
Action: tensor([[[7.9723e-04, 9.5621e-01],
         [1.5147e-03, 9.5475e-01],
         [1.7811e-03, 9.5428e-01],
         [1.8961e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000109, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.436090748193408
7.961369412019849 seconds in game passed.
Action: tensor([[[7.9723e-04, 9.5621e-01],
         [1.5147e-03, 9.5475e-01],
         [1.7811e-03, 9.5428e-01],
         [1.8961e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000060, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.436090748193408
7.986369412392378 seconds in game passed.
Action: tensor([[[7.9723e-04, 9.5621e-01],
         [1.5147e-03, 9.5475e-01],
         [1.7811e-03, 9.5428e-01],
         [1.8961e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000012, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.436090748193408
+++++++++++++: 4.768504747281801
8.011369412764907 seconds in game passed.
At 8.011369412764907 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.1757e-04, 9.5607e-01],
         [1.5031e-03, 9.5456e-01],
         [1.7862e-03, 9.5407e-01],
         [1.9113e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000219, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.768504747281801
Current reward: 0.11054581188450296
Current mitigation activation: 0
#############################
Total reward: 17.54663656007791
8.036369413137436 seconds in game passed.
Action: tensor([[[9.1757e-04, 9.5607e-01],
         [1.5031e-03, 9.5456e-01],
         [1.7862e-03, 9.5407e-01],
         [1.9113e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000347, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54663656007791
8.061369413509965 seconds in game passed.
Action: tensor([[[9.1757e-04, 9.5607e-01],
         [1.5031e-03, 9.5456e-01],
         [1.7862e-03, 9.5407e-01],
         [1.9113e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000486, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54663656007791
8.086369413882494 seconds in game passed.
Action: tensor([[[9.1757e-04, 9.5607e-01],
         [1.5031e-03, 9.5456e-01],
         [1.7862e-03, 9.5407e-01],
         [1.9113e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.004350, steer=0.000625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54663656007791
+++++++++++++: 23.403964156218887
8.111369414255023 seconds in game passed.
At 8.111369414255023 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0017, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006630, steer=0.000725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03972172218518352
Current mitigation activation: 0
#############################
Total reward: 17.586358282263095
8.136369414627552 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0017, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006636, steer=0.000868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.586358282263095
8.161369415000081 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0017, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006803, steer=0.001005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.586358282263095
8.18636941537261 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0014, 0.9544],
         [0.0017, 0.9539],
         [0.0018, 0.9536]]])
agent 0 action: VehicleControl(throttle=0.006915, steer=0.001142, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.586358282263095
+++++++++++++: 2070.434351363475
8.21136941574514 seconds in game passed.
At 8.21136941574514 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.7411e-03,  9.5576e-01],
         [ 1.5956e-03,  9.5387e-01],
         [-1.6010e-03,  9.5314e-01],
         [-3.8557e-04,  9.5262e-01]]])
agent 0 action: VehicleControl(throttle=0.031010, steer=0.006362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0004709580433250813
Current mitigation activation: 0
#############################
Total reward: 17.58682924030642
8.236369416117668 seconds in game passed.
Action: tensor([[[ 8.7411e-03,  9.5576e-01],
         [ 1.5956e-03,  9.5387e-01],
         [-1.6010e-03,  9.5314e-01],
         [-3.8557e-04,  9.5262e-01]]])
agent 0 action: VehicleControl(throttle=0.005723, steer=0.005783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.58682924030642
8.261369416490197 seconds in game passed.
Action: tensor([[[ 8.7411e-03,  9.5576e-01],
         [ 1.5956e-03,  9.5387e-01],
         [-1.6010e-03,  9.5314e-01],
         [-3.8557e-04,  9.5262e-01]]])
agent 0 action: VehicleControl(throttle=0.008920, steer=0.006032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.58682924030642
8.286369416862726 seconds in game passed.
Action: tensor([[[ 8.7411e-03,  9.5576e-01],
         [ 1.5956e-03,  9.5387e-01],
         [-1.6010e-03,  9.5314e-01],
         [-3.8557e-04,  9.5262e-01]]])
agent 0 action: VehicleControl(throttle=0.009663, steer=0.006281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.58682924030642
+++++++++++++: 165.7858636644251
8.311369417235255 seconds in game passed.
At 8.311369417235255 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0217,  0.9552],
         [ 0.0027,  0.9526],
         [-0.0060,  0.9513],
         [-0.0019,  0.9493]]])
agent 0 action: VehicleControl(throttle=0.054528, steer=0.015391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006176096963097949
Current mitigation activation: 0
#############################
Total reward: 17.59300533726952
8.336369417607784 seconds in game passed.
Action: tensor([[[ 0.0217,  0.9552],
         [ 0.0027,  0.9526],
         [-0.0060,  0.9513],
         [-0.0019,  0.9493]]])
agent 0 action: VehicleControl(throttle=0.051035, steer=0.014261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.59300533726952
8.361369417980313 seconds in game passed.
Action: tensor([[[ 0.0217,  0.9552],
         [ 0.0027,  0.9526],
         [-0.0060,  0.9513],
         [-0.0019,  0.9493]]])
agent 0 action: VehicleControl(throttle=0.052165, steer=0.014593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.59300533726952
8.386369418352842 seconds in game passed.
Action: tensor([[[ 0.0217,  0.9552],
         [ 0.0027,  0.9526],
         [-0.0060,  0.9513],
         [-0.0019,  0.9493]]])
agent 0 action: VehicleControl(throttle=0.053220, steer=0.014926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.59300533726952
+++++++++++++: 207.50818565156334
8.411369418725371 seconds in game passed.
At 8.411369418725371 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4246e-02,  9.5362e-01],
         [-2.2901e-05,  9.4726e-01],
         [-1.3167e-02,  9.1267e-01],
         [-8.7847e-03,  5.9808e-01]]])
agent 0 action: VehicleControl(throttle=0.077154, steer=0.014682, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.005187190771577437
Current mitigation activation: 0
#############################
Total reward: 17.598192528041096
8.4363694190979 seconds in game passed.
Action: tensor([[[ 2.4246e-02,  9.5362e-01],
         [-2.2901e-05,  9.4726e-01],
         [-1.3167e-02,  9.1267e-01],
         [-8.7847e-03,  5.9808e-01]]])
agent 0 action: VehicleControl(throttle=0.075927, steer=0.014641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.598192528041096
8.46136941947043 seconds in game passed.
Action: tensor([[[ 2.4246e-02,  9.5362e-01],
         [-2.2901e-05,  9.4726e-01],
         [-1.3167e-02,  9.1267e-01],
         [-8.7847e-03,  5.9808e-01]]])
agent 0 action: VehicleControl(throttle=0.077080, steer=0.014572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.598192528041096
8.486369419842958 seconds in game passed.
Action: tensor([[[ 2.4246e-02,  9.5362e-01],
         [-2.2901e-05,  9.4726e-01],
         [-1.3167e-02,  9.1267e-01],
         [-8.7847e-03,  5.9808e-01]]])
agent 0 action: VehicleControl(throttle=0.078177, steer=0.014503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.598192528041096
+++++++++++++: 247.82941288651546
8.511369420215487 seconds in game passed.
At 8.511369420215487 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0100,  0.9527],
         [-0.0039,  0.9419],
         [-0.0105,  0.8769],
         [-0.0045,  0.6080]]])
agent 0 action: VehicleControl(throttle=0.054705, steer=0.003267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004571759275204647
Current mitigation activation: 0
#############################
Total reward: 17.6027642873163
8.536369420588017 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9527],
         [-0.0039,  0.9419],
         [-0.0105,  0.8769],
         [-0.0045,  0.6080]]])
agent 0 action: VehicleControl(throttle=0.058049, steer=0.005163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6027642873163
8.561369420960546 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9527],
         [-0.0039,  0.9419],
         [-0.0105,  0.8769],
         [-0.0045,  0.6080]]])
agent 0 action: VehicleControl(throttle=0.058776, steer=0.005183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6027642873163
8.586369421333075 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9527],
         [-0.0039,  0.9419],
         [-0.0105,  0.8769],
         [-0.0045,  0.6080]]])
agent 0 action: VehicleControl(throttle=0.059505, steer=0.005203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6027642873163
+++++++++++++: 279.3865969420959
8.611369421705604 seconds in game passed.
At 8.611369421705604 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0296,  0.9512],
         [-0.0171,  0.9077],
         [-0.0116,  0.7411],
         [-0.0084,  0.5484]]])
agent 0 action: VehicleControl(throttle=0.192312, steer=-0.027680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004270274729399808
Current mitigation activation: 0
#############################
Total reward: 17.6070345620457
8.636369422078133 seconds in game passed.
Action: tensor([[[-0.0296,  0.9512],
         [-0.0171,  0.9077],
         [-0.0116,  0.7411],
         [-0.0084,  0.5484]]])
agent 0 action: VehicleControl(throttle=0.180498, steer=-0.022564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6070345620457
8.661369422450662 seconds in game passed.
Action: tensor([[[-0.0296,  0.9512],
         [-0.0171,  0.9077],
         [-0.0116,  0.7411],
         [-0.0084,  0.5484]]])
agent 0 action: VehicleControl(throttle=0.182635, steer=-0.022877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6070345620457
8.68636942282319 seconds in game passed.
Action: tensor([[[-0.0296,  0.9512],
         [-0.0171,  0.9077],
         [-0.0116,  0.7411],
         [-0.0084,  0.5484]]])
agent 0 action: VehicleControl(throttle=0.184635, steer=-0.023189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6070345620457
+++++++++++++: 304.533775421944
8.71136942319572 seconds in game passed.
At 8.71136942319572 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0399,  0.9496],
         [-0.0178,  0.8194],
         [-0.0074,  0.6095],
         [-0.0042,  0.4904]]])
agent 0 action: VehicleControl(throttle=0.645004, steer=-0.029262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004126024650398638
Current mitigation activation: 0
#############################
Total reward: 17.6111605866961
8.736369423568249 seconds in game passed.
Action: tensor([[[-0.0399,  0.9496],
         [-0.0178,  0.8194],
         [-0.0074,  0.6095],
         [-0.0042,  0.4904]]])
agent 0 action: VehicleControl(throttle=0.603274, steer=-0.028687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6111605866961
8.761369423940778 seconds in game passed.
Action: tensor([[[-0.0399,  0.9496],
         [-0.0178,  0.8194],
         [-0.0074,  0.6095],
         [-0.0042,  0.4904]]])
agent 0 action: VehicleControl(throttle=0.609999, steer=-0.029061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6111605866961
8.786369424313307 seconds in game passed.
Action: tensor([[[-0.0399,  0.9496],
         [-0.0178,  0.8194],
         [-0.0074,  0.6095],
         [-0.0042,  0.4904]]])
agent 0 action: VehicleControl(throttle=0.616423, steer=-0.029435, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.6111605866961
+++++++++++++: 294.41096961172514
8.811369424685836 seconds in game passed.
At 8.811369424685836 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0333,  0.9492],
         [-0.0101,  0.8066],
         [-0.0053,  0.5921],
         [-0.0070,  0.4824]]])
agent 0 action: VehicleControl(throttle=0.697052, steer=-0.020683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004493895999608988
Current mitigation activation: 0
#############################
Total reward: 17.61565448269571
8.836369425058365 seconds in game passed.
Action: tensor([[[-0.0333,  0.9492],
         [-0.0101,  0.8066],
         [-0.0053,  0.5921],
         [-0.0070,  0.4824]]])
agent 0 action: VehicleControl(throttle=0.695206, steer=-0.022468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.61565448269571
8.861369425430894 seconds in game passed.
Action: tensor([[[-0.0333,  0.9492],
         [-0.0101,  0.8066],
         [-0.0053,  0.5921],
         [-0.0070,  0.4824]]])
agent 0 action: VehicleControl(throttle=0.700438, steer=-0.022747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.61565448269571
8.886369425803423 seconds in game passed.
Action: tensor([[[-0.0333,  0.9492],
         [-0.0101,  0.8066],
         [-0.0053,  0.5921],
         [-0.0070,  0.4824]]])
agent 0 action: VehicleControl(throttle=0.704448, steer=-0.023026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.61565448269571
+++++++++++++: 202.16076412459972
8.911369426175952 seconds in game passed.
At 8.911369426175952 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.5278e-02,  9.4372e-01],
         [-4.9010e-03,  6.0824e-01],
         [-1.8935e-03,  4.7321e-01],
         [-3.6158e-04,  4.1787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006884116743768556
Current mitigation activation: 0
#############################
Total reward: 17.62253859943948
8.936369426548481 seconds in game passed.
Action: tensor([[[-2.5278e-02,  9.4372e-01],
         [-4.9010e-03,  6.0824e-01],
         [-1.8935e-03,  4.7321e-01],
         [-3.6158e-04,  4.1787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.62253859943948
8.96136942692101 seconds in game passed.
Action: tensor([[[-2.5278e-02,  9.4372e-01],
         [-4.9010e-03,  6.0824e-01],
         [-1.8935e-03,  4.7321e-01],
         [-3.6158e-04,  4.1787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.62253859943948
8.986369427293539 seconds in game passed.
Action: tensor([[[-2.5278e-02,  9.4372e-01],
         [-4.9010e-03,  6.0824e-01],
         [-1.8935e-03,  4.7321e-01],
         [-3.6158e-04,  4.1787e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.62253859943948
+++++++++++++: 44.88629573033456
9.011369427666068 seconds in game passed.
At 9.011369427666068 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1093e-02,  9.3376e-01],
         [ 1.4449e-04,  5.6106e-01],
         [ 4.1893e-04,  4.3716e-01],
         [ 1.2833e-03,  3.8021e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03251908174035269
Current mitigation activation: 0
#############################
Total reward: 17.655057681179834
9.036369428038597 seconds in game passed.
Action: tensor([[[-1.1093e-02,  9.3376e-01],
         [ 1.4449e-04,  5.6106e-01],
         [ 4.1893e-04,  4.3716e-01],
         [ 1.2833e-03,  3.8021e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.655057681179834
9.061369428411126 seconds in game passed.
Action: tensor([[[-1.1093e-02,  9.3376e-01],
         [ 1.4449e-04,  5.6106e-01],
         [ 4.1893e-04,  4.3716e-01],
         [ 1.2833e-03,  3.8021e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.655057681179834
9.086369428783655 seconds in game passed.
Action: tensor([[[-1.1093e-02,  9.3376e-01],
         [ 1.4449e-04,  5.6106e-01],
         [ 4.1893e-04,  4.3716e-01],
         [ 1.2833e-03,  3.8021e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.655057681179834
+++++++++++++: 18.122969776018643
9.111369429156184 seconds in game passed.
At 9.111369429156184 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0061,  0.8841],
         [-0.0029,  0.4971],
         [-0.0050,  0.3597],
         [-0.0052,  0.2880]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006791, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.08408583226340492
Current mitigation activation: 0
#############################
Total reward: 17.73914351344324
9.136369429528713 seconds in game passed.
Action: tensor([[[-0.0061,  0.8841],
         [-0.0029,  0.4971],
         [-0.0050,  0.3597],
         [-0.0052,  0.2880]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.73914351344324
9.161369429901242 seconds in game passed.
Action: tensor([[[-0.0061,  0.8841],
         [-0.0029,  0.4971],
         [-0.0050,  0.3597],
         [-0.0052,  0.2880]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.73914351344324
9.186369430273771 seconds in game passed.
Action: tensor([[[-0.0061,  0.8841],
         [-0.0029,  0.4971],
         [-0.0050,  0.3597],
         [-0.0052,  0.2880]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.73914351344324
+++++++++++++: 10.840758966290217
9.2113694306463 seconds in game passed.
At 9.2113694306463 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0034,  0.8351],
         [-0.0030,  0.4710],
         [-0.0059,  0.3360],
         [-0.0069,  0.2635]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.1460206264230146
Current mitigation activation: 0
#############################
Total reward: 17.88516413986625
9.23636943101883 seconds in game passed.
Action: tensor([[[ 0.0034,  0.8351],
         [-0.0030,  0.4710],
         [-0.0059,  0.3360],
         [-0.0069,  0.2635]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003871, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.88516413986625
9.261369431391358 seconds in game passed.
Action: tensor([[[ 0.0034,  0.8351],
         [-0.0030,  0.4710],
         [-0.0059,  0.3360],
         [-0.0069,  0.2635]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.88516413986625
9.286369431763887 seconds in game passed.
Action: tensor([[[ 0.0034,  0.8351],
         [-0.0030,  0.4710],
         [-0.0059,  0.3360],
         [-0.0069,  0.2635]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.88516413986625
+++++++++++++: 7.630242638037468
9.311369432136416 seconds in game passed.
At 9.311369432136416 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.8183],
         [-0.0023,  0.4590],
         [-0.0055,  0.3242],
         [-0.0070,  0.2518]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.630242638037468
Current reward: 0.17464714219175795
Current mitigation activation: 0
#############################
Total reward: 18.05981128205801
9.336369432508945 seconds in game passed.
Action: tensor([[[ 0.0057,  0.8183],
         [-0.0023,  0.4590],
         [-0.0055,  0.3242],
         [-0.0070,  0.2518]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003094, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.05981128205801
9.361369432881474 seconds in game passed.
Action: tensor([[[ 0.0057,  0.8183],
         [-0.0023,  0.4590],
         [-0.0055,  0.3242],
         [-0.0070,  0.2518]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003246, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.05981128205801
9.386369433254004 seconds in game passed.
Action: tensor([[[ 0.0057,  0.8183],
         [-0.0023,  0.4590],
         [-0.0055,  0.3242],
         [-0.0070,  0.2518]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.05981128205801
+++++++++++++: 6.086995008313695
9.411369433626533 seconds in game passed.
At 9.411369433626533 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.4663e-03,  8.0445e-01],
         [-5.5655e-04,  4.4901e-01],
         [-3.5007e-03,  3.1266e-01],
         [-5.3268e-03,  2.3940e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.086995008313695
Current reward: 0.19186871648821646
Current mitigation activation: 0
#############################
Total reward: 18.251679998546226
9.436369433999062 seconds in game passed.
Action: tensor([[[ 7.4663e-03,  8.0445e-01],
         [-5.5655e-04,  4.4901e-01],
         [-3.5007e-03,  3.1266e-01],
         [-5.3268e-03,  2.3940e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001979, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.251679998546226
9.46136943437159 seconds in game passed.
Action: tensor([[[ 7.4663e-03,  8.0445e-01],
         [-5.5655e-04,  4.4901e-01],
         [-3.5007e-03,  3.1266e-01],
         [-5.3268e-03,  2.3940e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.251679998546226
9.48636943474412 seconds in game passed.
Action: tensor([[[ 7.4663e-03,  8.0445e-01],
         [-5.5655e-04,  4.4901e-01],
         [-3.5007e-03,  3.1266e-01],
         [-5.3268e-03,  2.3940e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.251679998546226
+++++++++++++: 5.179569985364278
9.511369435116649 seconds in game passed.
At 9.511369435116649 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.4422e-03,  7.7098e-01],
         [-7.2612e-04,  4.3114e-01],
         [-3.1033e-03,  2.9976e-01],
         [-4.7904e-03,  2.2975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.179569985364278
Current reward: 0.2074749711083596
Current mitigation activation: 0
#############################
Total reward: 18.459154969654588
9.536369435489178 seconds in game passed.
Action: tensor([[[ 5.4422e-03,  7.7098e-01],
         [-7.2612e-04,  4.3114e-01],
         [-3.1033e-03,  2.9976e-01],
         [-4.7904e-03,  2.2975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003088, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.459154969654588
9.561369435861707 seconds in game passed.
Action: tensor([[[ 5.4422e-03,  7.7098e-01],
         [-7.2612e-04,  4.3114e-01],
         [-3.1033e-03,  2.9976e-01],
         [-4.7904e-03,  2.2975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003110, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.459154969654588
9.586369436234236 seconds in game passed.
Action: tensor([[[ 5.4422e-03,  7.7098e-01],
         [-7.2612e-04,  4.3114e-01],
         [-3.1033e-03,  2.9976e-01],
         [-4.7904e-03,  2.2975e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.459154969654588
+++++++++++++: 4.54853605019326
9.611369436606765 seconds in game passed.
At 9.611369436606765 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.7515],
         [-0.0010,  0.4215],
         [-0.0031,  0.2935],
         [-0.0047,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.54853605019326
Current reward: 0.22219659251011442
Current mitigation activation: 0
#############################
Total reward: 18.681351562164703
9.636369436979294 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7515],
         [-0.0010,  0.4215],
         [-0.0031,  0.2935],
         [-0.0047,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.681351562164703
9.661369437351823 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7515],
         [-0.0010,  0.4215],
         [-0.0031,  0.2935],
         [-0.0047,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.681351562164703
9.686369437724352 seconds in game passed.
Action: tensor([[[ 0.0057,  0.7515],
         [-0.0010,  0.4215],
         [-0.0031,  0.2935],
         [-0.0047,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.681351562164703
+++++++++++++: 4.06908041385757
9.711369438096881 seconds in game passed.
At 9.711369438096881 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0115,  0.7535],
         [ 0.0008,  0.4195],
         [-0.0010,  0.2922],
         [-0.0020,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.06908041385757
Current reward: 0.23633326631179152
Current mitigation activation: 0
#############################
Total reward: 18.917684828476496
9.73636943846941 seconds in game passed.
Action: tensor([[[ 0.0115,  0.7535],
         [ 0.0008,  0.4195],
         [-0.0010,  0.2922],
         [-0.0020,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.917684828476496
9.761369438841939 seconds in game passed.
Action: tensor([[[ 0.0115,  0.7535],
         [ 0.0008,  0.4195],
         [-0.0010,  0.2922],
         [-0.0020,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.917684828476496
9.786369439214468 seconds in game passed.
Action: tensor([[[ 0.0115,  0.7535],
         [ 0.0008,  0.4195],
         [-0.0010,  0.2922],
         [-0.0020,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.917684828476496
+++++++++++++: 3.6856925600324075
9.811369439586997 seconds in game passed.
At 9.811369439586997 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5468e-02,  7.4925e-01],
         [ 1.3891e-03,  4.1924e-01],
         [-1.8790e-04,  2.9240e-01],
         [-8.3689e-04,  2.2502e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6856925600324075
Current reward: 0.24999120645854755
Current mitigation activation: 0
#############################
Total reward: 19.16767603493504
9.836369439959526 seconds in game passed.
Action: tensor([[[ 1.5468e-02,  7.4925e-01],
         [ 1.3891e-03,  4.1924e-01],
         [-1.8790e-04,  2.9240e-01],
         [-8.3689e-04,  2.2502e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.16767603493504
9.861369440332055 seconds in game passed.
Action: tensor([[[ 1.5468e-02,  7.4925e-01],
         [ 1.3891e-03,  4.1924e-01],
         [-1.8790e-04,  2.9240e-01],
         [-8.3689e-04,  2.2502e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.16767603493504
9.886369440704584 seconds in game passed.
Action: tensor([[[ 1.5468e-02,  7.4925e-01],
         [ 1.3891e-03,  4.1924e-01],
         [-1.8790e-04,  2.9240e-01],
         [-8.3689e-04,  2.2502e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005899, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.16767603493504
+++++++++++++: 3.3676583424633084
9.911369441077113 seconds in game passed.
At 9.911369441077113 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.5411e-02, 7.4278e-01],
         [2.5655e-03, 4.1865e-01],
         [1.1721e-03, 2.9234e-01],
         [5.4850e-04, 2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007010, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3676583424633084
Current reward: 0.2632335437103359
Current mitigation activation: 0
#############################
Total reward: 19.430909578645377
9.936369441449642 seconds in game passed.
Action: tensor([[[1.5411e-02, 7.4278e-01],
         [2.5655e-03, 4.1865e-01],
         [1.1721e-03, 2.9234e-01],
         [5.4850e-04, 2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.430909578645377
9.961369441822171 seconds in game passed.
Action: tensor([[[1.5411e-02, 7.4278e-01],
         [2.5655e-03, 4.1865e-01],
         [1.1721e-03, 2.9234e-01],
         [5.4850e-04, 2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.430909578645377
9.9863694421947 seconds in game passed.
Action: tensor([[[1.5411e-02, 7.4278e-01],
         [2.5655e-03, 4.1865e-01],
         [1.1721e-03, 2.9234e-01],
         [5.4850e-04, 2.2499e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.430909578645377
+++++++++++++: 3.1837467935963253
10.01136944256723 seconds in game passed.
At 10.01136944256723 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1548e-02, 7.0811e-01],
         [1.5004e-03, 3.9775e-01],
         [5.8843e-04, 2.7800e-01],
         [2.8493e-04, 2.1534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1837467935963253
Current reward: 0.2727532459785754
Current mitigation activation: 0
#############################
Total reward: 19.70366282462395
10.036369442939758 seconds in game passed.
Action: tensor([[[1.1548e-02, 7.0811e-01],
         [1.5004e-03, 3.9775e-01],
         [5.8843e-04, 2.7800e-01],
         [2.8493e-04, 2.1534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.70366282462395
10.061369443312287 seconds in game passed.
Action: tensor([[[1.1548e-02, 7.0811e-01],
         [1.5004e-03, 3.9775e-01],
         [5.8843e-04, 2.7800e-01],
         [2.8493e-04, 2.1534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.70366282462395
10.086369443684816 seconds in game passed.
Action: tensor([[[1.1548e-02, 7.0811e-01],
         [1.5004e-03, 3.9775e-01],
         [5.8843e-04, 2.7800e-01],
         [2.8493e-04, 2.1534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.70366282462395
+++++++++++++: 3.2115130586063687
10.111369444057345 seconds in game passed.
At 10.111369444057345 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.7383e-03, 6.7760e-01],
         [1.1702e-03, 3.7674e-01],
         [6.6812e-04, 2.6348e-01],
         [2.7736e-04, 2.0559e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003871, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2115130586063687
Current reward: 0.2742923391603756
Current mitigation activation: 0
#############################
Total reward: 19.977955163784326
10.136369444429874 seconds in game passed.
Action: tensor([[[6.7383e-03, 6.7760e-01],
         [1.1702e-03, 3.7674e-01],
         [6.6812e-04, 2.6348e-01],
         [2.7736e-04, 2.0559e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.977955163784326
10.161369444802403 seconds in game passed.
Action: tensor([[[6.7383e-03, 6.7760e-01],
         [1.1702e-03, 3.7674e-01],
         [6.6812e-04, 2.6348e-01],
         [2.7736e-04, 2.0559e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.977955163784326
10.186369445174932 seconds in game passed.
Action: tensor([[[6.7383e-03, 6.7760e-01],
         [1.1702e-03, 3.7674e-01],
         [6.6812e-04, 2.6348e-01],
         [2.7736e-04, 2.0559e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.977955163784326
+++++++++++++: 3.246599658838988
10.211369445547462 seconds in game passed.
At 10.211369445547462 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.8211e-03, 6.5725e-01],
         [1.4058e-03, 3.6388e-01],
         [1.0069e-03, 2.5374e-01],
         [3.2394e-04, 1.9794e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.246599658838988
Current reward: 0.27556037698476593
Current mitigation activation: 0
#############################
Total reward: 20.253515540769094
10.23636944591999 seconds in game passed.
Action: tensor([[[3.8211e-03, 6.5725e-01],
         [1.4058e-03, 3.6388e-01],
         [1.0069e-03, 2.5374e-01],
         [3.2394e-04, 1.9794e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.253515540769094
10.26136944629252 seconds in game passed.
Action: tensor([[[3.8211e-03, 6.5725e-01],
         [1.4058e-03, 3.6388e-01],
         [1.0069e-03, 2.5374e-01],
         [3.2394e-04, 1.9794e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.253515540769094
10.286369446665049 seconds in game passed.
Action: tensor([[[3.8211e-03, 6.5725e-01],
         [1.4058e-03, 3.6388e-01],
         [1.0069e-03, 2.5374e-01],
         [3.2394e-04, 1.9794e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.253515540769094
+++++++++++++: 3.2818430733281323
10.311369447037578 seconds in game passed.
At 10.311369447037578 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.3020e-03, 6.5737e-01],
         [1.1216e-03, 3.6383e-01],
         [8.0603e-04, 2.5363e-01],
         [2.1905e-04, 1.9764e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2818430733281323
Current reward: 0.2768429639468245
Current mitigation activation: 0
#############################
Total reward: 20.530358504715917
10.336369447410107 seconds in game passed.
Action: tensor([[[3.3020e-03, 6.5737e-01],
         [1.1216e-03, 3.6383e-01],
         [8.0603e-04, 2.5363e-01],
         [2.1905e-04, 1.9764e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.530358504715917
10.361369447782636 seconds in game passed.
Action: tensor([[[3.3020e-03, 6.5737e-01],
         [1.1216e-03, 3.6383e-01],
         [8.0603e-04, 2.5363e-01],
         [2.1905e-04, 1.9764e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.530358504715917
10.386369448155165 seconds in game passed.
Action: tensor([[[3.3020e-03, 6.5737e-01],
         [1.1216e-03, 3.6383e-01],
         [8.0603e-04, 2.5363e-01],
         [2.1905e-04, 1.9764e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.530358504715917
+++++++++++++: 3.317640107357806
10.411369448527694 seconds in game passed.
At 10.411369448527694 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9251e-03,  6.4468e-01],
         [ 6.5866e-04,  3.5804e-01],
         [ 2.7663e-04,  2.5061e-01],
         [-3.5648e-04,  1.9547e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.317640107357806
Current reward: 0.27812385978188897
Current mitigation activation: 0
#############################
Total reward: 20.808482364497806
10.436369448900223 seconds in game passed.
Action: tensor([[[ 2.9251e-03,  6.4468e-01],
         [ 6.5866e-04,  3.5804e-01],
         [ 2.7663e-04,  2.5061e-01],
         [-3.5648e-04,  1.9547e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.808482364497806
10.461369449272752 seconds in game passed.
Action: tensor([[[ 2.9251e-03,  6.4468e-01],
         [ 6.5866e-04,  3.5804e-01],
         [ 2.7663e-04,  2.5061e-01],
         [-3.5648e-04,  1.9547e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003067, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.808482364497806
10.48636944964528 seconds in game passed.
Action: tensor([[[ 2.9251e-03,  6.4468e-01],
         [ 6.5866e-04,  3.5804e-01],
         [ 2.7663e-04,  2.5061e-01],
         [-3.5648e-04,  1.9547e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.808482364497806
+++++++++++++: 3.27215412217039
10.51136945001781 seconds in game passed.
At 10.51136945001781 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8924e-03,  6.4133e-01],
         [ 7.3306e-05,  3.5537e-01],
         [-4.2200e-04,  2.4818e-01],
         [-1.0779e-03,  1.9335e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.27215412217039
Current reward: 0.28236468492887795
Current mitigation activation: 0
#############################
Total reward: 21.090847049426685
10.536369450390339 seconds in game passed.
Action: tensor([[[ 1.8924e-03,  6.4133e-01],
         [ 7.3306e-05,  3.5537e-01],
         [-4.2200e-04,  2.4818e-01],
         [-1.0779e-03,  1.9335e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.090847049426685
10.561369450762868 seconds in game passed.
Action: tensor([[[ 1.8924e-03,  6.4133e-01],
         [ 7.3306e-05,  3.5537e-01],
         [-4.2200e-04,  2.4818e-01],
         [-1.0779e-03,  1.9335e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.090847049426685
10.586369451135397 seconds in game passed.
Action: tensor([[[ 1.8924e-03,  6.4133e-01],
         [ 7.3306e-05,  3.5537e-01],
         [-4.2200e-04,  2.4818e-01],
         [-1.0779e-03,  1.9335e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.090847049426685
+++++++++++++: 3.0003652988980103
10.611369451507926 seconds in game passed.
At 10.611369451507926 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1505e-03,  6.4605e-01],
         [ 4.6560e-04,  3.5641e-01],
         [-3.7104e-05,  2.4717e-01],
         [-7.3688e-04,  1.9148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0003652988980103
Current reward: 0.29582295939780046
Current mitigation activation: 0
#############################
Total reward: 21.386670008824485
10.636369451880455 seconds in game passed.
Action: tensor([[[ 2.1505e-03,  6.4605e-01],
         [ 4.6560e-04,  3.5641e-01],
         [-3.7104e-05,  2.4717e-01],
         [-7.3688e-04,  1.9148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.386670008824485
10.661369452252984 seconds in game passed.
Action: tensor([[[ 2.1505e-03,  6.4605e-01],
         [ 4.6560e-04,  3.5641e-01],
         [-3.7104e-05,  2.4717e-01],
         [-7.3688e-04,  1.9148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.386670008824485
10.686369452625513 seconds in game passed.
Action: tensor([[[ 2.1505e-03,  6.4605e-01],
         [ 4.6560e-04,  3.5641e-01],
         [-3.7104e-05,  2.4717e-01],
         [-7.3688e-04,  1.9148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.386670008824485
+++++++++++++: 2.7781903751927515
10.711369452998042 seconds in game passed.
At 10.711369452998042 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.4398e-04,  6.5845e-01],
         [-1.3364e-03,  3.6160e-01],
         [-1.9901e-03,  2.5003e-01],
         [-2.7331e-03,  1.9330e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7781903751927515
Current reward: 0.3081278360808074
Current mitigation activation: 0
#############################
Total reward: 21.694797844905292
10.736369453370571 seconds in game passed.
Action: tensor([[[-1.4398e-04,  6.5845e-01],
         [-1.3364e-03,  3.6160e-01],
         [-1.9901e-03,  2.5003e-01],
         [-2.7331e-03,  1.9330e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.694797844905292
10.7613694537431 seconds in game passed.
Action: tensor([[[-1.4398e-04,  6.5845e-01],
         [-1.3364e-03,  3.6160e-01],
         [-1.9901e-03,  2.5003e-01],
         [-2.7331e-03,  1.9330e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.694797844905292
10.78636945411563 seconds in game passed.
Action: tensor([[[-1.4398e-04,  6.5845e-01],
         [-1.3364e-03,  3.6160e-01],
         [-1.9901e-03,  2.5003e-01],
         [-2.7331e-03,  1.9330e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.694797844905292
+++++++++++++: 2.5950945945613695
10.811369454488158 seconds in game passed.
At 10.811369454488158 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0013,  0.3647],
         [-0.0019,  0.2504],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5950945945613695
Current reward: 0.3191487117050942
Current mitigation activation: 0
#############################
Total reward: 22.013946556610385
10.836369454860687 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0013,  0.3647],
         [-0.0019,  0.2504],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.013946556610385
10.861369455233216 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0013,  0.3647],
         [-0.0019,  0.2504],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.013946556610385
10.886369455605745 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6701],
         [-0.0013,  0.3647],
         [-0.0019,  0.2504],
         [-0.0026,  0.1929]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.013946556610385
+++++++++++++: 2.4352457252901947
10.911369455978274 seconds in game passed.
At 10.911369455978274 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.2203e-04,  6.7543e-01],
         [-1.7932e-03,  3.6512e-01],
         [-2.6798e-03,  2.5042e-01],
         [-3.5091e-03,  1.9280e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4352457252901947
Current reward: 0.3293307809543891
Current mitigation activation: 0
#############################
Total reward: 22.343277337564775
10.936369456350803 seconds in game passed.
Action: tensor([[[ 3.2203e-04,  6.7543e-01],
         [-1.7932e-03,  3.6512e-01],
         [-2.6798e-03,  2.5042e-01],
         [-3.5091e-03,  1.9280e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.343277337564775
10.961369456723332 seconds in game passed.
Action: tensor([[[ 3.2203e-04,  6.7543e-01],
         [-1.7932e-03,  3.6512e-01],
         [-2.6798e-03,  2.5042e-01],
         [-3.5091e-03,  1.9280e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.343277337564775
10.986369457095861 seconds in game passed.
Action: tensor([[[ 3.2203e-04,  6.7543e-01],
         [-1.7932e-03,  3.6512e-01],
         [-2.6798e-03,  2.5042e-01],
         [-3.5091e-03,  1.9280e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.343277337564775
+++++++++++++: 2.2911440488855277
11.01136945746839 seconds in game passed.
At 11.01136945746839 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6818],
         [-0.0025,  0.3676],
         [-0.0034,  0.2534],
         [-0.0045,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2911440488855277
Current reward: 0.33888645590859867
Current mitigation activation: 0
#############################
Total reward: 22.682163793473375
11.03636945784092 seconds in game passed.
Action: tensor([[[-0.0011,  0.6818],
         [-0.0025,  0.3676],
         [-0.0034,  0.2534],
         [-0.0045,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.682163793473375
11.061369458213449 seconds in game passed.
Action: tensor([[[-0.0011,  0.6818],
         [-0.0025,  0.3676],
         [-0.0034,  0.2534],
         [-0.0045,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.682163793473375
11.086369458585978 seconds in game passed.
Action: tensor([[[-0.0011,  0.6818],
         [-0.0025,  0.3676],
         [-0.0034,  0.2534],
         [-0.0045,  0.1955]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.682163793473375
+++++++++++++: 2.1585019242467047
11.111369458958507 seconds in game passed.
At 11.111369458958507 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6799],
         [-0.0037,  0.3704],
         [-0.0046,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1585019242467047
Current reward: 0.34793899289354074
Current mitigation activation: 0
#############################
Total reward: 23.030102786366914
11.136369459331036 seconds in game passed.
Action: tensor([[[-0.0014,  0.6799],
         [-0.0037,  0.3704],
         [-0.0046,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002618, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.030102786366914
11.161369459703565 seconds in game passed.
Action: tensor([[[-0.0014,  0.6799],
         [-0.0037,  0.3704],
         [-0.0046,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.030102786366914
11.186369460076094 seconds in game passed.
Action: tensor([[[-0.0014,  0.6799],
         [-0.0037,  0.3704],
         [-0.0046,  0.2560],
         [-0.0051,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.030102786366914
+++++++++++++: 2.0352801832793195
11.211369460448623 seconds in game passed.
At 11.211369460448623 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0027,  0.6784],
         [-0.0010,  0.3722],
         [-0.0020,  0.2577],
         [-0.0029,  0.1989]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0352801832793195
Current reward: 0.3565072844435032
Current mitigation activation: 0
#############################
Total reward: 23.386610070810416
11.236369460821152 seconds in game passed.
Action: tensor([[[ 0.0027,  0.6784],
         [-0.0010,  0.3722],
         [-0.0020,  0.2577],
         [-0.0029,  0.1989]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.386610070810416
11.26136946119368 seconds in game passed.
Action: tensor([[[ 0.0027,  0.6784],
         [-0.0010,  0.3722],
         [-0.0020,  0.2577],
         [-0.0029,  0.1989]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.386610070810416
11.28636946156621 seconds in game passed.
Action: tensor([[[ 0.0027,  0.6784],
         [-0.0010,  0.3722],
         [-0.0020,  0.2577],
         [-0.0029,  0.1989]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.386610070810416
+++++++++++++: 1.9198643554213908
11.311369461938739 seconds in game passed.
At 11.311369461938739 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0010,  0.6756],
         [-0.0012,  0.3731],
         [-0.0020,  0.2589],
         [-0.0026,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9198643554213908
Current reward: 0.3646140811835955
Current mitigation activation: 0
#############################
Total reward: 23.751224151994013
11.336369462311268 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6756],
         [-0.0012,  0.3731],
         [-0.0020,  0.2589],
         [-0.0026,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.751224151994013
11.361369462683797 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6756],
         [-0.0012,  0.3731],
         [-0.0020,  0.2589],
         [-0.0026,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.751224151994013
11.386369463056326 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6756],
         [-0.0012,  0.3731],
         [-0.0020,  0.2589],
         [-0.0026,  0.1997]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.751224151994013
+++++++++++++: 1.8111974620074984
11.411369463428855 seconds in game passed.
At 11.411369463428855 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.7271e-03,  6.7674e-01],
         [ 2.3121e-04,  3.8430e-01],
         [-5.3555e-04,  2.7115e-01],
         [-1.1196e-03,  2.1118e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8111974620074984
Current reward: 0.37225224811529783
Current mitigation activation: 0
#############################
Total reward: 24.12347640010931
11.436369463801384 seconds in game passed.
Action: tensor([[[ 5.7271e-03,  6.7674e-01],
         [ 2.3121e-04,  3.8430e-01],
         [-5.3555e-04,  2.7115e-01],
         [-1.1196e-03,  2.1118e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.12347640010931
11.461369464173913 seconds in game passed.
Action: tensor([[[ 5.7271e-03,  6.7674e-01],
         [ 2.3121e-04,  3.8430e-01],
         [-5.3555e-04,  2.7115e-01],
         [-1.1196e-03,  2.1118e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.12347640010931
11.486369464546442 seconds in game passed.
Action: tensor([[[ 5.7271e-03,  6.7674e-01],
         [ 2.3121e-04,  3.8430e-01],
         [-5.3555e-04,  2.7115e-01],
         [-1.1196e-03,  2.1118e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.12347640010931
+++++++++++++: 1.7083449190282758
11.511369464918971 seconds in game passed.
At 11.511369464918971 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.7715e-03,  7.0171e-01],
         [ 5.5611e-05,  3.9529e-01],
         [-8.1877e-04,  2.7715e-01],
         [-1.2053e-03,  2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7083449190282758
Current reward: 0.37942362028118654
Current mitigation activation: 0
#############################
Total reward: 24.5029000203905
11.5363694652915 seconds in game passed.
Action: tensor([[[ 6.7715e-03,  7.0171e-01],
         [ 5.5611e-05,  3.9529e-01],
         [-8.1877e-04,  2.7715e-01],
         [-1.2053e-03,  2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.5029000203905
11.56136946566403 seconds in game passed.
Action: tensor([[[ 6.7715e-03,  7.0171e-01],
         [ 5.5611e-05,  3.9529e-01],
         [-8.1877e-04,  2.7715e-01],
         [-1.2053e-03,  2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.5029000203905
11.586369466036558 seconds in game passed.
Action: tensor([[[ 6.7715e-03,  7.0171e-01],
         [ 5.5611e-05,  3.9529e-01],
         [-8.1877e-04,  2.7715e-01],
         [-1.2053e-03,  2.1436e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.5029000203905
+++++++++++++: 1.6104046876807518
11.611369466409087 seconds in game passed.
At 11.611369466409087 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.4225e-03,  7.2391e-01],
         [ 4.8839e-04,  4.0673e-01],
         [-3.6665e-04,  2.8452e-01],
         [-4.8620e-04,  2.1955e-01]]])
agent 0 action: VehicleControl(throttle=0.738410, steer=0.003723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6104046876807518
Current reward: 0.3861487939276438
Current mitigation activation: 0
#############################
Total reward: 24.88904881431814
11.636369466781616 seconds in game passed.
Action: tensor([[[ 9.4225e-03,  7.2391e-01],
         [ 4.8839e-04,  4.0673e-01],
         [-3.6665e-04,  2.8452e-01],
         [-4.8620e-04,  2.1955e-01]]])
agent 0 action: VehicleControl(throttle=0.689651, steer=0.003519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.88904881431814
11.661369467154145 seconds in game passed.
Action: tensor([[[ 9.4225e-03,  7.2391e-01],
         [ 4.8839e-04,  4.0673e-01],
         [-3.6665e-04,  2.8452e-01],
         [-4.8620e-04,  2.1955e-01]]])
agent 0 action: VehicleControl(throttle=0.630048, steer=0.003550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.88904881431814
11.686369467526674 seconds in game passed.
Action: tensor([[[ 9.4225e-03,  7.2391e-01],
         [ 4.8839e-04,  4.0673e-01],
         [-3.6665e-04,  2.8452e-01],
         [-4.8620e-04,  2.1955e-01]]])
agent 0 action: VehicleControl(throttle=0.572367, steer=0.003582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.88904881431814
+++++++++++++: 1.5175847325033909
11.711369467899203 seconds in game passed.
At 11.711369467899203 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1363e-02, 7.4825e-01],
         [2.3171e-03, 4.1393e-01],
         [1.1858e-03, 2.9006e-01],
         [6.5526e-04, 2.2498e-01]]])
agent 0 action: VehicleControl(throttle=0.529837, steer=0.005777, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5175847325033909
Current reward: 0.39230311489843017
Current mitigation activation: 0
#############################
Total reward: 25.28135192921657
11.736369468271732 seconds in game passed.
Action: tensor([[[1.1363e-02, 7.4825e-01],
         [2.3171e-03, 4.1393e-01],
         [1.1858e-03, 2.9006e-01],
         [6.5526e-04, 2.2498e-01]]])
agent 0 action: VehicleControl(throttle=0.507478, steer=0.005501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.28135192921657
11.761369468644261 seconds in game passed.
Action: tensor([[[1.1363e-02, 7.4825e-01],
         [2.3171e-03, 4.1393e-01],
         [1.1858e-03, 2.9006e-01],
         [6.5526e-04, 2.2498e-01]]])
agent 0 action: VehicleControl(throttle=0.483332, steer=0.005578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.28135192921657
11.78636946901679 seconds in game passed.
Action: tensor([[[1.1363e-02, 7.4825e-01],
         [2.3171e-03, 4.1393e-01],
         [1.1858e-03, 2.9006e-01],
         [6.5526e-04, 2.2498e-01]]])
agent 0 action: VehicleControl(throttle=0.459670, steer=0.005655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.28135192921657
+++++++++++++: 1.4373240199108996
11.81136946938932 seconds in game passed.
At 11.81136946938932 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4371e-02,  7.5920e-01],
         [ 1.3289e-03,  4.2266e-01],
         [-1.5273e-04,  2.9686e-01],
         [-6.4629e-04,  2.3012e-01]]])
agent 0 action: VehicleControl(throttle=0.436359, steer=0.006265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4373240199108996
Current reward: 0.3965562253467453
Current mitigation activation: 0
#############################
Total reward: 25.677908154563315
11.836369469761848 seconds in game passed.
Action: tensor([[[ 1.4371e-02,  7.5920e-01],
         [ 1.3289e-03,  4.2266e-01],
         [-1.5273e-04,  2.9686e-01],
         [-6.4629e-04,  2.3012e-01]]])
agent 0 action: VehicleControl(throttle=0.413524, steer=0.006252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.677908154563315
11.861369470134377 seconds in game passed.
Action: tensor([[[ 1.4371e-02,  7.5920e-01],
         [ 1.3289e-03,  4.2266e-01],
         [-1.5273e-04,  2.9686e-01],
         [-6.4629e-04,  2.3012e-01]]])
agent 0 action: VehicleControl(throttle=0.391162, steer=0.006328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.677908154563315
11.886369470506907 seconds in game passed.
Action: tensor([[[ 1.4371e-02,  7.5920e-01],
         [ 1.3289e-03,  4.2266e-01],
         [-1.5273e-04,  2.9686e-01],
         [-6.4629e-04,  2.3012e-01]]])
agent 0 action: VehicleControl(throttle=0.369268, steer=0.006404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.677908154563315
+++++++++++++: 1.3742816544895216
11.911369470879436 seconds in game passed.
At 11.911369470879436 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0090,  0.7910],
         [-0.0010,  0.4259],
         [-0.0028,  0.2944],
         [-0.0037,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.347471, steer=0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3742816544895216
Current reward: 0.3978134144423544
Current mitigation activation: 0
#############################
Total reward: 26.07572156900567
11.936369471251965 seconds in game passed.
Action: tensor([[[ 0.0090,  0.7910],
         [-0.0010,  0.4259],
         [-0.0028,  0.2944],
         [-0.0037,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.326137, steer=0.003159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.07572156900567
11.961369471624494 seconds in game passed.
Action: tensor([[[ 0.0090,  0.7910],
         [-0.0010,  0.4259],
         [-0.0028,  0.2944],
         [-0.0037,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.305266, steer=0.003202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.07572156900567
11.986369471997023 seconds in game passed.
Action: tensor([[[ 0.0090,  0.7910],
         [-0.0010,  0.4259],
         [-0.0028,  0.2944],
         [-0.0037,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.284856, steer=0.003245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.07572156900567
+++++++++++++: 1.3256273055921701
12.011369472369552 seconds in game passed.
At 12.011369472369552 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0108,  0.8232],
         [-0.0008,  0.4449],
         [-0.0033,  0.3073],
         [-0.0043,  0.2349]]])
agent 0 action: VehicleControl(throttle=0.265119, steer=0.004187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3256273055921701
Current reward: 0.3963469683040779
Current mitigation activation: 0
#############################
Total reward: 26.472068537309745
12.03636947274208 seconds in game passed.
Action: tensor([[[ 0.0108,  0.8232],
         [-0.0008,  0.4449],
         [-0.0033,  0.3073],
         [-0.0043,  0.2349]]])
agent 0 action: VehicleControl(throttle=0.245841, steer=0.004103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.472068537309745
12.06136947311461 seconds in game passed.
Action: tensor([[[ 0.0108,  0.8232],
         [-0.0008,  0.4449],
         [-0.0033,  0.3073],
         [-0.0043,  0.2349]]])
agent 0 action: VehicleControl(throttle=0.227019, steer=0.004167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.472068537309745
12.086369473487139 seconds in game passed.
Action: tensor([[[ 0.0108,  0.8232],
         [-0.0008,  0.4449],
         [-0.0033,  0.3073],
         [-0.0043,  0.2349]]])
agent 0 action: VehicleControl(throttle=0.208653, steer=0.004230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.472068537309745
+++++++++++++: 1.2888262102100225
12.111369473859668 seconds in game passed.
At 12.111369473859668 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 4.0718e-04,  1.0000e+00],
         [-4.8252e-03,  1.0000e+00],
         [-8.0297e-03,  1.0000e+00],
         [-9.0468e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002321, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2888262102100225
Current reward: 0.3925738476192593
Current mitigation activation: 1
#############################
Total reward: 26.864642384929006
12.136369474232197 seconds in game passed.
Action: tensor([[[ 4.0718e-04,  1.0000e+00],
         [-4.8252e-03,  1.0000e+00],
         [-8.0297e-03,  1.0000e+00],
         [-9.0468e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001223, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.864642384929006
12.161369474604726 seconds in game passed.
Action: tensor([[[ 4.0718e-04,  1.0000e+00],
         [-4.8252e-03,  1.0000e+00],
         [-8.0297e-03,  1.0000e+00],
         [-9.0468e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001217, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.864642384929006
12.186369474977255 seconds in game passed.
Action: tensor([[[ 4.0718e-04,  1.0000e+00],
         [-4.8252e-03,  1.0000e+00],
         [-8.0297e-03,  1.0000e+00],
         [-9.0468e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001212, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.864642384929006
+++++++++++++: 1.2653068079705023
12.211369475349784 seconds in game passed.
At 12.211369475349784 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0029,  1.0000],
         [-0.0026,  1.0000],
         [-0.0069,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001728, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2653068079705023
Current reward: 0.3862937587432075
Current mitigation activation: 1
#############################
Total reward: 27.250936143672213
12.236369475722313 seconds in game passed.
Action: tensor([[[ 0.0029,  1.0000],
         [-0.0026,  1.0000],
         [-0.0069,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001235, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.250936143672213
12.261369476094842 seconds in game passed.
Action: tensor([[[ 0.0029,  1.0000],
         [-0.0026,  1.0000],
         [-0.0069,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001233, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.250936143672213
12.286369476467371 seconds in game passed.
Action: tensor([[[ 0.0029,  1.0000],
         [-0.0026,  1.0000],
         [-0.0069,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001231, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.250936143672213
+++++++++++++: 1.2839886665238063
12.3113694768399 seconds in game passed.
At 12.3113694768399 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0038,  1.0000],
         [-0.0162,  1.0000],
         [-0.0196,  1.0000],
         [-0.0182,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006855, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2839886665238063
Current reward: 0.3724936660892296
Current mitigation activation: 1
#############################
Total reward: 27.623429809761443
12.336369477212429 seconds in game passed.
Action: tensor([[[ 0.0038,  1.0000],
         [-0.0162,  1.0000],
         [-0.0196,  1.0000],
         [-0.0182,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005597, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.623429809761443
12.361369477584958 seconds in game passed.
Action: tensor([[[ 0.0038,  1.0000],
         [-0.0162,  1.0000],
         [-0.0196,  1.0000],
         [-0.0182,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005673, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.623429809761443
12.386369477957487 seconds in game passed.
Action: tensor([[[ 0.0038,  1.0000],
         [-0.0162,  1.0000],
         [-0.0196,  1.0000],
         [-0.0182,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005749, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.623429809761443
+++++++++++++: 1.3697012241692486
12.411369478330016 seconds in game passed.
At 12.411369478330016 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0049,  0.9396],
         [-0.0098,  0.5602],
         [-0.0114,  0.3679],
         [-0.0104,  0.2749]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003123, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3697012241692486
Current reward: 0.34930258869739894
Current mitigation activation: 0
#############################
Total reward: 27.97273239845884
12.436369478702545 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9396],
         [-0.0098,  0.5602],
         [-0.0114,  0.3679],
         [-0.0104,  0.2749]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003654, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.97273239845884
12.461369479075074 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9396],
         [-0.0098,  0.5602],
         [-0.0114,  0.3679],
         [-0.0104,  0.2749]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003734, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.97273239845884
12.486369479447603 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9396],
         [-0.0098,  0.5602],
         [-0.0114,  0.3679],
         [-0.0104,  0.2749]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003813, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.97273239845884
+++++++++++++: 1.507676591212927
12.511369479820132 seconds in game passed.
At 12.511369479820132 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0072,  0.9433],
         [-0.0134,  0.5702],
         [-0.0151,  0.3650],
         [-0.0141,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005471, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.507676591212927
Current reward: 0.3235619146915655
Current mitigation activation: 0
#############################
Total reward: 28.29629431315041
12.536369480192661 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9433],
         [-0.0134,  0.5702],
         [-0.0151,  0.3650],
         [-0.0141,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005311, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.29629431315041
12.56136948056519 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9433],
         [-0.0134,  0.5702],
         [-0.0151,  0.3650],
         [-0.0141,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.006516, steer=-0.005410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.29629431315041
12.58636948093772 seconds in game passed.
Action: tensor([[[ 0.0072,  0.9433],
         [-0.0134,  0.5702],
         [-0.0151,  0.3650],
         [-0.0141,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.003416, steer=-0.005509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.29629431315041
+++++++++++++: 1.693420126974232
12.611369481310248 seconds in game passed.
At 12.611369481310248 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0093,  0.9457],
         [-0.0135,  0.5948],
         [-0.0141,  0.3717],
         [-0.0110,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004512, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.693420126974232
Current reward: 0.2988256527190585
Current mitigation activation: 0
#############################
Total reward: 28.59511996586947
12.636369481682777 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9457],
         [-0.0135,  0.5948],
         [-0.0141,  0.3717],
         [-0.0110,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004798, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.59511996586947
12.661369482055306 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9457],
         [-0.0135,  0.5948],
         [-0.0141,  0.3717],
         [-0.0110,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.000237, steer=-0.004901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.59511996586947
12.686369482427835 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9457],
         [-0.0135,  0.5948],
         [-0.0141,  0.3717],
         [-0.0110,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.59511996586947
+++++++++++++: 1.8812285021827946
12.711369482800364 seconds in game passed.
At 12.711369482800364 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0146,  0.9434],
         [-0.0092,  0.5771],
         [-0.0105,  0.3645],
         [-0.0079,  0.2646]]])
agent 0 action: VehicleControl(throttle=0.007393, steer=0.000336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8812285021827946
Current reward: 0.2803179832638652
Current mitigation activation: 0
#############################
Total reward: 28.875437949133335
12.736369483172894 seconds in game passed.
Action: tensor([[[ 0.0146,  0.9434],
         [-0.0092,  0.5771],
         [-0.0105,  0.3645],
         [-0.0079,  0.2646]]])
agent 0 action: VehicleControl(throttle=0.048363, steer=-0.000634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.875437949133335
12.761369483545423 seconds in game passed.
Action: tensor([[[ 0.0146,  0.9434],
         [-0.0092,  0.5771],
         [-0.0105,  0.3645],
         [-0.0079,  0.2646]]])
agent 0 action: VehicleControl(throttle=0.061213, steer=-0.000702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.875437949133335
12.786369483917952 seconds in game passed.
Action: tensor([[[ 0.0146,  0.9434],
         [-0.0092,  0.5771],
         [-0.0105,  0.3645],
         [-0.0079,  0.2646]]])
agent 0 action: VehicleControl(throttle=0.062001, steer=-0.000770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.875437949133335
+++++++++++++: 2.009955243032759
12.81136948429048 seconds in game passed.
At 12.81136948429048 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.9436],
         [-0.0090,  0.5943],
         [-0.0074,  0.3754],
         [-0.0047,  0.2721]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008719, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.009955243032759
Current reward: 0.2705178455128624
Current mitigation activation: 0
#############################
Total reward: 29.1459557946462
12.83636948466301 seconds in game passed.
Action: tensor([[[-0.0030,  0.9436],
         [-0.0090,  0.5943],
         [-0.0074,  0.3754],
         [-0.0047,  0.2721]]])
agent 0 action: VehicleControl(throttle=0.002096, steer=-0.007575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.1459557946462
12.861369485035539 seconds in game passed.
Action: tensor([[[-0.0030,  0.9436],
         [-0.0090,  0.5943],
         [-0.0074,  0.3754],
         [-0.0047,  0.2721]]])
agent 0 action: VehicleControl(throttle=0.002096, steer=-0.007730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.1459557946462
12.886369485408068 seconds in game passed.
Action: tensor([[[-0.0030,  0.9436],
         [-0.0090,  0.5943],
         [-0.0074,  0.3754],
         [-0.0047,  0.2721]]])
agent 0 action: VehicleControl(throttle=0.015850, steer=-0.007885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.1459557946462
+++++++++++++: 2.1090640241556176
12.911369485780597 seconds in game passed.
At 12.911369485780597 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0113, 0.9369],
         [0.0055, 0.5413],
         [0.0016, 0.3580],
         [0.0015, 0.2608]]])
agent 0 action: VehicleControl(throttle=0.686858, steer=0.009164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1090640241556176
Current reward: 0.2645636094612486
Current mitigation activation: 0
#############################
Total reward: 29.410519404107447
12.936369486153126 seconds in game passed.
Action: tensor([[[0.0113, 0.9369],
         [0.0055, 0.5413],
         [0.0016, 0.3580],
         [0.0015, 0.2608]]])
agent 0 action: VehicleControl(throttle=0.676338, steer=0.006397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.410519404107447
12.961369486525655 seconds in game passed.
Action: tensor([[[0.0113, 0.9369],
         [0.0055, 0.5413],
         [0.0016, 0.3580],
         [0.0015, 0.2608]]])
agent 0 action: VehicleControl(throttle=0.729015, steer=0.006460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.410519404107447
12.986369486898184 seconds in game passed.
Action: tensor([[[0.0113, 0.9369],
         [0.0055, 0.5413],
         [0.0016, 0.3580],
         [0.0015, 0.2608]]])
agent 0 action: VehicleControl(throttle=0.778108, steer=0.006524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.410519404107447
+++++++++++++: 2.3300308255977042
13.011369487270713 seconds in game passed.
At 13.011369487270713 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0073, 0.9342],
         [0.0050, 0.5290],
         [0.0017, 0.3515],
         [0.0015, 0.2576]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3300308255977042
Current reward: 0.2526793098119717
Current mitigation activation: 0
#############################
Total reward: 29.663198713919417
13.036369487643242 seconds in game passed.
Action: tensor([[[0.0073, 0.9342],
         [0.0050, 0.5290],
         [0.0017, 0.3515],
         [0.0015, 0.2576]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.663198713919417
13.061369488015771 seconds in game passed.
Action: tensor([[[0.0073, 0.9342],
         [0.0050, 0.5290],
         [0.0017, 0.3515],
         [0.0015, 0.2576]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.663198713919417
13.0863694883883 seconds in game passed.
Action: tensor([[[0.0073, 0.9342],
         [0.0050, 0.5290],
         [0.0017, 0.3515],
         [0.0015, 0.2576]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.663198713919417
+++++++++++++: 2.503702422317056
13.111369488760829 seconds in game passed.
At 13.111369488760829 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0038, 0.9336],
         [0.0054, 0.5269],
         [0.0033, 0.3499],
         [0.0031, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.503702422317056
Current reward: 0.24604779078747507
Current mitigation activation: 0
#############################
Total reward: 29.909246504706893
13.136369489133358 seconds in game passed.
Action: tensor([[[0.0038, 0.9336],
         [0.0054, 0.5269],
         [0.0033, 0.3499],
         [0.0031, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.909246504706893
13.161369489505887 seconds in game passed.
Action: tensor([[[0.0038, 0.9336],
         [0.0054, 0.5269],
         [0.0033, 0.3499],
         [0.0031, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.909246504706893
13.186369489878416 seconds in game passed.
Action: tensor([[[0.0038, 0.9336],
         [0.0054, 0.5269],
         [0.0033, 0.3499],
         [0.0031, 0.2570]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.909246504706893
+++++++++++++: 2.534235671686175
13.211369490250945 seconds in game passed.
At 13.211369490250945 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.9995e-03, 9.2259e-01],
         [3.4730e-03, 5.0516e-01],
         [5.3584e-04, 3.3886e-01],
         [3.6411e-04, 2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.534235671686175
Current reward: 0.2473669565245618
Current mitigation activation: 0
#############################
Total reward: 30.156613461231455
13.236369490623474 seconds in game passed.
Action: tensor([[[5.9995e-03, 9.2259e-01],
         [3.4730e-03, 5.0516e-01],
         [5.3584e-04, 3.3886e-01],
         [3.6411e-04, 2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.156613461231455
13.261369490996003 seconds in game passed.
Action: tensor([[[5.9995e-03, 9.2259e-01],
         [3.4730e-03, 5.0516e-01],
         [5.3584e-04, 3.3886e-01],
         [3.6411e-04, 2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.156613461231455
13.286369491368532 seconds in game passed.
Action: tensor([[[5.9995e-03, 9.2259e-01],
         [3.4730e-03, 5.0516e-01],
         [5.3584e-04, 3.3886e-01],
         [3.6411e-04, 2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003989, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.156613461231455
+++++++++++++: 2.4552035542887363
13.311369491741061 seconds in game passed.
At 13.311369491741061 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.8890e-03,  9.1059e-01],
         [-3.3049e-04,  4.9810e-01],
         [-2.0385e-03,  3.3882e-01],
         [-1.6311e-03,  2.5360e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4552035542887363
Current reward: 0.25403607365975195
Current mitigation activation: 0
#############################
Total reward: 30.410649534891206
13.33636949211359 seconds in game passed.
Action: tensor([[[-1.8890e-03,  9.1059e-01],
         [-3.3049e-04,  4.9810e-01],
         [-2.0385e-03,  3.3882e-01],
         [-1.6311e-03,  2.5360e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001004, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.410649534891206
13.36136949248612 seconds in game passed.
Action: tensor([[[-1.8890e-03,  9.1059e-01],
         [-3.3049e-04,  4.9810e-01],
         [-2.0385e-03,  3.3882e-01],
         [-1.6311e-03,  2.5360e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.410649534891206
13.386369492858648 seconds in game passed.
Action: tensor([[[-1.8890e-03,  9.1059e-01],
         [-3.3049e-04,  4.9810e-01],
         [-2.0385e-03,  3.3882e-01],
         [-1.6311e-03,  2.5360e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.410649534891206
+++++++++++++: 2.3323683534686577
13.411369493231177 seconds in game passed.
At 13.411369493231177 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0101,  0.9108],
         [-0.0019,  0.5126],
         [-0.0028,  0.3544],
         [-0.0024,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3323683534686577
Current reward: 0.2630660018449216
Current mitigation activation: 0
#############################
Total reward: 30.67371553673613
13.436369493603706 seconds in game passed.
Action: tensor([[[-0.0101,  0.9108],
         [-0.0019,  0.5126],
         [-0.0028,  0.3544],
         [-0.0024,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.67371553673613
13.461369493976235 seconds in game passed.
Action: tensor([[[-0.0101,  0.9108],
         [-0.0019,  0.5126],
         [-0.0028,  0.3544],
         [-0.0024,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.67371553673613
13.486369494348764 seconds in game passed.
Action: tensor([[[-0.0101,  0.9108],
         [-0.0019,  0.5126],
         [-0.0028,  0.3544],
         [-0.0024,  0.2692]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.67371553673613
+++++++++++++: 2.1981097955336457
13.511369494721293 seconds in game passed.
At 13.511369494721293 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0056,  0.9013],
         [-0.0033,  0.5182],
         [-0.0042,  0.3731],
         [-0.0030,  0.2939]]])
agent 0 action: VehicleControl(throttle=0.837961, steer=-0.003887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1981097955336457
Current reward: 0.2730203535944763
Current mitigation activation: 0
#############################
Total reward: 30.946735890330604
13.536369495093822 seconds in game passed.
Action: tensor([[[-0.0056,  0.9013],
         [-0.0033,  0.5182],
         [-0.0042,  0.3731],
         [-0.0030,  0.2939]]])
agent 0 action: VehicleControl(throttle=0.821422, steer=-0.004006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.946735890330604
13.561369495466352 seconds in game passed.
Action: tensor([[[-0.0056,  0.9013],
         [-0.0033,  0.5182],
         [-0.0042,  0.3731],
         [-0.0030,  0.2939]]])
agent 0 action: VehicleControl(throttle=0.790937, steer=-0.003986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.946735890330604
13.58636949583888 seconds in game passed.
Action: tensor([[[-0.0056,  0.9013],
         [-0.0033,  0.5182],
         [-0.0042,  0.3731],
         [-0.0030,  0.2939]]])
agent 0 action: VehicleControl(throttle=0.760535, steer=-0.003967, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.946735890330604
+++++++++++++: 2.066669960889747
13.61136949621141 seconds in game passed.
At 13.61136949621141 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.1620e-04,  8.8363e-01],
         [-1.9401e-03,  5.0863e-01],
         [-3.6282e-03,  3.6783e-01],
         [-2.9200e-03,  2.9012e-01]]])
agent 0 action: VehicleControl(throttle=0.785745, steer=-0.000403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.066669960889747
Current reward: 0.2831420983472813
Current mitigation activation: 0
#############################
Total reward: 31.229877988677885
13.636369496583939 seconds in game passed.
Action: tensor([[[ 3.1620e-04,  8.8363e-01],
         [-1.9401e-03,  5.0863e-01],
         [-3.6282e-03,  3.6783e-01],
         [-2.9200e-03,  2.9012e-01]]])
agent 0 action: VehicleControl(throttle=0.750882, steer=-0.000945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.229877988677885
13.661369496956468 seconds in game passed.
Action: tensor([[[ 3.1620e-04,  8.8363e-01],
         [-1.9401e-03,  5.0863e-01],
         [-3.6282e-03,  3.6783e-01],
         [-2.9200e-03,  2.9012e-01]]])
agent 0 action: VehicleControl(throttle=0.722406, steer=-0.000900, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.229877988677885
13.686369497328997 seconds in game passed.
Action: tensor([[[ 3.1620e-04,  8.8363e-01],
         [-1.9401e-03,  5.0863e-01],
         [-3.6282e-03,  3.6783e-01],
         [-2.9200e-03,  2.9012e-01]]])
agent 0 action: VehicleControl(throttle=0.694153, steer=-0.000855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.229877988677885
+++++++++++++: 1.9496668042975691
13.711369497701526 seconds in game passed.
At 13.711369497701526 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.5878e-03,  8.8956e-01],
         [-4.7176e-04,  5.0066e-01],
         [-1.5965e-03,  3.5545e-01],
         [-1.2814e-03,  2.7678e-01]]])
agent 0 action: VehicleControl(throttle=0.819151, steer=-0.001432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9496668042975691
Current reward: 0.2925019624171421
Current mitigation activation: 0
#############################
Total reward: 31.522379951095026
13.736369498074055 seconds in game passed.
Action: tensor([[[-3.5878e-03,  8.8956e-01],
         [-4.7176e-04,  5.0066e-01],
         [-1.5965e-03,  3.5545e-01],
         [-1.2814e-03,  2.7678e-01]]])
agent 0 action: VehicleControl(throttle=0.777642, steer=-0.001356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.522379951095026
13.761369498446584 seconds in game passed.
Action: tensor([[[-3.5878e-03,  8.8956e-01],
         [-4.7176e-04,  5.0066e-01],
         [-1.5965e-03,  3.5545e-01],
         [-1.2814e-03,  2.7678e-01]]])
agent 0 action: VehicleControl(throttle=0.752885, steer=-0.001374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.522379951095026
13.786369498819113 seconds in game passed.
Action: tensor([[[-3.5878e-03,  8.8956e-01],
         [-4.7176e-04,  5.0066e-01],
         [-1.5965e-03,  3.5545e-01],
         [-1.2814e-03,  2.7678e-01]]])
agent 0 action: VehicleControl(throttle=0.727753, steer=-0.001391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.522379951095026
+++++++++++++: 1.8507128278384393
13.811369499191642 seconds in game passed.
At 13.811369499191642 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.9244],
         [-0.0011,  0.5129],
         [-0.0031,  0.3492],
         [-0.0028,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.683510, steer=-0.001271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8507128278384393
Current reward: 0.30053203833926095
Current mitigation activation: 0
#############################
Total reward: 31.822911989434285
13.83636949956417 seconds in game passed.
Action: tensor([[[-0.0024,  0.9244],
         [-0.0011,  0.5129],
         [-0.0031,  0.3492],
         [-0.0028,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.661529, steer=-0.001216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.822911989434285
13.8613694999367 seconds in game passed.
Action: tensor([[[-0.0024,  0.9244],
         [-0.0011,  0.5129],
         [-0.0031,  0.3492],
         [-0.0028,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.638091, steer=-0.001151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.822911989434285
13.886369500309229 seconds in game passed.
Action: tensor([[[-0.0024,  0.9244],
         [-0.0011,  0.5129],
         [-0.0031,  0.3492],
         [-0.0028,  0.2632]]])
agent 0 action: VehicleControl(throttle=0.615514, steer=-0.001087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.822911989434285
+++++++++++++: 1.7643843720027061
13.911369500681758 seconds in game passed.
At 13.911369500681758 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0039,  0.9344],
         [-0.0055,  0.5165],
         [-0.0083,  0.3429],
         [-0.0072,  0.2538]]])
agent 0 action: VehicleControl(throttle=0.578443, steer=-0.001934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7643843720027061
Current reward: 0.30745097497919566
Current mitigation activation: 0
#############################
Total reward: 32.13036296441348
13.936369501054287 seconds in game passed.
Action: tensor([[[ 0.0039,  0.9344],
         [-0.0055,  0.5165],
         [-0.0083,  0.3429],
         [-0.0072,  0.2538]]])
agent 0 action: VehicleControl(throttle=0.551020, steer=-0.001933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.13036296441348
13.961369501426816 seconds in game passed.
Action: tensor([[[ 0.0039,  0.9344],
         [-0.0055,  0.5165],
         [-0.0083,  0.3429],
         [-0.0072,  0.2538]]])
agent 0 action: VehicleControl(throttle=0.523611, steer=-0.002053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.13036296441348
13.986369501799345 seconds in game passed.
Action: tensor([[[ 0.0039,  0.9344],
         [-0.0055,  0.5165],
         [-0.0083,  0.3429],
         [-0.0072,  0.2538]]])
agent 0 action: VehicleControl(throttle=0.497384, steer=-0.002173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.13036296441348
+++++++++++++: 1.6931818642262095
14.011369502171874 seconds in game passed.
At 14.011369502171874 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0050,  0.9377],
         [-0.0023,  0.5262],
         [-0.0044,  0.3445],
         [-0.0025,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.344717, steer=0.000664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6931818642262095
Current reward: 0.3128023392976881
Current mitigation activation: 0
#############################
Total reward: 32.44316530371117
14.036369502544403 seconds in game passed.
Action: tensor([[[ 0.0050,  0.9377],
         [-0.0023,  0.5262],
         [-0.0044,  0.3445],
         [-0.0025,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.331679, steer=0.000112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.44316530371117
14.061369502916932 seconds in game passed.
Action: tensor([[[ 0.0050,  0.9377],
         [-0.0023,  0.5262],
         [-0.0044,  0.3445],
         [-0.0025,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.307460, steer=0.000045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.44316530371117
14.086369503289461 seconds in game passed.
Action: tensor([[[ 0.0050,  0.9377],
         [-0.0023,  0.5262],
         [-0.0044,  0.3445],
         [-0.0025,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.293161, steer=-0.000022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.44316530371117
+++++++++++++: 1.6421317363939751
14.11136950366199 seconds in game passed.
At 14.11136950366199 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0049,  0.9415],
         [-0.0030,  0.5480],
         [-0.0043,  0.3564],
         [-0.0020,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.280998, steer=-0.000566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6421317363939751
Current reward: 0.3158381050919232
Current mitigation activation: 0
#############################
Total reward: 32.75900340880309
14.13636950403452 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9415],
         [-0.0030,  0.5480],
         [-0.0043,  0.3564],
         [-0.0020,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.268483, steer=-0.000546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.75900340880309
14.161369504407048 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9415],
         [-0.0030,  0.5480],
         [-0.0043,  0.3564],
         [-0.0020,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.256080, steer=-0.000607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.75900340880309
14.186369504779577 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9415],
         [-0.0030,  0.5480],
         [-0.0043,  0.3564],
         [-0.0020,  0.2610]]])
agent 0 action: VehicleControl(throttle=0.243851, steer=-0.000667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.75900340880309
+++++++++++++: 1.619455349700655
14.211369505152106 seconds in game passed.
At 14.211369505152106 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0060,  0.9395],
         [-0.0039,  0.5433],
         [-0.0059,  0.3528],
         [-0.0042,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.228868, steer=-0.000905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.619455349700655
Current reward: 0.3155062289638606
Current mitigation activation: 0
#############################
Total reward: 33.07450963776695
14.236369505524635 seconds in game passed.
Action: tensor([[[ 0.0060,  0.9395],
         [-0.0039,  0.5433],
         [-0.0059,  0.3528],
         [-0.0042,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.214153, steer=-0.000931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.07450963776695
14.261369505897164 seconds in game passed.
Action: tensor([[[ 0.0060,  0.9395],
         [-0.0039,  0.5433],
         [-0.0059,  0.3528],
         [-0.0042,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.199744, steer=-0.000988, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.07450963776695
14.286369506269693 seconds in game passed.
Action: tensor([[[ 0.0060,  0.9395],
         [-0.0039,  0.5433],
         [-0.0059,  0.3528],
         [-0.0042,  0.2568]]])
agent 0 action: VehicleControl(throttle=0.185670, steer=-0.001044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.07450963776695
+++++++++++++: 1.6229215620503068
14.311369506642222 seconds in game passed.
At 14.311369506642222 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.9389],
         [-0.0013,  0.5422],
         [-0.0034,  0.3574],
         [-0.0028,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.171360, steer=-0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6229215620503068
Current reward: 0.3121909455764005
Current mitigation activation: 0
#############################
Total reward: 33.386700583343355
14.336369507014751 seconds in game passed.
Action: tensor([[[-0.0014,  0.9389],
         [-0.0013,  0.5422],
         [-0.0034,  0.3574],
         [-0.0028,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.157430, steer=-0.002090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.386700583343355
14.36136950738728 seconds in game passed.
Action: tensor([[[-0.0014,  0.9389],
         [-0.0013,  0.5422],
         [-0.0034,  0.3574],
         [-0.0028,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.143898, steer=-0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.386700583343355
14.38636950775981 seconds in game passed.
Action: tensor([[[-0.0014,  0.9389],
         [-0.0013,  0.5422],
         [-0.0034,  0.3574],
         [-0.0028,  0.2648]]])
agent 0 action: VehicleControl(throttle=0.130779, steer=-0.002101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.386700583343355
+++++++++++++: 1.6473147335734868
14.411369508132339 seconds in game passed.
At 14.411369508132339 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.4626e-03,  9.4248e-01],
         [ 2.2307e-04,  5.6652e-01],
         [-1.1194e-03,  3.6547e-01],
         [-7.1375e-04,  2.6499e-01]]])
agent 0 action: VehicleControl(throttle=0.120540, steer=-0.001893, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6473147335734868
Current reward: 0.3068393393087624
Current mitigation activation: 0
#############################
Total reward: 33.693539922652114
14.436369508504868 seconds in game passed.
Action: tensor([[[-3.4626e-03,  9.4248e-01],
         [ 2.2307e-04,  5.6652e-01],
         [-1.1194e-03,  3.6547e-01],
         [-7.1375e-04,  2.6499e-01]]])
agent 0 action: VehicleControl(throttle=0.110734, steer=-0.001876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.693539922652114
14.461369508877397 seconds in game passed.
Action: tensor([[[-3.4626e-03,  9.4248e-01],
         [ 2.2307e-04,  5.6652e-01],
         [-1.1194e-03,  3.6547e-01],
         [-7.1375e-04,  2.6499e-01]]])
agent 0 action: VehicleControl(throttle=0.101370, steer=-0.001831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.693539922652114
14.486369509249926 seconds in game passed.
Action: tensor([[[-3.4626e-03,  9.4248e-01],
         [ 2.2307e-04,  5.6652e-01],
         [-1.1194e-03,  3.6547e-01],
         [-7.1375e-04,  2.6499e-01]]])
agent 0 action: VehicleControl(throttle=0.092454, steer=-0.001787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.693539922652114
+++++++++++++: 1.6913269499002295
14.511369509622455 seconds in game passed.
At 14.511369509622455 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.5035e-03,  9.4146e-01],
         [ 2.5203e-03,  5.7700e-01],
         [ 1.1656e-03,  3.8205e-01],
         [ 5.5718e-04,  2.8489e-01]]])
agent 0 action: VehicleControl(throttle=0.085399, steer=-0.000993, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6913269499002295
Current reward: 0.3000171452209005
Current mitigation activation: 0
#############################
Total reward: 33.99355706787301
14.536369509994984 seconds in game passed.
Action: tensor([[[-5.5035e-03,  9.4146e-01],
         [ 2.5203e-03,  5.7700e-01],
         [ 1.1656e-03,  3.8205e-01],
         [ 5.5718e-04,  2.8489e-01]]])
agent 0 action: VehicleControl(throttle=0.078802, steer=-0.001075, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.99355706787301
14.561369510367513 seconds in game passed.
Action: tensor([[[-5.5035e-03,  9.4146e-01],
         [ 2.5203e-03,  5.7700e-01],
         [ 1.1656e-03,  3.8205e-01],
         [ 5.5718e-04,  2.8489e-01]]])
agent 0 action: VehicleControl(throttle=0.072662, steer=-0.001031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.99355706787301
14.586369510740042 seconds in game passed.
Action: tensor([[[-5.5035e-03,  9.4146e-01],
         [ 2.5203e-03,  5.7700e-01],
         [ 1.1656e-03,  3.8205e-01],
         [ 5.5718e-04,  2.8489e-01]]])
agent 0 action: VehicleControl(throttle=0.066975, steer=-0.000987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.99355706787301
+++++++++++++: 1.7549001870082548
14.61136951111257 seconds in game passed.
At 14.61136951111257 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0150,  0.9442],
         [-0.0029,  0.5912],
         [-0.0020,  0.3803],
         [-0.0014,  0.2779]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009477, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7549001870082548
Current reward: 0.2921834759723122
Current mitigation activation: 0
#############################
Total reward: 34.28574054384533
14.6363695114851 seconds in game passed.
Action: tensor([[[-0.0150,  0.9442],
         [-0.0029,  0.5912],
         [-0.0020,  0.3803],
         [-0.0014,  0.2779]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008156, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.28574054384533
14.661369511857629 seconds in game passed.
Action: tensor([[[-0.0150,  0.9442],
         [-0.0029,  0.5912],
         [-0.0020,  0.3803],
         [-0.0014,  0.2779]]])
agent 0 action: VehicleControl(throttle=0.050692, steer=-0.008237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.28574054384533
14.686369512230158 seconds in game passed.
Action: tensor([[[-0.0150,  0.9442],
         [-0.0029,  0.5912],
         [-0.0020,  0.3803],
         [-0.0014,  0.2779]]])
agent 0 action: VehicleControl(throttle=0.046100, steer=-0.008317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.28574054384533
+++++++++++++: 1.842847827833978
14.711369512602687 seconds in game passed.
At 14.711369512602687 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0168,  0.9467],
         [-0.0033,  0.6049],
         [-0.0023,  0.3792],
         [-0.0014,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009594, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.842847827833978
Current reward: 0.28337048692005407
Current mitigation activation: 0
#############################
Total reward: 34.569111030765384
14.736369512975216 seconds in game passed.
Action: tensor([[[-0.0168,  0.9467],
         [-0.0033,  0.6049],
         [-0.0023,  0.3792],
         [-0.0014,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.034724, steer=-0.009483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.569111030765384
14.761369513347745 seconds in game passed.
Action: tensor([[[-0.0168,  0.9467],
         [-0.0033,  0.6049],
         [-0.0023,  0.3792],
         [-0.0014,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.029593, steer=-0.009570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.569111030765384
14.786369513720274 seconds in game passed.
Action: tensor([[[-0.0168,  0.9467],
         [-0.0033,  0.6049],
         [-0.0023,  0.3792],
         [-0.0014,  0.2733]]])
agent 0 action: VehicleControl(throttle=0.024826, steer=-0.009657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.569111030765384
+++++++++++++: 1.9629960431898446
14.811369514092803 seconds in game passed.
At 14.811369514092803 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.7798e-02,  9.4830e-01],
         [-2.8044e-03,  6.2630e-01],
         [-1.6807e-03,  3.8744e-01],
         [-6.3802e-04,  2.7862e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010026, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9629960431898446
Current reward: 0.2735596797719422
Current mitigation activation: 0
#############################
Total reward: 34.84267071053733
14.836369514465332 seconds in game passed.
Action: tensor([[[-1.7798e-02,  9.4830e-01],
         [-2.8044e-03,  6.2630e-01],
         [-1.6807e-03,  3.8744e-01],
         [-6.3802e-04,  2.7862e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010070, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.84267071053733
14.861369514837861 seconds in game passed.
Action: tensor([[[-1.7798e-02,  9.4830e-01],
         [-2.8044e-03,  6.2630e-01],
         [-1.6807e-03,  3.8744e-01],
         [-6.3802e-04,  2.7862e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010160, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.84267071053733
14.88636951521039 seconds in game passed.
Action: tensor([[[-1.7798e-02,  9.4830e-01],
         [-2.8044e-03,  6.2630e-01],
         [-1.6807e-03,  3.8744e-01],
         [-6.3802e-04,  2.7862e-01]]])
agent 0 action: VehicleControl(throttle=0.010127, steer=-0.010251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.84267071053733
+++++++++++++: 2.1076257061732933
14.91136951558292 seconds in game passed.
At 14.91136951558292 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0122,  0.9464],
         [ 0.0010,  0.5907],
         [ 0.0010,  0.3765],
         [ 0.0013,  0.2737]]])
agent 0 action: VehicleControl(throttle=0.119542, steer=-0.004642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1076257061732933
Current reward: 0.26400471308898454
Current mitigation activation: 0
#############################
Total reward: 35.106675423626314
14.936369515955448 seconds in game passed.
Action: tensor([[[-0.0122,  0.9464],
         [ 0.0010,  0.5907],
         [ 0.0010,  0.3765],
         [ 0.0013,  0.2737]]])
agent 0 action: VehicleControl(throttle=0.158665, steer=-0.005605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.106675423626314
14.961369516327977 seconds in game passed.
Action: tensor([[[-0.0122,  0.9464],
         [ 0.0010,  0.5907],
         [ 0.0010,  0.3765],
         [ 0.0013,  0.2737]]])
agent 0 action: VehicleControl(throttle=0.196315, steer=-0.005629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.106675423626314
14.986369516700506 seconds in game passed.
Action: tensor([[[-0.0122,  0.9464],
         [ 0.0010,  0.5907],
         [ 0.0010,  0.3765],
         [ 0.0013,  0.2737]]])
agent 0 action: VehicleControl(throttle=0.230843, steer=-0.005653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.106675423626314
+++++++++++++: 2.3037135725705093
15.011369517073035 seconds in game passed.
At 15.011369517073035 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.9413],
         [ 0.0030,  0.5431],
         [ 0.0011,  0.3543],
         [ 0.0013,  0.2589]]])
agent 0 action: VehicleControl(throttle=0.824522, steer=0.001068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3037135725705093
Current reward: 0.2535208982827521
Current mitigation activation: 0
#############################
Total reward: 35.360196321909065
15.036369517445564 seconds in game passed.
Action: tensor([[[-0.0010,  0.9413],
         [ 0.0030,  0.5431],
         [ 0.0011,  0.3543],
         [ 0.0013,  0.2589]]])
agent 0 action: VehicleControl(throttle=0.803926, steer=-0.000035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.360196321909065
15.061369517818093 seconds in game passed.
Action: tensor([[[-0.0010,  0.9413],
         [ 0.0030,  0.5431],
         [ 0.0011,  0.3543],
         [ 0.0013,  0.2589]]])
agent 0 action: VehicleControl(throttle=0.840156, steer=-0.000019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.360196321909065
15.086369518190622 seconds in game passed.
Action: tensor([[[-0.0010,  0.9413],
         [ 0.0030,  0.5431],
         [ 0.0011,  0.3543],
         [ 0.0013,  0.2589]]])
agent 0 action: VehicleControl(throttle=0.872392, steer=-0.000004, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.360196321909065
+++++++++++++: 2.4761479561730133
15.111369518563151 seconds in game passed.
At 15.111369518563151 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.4485e-03,  9.2801e-01],
         [ 1.6349e-03,  5.0387e-01],
         [-4.2950e-04,  3.3407e-01],
         [-2.4699e-04,  2.4470e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4761479561730133
Current reward: 0.24670193133575458
Current mitigation activation: 0
#############################
Total reward: 35.60689825324482
15.13636951893568 seconds in game passed.
Action: tensor([[[-3.4485e-03,  9.2801e-01],
         [ 1.6349e-03,  5.0387e-01],
         [-4.2950e-04,  3.3407e-01],
         [-2.4699e-04,  2.4470e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.60689825324482
15.16136951930821 seconds in game passed.
Action: tensor([[[-3.4485e-03,  9.2801e-01],
         [ 1.6349e-03,  5.0387e-01],
         [-4.2950e-04,  3.3407e-01],
         [-2.4699e-04,  2.4470e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.60689825324482
15.186369519680738 seconds in game passed.
Action: tensor([[[-3.4485e-03,  9.2801e-01],
         [ 1.6349e-03,  5.0387e-01],
         [-4.2950e-04,  3.3407e-01],
         [-2.4699e-04,  2.4470e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.60689825324482
+++++++++++++: 2.5658718906118048
15.211369520053267 seconds in game passed.
At 15.211369520053267 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.8953e-03, 9.2668e-01],
         [3.4401e-03, 5.0494e-01],
         [1.7211e-04, 3.3453e-01],
         [1.8299e-05, 2.4386e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5658718906118048
Current reward: 0.24514335104284557
Current mitigation activation: 0
#############################
Total reward: 35.85204160428767
15.236369520425797 seconds in game passed.
Action: tensor([[[3.8953e-03, 9.2668e-01],
         [3.4401e-03, 5.0494e-01],
         [1.7211e-04, 3.3453e-01],
         [1.8299e-05, 2.4386e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.85204160428767
15.261369520798326 seconds in game passed.
Action: tensor([[[3.8953e-03, 9.2668e-01],
         [3.4401e-03, 5.0494e-01],
         [1.7211e-04, 3.3453e-01],
         [1.8299e-05, 2.4386e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.85204160428767
15.286369521170855 seconds in game passed.
Action: tensor([[[3.8953e-03, 9.2668e-01],
         [3.4401e-03, 5.0494e-01],
         [1.7211e-04, 3.3453e-01],
         [1.8299e-05, 2.4386e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.85204160428767
+++++++++++++: 2.523717073604962
15.311369521543384 seconds in game passed.
At 15.311369521543384 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4638e-02, 9.1018e-01],
         [4.1283e-03, 4.9091e-01],
         [5.0955e-04, 3.2821e-01],
         [3.5723e-04, 2.3937e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007207, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.523717073604962
Current reward: 0.2500304218445808
Current mitigation activation: 0
#############################
Total reward: 36.10207202613225
15.336369521915913 seconds in game passed.
Action: tensor([[[1.4638e-02, 9.1018e-01],
         [4.1283e-03, 4.9091e-01],
         [5.0955e-04, 3.2821e-01],
         [3.5723e-04, 2.3937e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.10207202613225
15.361369522288442 seconds in game passed.
Action: tensor([[[1.4638e-02, 9.1018e-01],
         [4.1283e-03, 4.9091e-01],
         [5.0955e-04, 3.2821e-01],
         [3.5723e-04, 2.3937e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.10207202613225
15.38636952266097 seconds in game passed.
Action: tensor([[[1.4638e-02, 9.1018e-01],
         [4.1283e-03, 4.9091e-01],
         [5.0955e-04, 3.2821e-01],
         [3.5723e-04, 2.3937e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006721, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.10207202613225
+++++++++++++: 2.4181986814730436
15.4113695230335 seconds in game passed.
At 15.4113695230335 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0147, 0.9057],
         [0.0042, 0.4932],
         [0.0016, 0.3301],
         [0.0016, 0.2401]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4181986814730436
Current reward: 0.2580342483178151
Current mitigation activation: 0
#############################
Total reward: 36.36010627445006
15.436369523406029 seconds in game passed.
Action: tensor([[[0.0147, 0.9057],
         [0.0042, 0.4932],
         [0.0016, 0.3301],
         [0.0016, 0.2401]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.36010627445006
15.461369523778558 seconds in game passed.
Action: tensor([[[0.0147, 0.9057],
         [0.0042, 0.4932],
         [0.0016, 0.3301],
         [0.0016, 0.2401]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.36010627445006
15.486369524151087 seconds in game passed.
Action: tensor([[[0.0147, 0.9057],
         [0.0042, 0.4932],
         [0.0016, 0.3301],
         [0.0016, 0.2401]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.36010627445006
+++++++++++++: 2.4018435567363303
15.511369524523616 seconds in game passed.
At 15.511369524523616 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0154, 0.9097],
         [0.0040, 0.4913],
         [0.0018, 0.3278],
         [0.0022, 0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4018435567363303
Current reward: 0.2611076489785984
Current mitigation activation: 0
#############################
Total reward: 36.62121392342866
15.536369524896145 seconds in game passed.
Action: tensor([[[0.0154, 0.9097],
         [0.0040, 0.4913],
         [0.0018, 0.3278],
         [0.0022, 0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.62121392342866
15.561369525268674 seconds in game passed.
Action: tensor([[[0.0154, 0.9097],
         [0.0040, 0.4913],
         [0.0018, 0.3278],
         [0.0022, 0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.62121392342866
15.586369525641203 seconds in game passed.
Action: tensor([[[0.0154, 0.9097],
         [0.0040, 0.4913],
         [0.0018, 0.3278],
         [0.0022, 0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.62121392342866
+++++++++++++: 2.4252641832598707
15.611369526013732 seconds in game passed.
At 15.611369526013732 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0119, 0.9027],
         [0.0031, 0.4788],
         [0.0016, 0.3205],
         [0.0022, 0.2347]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005735, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4252641832598707
Current reward: 0.2618945249691519
Current mitigation activation: 0
#############################
Total reward: 36.88310844839781
15.636369526386261 seconds in game passed.
Action: tensor([[[0.0119, 0.9027],
         [0.0031, 0.4788],
         [0.0016, 0.3205],
         [0.0022, 0.2347]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.88310844839781
15.66136952675879 seconds in game passed.
Action: tensor([[[0.0119, 0.9027],
         [0.0031, 0.4788],
         [0.0016, 0.3205],
         [0.0022, 0.2347]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.88310844839781
15.686369527131319 seconds in game passed.
Action: tensor([[[0.0119, 0.9027],
         [0.0031, 0.4788],
         [0.0016, 0.3205],
         [0.0022, 0.2347]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.88310844839781
+++++++++++++: 2.4484921874059844
15.711369527503848 seconds in game passed.
At 15.711369527503848 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.9459e-03,  8.9501e-01],
         [ 9.5509e-04,  4.6940e-01],
         [-1.1027e-06,  3.1449e-01],
         [ 7.6111e-04,  2.3135e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4484921874059844
Current reward: 0.2627094306400076
Current mitigation activation: 0
#############################
Total reward: 37.14581787903782
15.736369527876377 seconds in game passed.
Action: tensor([[[ 4.9459e-03,  8.9501e-01],
         [ 9.5509e-04,  4.6940e-01],
         [-1.1027e-06,  3.1449e-01],
         [ 7.6111e-04,  2.3135e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.14581787903782
15.761369528248906 seconds in game passed.
Action: tensor([[[ 4.9459e-03,  8.9501e-01],
         [ 9.5509e-04,  4.6940e-01],
         [-1.1027e-06,  3.1449e-01],
         [ 7.6111e-04,  2.3135e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.14581787903782
15.786369528621435 seconds in game passed.
Action: tensor([[[ 4.9459e-03,  8.9501e-01],
         [ 9.5509e-04,  4.6940e-01],
         [-1.1027e-06,  3.1449e-01],
         [ 7.6111e-04,  2.3135e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.14581787903782
+++++++++++++: 2.4719390116568163
15.811369528993964 seconds in game passed.
At 15.811369528993964 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.1842e-04,  8.8069e-01],
         [-1.7732e-03,  4.6048e-01],
         [-2.6461e-03,  3.0991e-01],
         [-2.0647e-03,  2.2921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4719390116568163
Current reward: 0.2635278750319427
Current mitigation activation: 0
#############################
Total reward: 37.40934575406976
15.836369529366493 seconds in game passed.
Action: tensor([[[ 6.1842e-04,  8.8069e-01],
         [-1.7732e-03,  4.6048e-01],
         [-2.6461e-03,  3.0991e-01],
         [-2.0647e-03,  2.2921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.40934575406976
15.861369529739022 seconds in game passed.
Action: tensor([[[ 6.1842e-04,  8.8069e-01],
         [-1.7732e-03,  4.6048e-01],
         [-2.6461e-03,  3.0991e-01],
         [-2.0647e-03,  2.2921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.40934575406976
15.886369530111551 seconds in game passed.
Action: tensor([[[ 6.1842e-04,  8.8069e-01],
         [-1.7732e-03,  4.6048e-01],
         [-2.6461e-03,  3.0991e-01],
         [-2.0647e-03,  2.2921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.40934575406976
+++++++++++++: 2.4929947694614616
15.91136953048408 seconds in game passed.
At 15.91136953048408 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0039,  0.8752],
         [-0.0016,  0.4648],
         [-0.0030,  0.3136],
         [-0.0022,  0.2319]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4929947694614616
Current reward: 0.26448583841204937
Current mitigation activation: 0
#############################
Total reward: 37.67383159248181
15.93636953085661 seconds in game passed.
Action: tensor([[[ 0.0039,  0.8752],
         [-0.0016,  0.4648],
         [-0.0030,  0.3136],
         [-0.0022,  0.2319]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.67383159248181
15.961369531229138 seconds in game passed.
Action: tensor([[[ 0.0039,  0.8752],
         [-0.0016,  0.4648],
         [-0.0030,  0.3136],
         [-0.0022,  0.2319]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.67383159248181
15.986369531601667 seconds in game passed.
Action: tensor([[[ 0.0039,  0.8752],
         [-0.0016,  0.4648],
         [-0.0030,  0.3136],
         [-0.0022,  0.2319]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.67383159248181
+++++++++++++: 2.371798917519025
16.011369531974196 seconds in game passed.
At 16.011369531974196 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.8943],
         [-0.0012,  0.4676],
         [-0.0033,  0.3110],
         [-0.0035,  0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001622, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.371798917519025
Current reward: 0.2731807538011024
Current mitigation activation: 0
#############################
Total reward: 37.94701234628291
16.036369532346725 seconds in game passed.
Action: tensor([[[ 0.0021,  0.8943],
         [-0.0012,  0.4676],
         [-0.0033,  0.3110],
         [-0.0035,  0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.94701234628291
16.061369532719254 seconds in game passed.
Action: tensor([[[ 0.0021,  0.8943],
         [-0.0012,  0.4676],
         [-0.0033,  0.3110],
         [-0.0035,  0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.94701234628291
16.086369533091784 seconds in game passed.
Action: tensor([[[ 0.0021,  0.8943],
         [-0.0012,  0.4676],
         [-0.0033,  0.3110],
         [-0.0035,  0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.94701234628291
+++++++++++++: 2.203578395467606
16.111369533464313 seconds in game passed.
At 16.111369533464313 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0040,  0.8769],
         [-0.0022,  0.4530],
         [-0.0039,  0.3021],
         [-0.0036,  0.2227]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.203578395467606
Current reward: 0.2851209235283249
Current mitigation activation: 0
#############################
Total reward: 38.232133269811236
16.13636953383684 seconds in game passed.
Action: tensor([[[-0.0040,  0.8769],
         [-0.0022,  0.4530],
         [-0.0039,  0.3021],
         [-0.0036,  0.2227]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001107, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.232133269811236
16.16136953420937 seconds in game passed.
Action: tensor([[[-0.0040,  0.8769],
         [-0.0022,  0.4530],
         [-0.0039,  0.3021],
         [-0.0036,  0.2227]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.232133269811236
16.1863695345819 seconds in game passed.
Action: tensor([[[-0.0040,  0.8769],
         [-0.0022,  0.4530],
         [-0.0039,  0.3021],
         [-0.0036,  0.2227]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.232133269811236
+++++++++++++: 2.0616461096111003
16.21136953495443 seconds in game passed.
At 16.21136953495443 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0026,  0.8736],
         [-0.0031,  0.4532],
         [-0.0046,  0.3053],
         [-0.0038,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0616461096111003
Current reward: 0.29586610864223944
Current mitigation activation: 0
#############################
Total reward: 38.52799937845347
16.236369535326958 seconds in game passed.
Action: tensor([[[ 0.0026,  0.8736],
         [-0.0031,  0.4532],
         [-0.0046,  0.3053],
         [-0.0038,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.52799937845347
16.261369535699487 seconds in game passed.
Action: tensor([[[ 0.0026,  0.8736],
         [-0.0031,  0.4532],
         [-0.0046,  0.3053],
         [-0.0038,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.52799937845347
16.286369536072016 seconds in game passed.
Action: tensor([[[ 0.0026,  0.8736],
         [-0.0031,  0.4532],
         [-0.0046,  0.3053],
         [-0.0038,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.52799937845347
+++++++++++++: 1.9353579109538803
16.311369536444545 seconds in game passed.
At 16.311369536444545 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0020,  0.8850],
         [-0.0024,  0.4598],
         [-0.0044,  0.3068],
         [-0.0042,  0.2266]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000424, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9353579109538803
Current reward: 0.30582696061496806
Current mitigation activation: 0
#############################
Total reward: 38.83382633906844
16.336369536817074 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8850],
         [-0.0024,  0.4598],
         [-0.0044,  0.3068],
         [-0.0042,  0.2266]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.83382633906844
16.361369537189603 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8850],
         [-0.0024,  0.4598],
         [-0.0044,  0.3068],
         [-0.0042,  0.2266]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.83382633906844
16.386369537562132 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8850],
         [-0.0024,  0.4598],
         [-0.0044,  0.3068],
         [-0.0042,  0.2266]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.83382633906844
+++++++++++++: 1.8196931022288751
16.41136953793466 seconds in game passed.
At 16.41136953793466 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.4389e-04,  8.8557e-01],
         [-1.6059e-03,  4.6025e-01],
         [-3.7271e-03,  3.0943e-01],
         [-3.7836e-03,  2.3018e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8196931022288751
Current reward: 0.31519514854410047
Current mitigation activation: 0
#############################
Total reward: 39.149021487612536
16.43636953830719 seconds in game passed.
Action: tensor([[[-8.4389e-04,  8.8557e-01],
         [-1.6059e-03,  4.6025e-01],
         [-3.7271e-03,  3.0943e-01],
         [-3.7836e-03,  2.3018e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.149021487612536
16.46136953867972 seconds in game passed.
Action: tensor([[[-8.4389e-04,  8.8557e-01],
         [-1.6059e-03,  4.6025e-01],
         [-3.7271e-03,  3.0943e-01],
         [-3.7836e-03,  2.3018e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.149021487612536
16.486369539052248 seconds in game passed.
Action: tensor([[[-8.4389e-04,  8.8557e-01],
         [-1.6059e-03,  4.6025e-01],
         [-3.7271e-03,  3.0943e-01],
         [-3.7836e-03,  2.3018e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.149021487612536
+++++++++++++: 1.7120904133349624
16.511369539424777 seconds in game passed.
At 16.511369539424777 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.9545e-04,  9.1081e-01],
         [ 9.6659e-04,  4.7335e-01],
         [-1.6019e-03,  3.1404e-01],
         [-2.1849e-03,  2.3141e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7120904133349624
Current reward: 0.32406438321964876
Current mitigation activation: 0
#############################
Total reward: 39.473085870832186
16.536369539797306 seconds in game passed.
Action: tensor([[[-2.9545e-04,  9.1081e-01],
         [ 9.6659e-04,  4.7335e-01],
         [-1.6019e-03,  3.1404e-01],
         [-2.1849e-03,  2.3141e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.473085870832186
16.561369540169835 seconds in game passed.
Action: tensor([[[-2.9545e-04,  9.1081e-01],
         [ 9.6659e-04,  4.7335e-01],
         [-1.6019e-03,  3.1404e-01],
         [-2.1849e-03,  2.3141e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000714, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.473085870832186
16.586369540542364 seconds in game passed.
Action: tensor([[[-2.9545e-04,  9.1081e-01],
         [ 9.6659e-04,  4.7335e-01],
         [-1.6019e-03,  3.1404e-01],
         [-2.1849e-03,  2.3141e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.473085870832186
+++++++++++++: 1.6122159024820826
16.611369540914893 seconds in game passed.
At 16.611369540914893 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0096,  0.9032],
         [ 0.0020,  0.4930],
         [-0.0029,  0.3380],
         [-0.0047,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.585201, steer=0.005417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6122159024820826
Current reward: 0.33253788930224015
Current mitigation activation: 0
#############################
Total reward: 39.805623760134424
16.636369541287422 seconds in game passed.
Action: tensor([[[ 0.0096,  0.9032],
         [ 0.0020,  0.4930],
         [-0.0029,  0.3380],
         [-0.0047,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.571828, steer=0.004597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.805623760134424
16.66136954165995 seconds in game passed.
Action: tensor([[[ 0.0096,  0.9032],
         [ 0.0020,  0.4930],
         [-0.0029,  0.3380],
         [-0.0047,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.520852, steer=0.004579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.805623760134424
16.68636954203248 seconds in game passed.
Action: tensor([[[ 0.0096,  0.9032],
         [ 0.0020,  0.4930],
         [-0.0029,  0.3380],
         [-0.0047,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.507822, steer=0.004561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.805623760134424
+++++++++++++: 1.5212500399560893
16.71136954240501 seconds in game passed.
At 16.71136954240501 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.3380e-03, 9.2319e-01],
         [5.0073e-03, 5.1666e-01],
         [1.1483e-03, 3.5034e-01],
         [1.0443e-04, 2.6121e-01]]])
agent 0 action: VehicleControl(throttle=0.489299, steer=0.004763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5212500399560893
Current reward: 0.3405554431689293
Current mitigation activation: 0
#############################
Total reward: 40.146179203303355
16.73636954277754 seconds in game passed.
Action: tensor([[[4.3380e-03, 9.2319e-01],
         [5.0073e-03, 5.1666e-01],
         [1.1483e-03, 3.5034e-01],
         [1.0443e-04, 2.6121e-01]]])
agent 0 action: VehicleControl(throttle=0.470768, steer=0.004765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.146179203303355
16.761369543150067 seconds in game passed.
Action: tensor([[[4.3380e-03, 9.2319e-01],
         [5.0073e-03, 5.1666e-01],
         [1.1483e-03, 3.5034e-01],
         [1.0443e-04, 2.6121e-01]]])
agent 0 action: VehicleControl(throttle=0.452227, steer=0.004795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.146179203303355
16.786369543522596 seconds in game passed.
Action: tensor([[[4.3380e-03, 9.2319e-01],
         [5.0073e-03, 5.1666e-01],
         [1.1483e-03, 3.5034e-01],
         [1.0443e-04, 2.6121e-01]]])
agent 0 action: VehicleControl(throttle=0.433678, steer=0.004825, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.146179203303355
+++++++++++++: 1.4512587876223613
16.811369543895125 seconds in game passed.
At 16.811369543895125 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.9361],
         [0.0065, 0.5388],
         [0.0027, 0.3659],
         [0.0015, 0.2720]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005226, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4512587876223613
Current reward: 0.3463295908528147
Current mitigation activation: 0
#############################
Total reward: 40.49250879415617
16.836369544267654 seconds in game passed.
Action: tensor([[[0.0024, 0.9361],
         [0.0065, 0.5388],
         [0.0027, 0.3659],
         [0.0015, 0.2720]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005245, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49250879415617
16.861369544640183 seconds in game passed.
Action: tensor([[[0.0024, 0.9361],
         [0.0065, 0.5388],
         [0.0027, 0.3659],
         [0.0015, 0.2720]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005318, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49250879415617
16.886369545012712 seconds in game passed.
Action: tensor([[[0.0024, 0.9361],
         [0.0065, 0.5388],
         [0.0027, 0.3659],
         [0.0015, 0.2720]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005392, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49250879415617
+++++++++++++: 1.409622674801749
16.91136954538524 seconds in game passed.
At 16.91136954538524 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0191, 0.9317],
         [0.0085, 0.5276],
         [0.0045, 0.3552],
         [0.0036, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.014159, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.409622674801749
Current reward: 0.34844219969195445
Current mitigation activation: 0
#############################
Total reward: 40.840950993848125
16.93636954575777 seconds in game passed.
Action: tensor([[[0.0191, 0.9317],
         [0.0085, 0.5276],
         [0.0045, 0.3552],
         [0.0036, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012870, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.840950993848125
16.9613695461303 seconds in game passed.
Action: tensor([[[0.0191, 0.9317],
         [0.0085, 0.5276],
         [0.0045, 0.3552],
         [0.0036, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.013017, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.840950993848125
16.98636954650283 seconds in game passed.
Action: tensor([[[0.0191, 0.9317],
         [0.0085, 0.5276],
         [0.0045, 0.3552],
         [0.0036, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.285943, steer=0.013165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.840950993848125
+++++++++++++: 1.4384732039797916
17.011369546875358 seconds in game passed.
At 17.011369546875358 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0263, 0.9303],
         [0.0060, 0.5325],
         [0.0010, 0.3575],
         [0.0011, 0.2619]]])
agent 0 action: VehicleControl(throttle=0.269464, steer=0.014568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4384732039797916
Current reward: 0.3407087897354031
Current mitigation activation: 0
#############################
Total reward: 41.18165978358353
17.036369547247887 seconds in game passed.
Action: tensor([[[0.0263, 0.9303],
         [0.0060, 0.5325],
         [0.0010, 0.3575],
         [0.0011, 0.2619]]])
agent 0 action: VehicleControl(throttle=0.253509, steer=0.014527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.18165978358353
17.061369547620416 seconds in game passed.
Action: tensor([[[0.0263, 0.9303],
         [0.0060, 0.5325],
         [0.0010, 0.3575],
         [0.0011, 0.2619]]])
agent 0 action: VehicleControl(throttle=0.238068, steer=0.014693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.18165978358353
17.086369547992945 seconds in game passed.
Action: tensor([[[0.0263, 0.9303],
         [0.0060, 0.5325],
         [0.0010, 0.3575],
         [0.0011, 0.2619]]])
agent 0 action: VehicleControl(throttle=0.223131, steer=0.014858, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.18165978358353
+++++++++++++: 1.5384950986047574
17.111369548365474 seconds in game passed.
At 17.111369548365474 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0157,  0.9360],
         [-0.0012,  0.5530],
         [-0.0065,  0.3733],
         [-0.0063,  0.2753]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005121, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5384950986047574
Current reward: 0.3253919590199682
Current mitigation activation: 0
#############################
Total reward: 41.507051742603494
17.136369548738003 seconds in game passed.
Action: tensor([[[ 0.0157,  0.9360],
         [-0.0012,  0.5530],
         [-0.0065,  0.3733],
         [-0.0063,  0.2753]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006857, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.507051742603494
17.161369549110532 seconds in game passed.
Action: tensor([[[ 0.0157,  0.9360],
         [-0.0012,  0.5530],
         [-0.0065,  0.3733],
         [-0.0063,  0.2753]]])
agent 0 action: VehicleControl(throttle=0.175230, steer=0.006953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.507051742603494
17.18636954948306 seconds in game passed.
Action: tensor([[[ 0.0157,  0.9360],
         [-0.0012,  0.5530],
         [-0.0065,  0.3733],
         [-0.0063,  0.2753]]])
agent 0 action: VehicleControl(throttle=0.160230, steer=0.007049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.507051742603494
+++++++++++++: 1.607823110437918
17.21136954985559 seconds in game passed.
At 17.21136954985559 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.7624e-02,  9.3722e-01],
         [ 7.0698e-04,  5.3861e-01],
         [-5.0963e-03,  3.5422e-01],
         [-5.8243e-03,  2.5882e-01]]])
agent 0 action: VehicleControl(throttle=0.145938, steer=0.009318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.607823110437918
Current reward: 0.31717573824461825
Current mitigation activation: 0
#############################
Total reward: 41.824227480848116
17.23636955022812 seconds in game passed.
Action: tensor([[[ 1.7624e-02,  9.3722e-01],
         [ 7.0698e-04,  5.3861e-01],
         [-5.0963e-03,  3.5422e-01],
         [-5.8243e-03,  2.5882e-01]]])
agent 0 action: VehicleControl(throttle=0.132119, steer=0.009055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.824227480848116
17.261369550600648 seconds in game passed.
Action: tensor([[[ 1.7624e-02,  9.3722e-01],
         [ 7.0698e-04,  5.3861e-01],
         [-5.0963e-03,  3.5422e-01],
         [-5.8243e-03,  2.5882e-01]]])
agent 0 action: VehicleControl(throttle=0.118769, steer=0.009154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.824227480848116
17.286369550973177 seconds in game passed.
Action: tensor([[[ 1.7624e-02,  9.3722e-01],
         [ 7.0698e-04,  5.3861e-01],
         [-5.0963e-03,  3.5422e-01],
         [-5.8243e-03,  2.5882e-01]]])
agent 0 action: VehicleControl(throttle=0.105887, steer=0.009253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.824227480848116
+++++++++++++: 1.674936726531416
17.311369551345706 seconds in game passed.
At 17.311369551345706 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1357e-02,  9.3184e-01],
         [-8.2928e-04,  5.2560e-01],
         [-5.6014e-03,  3.5126e-01],
         [-6.2561e-03,  2.6005e-01]]])
agent 0 action: VehicleControl(throttle=0.190424, steer=0.005380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.674936726531416
Current reward: 0.31123154496233807
Current mitigation activation: 0
#############################
Total reward: 42.135459025810455
17.336369551718235 seconds in game passed.
Action: tensor([[[ 1.1357e-02,  9.3184e-01],
         [-8.2928e-04,  5.2560e-01],
         [-5.6014e-03,  3.5126e-01],
         [-6.2561e-03,  2.6005e-01]]])
agent 0 action: VehicleControl(throttle=0.190722, steer=0.006089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.135459025810455
17.361369552090764 seconds in game passed.
Action: tensor([[[ 1.1357e-02,  9.3184e-01],
         [-8.2928e-04,  5.2560e-01],
         [-5.6014e-03,  3.5126e-01],
         [-6.2561e-03,  2.6005e-01]]])
agent 0 action: VehicleControl(throttle=0.199081, steer=0.006144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.135459025810455
17.386369552463293 seconds in game passed.
Action: tensor([[[ 1.1357e-02,  9.3184e-01],
         [-8.2928e-04,  5.2560e-01],
         [-5.6014e-03,  3.5126e-01],
         [-6.2561e-03,  2.6005e-01]]])
agent 0 action: VehicleControl(throttle=0.207029, steer=0.006198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.135459025810455
+++++++++++++: 1.7373214962929593
17.411369552835822 seconds in game passed.
At 17.411369552835822 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0023,  0.9223],
         [-0.0075,  0.5160],
         [-0.0122,  0.3440],
         [-0.0125,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.310739, steer=-0.002712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7373214962929593
Current reward: 0.30743590704191376
Current mitigation activation: 0
#############################
Total reward: 42.44289493285237
17.43636955320835 seconds in game passed.
Action: tensor([[[ 0.0023,  0.9223],
         [-0.0075,  0.5160],
         [-0.0122,  0.3440],
         [-0.0125,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.294783, steer=-0.001265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.44289493285237
17.46136955358088 seconds in game passed.
Action: tensor([[[ 0.0023,  0.9223],
         [-0.0075,  0.5160],
         [-0.0122,  0.3440],
         [-0.0125,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.291016, steer=-0.001297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.44289493285237
17.48636955395341 seconds in game passed.
Action: tensor([[[ 0.0023,  0.9223],
         [-0.0075,  0.5160],
         [-0.0122,  0.3440],
         [-0.0125,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.287564, steer=-0.001330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.44289493285237
+++++++++++++: 1.777391322629728
17.51136955432594 seconds in game passed.
At 17.51136955432594 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.9319],
         [-0.0064,  0.5091],
         [-0.0112,  0.3348],
         [-0.0124,  0.2466]]])
agent 0 action: VehicleControl(throttle=0.432516, steer=-0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.777391322629728
Current reward: 0.30708742503375086
Current mitigation activation: 0
#############################
Total reward: 42.74998235788612
17.536369554698467 seconds in game passed.
Action: tensor([[[-0.0018,  0.9319],
         [-0.0064,  0.5091],
         [-0.0112,  0.3348],
         [-0.0124,  0.2466]]])
agent 0 action: VehicleControl(throttle=0.416813, steer=-0.002250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.74998235788612
17.561369555070996 seconds in game passed.
Action: tensor([[[-0.0018,  0.9319],
         [-0.0064,  0.5091],
         [-0.0112,  0.3348],
         [-0.0124,  0.2466]]])
agent 0 action: VehicleControl(throttle=0.416970, steer=-0.002315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.74998235788612
17.586369555443525 seconds in game passed.
Action: tensor([[[-0.0018,  0.9319],
         [-0.0064,  0.5091],
         [-0.0112,  0.3348],
         [-0.0124,  0.2466]]])
agent 0 action: VehicleControl(throttle=0.417476, steer=-0.002380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.74998235788612
+++++++++++++: 1.8064493308238718
17.611369555816054 seconds in game passed.
At 17.611369555816054 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.9168],
         [-0.0105,  0.4823],
         [-0.0153,  0.3248],
         [-0.0164,  0.2459]]])
agent 0 action: VehicleControl(throttle=0.780966, steer=-0.006329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8064493308238718
Current reward: 0.3085792914165525
Current mitigation activation: 0
#############################
Total reward: 43.05856164930267
17.636369556188583 seconds in game passed.
Action: tensor([[[-0.0035,  0.9168],
         [-0.0105,  0.4823],
         [-0.0153,  0.3248],
         [-0.0164,  0.2459]]])
agent 0 action: VehicleControl(throttle=0.752307, steer=-0.005851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.05856164930267
17.661369556561112 seconds in game passed.
Action: tensor([[[-0.0035,  0.9168],
         [-0.0105,  0.4823],
         [-0.0153,  0.3248],
         [-0.0164,  0.2459]]])
agent 0 action: VehicleControl(throttle=0.762071, steer=-0.006006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.05856164930267
17.68636955693364 seconds in game passed.
Action: tensor([[[-0.0035,  0.9168],
         [-0.0105,  0.4823],
         [-0.0153,  0.3248],
         [-0.0164,  0.2459]]])
agent 0 action: VehicleControl(throttle=0.771836, steer=-0.006160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.05856164930267
+++++++++++++: 1.83919603350599
17.71136955730617 seconds in game passed.
At 17.71136955730617 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0063,  0.8598],
         [-0.0129,  0.4571],
         [-0.0178,  0.3147],
         [-0.0194,  0.2412]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.83919603350599
Current reward: 0.31031680812865525
Current mitigation activation: 0
#############################
Total reward: 43.36887845743132
17.7363695576787 seconds in game passed.
Action: tensor([[[-0.0063,  0.8598],
         [-0.0129,  0.4571],
         [-0.0178,  0.3147],
         [-0.0194,  0.2412]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.36887845743132
17.76136955805123 seconds in game passed.
Action: tensor([[[-0.0063,  0.8598],
         [-0.0129,  0.4571],
         [-0.0178,  0.3147],
         [-0.0194,  0.2412]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.36887845743132
17.786369558423758 seconds in game passed.
Action: tensor([[[-0.0063,  0.8598],
         [-0.0129,  0.4571],
         [-0.0178,  0.3147],
         [-0.0194,  0.2412]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.36887845743132
+++++++++++++: 1.8755196403210517
17.811369558796287 seconds in game passed.
At 17.811369558796287 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0070,  0.8622],
         [-0.0144,  0.4560],
         [-0.0188,  0.3108],
         [-0.0202,  0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8755196403210517
Current reward: 0.3122932300565572
Current mitigation activation: 0
#############################
Total reward: 43.681171687487875
17.836369559168816 seconds in game passed.
Action: tensor([[[-0.0070,  0.8622],
         [-0.0144,  0.4560],
         [-0.0188,  0.3108],
         [-0.0202,  0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.681171687487875
17.861369559541345 seconds in game passed.
Action: tensor([[[-0.0070,  0.8622],
         [-0.0144,  0.4560],
         [-0.0188,  0.3108],
         [-0.0202,  0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.681171687487875
17.886369559913874 seconds in game passed.
Action: tensor([[[-0.0070,  0.8622],
         [-0.0144,  0.4560],
         [-0.0188,  0.3108],
         [-0.0202,  0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.681171687487875
+++++++++++++: 1.9153744289727275
17.911369560286403 seconds in game passed.
At 17.911369560286403 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.8426],
         [-0.0096,  0.4494],
         [-0.0128,  0.3099],
         [-0.0137,  0.2356]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005888, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9153744289727275
Current reward: 0.3145047459164457
Current mitigation activation: 0
#############################
Total reward: 43.99567643340432
17.93636956065893 seconds in game passed.
Action: tensor([[[-0.0019,  0.8426],
         [-0.0096,  0.4494],
         [-0.0128,  0.3099],
         [-0.0137,  0.2356]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.99567643340432
17.96136956103146 seconds in game passed.
Action: tensor([[[-0.0019,  0.8426],
         [-0.0096,  0.4494],
         [-0.0128,  0.3099],
         [-0.0137,  0.2356]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.99567643340432
17.98636956140399 seconds in game passed.
Action: tensor([[[-0.0019,  0.8426],
         [-0.0096,  0.4494],
         [-0.0128,  0.3099],
         [-0.0137,  0.2356]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.99567643340432
+++++++++++++: 2.041667811356042
18.01136956177652 seconds in game passed.
At 18.01136956177652 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.0067e-04,  8.5078e-01],
         [-1.1513e-02,  4.4590e-01],
         [-1.6437e-02,  3.0166e-01],
         [-1.8990e-02,  2.2644e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.041667811356042
Current reward: 0.3100144038163405
Current mitigation activation: 0
#############################
Total reward: 44.30569083722066
18.036369562149048 seconds in game passed.
Action: tensor([[[ 8.0067e-04,  8.5078e-01],
         [-1.1513e-02,  4.4590e-01],
         [-1.6437e-02,  3.0166e-01],
         [-1.8990e-02,  2.2644e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.30569083722066
18.061369562521577 seconds in game passed.
Action: tensor([[[ 8.0067e-04,  8.5078e-01],
         [-1.1513e-02,  4.4590e-01],
         [-1.6437e-02,  3.0166e-01],
         [-1.8990e-02,  2.2644e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.30569083722066
18.086369562894106 seconds in game passed.
Action: tensor([[[ 8.0067e-04,  8.5078e-01],
         [-1.1513e-02,  4.4590e-01],
         [-1.6437e-02,  3.0166e-01],
         [-1.8990e-02,  2.2644e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.30569083722066
+++++++++++++: 2.2163929524122614
18.111369563266635 seconds in game passed.
At 18.111369563266635 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.8491],
         [-0.0111,  0.4363],
         [-0.0150,  0.2883],
         [-0.0164,  0.2135]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2163929524122614
Current reward: 0.3038965816744284
Current mitigation activation: 0
#############################
Total reward: 44.60958741889509
18.136369563639164 seconds in game passed.
Action: tensor([[[ 0.0013,  0.8491],
         [-0.0111,  0.4363],
         [-0.0150,  0.2883],
         [-0.0164,  0.2135]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.60958741889509
18.161369564011693 seconds in game passed.
Action: tensor([[[ 0.0013,  0.8491],
         [-0.0111,  0.4363],
         [-0.0150,  0.2883],
         [-0.0164,  0.2135]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.60958741889509
18.186369564384222 seconds in game passed.
Action: tensor([[[ 0.0013,  0.8491],
         [-0.0111,  0.4363],
         [-0.0150,  0.2883],
         [-0.0164,  0.2135]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.60958741889509
+++++++++++++: 2.286304669333273
18.21136956475675 seconds in game passed.
At 18.21136956475675 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.7949],
         [-0.0075,  0.4173],
         [-0.0102,  0.2785],
         [-0.0114,  0.2076]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.286304669333273
Current reward: 0.30706633342282785
Current mitigation activation: 0
#############################
Total reward: 44.91665375231791
18.23636956512928 seconds in game passed.
Action: tensor([[[-0.0016,  0.7949],
         [-0.0075,  0.4173],
         [-0.0102,  0.2785],
         [-0.0114,  0.2076]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.91665375231791
18.26136956550181 seconds in game passed.
Action: tensor([[[-0.0016,  0.7949],
         [-0.0075,  0.4173],
         [-0.0102,  0.2785],
         [-0.0114,  0.2076]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.91665375231791
18.286369565874338 seconds in game passed.
Action: tensor([[[-0.0016,  0.7949],
         [-0.0075,  0.4173],
         [-0.0102,  0.2785],
         [-0.0114,  0.2076]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008270, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.91665375231791
+++++++++++++: 2.2879888015860863
18.311369566246867 seconds in game passed.
At 18.311369566246867 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.7643],
         [-0.0064,  0.4049],
         [-0.0090,  0.2751],
         [-0.0103,  0.2080]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2879888015860863
Current reward: 0.31537028974407116
Current mitigation activation: 0
#############################
Total reward: 45.23202404206199
18.336369566619396 seconds in game passed.
Action: tensor([[[-0.0014,  0.7643],
         [-0.0064,  0.4049],
         [-0.0090,  0.2751],
         [-0.0103,  0.2080]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007711, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.23202404206199
18.361369566991925 seconds in game passed.
Action: tensor([[[-0.0014,  0.7643],
         [-0.0064,  0.4049],
         [-0.0090,  0.2751],
         [-0.0103,  0.2080]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.23202404206199
18.386369567364454 seconds in game passed.
Action: tensor([[[-0.0014,  0.7643],
         [-0.0064,  0.4049],
         [-0.0090,  0.2751],
         [-0.0103,  0.2080]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.23202404206199
+++++++++++++: 2.2570171536119785
18.411369567736983 seconds in game passed.
At 18.411369567736983 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.7241],
         [-0.0059,  0.3886],
         [-0.0076,  0.2657],
         [-0.0084,  0.2018]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007708, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2570171536119785
Current reward: 0.3261168960431906
Current mitigation activation: 0
#############################
Total reward: 45.558140938105176
18.436369568109512 seconds in game passed.
Action: tensor([[[-0.0019,  0.7241],
         [-0.0059,  0.3886],
         [-0.0076,  0.2657],
         [-0.0084,  0.2018]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.558140938105176
18.46136956848204 seconds in game passed.
Action: tensor([[[-0.0019,  0.7241],
         [-0.0059,  0.3886],
         [-0.0076,  0.2657],
         [-0.0084,  0.2018]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.558140938105176
18.48636956885457 seconds in game passed.
Action: tensor([[[-0.0019,  0.7241],
         [-0.0059,  0.3886],
         [-0.0076,  0.2657],
         [-0.0084,  0.2018]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.558140938105176
+++++++++++++: 2.2113014530213664
18.5113695692271 seconds in game passed.
At 18.5113695692271 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3523e-04,  6.8444e-01],
         [-4.2711e-03,  3.7947e-01],
         [-5.8348e-03,  2.6311e-01],
         [-6.7381e-03,  2.0178e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2113014530213664
Current reward: 0.33806776304303743
Current mitigation activation: 0
#############################
Total reward: 45.89620870114821
18.53636956959963 seconds in game passed.
Action: tensor([[[ 1.3523e-04,  6.8444e-01],
         [-4.2711e-03,  3.7947e-01],
         [-5.8348e-03,  2.6311e-01],
         [-6.7381e-03,  2.0178e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.89620870114821
18.561369569972157 seconds in game passed.
Action: tensor([[[ 1.3523e-04,  6.8444e-01],
         [-4.2711e-03,  3.7947e-01],
         [-5.8348e-03,  2.6311e-01],
         [-6.7381e-03,  2.0178e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.89620870114821
18.586369570344687 seconds in game passed.
Action: tensor([[[ 1.3523e-04,  6.8444e-01],
         [-4.2711e-03,  3.7947e-01],
         [-5.8348e-03,  2.6311e-01],
         [-6.7381e-03,  2.0178e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.89620870114821
+++++++++++++: 2.160117172957356
18.611369570717216 seconds in game passed.
At 18.611369570717216 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0023,  0.6914],
         [-0.0021,  0.3793],
         [-0.0033,  0.2623],
         [-0.0041,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.160117172957356
Current reward: 0.3505629091787024
Current mitigation activation: 0
#############################
Total reward: 46.24677161032692
18.636369571089745 seconds in game passed.
Action: tensor([[[ 0.0023,  0.6914],
         [-0.0021,  0.3793],
         [-0.0033,  0.2623],
         [-0.0041,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003665, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.24677161032692
18.661369571462274 seconds in game passed.
Action: tensor([[[ 0.0023,  0.6914],
         [-0.0021,  0.3793],
         [-0.0033,  0.2623],
         [-0.0041,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.24677161032692
18.686369571834803 seconds in game passed.
Action: tensor([[[ 0.0023,  0.6914],
         [-0.0021,  0.3793],
         [-0.0033,  0.2623],
         [-0.0041,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.24677161032692
+++++++++++++: 2.108015356817216
18.71136957220733 seconds in game passed.
At 18.71136957220733 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.9204e-03,  6.7700e-01],
         [ 2.7938e-04,  3.7209e-01],
         [-2.8822e-04,  2.5548e-01],
         [-1.0909e-03,  1.9516e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.108015356817216
Current reward: 0.36323921204914156
Current mitigation activation: 0
#############################
Total reward: 46.61001082237606
18.73636957257986 seconds in game passed.
Action: tensor([[[ 4.9204e-03,  6.7700e-01],
         [ 2.7938e-04,  3.7209e-01],
         [-2.8822e-04,  2.5548e-01],
         [-1.0909e-03,  1.9516e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.61001082237606
18.76136957295239 seconds in game passed.
Action: tensor([[[ 4.9204e-03,  6.7700e-01],
         [ 2.7938e-04,  3.7209e-01],
         [-2.8822e-04,  2.5548e-01],
         [-1.0909e-03,  1.9516e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.61001082237606
18.78636957332492 seconds in game passed.
Action: tensor([[[ 4.9204e-03,  6.7700e-01],
         [ 2.7938e-04,  3.7209e-01],
         [-2.8822e-04,  2.5548e-01],
         [-1.0909e-03,  1.9516e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.61001082237606
+++++++++++++: 2.0571646402051402
18.811369573697448 seconds in game passed.
At 18.811369573697448 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6525],
         [0.0023, 0.3513],
         [0.0022, 0.2403],
         [0.0015, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0571646402051402
Current reward: 0.3758851042738134
Current mitigation activation: 0
#############################
Total reward: 46.985895926649874
18.836369574069977 seconds in game passed.
Action: tensor([[[0.0039, 0.6525],
         [0.0023, 0.3513],
         [0.0022, 0.2403],
         [0.0015, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.985895926649874
18.861369574442506 seconds in game passed.
Action: tensor([[[0.0039, 0.6525],
         [0.0023, 0.3513],
         [0.0022, 0.2403],
         [0.0015, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000853, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.985895926649874
18.886369574815035 seconds in game passed.
Action: tensor([[[0.0039, 0.6525],
         [0.0023, 0.3513],
         [0.0022, 0.2403],
         [0.0015, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.985895926649874
+++++++++++++: 2.0084563435591787
18.911369575187564 seconds in game passed.
At 18.911369575187564 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0053, 0.6414],
         [0.0043, 0.3438],
         [0.0040, 0.2358],
         [0.0031, 0.1803]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0084563435591787
Current reward: 0.38838030286560754
Current mitigation activation: 0
#############################
Total reward: 47.37427622951548
18.936369575560093 seconds in game passed.
Action: tensor([[[0.0053, 0.6414],
         [0.0043, 0.3438],
         [0.0040, 0.2358],
         [0.0031, 0.1803]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.37427622951548
18.961369575932622 seconds in game passed.
Action: tensor([[[0.0053, 0.6414],
         [0.0043, 0.3438],
         [0.0040, 0.2358],
         [0.0031, 0.1803]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.37427622951548
18.98636957630515 seconds in game passed.
Action: tensor([[[0.0053, 0.6414],
         [0.0043, 0.3438],
         [0.0040, 0.2358],
         [0.0031, 0.1803]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003269, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.37427622951548
+++++++++++++: 1.9622351408417869
19.01136957667768 seconds in game passed.
At 19.01136957667768 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6307],
         [0.0020, 0.3403],
         [0.0023, 0.2340],
         [0.0020, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9622351408417869
Current reward: 0.400649737659878
Current mitigation activation: 0
#############################
Total reward: 47.774925967175356
19.03636957705021 seconds in game passed.
Action: tensor([[[0.0022, 0.6307],
         [0.0020, 0.3403],
         [0.0023, 0.2340],
         [0.0020, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.774925967175356
19.061369577422738 seconds in game passed.
Action: tensor([[[0.0022, 0.6307],
         [0.0020, 0.3403],
         [0.0023, 0.2340],
         [0.0020, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.774925967175356
19.086369577795267 seconds in game passed.
Action: tensor([[[0.0022, 0.6307],
         [0.0020, 0.3403],
         [0.0023, 0.2340],
         [0.0020, 0.1793]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.774925967175356
+++++++++++++: 1.9184907749876887
19.111369578167796 seconds in game passed.
At 19.111369578167796 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.6598],
         [0.0016, 0.3506],
         [0.0014, 0.2401],
         [0.0008, 0.1839]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9184907749876887
Current reward: 0.41264853048610617
Current mitigation activation: 0
#############################
Total reward: 48.187574497661466
19.136369578540325 seconds in game passed.
Action: tensor([[[0.0024, 0.6598],
         [0.0016, 0.3506],
         [0.0014, 0.2401],
         [0.0008, 0.1839]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.187574497661466
19.161369578912854 seconds in game passed.
Action: tensor([[[0.0024, 0.6598],
         [0.0016, 0.3506],
         [0.0014, 0.2401],
         [0.0008, 0.1839]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.187574497661466
19.186369579285383 seconds in game passed.
Action: tensor([[[0.0024, 0.6598],
         [0.0016, 0.3506],
         [0.0014, 0.2401],
         [0.0008, 0.1839]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.187574497661466
+++++++++++++: 1.8771133808332061
19.211369579657912 seconds in game passed.
At 19.211369579657912 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7867e-03,  6.6042e-01],
         [ 1.3102e-03,  3.5123e-01],
         [ 3.7582e-04,  2.4015e-01],
         [-5.5987e-04,  1.8353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8771133808332061
Current reward: 0.42435019489590603
Current mitigation activation: 0
#############################
Total reward: 48.61192469255737
19.23636958003044 seconds in game passed.
Action: tensor([[[ 2.7867e-03,  6.6042e-01],
         [ 1.3102e-03,  3.5123e-01],
         [ 3.7582e-04,  2.4015e-01],
         [-5.5987e-04,  1.8353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001666, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.61192469255737
19.26136958040297 seconds in game passed.
Action: tensor([[[ 2.7867e-03,  6.6042e-01],
         [ 1.3102e-03,  3.5123e-01],
         [ 3.7582e-04,  2.4015e-01],
         [-5.5987e-04,  1.8353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001753, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.61192469255737
19.2863695807755 seconds in game passed.
Action: tensor([[[ 2.7867e-03,  6.6042e-01],
         [ 1.3102e-03,  3.5123e-01],
         [ 3.7582e-04,  2.4015e-01],
         [-5.5987e-04,  1.8353e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.61192469255737
+++++++++++++: 1.8379118597018247
19.31136958114803 seconds in game passed.
At 19.31136958114803 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0018,  0.6739],
         [-0.0017,  0.3528],
         [-0.0030,  0.2401],
         [-0.0039,  0.1838]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000755, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8379118597018247
Current reward: 0.4357449366073567
Current mitigation activation: 0
#############################
Total reward: 49.04766962916473
19.336369581520557 seconds in game passed.
Action: tensor([[[ 0.0018,  0.6739],
         [-0.0017,  0.3528],
         [-0.0030,  0.2401],
         [-0.0039,  0.1838]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.04766962916473
19.361369581893086 seconds in game passed.
Action: tensor([[[ 0.0018,  0.6739],
         [-0.0017,  0.3528],
         [-0.0030,  0.2401],
         [-0.0039,  0.1838]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.04766962916473
19.386369582265615 seconds in game passed.
Action: tensor([[[ 0.0018,  0.6739],
         [-0.0017,  0.3528],
         [-0.0030,  0.2401],
         [-0.0039,  0.1838]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.04766962916473
+++++++++++++: 1.800705085024146
19.411369582638144 seconds in game passed.
At 19.411369582638144 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.6989e-04,  6.6802e-01],
         [-1.3006e-03,  3.4753e-01],
         [-2.0847e-03,  2.3619e-01],
         [-2.4874e-03,  1.8098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.800705085024146
Current reward: 0.44681859144514235
Current mitigation activation: 0
#############################
Total reward: 49.494488220609874
19.436369583010674 seconds in game passed.
Action: tensor([[[ 1.6989e-04,  6.6802e-01],
         [-1.3006e-03,  3.4753e-01],
         [-2.0847e-03,  2.3619e-01],
         [-2.4874e-03,  1.8098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.494488220609874
19.461369583383203 seconds in game passed.
Action: tensor([[[ 1.6989e-04,  6.6802e-01],
         [-1.3006e-03,  3.4753e-01],
         [-2.0847e-03,  2.3619e-01],
         [-2.4874e-03,  1.8098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.494488220609874
19.48636958375573 seconds in game passed.
Action: tensor([[[ 1.6989e-04,  6.6802e-01],
         [-1.3006e-03,  3.4753e-01],
         [-2.0847e-03,  2.3619e-01],
         [-2.4874e-03,  1.8098e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.494488220609874
+++++++++++++: 1.793639269800033
19.51136958412826 seconds in game passed.
At 19.51136958412826 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0007,  0.6649],
         [-0.0019,  0.3454],
         [-0.0023,  0.2343],
         [-0.0024,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001009, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.793639269800033
Current reward: 0.45353223649329394
Current mitigation activation: 0
#############################
Total reward: 49.94802045710317
19.53636958450079 seconds in game passed.
Action: tensor([[[-0.0007,  0.6649],
         [-0.0019,  0.3454],
         [-0.0023,  0.2343],
         [-0.0024,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.94802045710317
19.56136958487332 seconds in game passed.
Action: tensor([[[-0.0007,  0.6649],
         [-0.0019,  0.3454],
         [-0.0023,  0.2343],
         [-0.0024,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.94802045710317
19.586369585245848 seconds in game passed.
Action: tensor([[[-0.0007,  0.6649],
         [-0.0019,  0.3454],
         [-0.0023,  0.2343],
         [-0.0024,  0.1795]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.94802045710317
+++++++++++++: 1.820472644582896
19.611369585618377 seconds in game passed.
At 19.611369585618377 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.5725e-05,  6.4111e-01],
         [-1.2253e-04,  3.3825e-01],
         [-2.8968e-04,  2.3118e-01],
         [-2.6476e-04,  1.7728e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.820472644582896
Current reward: 0.455483494438248
Current mitigation activation: 0
#############################
Total reward: 50.40350395154142
19.636369585990906 seconds in game passed.
Action: tensor([[[-9.5725e-05,  6.4111e-01],
         [-1.2253e-04,  3.3825e-01],
         [-2.8968e-04,  2.3118e-01],
         [-2.6476e-04,  1.7728e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.40350395154142
19.661369586363435 seconds in game passed.
Action: tensor([[[-9.5725e-05,  6.4111e-01],
         [-1.2253e-04,  3.3825e-01],
         [-2.8968e-04,  2.3118e-01],
         [-2.6476e-04,  1.7728e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.40350395154142
19.686369586735964 seconds in game passed.
Action: tensor([[[-9.5725e-05,  6.4111e-01],
         [-1.2253e-04,  3.3825e-01],
         [-2.8968e-04,  2.3118e-01],
         [-2.6476e-04,  1.7728e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000473, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.40350395154142
+++++++++++++: 1.848695744554649
19.711369587108493 seconds in game passed.
At 19.711369587108493 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0029, 0.6202],
         [0.0021, 0.3370],
         [0.0020, 0.2321],
         [0.0018, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.848695744554649
Current reward: 0.457643445965425
Current mitigation activation: 0
#############################
Total reward: 50.86114739750684
19.736369587481022 seconds in game passed.
Action: tensor([[[0.0029, 0.6202],
         [0.0021, 0.3370],
         [0.0020, 0.2321],
         [0.0018, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.86114739750684
19.76136958785355 seconds in game passed.
Action: tensor([[[0.0029, 0.6202],
         [0.0021, 0.3370],
         [0.0020, 0.2321],
         [0.0018, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.86114739750684
19.78636958822608 seconds in game passed.
Action: tensor([[[0.0029, 0.6202],
         [0.0021, 0.3370],
         [0.0020, 0.2321],
         [0.0018, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002832, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.86114739750684
+++++++++++++: 1.8786348396940427
19.81136958859861 seconds in game passed.
At 19.81136958859861 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0041, 0.6300],
         [0.0021, 0.3395],
         [0.0021, 0.2347],
         [0.0019, 0.1806]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8786348396940427
Current reward: 0.4599585744651984
Current mitigation activation: 0
#############################
Total reward: 51.32110597197204
19.836369588971138 seconds in game passed.
Action: tensor([[[0.0041, 0.6300],
         [0.0021, 0.3395],
         [0.0021, 0.2347],
         [0.0019, 0.1806]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.32110597197204
19.861369589343667 seconds in game passed.
Action: tensor([[[0.0041, 0.6300],
         [0.0021, 0.3395],
         [0.0021, 0.2347],
         [0.0019, 0.1806]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.32110597197204
19.886369589716196 seconds in game passed.
Action: tensor([[[0.0041, 0.6300],
         [0.0021, 0.3395],
         [0.0021, 0.2347],
         [0.0019, 0.1806]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.32110597197204
+++++++++++++: 1.9102653548947577
19.911369590088725 seconds in game passed.
At 19.911369590088725 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.6299],
         [0.0014, 0.3341],
         [0.0016, 0.2292],
         [0.0016, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9102653548947577
Current reward: 0.4624233756155373
Current mitigation activation: 0
#############################
Total reward: 51.783529347587574
19.936369590461254 seconds in game passed.
Action: tensor([[[0.0024, 0.6299],
         [0.0014, 0.3341],
         [0.0016, 0.2292],
         [0.0016, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002194, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.783529347587574
19.961369590833783 seconds in game passed.
Action: tensor([[[0.0024, 0.6299],
         [0.0014, 0.3341],
         [0.0016, 0.2292],
         [0.0016, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.783529347587574
19.986369591206312 seconds in game passed.
Action: tensor([[[0.0024, 0.6299],
         [0.0014, 0.3341],
         [0.0016, 0.2292],
         [0.0016, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.783529347587574
+++++++++++++: 1.9061031657309004
20.01136959157884 seconds in game passed.
At 20.01136959157884 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4354e-03,  6.1885e-01],
         [-5.7423e-04,  3.3028e-01],
         [-4.9514e-04,  2.2708e-01],
         [-3.6345e-04,  1.7400e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9061031657309004
Current reward: 0.4699557586313362
Current mitigation activation: 0
#############################
Total reward: 52.25348510621891
20.03636959195137 seconds in game passed.
Action: tensor([[[ 2.4354e-03,  6.1885e-01],
         [-5.7423e-04,  3.3028e-01],
         [-4.9514e-04,  2.2708e-01],
         [-3.6345e-04,  1.7400e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.25348510621891
20.0613695923239 seconds in game passed.
Action: tensor([[[ 2.4354e-03,  6.1885e-01],
         [-5.7423e-04,  3.3028e-01],
         [-4.9514e-04,  2.2708e-01],
         [-3.6345e-04,  1.7400e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.25348510621891
20.08636959269643 seconds in game passed.
Action: tensor([[[ 2.4354e-03,  6.1885e-01],
         [-5.7423e-04,  3.3028e-01],
         [-4.9514e-04,  2.2708e-01],
         [-3.6345e-04,  1.7400e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000833, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.25348510621891
+++++++++++++: 1.8413596218165489
20.111369593068957 seconds in game passed.
At 20.111369593068957 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.0793e-04,  6.0864e-01],
         [-1.7265e-03,  3.2942e-01],
         [-1.9642e-03,  2.2700e-01],
         [-2.0816e-03,  1.7452e-01]]])
agent 0 action: VehicleControl(throttle=0.875869, steer=-0.000792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8413596218165489
Current reward: 0.48594495087801054
Current mitigation activation: 0
#############################
Total reward: 52.73943005709692
20.136369593441486 seconds in game passed.
Action: tensor([[[ 5.0793e-04,  6.0864e-01],
         [-1.7265e-03,  3.2942e-01],
         [-1.9642e-03,  2.2700e-01],
         [-2.0816e-03,  1.7452e-01]]])
agent 0 action: VehicleControl(throttle=0.834205, steer=-0.000561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.73943005709692
20.161369593814015 seconds in game passed.
Action: tensor([[[ 5.0793e-04,  6.0864e-01],
         [-1.7265e-03,  3.2942e-01],
         [-1.9642e-03,  2.2700e-01],
         [-2.0816e-03,  1.7452e-01]]])
agent 0 action: VehicleControl(throttle=0.785727, steer=-0.000594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.73943005709692
20.186369594186544 seconds in game passed.
Action: tensor([[[ 5.0793e-04,  6.0864e-01],
         [-1.7265e-03,  3.2942e-01],
         [-1.9642e-03,  2.2700e-01],
         [-2.0816e-03,  1.7452e-01]]])
agent 0 action: VehicleControl(throttle=0.738587, steer=-0.000628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.73943005709692
+++++++++++++: 1.7889849725646692
20.211369594559073 seconds in game passed.
At 20.211369594559073 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0031,  0.6090],
         [-0.0068,  0.3315],
         [-0.0075,  0.2286],
         [-0.0078,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.620720, steer=-0.005822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7889849725646692
Current reward: 0.5000331006453779
Current mitigation activation: 0
#############################
Total reward: 53.23946315774229
20.236369594931602 seconds in game passed.
Action: tensor([[[-0.0031,  0.6090],
         [-0.0068,  0.3315],
         [-0.0075,  0.2286],
         [-0.0078,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.584177, steer=-0.005056, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.23946315774229
20.26136959530413 seconds in game passed.
Action: tensor([[[-0.0031,  0.6090],
         [-0.0068,  0.3315],
         [-0.0075,  0.2286],
         [-0.0078,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.542399, steer=-0.005142, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.23946315774229
20.28636959567666 seconds in game passed.
Action: tensor([[[-0.0031,  0.6090],
         [-0.0068,  0.3315],
         [-0.0075,  0.2286],
         [-0.0078,  0.1753]]])
agent 0 action: VehicleControl(throttle=0.503710, steer=-0.005227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.23946315774229
+++++++++++++: 1.7486468152084733
20.31136959604919 seconds in game passed.
At 20.31136959604919 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0037,  0.6214],
         [-0.0071,  0.3309],
         [-0.0080,  0.2259],
         [-0.0085,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.617656, steer=-0.005827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7486468152084733
Current reward: 0.5120424572692117
Current mitigation activation: 0
#############################
Total reward: 53.7515056150115
20.33636959642172 seconds in game passed.
Action: tensor([[[-0.0037,  0.6214],
         [-0.0071,  0.3309],
         [-0.0080,  0.2259],
         [-0.0085,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.570478, steer=-0.005801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.7515056150115
20.361369596794248 seconds in game passed.
Action: tensor([[[-0.0037,  0.6214],
         [-0.0071,  0.3309],
         [-0.0080,  0.2259],
         [-0.0085,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.542347, steer=-0.005865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.7515056150115
20.386369597166777 seconds in game passed.
Action: tensor([[[-0.0037,  0.6214],
         [-0.0071,  0.3309],
         [-0.0080,  0.2259],
         [-0.0085,  0.1730]]])
agent 0 action: VehicleControl(throttle=0.516240, steer=-0.005929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.7515056150115
+++++++++++++: 1.725377533252189
20.411369597539306 seconds in game passed.
At 20.411369597539306 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.6286],
         [-0.0048,  0.3319],
         [-0.0055,  0.2260],
         [-0.0059,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.529963, steer=-0.003817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.725377533252189
Current reward: 0.5209646171865503
Current mitigation activation: 0
#############################
Total reward: 54.27247023219805
20.436369597911835 seconds in game passed.
Action: tensor([[[-0.0027,  0.6286],
         [-0.0048,  0.3319],
         [-0.0055,  0.2260],
         [-0.0059,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.503278, steer=-0.004214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.27247023219805
20.461369598284364 seconds in game passed.
Action: tensor([[[-0.0027,  0.6286],
         [-0.0048,  0.3319],
         [-0.0055,  0.2260],
         [-0.0059,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.482583, steer=-0.004252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.27247023219805
20.486369598656893 seconds in game passed.
Action: tensor([[[-0.0027,  0.6286],
         [-0.0048,  0.3319],
         [-0.0055,  0.2260],
         [-0.0059,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.463505, steer=-0.004290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.27247023219805
+++++++++++++: 1.7167065407815414
20.511369599029422 seconds in game passed.
At 20.511369599029422 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0740e-03,  6.0898e-01],
         [-2.5178e-04,  3.2844e-01],
         [-8.5522e-04,  2.2624e-01],
         [-1.6888e-03,  1.7377e-01]]])
agent 0 action: VehicleControl(throttle=0.368118, steer=0.000523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7167065407815414
Current reward: 0.5271874665546387
Current mitigation activation: 0
#############################
Total reward: 54.79965769875269
20.53636959940195 seconds in game passed.
Action: tensor([[[ 1.0740e-03,  6.0898e-01],
         [-2.5178e-04,  3.2844e-01],
         [-8.5522e-04,  2.2624e-01],
         [-1.6888e-03,  1.7377e-01]]])
agent 0 action: VehicleControl(throttle=0.359371, steer=-0.000256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.79965769875269
20.56136959977448 seconds in game passed.
Action: tensor([[[ 1.0740e-03,  6.0898e-01],
         [-2.5178e-04,  3.2844e-01],
         [-8.5522e-04,  2.2624e-01],
         [-1.6888e-03,  1.7377e-01]]])
agent 0 action: VehicleControl(throttle=0.344372, steer=-0.000236, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.79965769875269
20.58636960014701 seconds in game passed.
Action: tensor([[[ 1.0740e-03,  6.0898e-01],
         [-2.5178e-04,  3.2844e-01],
         [-8.5522e-04,  2.2624e-01],
         [-1.6888e-03,  1.7377e-01]]])
agent 0 action: VehicleControl(throttle=0.331901, steer=-0.000216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.79965769875269
+++++++++++++: 1.7198543269654185
20.611369600519538 seconds in game passed.
At 20.611369600519538 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0044, 0.6248],
         [0.0032, 0.3363],
         [0.0028, 0.2311],
         [0.0019, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.228094, steer=0.003646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7198543269654185
Current reward: 0.5312865574688356
Current mitigation activation: 0
#############################
Total reward: 55.33094425622153
20.636369600892067 seconds in game passed.
Action: tensor([[[0.0044, 0.6248],
         [0.0032, 0.3363],
         [0.0028, 0.2311],
         [0.0019, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.227616, steer=0.003053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.33094425622153
20.661369601264596 seconds in game passed.
Action: tensor([[[0.0044, 0.6248],
         [0.0032, 0.3363],
         [0.0028, 0.2311],
         [0.0019, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.217076, steer=0.003096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.33094425622153
20.686369601637125 seconds in game passed.
Action: tensor([[[0.0044, 0.6248],
         [0.0032, 0.3363],
         [0.0028, 0.2311],
         [0.0019, 0.1776]]])
agent 0 action: VehicleControl(throttle=0.206518, steer=0.003140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.33094425622153
+++++++++++++: 1.7367627053483965
20.711369602009654 seconds in game passed.
At 20.711369602009654 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6302],
         [0.0023, 0.3367],
         [0.0018, 0.2307],
         [0.0010, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.234521, steer=0.002189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7367627053483965
Current reward: 0.5330808132552733
Current mitigation activation: 0
#############################
Total reward: 55.8640250694768
20.736369602382183 seconds in game passed.
Action: tensor([[[0.0037, 0.6302],
         [0.0023, 0.3367],
         [0.0018, 0.2307],
         [0.0010, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.233910, steer=0.002353, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.8640250694768
20.761369602754712 seconds in game passed.
Action: tensor([[[0.0037, 0.6302],
         [0.0023, 0.3367],
         [0.0018, 0.2307],
         [0.0010, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.238045, steer=0.002357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.8640250694768
20.78636960312724 seconds in game passed.
Action: tensor([[[0.0037, 0.6302],
         [0.0023, 0.3367],
         [0.0018, 0.2307],
         [0.0010, 0.1771]]])
agent 0 action: VehicleControl(throttle=0.243547, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.8640250694768
+++++++++++++: 1.7687111603015973
20.81136960349977 seconds in game passed.
At 20.81136960349977 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0019, 0.6254],
         [0.0022, 0.3342],
         [0.0020, 0.2290],
         [0.0013, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.292060, steer=0.001598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7687111603015973
Current reward: 0.5326216051040713
Current mitigation activation: 0
#############################
Total reward: 56.39664667458087
20.8363696038723 seconds in game passed.
Action: tensor([[[0.0019, 0.6254],
         [0.0022, 0.3342],
         [0.0020, 0.2290],
         [0.0013, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.295674, steer=0.001715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.39664667458087
20.86136960424483 seconds in game passed.
Action: tensor([[[0.0019, 0.6254],
         [0.0022, 0.3342],
         [0.0020, 0.2290],
         [0.0013, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.304415, steer=0.001706, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.39664667458087
20.886369604617357 seconds in game passed.
Action: tensor([[[0.0019, 0.6254],
         [0.0022, 0.3342],
         [0.0020, 0.2290],
         [0.0013, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.313373, steer=0.001698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.39664667458087
+++++++++++++: 1.8114878664991825
20.911369604989886 seconds in game passed.
At 20.911369604989886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.9999e-04,  6.1441e-01],
         [-8.4594e-05,  3.3032e-01],
         [-4.4993e-04,  2.2699e-01],
         [-1.4428e-03,  1.7449e-01]]])
agent 0 action: VehicleControl(throttle=0.344781, steer=-0.000853, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8114878664991825
Current reward: 0.5309717866873744
Current mitigation activation: 0
#############################
Total reward: 56.927618461268246
20.936369605362415 seconds in game passed.
Action: tensor([[[-2.9999e-04,  6.1441e-01],
         [-8.4594e-05,  3.3032e-01],
         [-4.4993e-04,  2.2699e-01],
         [-1.4428e-03,  1.7449e-01]]])
agent 0 action: VehicleControl(throttle=0.349666, steer=-0.000454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.927618461268246
20.961369605734944 seconds in game passed.
Action: tensor([[[-2.9999e-04,  6.1441e-01],
         [-8.4594e-05,  3.3032e-01],
         [-4.4993e-04,  2.2699e-01],
         [-1.4428e-03,  1.7449e-01]]])
agent 0 action: VehicleControl(throttle=0.357761, steer=-0.000477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.927618461268246
20.986369606107473 seconds in game passed.
Action: tensor([[[-2.9999e-04,  6.1441e-01],
         [-8.4594e-05,  3.3032e-01],
         [-4.4993e-04,  2.2699e-01],
         [-1.4428e-03,  1.7449e-01]]])
agent 0 action: VehicleControl(throttle=0.366227, steer=-0.000499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.927618461268246
+++++++++++++: 1.8592149415220478
21.011369606480002 seconds in game passed.
At 21.011369606480002 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6168],
         [-0.0017,  0.3301],
         [-0.0020,  0.2258],
         [-0.0027,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.406868, steer=-0.002434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8592149415220478
Current reward: 0.5293171415094864
Current mitigation activation: 0
#############################
Total reward: 57.45693560277773
21.03636960685253 seconds in game passed.
Action: tensor([[[-0.0021,  0.6168],
         [-0.0017,  0.3301],
         [-0.0020,  0.2258],
         [-0.0027,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.412654, steer=-0.002144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.45693560277773
21.06136960722506 seconds in game passed.
Action: tensor([[[-0.0021,  0.6168],
         [-0.0017,  0.3301],
         [-0.0020,  0.2258],
         [-0.0027,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.421983, steer=-0.002171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.45693560277773
21.08636960759759 seconds in game passed.
Action: tensor([[[-0.0021,  0.6168],
         [-0.0017,  0.3301],
         [-0.0020,  0.2258],
         [-0.0027,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.431161, steer=-0.002198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.45693560277773
+++++++++++++: 1.9079449477494483
21.11136960797012 seconds in game passed.
At 21.11136960797012 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.6214],
         [-0.0023,  0.3312],
         [-0.0021,  0.2260],
         [-0.0021,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.450550, steer=-0.002967, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9079449477494483
Current reward: 0.5283153555682951
Current mitigation activation: 0
#############################
Total reward: 57.98525095834603
21.136369608342648 seconds in game passed.
Action: tensor([[[-0.0030,  0.6214],
         [-0.0023,  0.3312],
         [-0.0021,  0.2260],
         [-0.0021,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.459445, steer=-0.002861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.98525095834603
21.161369608715177 seconds in game passed.
Action: tensor([[[-0.0030,  0.6214],
         [-0.0023,  0.3312],
         [-0.0021,  0.2260],
         [-0.0021,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.469177, steer=-0.002879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.98525095834603
21.186369609087706 seconds in game passed.
Action: tensor([[[-0.0030,  0.6214],
         [-0.0023,  0.3312],
         [-0.0021,  0.2260],
         [-0.0021,  0.1732]]])
agent 0 action: VehicleControl(throttle=0.478640, steer=-0.002898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.98525095834603
+++++++++++++: 1.9548375682123489
21.211369609460235 seconds in game passed.
At 21.211369609460235 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.7447e-05,  6.0426e-01],
         [ 2.4011e-04,  3.2671e-01],
         [ 6.5275e-04,  2.2434e-01],
         [ 8.9996e-04,  1.7207e-01]]])
agent 0 action: VehicleControl(throttle=0.471189, steer=0.000147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9548375682123489
Current reward: 0.5283199207737925
Current mitigation activation: 0
#############################
Total reward: 58.51357087911982
21.236369609832764 seconds in game passed.
Action: tensor([[[-8.7447e-05,  6.0426e-01],
         [ 2.4011e-04,  3.2671e-01],
         [ 6.5275e-04,  2.2434e-01],
         [ 8.9996e-04,  1.7207e-01]]])
agent 0 action: VehicleControl(throttle=0.482560, steer=-0.000284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.51357087911982
21.261369610205293 seconds in game passed.
Action: tensor([[[-8.7447e-05,  6.0426e-01],
         [ 2.4011e-04,  3.2671e-01],
         [ 6.5275e-04,  2.2434e-01],
         [ 8.9996e-04,  1.7207e-01]]])
agent 0 action: VehicleControl(throttle=0.491825, steer=-0.000218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.51357087911982
21.28636961057782 seconds in game passed.
Action: tensor([[[-8.7447e-05,  6.0426e-01],
         [ 2.4011e-04,  3.2671e-01],
         [ 6.5275e-04,  2.2434e-01],
         [ 8.9996e-04,  1.7207e-01]]])
agent 0 action: VehicleControl(throttle=0.500934, steer=-0.000153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.51357087911982
+++++++++++++: 1.9984141834727476
21.31136961095035 seconds in game passed.
At 21.31136961095035 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.6034],
         [0.0019, 0.3250],
         [0.0021, 0.2224],
         [0.0021, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.562615, steer=0.001641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9984141834727476
Current reward: 0.5294132013975417
Current mitigation activation: 0
#############################
Total reward: 59.04298408051736
21.33636961132288 seconds in game passed.
Action: tensor([[[0.0012, 0.6034],
         [0.0019, 0.3250],
         [0.0021, 0.2224],
         [0.0021, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.564328, steer=0.001446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.04298408051736
21.36136961169541 seconds in game passed.
Action: tensor([[[0.0012, 0.6034],
         [0.0019, 0.3250],
         [0.0021, 0.2224],
         [0.0021, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.571273, steer=0.001535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.04298408051736
21.386369612067938 seconds in game passed.
Action: tensor([[[0.0012, 0.6034],
         [0.0019, 0.3250],
         [0.0021, 0.2224],
         [0.0021, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.577242, steer=0.001624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.04298408051736
+++++++++++++: 2.0383987181857353
21.411369612440467 seconds in game passed.
At 21.411369612440467 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6153],
         [0.0037, 0.3297],
         [0.0033, 0.2251],
         [0.0023, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.534948, steer=0.003548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0383987181857353
Current reward: 0.5314910742349978
Current mitigation activation: 0
#############################
Total reward: 59.574475154752356
21.436369612812996 seconds in game passed.
Action: tensor([[[0.0026, 0.6153],
         [0.0037, 0.3297],
         [0.0033, 0.2251],
         [0.0023, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.543375, steer=0.003327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.574475154752356
21.461369613185525 seconds in game passed.
Action: tensor([[[0.0026, 0.6153],
         [0.0037, 0.3297],
         [0.0033, 0.2251],
         [0.0023, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.548226, steer=0.003413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.574475154752356
21.486369613558054 seconds in game passed.
Action: tensor([[[0.0026, 0.6153],
         [0.0037, 0.3297],
         [0.0033, 0.2251],
         [0.0023, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.553000, steer=0.003499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.574475154752356
+++++++++++++: 2.0741185786559972
21.511369613930583 seconds in game passed.
At 21.511369613930583 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6113],
         [0.0038, 0.3266],
         [0.0037, 0.2228],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.631110, steer=0.003644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0741185786559972
Current reward: 0.5345203304205413
Current mitigation activation: 0
#############################
Total reward: 60.1089954851729
21.536369614303112 seconds in game passed.
Action: tensor([[[0.0026, 0.6113],
         [0.0038, 0.3266],
         [0.0037, 0.2228],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.630132, steer=0.003663, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.1089954851729
21.56136961467564 seconds in game passed.
Action: tensor([[[0.0026, 0.6113],
         [0.0038, 0.3266],
         [0.0037, 0.2228],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.636914, steer=0.003700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.1089954851729
21.58636961504817 seconds in game passed.
Action: tensor([[[0.0026, 0.6113],
         [0.0038, 0.3266],
         [0.0037, 0.2228],
         [0.0031, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.643760, steer=0.003737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.1089954851729
+++++++++++++: 2.1104832846150017
21.6113696154207 seconds in game passed.
At 21.6113696154207 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6080],
         [0.0047, 0.3243],
         [0.0049, 0.2208],
         [0.0041, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.701544, steer=0.004108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1104832846150017
Current reward: 0.5377291711441403
Current mitigation activation: 0
#############################
Total reward: 60.64672465631704
21.636369615793228 seconds in game passed.
Action: tensor([[[0.0018, 0.6080],
         [0.0047, 0.3243],
         [0.0049, 0.2208],
         [0.0041, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.704742, steer=0.004048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.64672465631704
21.661369616165757 seconds in game passed.
Action: tensor([[[0.0018, 0.6080],
         [0.0047, 0.3243],
         [0.0049, 0.2208],
         [0.0041, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.713246, steer=0.004049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.64672465631704
21.686369616538286 seconds in game passed.
Action: tensor([[[0.0018, 0.6080],
         [0.0047, 0.3243],
         [0.0049, 0.2208],
         [0.0041, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.721769, steer=0.004050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.64672465631704
+++++++++++++: 2.147897299741959
21.711369616910815 seconds in game passed.
At 21.711369616910815 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0008, 0.6160],
         [0.0037, 0.3274],
         [0.0038, 0.2223],
         [0.0029, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.698721, steer=0.002881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.147897299741959
Current reward: 0.5410427290509069
Current mitigation activation: 0
#############################
Total reward: 61.18776738536795
21.736369617283344 seconds in game passed.
Action: tensor([[[0.0008, 0.6160],
         [0.0037, 0.3274],
         [0.0038, 0.2223],
         [0.0029, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.709708, steer=0.003074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.18776738536795
21.761369617655873 seconds in game passed.
Action: tensor([[[0.0008, 0.6160],
         [0.0037, 0.3274],
         [0.0038, 0.2223],
         [0.0029, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.717255, steer=0.003073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.18776738536795
21.786369618028402 seconds in game passed.
Action: tensor([[[0.0008, 0.6160],
         [0.0037, 0.3274],
         [0.0038, 0.2223],
         [0.0029, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.724657, steer=0.003072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.18776738536795
+++++++++++++: 2.186290775493412
21.81136961840093 seconds in game passed.
At 21.81136961840093 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6239],
         [0.0057, 0.3284],
         [0.0060, 0.2224],
         [0.0053, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.777493, steer=0.005540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.186290775493412
Current reward: 0.544453281039218
Current mitigation activation: 0
#############################
Total reward: 61.732220666407166
21.83636961877346 seconds in game passed.
Action: tensor([[[0.0032, 0.6239],
         [0.0057, 0.3284],
         [0.0060, 0.2224],
         [0.0053, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.779732, steer=0.005166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.732220666407166
21.86136961914599 seconds in game passed.
Action: tensor([[[0.0032, 0.6239],
         [0.0057, 0.3284],
         [0.0060, 0.2224],
         [0.0053, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.786691, steer=0.005198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.732220666407166
21.88636961951852 seconds in game passed.
Action: tensor([[[0.0032, 0.6239],
         [0.0057, 0.3284],
         [0.0060, 0.2224],
         [0.0053, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.793459, steer=0.005230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.732220666407166
+++++++++++++: 2.2255792935998513
21.911369619891047 seconds in game passed.
At 21.911369619891047 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0057, 0.6349],
         [0.0080, 0.3315],
         [0.0086, 0.2236],
         [0.0080, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.796297, steer=0.008027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2255792935998513
Current reward: 0.5479544269253502
Current mitigation activation: 0
#############################
Total reward: 62.28017509333252
21.936369620263577 seconds in game passed.
Action: tensor([[[0.0057, 0.6349],
         [0.0080, 0.3315],
         [0.0086, 0.2236],
         [0.0080, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.802769, steer=0.007662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.28017509333252
21.961369620636106 seconds in game passed.
Action: tensor([[[0.0057, 0.6349],
         [0.0080, 0.3315],
         [0.0086, 0.2236],
         [0.0080, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.796119, steer=0.007748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.28017509333252
21.986369621008635 seconds in game passed.
Action: tensor([[[0.0057, 0.6349],
         [0.0080, 0.3315],
         [0.0086, 0.2236],
         [0.0080, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.780262, steer=0.007835, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.28017509333252
+++++++++++++: 2.255112476058154
22.011369621381164 seconds in game passed.
At 22.011369621381164 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0106, 0.6462],
         [0.0159, 0.3358],
         [0.0178, 0.2253],
         [0.0175, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.721083, steer=0.015768, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.255112476058154
Current reward: 0.5528527150285738
Current mitigation activation: 0
#############################
Total reward: 62.83302780836109
22.036369621753693 seconds in game passed.
Action: tensor([[[0.0106, 0.6462],
         [0.0159, 0.3358],
         [0.0178, 0.2253],
         [0.0175, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.708812, steer=0.014664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.83302780836109
22.06136962212622 seconds in game passed.
Action: tensor([[[0.0106, 0.6462],
         [0.0159, 0.3358],
         [0.0178, 0.2253],
         [0.0175, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.691919, steer=0.014851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.83302780836109
22.08636962249875 seconds in game passed.
Action: tensor([[[0.0106, 0.6462],
         [0.0159, 0.3358],
         [0.0178, 0.2253],
         [0.0175, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.675044, steer=0.015039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.83302780836109
+++++++++++++: 2.25395278364676
22.11136962287128 seconds in game passed.
At 22.11136962287128 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0095, 0.6343],
         [0.0098, 0.3330],
         [0.0098, 0.2250],
         [0.0088, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.641810, steer=0.010192, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.25395278364676
Current reward: 0.5616248611116208
Current mitigation activation: 0
#############################
Total reward: 63.394652669472705
22.13636962324381 seconds in game passed.
Action: tensor([[[0.0095, 0.6343],
         [0.0098, 0.3330],
         [0.0098, 0.2250],
         [0.0088, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.626843, steer=0.011167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.394652669472705
22.161369623616338 seconds in game passed.
Action: tensor([[[0.0095, 0.6343],
         [0.0098, 0.3330],
         [0.0098, 0.2250],
         [0.0088, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.610427, steer=0.011310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.394652669472705
22.186369623988867 seconds in game passed.
Action: tensor([[[0.0095, 0.6343],
         [0.0098, 0.3330],
         [0.0098, 0.2250],
         [0.0088, 0.1717]]])
agent 0 action: VehicleControl(throttle=0.594622, steer=0.011453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.394652669472705
+++++++++++++: 2.2533101066846988
22.211369624361396 seconds in game passed.
At 22.211369624361396 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6213],
         [0.0049, 0.3297],
         [0.0047, 0.2239],
         [0.0036, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.568991, steer=0.005689, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2533101066846988
Current reward: 0.5700618434778535
Current mitigation activation: 0
#############################
Total reward: 63.96471451295056
22.236369624733925 seconds in game passed.
Action: tensor([[[0.0039, 0.6213],
         [0.0049, 0.3297],
         [0.0047, 0.2239],
         [0.0036, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.555566, steer=0.006709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.96471451295056
22.261369625106454 seconds in game passed.
Action: tensor([[[0.0039, 0.6213],
         [0.0049, 0.3297],
         [0.0047, 0.2239],
         [0.0036, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.541620, steer=0.006761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.96471451295056
22.286369625478983 seconds in game passed.
Action: tensor([[[0.0039, 0.6213],
         [0.0049, 0.3297],
         [0.0047, 0.2239],
         [0.0036, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.528433, steer=0.006812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.96471451295056
+++++++++++++: 2.2579087302116814
22.311369625851512 seconds in game passed.
At 22.311369625851512 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6272],
         [0.0049, 0.3304],
         [0.0049, 0.2239],
         [0.0041, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.549552, steer=0.006901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2579087302116814
Current reward: 0.5775400440862116
Current mitigation activation: 0
#############################
Total reward: 64.54225455703677
22.33636962622404 seconds in game passed.
Action: tensor([[[0.0039, 0.6272],
         [0.0049, 0.3304],
         [0.0049, 0.2239],
         [0.0041, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.533950, steer=0.006926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.54225455703677
22.36136962659657 seconds in game passed.
Action: tensor([[[0.0039, 0.6272],
         [0.0049, 0.3304],
         [0.0049, 0.2239],
         [0.0041, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.522580, steer=0.006960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.54225455703677
22.3863696269691 seconds in game passed.
Action: tensor([[[0.0039, 0.6272],
         [0.0049, 0.3304],
         [0.0049, 0.2239],
         [0.0041, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.511608, steer=0.006994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.54225455703677
+++++++++++++: 2.2686097522459905
22.411369627341628 seconds in game passed.
At 22.411369627341628 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6107],
         [0.0044, 0.3251],
         [0.0042, 0.2214],
         [0.0034, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.523879, steer=0.006408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2686097522459905
Current reward: 0.5839827478327554
Current mitigation activation: 0
#############################
Total reward: 65.12623730486952
22.436369627714157 seconds in game passed.
Action: tensor([[[0.0033, 0.6107],
         [0.0044, 0.3251],
         [0.0042, 0.2214],
         [0.0034, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.512308, steer=0.006516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.12623730486952
22.461369628086686 seconds in game passed.
Action: tensor([[[0.0033, 0.6107],
         [0.0044, 0.3251],
         [0.0042, 0.2214],
         [0.0034, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.503519, steer=0.006525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.12623730486952
22.486369628459215 seconds in game passed.
Action: tensor([[[0.0033, 0.6107],
         [0.0044, 0.3251],
         [0.0042, 0.2214],
         [0.0034, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.495026, steer=0.006534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.12623730486952
+++++++++++++: 2.2839192263539148
22.511369628831744 seconds in game passed.
At 22.511369628831744 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9749e-03, 6.1439e-01],
         [2.5685e-03, 3.2699e-01],
         [1.7034e-03, 2.2251e-01],
         [1.9649e-04, 1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.455994, steer=0.004641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2839192263539148
Current reward: 0.5896415366404457
Current mitigation activation: 0
#############################
Total reward: 65.71587884150996
22.536369629204273 seconds in game passed.
Action: tensor([[[1.9749e-03, 6.1439e-01],
         [2.5685e-03, 3.2699e-01],
         [1.7034e-03, 2.2251e-01],
         [1.9649e-04, 1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.450261, steer=0.004943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.71587884150996
22.561369629576802 seconds in game passed.
Action: tensor([[[1.9749e-03, 6.1439e-01],
         [2.5685e-03, 3.2699e-01],
         [1.7034e-03, 2.2251e-01],
         [1.9649e-04, 1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.441771, steer=0.004931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.71587884150996
22.58636962994933 seconds in game passed.
Action: tensor([[[1.9749e-03, 6.1439e-01],
         [2.5685e-03, 3.2699e-01],
         [1.7034e-03, 2.2251e-01],
         [1.9649e-04, 1.7034e-01]]])
agent 0 action: VehicleControl(throttle=0.433925, steer=0.004919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.71587884150996
+++++++++++++: 2.3026434208938915
22.61136963032186 seconds in game passed.
At 22.61136963032186 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9276e-03, 6.1798e-01],
         [1.8828e-03, 3.2703e-01],
         [1.4073e-03, 2.2239e-01],
         [4.1271e-04, 1.7035e-01]]])
agent 0 action: VehicleControl(throttle=0.461545, steer=0.004376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3026434208938915
Current reward: 0.5947185371782281
Current mitigation activation: 0
#############################
Total reward: 66.31059737868819
22.63636963069439 seconds in game passed.
Action: tensor([[[1.9276e-03, 6.1798e-01],
         [1.8828e-03, 3.2703e-01],
         [1.4073e-03, 2.2239e-01],
         [4.1271e-04, 1.7035e-01]]])
agent 0 action: VehicleControl(throttle=0.450866, steer=0.004442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.31059737868819
22.66136963106692 seconds in game passed.
Action: tensor([[[1.9276e-03, 6.1798e-01],
         [1.8828e-03, 3.2703e-01],
         [1.4073e-03, 2.2239e-01],
         [4.1271e-04, 1.7035e-01]]])
agent 0 action: VehicleControl(throttle=0.444345, steer=0.004421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.31059737868819
22.686369631439447 seconds in game passed.
Action: tensor([[[1.9276e-03, 6.1798e-01],
         [1.8828e-03, 3.2703e-01],
         [1.4073e-03, 2.2239e-01],
         [4.1271e-04, 1.7035e-01]]])
agent 0 action: VehicleControl(throttle=0.438000, steer=0.004400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.31059737868819
+++++++++++++: 2.3253968896984434
22.711369631811976 seconds in game passed.
At 22.711369631811976 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.6152],
         [0.0038, 0.3277],
         [0.0039, 0.2230],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.378471, steer=0.006169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3253968896984434
Current reward: 0.599172430633959
Current mitigation activation: 0
#############################
Total reward: 66.90976980932214
22.736369632184505 seconds in game passed.
Action: tensor([[[0.0027, 0.6152],
         [0.0038, 0.3277],
         [0.0039, 0.2230],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.378088, steer=0.005885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.90976980932214
22.761369632557034 seconds in game passed.
Action: tensor([[[0.0027, 0.6152],
         [0.0038, 0.3277],
         [0.0039, 0.2230],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.372439, steer=0.005894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.90976980932214
22.786369632929564 seconds in game passed.
Action: tensor([[[0.0027, 0.6152],
         [0.0038, 0.3277],
         [0.0039, 0.2230],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.367510, steer=0.005904, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.90976980932214
+++++++++++++: 2.3512740558036644
22.811369633302093 seconds in game passed.
At 22.811369633302093 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0036, 0.6223],
         [0.0055, 0.3300],
         [0.0055, 0.2240],
         [0.0046, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.351166, steer=0.007432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3512740558036644
Current reward: 0.6031738211070334
Current mitigation activation: 0
#############################
Total reward: 67.51294363042918
22.83636963367462 seconds in game passed.
Action: tensor([[[0.0036, 0.6223],
         [0.0055, 0.3300],
         [0.0055, 0.2240],
         [0.0046, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.347915, steer=0.007177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.51294363042918
22.86136963404715 seconds in game passed.
Action: tensor([[[0.0036, 0.6223],
         [0.0055, 0.3300],
         [0.0055, 0.2240],
         [0.0046, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.343975, steer=0.007177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.51294363042918
22.88636963441968 seconds in game passed.
Action: tensor([[[0.0036, 0.6223],
         [0.0055, 0.3300],
         [0.0055, 0.2240],
         [0.0046, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.340563, steer=0.007177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.51294363042918
+++++++++++++: 2.3814373184696755
22.91136963479221 seconds in game passed.
At 22.91136963479221 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6107],
         [0.0024, 0.3279],
         [0.0020, 0.2237],
         [0.0010, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.294868, steer=0.004203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3814373184696755
Current reward: 0.6066170251879
Current mitigation activation: 0
#############################
Total reward: 68.11956065561708
22.936369635164738 seconds in game passed.
Action: tensor([[[0.0020, 0.6107],
         [0.0024, 0.3279],
         [0.0020, 0.2237],
         [0.0010, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.296438, steer=0.004630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.11956065561708
22.961369635537267 seconds in game passed.
Action: tensor([[[0.0020, 0.6107],
         [0.0024, 0.3279],
         [0.0020, 0.2237],
         [0.0010, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.294091, steer=0.004572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.11956065561708
22.986369635909796 seconds in game passed.
Action: tensor([[[0.0020, 0.6107],
         [0.0024, 0.3279],
         [0.0020, 0.2237],
         [0.0010, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.292709, steer=0.004513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.11956065561708
+++++++++++++: 2.416094447290039
23.011369636282325 seconds in game passed.
At 23.011369636282325 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.3935e-04,  6.0922e-01],
         [ 1.0985e-03,  3.2657e-01],
         [ 7.8293e-04,  2.2263e-01],
         [-7.8559e-05,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.326321, steer=0.003024, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.416094447290039
Current reward: 0.6095289930833054
Current mitigation activation: 0
#############################
Total reward: 68.72908964870038
23.036369636654854 seconds in game passed.
Action: tensor([[[ 9.3935e-04,  6.0922e-01],
         [ 1.0985e-03,  3.2657e-01],
         [ 7.8293e-04,  2.2263e-01],
         [-7.8559e-05,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.323745, steer=0.003094, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72908964870038
23.061369637027383 seconds in game passed.
Action: tensor([[[ 9.3935e-04,  6.0922e-01],
         [ 1.0985e-03,  3.2657e-01],
         [ 7.8293e-04,  2.2263e-01],
         [-7.8559e-05,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.325299, steer=0.002941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72908964870038
23.086369637399912 seconds in game passed.
Action: tensor([[[ 9.3935e-04,  6.0922e-01],
         [ 1.0985e-03,  3.2657e-01],
         [ 7.8293e-04,  2.2263e-01],
         [-7.8559e-05,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.327160, steer=0.002787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.72908964870038
+++++++++++++: 2.4552453075607596
23.11136963777244 seconds in game passed.
At 23.11136963777244 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.6265],
         [-0.0007,  0.3304],
         [-0.0012,  0.2238],
         [-0.0020,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.368647, steer=0.000316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4552453075607596
Current reward: 0.6119694780184172
Current mitigation activation: 0
#############################
Total reward: 69.3410591267188
23.13636963814497 seconds in game passed.
Action: tensor([[[-0.0016,  0.6265],
         [-0.0007,  0.3304],
         [-0.0012,  0.2238],
         [-0.0020,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.367613, steer=0.000581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.3410591267188
23.1613696385175 seconds in game passed.
Action: tensor([[[-0.0016,  0.6265],
         [-0.0007,  0.3304],
         [-0.0012,  0.2238],
         [-0.0020,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.370877, steer=0.000456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.3410591267188
23.186369638890028 seconds in game passed.
Action: tensor([[[-0.0016,  0.6265],
         [-0.0007,  0.3304],
         [-0.0012,  0.2238],
         [-0.0020,  0.1704]]])
agent 0 action: VehicleControl(throttle=0.374047, steer=0.000330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.3410591267188
+++++++++++++: 2.496307550940314
23.211369639262557 seconds in game passed.
At 23.211369639262557 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6116],
         [-0.0016,  0.3258],
         [-0.0022,  0.2214],
         [-0.0033,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.390935, steer=-0.000563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.496307550940314
Current reward: 0.6143112888002937
Current mitigation activation: 0
#############################
Total reward: 69.9553704155191
23.236369639635086 seconds in game passed.
Action: tensor([[[-0.0022,  0.6116],
         [-0.0016,  0.3258],
         [-0.0022,  0.2214],
         [-0.0033,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.392894, steer=-0.000500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.9553704155191
23.261369640007615 seconds in game passed.
Action: tensor([[[-0.0022,  0.6116],
         [-0.0016,  0.3258],
         [-0.0022,  0.2214],
         [-0.0033,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.396239, steer=-0.000574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.9553704155191
23.286369640380144 seconds in game passed.
Action: tensor([[[-0.0022,  0.6116],
         [-0.0016,  0.3258],
         [-0.0022,  0.2214],
         [-0.0033,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.399446, steer=-0.000647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.9553704155191
+++++++++++++: 2.536508571958469
23.311369640752673 seconds in game passed.
At 23.311369640752673 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6118],
         [-0.0020,  0.3265],
         [-0.0022,  0.2220],
         [-0.0029,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.379995, steer=-0.001185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.536508571958469
Current reward: 0.6168983532964369
Current mitigation activation: 0
#############################
Total reward: 70.57226876881553
23.336369641125202 seconds in game passed.
Action: tensor([[[-0.0025,  0.6118],
         [-0.0020,  0.3265],
         [-0.0022,  0.2220],
         [-0.0029,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.384725, steer=-0.001188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.57226876881553
23.36136964149773 seconds in game passed.
Action: tensor([[[-0.0025,  0.6118],
         [-0.0020,  0.3265],
         [-0.0022,  0.2220],
         [-0.0029,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.387078, steer=-0.001267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.57226876881553
23.38636964187026 seconds in game passed.
Action: tensor([[[-0.0025,  0.6118],
         [-0.0020,  0.3265],
         [-0.0022,  0.2220],
         [-0.0029,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.389535, steer=-0.001346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.57226876881553
+++++++++++++: 2.57495704588316
23.41136964224279 seconds in game passed.
At 23.41136964224279 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7341e-04,  6.0572e-01],
         [-3.2382e-04,  3.2547e-01],
         [-4.5516e-04,  2.2182e-01],
         [-9.7875e-04,  1.6896e-01]]])
agent 0 action: VehicleControl(throttle=0.364405, steer=0.000927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.57495704588316
Current reward: 0.6198103161005111
Current mitigation activation: 0
#############################
Total reward: 71.19207908491605
23.43636964261532 seconds in game passed.
Action: tensor([[[ 2.7341e-04,  6.0572e-01],
         [-3.2382e-04,  3.2547e-01],
         [-4.5516e-04,  2.2182e-01],
         [-9.7875e-04,  1.6896e-01]]])
agent 0 action: VehicleControl(throttle=0.369298, steer=0.000491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.19207908491605
23.461369642987847 seconds in game passed.
Action: tensor([[[ 2.7341e-04,  6.0572e-01],
         [-3.2382e-04,  3.2547e-01],
         [-4.5516e-04,  2.2182e-01],
         [-9.7875e-04,  1.6896e-01]]])
agent 0 action: VehicleControl(throttle=0.371389, steer=0.000443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.19207908491605
23.486369643360376 seconds in game passed.
Action: tensor([[[ 2.7341e-04,  6.0572e-01],
         [-3.2382e-04,  3.2547e-01],
         [-4.5516e-04,  2.2182e-01],
         [-9.7875e-04,  1.6896e-01]]])
agent 0 action: VehicleControl(throttle=0.373727, steer=0.000394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.19207908491605
+++++++++++++: 2.6128362650252117
23.511369643732905 seconds in game passed.
At 23.511369643732905 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.7055e-04,  6.0961e-01],
         [-3.1872e-04,  3.2743e-01],
         [-7.9668e-04,  2.2289e-01],
         [-1.4957e-03,  1.6942e-01]]])
agent 0 action: VehicleControl(throttle=0.345809, steer=0.000113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6128362650252117
Current reward: 0.62287874026251
Current mitigation activation: 0
#############################
Total reward: 71.81495782517855
23.536369644105434 seconds in game passed.
Action: tensor([[[-3.7055e-04,  6.0961e-01],
         [-3.1872e-04,  3.2743e-01],
         [-7.9668e-04,  2.2289e-01],
         [-1.4957e-03,  1.6942e-01]]])
agent 0 action: VehicleControl(throttle=0.351678, steer=0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.81495782517855
23.561369644477963 seconds in game passed.
Action: tensor([[[-3.7055e-04,  6.0961e-01],
         [-3.1872e-04,  3.2743e-01],
         [-7.9668e-04,  2.2289e-01],
         [-1.4957e-03,  1.6942e-01]]])
agent 0 action: VehicleControl(throttle=0.354472, steer=0.000091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.81495782517855
23.586369644850492 seconds in game passed.
Action: tensor([[[-3.7055e-04,  6.0961e-01],
         [-3.1872e-04,  3.2743e-01],
         [-7.9668e-04,  2.2289e-01],
         [-1.4957e-03,  1.6942e-01]]])
agent 0 action: VehicleControl(throttle=0.357590, steer=0.000060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.81495782517855
+++++++++++++: 2.6514278692961653
23.61136964522302 seconds in game passed.
At 23.61136964522302 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.2188e-04,  6.1576e-01],
         [ 1.0116e-03,  3.2904e-01],
         [ 5.9200e-04,  2.2363e-01],
         [-2.1211e-04,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.366131, steer=0.001531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6514278692961653
Current reward: 0.6259431761292926
Current mitigation activation: 0
#############################
Total reward: 72.44090100130785
23.63636964559555 seconds in game passed.
Action: tensor([[[ 9.2188e-04,  6.1576e-01],
         [ 1.0116e-03,  3.2904e-01],
         [ 5.9200e-04,  2.2363e-01],
         [-2.1211e-04,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.368680, steer=0.001273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.44090100130785
23.66136964596808 seconds in game passed.
Action: tensor([[[ 9.2188e-04,  6.1576e-01],
         [ 1.0116e-03,  3.2904e-01],
         [ 5.9200e-04,  2.2363e-01],
         [-2.1211e-04,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.371917, steer=0.001263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.44090100130785
23.68636964634061 seconds in game passed.
Action: tensor([[[ 9.2188e-04,  6.1576e-01],
         [ 1.0116e-03,  3.2904e-01],
         [ 5.9200e-04,  2.2363e-01],
         [-2.1211e-04,  1.7025e-01]]])
agent 0 action: VehicleControl(throttle=0.375179, steer=0.001252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.44090100130785
+++++++++++++: 2.691383266732523
23.711369646713138 seconds in game passed.
At 23.711369646713138 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0051, 0.6257],
         [0.0027, 0.3325],
         [0.0018, 0.2264],
         [0.0007, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.357629, steer=0.004148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.691383266732523
Current reward: 0.6289346838885805
Current mitigation activation: 0
#############################
Total reward: 73.06983568519644
23.736369647085667 seconds in game passed.
Action: tensor([[[0.0051, 0.6257],
         [0.0027, 0.3325],
         [0.0018, 0.2264],
         [0.0007, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.363514, steer=0.003666, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.06983568519644
23.761369647458196 seconds in game passed.
Action: tensor([[[0.0051, 0.6257],
         [0.0027, 0.3325],
         [0.0018, 0.2264],
         [0.0007, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.367168, steer=0.003667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.06983568519644
23.786369647830725 seconds in game passed.
Action: tensor([[[0.0051, 0.6257],
         [0.0027, 0.3325],
         [0.0018, 0.2264],
         [0.0007, 0.1721]]])
agent 0 action: VehicleControl(throttle=0.370931, steer=0.003668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.06983568519644
+++++++++++++: 2.7318590877218885
23.811369648203254 seconds in game passed.
At 23.811369648203254 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1076e-03,  6.1567e-01],
         [-3.1956e-04,  3.2716e-01],
         [-7.8249e-04,  2.2340e-01],
         [-1.2763e-03,  1.6998e-01]]])
agent 0 action: VehicleControl(throttle=0.464198, steer=0.000208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7318590877218885
Current reward: 0.631959915019634
Current mitigation activation: 0
#############################
Total reward: 73.70179560021607
23.836369648575783 seconds in game passed.
Action: tensor([[[ 2.1076e-03,  6.1567e-01],
         [-3.1956e-04,  3.2716e-01],
         [-7.8249e-04,  2.2340e-01],
         [-1.2763e-03,  1.6998e-01]]])
agent 0 action: VehicleControl(throttle=0.459631, steer=0.000726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.70179560021607
23.861369648948312 seconds in game passed.
Action: tensor([[[ 2.1076e-03,  6.1567e-01],
         [-3.1956e-04,  3.2716e-01],
         [-7.8249e-04,  2.2340e-01],
         [-1.2763e-03,  1.6998e-01]]])
agent 0 action: VehicleControl(throttle=0.464282, steer=0.000676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.70179560021607
23.88636964932084 seconds in game passed.
Action: tensor([[[ 2.1076e-03,  6.1567e-01],
         [-3.1956e-04,  3.2716e-01],
         [-7.8249e-04,  2.2340e-01],
         [-1.2763e-03,  1.6998e-01]]])
agent 0 action: VehicleControl(throttle=0.468120, steer=0.000625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.70179560021607
+++++++++++++: 2.772127978214329
23.91136964969337 seconds in game passed.
At 23.91136964969337 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6175],
         [-0.0023,  0.3281],
         [-0.0025,  0.2235],
         [-0.0028,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.457741, steer=-0.002090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.772127978214329
Current reward: 0.6350897121049377
Current mitigation activation: 0
#############################
Total reward: 74.33688531232102
23.9363696500659 seconds in game passed.
Action: tensor([[[-0.0011,  0.6175],
         [-0.0023,  0.3281],
         [-0.0025,  0.2235],
         [-0.0028,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.462213, steer=-0.001694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.33688531232102
23.961369650438428 seconds in game passed.
Action: tensor([[[-0.0011,  0.6175],
         [-0.0023,  0.3281],
         [-0.0025,  0.2235],
         [-0.0028,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.464732, steer=-0.001741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.33688531232102
23.986369650810957 seconds in game passed.
Action: tensor([[[-0.0011,  0.6175],
         [-0.0023,  0.3281],
         [-0.0025,  0.2235],
         [-0.0028,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.466893, steer=-0.001789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.33688531232102
+++++++++++++: 2.8084531288447616
24.011369651183486 seconds in game passed.
At 24.011369651183486 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.6116],
         [-0.0029,  0.3260],
         [-0.0034,  0.2220],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.484556, steer=-0.002306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8084531288447616
Current reward: 0.6387019542319803
Current mitigation activation: 0
#############################
Total reward: 74.97558726655299
24.036369651556015 seconds in game passed.
Action: tensor([[[-0.0010,  0.6116],
         [-0.0029,  0.3260],
         [-0.0034,  0.2220],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.484121, steer=-0.002265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.97558726655299
24.061369651928544 seconds in game passed.
Action: tensor([[[-0.0010,  0.6116],
         [-0.0029,  0.3260],
         [-0.0034,  0.2220],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.485056, steer=-0.002304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.97558726655299
24.086369652301073 seconds in game passed.
Action: tensor([[[-0.0010,  0.6116],
         [-0.0029,  0.3260],
         [-0.0034,  0.2220],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.485570, steer=-0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.97558726655299
+++++++++++++: 2.841055545195231
24.111369652673602 seconds in game passed.
At 24.111369652673602 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0037,  0.6190],
         [-0.0072,  0.3297],
         [-0.0079,  0.2238],
         [-0.0082,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.425983, steer=-0.006564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.841055545195231
Current reward: 0.6427276506627365
Current mitigation activation: 0
#############################
Total reward: 75.61831491721573
24.13636965304613 seconds in game passed.
Action: tensor([[[-0.0037,  0.6190],
         [-0.0072,  0.3297],
         [-0.0079,  0.2238],
         [-0.0082,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.431038, steer=-0.005928, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.61831491721573
24.16136965341866 seconds in game passed.
Action: tensor([[[-0.0037,  0.6190],
         [-0.0072,  0.3297],
         [-0.0079,  0.2238],
         [-0.0082,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.429744, steer=-0.005986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.61831491721573
24.18636965379119 seconds in game passed.
Action: tensor([[[-0.0037,  0.6190],
         [-0.0072,  0.3297],
         [-0.0079,  0.2238],
         [-0.0082,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.428700, steer=-0.006044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.61831491721573
+++++++++++++: 2.871154976624544
24.211369654163718 seconds in game passed.
At 24.211369654163718 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6003],
         [-0.0022,  0.3243],
         [-0.0023,  0.2213],
         [-0.0027,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.426439, steer=-0.001795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.871154976624544
Current reward: 0.6469968901335195
Current mitigation activation: 0
#############################
Total reward: 76.26531180734925
24.236369654536247 seconds in game passed.
Action: tensor([[[-0.0022,  0.6003],
         [-0.0022,  0.3243],
         [-0.0023,  0.2213],
         [-0.0027,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.425620, steer=-0.002509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26531180734925
24.261369654908776 seconds in game passed.
Action: tensor([[[-0.0022,  0.6003],
         [-0.0022,  0.3243],
         [-0.0023,  0.2213],
         [-0.0027,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.424766, steer=-0.002514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26531180734925
24.286369655281305 seconds in game passed.
Action: tensor([[[-0.0022,  0.6003],
         [-0.0022,  0.3243],
         [-0.0023,  0.2213],
         [-0.0027,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.424026, steer=-0.002519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26531180734925
+++++++++++++: 2.9020093339593065
24.311369655653834 seconds in game passed.
At 24.311369655653834 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.1734e-04,  6.0381e-01],
         [ 3.5599e-04,  3.2534e-01],
         [ 4.1983e-04,  2.2189e-01],
         [-1.4968e-05,  1.6834e-01]]])
agent 0 action: VehicleControl(throttle=0.423584, steer=-0.000048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9020093339593065
Current reward: 0.6511571085034006
Current mitigation activation: 0
#############################
Total reward: 76.91646891585265
24.336369656026363 seconds in game passed.
Action: tensor([[[-7.1734e-04,  6.0381e-01],
         [ 3.5599e-04,  3.2534e-01],
         [ 4.1983e-04,  2.2189e-01],
         [-1.4968e-05,  1.6834e-01]]])
agent 0 action: VehicleControl(throttle=0.423263, steer=-0.000430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.91646891585265
24.361369656398892 seconds in game passed.
Action: tensor([[[-7.1734e-04,  6.0381e-01],
         [ 3.5599e-04,  3.2534e-01],
         [ 4.1983e-04,  2.2189e-01],
         [-1.4968e-05,  1.6834e-01]]])
agent 0 action: VehicleControl(throttle=0.423006, steer=-0.000405, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.91646891585265
24.38636965677142 seconds in game passed.
Action: tensor([[[-7.1734e-04,  6.0381e-01],
         [ 3.5599e-04,  3.2534e-01],
         [ 4.1983e-04,  2.2189e-01],
         [-1.4968e-05,  1.6834e-01]]])
agent 0 action: VehicleControl(throttle=0.422801, steer=-0.000380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.91646891585265
+++++++++++++: 2.9343247793022122
24.41136965714395 seconds in game passed.
At 24.41136965714395 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.6070],
         [0.0016, 0.3268],
         [0.0017, 0.2227],
         [0.0014, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.404223, steer=0.001321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9343247793022122
Current reward: 0.6551494765203787
Current mitigation activation: 0
#############################
Total reward: 77.57161839237303
24.43636965751648 seconds in game passed.
Action: tensor([[[0.0012, 0.6070],
         [0.0016, 0.3268],
         [0.0017, 0.2227],
         [0.0014, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.406176, steer=0.001059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.57161839237303
24.46136965788901 seconds in game passed.
Action: tensor([[[0.0012, 0.6070],
         [0.0016, 0.3268],
         [0.0017, 0.2227],
         [0.0014, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.406227, steer=0.001078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.57161839237303
24.486369658261538 seconds in game passed.
Action: tensor([[[0.0012, 0.6070],
         [0.0016, 0.3268],
         [0.0017, 0.2227],
         [0.0014, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.406451, steer=0.001096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.57161839237303
+++++++++++++: 2.9676771986872126
24.511369658634067 seconds in game passed.
At 24.511369658634067 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6037],
         [0.0031, 0.3252],
         [0.0031, 0.2228],
         [0.0025, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.429218, steer=0.003002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9676771986872126
Current reward: 0.6590272724775053
Current mitigation activation: 0
#############################
Total reward: 78.23064566485053
24.536369659006596 seconds in game passed.
Action: tensor([[[0.0032, 0.6037],
         [0.0031, 0.3252],
         [0.0031, 0.2228],
         [0.0025, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.427880, steer=0.002732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.23064566485053
24.561369659379125 seconds in game passed.
Action: tensor([[[0.0032, 0.6037],
         [0.0031, 0.3252],
         [0.0031, 0.2228],
         [0.0025, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.428894, steer=0.002773, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.23064566485053
24.586369659751654 seconds in game passed.
Action: tensor([[[0.0032, 0.6037],
         [0.0031, 0.3252],
         [0.0031, 0.2228],
         [0.0025, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.429750, steer=0.002813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.23064566485053
+++++++++++++: 3.0021986322235934
24.611369660124183 seconds in game passed.
At 24.611369660124183 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6098],
         [0.0022, 0.3267],
         [0.0024, 0.2230],
         [0.0024, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.441653, steer=0.002205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0021986322235934
Current reward: 0.6627867558631357
Current mitigation activation: 0
#############################
Total reward: 78.89343242071367
24.63636966049671 seconds in game passed.
Action: tensor([[[0.0034, 0.6098],
         [0.0022, 0.3267],
         [0.0024, 0.2230],
         [0.0024, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.441172, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.89343242071367
24.66136966086924 seconds in game passed.
Action: tensor([[[0.0034, 0.6098],
         [0.0022, 0.3267],
         [0.0024, 0.2230],
         [0.0024, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.441744, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.89343242071367
24.68636966124177 seconds in game passed.
Action: tensor([[[0.0034, 0.6098],
         [0.0022, 0.3267],
         [0.0024, 0.2230],
         [0.0024, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.442124, steer=0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.89343242071367
+++++++++++++: 3.036475999220019
24.7113696616143 seconds in game passed.
At 24.7113696616143 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2044e-03, 6.1894e-01],
         [2.5630e-04, 3.2830e-01],
         [2.3670e-04, 2.2323e-01],
         [2.1760e-04, 1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.478360, steer=0.000091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.036475999220019
Current reward: 0.6665712615421147
Current mitigation activation: 0
#############################
Total reward: 79.56000368225578
24.736369661986828 seconds in game passed.
Action: tensor([[[1.2044e-03, 6.1894e-01],
         [2.5630e-04, 3.2830e-01],
         [2.3670e-04, 2.2323e-01],
         [2.1760e-04, 1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.475290, steer=0.000430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.56000368225578
24.761369662359357 seconds in game passed.
Action: tensor([[[1.2044e-03, 6.1894e-01],
         [2.5630e-04, 3.2830e-01],
         [2.3670e-04, 2.2323e-01],
         [2.1760e-04, 1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.475779, steer=0.000395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.56000368225578
24.786369662731886 seconds in game passed.
Action: tensor([[[1.2044e-03, 6.1894e-01],
         [2.5630e-04, 3.2830e-01],
         [2.3670e-04, 2.2323e-01],
         [2.1760e-04, 1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.475841, steer=0.000360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.56000368225578
+++++++++++++: 3.069394934067956
24.811369663104415 seconds in game passed.
At 24.811369663104415 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.6115],
         [-0.0036,  0.3253],
         [-0.0042,  0.2214],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.508260, steer=-0.003634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.069394934067956
Current reward: 0.6704709511485214
Current mitigation activation: 0
#############################
Total reward: 80.2304746334043
24.836369663476944 seconds in game passed.
Action: tensor([[[-0.0017,  0.6115],
         [-0.0036,  0.3253],
         [-0.0042,  0.2214],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.503556, steer=-0.003015, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.2304746334043
24.861369663849473 seconds in game passed.
Action: tensor([[[-0.0017,  0.6115],
         [-0.0036,  0.3253],
         [-0.0042,  0.2214],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.502111, steer=-0.003056, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.2304746334043
24.886369664222002 seconds in game passed.
Action: tensor([[[-0.0017,  0.6115],
         [-0.0036,  0.3253],
         [-0.0042,  0.2214],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.500174, steer=-0.003096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.2304746334043
+++++++++++++: 3.099616129091027
24.91136966459453 seconds in game passed.
At 24.91136966459453 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0051,  0.6144],
         [-0.0094,  0.3270],
         [-0.0102,  0.2226],
         [-0.0105,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.465846, steer=-0.008799, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.099616129091027
Current reward: 0.674555123275627
Current mitigation activation: 0
#############################
Total reward: 80.90502975667992
24.93636966496706 seconds in game passed.
Action: tensor([[[-0.0051,  0.6144],
         [-0.0094,  0.3270],
         [-0.0102,  0.2226],
         [-0.0105,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.466522, steer=-0.007932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.90502975667992
24.96136966533959 seconds in game passed.
Action: tensor([[[-0.0051,  0.6144],
         [-0.0094,  0.3270],
         [-0.0102,  0.2226],
         [-0.0105,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.463745, steer=-0.008003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.90502975667992
24.986369665712118 seconds in game passed.
Action: tensor([[[-0.0051,  0.6144],
         [-0.0094,  0.3270],
         [-0.0102,  0.2226],
         [-0.0105,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.461036, steer=-0.008074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.90502975667992
+++++++++++++: 3.126749044584239
25.011369666084647 seconds in game passed.
At 25.011369666084647 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6182],
         [-0.0057,  0.3279],
         [-0.0061,  0.2230],
         [-0.0064,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.462574, steer=-0.004680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.126749044584239
Current reward: 0.6784279063202011
Current mitigation activation: 0
#############################
Total reward: 81.58345766300012
25.036369666457176 seconds in game passed.
Action: tensor([[[-0.0033,  0.6182],
         [-0.0057,  0.3279],
         [-0.0061,  0.2230],
         [-0.0064,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.459427, steer=-0.005282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.58345766300012
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:03:15 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:04:02 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 47.49s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.48s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.494               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 81.58, average_reward: 81.58345766300012 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00004/fi_lead_slowdown_data
