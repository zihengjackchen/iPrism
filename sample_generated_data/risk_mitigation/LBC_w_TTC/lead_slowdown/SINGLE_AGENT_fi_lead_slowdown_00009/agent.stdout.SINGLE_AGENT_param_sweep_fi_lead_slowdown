New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190846-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190846-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190846-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190846-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190846-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190846-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 43.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 43}
1.5178050734102726 seconds in game passed.
Action: tensor([[[0.0034, 0.5925],
         [0.0022, 0.3310],
         [0.0019, 0.2349],
         [0.0011, 0.1824]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5428050737828016 seconds in game passed.
Action: tensor([[[0.0034, 0.5925],
         [0.0022, 0.3310],
         [0.0019, 0.2349],
         [0.0011, 0.1824]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5678050741553307 seconds in game passed.
Action: tensor([[[0.0034, 0.5925],
         [0.0022, 0.3310],
         [0.0019, 0.2349],
         [0.0011, 0.1824]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5928050745278597 seconds in game passed.
Action: tensor([[[0.0034, 0.5925],
         [0.0022, 0.3310],
         [0.0019, 0.2349],
         [0.0011, 0.1824]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6178050749003887 seconds in game passed.
Action: tensor([[[0.0034, 0.5925],
         [0.0022, 0.3310],
         [0.0019, 0.2349],
         [0.0011, 0.1824]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6428050752729177 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.6678050756454468 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6928050760179758 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7178050763905048 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3228],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7428050767630339 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1696]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.767805077135563 seconds in game passed.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1696]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.792805077508092 seconds in game passed.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1696]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.817805077880621 seconds in game passed.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1696]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003405, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.84280507825315 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0036, 0.5933],
         [0.0016, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.867805078625679 seconds in game passed.
Action: tensor([[[0.0036, 0.5933],
         [0.0016, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.892805078998208 seconds in game passed.
Action: tensor([[[0.0036, 0.5933],
         [0.0016, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.917805079370737 seconds in game passed.
Action: tensor([[[0.0036, 0.5933],
         [0.0016, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.942805079743266 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9678050801157951 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9928050804883242 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.017805080860853 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0428050812333822 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4671e-03, 5.9047e-01],
         [1.3519e-03, 3.2230e-01],
         [1.1208e-03, 2.2210e-01],
         [5.7557e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0678050816059113 seconds in game passed.
Action: tensor([[[2.4671e-03, 5.9047e-01],
         [1.3519e-03, 3.2230e-01],
         [1.1208e-03, 2.2210e-01],
         [5.7557e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0928050819784403 seconds in game passed.
Action: tensor([[[2.4671e-03, 5.9047e-01],
         [1.3519e-03, 3.2230e-01],
         [1.1208e-03, 2.2210e-01],
         [5.7557e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1178050823509693 seconds in game passed.
Action: tensor([[[2.4671e-03, 5.9047e-01],
         [1.3519e-03, 3.2230e-01],
         [1.1208e-03, 2.2210e-01],
         [5.7557e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.1428050827234983 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.1678050830960274 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1928050834685564 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2178050838410854 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.2428050842136145 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.2678050845861435 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2928050849586725 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3178050853312016 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.3428050857037306 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.3678050860762596 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3928050864487886 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4178050868213177 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.4428050871938467 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002767, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4678050875663757 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4928050879389048 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002810, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.517805088311434 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.542805088683963 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.567805089056492 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.592805089429021 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.61780508980155 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.642805090174079 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.667805090546608 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.692805090919137 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.717805091291666 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.742805091664195 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.767805092036724 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.792805092409253 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.817805092781782 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.842805093154311 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.86780509352684 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8928050938993692 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9178050942718983 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.9428050946444273 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.9678050950169563 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9928050953894854 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0178050957620144 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.0428050961345434 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.0678050965070724 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0928050968796015 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1178050972521305 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.1428050976246595 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.1678050979971886 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1928050983697176 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2178050987422466 seconds in game passed.
Action: tensor([[[0.0017, 0.5874],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.2428050991147757 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.2678050994873047 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2928050998598337 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3178051002323627 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3428051006048918 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.367805100977421 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.39280510134995 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.417805101722479 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.442805102095008 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.467805102467537 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.492805102840066 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.517805103212595 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.542805103585124 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.567805103957653 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.592805104330182 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.617805104702711 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.64280510507524 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.667805105447769 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.692805105820298 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7178051061928272 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7428051065653563 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7678051069378853 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7928051073104143 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8178051076829433 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8428051080554724 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8678051084280014 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8928051088005304 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9178051091730595 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.9428051095455885 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.9678051099181175 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9928051102906466 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.017805110663176 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.042805111035705 seconds in game passed.
At 4.042805111035705 seconds, saving state-action tuples.
Action: tensor([[[1.4076e-03, 5.8609e-01],
         [1.1293e-03, 3.2068e-01],
         [9.9408e-04, 2.2101e-01],
         [3.4171e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001841, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.067805111408234 seconds in game passed.
Action: tensor([[[1.4076e-03, 5.8609e-01],
         [1.1293e-03, 3.2068e-01],
         [9.9408e-04, 2.2101e-01],
         [3.4171e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001916, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.092805111780763 seconds in game passed.
Action: tensor([[[1.4076e-03, 5.8609e-01],
         [1.1293e-03, 3.2068e-01],
         [9.9408e-04, 2.2101e-01],
         [3.4171e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.117805112153292 seconds in game passed.
Action: tensor([[[1.4076e-03, 5.8609e-01],
         [1.1293e-03, 3.2068e-01],
         [9.9408e-04, 2.2101e-01],
         [3.4171e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.883738821806649
4.142805112525821 seconds in game passed.
At 4.142805112525821 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.65612528475237
4.16780511289835 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
4.192805113270879 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 0.65612528475237
4.217805113643408 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
+++++++++++++: 8.843383999601484
4.242805114015937 seconds in game passed.
At 4.242805114015937 seconds, saving state-action tuples.
Action: tensor([[[0.0022, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383999601484
Current reward: 0.49259322239340864
Current mitigation activation: 0
#############################
Total reward: 1.1487185071457786
4.267805114388466 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.292805114760995 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.317805115133524 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
+++++++++++++: 7.228541501275198
4.342805115506053 seconds in game passed.
At 4.342805115506053 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228541501275198
Current reward: 0.5118171195076244
Current mitigation activation: 0
#############################
Total reward: 1.660535626653403
4.367805115878582 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535626653403
4.392805116251111 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535626653403
4.41780511662364 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535626653403
+++++++++++++: 6.2159331184388575
4.442805116996169 seconds in game passed.
At 4.442805116996169 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002734, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.2159331184388575
Current reward: 0.5264941465786098
Current mitigation activation: 0
#############################
Total reward: 2.187029773232013
4.467805117368698 seconds in game passed.
Action: tensor([[[0.0021, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029773232013
4.492805117741227 seconds in game passed.
Action: tensor([[[0.0021, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002890, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029773232013
4.517805118113756 seconds in game passed.
Action: tensor([[[0.0021, 0.5899],
         [0.0022, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029773232013
+++++++++++++: 5.508365853638963
4.542805118486285 seconds in game passed.
At 4.542805118486285 seconds, saving state-action tuples.
Action: tensor([[[-8.8461e-05,  5.8869e-01],
         [ 1.6116e-04,  3.2202e-01],
         [ 2.8261e-04,  2.2121e-01],
         [-9.1262e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508365853638963
Current reward: 0.537623498978236
Current mitigation activation: 0
#############################
Total reward: 2.724653272210249
4.567805118858814 seconds in game passed.
Action: tensor([[[-8.8461e-05,  5.8869e-01],
         [ 1.6116e-04,  3.2202e-01],
         [ 2.8261e-04,  2.2121e-01],
         [-9.1262e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653272210249
4.592805119231343 seconds in game passed.
Action: tensor([[[-8.8461e-05,  5.8869e-01],
         [ 1.6116e-04,  3.2202e-01],
         [ 2.8261e-04,  2.2121e-01],
         [-9.1262e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653272210249
4.617805119603872 seconds in game passed.
Action: tensor([[[-8.8461e-05,  5.8869e-01],
         [ 1.6116e-04,  3.2202e-01],
         [ 2.8261e-04,  2.2121e-01],
         [-9.1262e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653272210249
+++++++++++++: 4.9761342678197185
4.642805119976401 seconds in game passed.
At 4.642805119976401 seconds, saving state-action tuples.
Action: tensor([[[ 2.1805e-04,  5.8924e-01],
         [-3.8893e-04,  3.2137e-01],
         [-3.0237e-04,  2.2102e-01],
         [-4.6407e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.9761342678197185
Current reward: 0.5459292659195056
Current mitigation activation: 0
#############################
Total reward: 3.2705825381297546
4.66780512034893 seconds in game passed.
Action: tensor([[[ 2.1805e-04,  5.8924e-01],
         [-3.8893e-04,  3.2137e-01],
         [-3.0237e-04,  2.2102e-01],
         [-4.6407e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825381297546
4.692805120721459 seconds in game passed.
Action: tensor([[[ 2.1805e-04,  5.8924e-01],
         [-3.8893e-04,  3.2137e-01],
         [-3.0237e-04,  2.2102e-01],
         [-4.6407e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000560, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825381297546
4.717805121093988 seconds in game passed.
Action: tensor([[[ 2.1805e-04,  5.8924e-01],
         [-3.8893e-04,  3.2137e-01],
         [-3.0237e-04,  2.2102e-01],
         [-4.6407e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825381297546
+++++++++++++: 4.552585584603673
4.7428051214665174 seconds in game passed.
At 4.7428051214665174 seconds, saving state-action tuples.
Action: tensor([[[-3.0705e-04,  5.9096e-01],
         [-9.9485e-04,  3.2154e-01],
         [-8.7491e-04,  2.2106e-01],
         [-1.0165e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552585584603673
Current reward: 0.5519989036455549
Current mitigation activation: 0
#############################
Total reward: 3.8225814417753097
4.7678051218390465 seconds in game passed.
Action: tensor([[[-3.0705e-04,  5.9096e-01],
         [-9.9485e-04,  3.2154e-01],
         [-8.7491e-04,  2.2106e-01],
         [-1.0165e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225814417753097
4.7928051222115755 seconds in game passed.
Action: tensor([[[-3.0705e-04,  5.9096e-01],
         [-9.9485e-04,  3.2154e-01],
         [-8.7491e-04,  2.2106e-01],
         [-1.0165e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225814417753097
4.8178051225841045 seconds in game passed.
Action: tensor([[[-3.0705e-04,  5.9096e-01],
         [-9.9485e-04,  3.2154e-01],
         [-8.7491e-04,  2.2106e-01],
         [-1.0165e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225814417753097
+++++++++++++: 4.199609653749305
4.842805122956634 seconds in game passed.
At 4.842805122956634 seconds, saving state-action tuples.
Action: tensor([[[ 4.9079e-04,  5.9008e-01],
         [-5.5362e-04,  3.2160e-01],
         [-4.0992e-04,  2.2124e-01],
         [-4.2406e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199609653749305
Current reward: 0.5563326550427872
Current mitigation activation: 0
#############################
Total reward: 4.378914096818097
4.867805123329163 seconds in game passed.
Action: tensor([[[ 4.9079e-04,  5.9008e-01],
         [-5.5362e-04,  3.2160e-01],
         [-4.0992e-04,  2.2124e-01],
         [-4.2406e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914096818097
4.892805123701692 seconds in game passed.
Action: tensor([[[ 4.9079e-04,  5.9008e-01],
         [-5.5362e-04,  3.2160e-01],
         [-4.0992e-04,  2.2124e-01],
         [-4.2406e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914096818097
4.917805124074221 seconds in game passed.
Action: tensor([[[ 4.9079e-04,  5.9008e-01],
         [-5.5362e-04,  3.2160e-01],
         [-4.0992e-04,  2.2124e-01],
         [-4.2406e-04,  1.6776e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914096818097
+++++++++++++: 3.894804549009263
4.94280512444675 seconds in game passed.
At 4.94280512444675 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.894804549009263
Current reward: 0.5593056723926618
Current mitigation activation: 0
#############################
Total reward: 4.938219769210758
4.967805124819279 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938219769210758
4.992805125191808 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938219769210758
5.017805125564337 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938219769210758
+++++++++++++: 3.624634108437151
5.042805125936866 seconds in game passed.
At 5.042805125936866 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.5896],
         [0.0011, 0.3220],
         [0.0009, 0.2228],
         [0.0006, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.624634108437151
Current reward: 0.5611797225218227
Current mitigation activation: 0
#############################
Total reward: 5.499399491732581
5.067805126309395 seconds in game passed.
Action: tensor([[[0.0013, 0.5896],
         [0.0011, 0.3220],
         [0.0009, 0.2228],
         [0.0006, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399491732581
5.092805126681924 seconds in game passed.
Action: tensor([[[0.0013, 0.5896],
         [0.0011, 0.3220],
         [0.0009, 0.2228],
         [0.0006, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399491732581
5.117805127054453 seconds in game passed.
Action: tensor([[[0.0013, 0.5896],
         [0.0011, 0.3220],
         [0.0009, 0.2228],
         [0.0006, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399491732581
+++++++++++++: 3.380481635661648
5.142805127426982 seconds in game passed.
At 5.142805127426982 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380481635661648
Current reward: 0.5621374409795563
Current mitigation activation: 0
#############################
Total reward: 6.061536932712137
5.167805127799511 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061536932712137
5.19280512817204 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061536932712137
5.217805128544569 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061536932712137
+++++++++++++: 3.1566339221200774
5.242805128917098 seconds in game passed.
At 5.242805128917098 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0016, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1566339221200774
Current reward: 0.5623075245249998
Current mitigation activation: 0
#############################
Total reward: 6.623844457237137
5.267805129289627 seconds in game passed.
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0016, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623844457237137
5.292805129662156 seconds in game passed.
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0016, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623844457237137
5.317805130034685 seconds in game passed.
Action: tensor([[[0.0026, 0.5948],
         [0.0020, 0.3222],
         [0.0019, 0.2215],
         [0.0016, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623844457237137
+++++++++++++: 2.9489204640260422
5.342805130407214 seconds in game passed.
At 5.342805130407214 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9489204640260422
Current reward: 0.5617994737445824
Current mitigation activation: 0
#############################
Total reward: 7.185643930981719
5.367805130779743 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185643930981719
5.392805131152272 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185643930981719
5.417805131524801 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0029, 0.2215],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185643930981719
+++++++++++++: 2.788091853175925
5.44280513189733 seconds in game passed.
At 5.44280513189733 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.9020e-04,  5.8797e-01],
         [ 1.0263e-04,  3.2083e-01],
         [-5.3346e-05,  2.2099e-01],
         [-3.6352e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.788091853175925
Current reward: 0.5575264429481974
Current mitigation activation: 0
#############################
Total reward: 7.7431703739299165
5.467805132269859 seconds in game passed.
Action: tensor([[[ 8.9020e-04,  5.8797e-01],
         [ 1.0263e-04,  3.2083e-01],
         [-5.3346e-05,  2.2099e-01],
         [-3.6352e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.7431703739299165
5.492805132642388 seconds in game passed.
Action: tensor([[[ 8.9020e-04,  5.8797e-01],
         [ 1.0263e-04,  3.2083e-01],
         [-5.3346e-05,  2.2099e-01],
         [-3.6352e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.7431703739299165
5.517805133014917 seconds in game passed.
Action: tensor([[[ 8.9020e-04,  5.8797e-01],
         [ 1.0263e-04,  3.2083e-01],
         [-5.3346e-05,  2.2099e-01],
         [-3.6352e-04,  1.6773e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000750, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.7431703739299165
+++++++++++++: 2.691296626052753
5.542805133387446 seconds in game passed.
At 5.542805133387446 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5938],
         [-0.0021,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.691296626052753
Current reward: 0.5472045733034983
Current mitigation activation: 0
#############################
Total reward: 8.290374947233415
5.567805133759975 seconds in game passed.
Action: tensor([[[-0.0010,  0.5938],
         [-0.0021,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290374947233415
5.5928051341325045 seconds in game passed.
Action: tensor([[[-0.0010,  0.5938],
         [-0.0021,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290374947233415
5.6178051345050335 seconds in game passed.
Action: tensor([[[-0.0010,  0.5938],
         [-0.0021,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290374947233415
+++++++++++++: 2.595025257872058
5.6428051348775625 seconds in game passed.
At 5.6428051348775625 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.5916],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.595025257872058
Current reward: 0.5368279384278447
Current mitigation activation: 0
#############################
Total reward: 8.82720288566126
5.6678051352500916 seconds in game passed.
Action: tensor([[[-0.0023,  0.5916],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.82720288566126
5.692805135622621 seconds in game passed.
Action: tensor([[[-0.0023,  0.5916],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.82720288566126
5.71780513599515 seconds in game passed.
Action: tensor([[[-0.0023,  0.5916],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.82720288566126
+++++++++++++: 2.4986321861041665
5.742805136367679 seconds in game passed.
At 5.742805136367679 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4986321861041665
Current reward: 0.5264624326625167
Current mitigation activation: 0
#############################
Total reward: 9.353665318323776
5.767805136740208 seconds in game passed.
Action: tensor([[[-0.0026,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353665318323776
5.792805137112737 seconds in game passed.
Action: tensor([[[-0.0026,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353665318323776
5.817805137485266 seconds in game passed.
Action: tensor([[[-0.0026,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353665318323776
+++++++++++++: 2.4022181694350304
5.842805137857795 seconds in game passed.
At 5.842805137857795 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.7842e-04,  5.9085e-01],
         [-7.5582e-04,  3.2182e-01],
         [-7.7737e-04,  2.2151e-01],
         [-9.8816e-04,  1.6819e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4022181694350304
Current reward: 0.5160982748374141
Current mitigation activation: 0
#############################
Total reward: 9.86976359316119
5.867805138230324 seconds in game passed.
Action: tensor([[[-1.7842e-04,  5.9085e-01],
         [-7.5582e-04,  3.2182e-01],
         [-7.7737e-04,  2.2151e-01],
         [-9.8816e-04,  1.6819e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.86976359316119
5.892805138602853 seconds in game passed.
Action: tensor([[[-1.7842e-04,  5.9085e-01],
         [-7.5582e-04,  3.2182e-01],
         [-7.7737e-04,  2.2151e-01],
         [-9.8816e-04,  1.6819e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.86976359316119
5.917805138975382 seconds in game passed.
Action: tensor([[[-1.7842e-04,  5.9085e-01],
         [-7.5582e-04,  3.2182e-01],
         [-7.7737e-04,  2.2151e-01],
         [-9.8816e-04,  1.6819e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.86976359316119
+++++++++++++: 2.2737336929999277
5.942805139347911 seconds in game passed.
At 5.942805139347911 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.3839e-05,  5.9325e-01],
         [ 2.6909e-04,  3.2273e-01],
         [ 3.0109e-04,  2.2203e-01],
         [-9.5144e-05,  1.6860e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2737336929999277
Current reward: 0.5093358652128621
Current mitigation activation: 0
#############################
Total reward: 10.379099458374052
5.96780513972044 seconds in game passed.
Action: tensor([[[ 4.3839e-05,  5.9325e-01],
         [ 2.6909e-04,  3.2273e-01],
         [ 3.0109e-04,  2.2203e-01],
         [-9.5144e-05,  1.6860e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379099458374052
5.992805140092969 seconds in game passed.
Action: tensor([[[ 4.3839e-05,  5.9325e-01],
         [ 2.6909e-04,  3.2273e-01],
         [ 3.0109e-04,  2.2203e-01],
         [-9.5144e-05,  1.6860e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379099458374052
6.017805140465498 seconds in game passed.
Action: tensor([[[ 4.3839e-05,  5.9325e-01],
         [ 2.6909e-04,  3.2273e-01],
         [ 3.0109e-04,  2.2203e-01],
         [-9.5144e-05,  1.6860e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379099458374052
+++++++++++++: 2.069423160887932
6.042805140838027 seconds in game passed.
At 6.042805140838027 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.069423160887932
Current reward: 0.512237312256301
Current mitigation activation: 0
#############################
Total reward: 10.891336770630353
6.067805141210556 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.872071, steer=0.003277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891336770630353
6.092805141583085 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.819237, steer=0.003304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891336770630353
6.117805141955614 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.767579, steer=0.003332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891336770630353
+++++++++++++: 1.8865396602580815
6.142805142328143 seconds in game passed.
At 6.142805142328143 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0021, 0.6209],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.464007, steer=0.002072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865396602580815
Current reward: 0.5134810593809904
Current mitigation activation: 0
#############################
Total reward: 11.404817830011343
6.167805142700672 seconds in game passed.
Action: tensor([[[0.0021, 0.6209],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.439028, steer=0.002286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404817830011343
6.192805143073201 seconds in game passed.
Action: tensor([[[0.0021, 0.6209],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.389547, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404817830011343
6.21780514344573 seconds in game passed.
Action: tensor([[[0.0021, 0.6209],
         [0.0025, 0.3401],
         [0.0020, 0.2343],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.363202, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404817830011343
+++++++++++++: 1.7243128944699353
6.242805143818259 seconds in game passed.
At 6.242805143818259 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.3661e-04,  6.3451e-01],
         [-9.2164e-06,  3.4346e-01],
         [-7.0114e-04,  2.3562e-01],
         [-1.7997e-03,  1.7999e-01]]])
agent 0 action: VehicleControl(throttle=0.352020, steer=-0.000173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7243128944699353
Current reward: 0.512534785600512
Current mitigation activation: 0
#############################
Total reward: 11.917352615611854
6.267805144190788 seconds in game passed.
Action: tensor([[[ 5.3661e-04,  6.3451e-01],
         [-9.2164e-06,  3.4346e-01],
         [-7.0114e-04,  2.3562e-01],
         [-1.7997e-03,  1.7999e-01]]])
agent 0 action: VehicleControl(throttle=0.339410, steer=0.000210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917352615611854
6.292805144563317 seconds in game passed.
Action: tensor([[[ 5.3661e-04,  6.3451e-01],
         [-9.2164e-06,  3.4346e-01],
         [-7.0114e-04,  2.3562e-01],
         [-1.7997e-03,  1.7999e-01]]])
agent 0 action: VehicleControl(throttle=0.327218, steer=0.000186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917352615611854
6.317805144935846 seconds in game passed.
Action: tensor([[[ 5.3661e-04,  6.3451e-01],
         [-9.2164e-06,  3.4346e-01],
         [-7.0114e-04,  2.3562e-01],
         [-1.7997e-03,  1.7999e-01]]])
agent 0 action: VehicleControl(throttle=0.315439, steer=0.000162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917352615611854
+++++++++++++: 1.5890087210478339
6.342805145308375 seconds in game passed.
At 6.342805145308375 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6536],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.304433, steer=-0.000063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5890087210478339
Current reward: 0.5075272698166563
Current mitigation activation: 0
#############################
Total reward: 12.42487988542851
6.367805145680904 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6536],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.293836, steer=-0.000061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.42487988542851
6.392805146053433 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6536],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.283192, steer=-0.000092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.42487988542851
6.4178051464259624 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6536],
         [-0.0007,  0.3520],
         [-0.0018,  0.2415],
         [-0.0030,  0.1843]]])
agent 0 action: VehicleControl(throttle=0.272523, steer=-0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.42487988542851
+++++++++++++: 1.477917545580364
6.4428051467984915 seconds in game passed.
At 6.4428051467984915 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6670],
         [-0.0049,  0.3559],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.261747, steer=-0.004410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.477917545580364
Current reward: 0.49809546676504046
Current mitigation activation: 0
#############################
Total reward: 12.92297535219355
6.4678051471710205 seconds in game passed.
Action: tensor([[[-0.0015,  0.6670],
         [-0.0049,  0.3559],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.250951, steer=-0.003752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92297535219355
6.4928051475435495 seconds in game passed.
Action: tensor([[[-0.0015,  0.6670],
         [-0.0049,  0.3559],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.240138, steer=-0.003801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92297535219355
6.517805147916079 seconds in game passed.
Action: tensor([[[-0.0015,  0.6670],
         [-0.0049,  0.3559],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.229305, steer=-0.003849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92297535219355
+++++++++++++: 1.381817951916181
6.542805148288608 seconds in game passed.
At 6.542805148288608 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.2426e-04,  6.8513e-01],
         [-3.9345e-03,  3.6684e-01],
         [-5.6965e-03,  2.5098e-01],
         [-7.0168e-03,  1.9109e-01]]])
agent 0 action: VehicleControl(throttle=0.218527, steer=-0.002631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.381817951916181
Current reward: 0.48556602849806463
Current mitigation activation: 0
#############################
Total reward: 13.408541380691615
6.567805148661137 seconds in game passed.
Action: tensor([[[-2.2426e-04,  6.8513e-01],
         [-3.9345e-03,  3.6684e-01],
         [-5.6965e-03,  2.5098e-01],
         [-7.0168e-03,  1.9109e-01]]])
agent 0 action: VehicleControl(throttle=0.207731, steer=-0.002847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408541380691615
6.592805149033666 seconds in game passed.
Action: tensor([[[-2.2426e-04,  6.8513e-01],
         [-3.9345e-03,  3.6684e-01],
         [-5.6965e-03,  2.5098e-01],
         [-7.0168e-03,  1.9109e-01]]])
agent 0 action: VehicleControl(throttle=0.196916, steer=-0.002858, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408541380691615
6.617805149406195 seconds in game passed.
Action: tensor([[[-2.2426e-04,  6.8513e-01],
         [-3.9345e-03,  3.6684e-01],
         [-5.6965e-03,  2.5098e-01],
         [-7.0168e-03,  1.9109e-01]]])
agent 0 action: VehicleControl(throttle=0.186083, steer=-0.002869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408541380691615
+++++++++++++: 1.2945084256380865
6.642805149778724 seconds in game passed.
At 6.642805149778724 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.5034e-04,  1.0000e+00],
         [-4.6991e-03,  1.0000e+00],
         [-5.9096e-03,  1.0000e+00],
         [-6.4701e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003045, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2945084256380865
Current reward: 0.4710450508475084
Current mitigation activation: 1
#############################
Total reward: 13.879586431539122
6.667805150151253 seconds in game passed.
Action: tensor([[[-3.5034e-04,  1.0000e+00],
         [-4.6991e-03,  1.0000e+00],
         [-5.9096e-03,  1.0000e+00],
         [-6.4701e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003009, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879586431539122
6.692805150523782 seconds in game passed.
Action: tensor([[[-3.5034e-04,  1.0000e+00],
         [-4.6991e-03,  1.0000e+00],
         [-5.9096e-03,  1.0000e+00],
         [-6.4701e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003004, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879586431539122
6.717805150896311 seconds in game passed.
Action: tensor([[[-3.5034e-04,  1.0000e+00],
         [-4.6991e-03,  1.0000e+00],
         [-5.9096e-03,  1.0000e+00],
         [-6.4701e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002998, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.879586431539122
+++++++++++++: 1.214876624855194
6.74280515126884 seconds in game passed.
At 6.74280515126884 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000971, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.214876624855194
Current reward: 0.4546787383808243
Current mitigation activation: 1
#############################
Total reward: 14.334265169919947
6.767805151641369 seconds in game passed.
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001271, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334265169919947
6.792805152013898 seconds in game passed.
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001239, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334265169919947
6.817805152386427 seconds in game passed.
Action: tensor([[[ 0.0021,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001206, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334265169919947
+++++++++++++: 1.1621240349297284
6.842805152758956 seconds in game passed.
At 6.842805152758956 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.8099e-03,  1.0000e+00],
         [ 8.5937e-04,  1.0000e+00],
         [-1.4611e-03,  1.0000e+00],
         [-1.5579e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006140, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1621240349297284
Current reward: 0.4318757242498068
Current mitigation activation: 1
#############################
Total reward: 14.766140894169753
6.867805153131485 seconds in game passed.
Action: tensor([[[ 8.8099e-03,  1.0000e+00],
         [ 8.5937e-04,  1.0000e+00],
         [-1.4611e-03,  1.0000e+00],
         [-1.5579e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004998, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766140894169753
6.892805153504014 seconds in game passed.
Action: tensor([[[ 8.8099e-03,  1.0000e+00],
         [ 8.5937e-04,  1.0000e+00],
         [-1.4611e-03,  1.0000e+00],
         [-1.5579e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005068, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766140894169753
6.917805153876543 seconds in game passed.
Action: tensor([[[ 8.8099e-03,  1.0000e+00],
         [ 8.5937e-04,  1.0000e+00],
         [-1.4611e-03,  1.0000e+00],
         [-1.5579e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005137, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766140894169753
+++++++++++++: 1.1436183706603262
6.942805154249072 seconds in game passed.
At 6.942805154249072 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0136,  1.0000],
         [-0.0042,  1.0000],
         [-0.0062,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012257, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1436183706603262
Current reward: 0.4016899469316927
Current mitigation activation: 1
#############################
Total reward: 15.167830841101447
6.967805154621601 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0042,  1.0000],
         [-0.0062,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009497, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.167830841101447
6.99280515499413 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0042,  1.0000],
         [-0.0062,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009615, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.167830841101447
7.017805155366659 seconds in game passed.
Action: tensor([[[-0.0136,  1.0000],
         [-0.0042,  1.0000],
         [-0.0062,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009734, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.167830841101447
+++++++++++++: 1.1456535902492275
7.042805155739188 seconds in game passed.
At 7.042805155739188 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0119,  1.0000],
         [-0.0065,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010301, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1456535902492275
Current reward: 0.3689750916423826
Current mitigation activation: 1
#############################
Total reward: 15.53680593274383
7.067805156111717 seconds in game passed.
Action: tensor([[[-0.0119,  1.0000],
         [-0.0065,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010395, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53680593274383
7.092805156484246 seconds in game passed.
Action: tensor([[[-0.0119,  1.0000],
         [-0.0065,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010556, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53680593274383
7.117805156856775 seconds in game passed.
Action: tensor([[[-0.0119,  1.0000],
         [-0.0065,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010718, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53680593274383
+++++++++++++: 1.1654232915025458
7.142805157229304 seconds in game passed.
At 7.142805157229304 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0155,  1.0000],
         [-0.0114,  1.0000],
         [-0.0094,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016260, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1654232915025458
Current reward: 0.3357161920937016
Current mitigation activation: 1
#############################
Total reward: 15.872522124837532
7.167805157601833 seconds in game passed.
Action: tensor([[[-0.0155,  1.0000],
         [-0.0114,  1.0000],
         [-0.0094,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015574, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872522124837532
7.192805157974362 seconds in game passed.
Action: tensor([[[-0.0155,  1.0000],
         [-0.0114,  1.0000],
         [-0.0094,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015778, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872522124837532
7.217805158346891 seconds in game passed.
Action: tensor([[[-0.0155,  1.0000],
         [-0.0114,  1.0000],
         [-0.0094,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015982, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872522124837532
+++++++++++++: 1.2054276648219469
7.24280515871942 seconds in game passed.
At 7.24280515871942 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0200,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015777, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2054276648219469
Current reward: 0.30273344637726196
Current mitigation activation: 1
#############################
Total reward: 16.175255571214795
7.2678051590919495 seconds in game passed.
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0200,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016015, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175255571214795
7.2928051594644785 seconds in game passed.
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0200,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016189, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175255571214795
7.3178051598370075 seconds in game passed.
Action: tensor([[[-0.0111,  1.0000],
         [-0.0152,  1.0000],
         [-0.0200,  1.0000],
         [-0.0208,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016364, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.175255571214795
+++++++++++++: 1.2712124901120947
7.3428051602095366 seconds in game passed.
At 7.3428051602095366 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0105,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021815, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2712124901120947
Current reward: 0.2705102892363085
Current mitigation activation: 1
#############################
Total reward: 16.445765860451104
7.367805160582066 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0105,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015712, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.445765860451104
7.392805160954595 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0105,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015935, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.445765860451104
7.417805161327124 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0042,  1.0000],
         [-0.0105,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016158, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.445765860451104
+++++++++++++: 1.3700239933685603
7.442805161699653 seconds in game passed.
At 7.442805161699653 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.7444e-03, 9.5603e-01],
         [1.1288e-03, 9.5438e-01],
         [3.7406e-04, 9.5378e-01],
         [7.1936e-04, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003394, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3700239933685603
Current reward: 0.23965125804774406
Current mitigation activation: 0
#############################
Total reward: 16.685417118498847
7.467805162072182 seconds in game passed.
Action: tensor([[[1.7444e-03, 9.5603e-01],
         [1.1288e-03, 9.5438e-01],
         [3.7406e-04, 9.5378e-01],
         [7.1936e-04, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000062, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685417118498847
7.492805162444711 seconds in game passed.
Action: tensor([[[1.7444e-03, 9.5603e-01],
         [1.1288e-03, 9.5438e-01],
         [3.7406e-04, 9.5378e-01],
         [7.1936e-04, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000001, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685417118498847
7.51780516281724 seconds in game passed.
Action: tensor([[[1.7444e-03, 9.5603e-01],
         [1.1288e-03, 9.5438e-01],
         [3.7406e-04, 9.5378e-01],
         [7.1936e-04, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000063, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685417118498847
+++++++++++++: 1.5133010344918698
7.542805163189769 seconds in game passed.
At 7.542805163189769 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.8499e-04, 9.5593e-01],
         [1.0843e-03, 9.5429e-01],
         [9.1790e-04, 9.5371e-01],
         [1.4137e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000519, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5133010344918698
Current reward: 0.21055636013560447
Current mitigation activation: 0
#############################
Total reward: 16.895973478634453
7.567805163562298 seconds in game passed.
Action: tensor([[[7.8499e-04, 9.5593e-01],
         [1.0843e-03, 9.5429e-01],
         [9.1790e-04, 9.5371e-01],
         [1.4137e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000371, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.895973478634453
7.592805163934827 seconds in game passed.
Action: tensor([[[7.8499e-04, 9.5593e-01],
         [1.0843e-03, 9.5429e-01],
         [9.1790e-04, 9.5371e-01],
         [1.4137e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000328, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.895973478634453
7.617805164307356 seconds in game passed.
Action: tensor([[[7.8499e-04, 9.5593e-01],
         [1.0843e-03, 9.5429e-01],
         [9.1790e-04, 9.5371e-01],
         [1.4137e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000285, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.895973478634453
+++++++++++++: 1.7428112714426531
7.642805164679885 seconds in game passed.
At 7.642805164679885 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.0123e-04, 9.5609e-01],
         [1.5222e-03, 9.5457e-01],
         [1.8234e-03, 9.5407e-01],
         [1.9201e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000047, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7428112714426531
Current reward: 0.18257656080373494
Current mitigation activation: 0
#############################
Total reward: 17.078550039438188
7.667805165052414 seconds in game passed.
Action: tensor([[[8.0123e-04, 9.5609e-01],
         [1.5222e-03, 9.5457e-01],
         [1.8234e-03, 9.5407e-01],
         [1.9201e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000048, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078550039438188
7.692805165424943 seconds in game passed.
Action: tensor([[[8.0123e-04, 9.5609e-01],
         [1.5222e-03, 9.5457e-01],
         [1.8234e-03, 9.5407e-01],
         [1.9201e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000096, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078550039438188
7.717805165797472 seconds in game passed.
Action: tensor([[[8.0123e-04, 9.5609e-01],
         [1.5222e-03, 9.5457e-01],
         [1.8234e-03, 9.5407e-01],
         [1.9201e-03, 9.5379e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000145, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078550039438188
+++++++++++++: 2.163589928945766
7.742805166170001 seconds in game passed.
At 7.742805166170001 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.5912e-04, 9.5621e-01],
         [1.5218e-03, 9.5476e-01],
         [1.7890e-03, 9.5429e-01],
         [1.8679e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000146, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.163589928945766
Current reward: 0.15674616850114564
Current mitigation activation: 0
#############################
Total reward: 17.235296207939335
7.76780516654253 seconds in game passed.
Action: tensor([[[7.5912e-04, 9.5621e-01],
         [1.5218e-03, 9.5476e-01],
         [1.7890e-03, 9.5429e-01],
         [1.8679e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000177, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235296207939335
7.792805166915059 seconds in game passed.
Action: tensor([[[7.5912e-04, 9.5621e-01],
         [1.5218e-03, 9.5476e-01],
         [1.7890e-03, 9.5429e-01],
         [1.8679e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000204, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235296207939335
7.817805167287588 seconds in game passed.
Action: tensor([[[7.5912e-04, 9.5621e-01],
         [1.5218e-03, 9.5476e-01],
         [1.7890e-03, 9.5429e-01],
         [1.8679e-03, 9.5403e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000231, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.235296207939335
+++++++++++++: 2.9753046533036454
7.842805167660117 seconds in game passed.
At 7.842805167660117 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.6990e-04, 9.5619e-01],
         [1.5236e-03, 9.5474e-01],
         [1.7925e-03, 9.5426e-01],
         [1.8980e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000191, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9753046533036454
Current reward: 0.13266470916427414
Current mitigation activation: 0
#############################
Total reward: 17.36796091710361
7.867805168032646 seconds in game passed.
Action: tensor([[[7.6990e-04, 9.5619e-01],
         [1.5236e-03, 9.5474e-01],
         [1.7925e-03, 9.5426e-01],
         [1.8980e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000141, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36796091710361
7.892805168405175 seconds in game passed.
Action: tensor([[[7.6990e-04, 9.5619e-01],
         [1.5236e-03, 9.5474e-01],
         [1.7925e-03, 9.5426e-01],
         [1.8980e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000092, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36796091710361
7.917805168777704 seconds in game passed.
Action: tensor([[[7.6990e-04, 9.5619e-01],
         [1.5236e-03, 9.5474e-01],
         [1.7925e-03, 9.5426e-01],
         [1.8980e-03, 9.5400e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000044, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36796091710361
+++++++++++++: 4.798284415812953
7.942805169150233 seconds in game passed.
At 7.942805169150233 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.2411e-04, 9.5606e-01],
         [1.5111e-03, 9.5455e-01],
         [1.7931e-03, 9.5406e-01],
         [1.9175e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000264, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.798284415812953
Current reward: 0.11047377406840245
Current mitigation activation: 0
#############################
Total reward: 17.478434691172012
7.967805169522762 seconds in game passed.
Action: tensor([[[9.2411e-04, 9.5606e-01],
         [1.5111e-03, 9.5455e-01],
         [1.7931e-03, 9.5406e-01],
         [1.9175e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000382, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.478434691172012
7.992805169895291 seconds in game passed.
Action: tensor([[[9.2411e-04, 9.5606e-01],
         [1.5111e-03, 9.5455e-01],
         [1.7931e-03, 9.5406e-01],
         [1.9175e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000514, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.478434691172012
8.01780517026782 seconds in game passed.
Action: tensor([[[9.2411e-04, 9.5606e-01],
         [1.5111e-03, 9.5455e-01],
         [1.7931e-03, 9.5406e-01],
         [1.9175e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.004389, steer=0.000647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.478434691172012
+++++++++++++: 23.704429549977167
8.04280517064035 seconds in game passed.
At 8.04280517064035 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9559],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006672, steer=0.000700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0392814860880516
Current mitigation activation: 0
#############################
Total reward: 17.517716177260063
8.067805171012878 seconds in game passed.
Action: tensor([[[0.0010, 0.9559],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006676, steer=0.000849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517716177260063
8.092805171385407 seconds in game passed.
Action: tensor([[[0.0010, 0.9559],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006841, steer=0.000985, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517716177260063
8.117805171757936 seconds in game passed.
Action: tensor([[[0.0010, 0.9559],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006954, steer=0.001120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517716177260063
+++++++++++++: 2103.0852863036193
8.142805172130466 seconds in game passed.
At 8.142805172130466 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.4062e-03,  9.5574e-01],
         [ 1.7074e-03,  9.5383e-01],
         [-1.7170e-03,  9.5308e-01],
         [-3.9086e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.033027, steer=0.006862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00046441353161501004
Current mitigation activation: 0
#############################
Total reward: 17.518180590791676
8.167805172502995 seconds in game passed.
Action: tensor([[[ 9.4062e-03,  9.5574e-01],
         [ 1.7074e-03,  9.5383e-01],
         [-1.7170e-03,  9.5308e-01],
         [-3.9086e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.007561, steer=0.006195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518180590791676
8.192805172875524 seconds in game passed.
Action: tensor([[[ 9.4062e-03,  9.5574e-01],
         [ 1.7074e-03,  9.5383e-01],
         [-1.7170e-03,  9.5308e-01],
         [-3.9086e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.010778, steer=0.006443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518180590791676
8.217805173248053 seconds in game passed.
Action: tensor([[[ 9.4062e-03,  9.5574e-01],
         [ 1.7074e-03,  9.5383e-01],
         [-1.7170e-03,  9.5308e-01],
         [-3.9086e-04,  9.5254e-01]]])
agent 0 action: VehicleControl(throttle=0.011541, steer=0.006692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518180590791676
+++++++++++++: 166.01469741191235
8.242805173620582 seconds in game passed.
At 8.242805173620582 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0024,  0.9521],
         [-0.0082,  0.9504],
         [-0.0031,  0.9417]]])
agent 0 action: VehicleControl(throttle=0.067351, steer=0.017118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006176163154197567
Current mitigation activation: 0
#############################
Total reward: 17.524356753945874
8.26780517399311 seconds in game passed.
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0024,  0.9521],
         [-0.0082,  0.9504],
         [-0.0031,  0.9417]]])
agent 0 action: VehicleControl(throttle=0.062837, steer=0.015788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.524356753945874
8.29280517436564 seconds in game passed.
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0024,  0.9521],
         [-0.0082,  0.9504],
         [-0.0031,  0.9417]]])
agent 0 action: VehicleControl(throttle=0.064098, steer=0.016138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.524356753945874
8.317805174738169 seconds in game passed.
Action: tensor([[[ 0.0249,  0.9550],
         [ 0.0024,  0.9521],
         [-0.0082,  0.9504],
         [-0.0031,  0.9417]]])
agent 0 action: VehicleControl(throttle=0.065271, steer=0.016487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.524356753945874
+++++++++++++: 207.84158344396323
8.342805175110698 seconds in game passed.
At 8.342805175110698 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4715e-02,  9.5366e-01],
         [ 2.2738e-04,  9.4739e-01],
         [-1.3168e-02,  9.1372e-01],
         [-8.6902e-03,  5.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.077022, steer=0.014918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.005186956325615005
Current mitigation activation: 0
#############################
Total reward: 17.52954371027149
8.367805175483227 seconds in game passed.
Action: tensor([[[ 2.4715e-02,  9.5366e-01],
         [ 2.2738e-04,  9.4739e-01],
         [-1.3168e-02,  9.1372e-01],
         [-8.6902e-03,  5.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.077064, steer=0.015108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52954371027149
8.392805175855756 seconds in game passed.
Action: tensor([[[ 2.4715e-02,  9.5366e-01],
         [ 2.2738e-04,  9.4739e-01],
         [-1.3168e-02,  9.1372e-01],
         [-8.6902e-03,  5.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.078184, steer=0.015046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52954371027149
8.417805176228285 seconds in game passed.
Action: tensor([[[ 2.4715e-02,  9.5366e-01],
         [ 2.2738e-04,  9.4739e-01],
         [-1.3168e-02,  9.1372e-01],
         [-8.6902e-03,  5.9994e-01]]])
agent 0 action: VehicleControl(throttle=0.079255, steer=0.014985, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.52954371027149
+++++++++++++: 245.53768456749978
8.442805176600814 seconds in game passed.
At 8.442805176600814 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0091,  0.9527],
         [-0.0043,  0.9417],
         [-0.0109,  0.8743],
         [-0.0053,  0.6037]]])
agent 0 action: VehicleControl(throttle=0.054621, steer=0.002419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004620088676473364
Current mitigation activation: 0
#############################
Total reward: 17.534163798947965
8.467805176973343 seconds in game passed.
Action: tensor([[[ 0.0091,  0.9527],
         [-0.0043,  0.9417],
         [-0.0109,  0.8743],
         [-0.0053,  0.6037]]])
agent 0 action: VehicleControl(throttle=0.058058, steer=0.004527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.534163798947965
8.492805177345872 seconds in game passed.
Action: tensor([[[ 0.0091,  0.9527],
         [-0.0043,  0.9417],
         [-0.0109,  0.8743],
         [-0.0053,  0.6037]]])
agent 0 action: VehicleControl(throttle=0.058761, steer=0.004539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.534163798947965
8.517805177718401 seconds in game passed.
Action: tensor([[[ 0.0091,  0.9527],
         [-0.0043,  0.9417],
         [-0.0109,  0.8743],
         [-0.0053,  0.6037]]])
agent 0 action: VehicleControl(throttle=0.059471, steer=0.004551, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.534163798947965
+++++++++++++: 275.10704890460556
8.54280517809093 seconds in game passed.
At 8.54280517809093 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0322,  0.9513],
         [-0.0190,  0.9066],
         [-0.0126,  0.7319],
         [-0.0086,  0.5388]]])
agent 0 action: VehicleControl(throttle=0.198633, steer=-0.030271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0043425680857245375
Current mitigation activation: 0
#############################
Total reward: 17.53850636703369
8.567805178463459 seconds in game passed.
Action: tensor([[[-0.0322,  0.9513],
         [-0.0190,  0.9066],
         [-0.0126,  0.7319],
         [-0.0086,  0.5388]]])
agent 0 action: VehicleControl(throttle=0.186202, steer=-0.024865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53850636703369
8.592805178835988 seconds in game passed.
Action: tensor([[[-0.0322,  0.9513],
         [-0.0190,  0.9066],
         [-0.0126,  0.7319],
         [-0.0086,  0.5388]]])
agent 0 action: VehicleControl(throttle=0.188399, steer=-0.025206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53850636703369
8.617805179208517 seconds in game passed.
Action: tensor([[[-0.0322,  0.9513],
         [-0.0190,  0.9066],
         [-0.0126,  0.7319],
         [-0.0086,  0.5388]]])
agent 0 action: VehicleControl(throttle=0.190453, steer=-0.025547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.53850636703369
+++++++++++++: 298.3159650041102
8.642805179581046 seconds in game passed.
At 8.642805179581046 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0381,  0.9496],
         [-0.0168,  0.8183],
         [-0.0073,  0.6055],
         [-0.0047,  0.4864]]])
agent 0 action: VehicleControl(throttle=0.651270, steer=-0.027077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004216891862582353
Current mitigation activation: 0
#############################
Total reward: 17.542723258896274
8.667805179953575 seconds in game passed.
Action: tensor([[[-0.0381,  0.9496],
         [-0.0168,  0.8183],
         [-0.0073,  0.6055],
         [-0.0047,  0.4864]]])
agent 0 action: VehicleControl(throttle=0.609548, steer=-0.027237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.542723258896274
8.692805180326104 seconds in game passed.
Action: tensor([[[-0.0381,  0.9496],
         [-0.0168,  0.8183],
         [-0.0073,  0.6055],
         [-0.0047,  0.4864]]])
agent 0 action: VehicleControl(throttle=0.616319, steer=-0.027593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.542723258896274
8.717805180698633 seconds in game passed.
Action: tensor([[[-0.0381,  0.9496],
         [-0.0168,  0.8183],
         [-0.0073,  0.6055],
         [-0.0047,  0.4864]]])
agent 0 action: VehicleControl(throttle=0.622781, steer=-0.027949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.542723258896274
+++++++++++++: 288.51195092400604
8.742805181071162 seconds in game passed.
At 8.742805181071162 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0333,  0.9491],
         [-0.0102,  0.7919],
         [-0.0052,  0.5756],
         [-0.0061,  0.4708]]])
agent 0 action: VehicleControl(throttle=0.786760, steer=-0.020891, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004590764823965573
Current mitigation activation: 0
#############################
Total reward: 17.54731402372024
8.767805181443691 seconds in game passed.
Action: tensor([[[-0.0333,  0.9491],
         [-0.0102,  0.7919],
         [-0.0052,  0.5756],
         [-0.0061,  0.4708]]])
agent 0 action: VehicleControl(throttle=0.777013, steer=-0.022394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54731402372024
8.79280518181622 seconds in game passed.
Action: tensor([[[-0.0333,  0.9491],
         [-0.0102,  0.7919],
         [-0.0052,  0.5756],
         [-0.0061,  0.4708]]])
agent 0 action: VehicleControl(throttle=0.783120, steer=-0.022673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54731402372024
8.81780518218875 seconds in game passed.
Action: tensor([[[-0.0333,  0.9491],
         [-0.0102,  0.7919],
         [-0.0052,  0.5756],
         [-0.0061,  0.4708]]])
agent 0 action: VehicleControl(throttle=0.787592, steer=-0.022952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54731402372024
+++++++++++++: 191.61288213512523
8.842805182561278 seconds in game passed.
At 8.842805182561278 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.4969e-02,  9.4336e-01],
         [-4.9896e-03,  6.0597e-01],
         [-1.9714e-03,  4.7197e-01],
         [-3.9591e-04,  4.1683e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0072705728858643145
Current mitigation activation: 0
#############################
Total reward: 17.554584596606105
8.867805182933807 seconds in game passed.
Action: tensor([[[-2.4969e-02,  9.4336e-01],
         [-4.9896e-03,  6.0597e-01],
         [-1.9714e-03,  4.7197e-01],
         [-3.9591e-04,  4.1683e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014880, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.554584596606105
8.892805183306336 seconds in game passed.
Action: tensor([[[-2.4969e-02,  9.4336e-01],
         [-4.9896e-03,  6.0597e-01],
         [-1.9714e-03,  4.7197e-01],
         [-3.9591e-04,  4.1683e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.554584596606105
8.917805183678865 seconds in game passed.
Action: tensor([[[-2.4969e-02,  9.4336e-01],
         [-4.9896e-03,  6.0597e-01],
         [-1.9714e-03,  4.7197e-01],
         [-3.9591e-04,  4.1683e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.554584596606105
+++++++++++++: 43.33643152446173
8.942805184051394 seconds in game passed.
At 8.942805184051394 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1248e-02,  9.3293e-01],
         [-2.2312e-04,  5.6005e-01],
         [ 1.5960e-04,  4.3668e-01],
         [ 1.1278e-03,  3.7967e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.033716028259055175
Current mitigation activation: 0
#############################
Total reward: 17.58830062486516
8.967805184423923 seconds in game passed.
Action: tensor([[[-1.1248e-02,  9.3293e-01],
         [-2.2312e-04,  5.6005e-01],
         [ 1.5960e-04,  4.3668e-01],
         [ 1.1278e-03,  3.7967e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.58830062486516
8.992805184796453 seconds in game passed.
Action: tensor([[[-1.1248e-02,  9.3293e-01],
         [-2.2312e-04,  5.6005e-01],
         [ 1.5960e-04,  4.3668e-01],
         [ 1.1278e-03,  3.7967e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007001, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.58830062486516
9.017805185168982 seconds in game passed.
Action: tensor([[[-1.1248e-02,  9.3293e-01],
         [-2.2312e-04,  5.6005e-01],
         [ 1.5960e-04,  4.3668e-01],
         [ 1.1278e-03,  3.7967e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.58830062486516
+++++++++++++: 18.67216968564441
9.04280518554151 seconds in game passed.
At 9.04280518554151 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.8794],
         [-0.0024,  0.4958],
         [-0.0047,  0.3609],
         [-0.0051,  0.2906]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.08169580154687864
Current mitigation activation: 0
#############################
Total reward: 17.669996426412037
9.06780518591404 seconds in game passed.
Action: tensor([[[-0.0030,  0.8794],
         [-0.0024,  0.4958],
         [-0.0047,  0.3609],
         [-0.0051,  0.2906]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.669996426412037
9.092805186286569 seconds in game passed.
Action: tensor([[[-0.0030,  0.8794],
         [-0.0024,  0.4958],
         [-0.0047,  0.3609],
         [-0.0051,  0.2906]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005435, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.669996426412037
9.117805186659098 seconds in game passed.
Action: tensor([[[-0.0030,  0.8794],
         [-0.0024,  0.4958],
         [-0.0047,  0.3609],
         [-0.0051,  0.2906]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.669996426412037
+++++++++++++: 10.316091287904484
9.142805187031627 seconds in game passed.
At 9.142805187031627 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0049,  0.8392],
         [-0.0024,  0.4742],
         [-0.0056,  0.3397],
         [-0.0068,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.1535244330188134
Current mitigation activation: 0
#############################
Total reward: 17.82352085943085
9.167805187404156 seconds in game passed.
Action: tensor([[[ 0.0049,  0.8392],
         [-0.0024,  0.4742],
         [-0.0056,  0.3397],
         [-0.0068,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.82352085943085
9.192805187776685 seconds in game passed.
Action: tensor([[[ 0.0049,  0.8392],
         [-0.0024,  0.4742],
         [-0.0056,  0.3397],
         [-0.0068,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002925, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.82352085943085
9.217805188149214 seconds in game passed.
Action: tensor([[[ 0.0049,  0.8392],
         [-0.0024,  0.4742],
         [-0.0056,  0.3397],
         [-0.0068,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.82352085943085
+++++++++++++: 7.242641145812659
9.242805188521743 seconds in game passed.
At 9.242805188521743 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0054,  0.8207],
         [-0.0021,  0.4597],
         [-0.0055,  0.3242],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.242641145812659
Current reward: 0.17710393347789533
Current mitigation activation: 0
#############################
Total reward: 18.000624792908745
9.267805188894272 seconds in game passed.
Action: tensor([[[ 0.0054,  0.8207],
         [-0.0021,  0.4597],
         [-0.0055,  0.3242],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.000624792908745
9.2928051892668 seconds in game passed.
Action: tensor([[[ 0.0054,  0.8207],
         [-0.0021,  0.4597],
         [-0.0055,  0.3242],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003152, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.000624792908745
9.31780518963933 seconds in game passed.
Action: tensor([[[ 0.0054,  0.8207],
         [-0.0021,  0.4597],
         [-0.0055,  0.3242],
         [-0.0072,  0.2516]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.000624792908745
+++++++++++++: 5.880873989570323
9.342805190011859 seconds in game passed.
At 9.342805190011859 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6137e-03,  8.0653e-01],
         [-5.1312e-04,  4.4929e-01],
         [-3.5243e-03,  3.1257e-01],
         [-5.4527e-03,  2.3922e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.880873989570323
Current reward: 0.1938266349969433
Current mitigation activation: 0
#############################
Total reward: 18.194451427905687
9.367805190384388 seconds in game passed.
Action: tensor([[[ 7.6137e-03,  8.0653e-01],
         [-5.1312e-04,  4.4929e-01],
         [-3.5243e-03,  3.1257e-01],
         [-5.4527e-03,  2.3922e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001863, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.194451427905687
9.392805190756917 seconds in game passed.
Action: tensor([[[ 7.6137e-03,  8.0653e-01],
         [-5.1312e-04,  4.4929e-01],
         [-3.5243e-03,  3.1257e-01],
         [-5.4527e-03,  2.3922e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.194451427905687
9.417805191129446 seconds in game passed.
Action: tensor([[[ 7.6137e-03,  8.0653e-01],
         [-5.1312e-04,  4.4929e-01],
         [-3.5243e-03,  3.1257e-01],
         [-5.4527e-03,  2.3922e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002128, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.194451427905687
+++++++++++++: 5.042921504877402
9.442805191501975 seconds in game passed.
At 9.442805191501975 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.3454e-03,  7.7209e-01],
         [-5.4383e-04,  4.3234e-01],
         [-3.0014e-03,  3.0081e-01],
         [-4.7151e-03,  2.3071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.042921504877402
Current reward: 0.20917565991155285
Current mitigation activation: 0
#############################
Total reward: 18.403627087817238
9.467805191874504 seconds in game passed.
Action: tensor([[[ 6.3454e-03,  7.7209e-01],
         [-5.4383e-04,  4.3234e-01],
         [-3.0014e-03,  3.0081e-01],
         [-4.7151e-03,  2.3071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.403627087817238
9.492805192247033 seconds in game passed.
Action: tensor([[[ 6.3454e-03,  7.7209e-01],
         [-5.4383e-04,  4.3234e-01],
         [-3.0014e-03,  3.0081e-01],
         [-4.7151e-03,  2.3071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.403627087817238
9.517805192619562 seconds in game passed.
Action: tensor([[[ 6.3454e-03,  7.7209e-01],
         [-5.4383e-04,  4.3234e-01],
         [-3.0014e-03,  3.0081e-01],
         [-4.7151e-03,  2.3071e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.403627087817238
+++++++++++++: 4.4465586260669125
9.542805192992091 seconds in game passed.
At 9.542805192992091 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0063,  0.7566],
         [-0.0009,  0.4233],
         [-0.0030,  0.2944],
         [-0.0045,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.4465586260669125
Current reward: 0.22375010171597695
Current mitigation activation: 0
#############################
Total reward: 18.627377189533217
9.56780519336462 seconds in game passed.
Action: tensor([[[ 0.0063,  0.7566],
         [-0.0009,  0.4233],
         [-0.0030,  0.2944],
         [-0.0045,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.627377189533217
9.59280519373715 seconds in game passed.
Action: tensor([[[ 0.0063,  0.7566],
         [-0.0009,  0.4233],
         [-0.0030,  0.2944],
         [-0.0045,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.627377189533217
9.617805194109678 seconds in game passed.
Action: tensor([[[ 0.0063,  0.7566],
         [-0.0009,  0.4233],
         [-0.0030,  0.2944],
         [-0.0045,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.627377189533217
+++++++++++++: 3.987890131263552
9.642805194482207 seconds in game passed.
At 9.642805194482207 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2474e-02,  7.5979e-01],
         [ 5.0218e-04,  4.2152e-01],
         [-1.3492e-03,  2.9306e-01],
         [-2.2927e-03,  2.2534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.987890131263552
Current reward: 0.23778332103208688
Current mitigation activation: 0
#############################
Total reward: 18.865160510565303
9.667805194854736 seconds in game passed.
Action: tensor([[[ 1.2474e-02,  7.5979e-01],
         [ 5.0218e-04,  4.2152e-01],
         [-1.3492e-03,  2.9306e-01],
         [-2.2927e-03,  2.2534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.865160510565303
9.692805195227265 seconds in game passed.
Action: tensor([[[ 1.2474e-02,  7.5979e-01],
         [ 5.0218e-04,  4.2152e-01],
         [-1.3492e-03,  2.9306e-01],
         [-2.2927e-03,  2.2534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.865160510565303
9.717805195599794 seconds in game passed.
Action: tensor([[[ 1.2474e-02,  7.5979e-01],
         [ 5.0218e-04,  4.2152e-01],
         [-1.3492e-03,  2.9306e-01],
         [-2.2927e-03,  2.2534e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.865160510565303
+++++++++++++: 3.6180990084484943
9.742805195972323 seconds in game passed.
At 9.742805195972323 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5806e-02,  7.5387e-01],
         [ 1.2656e-03,  4.2158e-01],
         [-2.0183e-04,  2.9442e-01],
         [-7.0929e-04,  2.2675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6180990084484943
Current reward: 0.2513647394249825
Current mitigation activation: 0
#############################
Total reward: 19.116525249990286
9.767805196344852 seconds in game passed.
Action: tensor([[[ 1.5806e-02,  7.5387e-01],
         [ 1.2656e-03,  4.2158e-01],
         [-2.0183e-04,  2.9442e-01],
         [-7.0929e-04,  2.2675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.116525249990286
9.792805196717381 seconds in game passed.
Action: tensor([[[ 1.5806e-02,  7.5387e-01],
         [ 1.2656e-03,  4.2158e-01],
         [-2.0183e-04,  2.9442e-01],
         [-7.0929e-04,  2.2675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.116525249990286
9.81780519708991 seconds in game passed.
Action: tensor([[[ 1.5806e-02,  7.5387e-01],
         [ 1.2656e-03,  4.2158e-01],
         [-2.0183e-04,  2.9442e-01],
         [-7.0929e-04,  2.2675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.116525249990286
+++++++++++++: 3.309999945201095
9.84280519746244 seconds in game passed.
At 9.84280519746244 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0147, 0.7407],
         [0.0031, 0.4197],
         [0.0018, 0.2936],
         [0.0013, 0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.309999945201095
Current reward: 0.26453307221916755
Current mitigation activation: 0
#############################
Total reward: 19.38105832220945
9.867805197834969 seconds in game passed.
Action: tensor([[[0.0147, 0.7407],
         [0.0031, 0.4197],
         [0.0018, 0.2936],
         [0.0013, 0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.38105832220945
9.892805198207498 seconds in game passed.
Action: tensor([[[0.0147, 0.7407],
         [0.0031, 0.4197],
         [0.0018, 0.2936],
         [0.0013, 0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.38105832220945
9.917805198580027 seconds in game passed.
Action: tensor([[[0.0147, 0.7407],
         [0.0031, 0.4197],
         [0.0018, 0.2936],
         [0.0013, 0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.38105832220945
+++++++++++++: 3.161649676858974
9.942805198952556 seconds in game passed.
At 9.942805198952556 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0495e-02, 7.1169e-01],
         [1.6833e-03, 3.9878e-01],
         [8.4300e-04, 2.7854e-01],
         [4.3277e-04, 2.1563e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.161649676858974
Current reward: 0.2728176920194979
Current mitigation activation: 0
#############################
Total reward: 19.65387601422895
9.967805199325085 seconds in game passed.
Action: tensor([[[1.0495e-02, 7.1169e-01],
         [1.6833e-03, 3.9878e-01],
         [8.4300e-04, 2.7854e-01],
         [4.3277e-04, 2.1563e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.65387601422895
9.992805199697614 seconds in game passed.
Action: tensor([[[1.0495e-02, 7.1169e-01],
         [1.6833e-03, 3.9878e-01],
         [8.4300e-04, 2.7854e-01],
         [4.3277e-04, 2.1563e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.65387601422895
10.017805200070143 seconds in game passed.
Action: tensor([[[1.0495e-02, 7.1169e-01],
         [1.6833e-03, 3.9878e-01],
         [8.4300e-04, 2.7854e-01],
         [4.3277e-04, 2.1563e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.65387601422895
+++++++++++++: 3.1952953724118296
10.042805200442672 seconds in game passed.
At 10.042805200442672 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.9019e-03, 6.8229e-01],
         [1.2595e-03, 3.7950e-01],
         [7.4603e-04, 2.6566e-01],
         [3.7443e-04, 2.0744e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1952953724118296
Current reward: 0.2741009449161197
Current mitigation activation: 0
#############################
Total reward: 19.92797695914507
10.0678052008152 seconds in game passed.
Action: tensor([[[6.9019e-03, 6.8229e-01],
         [1.2595e-03, 3.7950e-01],
         [7.4603e-04, 2.6566e-01],
         [3.7443e-04, 2.0744e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.92797695914507
10.09280520118773 seconds in game passed.
Action: tensor([[[6.9019e-03, 6.8229e-01],
         [1.2595e-03, 3.7950e-01],
         [7.4603e-04, 2.6566e-01],
         [3.7443e-04, 2.0744e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.92797695914507
10.117805201560259 seconds in game passed.
Action: tensor([[[6.9019e-03, 6.8229e-01],
         [1.2595e-03, 3.7950e-01],
         [7.4603e-04, 2.6566e-01],
         [3.7443e-04, 2.0744e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.92797695914507
+++++++++++++: 3.2300165643435403
10.142805201932788 seconds in game passed.
At 10.142805201932788 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.1332e-03, 6.6093e-01],
         [1.6088e-03, 3.6545e-01],
         [1.1411e-03, 2.5469e-01],
         [4.0691e-04, 1.9867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2300165643435403
Current reward: 0.2753622741443523
Current mitigation activation: 0
#############################
Total reward: 20.203339233289423
10.167805202305317 seconds in game passed.
Action: tensor([[[4.1332e-03, 6.6093e-01],
         [1.6088e-03, 3.6545e-01],
         [1.1411e-03, 2.5469e-01],
         [4.0691e-04, 1.9867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.203339233289423
10.192805202677846 seconds in game passed.
Action: tensor([[[4.1332e-03, 6.6093e-01],
         [1.6088e-03, 3.6545e-01],
         [1.1411e-03, 2.5469e-01],
         [4.0691e-04, 1.9867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.203339233289423
10.217805203050375 seconds in game passed.
Action: tensor([[[4.1332e-03, 6.6093e-01],
         [1.6088e-03, 3.6545e-01],
         [1.1411e-03, 2.5469e-01],
         [4.0691e-04, 1.9867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004081, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.203339233289423
+++++++++++++: 3.265012433643554
10.242805203422904 seconds in game passed.
At 10.242805203422904 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.1382e-03, 6.5401e-01],
         [1.0653e-03, 3.6232e-01],
         [7.7456e-04, 2.5293e-01],
         [1.9044e-04, 1.9727e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.265012433643554
Current reward: 0.27663416247863537
Current mitigation activation: 0
#############################
Total reward: 20.47997339576806
10.267805203795433 seconds in game passed.
Action: tensor([[[3.1382e-03, 6.5401e-01],
         [1.0653e-03, 3.6232e-01],
         [7.7456e-04, 2.5293e-01],
         [1.9044e-04, 1.9727e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47997339576806
10.292805204167962 seconds in game passed.
Action: tensor([[[3.1382e-03, 6.5401e-01],
         [1.0653e-03, 3.6232e-01],
         [7.7456e-04, 2.5293e-01],
         [1.9044e-04, 1.9727e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47997339576806
10.317805204540491 seconds in game passed.
Action: tensor([[[3.1382e-03, 6.5401e-01],
         [1.0653e-03, 3.6232e-01],
         [7.7456e-04, 2.5293e-01],
         [1.9044e-04, 1.9727e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.47997339576806
+++++++++++++: 3.300543004264811
10.34280520491302 seconds in game passed.
At 10.34280520491302 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0509e-03,  6.4731e-01],
         [ 5.1235e-04,  3.6021e-01],
         [ 2.0286e-04,  2.5223e-01],
         [-3.6054e-04,  1.9675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.300543004264811
Current reward: 0.27790451605324024
Current mitigation activation: 0
#############################
Total reward: 20.7578779118213
10.36780520528555 seconds in game passed.
Action: tensor([[[ 3.0509e-03,  6.4731e-01],
         [ 5.1235e-04,  3.6021e-01],
         [ 2.0286e-04,  2.5223e-01],
         [-3.6054e-04,  1.9675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.7578779118213
10.392805205658078 seconds in game passed.
Action: tensor([[[ 3.0509e-03,  6.4731e-01],
         [ 5.1235e-04,  3.6021e-01],
         [ 2.0286e-04,  2.5223e-01],
         [-3.6054e-04,  1.9675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.7578779118213
10.417805206030607 seconds in game passed.
Action: tensor([[[ 3.0509e-03,  6.4731e-01],
         [ 5.1235e-04,  3.6021e-01],
         [ 2.0286e-04,  2.5223e-01],
         [-3.6054e-04,  1.9675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.7578779118213
+++++++++++++: 3.222790198116612
10.442805206403136 seconds in game passed.
At 10.442805206403136 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0801e-03,  6.3893e-01],
         [ 3.2055e-04,  3.5459e-01],
         [-1.9313e-04,  2.4729e-01],
         [-8.5793e-04,  1.9234e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.222790198116612
Current reward: 0.2833622131908091
Current mitigation activation: 0
#############################
Total reward: 21.04124012501211
10.467805206775665 seconds in game passed.
Action: tensor([[[ 2.0801e-03,  6.3893e-01],
         [ 3.2055e-04,  3.5459e-01],
         [-1.9313e-04,  2.4729e-01],
         [-8.5793e-04,  1.9234e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.04124012501211
10.492805207148194 seconds in game passed.
Action: tensor([[[ 2.0801e-03,  6.3893e-01],
         [ 3.2055e-04,  3.5459e-01],
         [-1.9313e-04,  2.4729e-01],
         [-8.5793e-04,  1.9234e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002576, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.04124012501211
10.517805207520723 seconds in game passed.
Action: tensor([[[ 2.0801e-03,  6.3893e-01],
         [ 3.2055e-04,  3.5459e-01],
         [-1.9313e-04,  2.4729e-01],
         [-8.5793e-04,  1.9234e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.04124012501211
+++++++++++++: 2.9506393152324293
10.542805207893252 seconds in game passed.
At 10.542805207893252 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2808e-03,  6.4368e-01],
         [ 4.8498e-04,  3.5540e-01],
         [-3.7640e-05,  2.4649e-01],
         [-7.3356e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9506393152324293
Current reward: 0.2970611960230264
Current mitigation activation: 0
#############################
Total reward: 21.338301321035136
10.567805208265781 seconds in game passed.
Action: tensor([[[ 2.2808e-03,  6.4368e-01],
         [ 4.8498e-04,  3.5540e-01],
         [-3.7640e-05,  2.4649e-01],
         [-7.3356e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.338301321035136
10.59280520863831 seconds in game passed.
Action: tensor([[[ 2.2808e-03,  6.4368e-01],
         [ 4.8498e-04,  3.5540e-01],
         [-3.7640e-05,  2.4649e-01],
         [-7.3356e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002708, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.338301321035136
10.61780520901084 seconds in game passed.
Action: tensor([[[ 2.2808e-03,  6.4368e-01],
         [ 4.8498e-04,  3.5540e-01],
         [-3.7640e-05,  2.4649e-01],
         [-7.3356e-04,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.338301321035136
+++++++++++++: 2.736326832236542
10.642805209383368 seconds in game passed.
At 10.642805209383368 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5170e-03,  6.6185e-01],
         [-1.8863e-04,  3.6234e-01],
         [-7.0708e-04,  2.5017e-01],
         [-1.3941e-03,  1.9331e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.736326832236542
Current reward: 0.3091596845541746
Current mitigation activation: 0
#############################
Total reward: 21.64746100558931
10.667805209755898 seconds in game passed.
Action: tensor([[[ 1.5170e-03,  6.6185e-01],
         [-1.8863e-04,  3.6234e-01],
         [-7.0708e-04,  2.5017e-01],
         [-1.3941e-03,  1.9331e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.64746100558931
10.692805210128427 seconds in game passed.
Action: tensor([[[ 1.5170e-03,  6.6185e-01],
         [-1.8863e-04,  3.6234e-01],
         [-7.0708e-04,  2.5017e-01],
         [-1.3941e-03,  1.9331e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.64746100558931
10.717805210500956 seconds in game passed.
Action: tensor([[[ 1.5170e-03,  6.6185e-01],
         [-1.8863e-04,  3.6234e-01],
         [-7.0708e-04,  2.5017e-01],
         [-1.3941e-03,  1.9331e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001824, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.64746100558931
+++++++++++++: 2.557984543520419
10.742805210873485 seconds in game passed.
At 10.742805210873485 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6741],
         [-0.0011,  0.3653],
         [-0.0017,  0.2503],
         [-0.0025,  0.1926]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.557984543520419
Current reward: 0.32005013060779225
Current mitigation activation: 0
#############################
Total reward: 21.967511136197103
10.767805211246014 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6741],
         [-0.0011,  0.3653],
         [-0.0017,  0.2503],
         [-0.0025,  0.1926]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.967511136197103
10.792805211618543 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6741],
         [-0.0011,  0.3653],
         [-0.0017,  0.2503],
         [-0.0025,  0.1926]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.967511136197103
10.817805211991072 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6741],
         [-0.0011,  0.3653],
         [-0.0017,  0.2503],
         [-0.0025,  0.1926]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.967511136197103
+++++++++++++: 2.401438246905659
10.8428052123636 seconds in game passed.
At 10.8428052123636 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.0750e-04,  6.7797e-01],
         [-1.7747e-03,  3.6661e-01],
         [-2.6832e-03,  2.5180e-01],
         [-3.6361e-03,  1.9413e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.401438246905659
Current reward: 0.3301360432222209
Current mitigation activation: 0
#############################
Total reward: 22.297647179419325
10.86780521273613 seconds in game passed.
Action: tensor([[[-3.0750e-04,  6.7797e-01],
         [-1.7747e-03,  3.6661e-01],
         [-2.6832e-03,  2.5180e-01],
         [-3.6361e-03,  1.9413e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.297647179419325
10.892805213108659 seconds in game passed.
Action: tensor([[[-3.0750e-04,  6.7797e-01],
         [-1.7747e-03,  3.6661e-01],
         [-2.6832e-03,  2.5180e-01],
         [-3.6361e-03,  1.9413e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.297647179419325
10.917805213481188 seconds in game passed.
Action: tensor([[[-3.0750e-04,  6.7797e-01],
         [-1.7747e-03,  3.6661e-01],
         [-2.6832e-03,  2.5180e-01],
         [-3.6361e-03,  1.9413e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.297647179419325
+++++++++++++: 2.259796428943319
10.942805213853717 seconds in game passed.
At 10.942805213853717 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.6934],
         [-0.0024,  0.3720],
         [-0.0032,  0.2556],
         [-0.0042,  0.1967]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.259796428943319
Current reward: 0.33961602850089706
Current mitigation activation: 0
#############################
Total reward: 22.63726320792022
10.967805214226246 seconds in game passed.
Action: tensor([[[-0.0016,  0.6934],
         [-0.0024,  0.3720],
         [-0.0032,  0.2556],
         [-0.0042,  0.1967]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.63726320792022
10.992805214598775 seconds in game passed.
Action: tensor([[[-0.0016,  0.6934],
         [-0.0024,  0.3720],
         [-0.0032,  0.2556],
         [-0.0042,  0.1967]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.63726320792022
11.017805214971304 seconds in game passed.
Action: tensor([[[-0.0016,  0.6934],
         [-0.0024,  0.3720],
         [-0.0032,  0.2556],
         [-0.0042,  0.1967]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.63726320792022
+++++++++++++: 2.129216668161404
11.042805215343833 seconds in game passed.
At 11.042805215343833 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.5352e-04,  6.8567e-01],
         [-3.5133e-03,  3.7326e-01],
         [-4.3793e-03,  2.5828e-01],
         [-4.9595e-03,  1.9921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.129216668161404
Current reward: 0.348594862130458
Current mitigation activation: 0
#############################
Total reward: 22.98585807005068
11.067805215716362 seconds in game passed.
Action: tensor([[[-5.5352e-04,  6.8567e-01],
         [-3.5133e-03,  3.7326e-01],
         [-4.3793e-03,  2.5828e-01],
         [-4.9595e-03,  1.9921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.98585807005068
11.092805216088891 seconds in game passed.
Action: tensor([[[-5.5352e-04,  6.8567e-01],
         [-3.5133e-03,  3.7326e-01],
         [-4.3793e-03,  2.5828e-01],
         [-4.9595e-03,  1.9921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002176, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.98585807005068
11.11780521646142 seconds in game passed.
Action: tensor([[[-5.5352e-04,  6.8567e-01],
         [-3.5133e-03,  3.7326e-01],
         [-4.3793e-03,  2.5828e-01],
         [-4.9595e-03,  1.9921e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.98585807005068
+++++++++++++: 2.0076744647171316
11.142805216833949 seconds in game passed.
At 11.142805216833949 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0031,  0.6782],
         [-0.0009,  0.3726],
         [-0.0018,  0.2579],
         [-0.0026,  0.1991]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0076744647171316
Current reward: 0.3570987440845907
Current mitigation activation: 0
#############################
Total reward: 23.34295681413527
11.167805217206478 seconds in game passed.
Action: tensor([[[ 0.0031,  0.6782],
         [-0.0009,  0.3726],
         [-0.0018,  0.2579],
         [-0.0026,  0.1991]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.34295681413527
11.192805217579007 seconds in game passed.
Action: tensor([[[ 0.0031,  0.6782],
         [-0.0009,  0.3726],
         [-0.0018,  0.2579],
         [-0.0026,  0.1991]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.34295681413527
11.217805217951536 seconds in game passed.
Action: tensor([[[ 0.0031,  0.6782],
         [-0.0009,  0.3726],
         [-0.0018,  0.2579],
         [-0.0026,  0.1991]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.34295681413527
+++++++++++++: 1.893828599243132
11.242805218324065 seconds in game passed.
At 11.242805218324065 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0020,  0.6849],
         [-0.0011,  0.3785],
         [-0.0020,  0.2633],
         [-0.0027,  0.2035]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.893828599243132
Current reward: 0.36512884997681466
Current mitigation activation: 0
#############################
Total reward: 23.708085664112087
11.267805218696594 seconds in game passed.
Action: tensor([[[ 0.0020,  0.6849],
         [-0.0011,  0.3785],
         [-0.0020,  0.2633],
         [-0.0027,  0.2035]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000024, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.708085664112087
11.292805219069123 seconds in game passed.
Action: tensor([[[ 0.0020,  0.6849],
         [-0.0011,  0.3785],
         [-0.0020,  0.2633],
         [-0.0027,  0.2035]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.708085664112087
11.317805219441652 seconds in game passed.
Action: tensor([[[ 0.0020,  0.6849],
         [-0.0011,  0.3785],
         [-0.0020,  0.2633],
         [-0.0027,  0.2035]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000067, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.708085664112087
+++++++++++++: 1.7864592200376355
11.342805219814181 seconds in game passed.
At 11.342805219814181 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6200e-03,  6.8522e-01],
         [ 1.5950e-04,  3.9207e-01],
         [-8.1521e-04,  2.7737e-01],
         [-1.4040e-03,  2.1621e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003209, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7864592200376355
Current reward: 0.37269875731988045
Current mitigation activation: 0
#############################
Total reward: 24.080784421431968
11.36780522018671 seconds in game passed.
Action: tensor([[[ 7.6200e-03,  6.8522e-01],
         [ 1.5950e-04,  3.9207e-01],
         [-8.1521e-04,  2.7737e-01],
         [-1.4040e-03,  2.1621e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.080784421431968
11.39280522055924 seconds in game passed.
Action: tensor([[[ 7.6200e-03,  6.8522e-01],
         [ 1.5950e-04,  3.9207e-01],
         [-8.1521e-04,  2.7737e-01],
         [-1.4040e-03,  2.1621e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.080784421431968
11.417805220931768 seconds in game passed.
Action: tensor([[[ 7.6200e-03,  6.8522e-01],
         [ 1.5950e-04,  3.9207e-01],
         [-8.1521e-04,  2.7737e-01],
         [-1.4040e-03,  2.1621e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.080784421431968
+++++++++++++: 1.6847639204106855
11.442805221304297 seconds in game passed.
At 11.442805221304297 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.5582e-03,  7.0923e-01],
         [-1.0075e-04,  3.9782e-01],
         [-1.0552e-03,  2.7843e-01],
         [-1.4648e-03,  2.1504e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6847639204106855
Current reward: 0.3797998359819507
Current mitigation activation: 0
#############################
Total reward: 24.46058425741392
11.467805221676826 seconds in game passed.
Action: tensor([[[ 6.5582e-03,  7.0923e-01],
         [-1.0075e-04,  3.9782e-01],
         [-1.0552e-03,  2.7843e-01],
         [-1.4648e-03,  2.1504e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.46058425741392
11.492805222049356 seconds in game passed.
Action: tensor([[[ 6.5582e-03,  7.0923e-01],
         [-1.0075e-04,  3.9782e-01],
         [-1.0552e-03,  2.7843e-01],
         [-1.4648e-03,  2.1504e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.46058425741392
11.517805222421885 seconds in game passed.
Action: tensor([[[ 6.5582e-03,  7.0923e-01],
         [-1.0075e-04,  3.9782e-01],
         [-1.0552e-03,  2.7843e-01],
         [-1.4648e-03,  2.1504e-01]]])
agent 0 action: VehicleControl(throttle=0.857399, steer=0.002234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.46058425741392
+++++++++++++: 1.5878488729151627
11.542805222794414 seconds in game passed.
At 11.542805222794414 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.0279e-03,  7.3277e-01],
         [ 3.9147e-04,  4.1134e-01],
         [-3.5064e-04,  2.8779e-01],
         [-3.8479e-04,  2.2217e-01]]])
agent 0 action: VehicleControl(throttle=0.651872, steer=0.003651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5878488729151627
Current reward: 0.3864542639278072
Current mitigation activation: 0
#############################
Total reward: 24.847038521341727
11.567805223166943 seconds in game passed.
Action: tensor([[[ 9.0279e-03,  7.3277e-01],
         [ 3.9147e-04,  4.1134e-01],
         [-3.5064e-04,  2.8779e-01],
         [-3.8479e-04,  2.2217e-01]]])
agent 0 action: VehicleControl(throttle=0.606873, steer=0.003448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.847038521341727
11.592805223539472 seconds in game passed.
Action: tensor([[[ 9.0279e-03,  7.3277e-01],
         [ 3.9147e-04,  4.1134e-01],
         [-3.5064e-04,  2.8779e-01],
         [-3.8479e-04,  2.2217e-01]]])
agent 0 action: VehicleControl(throttle=0.555238, steer=0.003477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.847038521341727
11.617805223912 seconds in game passed.
Action: tensor([[[ 9.0279e-03,  7.3277e-01],
         [ 3.9147e-04,  4.1134e-01],
         [-3.5064e-04,  2.8779e-01],
         [-3.8479e-04,  2.2217e-01]]])
agent 0 action: VehicleControl(throttle=0.532467, steer=0.003505, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.847038521341727
+++++++++++++: 1.49644607633742
11.64280522428453 seconds in game passed.
At 11.64280522428453 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1247e-02, 7.5137e-01],
         [2.0624e-03, 4.1554e-01],
         [9.1223e-04, 2.9135e-01],
         [4.4086e-04, 2.2597e-01]]])
agent 0 action: VehicleControl(throttle=0.507544, steer=0.005679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.49644607633742
Current reward: 0.392457633303927
Current mitigation activation: 0
#############################
Total reward: 25.239496154645654
11.667805224657059 seconds in game passed.
Action: tensor([[[1.1247e-02, 7.5137e-01],
         [2.0624e-03, 4.1554e-01],
         [9.1223e-04, 2.9135e-01],
         [4.4086e-04, 2.2597e-01]]])
agent 0 action: VehicleControl(throttle=0.483114, steer=0.005386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.239496154645654
11.692805225029588 seconds in game passed.
Action: tensor([[[1.1247e-02, 7.5137e-01],
         [2.0624e-03, 4.1554e-01],
         [9.1223e-04, 2.9135e-01],
         [4.4086e-04, 2.2597e-01]]])
agent 0 action: VehicleControl(throttle=0.459171, steer=0.005445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.239496154645654
11.717805225402117 seconds in game passed.
Action: tensor([[[1.1247e-02, 7.5137e-01],
         [2.0624e-03, 4.1554e-01],
         [9.1223e-04, 2.9135e-01],
         [4.4086e-04, 2.2597e-01]]])
agent 0 action: VehicleControl(throttle=0.435709, steer=0.005503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.239496154645654
+++++++++++++: 1.4198292316906338
11.742805225774646 seconds in game passed.
At 11.742805225774646 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5420e-02,  7.6282e-01],
         [ 1.6640e-03,  4.2506e-01],
         [-2.5116e-05,  2.9822e-01],
         [-6.0067e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.412503, steer=0.007041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4198292316906338
Current reward: 0.3961400758162247
Current mitigation activation: 0
#############################
Total reward: 25.635636230461877
11.767805226147175 seconds in game passed.
Action: tensor([[[ 1.5420e-02,  7.6282e-01],
         [ 1.6640e-03,  4.2506e-01],
         [-2.5116e-05,  2.9822e-01],
         [-6.0067e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.389772, steer=0.006881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.635636230461877
11.792805226519704 seconds in game passed.
Action: tensor([[[ 1.5420e-02,  7.6282e-01],
         [ 1.6640e-03,  4.2506e-01],
         [-2.5116e-05,  2.9822e-01],
         [-6.0067e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.367510, steer=0.006964, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.635636230461877
11.817805226892233 seconds in game passed.
Action: tensor([[[ 1.5420e-02,  7.6282e-01],
         [ 1.6640e-03,  4.2506e-01],
         [-2.5116e-05,  2.9822e-01],
         [-6.0067e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.345717, steer=0.007047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.635636230461877
+++++++++++++: 1.3604304335739628
11.842805227264762 seconds in game passed.
At 11.842805227264762 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0098,  0.7920],
         [-0.0015,  0.4294],
         [-0.0033,  0.2989],
         [-0.0039,  0.2306]]])
agent 0 action: VehicleControl(throttle=0.324448, steer=0.002340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3604304335739628
Current reward: 0.39676265292575164
Current mitigation activation: 0
#############################
Total reward: 26.03239888338763
11.867805227637291 seconds in game passed.
Action: tensor([[[ 0.0098,  0.7920],
         [-0.0015,  0.4294],
         [-0.0033,  0.2989],
         [-0.0039,  0.2306]]])
agent 0 action: VehicleControl(throttle=0.303641, steer=0.003176, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.03239888338763
11.89280522800982 seconds in game passed.
Action: tensor([[[ 0.0098,  0.7920],
         [-0.0015,  0.4294],
         [-0.0033,  0.2989],
         [-0.0039,  0.2306]]])
agent 0 action: VehicleControl(throttle=0.283297, steer=0.003221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.03239888338763
11.917805228382349 seconds in game passed.
Action: tensor([[[ 0.0098,  0.7920],
         [-0.0015,  0.4294],
         [-0.0033,  0.2989],
         [-0.0039,  0.2306]]])
agent 0 action: VehicleControl(throttle=0.263412, steer=0.003265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.03239888338763
+++++++++++++: 1.3149421884390777
11.942805228754878 seconds in game passed.
At 11.942805228754878 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0720e-02,  8.3516e-01],
         [-3.4473e-04,  4.5002e-01],
         [-2.8282e-03,  3.1066e-01],
         [-3.8669e-03,  2.3755e-01]]])
agent 0 action: VehicleControl(throttle=0.244290, steer=0.004598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3149421884390777
Current reward: 0.39472471870662923
Current mitigation activation: 0
#############################
Total reward: 26.42712360209426
11.967805229127407 seconds in game passed.
Action: tensor([[[ 1.0720e-02,  8.3516e-01],
         [-3.4473e-04,  4.5002e-01],
         [-2.8282e-03,  3.1066e-01],
         [-3.8669e-03,  2.3755e-01]]])
agent 0 action: VehicleControl(throttle=0.225626, steer=0.004454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.42712360209426
11.992805229499936 seconds in game passed.
Action: tensor([[[ 1.0720e-02,  8.3516e-01],
         [-3.4473e-04,  4.5002e-01],
         [-2.8282e-03,  3.1066e-01],
         [-3.8669e-03,  2.3755e-01]]])
agent 0 action: VehicleControl(throttle=0.207417, steer=0.004522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.42712360209426
12.017805229872465 seconds in game passed.
Action: tensor([[[ 1.0720e-02,  8.3516e-01],
         [-3.4473e-04,  4.5002e-01],
         [-2.8282e-03,  3.1066e-01],
         [-3.8669e-03,  2.3755e-01]]])
agent 0 action: VehicleControl(throttle=0.189663, steer=0.004589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.42712360209426
+++++++++++++: 1.28088594116358
12.042805230244994 seconds in game passed.
At 12.042805230244994 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0034,  1.0000],
         [-0.0048,  1.0000],
         [-0.0089,  1.0000],
         [-0.0107,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004720, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.28088594116358
Current reward: 0.39047080238404686
Current mitigation activation: 1
#############################
Total reward: 26.817594404478307
12.067805230617523 seconds in game passed.
Action: tensor([[[-0.0034,  1.0000],
         [-0.0048,  1.0000],
         [-0.0089,  1.0000],
         [-0.0107,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003197, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.817594404478307
12.092805230990052 seconds in game passed.
Action: tensor([[[-0.0034,  1.0000],
         [-0.0048,  1.0000],
         [-0.0089,  1.0000],
         [-0.0107,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003222, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.817594404478307
12.117805231362581 seconds in game passed.
Action: tensor([[[-0.0034,  1.0000],
         [-0.0048,  1.0000],
         [-0.0089,  1.0000],
         [-0.0107,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003247, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.817594404478307
+++++++++++++: 1.25978925277773
12.14280523173511 seconds in game passed.
At 12.14280523173511 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0066,  1.0000],
         [-0.0043,  1.0000],
         [-0.0093,  1.0000],
         [-0.0108,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003399, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.25978925277773
Current reward: 0.38380141996237105
Current mitigation activation: 1
#############################
Total reward: 27.201395824440677
12.16780523210764 seconds in game passed.
Action: tensor([[[ 0.0066,  1.0000],
         [-0.0043,  1.0000],
         [-0.0093,  1.0000],
         [-0.0108,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002302, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.201395824440677
12.192805232480168 seconds in game passed.
Action: tensor([[[ 0.0066,  1.0000],
         [-0.0043,  1.0000],
         [-0.0093,  1.0000],
         [-0.0108,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002311, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.201395824440677
12.217805232852697 seconds in game passed.
Action: tensor([[[ 0.0066,  1.0000],
         [-0.0043,  1.0000],
         [-0.0093,  1.0000],
         [-0.0108,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002320, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.201395824440677
+++++++++++++: 1.2803215840052857
12.242805233225226 seconds in game passed.
At 12.242805233225226 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0042,  1.0000],
         [-0.0177,  1.0000],
         [-0.0209,  1.0000],
         [-0.0194,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007706, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2803215840052857
Current reward: 0.3697934400677408
Current mitigation activation: 1
#############################
Total reward: 27.57118926450842
12.267805233597755 seconds in game passed.
Action: tensor([[[ 0.0042,  1.0000],
         [-0.0177,  1.0000],
         [-0.0209,  1.0000],
         [-0.0194,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006139, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.57118926450842
12.292805233970284 seconds in game passed.
Action: tensor([[[ 0.0042,  1.0000],
         [-0.0177,  1.0000],
         [-0.0209,  1.0000],
         [-0.0194,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006227, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.57118926450842
12.317805234342813 seconds in game passed.
Action: tensor([[[ 0.0042,  1.0000],
         [-0.0177,  1.0000],
         [-0.0209,  1.0000],
         [-0.0194,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006316, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.57118926450842
+++++++++++++: 1.3675665344037125
12.342805234715343 seconds in game passed.
At 12.342805234715343 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0075,  0.9396],
         [-0.0141,  0.5598],
         [-0.0156,  0.3667],
         [-0.0139,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005135, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3675665344037125
Current reward: 0.34657473915285136
Current mitigation activation: 0
#############################
Total reward: 27.917764003661272
12.367805235087872 seconds in game passed.
Action: tensor([[[ 0.0075,  0.9396],
         [-0.0141,  0.5598],
         [-0.0156,  0.3667],
         [-0.0139,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005459, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.917764003661272
12.3928052354604 seconds in game passed.
Action: tensor([[[ 0.0075,  0.9396],
         [-0.0141,  0.5598],
         [-0.0156,  0.3667],
         [-0.0139,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005568, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.917764003661272
12.41780523583293 seconds in game passed.
Action: tensor([[[ 0.0075,  0.9396],
         [-0.0141,  0.5598],
         [-0.0156,  0.3667],
         [-0.0139,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005677, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.917764003661272
+++++++++++++: 1.5072594835410904
12.442805236205459 seconds in game passed.
At 12.442805236205459 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0046,  0.9443],
         [-0.0175,  0.5799],
         [-0.0189,  0.3686],
         [-0.0175,  0.2705]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009433, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5072594835410904
Current reward: 0.32089152708146473
Current mitigation activation: 0
#############################
Total reward: 28.238655530742736
12.467805236577988 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9443],
         [-0.0175,  0.5799],
         [-0.0189,  0.3686],
         [-0.0175,  0.2705]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008970, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.238655530742736
12.492805236950517 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9443],
         [-0.0175,  0.5799],
         [-0.0189,  0.3686],
         [-0.0175,  0.2705]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009110, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.238655530742736
12.517805237323046 seconds in game passed.
Action: tensor([[[ 0.0046,  0.9443],
         [-0.0175,  0.5799],
         [-0.0189,  0.3686],
         [-0.0175,  0.2705]]])
agent 0 action: VehicleControl(throttle=0.001078, steer=-0.009250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.238655530742736
+++++++++++++: 1.6964249798738504
12.542805237695575 seconds in game passed.
At 12.542805237695575 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0093,  0.9454],
         [-0.0137,  0.6011],
         [-0.0151,  0.3769],
         [-0.0125,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004253, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6964249798738504
Current reward: 0.29613187802417273
Current mitigation activation: 0
#############################
Total reward: 28.53478740876691
12.567805238068104 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9454],
         [-0.0137,  0.6011],
         [-0.0151,  0.3769],
         [-0.0125,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005204, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.53478740876691
12.592805238440633 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9454],
         [-0.0137,  0.6011],
         [-0.0151,  0.3769],
         [-0.0125,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.53478740876691
12.617805238813162 seconds in game passed.
Action: tensor([[[ 0.0093,  0.9454],
         [-0.0137,  0.6011],
         [-0.0151,  0.3769],
         [-0.0125,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.53478740876691
+++++++++++++: 1.936764066734441
12.64280523918569 seconds in game passed.
At 12.64280523918569 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0073,  0.9454],
         [-0.0097,  0.6037],
         [-0.0100,  0.3757],
         [-0.0068,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.936764066734441
Current reward: 0.2738486948393996
Current mitigation activation: 0
#############################
Total reward: 28.80863610360631
12.66780523955822 seconds in game passed.
Action: tensor([[[ 0.0073,  0.9454],
         [-0.0097,  0.6037],
         [-0.0100,  0.3757],
         [-0.0068,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.80863610360631
12.692805239930749 seconds in game passed.
Action: tensor([[[ 0.0073,  0.9454],
         [-0.0097,  0.6037],
         [-0.0100,  0.3757],
         [-0.0068,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.80863610360631
12.717805240303278 seconds in game passed.
Action: tensor([[[ 0.0073,  0.9454],
         [-0.0097,  0.6037],
         [-0.0100,  0.3757],
         [-0.0068,  0.2719]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.80863610360631
+++++++++++++: 2.1449199380848594
12.742805240675807 seconds in game passed.
At 12.742805240675807 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1314e-02, 9.4179e-01],
         [3.2163e-03, 5.6174e-01],
         [7.8049e-04, 3.6539e-01],
         [2.1880e-03, 2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.426354, steer=0.006968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1449199380848594
Current reward: 0.25990934082741574
Current mitigation activation: 0
#############################
Total reward: 29.068545444433727
12.767805241048336 seconds in game passed.
Action: tensor([[[1.1314e-02, 9.4179e-01],
         [3.2163e-03, 5.6174e-01],
         [7.8049e-04, 3.6539e-01],
         [2.1880e-03, 2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.405972, steer=0.005117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.068545444433727
12.792805241420865 seconds in game passed.
Action: tensor([[[1.1314e-02, 9.4179e-01],
         [3.2163e-03, 5.6174e-01],
         [7.8049e-04, 3.6539e-01],
         [2.1880e-03, 2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.465081, steer=0.005115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.068545444433727
12.817805241793394 seconds in game passed.
Action: tensor([[[1.1314e-02, 9.4179e-01],
         [3.2163e-03, 5.6174e-01],
         [7.8049e-04, 3.6539e-01],
         [2.1880e-03, 2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.516067, steer=0.005114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.068545444433727
+++++++++++++: 2.2654181879071373
12.842805242165923 seconds in game passed.
At 12.842805242165923 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0098, 0.9385],
         [0.0053, 0.5473],
         [0.0015, 0.3601],
         [0.0014, 0.2612]]])
agent 0 action: VehicleControl(throttle=0.732159, steer=0.005980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2654181879071373
Current reward: 0.254310920277654
Current mitigation activation: 0
#############################
Total reward: 29.32285636471138
12.867805242538452 seconds in game passed.
Action: tensor([[[0.0098, 0.9385],
         [0.0053, 0.5473],
         [0.0015, 0.3601],
         [0.0014, 0.2612]]])
agent 0 action: VehicleControl(throttle=0.755640, steer=0.005901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.32285636471138
12.892805242910981 seconds in game passed.
Action: tensor([[[0.0098, 0.9385],
         [0.0053, 0.5473],
         [0.0015, 0.3601],
         [0.0014, 0.2612]]])
agent 0 action: VehicleControl(throttle=0.790694, steer=0.005957, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.32285636471138
12.91780524328351 seconds in game passed.
Action: tensor([[[0.0098, 0.9385],
         [0.0053, 0.5473],
         [0.0015, 0.3601],
         [0.0014, 0.2612]]])
agent 0 action: VehicleControl(throttle=0.818293, steer=0.006014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.32285636471138
+++++++++++++: 2.45597152150403
12.94280524365604 seconds in game passed.
At 12.94280524365604 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0073, 0.9333],
         [0.0048, 0.5250],
         [0.0014, 0.3473],
         [0.0012, 0.2536]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.45597152150403
Current reward: 0.24627273375331327
Current mitigation activation: 0
#############################
Total reward: 29.569129098464693
12.967805244028568 seconds in game passed.
Action: tensor([[[0.0073, 0.9333],
         [0.0048, 0.5250],
         [0.0014, 0.3473],
         [0.0012, 0.2536]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.569129098464693
12.992805244401097 seconds in game passed.
Action: tensor([[[0.0073, 0.9333],
         [0.0048, 0.5250],
         [0.0014, 0.3473],
         [0.0012, 0.2536]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.569129098464693
13.017805244773626 seconds in game passed.
Action: tensor([[[0.0073, 0.9333],
         [0.0048, 0.5250],
         [0.0014, 0.3473],
         [0.0012, 0.2536]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.569129098464693
+++++++++++++: 2.519271527577727
13.042805245146155 seconds in game passed.
At 13.042805245146155 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.9297],
         [0.0046, 0.5166],
         [0.0025, 0.3444],
         [0.0025, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.519271527577727
Current reward: 0.24590725226849816
Current mitigation activation: 0
#############################
Total reward: 29.81503635073319
13.067805245518684 seconds in game passed.
Action: tensor([[[0.0031, 0.9297],
         [0.0046, 0.5166],
         [0.0025, 0.3444],
         [0.0025, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.81503635073319
13.092805245891213 seconds in game passed.
Action: tensor([[[0.0031, 0.9297],
         [0.0046, 0.5166],
         [0.0025, 0.3444],
         [0.0025, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.81503635073319
13.117805246263742 seconds in game passed.
Action: tensor([[[0.0031, 0.9297],
         [0.0046, 0.5166],
         [0.0025, 0.3444],
         [0.0025, 0.2537]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.81503635073319
+++++++++++++: 2.461583929412415
13.142805246636271 seconds in game passed.
At 13.142805246636271 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.9816e-03, 9.2089e-01],
         [3.5552e-03, 5.0418e-01],
         [4.2573e-04, 3.3893e-01],
         [1.5393e-04, 2.5111e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.461583929412415
Current reward: 0.25154393198789343
Current mitigation activation: 0
#############################
Total reward: 30.066580282721084
13.1678052470088 seconds in game passed.
Action: tensor([[[4.9816e-03, 9.2089e-01],
         [3.5552e-03, 5.0418e-01],
         [4.2573e-04, 3.3893e-01],
         [1.5393e-04, 2.5111e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003734, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.066580282721084
13.19280524738133 seconds in game passed.
Action: tensor([[[4.9816e-03, 9.2089e-01],
         [3.5552e-03, 5.0418e-01],
         [4.2573e-04, 3.3893e-01],
         [1.5393e-04, 2.5111e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.066580282721084
13.217805247753859 seconds in game passed.
Action: tensor([[[4.9816e-03, 9.2089e-01],
         [3.5552e-03, 5.0418e-01],
         [4.2573e-04, 3.3893e-01],
         [1.5393e-04, 2.5111e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.066580282721084
+++++++++++++: 2.3471694069831353
13.242805248126388 seconds in game passed.
At 13.242805248126388 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5892e-03,  9.0889e-01],
         [-1.6027e-04,  4.9670e-01],
         [-1.9647e-03,  3.3880e-01],
         [-1.4837e-03,  2.5410e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001663, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3471694069831353
Current reward: 0.26012938322091383
Current mitigation activation: 0
#############################
Total reward: 30.326709665941998
13.267805248498917 seconds in game passed.
Action: tensor([[[-1.5892e-03,  9.0889e-01],
         [-1.6027e-04,  4.9670e-01],
         [-1.9647e-03,  3.3880e-01],
         [-1.4837e-03,  2.5410e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.326709665941998
13.292805248871446 seconds in game passed.
Action: tensor([[[-1.5892e-03,  9.0889e-01],
         [-1.6027e-04,  4.9670e-01],
         [-1.9647e-03,  3.3880e-01],
         [-1.4837e-03,  2.5410e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.326709665941998
13.317805249243975 seconds in game passed.
Action: tensor([[[-1.5892e-03,  9.0889e-01],
         [-1.6027e-04,  4.9670e-01],
         [-1.9647e-03,  3.3880e-01],
         [-1.4837e-03,  2.5410e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.326709665941998
+++++++++++++: 2.2153697624909854
13.342805249616504 seconds in game passed.
At 13.342805249616504 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0104,  0.9139],
         [-0.0027,  0.5163],
         [-0.0039,  0.3588],
         [-0.0035,  0.2742]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2153697624909854
Current reward: 0.2699203659278845
Current mitigation activation: 0
#############################
Total reward: 30.596630031869882
13.367805249989033 seconds in game passed.
Action: tensor([[[-0.0104,  0.9139],
         [-0.0027,  0.5163],
         [-0.0039,  0.3588],
         [-0.0035,  0.2742]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.596630031869882
13.392805250361562 seconds in game passed.
Action: tensor([[[-0.0104,  0.9139],
         [-0.0027,  0.5163],
         [-0.0039,  0.3588],
         [-0.0035,  0.2742]]])
agent 0 action: VehicleControl(throttle=0.888291, steer=-0.005165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.596630031869882
13.41780525073409 seconds in game passed.
Action: tensor([[[-0.0104,  0.9139],
         [-0.0027,  0.5163],
         [-0.0039,  0.3588],
         [-0.0035,  0.2742]]])
agent 0 action: VehicleControl(throttle=0.858488, steer=-0.005157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.596630031869882
+++++++++++++: 2.0831396993255042
13.44280525110662 seconds in game passed.
At 13.44280525110662 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0061,  0.9095],
         [-0.0033,  0.5280],
         [-0.0041,  0.3817],
         [-0.0028,  0.3027]]])
agent 0 action: VehicleControl(throttle=0.638450, steer=-0.003749, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0831396993255042
Current reward: 0.28006789455316405
Current mitigation activation: 0
#############################
Total reward: 30.876697926423045
13.467805251479149 seconds in game passed.
Action: tensor([[[-0.0061,  0.9095],
         [-0.0033,  0.5280],
         [-0.0041,  0.3817],
         [-0.0028,  0.3027]]])
agent 0 action: VehicleControl(throttle=0.625680, steer=-0.003914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.876697926423045
13.492805251851678 seconds in game passed.
Action: tensor([[[-0.0061,  0.9095],
         [-0.0033,  0.5280],
         [-0.0041,  0.3817],
         [-0.0028,  0.3027]]])
agent 0 action: VehicleControl(throttle=0.593323, steer=-0.003854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.876697926423045
13.517805252224207 seconds in game passed.
Action: tensor([[[-0.0061,  0.9095],
         [-0.0033,  0.5280],
         [-0.0041,  0.3817],
         [-0.0028,  0.3027]]])
agent 0 action: VehicleControl(throttle=0.563093, steer=-0.003794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.876697926423045
+++++++++++++: 1.9600049690030033
13.542805252596736 seconds in game passed.
At 13.542805252596736 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.8931],
         [-0.0028,  0.5119],
         [-0.0044,  0.3694],
         [-0.0036,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.690247, steer=-0.002234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9600049690030033
Current reward: 0.2899009351775015
Current mitigation activation: 0
#############################
Total reward: 31.166598861600548
13.567805252969265 seconds in game passed.
Action: tensor([[[-0.0034,  0.8931],
         [-0.0028,  0.5119],
         [-0.0044,  0.3694],
         [-0.0036,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.649547, steer=-0.002468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.166598861600548
13.592805253341794 seconds in game passed.
Action: tensor([[[-0.0034,  0.8931],
         [-0.0028,  0.5119],
         [-0.0044,  0.3694],
         [-0.0036,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.627322, steer=-0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.166598861600548
13.617805253714323 seconds in game passed.
Action: tensor([[[-0.0034,  0.8931],
         [-0.0028,  0.5119],
         [-0.0044,  0.3694],
         [-0.0036,  0.2917]]])
agent 0 action: VehicleControl(throttle=0.605820, steer=-0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.166598861600548
+++++++++++++: 1.8646521063251469
13.642805254086852 seconds in game passed.
At 13.642805254086852 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0113,  0.9143],
         [-0.0013,  0.5165],
         [-0.0019,  0.3622],
         [-0.0013,  0.2806]]])
agent 0 action: VehicleControl(throttle=0.618754, steer=-0.004681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8646521063251469
Current reward: 0.2976402903016909
Current mitigation activation: 0
#############################
Total reward: 31.464239151902238
13.667805254459381 seconds in game passed.
Action: tensor([[[-0.0113,  0.9143],
         [-0.0013,  0.5165],
         [-0.0019,  0.3622],
         [-0.0013,  0.2806]]])
agent 0 action: VehicleControl(throttle=0.596409, steer=-0.004330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.464239151902238
13.69280525483191 seconds in game passed.
Action: tensor([[[-0.0113,  0.9143],
         [-0.0013,  0.5165],
         [-0.0019,  0.3622],
         [-0.0013,  0.2806]]])
agent 0 action: VehicleControl(throttle=0.578806, steer=-0.004351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.464239151902238
13.71780525520444 seconds in game passed.
Action: tensor([[[-0.0113,  0.9143],
         [-0.0013,  0.5165],
         [-0.0019,  0.3622],
         [-0.0013,  0.2806]]])
agent 0 action: VehicleControl(throttle=0.562183, steer=-0.004373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.464239151902238
+++++++++++++: 1.792622581544349
13.742805255576968 seconds in game passed.
At 13.742805255576968 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.4906e-04,  9.3048e-01],
         [-2.7076e-03,  5.1982e-01],
         [-5.6130e-03,  3.5319e-01],
         [-5.2062e-03,  2.6682e-01]]])
agent 0 action: VehicleControl(throttle=0.568181, steer=-0.000605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.792622581544349
Current reward: 0.30324794358425133
Current mitigation activation: 0
#############################
Total reward: 31.767487095486487
13.767805255949497 seconds in game passed.
Action: tensor([[[ 3.4906e-04,  9.3048e-01],
         [-2.7076e-03,  5.1982e-01],
         [-5.6130e-03,  3.5319e-01],
         [-5.2062e-03,  2.6682e-01]]])
agent 0 action: VehicleControl(throttle=0.546546, steer=-0.001346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.767487095486487
13.792805256322026 seconds in game passed.
Action: tensor([[[ 3.4906e-04,  9.3048e-01],
         [-2.7076e-03,  5.1982e-01],
         [-5.6130e-03,  3.5319e-01],
         [-5.2062e-03,  2.6682e-01]]])
agent 0 action: VehicleControl(throttle=0.528258, steer=-0.001443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.767487095486487
13.817805256694555 seconds in game passed.
Action: tensor([[[ 3.4906e-04,  9.3048e-01],
         [-2.7076e-03,  5.1982e-01],
         [-5.6130e-03,  3.5319e-01],
         [-5.2062e-03,  2.6682e-01]]])
agent 0 action: VehicleControl(throttle=0.510462, steer=-0.001540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.767487095486487
+++++++++++++: 1.7365998420226956
13.842805257067084 seconds in game passed.
At 13.842805257067084 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0029,  0.9383],
         [-0.0050,  0.5303],
         [-0.0074,  0.3485],
         [-0.0059,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.377710, steer=-0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7365998420226956
Current reward: 0.3071770504354531
Current mitigation activation: 0
#############################
Total reward: 32.07466414592194
13.867805257439613 seconds in game passed.
Action: tensor([[[ 0.0029,  0.9383],
         [-0.0050,  0.5303],
         [-0.0074,  0.3485],
         [-0.0059,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.370448, steer=-0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.07466414592194
13.892805257812142 seconds in game passed.
Action: tensor([[[ 0.0029,  0.9383],
         [-0.0050,  0.5303],
         [-0.0074,  0.3485],
         [-0.0059,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.352609, steer=-0.002400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.07466414592194
13.917805258184671 seconds in game passed.
Action: tensor([[[ 0.0029,  0.9383],
         [-0.0050,  0.5303],
         [-0.0074,  0.3485],
         [-0.0059,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.337453, steer=-0.002511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.07466414592194
+++++++++++++: 1.6959577827577488
13.9428052585572 seconds in game passed.
At 13.9428052585572 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0052,  0.9422],
         [-0.0052,  0.5521],
         [-0.0070,  0.3575],
         [-0.0045,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.278838, steer=-0.001692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6959577827577488
Current reward: 0.3093681144754796
Current mitigation activation: 0
#############################
Total reward: 32.384032260397426
13.96780525892973 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9422],
         [-0.0052,  0.5521],
         [-0.0070,  0.3575],
         [-0.0045,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.271061, steer=-0.001930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.384032260397426
13.992805259302258 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9422],
         [-0.0052,  0.5521],
         [-0.0070,  0.3575],
         [-0.0045,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.258316, steer=-0.002016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.384032260397426
14.017805259674788 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9422],
         [-0.0052,  0.5521],
         [-0.0070,  0.3575],
         [-0.0045,  0.2620]]])
agent 0 action: VehicleControl(throttle=0.245679, steer=-0.002103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.384032260397426
+++++++++++++: 1.678145323195369
14.042805260047317 seconds in game passed.
At 14.042805260047317 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.4381e-03,  9.4342e-01],
         [-5.8001e-04,  5.6234e-01],
         [-2.8328e-03,  3.6420e-01],
         [-4.5712e-04,  2.6472e-01]]])
agent 0 action: VehicleControl(throttle=0.232047, steer=0.003258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.678145323195369
Current reward: 0.30899991929162757
Current mitigation activation: 0
#############################
Total reward: 32.693032179689055
14.067805260419846 seconds in game passed.
Action: tensor([[[ 9.4381e-03,  9.4342e-01],
         [-5.8001e-04,  5.6234e-01],
         [-2.8328e-03,  3.6420e-01],
         [-4.5712e-04,  2.6472e-01]]])
agent 0 action: VehicleControl(throttle=0.218639, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.693032179689055
14.092805260792375 seconds in game passed.
Action: tensor([[[ 9.4381e-03,  9.4342e-01],
         [-5.8001e-04,  5.6234e-01],
         [-2.8328e-03,  3.6420e-01],
         [-4.5712e-04,  2.6472e-01]]])
agent 0 action: VehicleControl(throttle=0.205499, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.693032179689055
14.117805261164904 seconds in game passed.
Action: tensor([[[ 9.4381e-03,  9.4342e-01],
         [-5.8001e-04,  5.6234e-01],
         [-2.8328e-03,  3.6420e-01],
         [-4.5712e-04,  2.6472e-01]]])
agent 0 action: VehicleControl(throttle=0.192662, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.693032179689055
+++++++++++++: 1.6852525874261233
14.142805261537433 seconds in game passed.
At 14.142805261537433 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0052,  0.9417],
         [-0.0034,  0.5548],
         [-0.0062,  0.3597],
         [-0.0047,  0.2625]]])
agent 0 action: VehicleControl(throttle=0.178545, steer=-0.001723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6852525874261233
Current reward: 0.30599973247361395
Current mitigation activation: 0
#############################
Total reward: 32.99903191216267
14.167805261909962 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9417],
         [-0.0034,  0.5548],
         [-0.0062,  0.3597],
         [-0.0047,  0.2625]]])
agent 0 action: VehicleControl(throttle=0.164786, steer=-0.001109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.99903191216267
14.19280526228249 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9417],
         [-0.0034,  0.5548],
         [-0.0062,  0.3597],
         [-0.0047,  0.2625]]])
agent 0 action: VehicleControl(throttle=0.151408, steer=-0.001161, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.99903191216267
14.21780526265502 seconds in game passed.
Action: tensor([[[ 0.0052,  0.9417],
         [-0.0034,  0.5548],
         [-0.0062,  0.3597],
         [-0.0047,  0.2625]]])
agent 0 action: VehicleControl(throttle=0.138427, steer=-0.001213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.99903191216267
+++++++++++++: 1.7136344566397552
14.242805263027549 seconds in game passed.
At 14.242805263027549 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.1419e-04,  9.4169e-01],
         [ 2.9042e-05,  5.5763e-01],
         [-2.4727e-03,  3.6475e-01],
         [-2.2531e-03,  2.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.125185, steer=-0.001027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7136344566397552
Current reward: 0.30107817604660403
Current mitigation activation: 0
#############################
Total reward: 33.30011008820927
14.267805263400078 seconds in game passed.
Action: tensor([[[-2.1419e-04,  9.4169e-01],
         [ 2.9042e-05,  5.5763e-01],
         [-2.4727e-03,  3.6475e-01],
         [-2.2531e-03,  2.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.112366, steer=-0.001050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.30011008820927
14.292805263772607 seconds in game passed.
Action: tensor([[[-2.1419e-04,  9.4169e-01],
         [ 2.9042e-05,  5.5763e-01],
         [-2.4727e-03,  3.6475e-01],
         [-2.2531e-03,  2.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.099980, steer=-0.001042, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.30011008820927
14.317805264145136 seconds in game passed.
Action: tensor([[[-2.1419e-04,  9.4169e-01],
         [ 2.9042e-05,  5.5763e-01],
         [-2.4727e-03,  3.6475e-01],
         [-2.2531e-03,  2.6926e-01]]])
agent 0 action: VehicleControl(throttle=0.088035, steer=-0.001035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.30011008820927
+++++++++++++: 1.762069484586654
14.342805264517665 seconds in game passed.
At 14.342805264517665 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.6309e-03,  9.4327e-01],
         [ 1.0073e-03,  5.6959e-01],
         [-1.9895e-04,  3.6719e-01],
         [ 2.2274e-04,  2.6683e-01]]])
agent 0 action: VehicleControl(throttle=0.079592, steer=-0.001330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.762069484586654
Current reward: 0.2947622135128231
Current mitigation activation: 0
#############################
Total reward: 33.5948723017221
14.367805264890194 seconds in game passed.
Action: tensor([[[-2.6309e-03,  9.4327e-01],
         [ 1.0073e-03,  5.6959e-01],
         [-1.9895e-04,  3.6719e-01],
         [ 2.2274e-04,  2.6683e-01]]])
agent 0 action: VehicleControl(throttle=0.071601, steer=-0.001208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.5948723017221
14.392805265262723 seconds in game passed.
Action: tensor([[[-2.6309e-03,  9.4327e-01],
         [ 1.0073e-03,  5.6959e-01],
         [-1.9895e-04,  3.6719e-01],
         [ 2.2274e-04,  2.6683e-01]]])
agent 0 action: VehicleControl(throttle=0.064066, steer=-0.001146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.5948723017221
14.417805265635252 seconds in game passed.
Action: tensor([[[-2.6309e-03,  9.4327e-01],
         [ 1.0073e-03,  5.6959e-01],
         [-1.9895e-04,  3.6719e-01],
         [ 2.2274e-04,  2.6683e-01]]])
agent 0 action: VehicleControl(throttle=0.056992, steer=-0.001084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.5948723017221
+++++++++++++: 1.8312582502592036
14.442805266007781 seconds in game passed.
At 14.442805266007781 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.5824e-03,  9.4006e-01],
         [ 2.4709e-03,  5.5953e-01],
         [ 3.4396e-04,  3.7139e-01],
         [-2.4416e-04,  2.7723e-01]]])
agent 0 action: VehicleControl(throttle=0.094808, steer=-0.000793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8312582502592036
Current reward: 0.28742575648455504
Current mitigation activation: 0
#############################
Total reward: 33.88229805820665
14.46780526638031 seconds in game passed.
Action: tensor([[[-4.5824e-03,  9.4006e-01],
         [ 2.4709e-03,  5.5953e-01],
         [ 3.4396e-04,  3.7139e-01],
         [-2.4416e-04,  2.7723e-01]]])
agent 0 action: VehicleControl(throttle=0.120433, steer=-0.000783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.88229805820665
14.492805266752839 seconds in game passed.
Action: tensor([[[-4.5824e-03,  9.4006e-01],
         [ 2.4709e-03,  5.5953e-01],
         [ 3.4396e-04,  3.7139e-01],
         [-2.4416e-04,  2.7723e-01]]])
agent 0 action: VehicleControl(throttle=0.148282, steer=-0.000732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.88229805820665
14.517805267125368 seconds in game passed.
Action: tensor([[[-4.5824e-03,  9.4006e-01],
         [ 2.4709e-03,  5.5953e-01],
         [ 3.4396e-04,  3.7139e-01],
         [-2.4416e-04,  2.7723e-01]]])
agent 0 action: VehicleControl(throttle=0.176821, steer=-0.000681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.88229805820665
+++++++++++++: 1.9217871523762584
14.542805267497897 seconds in game passed.
At 14.542805267497897 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0094,  0.9425],
         [-0.0021,  0.5640],
         [-0.0028,  0.3606],
         [-0.0026,  0.2629]]])
agent 0 action: VehicleControl(throttle=0.158900, steer=-0.006289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9217871523762584
Current reward: 0.27946618125746764
Current mitigation activation: 0
#############################
Total reward: 34.16176423946412
14.567805267870426 seconds in game passed.
Action: tensor([[[-0.0094,  0.9425],
         [-0.0021,  0.5640],
         [-0.0028,  0.3606],
         [-0.0026,  0.2629]]])
agent 0 action: VehicleControl(throttle=0.190295, steer=-0.005382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.16176423946412
14.592805268242955 seconds in game passed.
Action: tensor([[[-0.0094,  0.9425],
         [-0.0021,  0.5640],
         [-0.0028,  0.3606],
         [-0.0026,  0.2629]]])
agent 0 action: VehicleControl(throttle=0.216847, steer=-0.005405, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.16176423946412
14.617805268615484 seconds in game passed.
Action: tensor([[[-0.0094,  0.9425],
         [-0.0021,  0.5640],
         [-0.0028,  0.3606],
         [-0.0026,  0.2629]]])
agent 0 action: VehicleControl(throttle=0.243296, steer=-0.005428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.16176423946412
+++++++++++++: 2.0257286471378158
14.642805268988013 seconds in game passed.
At 14.642805268988013 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0181,  0.9441],
         [-0.0038,  0.5723],
         [-0.0028,  0.3621],
         [-0.0018,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.174861, steer=-0.010678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0257286471378158
Current reward: 0.27186175671634427
Current mitigation activation: 0
#############################
Total reward: 34.43362599618047
14.667805269360542 seconds in game passed.
Action: tensor([[[-0.0181,  0.9441],
         [-0.0038,  0.5723],
         [-0.0028,  0.3621],
         [-0.0018,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.208765, steer=-0.009866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.43362599618047
14.692805269733071 seconds in game passed.
Action: tensor([[[-0.0181,  0.9441],
         [-0.0038,  0.5723],
         [-0.0028,  0.3621],
         [-0.0018,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.232397, steer=-0.009920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.43362599618047
14.7178052701056 seconds in game passed.
Action: tensor([[[-0.0181,  0.9441],
         [-0.0038,  0.5723],
         [-0.0028,  0.3621],
         [-0.0018,  0.2600]]])
agent 0 action: VehicleControl(throttle=0.256018, steer=-0.009975, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.43362599618047
+++++++++++++: 2.132314364599761
14.74280527047813 seconds in game passed.
At 14.74280527047813 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0167,  0.9475],
         [-0.0054,  0.6056],
         [-0.0036,  0.3720],
         [-0.0020,  0.2664]]])
agent 0 action: VehicleControl(throttle=0.005065, steer=-0.010776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.132314364599761
Current reward: 0.26542981783419256
Current mitigation activation: 0
#############################
Total reward: 34.69905581401466
14.767805270850658 seconds in game passed.
Action: tensor([[[-0.0167,  0.9475],
         [-0.0054,  0.6056],
         [-0.0036,  0.3720],
         [-0.0020,  0.2664]]])
agent 0 action: VehicleControl(throttle=0.028696, steer=-0.010761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.69905581401466
14.792805271223187 seconds in game passed.
Action: tensor([[[-0.0167,  0.9475],
         [-0.0054,  0.6056],
         [-0.0036,  0.3720],
         [-0.0020,  0.2664]]])
agent 0 action: VehicleControl(throttle=0.026243, steer=-0.010863, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.69905581401466
14.817805271595716 seconds in game passed.
Action: tensor([[[-0.0167,  0.9475],
         [-0.0054,  0.6056],
         [-0.0036,  0.3720],
         [-0.0020,  0.2664]]])
agent 0 action: VehicleControl(throttle=0.023966, steer=-0.010965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.69905581401466
+++++++++++++: 2.2410935267003866
14.842805271968246 seconds in game passed.
At 14.842805271968246 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5012e-02,  9.4630e-01],
         [-1.7242e-03,  5.8454e-01],
         [-4.4389e-04,  3.6674e-01],
         [ 8.0039e-04,  2.6372e-01]]])
agent 0 action: VehicleControl(throttle=0.266225, steer=-0.007447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2410935267003866
Current reward: 0.26003436073734665
Current mitigation activation: 0
#############################
Total reward: 34.959090174752006
14.867805272340775 seconds in game passed.
Action: tensor([[[-1.5012e-02,  9.4630e-01],
         [-1.7242e-03,  5.8454e-01],
         [-4.4389e-04,  3.6674e-01],
         [ 8.0039e-04,  2.6372e-01]]])
agent 0 action: VehicleControl(throttle=0.271199, steer=-0.008101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.959090174752006
14.892805272713304 seconds in game passed.
Action: tensor([[[-1.5012e-02,  9.4630e-01],
         [-1.7242e-03,  5.8454e-01],
         [-4.4389e-04,  3.6674e-01],
         [ 8.0039e-04,  2.6372e-01]]])
agent 0 action: VehicleControl(throttle=0.299770, steer=-0.008159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.959090174752006
14.917805273085833 seconds in game passed.
Action: tensor([[[-1.5012e-02,  9.4630e-01],
         [-1.7242e-03,  5.8454e-01],
         [-4.4389e-04,  3.6674e-01],
         [ 8.0039e-04,  2.6372e-01]]])
agent 0 action: VehicleControl(throttle=0.327281, steer=-0.008217, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.959090174752006
+++++++++++++: 2.3725140397398654
14.942805273458362 seconds in game passed.
At 14.942805273458362 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.8979e-03,  9.3939e-01],
         [ 1.4590e-03,  5.3180e-01],
         [ 3.6112e-04,  3.4604e-01],
         [ 7.9965e-04,  2.5201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3725140397398654
Current reward: 0.2544244377916841
Current mitigation activation: 0
#############################
Total reward: 35.21351461254369
14.96780527383089 seconds in game passed.
Action: tensor([[[-5.8979e-03,  9.3939e-01],
         [ 1.4590e-03,  5.3180e-01],
         [ 3.6112e-04,  3.4604e-01],
         [ 7.9965e-04,  2.5201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.21351461254369
14.99280527420342 seconds in game passed.
Action: tensor([[[-5.8979e-03,  9.3939e-01],
         [ 1.4590e-03,  5.3180e-01],
         [ 3.6112e-04,  3.4604e-01],
         [ 7.9965e-04,  2.5201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.21351461254369
15.017805274575949 seconds in game passed.
Action: tensor([[[-5.8979e-03,  9.3939e-01],
         [ 1.4590e-03,  5.3180e-01],
         [ 3.6112e-04,  3.4604e-01],
         [ 7.9965e-04,  2.5201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.21351461254369
+++++++++++++: 2.4989330100825318
15.042805274948478 seconds in game passed.
At 15.042805274948478 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.9232],
         [0.0032, 0.4951],
         [0.0011, 0.3259],
         [0.0012, 0.2369]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4989330100825318
Current reward: 0.250202182508364
Current mitigation activation: 0
#############################
Total reward: 35.46371679505206
15.067805275321007 seconds in game passed.
Action: tensor([[[0.0035, 0.9232],
         [0.0032, 0.4951],
         [0.0011, 0.3259],
         [0.0012, 0.2369]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.46371679505206
15.092805275693536 seconds in game passed.
Action: tensor([[[0.0035, 0.9232],
         [0.0032, 0.4951],
         [0.0011, 0.3259],
         [0.0012, 0.2369]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001753, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.46371679505206
15.117805276066065 seconds in game passed.
Action: tensor([[[0.0035, 0.9232],
         [0.0032, 0.4951],
         [0.0011, 0.3259],
         [0.0012, 0.2369]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.46371679505206
+++++++++++++: 2.5408228178437122
15.142805276438594 seconds in game passed.
At 15.142805276438594 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.7358e-03, 9.0408e-01],
         [2.8822e-03, 4.7979e-01],
         [3.4006e-04, 3.2159e-01],
         [5.5760e-05, 2.3640e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000835, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5408228178437122
Current reward: 0.2507834741694213
Current mitigation activation: 0
#############################
Total reward: 35.71450026922148
15.167805276811123 seconds in game passed.
Action: tensor([[[1.7358e-03, 9.0408e-01],
         [2.8822e-03, 4.7979e-01],
         [3.4006e-04, 3.2159e-01],
         [5.5760e-05, 2.3640e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.71450026922148
15.192805277183652 seconds in game passed.
Action: tensor([[[1.7358e-03, 9.0408e-01],
         [2.8822e-03, 4.7979e-01],
         [3.4006e-04, 3.2159e-01],
         [5.5760e-05, 2.3640e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.71450026922148
15.217805277556181 seconds in game passed.
Action: tensor([[[1.7358e-03, 9.0408e-01],
         [2.8822e-03, 4.7979e-01],
         [3.4006e-04, 3.2159e-01],
         [5.5760e-05, 2.3640e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.71450026922148
+++++++++++++: 2.4731661574462067
15.24280527792871 seconds in game passed.
At 15.24280527792871 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.6092e-03,  9.0628e-01],
         [ 2.1273e-03,  4.7938e-01],
         [-8.3852e-04,  3.1802e-01],
         [-7.8528e-04,  2.3148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4731661574462067
Current reward: 0.2567848725268525
Current mitigation activation: 0
#############################
Total reward: 35.97128514174833
15.267805278301239 seconds in game passed.
Action: tensor([[[ 8.6092e-03,  9.0628e-01],
         [ 2.1273e-03,  4.7938e-01],
         [-8.3852e-04,  3.1802e-01],
         [-7.8528e-04,  2.3148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.97128514174833
15.292805278673768 seconds in game passed.
Action: tensor([[[ 8.6092e-03,  9.0628e-01],
         [ 2.1273e-03,  4.7938e-01],
         [-8.3852e-04,  3.1802e-01],
         [-7.8528e-04,  2.3148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.97128514174833
15.317805279046297 seconds in game passed.
Action: tensor([[[ 8.6092e-03,  9.0628e-01],
         [ 2.1273e-03,  4.7938e-01],
         [-8.3852e-04,  3.1802e-01],
         [-7.8528e-04,  2.3148e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.97128514174833
+++++++++++++: 2.4004998559401938
15.342805279418826 seconds in game passed.
At 15.342805279418826 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.5015e-02, 8.9349e-01],
         [3.6423e-03, 4.7946e-01],
         [7.9903e-04, 3.2024e-01],
         [7.1441e-04, 2.3313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4004998559401938
Current reward: 0.26294941891503226
Current mitigation activation: 0
#############################
Total reward: 36.23423456066337
15.367805279791355 seconds in game passed.
Action: tensor([[[1.5015e-02, 8.9349e-01],
         [3.6423e-03, 4.7946e-01],
         [7.9903e-04, 3.2024e-01],
         [7.1441e-04, 2.3313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.23423456066337
15.392805280163884 seconds in game passed.
Action: tensor([[[1.5015e-02, 8.9349e-01],
         [3.6423e-03, 4.7946e-01],
         [7.9903e-04, 3.2024e-01],
         [7.1441e-04, 2.3313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.23423456066337
15.417805280536413 seconds in game passed.
Action: tensor([[[1.5015e-02, 8.9349e-01],
         [3.6423e-03, 4.7946e-01],
         [7.9903e-04, 3.2024e-01],
         [7.1441e-04, 2.3313e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.23423456066337
+++++++++++++: 2.4192700890048577
15.442805280908942 seconds in game passed.
At 15.442805280908942 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0129, 0.9004],
         [0.0038, 0.4844],
         [0.0019, 0.3239],
         [0.0021, 0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4192700890048577
Current reward: 0.26390138738135116
Current mitigation activation: 0
#############################
Total reward: 36.49813594804472
15.467805281281471 seconds in game passed.
Action: tensor([[[0.0129, 0.9004],
         [0.0038, 0.4844],
         [0.0019, 0.3239],
         [0.0021, 0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.49813594804472
15.492805281654 seconds in game passed.
Action: tensor([[[0.0129, 0.9004],
         [0.0038, 0.4844],
         [0.0019, 0.3239],
         [0.0021, 0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.49813594804472
15.51780528202653 seconds in game passed.
Action: tensor([[[0.0129, 0.9004],
         [0.0038, 0.4844],
         [0.0019, 0.3239],
         [0.0021, 0.2357]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.49813594804472
+++++++++++++: 2.4415595248916557
15.542805282399058 seconds in game passed.
At 15.542805282399058 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0133, 0.8858],
         [0.0029, 0.4731],
         [0.0015, 0.3178],
         [0.0020, 0.2333]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4415595248916557
Current reward: 0.2646649602831792
Current mitigation activation: 0
#############################
Total reward: 36.7628009083279
15.567805282771587 seconds in game passed.
Action: tensor([[[0.0133, 0.8858],
         [0.0029, 0.4731],
         [0.0015, 0.3178],
         [0.0020, 0.2333]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.7628009083279
15.592805283144116 seconds in game passed.
Action: tensor([[[0.0133, 0.8858],
         [0.0029, 0.4731],
         [0.0015, 0.3178],
         [0.0020, 0.2333]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.7628009083279
15.617805283516645 seconds in game passed.
Action: tensor([[[0.0133, 0.8858],
         [0.0029, 0.4731],
         [0.0015, 0.3178],
         [0.0020, 0.2333]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.7628009083279
+++++++++++++: 2.4639445914171776
15.642805283889174 seconds in game passed.
At 15.642805283889174 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0095, 0.8834],
         [0.0032, 0.4653],
         [0.0023, 0.3120],
         [0.0029, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4639445914171776
Current reward: 0.2654403854194977
Current mitigation activation: 0
#############################
Total reward: 37.02824129374739
15.667805284261703 seconds in game passed.
Action: tensor([[[0.0095, 0.8834],
         [0.0032, 0.4653],
         [0.0023, 0.3120],
         [0.0029, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.02824129374739
15.692805284634233 seconds in game passed.
Action: tensor([[[0.0095, 0.8834],
         [0.0032, 0.4653],
         [0.0023, 0.3120],
         [0.0029, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005976, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.02824129374739
15.717805285006762 seconds in game passed.
Action: tensor([[[0.0095, 0.8834],
         [0.0032, 0.4653],
         [0.0023, 0.3120],
         [0.0029, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006156, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.02824129374739
+++++++++++++: 2.486507676914645
15.74280528537929 seconds in game passed.
At 15.74280528537929 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.0090e-03,  8.8050e-01],
         [ 3.1339e-04,  4.6383e-01],
         [-1.1781e-03,  3.1236e-01],
         [-8.9835e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.486507676914645
Current reward: 0.26622347281508485
Current mitigation activation: 0
#############################
Total reward: 37.29446476656248
15.76780528575182 seconds in game passed.
Action: tensor([[[ 6.0090e-03,  8.8050e-01],
         [ 3.1339e-04,  4.6383e-01],
         [-1.1781e-03,  3.1236e-01],
         [-8.9835e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.29446476656248
15.792805286124349 seconds in game passed.
Action: tensor([[[ 6.0090e-03,  8.8050e-01],
         [ 3.1339e-04,  4.6383e-01],
         [-1.1781e-03,  3.1236e-01],
         [-8.9835e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.29446476656248
15.817805286496878 seconds in game passed.
Action: tensor([[[ 6.0090e-03,  8.8050e-01],
         [ 3.1339e-04,  4.6383e-01],
         [-1.1781e-03,  3.1236e-01],
         [-8.9835e-04,  2.3060e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003711, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.29446476656248
+++++++++++++: 2.460383162893741
15.842805286869407 seconds in game passed.
At 15.842805286869407 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0393e-03,  8.8048e-01],
         [-3.9469e-04,  4.6377e-01],
         [-1.9827e-03,  3.1146e-01],
         [-1.7277e-03,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001666, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.460383162893741
Current reward: 0.2695938417562244
Current mitigation activation: 0
#############################
Total reward: 37.5640586083187
15.867805287241936 seconds in game passed.
Action: tensor([[[ 2.0393e-03,  8.8048e-01],
         [-3.9469e-04,  4.6377e-01],
         [-1.9827e-03,  3.1146e-01],
         [-1.7277e-03,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002111, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.5640586083187
15.892805287614465 seconds in game passed.
Action: tensor([[[ 2.0393e-03,  8.8048e-01],
         [-3.9469e-04,  4.6377e-01],
         [-1.9827e-03,  3.1146e-01],
         [-1.7277e-03,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002201, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.5640586083187
15.917805287986994 seconds in game passed.
Action: tensor([[[ 2.0393e-03,  8.8048e-01],
         [-3.9469e-04,  4.6377e-01],
         [-1.9827e-03,  3.1146e-01],
         [-1.7277e-03,  2.2973e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.5640586083187
+++++++++++++: 2.289581302339536
15.942805288359523 seconds in game passed.
At 15.942805288359523 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0046,  0.8810],
         [-0.0009,  0.4646],
         [-0.0032,  0.3118],
         [-0.0036,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.289581302339536
Current reward: 0.28131494362193793
Current mitigation activation: 0
#############################
Total reward: 37.84537355194064
15.967805288732052 seconds in game passed.
Action: tensor([[[ 0.0046,  0.8810],
         [-0.0009,  0.4646],
         [-0.0032,  0.3118],
         [-0.0036,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.84537355194064
15.99280528910458 seconds in game passed.
Action: tensor([[[ 0.0046,  0.8810],
         [-0.0009,  0.4646],
         [-0.0032,  0.3118],
         [-0.0036,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.84537355194064
16.01780528947711 seconds in game passed.
Action: tensor([[[ 0.0046,  0.8810],
         [-0.0009,  0.4646],
         [-0.0032,  0.3118],
         [-0.0036,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.84537355194064
+++++++++++++: 2.137830111197582
16.04280528984964 seconds in game passed.
At 16.04280528984964 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6790e-05,  8.7567e-01],
         [-1.8513e-03,  4.5371e-01],
         [-4.2091e-03,  3.0233e-01],
         [-4.5931e-03,  2.2268e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.137830111197582
Current reward: 0.29244544828759733
Current mitigation activation: 0
#############################
Total reward: 38.137819000228234
16.067805290222168 seconds in game passed.
Action: tensor([[[ 7.6790e-05,  8.7567e-01],
         [-1.8513e-03,  4.5371e-01],
         [-4.2091e-03,  3.0233e-01],
         [-4.5931e-03,  2.2268e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.137819000228234
16.092805290594697 seconds in game passed.
Action: tensor([[[ 7.6790e-05,  8.7567e-01],
         [-1.8513e-03,  4.5371e-01],
         [-4.2091e-03,  3.0233e-01],
         [-4.5931e-03,  2.2268e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.137819000228234
16.117805290967226 seconds in game passed.
Action: tensor([[[ 7.6790e-05,  8.7567e-01],
         [-1.8513e-03,  4.5371e-01],
         [-4.2091e-03,  3.0233e-01],
         [-4.5931e-03,  2.2268e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.137819000228234
+++++++++++++: 2.0049723385078595
16.142805291339755 seconds in game passed.
At 16.142805291339755 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0042,  0.8767],
         [-0.0027,  0.4532],
         [-0.0048,  0.3035],
         [-0.0044,  0.2240]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0049723385078595
Current reward: 0.3026813296732051
Current mitigation activation: 0
#############################
Total reward: 38.44050032990144
16.167805291712284 seconds in game passed.
Action: tensor([[[ 0.0042,  0.8767],
         [-0.0027,  0.4532],
         [-0.0048,  0.3035],
         [-0.0044,  0.2240]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.44050032990144
16.192805292084813 seconds in game passed.
Action: tensor([[[ 0.0042,  0.8767],
         [-0.0027,  0.4532],
         [-0.0048,  0.3035],
         [-0.0044,  0.2240]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.44050032990144
16.217805292457342 seconds in game passed.
Action: tensor([[[ 0.0042,  0.8767],
         [-0.0027,  0.4532],
         [-0.0048,  0.3035],
         [-0.0044,  0.2240]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.44050032990144
+++++++++++++: 1.8844876156170773
16.24280529282987 seconds in game passed.
At 16.24280529282987 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0020,  0.8834],
         [-0.0034,  0.4581],
         [-0.0058,  0.3059],
         [-0.0056,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8844876156170773
Current reward: 0.3122661345183534
Current mitigation activation: 0
#############################
Total reward: 38.75276646441979
16.2678052932024 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8834],
         [-0.0034,  0.4581],
         [-0.0058,  0.3059],
         [-0.0056,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.75276646441979
16.29280529357493 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8834],
         [-0.0034,  0.4581],
         [-0.0058,  0.3059],
         [-0.0056,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.75276646441979
16.31780529394746 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8834],
         [-0.0034,  0.4581],
         [-0.0058,  0.3059],
         [-0.0056,  0.2258]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.75276646441979
+++++++++++++: 1.7728651581162542
16.342805294319987 seconds in game passed.
At 16.342805294319987 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.8894],
         [-0.0014,  0.4599],
         [-0.0035,  0.3082],
         [-0.0036,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7728651581162542
Current reward: 0.3213300774699357
Current mitigation activation: 0
#############################
Total reward: 39.07409654188973
16.367805294692516 seconds in game passed.
Action: tensor([[[-0.0035,  0.8894],
         [-0.0014,  0.4599],
         [-0.0035,  0.3082],
         [-0.0036,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07409654188973
16.392805295065045 seconds in game passed.
Action: tensor([[[-0.0035,  0.8894],
         [-0.0014,  0.4599],
         [-0.0035,  0.3082],
         [-0.0036,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07409654188973
16.417805295437574 seconds in game passed.
Action: tensor([[[-0.0035,  0.8894],
         [-0.0014,  0.4599],
         [-0.0035,  0.3082],
         [-0.0036,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07409654188973
+++++++++++++: 1.6684367886683074
16.442805295810103 seconds in game passed.
At 16.442805295810103 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2756e-03,  9.1374e-01],
         [ 8.2684e-04,  4.7769e-01],
         [-2.3440e-03,  3.1726e-01],
         [-3.3898e-03,  2.3382e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6684367886683074
Current reward: 0.32991687972165085
Current mitigation activation: 0
#############################
Total reward: 39.40401342161138
16.467805296182632 seconds in game passed.
Action: tensor([[[-1.2756e-03,  9.1374e-01],
         [ 8.2684e-04,  4.7769e-01],
         [-2.3440e-03,  3.1726e-01],
         [-3.3898e-03,  2.3382e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.40401342161138
16.49280529655516 seconds in game passed.
Action: tensor([[[-1.2756e-03,  9.1374e-01],
         [ 8.2684e-04,  4.7769e-01],
         [-2.3440e-03,  3.1726e-01],
         [-3.3898e-03,  2.3382e-01]]])
agent 0 action: VehicleControl(throttle=0.878578, steer=0.000698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.40401342161138
16.51780529692769 seconds in game passed.
Action: tensor([[[-1.2756e-03,  9.1374e-01],
         [ 8.2684e-04,  4.7769e-01],
         [-2.3440e-03,  3.1726e-01],
         [-3.3898e-03,  2.3382e-01]]])
agent 0 action: VehicleControl(throttle=0.830987, steer=0.000614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.40401342161138
+++++++++++++: 1.5711333089859487
16.54280529730022 seconds in game passed.
At 16.54280529730022 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0078,  0.9012],
         [ 0.0013,  0.4938],
         [-0.0033,  0.3407],
         [-0.0051,  0.2569]]])
agent 0 action: VehicleControl(throttle=0.488005, steer=0.004667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5711333089859487
Current reward: 0.3381171774380188
Current mitigation activation: 0
#############################
Total reward: 39.7421305990494
16.56780529767275 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9012],
         [ 0.0013,  0.4938],
         [-0.0033,  0.3407],
         [-0.0051,  0.2569]]])
agent 0 action: VehicleControl(throttle=0.506296, steer=0.003950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.7421305990494
16.592805298045278 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9012],
         [ 0.0013,  0.4938],
         [-0.0033,  0.3407],
         [-0.0051,  0.2569]]])
agent 0 action: VehicleControl(throttle=0.489202, steer=0.003914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.7421305990494
16.617805298417807 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9012],
         [ 0.0013,  0.4938],
         [-0.0033,  0.3407],
         [-0.0051,  0.2569]]])
agent 0 action: VehicleControl(throttle=0.472099, steer=0.003879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.7421305990494
+++++++++++++: 1.4832436326799465
16.642805298790336 seconds in game passed.
At 16.642805298790336 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.2169e-03,  9.2532e-01],
         [ 4.5532e-03,  5.2182e-01],
         [ 8.0801e-04,  3.5603e-01],
         [-3.2394e-04,  2.6678e-01]]])
agent 0 action: VehicleControl(throttle=0.453586, steer=0.004876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4832436326799465
Current reward: 0.34572273482965943
Current mitigation activation: 0
#############################
Total reward: 40.08785333387906
16.667805299162865 seconds in game passed.
Action: tensor([[[ 4.2169e-03,  9.2532e-01],
         [ 4.5532e-03,  5.2182e-01],
         [ 8.0801e-04,  3.5603e-01],
         [-3.2394e-04,  2.6678e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004696, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.08785333387906
16.692805299535394 seconds in game passed.
Action: tensor([[[ 4.2169e-03,  9.2532e-01],
         [ 4.5532e-03,  5.2182e-01],
         [ 8.0801e-04,  3.5603e-01],
         [-3.2394e-04,  2.6678e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004685, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.08785333387906
16.717805299907923 seconds in game passed.
Action: tensor([[[ 4.2169e-03,  9.2532e-01],
         [ 4.5532e-03,  5.2182e-01],
         [ 8.0801e-04,  3.5603e-01],
         [-3.2394e-04,  2.6678e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004674, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.08785333387906
+++++++++++++: 1.4189758691197065
16.74280530028045 seconds in game passed.
At 16.74280530028045 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.6018e-03, 9.3698e-01],
         [5.3476e-03, 5.3960e-01],
         [1.3389e-03, 3.6494e-01],
         [3.8441e-04, 2.7037e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004177, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4189758691197065
Current reward: 0.3505372945258999
Current mitigation activation: 0
#############################
Total reward: 40.43839062840496
16.76780530065298 seconds in game passed.
Action: tensor([[[1.6018e-03, 9.3698e-01],
         [5.3476e-03, 5.3960e-01],
         [1.3389e-03, 3.6494e-01],
         [3.8441e-04, 2.7037e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004285, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.43839062840496
16.79280530102551 seconds in game passed.
Action: tensor([[[1.6018e-03, 9.3698e-01],
         [5.3476e-03, 5.3960e-01],
         [1.3389e-03, 3.6494e-01],
         [3.8441e-04, 2.7037e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004306, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.43839062840496
16.81780530139804 seconds in game passed.
Action: tensor([[[1.6018e-03, 9.3698e-01],
         [5.3476e-03, 5.3960e-01],
         [1.3389e-03, 3.6494e-01],
         [3.8441e-04, 2.7037e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004328, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.43839062840496
+++++++++++++: 1.4151756397931312
16.842805301770568 seconds in game passed.
At 16.842805301770568 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0176, 0.9304],
         [0.0071, 0.5258],
         [0.0036, 0.3542],
         [0.0030, 0.2601]]])
agent 0 action: VehicleControl(throttle=0.306799, steer=0.012590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4151756397931312
Current reward: 0.34671983457747957
Current mitigation activation: 0
#############################
Total reward: 40.78511046298244
16.867805302143097 seconds in game passed.
Action: tensor([[[0.0176, 0.9304],
         [0.0071, 0.5258],
         [0.0036, 0.3542],
         [0.0030, 0.2601]]])
agent 0 action: VehicleControl(throttle=0.289953, steer=0.011363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.78511046298244
16.892805302515626 seconds in game passed.
Action: tensor([[[0.0176, 0.9304],
         [0.0071, 0.5258],
         [0.0036, 0.3542],
         [0.0030, 0.2601]]])
agent 0 action: VehicleControl(throttle=0.273636, steer=0.011491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.78511046298244
16.917805302888155 seconds in game passed.
Action: tensor([[[0.0176, 0.9304],
         [0.0071, 0.5258],
         [0.0036, 0.3542],
         [0.0030, 0.2601]]])
agent 0 action: VehicleControl(throttle=0.257836, steer=0.011619, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.78511046298244
+++++++++++++: 1.4969188727467095
16.942805303260684 seconds in game passed.
At 16.942805303260684 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0252, 0.9298],
         [0.0058, 0.5297],
         [0.0010, 0.3551],
         [0.0011, 0.2599]]])
agent 0 action: VehicleControl(throttle=0.242680, steer=0.014040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4969188727467095
Current reward: 0.33205108260525695
Current mitigation activation: 0
#############################
Total reward: 41.11716154558769
16.967805303633213 seconds in game passed.
Action: tensor([[[0.0252, 0.9298],
         [0.0058, 0.5297],
         [0.0010, 0.3551],
         [0.0011, 0.2599]]])
agent 0 action: VehicleControl(throttle=0.228025, steer=0.013806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.11716154558769
16.992805304005742 seconds in game passed.
Action: tensor([[[0.0252, 0.9298],
         [0.0058, 0.5297],
         [0.0010, 0.3551],
         [0.0011, 0.2599]]])
agent 0 action: VehicleControl(throttle=0.213862, steer=0.013952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.11716154558769
17.01780530437827 seconds in game passed.
Action: tensor([[[0.0252, 0.9298],
         [0.0058, 0.5297],
         [0.0010, 0.3551],
         [0.0011, 0.2599]]])
agent 0 action: VehicleControl(throttle=0.200187, steer=0.014097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.11716154558769
+++++++++++++: 1.5652406502415803
17.0428053047508 seconds in game passed.
At 17.0428053047508 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0139,  0.9361],
         [-0.0020,  0.5510],
         [-0.0069,  0.3702],
         [-0.0066,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.185057, steer=0.003690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5652406502415803
Current reward: 0.3222464543529165
Current mitigation activation: 0
#############################
Total reward: 41.439407999940606
17.06780530512333 seconds in game passed.
Action: tensor([[[ 0.0139,  0.9361],
         [-0.0020,  0.5510],
         [-0.0069,  0.3702],
         [-0.0066,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.170405, steer=0.005498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.439407999940606
17.092805305495858 seconds in game passed.
Action: tensor([[[ 0.0139,  0.9361],
         [-0.0020,  0.5510],
         [-0.0069,  0.3702],
         [-0.0066,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.156229, steer=0.005561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.439407999940606
17.117805305868387 seconds in game passed.
Action: tensor([[[ 0.0139,  0.9361],
         [-0.0020,  0.5510],
         [-0.0069,  0.3702],
         [-0.0066,  0.2726]]])
agent 0 action: VehicleControl(throttle=0.142523, steer=0.005623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.439407999940606
+++++++++++++: 1.6060062455359383
17.142805306240916 seconds in game passed.
At 17.142805306240916 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0183,  0.9369],
         [ 0.0020,  0.5367],
         [-0.0038,  0.3546],
         [-0.0047,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.129112, steer=0.010444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6060062455359383
Current reward: 0.3177801166662275
Current mitigation activation: 0
#############################
Total reward: 41.757188116606834
17.167805306613445 seconds in game passed.
Action: tensor([[[ 0.0183,  0.9369],
         [ 0.0020,  0.5367],
         [-0.0038,  0.3546],
         [-0.0047,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.116166, steer=0.009759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.757188116606834
17.192805306985974 seconds in game passed.
Action: tensor([[[ 0.0183,  0.9369],
         [ 0.0020,  0.5367],
         [-0.0038,  0.3546],
         [-0.0047,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.103684, steer=0.009861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.757188116606834
17.217805307358503 seconds in game passed.
Action: tensor([[[ 0.0183,  0.9369],
         [ 0.0020,  0.5367],
         [-0.0038,  0.3546],
         [-0.0047,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.091664, steer=0.009963, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.757188116606834
+++++++++++++: 1.650658535010111
17.242805307731032 seconds in game passed.
At 17.242805307731032 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.6435e-03,  9.3186e-01],
         [-7.4501e-04,  5.2507e-01],
         [-5.3798e-03,  3.4991e-01],
         [-6.1435e-03,  2.5823e-01]]])
agent 0 action: VehicleControl(throttle=0.129844, steer=0.004195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.650658535010111
Current reward: 0.3141771755749074
Current mitigation activation: 0
#############################
Total reward: 42.07136529218174
17.26780530810356 seconds in game passed.
Action: tensor([[[ 9.6435e-03,  9.3186e-01],
         [-7.4501e-04,  5.2507e-01],
         [-5.3798e-03,  3.4991e-01],
         [-6.1435e-03,  2.5823e-01]]])
agent 0 action: VehicleControl(throttle=0.133084, steer=0.005221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.07136529218174
17.29280530847609 seconds in game passed.
Action: tensor([[[ 9.6435e-03,  9.3186e-01],
         [-7.4501e-04,  5.2507e-01],
         [-5.3798e-03,  3.4991e-01],
         [-6.1435e-03,  2.5823e-01]]])
agent 0 action: VehicleControl(throttle=0.140543, steer=0.005277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.07136529218174
17.31780530884862 seconds in game passed.
Action: tensor([[[ 9.6435e-03,  9.3186e-01],
         [-7.4501e-04,  5.2507e-01],
         [-5.3798e-03,  3.4991e-01],
         [-6.1435e-03,  2.5823e-01]]])
agent 0 action: VehicleControl(throttle=0.131894, steer=0.005333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.07136529218174
+++++++++++++: 1.6968704730904036
17.34280530922115 seconds in game passed.
At 17.34280530922115 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0025,  0.9195],
         [-0.0082,  0.5135],
         [-0.0129,  0.3423],
         [-0.0130,  0.2513]]])
agent 0 action: VehicleControl(throttle=0.237295, steer=-0.003396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6968704730904036
Current reward: 0.31162404000037003
Current mitigation activation: 0
#############################
Total reward: 42.382989332182106
17.367805309593678 seconds in game passed.
Action: tensor([[[ 0.0025,  0.9195],
         [-0.0082,  0.5135],
         [-0.0129,  0.3423],
         [-0.0130,  0.2513]]])
agent 0 action: VehicleControl(throttle=0.220580, steer=-0.001974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.382989332182106
17.392805309966207 seconds in game passed.
Action: tensor([[[ 0.0025,  0.9195],
         [-0.0082,  0.5135],
         [-0.0129,  0.3423],
         [-0.0130,  0.2513]]])
agent 0 action: VehicleControl(throttle=0.216051, steer=-0.002002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.382989332182106
17.417805310338736 seconds in game passed.
Action: tensor([[[ 0.0025,  0.9195],
         [-0.0082,  0.5135],
         [-0.0129,  0.3423],
         [-0.0130,  0.2513]]])
agent 0 action: VehicleControl(throttle=0.211929, steer=-0.002030, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.382989332182106
+++++++++++++: 1.7206118791036473
17.442805310711265 seconds in game passed.
At 17.442805310711265 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.0008e-04,  9.3421e-01],
         [-4.8850e-03,  5.1645e-01],
         [-9.8640e-03,  3.4046e-01],
         [-1.1235e-02,  2.5143e-01]]])
agent 0 action: VehicleControl(throttle=0.233892, steer=-0.000312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7206118791036473
Current reward: 0.31241441897962346
Current mitigation activation: 0
#############################
Total reward: 42.69540375116173
17.467805311083794 seconds in game passed.
Action: tensor([[[ 7.0008e-04,  9.3421e-01],
         [-4.8850e-03,  5.1645e-01],
         [-9.8640e-03,  3.4046e-01],
         [-1.1235e-02,  2.5143e-01]]])
agent 0 action: VehicleControl(throttle=0.230531, steer=-0.000641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.69540375116173
17.492805311456323 seconds in game passed.
Action: tensor([[[ 7.0008e-04,  9.3421e-01],
         [-4.8850e-03,  5.1645e-01],
         [-9.8640e-03,  3.4046e-01],
         [-1.1235e-02,  2.5143e-01]]])
agent 0 action: VehicleControl(throttle=0.230075, steer=-0.000678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.69540375116173
17.51780531182885 seconds in game passed.
Action: tensor([[[ 7.0008e-04,  9.3421e-01],
         [-4.8850e-03,  5.1645e-01],
         [-9.8640e-03,  3.4046e-01],
         [-1.1235e-02,  2.5143e-01]]])
agent 0 action: VehicleControl(throttle=0.230052, steer=-0.000715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.69540375116173
+++++++++++++: 1.7458587656027968
17.54280531220138 seconds in game passed.
At 17.54280531220138 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.9187],
         [-0.0087,  0.4875],
         [-0.0130,  0.3284],
         [-0.0139,  0.2483]]])
agent 0 action: VehicleControl(throttle=0.614944, steer=-0.004723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7458587656027968
Current reward: 0.31370049168232816
Current mitigation activation: 0
#############################
Total reward: 43.00910424284405
17.56780531257391 seconds in game passed.
Action: tensor([[[-0.0016,  0.9187],
         [-0.0087,  0.4875],
         [-0.0130,  0.3284],
         [-0.0139,  0.2483]]])
agent 0 action: VehicleControl(throttle=0.582412, steer=-0.004195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.00910424284405
17.59280531294644 seconds in game passed.
Action: tensor([[[-0.0016,  0.9187],
         [-0.0087,  0.4875],
         [-0.0130,  0.3284],
         [-0.0139,  0.2483]]])
agent 0 action: VehicleControl(throttle=0.590291, steer=-0.004314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.00910424284405
17.617805313318968 seconds in game passed.
Action: tensor([[[-0.0016,  0.9187],
         [-0.0087,  0.4875],
         [-0.0130,  0.3284],
         [-0.0139,  0.2483]]])
agent 0 action: VehicleControl(throttle=0.598177, steer=-0.004434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.00910424284405
+++++++++++++: 1.7746712560142048
17.642805313691497 seconds in game passed.
At 17.642805313691497 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0053,  0.8634],
         [-0.0123,  0.4611],
         [-0.0176,  0.3190],
         [-0.0194,  0.2456]]])
agent 0 action: VehicleControl(throttle=0.793981, steer=-0.008797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7746712560142048
Current reward: 0.3152337442679932
Current mitigation activation: 0
#############################
Total reward: 43.324337987112045
17.667805314064026 seconds in game passed.
Action: tensor([[[-0.0053,  0.8634],
         [-0.0123,  0.4611],
         [-0.0176,  0.3190],
         [-0.0194,  0.2456]]])
agent 0 action: VehicleControl(throttle=0.784046, steer=-0.008273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.324337987112045
17.692805314436555 seconds in game passed.
Action: tensor([[[-0.0053,  0.8634],
         [-0.0123,  0.4611],
         [-0.0176,  0.3190],
         [-0.0194,  0.2456]]])
agent 0 action: VehicleControl(throttle=0.794058, steer=-0.008447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.324337987112045
17.717805314809084 seconds in game passed.
Action: tensor([[[-0.0053,  0.8634],
         [-0.0123,  0.4611],
         [-0.0176,  0.3190],
         [-0.0194,  0.2456]]])
agent 0 action: VehicleControl(throttle=0.804072, steer=-0.008621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.324337987112045
+++++++++++++: 1.8069484006809557
17.742805315181613 seconds in game passed.
At 17.742805315181613 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0070,  0.8742],
         [-0.0146,  0.4679],
         [-0.0192,  0.3185],
         [-0.0204,  0.2406]]])
agent 0 action: VehicleControl(throttle=0.745897, steer=-0.011249, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8069484006809557
Current reward: 0.3170018998803399
Current mitigation activation: 0
#############################
Total reward: 43.641339886992384
17.767805315554142 seconds in game passed.
Action: tensor([[[-0.0070,  0.8742],
         [-0.0146,  0.4679],
         [-0.0192,  0.3185],
         [-0.0204,  0.2406]]])
agent 0 action: VehicleControl(throttle=0.762399, steer=-0.011037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.641339886992384
17.79280531592667 seconds in game passed.
Action: tensor([[[-0.0070,  0.8742],
         [-0.0146,  0.4679],
         [-0.0192,  0.3185],
         [-0.0204,  0.2406]]])
agent 0 action: VehicleControl(throttle=0.771710, steer=-0.011231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.641339886992384
17.8178053162992 seconds in game passed.
Action: tensor([[[-0.0070,  0.8742],
         [-0.0146,  0.4679],
         [-0.0192,  0.3185],
         [-0.0204,  0.2406]]])
agent 0 action: VehicleControl(throttle=0.815641, steer=-0.011425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.641339886992384
+++++++++++++: 1.8606589038226455
17.84280531667173 seconds in game passed.
At 17.84280531667173 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.8524],
         [-0.0097,  0.4536],
         [-0.0130,  0.3120],
         [-0.0136,  0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8606589038226455
Current reward: 0.3173054420245035
Current mitigation activation: 0
#############################
Total reward: 43.95864532901689
17.867805317044258 seconds in game passed.
Action: tensor([[[-0.0026,  0.8524],
         [-0.0097,  0.4536],
         [-0.0130,  0.3120],
         [-0.0136,  0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.95864532901689
17.892805317416787 seconds in game passed.
Action: tensor([[[-0.0026,  0.8524],
         [-0.0097,  0.4536],
         [-0.0130,  0.3120],
         [-0.0136,  0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.95864532901689
17.917805317789316 seconds in game passed.
Action: tensor([[[-0.0026,  0.8524],
         [-0.0097,  0.4536],
         [-0.0130,  0.3120],
         [-0.0136,  0.2366]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.95864532901689
+++++++++++++: 2.0407673940652584
17.942805318161845 seconds in game passed.
At 17.942805318161845 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.8697],
         [-0.0097,  0.4570],
         [-0.0145,  0.3078],
         [-0.0168,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0407673940652584
Current reward: 0.30767178456180344
Current mitigation activation: 0
#############################
Total reward: 44.266317113578694
17.967805318534374 seconds in game passed.
Action: tensor([[[ 0.0011,  0.8697],
         [-0.0097,  0.4570],
         [-0.0145,  0.3078],
         [-0.0168,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.266317113578694
17.992805318906903 seconds in game passed.
Action: tensor([[[ 0.0011,  0.8697],
         [-0.0097,  0.4570],
         [-0.0145,  0.3078],
         [-0.0168,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.266317113578694
18.017805319279432 seconds in game passed.
Action: tensor([[[ 0.0011,  0.8697],
         [-0.0097,  0.4570],
         [-0.0145,  0.3078],
         [-0.0168,  0.2300]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.266317113578694
+++++++++++++: 2.1625362700478337
18.04280531965196 seconds in game passed.
At 18.04280531965196 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0042,  0.8432],
         [-0.0103,  0.4367],
         [-0.0144,  0.2911],
         [-0.0157,  0.2167]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1625362700478337
Current reward: 0.3055384657472678
Current mitigation activation: 0
#############################
Total reward: 44.57185557932596
18.06780532002449 seconds in game passed.
Action: tensor([[[ 0.0042,  0.8432],
         [-0.0103,  0.4367],
         [-0.0144,  0.2911],
         [-0.0157,  0.2167]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.57185557932596
18.09280532039702 seconds in game passed.
Action: tensor([[[ 0.0042,  0.8432],
         [-0.0103,  0.4367],
         [-0.0144,  0.2911],
         [-0.0157,  0.2167]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.57185557932596
18.11780532076955 seconds in game passed.
Action: tensor([[[ 0.0042,  0.8432],
         [-0.0103,  0.4367],
         [-0.0144,  0.2911],
         [-0.0157,  0.2167]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.57185557932596
+++++++++++++: 2.19808732600694
18.142805321142077 seconds in game passed.
At 18.142805321142077 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.8414e-04,  7.9608e-01],
         [-7.2732e-03,  4.1834e-01],
         [-9.9030e-03,  2.7935e-01],
         [-1.1014e-02,  2.0830e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.19808732600694
Current reward: 0.31086835900563486
Current mitigation activation: 0
#############################
Total reward: 44.882723938331594
18.167805321514606 seconds in game passed.
Action: tensor([[[-6.8414e-04,  7.9608e-01],
         [-7.2732e-03,  4.1834e-01],
         [-9.9030e-03,  2.7935e-01],
         [-1.1014e-02,  2.0830e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.882723938331594
18.192805321887136 seconds in game passed.
Action: tensor([[[-6.8414e-04,  7.9608e-01],
         [-7.2732e-03,  4.1834e-01],
         [-9.9030e-03,  2.7935e-01],
         [-1.1014e-02,  2.0830e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007353, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.882723938331594
18.217805322259665 seconds in game passed.
Action: tensor([[[-6.8414e-04,  7.9608e-01],
         [-7.2732e-03,  4.1834e-01],
         [-9.9030e-03,  2.7935e-01],
         [-1.1014e-02,  2.0830e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.882723938331594
+++++++++++++: 2.185349864545139
18.242805322632194 seconds in game passed.
At 18.242805322632194 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0032,  0.7482],
         [-0.0073,  0.4014],
         [-0.0097,  0.2759],
         [-0.0111,  0.2109]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.185349864545139
Current reward: 0.32002053639954187
Current mitigation activation: 0
#############################
Total reward: 45.20274447473113
18.267805323004723 seconds in game passed.
Action: tensor([[[-0.0032,  0.7482],
         [-0.0073,  0.4014],
         [-0.0097,  0.2759],
         [-0.0111,  0.2109]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008505, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.20274447473113
18.29280532337725 seconds in game passed.
Action: tensor([[[-0.0032,  0.7482],
         [-0.0073,  0.4014],
         [-0.0097,  0.2759],
         [-0.0111,  0.2109]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.20274447473113
18.31780532374978 seconds in game passed.
Action: tensor([[[-0.0032,  0.7482],
         [-0.0073,  0.4014],
         [-0.0097,  0.2759],
         [-0.0111,  0.2109]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.20274447473113
+++++++++++++: 2.1495934294605235
18.34280532412231 seconds in game passed.
At 18.34280532412231 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.7142],
         [-0.0066,  0.3893],
         [-0.0083,  0.2675],
         [-0.0090,  0.2038]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1495934294605235
Current reward: 0.3310479622701272
Current mitigation activation: 0
#############################
Total reward: 45.53379243700126
18.36780532449484 seconds in game passed.
Action: tensor([[[-0.0025,  0.7142],
         [-0.0066,  0.3893],
         [-0.0083,  0.2675],
         [-0.0090,  0.2038]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.53379243700126
18.392805324867368 seconds in game passed.
Action: tensor([[[-0.0025,  0.7142],
         [-0.0066,  0.3893],
         [-0.0083,  0.2675],
         [-0.0090,  0.2038]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.53379243700126
18.417805325239897 seconds in game passed.
Action: tensor([[[-0.0025,  0.7142],
         [-0.0066,  0.3893],
         [-0.0083,  0.2675],
         [-0.0090,  0.2038]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.53379243700126
+++++++++++++: 2.104014923063844
18.442805325612426 seconds in game passed.
At 18.442805325612426 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.7188],
         [-0.0032,  0.3913],
         [-0.0047,  0.2687],
         [-0.0055,  0.2048]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.104014923063844
Current reward: 0.34297482914541416
Current mitigation activation: 0
#############################
Total reward: 45.87676726614667
18.467805325984955 seconds in game passed.
Action: tensor([[[ 0.0008,  0.7188],
         [-0.0032,  0.3913],
         [-0.0047,  0.2687],
         [-0.0055,  0.2048]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004821, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.87676726614667
18.492805326357484 seconds in game passed.
Action: tensor([[[ 0.0008,  0.7188],
         [-0.0032,  0.3913],
         [-0.0047,  0.2687],
         [-0.0055,  0.2048]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.87676726614667
18.517805326730013 seconds in game passed.
Action: tensor([[[ 0.0008,  0.7188],
         [-0.0032,  0.3913],
         [-0.0047,  0.2687],
         [-0.0055,  0.2048]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.87676726614667
+++++++++++++: 2.055165851900617
18.542805327102542 seconds in game passed.
At 18.542805327102542 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0045,  0.6958],
         [-0.0016,  0.3849],
         [-0.0031,  0.2663],
         [-0.0042,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.055165851900617
Current reward: 0.35528886242088
Current mitigation activation: 0
#############################
Total reward: 46.23205612856755
18.56780532747507 seconds in game passed.
Action: tensor([[[ 0.0045,  0.6958],
         [-0.0016,  0.3849],
         [-0.0031,  0.2663],
         [-0.0042,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.23205612856755
18.5928053278476 seconds in game passed.
Action: tensor([[[ 0.0045,  0.6958],
         [-0.0016,  0.3849],
         [-0.0031,  0.2663],
         [-0.0042,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.23205612856755
18.61780532822013 seconds in game passed.
Action: tensor([[[ 0.0045,  0.6958],
         [-0.0016,  0.3849],
         [-0.0031,  0.2663],
         [-0.0042,  0.2043]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.23205612856755
+++++++++++++: 2.0062456146573404
18.642805328592658 seconds in game passed.
At 18.642805328592658 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.5466e-03,  6.7560e-01],
         [-2.7550e-04,  3.7060e-01],
         [-2.8886e-04,  2.5367e-01],
         [-4.8596e-04,  1.9363e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0062456146573404
Current reward: 0.3676978478185874
Current mitigation activation: 0
#############################
Total reward: 46.59975397638614
18.667805328965187 seconds in game passed.
Action: tensor([[[ 4.5466e-03,  6.7560e-01],
         [-2.7550e-04,  3.7060e-01],
         [-2.8886e-04,  2.5367e-01],
         [-4.8596e-04,  1.9363e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.59975397638614
18.692805329337716 seconds in game passed.
Action: tensor([[[ 4.5466e-03,  6.7560e-01],
         [-2.7550e-04,  3.7060e-01],
         [-2.8886e-04,  2.5367e-01],
         [-4.8596e-04,  1.9363e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001013, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.59975397638614
18.717805329710245 seconds in game passed.
Action: tensor([[[ 4.5466e-03,  6.7560e-01],
         [-2.7550e-04,  3.7060e-01],
         [-2.8886e-04,  2.5367e-01],
         [-4.8596e-04,  1.9363e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.59975397638614
+++++++++++++: 1.9587478573644173
18.742805330082774 seconds in game passed.
At 18.742805330082774 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.4437e-03, 6.5813e-01],
         [1.3624e-03, 3.5405e-01],
         [1.0987e-03, 2.4311e-01],
         [4.3324e-04, 1.8616e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9587478573644173
Current reward: 0.3800311466663493
Current mitigation activation: 0
#############################
Total reward: 46.97978512305249
18.767805330455303 seconds in game passed.
Action: tensor([[[3.4437e-03, 6.5813e-01],
         [1.3624e-03, 3.5405e-01],
         [1.0987e-03, 2.4311e-01],
         [4.3324e-04, 1.8616e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.97978512305249
18.792805330827832 seconds in game passed.
Action: tensor([[[3.4437e-03, 6.5813e-01],
         [1.3624e-03, 3.5405e-01],
         [1.0987e-03, 2.4311e-01],
         [4.3324e-04, 1.8616e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.97978512305249
18.81780533120036 seconds in game passed.
Action: tensor([[[3.4437e-03, 6.5813e-01],
         [1.3624e-03, 3.5405e-01],
         [1.0987e-03, 2.4311e-01],
         [4.3324e-04, 1.8616e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.97978512305249
+++++++++++++: 1.913315396088881
18.84280533157289 seconds in game passed.
At 18.84280533157289 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0047, 0.6545],
         [0.0036, 0.3517],
         [0.0034, 0.2414],
         [0.0027, 0.1851]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.913315396088881
Current reward: 0.39218650841984437
Current mitigation activation: 0
#############################
Total reward: 47.371971631472334
18.86780533194542 seconds in game passed.
Action: tensor([[[0.0047, 0.6545],
         [0.0036, 0.3517],
         [0.0034, 0.2414],
         [0.0027, 0.1851]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002435, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.371971631472334
18.89280533231795 seconds in game passed.
Action: tensor([[[0.0047, 0.6545],
         [0.0036, 0.3517],
         [0.0034, 0.2414],
         [0.0027, 0.1851]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.371971631472334
18.917805332690477 seconds in game passed.
Action: tensor([[[0.0047, 0.6545],
         [0.0036, 0.3517],
         [0.0034, 0.2414],
         [0.0027, 0.1851]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.371971631472334
+++++++++++++: 1.870146147832028
18.942805333063006 seconds in game passed.
At 18.942805333063006 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9808e-03, 6.4995e-01],
         [7.4175e-04, 3.4847e-01],
         [7.7681e-04, 2.3999e-01],
         [3.1881e-04, 1.8428e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.870146147832028
Current reward: 0.4041063083528793
Current mitigation activation: 0
#############################
Total reward: 47.776077939825214
18.967805333435535 seconds in game passed.
Action: tensor([[[1.9808e-03, 6.4995e-01],
         [7.4175e-04, 3.4847e-01],
         [7.7681e-04, 2.3999e-01],
         [3.1881e-04, 1.8428e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.776077939825214
18.992805333808064 seconds in game passed.
Action: tensor([[[1.9808e-03, 6.4995e-01],
         [7.4175e-04, 3.4847e-01],
         [7.7681e-04, 2.3999e-01],
         [3.1881e-04, 1.8428e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.776077939825214
19.017805334180593 seconds in game passed.
Action: tensor([[[1.9808e-03, 6.4995e-01],
         [7.4175e-04, 3.4847e-01],
         [7.7681e-04, 2.3999e-01],
         [3.1881e-04, 1.8428e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.776077939825214
+++++++++++++: 1.829201222358038
19.042805334553123 seconds in game passed.
At 19.042805334553123 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.6341e-03, 6.5341e-01],
         [1.7742e-03, 3.4960e-01],
         [1.1536e-03, 2.4002e-01],
         [5.5390e-04, 1.8372e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.829201222358038
Current reward: 0.41575003930066545
Current mitigation activation: 0
#############################
Total reward: 48.19182797912588
19.06780533492565 seconds in game passed.
Action: tensor([[[3.6341e-03, 6.5341e-01],
         [1.7742e-03, 3.4960e-01],
         [1.1536e-03, 2.4002e-01],
         [5.5390e-04, 1.8372e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.19182797912588
19.09280533529818 seconds in game passed.
Action: tensor([[[3.6341e-03, 6.5341e-01],
         [1.7742e-03, 3.4960e-01],
         [1.1536e-03, 2.4002e-01],
         [5.5390e-04, 1.8372e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.19182797912588
19.11780533567071 seconds in game passed.
Action: tensor([[[3.6341e-03, 6.5341e-01],
         [1.7742e-03, 3.4960e-01],
         [1.1536e-03, 2.4002e-01],
         [5.5390e-04, 1.8372e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.19182797912588
+++++++++++++: 1.7903598463246408
19.14280533604324 seconds in game passed.
At 19.14280533604324 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6762],
         [-0.0019,  0.3563],
         [-0.0029,  0.2427],
         [-0.0034,  0.1854]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7903598463246408
Current reward: 0.42709820721576364
Current mitigation activation: 0
#############################
Total reward: 48.618926186341646
19.167805336415768 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6762],
         [-0.0019,  0.3563],
         [-0.0029,  0.2427],
         [-0.0034,  0.1854]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.618926186341646
19.192805336788297 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6762],
         [-0.0019,  0.3563],
         [-0.0029,  0.2427],
         [-0.0034,  0.1854]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.618926186341646
19.217805337160826 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6762],
         [-0.0019,  0.3563],
         [-0.0029,  0.2427],
         [-0.0034,  0.1854]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.618926186341646
+++++++++++++: 1.7534511225620038
19.242805337533355 seconds in game passed.
At 19.242805337533355 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0022,  0.6869],
         [-0.0025,  0.3557],
         [-0.0039,  0.2411],
         [-0.0047,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000872, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7534511225620038
Current reward: 0.4381378136663463
Current mitigation activation: 0
#############################
Total reward: 49.05706400000799
19.267805337905884 seconds in game passed.
Action: tensor([[[ 0.0022,  0.6869],
         [-0.0025,  0.3557],
         [-0.0039,  0.2411],
         [-0.0047,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.05706400000799
19.292805338278413 seconds in game passed.
Action: tensor([[[ 0.0022,  0.6869],
         [-0.0025,  0.3557],
         [-0.0039,  0.2411],
         [-0.0047,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.05706400000799
19.317805338650942 seconds in game passed.
Action: tensor([[[ 0.0022,  0.6869],
         [-0.0025,  0.3557],
         [-0.0039,  0.2411],
         [-0.0047,  0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.05706400000799
+++++++++++++: 1.7245318967515082
19.34280533902347 seconds in game passed.
At 19.34280533902347 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0007,  0.6854],
         [-0.0026,  0.3538],
         [-0.0033,  0.2397],
         [-0.0035,  0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7245318967515082
Current reward: 0.4479487380282662
Current mitigation activation: 0
#############################
Total reward: 49.50501273803626
19.367805339396 seconds in game passed.
Action: tensor([[[-0.0007,  0.6854],
         [-0.0026,  0.3538],
         [-0.0033,  0.2397],
         [-0.0035,  0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.50501273803626
19.39280533976853 seconds in game passed.
Action: tensor([[[-0.0007,  0.6854],
         [-0.0026,  0.3538],
         [-0.0033,  0.2397],
         [-0.0035,  0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.50501273803626
19.417805340141058 seconds in game passed.
Action: tensor([[[-0.0007,  0.6854],
         [-0.0026,  0.3538],
         [-0.0033,  0.2397],
         [-0.0035,  0.1835]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.50501273803626
+++++++++++++: 1.740857294057234
19.442805340513587 seconds in game passed.
At 19.442805340513587 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6702],
         [-0.0013,  0.3467],
         [-0.0019,  0.2357],
         [-0.0021,  0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.740857294057234
Current reward: 0.45095276814282176
Current mitigation activation: 0
#############################
Total reward: 49.955965506179076
19.467805340886116 seconds in game passed.
Action: tensor([[[-0.0014,  0.6702],
         [-0.0013,  0.3467],
         [-0.0019,  0.2357],
         [-0.0021,  0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.955965506179076
19.492805341258645 seconds in game passed.
Action: tensor([[[-0.0014,  0.6702],
         [-0.0013,  0.3467],
         [-0.0019,  0.2357],
         [-0.0021,  0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.955965506179076
19.517805341631174 seconds in game passed.
Action: tensor([[[-0.0014,  0.6702],
         [-0.0013,  0.3467],
         [-0.0019,  0.2357],
         [-0.0021,  0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.955965506179076
+++++++++++++: 1.7665967696916982
19.542805342003703 seconds in game passed.
At 19.542805342003703 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.6281],
         [0.0022, 0.3378],
         [0.0021, 0.2321],
         [0.0019, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7665967696916982
Current reward: 0.45288163168931317
Current mitigation activation: 0
#############################
Total reward: 50.40884713786839
19.567805342376232 seconds in game passed.
Action: tensor([[[0.0027, 0.6281],
         [0.0022, 0.3378],
         [0.0021, 0.2321],
         [0.0019, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.40884713786839
19.59280534274876 seconds in game passed.
Action: tensor([[[0.0027, 0.6281],
         [0.0022, 0.3378],
         [0.0021, 0.2321],
         [0.0019, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.40884713786839
19.61780534312129 seconds in game passed.
Action: tensor([[[0.0027, 0.6281],
         [0.0022, 0.3378],
         [0.0021, 0.2321],
         [0.0019, 0.1782]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.40884713786839
+++++++++++++: 1.7940097606500987
19.64280534349382 seconds in game passed.
At 19.64280534349382 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0054, 0.6436],
         [0.0025, 0.3464],
         [0.0023, 0.2389],
         [0.0019, 0.1841]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7940097606500987
Current reward: 0.454978476662818
Current mitigation activation: 0
#############################
Total reward: 50.86382561453121
19.66780534386635 seconds in game passed.
Action: tensor([[[0.0054, 0.6436],
         [0.0025, 0.3464],
         [0.0023, 0.2389],
         [0.0019, 0.1841]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003735, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.86382561453121
19.692805344238877 seconds in game passed.
Action: tensor([[[0.0054, 0.6436],
         [0.0025, 0.3464],
         [0.0023, 0.2389],
         [0.0019, 0.1841]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.86382561453121
19.717805344611406 seconds in game passed.
Action: tensor([[[0.0054, 0.6436],
         [0.0025, 0.3464],
         [0.0023, 0.2389],
         [0.0019, 0.1841]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.86382561453121
+++++++++++++: 1.8231409985160782
19.742805344983935 seconds in game passed.
At 19.742805344983935 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0049, 0.6320],
         [0.0025, 0.3403],
         [0.0025, 0.2350],
         [0.0022, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8231409985160782
Current reward: 0.45722920659297306
Current mitigation activation: 0
#############################
Total reward: 51.32105482112418
19.767805345356464 seconds in game passed.
Action: tensor([[[0.0049, 0.6320],
         [0.0025, 0.3403],
         [0.0025, 0.2350],
         [0.0022, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.32105482112418
19.792805345728993 seconds in game passed.
Action: tensor([[[0.0049, 0.6320],
         [0.0025, 0.3403],
         [0.0025, 0.2350],
         [0.0022, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.32105482112418
19.817805346101522 seconds in game passed.
Action: tensor([[[0.0049, 0.6320],
         [0.0025, 0.3403],
         [0.0025, 0.2350],
         [0.0022, 0.1805]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003706, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.32105482112418
+++++++++++++: 1.8485951539849346
19.84280534647405 seconds in game passed.
At 19.84280534647405 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.7977e-03, 6.3465e-01],
         [1.0066e-04, 3.3623e-01],
         [9.9562e-05, 2.3148e-01],
         [1.5499e-04, 1.7804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8485951539849346
Current reward: 0.4603576095979235
Current mitigation activation: 0
#############################
Total reward: 51.7814124307221
19.86780534684658 seconds in game passed.
Action: tensor([[[2.7977e-03, 6.3465e-01],
         [1.0066e-04, 3.3623e-01],
         [9.9562e-05, 2.3148e-01],
         [1.5499e-04, 1.7804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.7814124307221
19.89280534721911 seconds in game passed.
Action: tensor([[[2.7977e-03, 6.3465e-01],
         [1.0066e-04, 3.3623e-01],
         [9.9562e-05, 2.3148e-01],
         [1.5499e-04, 1.7804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.7814124307221
19.91780534759164 seconds in game passed.
Action: tensor([[[2.7977e-03, 6.3465e-01],
         [1.0066e-04, 3.3623e-01],
         [9.9562e-05, 2.3148e-01],
         [1.5499e-04, 1.7804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001390, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.7814124307221
+++++++++++++: 1.8016953297559506
19.942805347964168 seconds in game passed.
At 19.942805347964168 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2240e-03,  6.1731e-01],
         [-6.1382e-04,  3.3259e-01],
         [-7.7473e-04,  2.2992e-01],
         [-9.2611e-04,  1.7725e-01]]])
agent 0 action: VehicleControl(throttle=0.898712, steer=0.000642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8016953297559506
Current reward: 0.47392243871945505
Current mitigation activation: 0
#############################
Total reward: 52.255334869441555
19.967805348336697 seconds in game passed.
Action: tensor([[[ 2.2240e-03,  6.1731e-01],
         [-6.1382e-04,  3.3259e-01],
         [-7.7473e-04,  2.2992e-01],
         [-9.2611e-04,  1.7725e-01]]])
agent 0 action: VehicleControl(throttle=0.851434, steer=0.000756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.255334869441555
19.992805348709226 seconds in game passed.
Action: tensor([[[ 2.2240e-03,  6.1731e-01],
         [-6.1382e-04,  3.3259e-01],
         [-7.7473e-04,  2.2992e-01],
         [-9.2611e-04,  1.7725e-01]]])
agent 0 action: VehicleControl(throttle=0.800609, steer=0.000747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.255334869441555
20.017805349081755 seconds in game passed.
Action: tensor([[[ 2.2240e-03,  6.1731e-01],
         [-6.1382e-04,  3.3259e-01],
         [-7.7473e-04,  2.2992e-01],
         [-9.2611e-04,  1.7725e-01]]])
agent 0 action: VehicleControl(throttle=0.751119, steer=0.000737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.255334869441555
+++++++++++++: 1.745412509089247
20.042805349454284 seconds in game passed.
At 20.042805349454284 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0032,  0.6213],
         [-0.0055,  0.3351],
         [-0.0061,  0.2311],
         [-0.0066,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.655572, steer=-0.005066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.745412509089247
Current reward: 0.4888404382745526
Current mitigation activation: 0
#############################
Total reward: 52.744175307716105
20.067805349826813 seconds in game passed.
Action: tensor([[[-0.0032,  0.6213],
         [-0.0055,  0.3351],
         [-0.0061,  0.2311],
         [-0.0066,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.614333, steer=-0.004196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.744175307716105
20.09280535019934 seconds in game passed.
Action: tensor([[[-0.0032,  0.6213],
         [-0.0055,  0.3351],
         [-0.0061,  0.2311],
         [-0.0066,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.570487, steer=-0.004280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.744175307716105
20.11780535057187 seconds in game passed.
Action: tensor([[[-0.0032,  0.6213],
         [-0.0055,  0.3351],
         [-0.0061,  0.2311],
         [-0.0066,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.529573, steer=-0.004364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.744175307716105
+++++++++++++: 1.7022071700313475
20.1428053509444 seconds in game passed.
At 20.1428053509444 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6190],
         [-0.0048,  0.3316],
         [-0.0056,  0.2268],
         [-0.0062,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.590991, steer=-0.003461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7022071700313475
Current reward: 0.5015139488662788
Current mitigation activation: 0
#############################
Total reward: 53.24568925658238
20.16780535131693 seconds in game passed.
Action: tensor([[[-0.0022,  0.6190],
         [-0.0048,  0.3316],
         [-0.0056,  0.2268],
         [-0.0062,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.547178, steer=-0.003653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.24568925658238
20.192805351689458 seconds in game passed.
Action: tensor([[[-0.0022,  0.6190],
         [-0.0048,  0.3316],
         [-0.0056,  0.2268],
         [-0.0062,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.516988, steer=-0.003689, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.24568925658238
20.217805352061987 seconds in game passed.
Action: tensor([[[-0.0022,  0.6190],
         [-0.0048,  0.3316],
         [-0.0056,  0.2268],
         [-0.0062,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.489273, steer=-0.003724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.24568925658238
+++++++++++++: 1.6759616164351816
20.242805352434516 seconds in game passed.
At 20.242805352434516 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0043,  0.6211],
         [-0.0060,  0.3308],
         [-0.0065,  0.2258],
         [-0.0067,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.515092, steer=-0.005511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6759616164351816
Current reward: 0.51107447060706
Current mitigation activation: 0
#############################
Total reward: 53.756763727189444
20.267805352807045 seconds in game passed.
Action: tensor([[[-0.0043,  0.6211],
         [-0.0060,  0.3308],
         [-0.0065,  0.2258],
         [-0.0067,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.486731, steer=-0.005275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.756763727189444
20.292805353179574 seconds in game passed.
Action: tensor([[[-0.0043,  0.6211],
         [-0.0060,  0.3308],
         [-0.0065,  0.2258],
         [-0.0067,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.466539, steer=-0.005328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.756763727189444
20.317805353552103 seconds in game passed.
Action: tensor([[[-0.0043,  0.6211],
         [-0.0060,  0.3308],
         [-0.0065,  0.2258],
         [-0.0067,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.448309, steer=-0.005382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.756763727189444
+++++++++++++: 1.6655881128351875
20.342805353924632 seconds in game passed.
At 20.342805353924632 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6223],
         [-0.0035,  0.3312],
         [-0.0040,  0.2265],
         [-0.0043,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.430180, steer=-0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6655881128351875
Current reward: 0.5176357044194945
Current mitigation activation: 0
#############################
Total reward: 54.27439943160894
20.36780535429716 seconds in game passed.
Action: tensor([[[-0.0013,  0.6223],
         [-0.0035,  0.3312],
         [-0.0040,  0.2265],
         [-0.0043,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.415413, steer=-0.002905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.27439943160894
20.39280535466969 seconds in game passed.
Action: tensor([[[-0.0013,  0.6223],
         [-0.0035,  0.3312],
         [-0.0040,  0.2265],
         [-0.0043,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.402364, steer=-0.002914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.27439943160894
20.41780535504222 seconds in game passed.
Action: tensor([[[-0.0013,  0.6223],
         [-0.0035,  0.3312],
         [-0.0040,  0.2265],
         [-0.0043,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.391150, steer=-0.002924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.27439943160894
+++++++++++++: 1.6680622934761593
20.442805355414748 seconds in game passed.
At 20.442805355414748 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6113],
         [0.0025, 0.3317],
         [0.0022, 0.2285],
         [0.0013, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.249247, steer=0.003255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6680622934761593
Current reward: 0.5218195515803408
Current mitigation activation: 0
#############################
Total reward: 54.796218983189284
20.467805355787277 seconds in game passed.
Action: tensor([[[0.0031, 0.6113],
         [0.0025, 0.3317],
         [0.0022, 0.2285],
         [0.0013, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.252891, steer=0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.796218983189284
20.492805356159806 seconds in game passed.
Action: tensor([[[0.0031, 0.6113],
         [0.0025, 0.3317],
         [0.0022, 0.2285],
         [0.0013, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.244610, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.796218983189284
20.517805356532335 seconds in game passed.
Action: tensor([[[0.0031, 0.6113],
         [0.0025, 0.3317],
         [0.0022, 0.2285],
         [0.0013, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.239209, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.796218983189284
+++++++++++++: 1.6823431232303623
20.542805356904864 seconds in game passed.
At 20.542805356904864 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.0571e-03, 6.3118e-01],
         [1.9962e-03, 3.3893e-01],
         [1.4126e-03, 2.3263e-01],
         [4.9237e-04, 1.7887e-01]]])
agent 0 action: VehicleControl(throttle=0.191182, steer=0.002403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6823431232303623
Current reward: 0.5239866853814499
Current mitigation activation: 0
#############################
Total reward: 55.320205668570736
20.567805357277393 seconds in game passed.
Action: tensor([[[4.0571e-03, 6.3118e-01],
         [1.9962e-03, 3.3893e-01],
         [1.4126e-03, 2.3263e-01],
         [4.9237e-04, 1.7887e-01]]])
agent 0 action: VehicleControl(throttle=0.189890, steer=0.002403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.320205668570736
20.592805357649922 seconds in game passed.
Action: tensor([[[4.0571e-03, 6.3118e-01],
         [1.9962e-03, 3.3893e-01],
         [1.4126e-03, 2.3263e-01],
         [4.9237e-04, 1.7887e-01]]])
agent 0 action: VehicleControl(throttle=0.192054, steer=0.002407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.320205668570736
20.61780535802245 seconds in game passed.
Action: tensor([[[4.0571e-03, 6.3118e-01],
         [1.9962e-03, 3.3893e-01],
         [1.4126e-03, 2.3263e-01],
         [4.9237e-04, 1.7887e-01]]])
agent 0 action: VehicleControl(throttle=0.195744, steer=0.002411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.320205668570736
+++++++++++++: 1.710661026081339
20.64280535839498 seconds in game passed.
At 20.64280535839498 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6291],
         [0.0020, 0.3366],
         [0.0016, 0.2305],
         [0.0007, 0.1769]]])
agent 0 action: VehicleControl(throttle=0.264256, steer=0.001943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.710661026081339
Current reward: 0.5239733591480347
Current mitigation activation: 0
#############################
Total reward: 55.84417902771877
20.66780535876751 seconds in game passed.
Action: tensor([[[0.0028, 0.6291],
         [0.0020, 0.3366],
         [0.0016, 0.2305],
         [0.0007, 0.1769]]])
agent 0 action: VehicleControl(throttle=0.266960, steer=0.002005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.84417902771877
20.69280535914004 seconds in game passed.
Action: tensor([[[0.0028, 0.6291],
         [0.0020, 0.3366],
         [0.0016, 0.2305],
         [0.0007, 0.1769]]])
agent 0 action: VehicleControl(throttle=0.277264, steer=0.001991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.84417902771877
20.717805359512568 seconds in game passed.
Action: tensor([[[0.0028, 0.6291],
         [0.0020, 0.3366],
         [0.0016, 0.2305],
         [0.0007, 0.1769]]])
agent 0 action: VehicleControl(throttle=0.287973, steer=0.001977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.84417902771877
+++++++++++++: 1.7518092891794232
20.742805359885097 seconds in game passed.
At 20.742805359885097 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.7603e-04, 6.2253e-01],
         [1.3929e-03, 3.3440e-01],
         [1.2231e-03, 2.2951e-01],
         [3.4947e-04, 1.7638e-01]]])
agent 0 action: VehicleControl(throttle=0.307273, steer=0.000629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7518092891794232
Current reward: 0.5223277547820997
Current mitigation activation: 0
#############################
Total reward: 56.36650678250087
20.767805360257626 seconds in game passed.
Action: tensor([[[6.7603e-04, 6.2253e-01],
         [1.3929e-03, 3.3440e-01],
         [1.2231e-03, 2.2951e-01],
         [3.4947e-04, 1.7638e-01]]])
agent 0 action: VehicleControl(throttle=0.316696, steer=0.000823, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.36650678250087
20.792805360630155 seconds in game passed.
Action: tensor([[[6.7603e-04, 6.2253e-01],
         [1.3929e-03, 3.3440e-01],
         [1.2231e-03, 2.2951e-01],
         [3.4947e-04, 1.7638e-01]]])
agent 0 action: VehicleControl(throttle=0.327170, steer=0.000797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.36650678250087
20.817805361002684 seconds in game passed.
Action: tensor([[[6.7603e-04, 6.2253e-01],
         [1.3929e-03, 3.3440e-01],
         [1.2231e-03, 2.2951e-01],
         [3.4947e-04, 1.7638e-01]]])
agent 0 action: VehicleControl(throttle=0.337549, steer=0.000771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.36650678250087
+++++++++++++: 1.799701906895168
20.842805361375213 seconds in game passed.
At 20.842805361375213 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6220],
         [-0.0008,  0.3332],
         [-0.0009,  0.2284],
         [-0.0016,  0.1756]]])
agent 0 action: VehicleControl(throttle=0.382279, steer=-0.001625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.799701906895168
Current reward: 0.520374293913169
Current mitigation activation: 0
#############################
Total reward: 56.88688107641404
20.86780536174774 seconds in game passed.
Action: tensor([[[-0.0013,  0.6220],
         [-0.0008,  0.3332],
         [-0.0009,  0.2284],
         [-0.0016,  0.1756]]])
agent 0 action: VehicleControl(throttle=0.388467, steer=-0.001253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.88688107641404
20.89280536212027 seconds in game passed.
Action: tensor([[[-0.0013,  0.6220],
         [-0.0008,  0.3332],
         [-0.0009,  0.2284],
         [-0.0016,  0.1756]]])
agent 0 action: VehicleControl(throttle=0.398676, steer=-0.001277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.88688107641404
20.9178053624928 seconds in game passed.
Action: tensor([[[-0.0013,  0.6220],
         [-0.0008,  0.3332],
         [-0.0009,  0.2284],
         [-0.0016,  0.1756]]])
agent 0 action: VehicleControl(throttle=0.408802, steer=-0.001300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.88688107641404
+++++++++++++: 1.8497462958349538
20.94280536286533 seconds in game passed.
At 20.94280536286533 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6226],
         [-0.0015,  0.3350],
         [-0.0019,  0.2298],
         [-0.0026,  0.1764]]])
agent 0 action: VehicleControl(throttle=0.362292, steer=-0.001922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8497462958349538
Current reward: 0.518947220394876
Current mitigation activation: 0
#############################
Total reward: 57.40582829680892
20.967805363237858 seconds in game passed.
Action: tensor([[[-0.0015,  0.6226],
         [-0.0015,  0.3350],
         [-0.0019,  0.2298],
         [-0.0026,  0.1764]]])
agent 0 action: VehicleControl(throttle=0.378239, steer=-0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.40582829680892
20.992805363610387 seconds in game passed.
Action: tensor([[[-0.0015,  0.6226],
         [-0.0015,  0.3350],
         [-0.0019,  0.2298],
         [-0.0026,  0.1764]]])
agent 0 action: VehicleControl(throttle=0.388225, steer=-0.001866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.40582829680892
21.017805363982916 seconds in game passed.
Action: tensor([[[-0.0015,  0.6226],
         [-0.0015,  0.3350],
         [-0.0019,  0.2298],
         [-0.0026,  0.1764]]])
agent 0 action: VehicleControl(throttle=0.398692, steer=-0.001888, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.40582829680892
+++++++++++++: 1.8989270789148711
21.042805364355445 seconds in game passed.
At 21.042805364355445 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6302],
         [-0.0024,  0.3366],
         [-0.0023,  0.2305],
         [-0.0022,  0.1770]]])
agent 0 action: VehicleControl(throttle=0.430263, steer=-0.002895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8989270789148711
Current reward: 0.518461513850651
Current mitigation activation: 0
#############################
Total reward: 57.92428981065957
21.067805364727974 seconds in game passed.
Action: tensor([[[-0.0024,  0.6302],
         [-0.0024,  0.3366],
         [-0.0023,  0.2305],
         [-0.0022,  0.1770]]])
agent 0 action: VehicleControl(throttle=0.439762, steer=-0.002696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.92428981065957
21.092805365100503 seconds in game passed.
Action: tensor([[[-0.0024,  0.6302],
         [-0.0024,  0.3366],
         [-0.0023,  0.2305],
         [-0.0022,  0.1770]]])
agent 0 action: VehicleControl(throttle=0.451434, steer=-0.002669, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.92428981065957
21.117805365473032 seconds in game passed.
Action: tensor([[[-0.0024,  0.6302],
         [-0.0024,  0.3366],
         [-0.0023,  0.2305],
         [-0.0022,  0.1770]]])
agent 0 action: VehicleControl(throttle=0.462872, steer=-0.002642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.92428981065957
+++++++++++++: 1.9475707987486839
21.14280536584556 seconds in game passed.
At 21.14280536584556 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.5804e-04,  6.0781e-01],
         [-3.3613e-04,  3.2742e-01],
         [ 1.9184e-04,  2.2397e-01],
         [ 5.8331e-04,  1.7135e-01]]])
agent 0 action: VehicleControl(throttle=0.571350, steer=-0.000348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9475707987486839
Current reward: 0.518754063431297
Current mitigation activation: 0
#############################
Total reward: 58.44304387409087
21.16780536621809 seconds in game passed.
Action: tensor([[[-5.5804e-04,  6.0781e-01],
         [-3.3613e-04,  3.2742e-01],
         [ 1.9184e-04,  2.2397e-01],
         [ 5.8331e-04,  1.7135e-01]]])
agent 0 action: VehicleControl(throttle=0.571768, steer=-0.000683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.44304387409087
21.19280536659062 seconds in game passed.
Action: tensor([[[-5.5804e-04,  6.0781e-01],
         [-3.3613e-04,  3.2742e-01],
         [ 1.9184e-04,  2.2397e-01],
         [ 5.8331e-04,  1.7135e-01]]])
agent 0 action: VehicleControl(throttle=0.581992, steer=-0.000642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.44304387409087
21.217805366963148 seconds in game passed.
Action: tensor([[[-5.5804e-04,  6.0781e-01],
         [-3.3613e-04,  3.2742e-01],
         [ 1.9184e-04,  2.2397e-01],
         [ 5.8331e-04,  1.7135e-01]]])
agent 0 action: VehicleControl(throttle=0.590754, steer=-0.000602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.44304387409087
+++++++++++++: 1.993617101340008
21.242805367335677 seconds in game passed.
At 21.242805367335677 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6099],
         [0.0036, 0.3280],
         [0.0037, 0.2242],
         [0.0034, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.596672, steer=0.003876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.993617101340008
Current reward: 0.5200211066727176
Current mitigation activation: 0
#############################
Total reward: 58.96306498076358
21.267805367708206 seconds in game passed.
Action: tensor([[[0.0033, 0.6099],
         [0.0036, 0.3280],
         [0.0037, 0.2242],
         [0.0034, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.602510, steer=0.003251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.96306498076358
21.292805368080735 seconds in game passed.
Action: tensor([[[0.0033, 0.6099],
         [0.0036, 0.3280],
         [0.0037, 0.2242],
         [0.0034, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.607140, steer=0.003355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.96306498076358
21.317805368453264 seconds in game passed.
Action: tensor([[[0.0033, 0.6099],
         [0.0036, 0.3280],
         [0.0037, 0.2242],
         [0.0034, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.610718, steer=0.003459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.96306498076358
+++++++++++++: 2.03219504480052
21.342805368825793 seconds in game passed.
At 21.342805368825793 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0021, 0.6259],
         [0.0033, 0.3323],
         [0.0031, 0.2263],
         [0.0025, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.628270, steer=0.002863, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.03219504480052
Current reward: 0.5228004469306051
Current mitigation activation: 0
#############################
Total reward: 59.485865427694186
21.367805369198322 seconds in game passed.
Action: tensor([[[0.0021, 0.6259],
         [0.0033, 0.3323],
         [0.0031, 0.2263],
         [0.0025, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.633010, steer=0.003039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.485865427694186
21.39280536957085 seconds in game passed.
Action: tensor([[[0.0021, 0.6259],
         [0.0033, 0.3323],
         [0.0031, 0.2263],
         [0.0025, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.639036, steer=0.003105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.485865427694186
21.41780536994338 seconds in game passed.
Action: tensor([[[0.0021, 0.6259],
         [0.0033, 0.3323],
         [0.0031, 0.2263],
         [0.0025, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.645136, steer=0.003171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.485865427694186
+++++++++++++: 2.068970730966764
21.44280537031591 seconds in game passed.
At 21.44280537031591 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6107],
         [0.0033, 0.3262],
         [0.0032, 0.2224],
         [0.0025, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.716960, steer=0.003105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.068970730966764
Current reward: 0.5261325637542087
Current mitigation activation: 0
#############################
Total reward: 60.011997991448396
21.46780537068844 seconds in game passed.
Action: tensor([[[0.0020, 0.6107],
         [0.0033, 0.3262],
         [0.0032, 0.2224],
         [0.0025, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.718498, steer=0.003118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.011997991448396
21.492805371060967 seconds in game passed.
Action: tensor([[[0.0020, 0.6107],
         [0.0033, 0.3262],
         [0.0032, 0.2224],
         [0.0025, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.726846, steer=0.003119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.011997991448396
21.517805371433496 seconds in game passed.
Action: tensor([[[0.0020, 0.6107],
         [0.0033, 0.3262],
         [0.0032, 0.2224],
         [0.0025, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.735166, steer=0.003121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.011997991448396
+++++++++++++: 2.1073230964349197
21.542805371806026 seconds in game passed.
At 21.542805371806026 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6094],
         [0.0051, 0.3247],
         [0.0052, 0.2209],
         [0.0043, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.786003, steer=0.004417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1073230964349197
Current reward: 0.5295068713798973
Current mitigation activation: 0
#############################
Total reward: 60.54150486282829
21.567805372178555 seconds in game passed.
Action: tensor([[[0.0018, 0.6094],
         [0.0051, 0.3247],
         [0.0052, 0.2209],
         [0.0043, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.790761, steer=0.004218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.54150486282829
21.592805372551084 seconds in game passed.
Action: tensor([[[0.0018, 0.6094],
         [0.0051, 0.3247],
         [0.0052, 0.2209],
         [0.0043, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.799877, steer=0.004232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.54150486282829
21.617805372923613 seconds in game passed.
Action: tensor([[[0.0018, 0.6094],
         [0.0051, 0.3247],
         [0.0052, 0.2209],
         [0.0043, 0.1690]]])
agent 0 action: VehicleControl(throttle=0.808854, steer=0.004247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.54150486282829
+++++++++++++: 2.1467241853115095
21.64280537329614 seconds in game passed.
At 21.64280537329614 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6226],
         [0.0053, 0.3289],
         [0.0057, 0.2227],
         [0.0048, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.800372, steer=0.004530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1467241853115095
Current reward: 0.5329886228013114
Current mitigation activation: 0
#############################
Total reward: 61.0744934856296
21.66780537366867 seconds in game passed.
Action: tensor([[[0.0022, 0.6226],
         [0.0053, 0.3289],
         [0.0057, 0.2227],
         [0.0048, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.809924, steer=0.004509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.0744934856296
21.6928053740412 seconds in game passed.
Action: tensor([[[0.0022, 0.6226],
         [0.0053, 0.3289],
         [0.0057, 0.2227],
         [0.0048, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.817533, steer=0.004531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.0744934856296
21.71780537441373 seconds in game passed.
Action: tensor([[[0.0022, 0.6226],
         [0.0053, 0.3289],
         [0.0057, 0.2227],
         [0.0048, 0.1709]]])
agent 0 action: VehicleControl(throttle=0.824954, steer=0.004553, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.0744934856296
+++++++++++++: 2.187109018743338
21.742805374786258 seconds in game passed.
At 21.742805374786258 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6308],
         [0.0051, 0.3309],
         [0.0050, 0.2240],
         [0.0042, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.842683, steer=0.004930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.187109018743338
Current reward: 0.5365690733702222
Current mitigation activation: 0
#############################
Total reward: 61.611062558999826
21.767805375158787 seconds in game passed.
Action: tensor([[[0.0034, 0.6308],
         [0.0051, 0.3309],
         [0.0050, 0.2240],
         [0.0042, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.848617, steer=0.004913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.611062558999826
21.792805375531316 seconds in game passed.
Action: tensor([[[0.0034, 0.6308],
         [0.0051, 0.3309],
         [0.0050, 0.2240],
         [0.0042, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.855488, steer=0.004952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.611062558999826
21.817805375903845 seconds in game passed.
Action: tensor([[[0.0034, 0.6308],
         [0.0051, 0.3309],
         [0.0050, 0.2240],
         [0.0042, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.862171, steer=0.004991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.611062558999826
+++++++++++++: 2.2276298078047234
21.842805376276374 seconds in game passed.
At 21.842805376276374 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0066, 0.6352],
         [0.0092, 0.3328],
         [0.0096, 0.2245],
         [0.0086, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.830074, steer=0.009368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2276298078047234
Current reward: 0.5403355136941193
Current mitigation activation: 0
#############################
Total reward: 62.151398072693944
21.867805376648903 seconds in game passed.
Action: tensor([[[0.0066, 0.6352],
         [0.0092, 0.3328],
         [0.0096, 0.2245],
         [0.0086, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.815791, steer=0.008765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.151398072693944
21.892805377021432 seconds in game passed.
Action: tensor([[[0.0066, 0.6352],
         [0.0092, 0.3328],
         [0.0096, 0.2245],
         [0.0086, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.798939, steer=0.008873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.151398072693944
21.91780537739396 seconds in game passed.
Action: tensor([[[0.0066, 0.6352],
         [0.0092, 0.3328],
         [0.0096, 0.2245],
         [0.0086, 0.1719]]])
agent 0 action: VehicleControl(throttle=0.781409, steer=0.008982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.151398072693944
+++++++++++++: 2.2381235897334455
21.94280537776649 seconds in game passed.
At 21.94280537776649 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0107, 0.6458],
         [0.0162, 0.3363],
         [0.0177, 0.2259],
         [0.0168, 0.1723]]])
agent 0 action: VehicleControl(throttle=0.742855, steer=0.015993, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2381235897334455
Current reward: 0.5479832413205461
Current mitigation activation: 0
#############################
Total reward: 62.69938131401449
21.96780537813902 seconds in game passed.
Action: tensor([[[0.0107, 0.6458],
         [0.0162, 0.3363],
         [0.0177, 0.2259],
         [0.0168, 0.1723]]])
agent 0 action: VehicleControl(throttle=0.727178, steer=0.015041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.69938131401449
21.992805378511548 seconds in game passed.
Action: tensor([[[0.0107, 0.6458],
         [0.0162, 0.3363],
         [0.0177, 0.2259],
         [0.0168, 0.1723]]])
agent 0 action: VehicleControl(throttle=0.709339, steer=0.015227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.69938131401449
22.017805378884077 seconds in game passed.
Action: tensor([[[0.0107, 0.6458],
         [0.0162, 0.3363],
         [0.0177, 0.2259],
         [0.0168, 0.1723]]])
agent 0 action: VehicleControl(throttle=0.691508, steer=0.015413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.69938131401449
+++++++++++++: 2.23322851437173
22.042805379256606 seconds in game passed.
At 22.042805379256606 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0073, 0.6281],
         [0.0071, 0.3314],
         [0.0072, 0.2246],
         [0.0066, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.673875, steer=0.007415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.23322851437173
Current reward: 0.5573946562117352
Current mitigation activation: 0
#############################
Total reward: 63.25677597022622
22.067805379629135 seconds in game passed.
Action: tensor([[[0.0073, 0.6281],
         [0.0071, 0.3314],
         [0.0072, 0.2246],
         [0.0066, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.656288, steer=0.008879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.25677597022622
22.092805380001664 seconds in game passed.
Action: tensor([[[0.0073, 0.6281],
         [0.0071, 0.3314],
         [0.0072, 0.2246],
         [0.0066, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.638973, steer=0.008991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.25677597022622
22.117805380374193 seconds in game passed.
Action: tensor([[[0.0073, 0.6281],
         [0.0071, 0.3314],
         [0.0072, 0.2246],
         [0.0066, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.622143, steer=0.009103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.25677597022622
+++++++++++++: 2.2307702234064934
22.142805380746722 seconds in game passed.
At 22.142805380746722 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6241],
         [0.0051, 0.3300],
         [0.0050, 0.2239],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.613147, steer=0.006390, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2307702234064934
Current reward: 0.566188833766475
Current mitigation activation: 0
#############################
Total reward: 63.8229648039927
22.16780538111925 seconds in game passed.
Action: tensor([[[0.0040, 0.6241],
         [0.0051, 0.3300],
         [0.0050, 0.2239],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.595486, steer=0.006911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.8229648039927
22.19280538149178 seconds in game passed.
Action: tensor([[[0.0040, 0.6241],
         [0.0051, 0.3300],
         [0.0050, 0.2239],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.579256, steer=0.006971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.8229648039927
22.21780538186431 seconds in game passed.
Action: tensor([[[0.0040, 0.6241],
         [0.0051, 0.3300],
         [0.0050, 0.2239],
         [0.0039, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.563610, steer=0.007031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.8229648039927
+++++++++++++: 2.233073900803759
22.24280538223684 seconds in game passed.
At 22.24280538223684 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0041, 0.6244],
         [0.0056, 0.3293],
         [0.0056, 0.2232],
         [0.0048, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.578800, steer=0.007484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.233073900803759
Current reward: 0.5740611933770188
Current mitigation activation: 0
#############################
Total reward: 64.39702599736971
22.267805382609367 seconds in game passed.
Action: tensor([[[0.0041, 0.6244],
         [0.0056, 0.3293],
         [0.0056, 0.2232],
         [0.0048, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.561602, steer=0.007430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.39702599736971
22.292805382981896 seconds in game passed.
Action: tensor([[[0.0041, 0.6244],
         [0.0056, 0.3293],
         [0.0056, 0.2232],
         [0.0048, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.548226, steer=0.007449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.39702599736971
22.317805383354425 seconds in game passed.
Action: tensor([[[0.0041, 0.6244],
         [0.0056, 0.3293],
         [0.0056, 0.2232],
         [0.0048, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.535298, steer=0.007467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.39702599736971
+++++++++++++: 2.240768944980909
22.342805383726954 seconds in game passed.
At 22.342805383726954 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0030, 0.6130],
         [0.0045, 0.3258],
         [0.0042, 0.2218],
         [0.0032, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.532390, steer=0.006212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.240768944980909
Current reward: 0.5809604399116315
Current mitigation activation: 0
#############################
Total reward: 64.97798643728134
22.367805384099483 seconds in game passed.
Action: tensor([[[0.0030, 0.6130],
         [0.0045, 0.3258],
         [0.0042, 0.2218],
         [0.0032, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.519461, steer=0.006436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.97798643728134
22.392805384472013 seconds in game passed.
Action: tensor([[[0.0030, 0.6130],
         [0.0045, 0.3258],
         [0.0042, 0.2218],
         [0.0032, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.508056, steer=0.006448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.97798643728134
22.41780538484454 seconds in game passed.
Action: tensor([[[0.0030, 0.6130],
         [0.0045, 0.3258],
         [0.0042, 0.2218],
         [0.0032, 0.1699]]])
agent 0 action: VehicleControl(throttle=0.497125, steer=0.006461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.97798643728134
+++++++++++++: 2.2530430590508206
22.44280538521707 seconds in game passed.
At 22.44280538521707 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9579e-03, 6.1385e-01],
         [2.4587e-03, 3.2681e-01],
         [1.8578e-03, 2.2255e-01],
         [5.9862e-04, 1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.459343, steer=0.004589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2530430590508206
Current reward: 0.5870372999673417
Current mitigation activation: 0
#############################
Total reward: 65.56502373724868
22.4678053855896 seconds in game passed.
Action: tensor([[[1.9579e-03, 6.1385e-01],
         [2.4587e-03, 3.2681e-01],
         [1.8578e-03, 2.2255e-01],
         [5.9862e-04, 1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.451235, steer=0.004893, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.56502373724868
22.49280538596213 seconds in game passed.
Action: tensor([[[1.9579e-03, 6.1385e-01],
         [2.4587e-03, 3.2681e-01],
         [1.8578e-03, 2.2255e-01],
         [5.9862e-04, 1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.440871, steer=0.004887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.56502373724868
22.517805386334658 seconds in game passed.
Action: tensor([[[1.9579e-03, 6.1385e-01],
         [2.4587e-03, 3.2681e-01],
         [1.8578e-03, 2.2255e-01],
         [5.9862e-04, 1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.431261, steer=0.004881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.56502373724868
+++++++++++++: 2.269609682306989
22.542805386707187 seconds in game passed.
At 22.542805386707187 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6119],
         [0.0022, 0.3258],
         [0.0018, 0.2222],
         [0.0008, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.438191, steer=0.004717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.269609682306989
Current reward: 0.5923739341321541
Current mitigation activation: 0
#############################
Total reward: 66.15739767138083
22.567805387079716 seconds in game passed.
Action: tensor([[[0.0020, 0.6119],
         [0.0022, 0.3258],
         [0.0018, 0.2222],
         [0.0008, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.427880, steer=0.004720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.15739767138083
22.592805387452245 seconds in game passed.
Action: tensor([[[0.0020, 0.6119],
         [0.0022, 0.3258],
         [0.0018, 0.2222],
         [0.0008, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.419867, steer=0.004699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.15739767138083
22.617805387824774 seconds in game passed.
Action: tensor([[[0.0020, 0.6119],
         [0.0022, 0.3258],
         [0.0018, 0.2222],
         [0.0008, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.412302, steer=0.004677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.15739767138083
+++++++++++++: 2.291173244549435
22.642805388197303 seconds in game passed.
At 22.642805388197303 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6229],
         [0.0044, 0.3297],
         [0.0043, 0.2241],
         [0.0033, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.377304, steer=0.006685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.291173244549435
Current reward: 0.5969264577910667
Current mitigation activation: 0
#############################
Total reward: 66.7543241291719
22.667805388569832 seconds in game passed.
Action: tensor([[[0.0031, 0.6229],
         [0.0044, 0.3297],
         [0.0043, 0.2241],
         [0.0033, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.373503, steer=0.006347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.7543241291719
22.69280538894236 seconds in game passed.
Action: tensor([[[0.0031, 0.6229],
         [0.0044, 0.3297],
         [0.0043, 0.2241],
         [0.0033, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.367263, steer=0.006344, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.7543241291719
22.71780538931489 seconds in game passed.
Action: tensor([[[0.0031, 0.6229],
         [0.0044, 0.3297],
         [0.0043, 0.2241],
         [0.0033, 0.1712]]])
agent 0 action: VehicleControl(throttle=0.361669, steer=0.006341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.7543241291719
+++++++++++++: 2.317126696874451
22.74280538968742 seconds in game passed.
At 22.74280538968742 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6186],
         [0.0056, 0.3296],
         [0.0058, 0.2240],
         [0.0051, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.317074, steer=0.007610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.317126696874451
Current reward: 0.6008423769008608
Current mitigation activation: 0
#############################
Total reward: 67.35516650607276
22.767805390059948 seconds in game passed.
Action: tensor([[[0.0040, 0.6186],
         [0.0056, 0.3296],
         [0.0058, 0.2240],
         [0.0051, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.316188, steer=0.007406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.35516650607276
22.792805390432477 seconds in game passed.
Action: tensor([[[0.0040, 0.6186],
         [0.0056, 0.3296],
         [0.0058, 0.2240],
         [0.0051, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.311728, steer=0.007413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.35516650607276
22.817805390805006 seconds in game passed.
Action: tensor([[[0.0040, 0.6186],
         [0.0056, 0.3296],
         [0.0058, 0.2240],
         [0.0051, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.308038, steer=0.007420, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.35516650607276
+++++++++++++: 2.347795388127835
22.842805391177535 seconds in game passed.
At 22.842805391177535 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6077],
         [0.0021, 0.3274],
         [0.0016, 0.2235],
         [0.0006, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.271538, steer=0.003934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.347795388127835
Current reward: 0.6041407506683797
Current mitigation activation: 0
#############################
Total reward: 67.95930725674114
22.867805391550064 seconds in game passed.
Action: tensor([[[0.0020, 0.6077],
         [0.0021, 0.3274],
         [0.0016, 0.2235],
         [0.0006, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.272931, steer=0.004429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.95930725674114
22.892805391922593 seconds in game passed.
Action: tensor([[[0.0020, 0.6077],
         [0.0021, 0.3274],
         [0.0016, 0.2235],
         [0.0006, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.271575, steer=0.004356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.95930725674114
22.917805392295122 seconds in game passed.
Action: tensor([[[0.0020, 0.6077],
         [0.0021, 0.3274],
         [0.0016, 0.2235],
         [0.0006, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.271225, steer=0.004283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.95930725674114
+++++++++++++: 2.38381363916677
22.94280539266765 seconds in game passed.
At 22.94280539266765 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.0878e-04, 6.1667e-01],
         [1.4270e-03, 3.2810e-01],
         [1.1645e-03, 2.2308e-01],
         [3.0678e-04, 1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.338897, steer=0.003126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.38381363916677
Current reward: 0.6068017840423903
Current mitigation activation: 0
#############################
Total reward: 68.56610904078353
22.96780539304018 seconds in game passed.
Action: tensor([[[6.0878e-04, 6.1667e-01],
         [1.4270e-03, 3.2810e-01],
         [1.1645e-03, 2.2308e-01],
         [3.0678e-04, 1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.334025, steer=0.003138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.56610904078353
22.99280539341271 seconds in game passed.
Action: tensor([[[6.0878e-04, 6.1667e-01],
         [1.4270e-03, 3.2810e-01],
         [1.1645e-03, 2.2308e-01],
         [3.0678e-04, 1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.336732, steer=0.002983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.56610904078353
23.01780539378524 seconds in game passed.
Action: tensor([[[6.0878e-04, 6.1667e-01],
         [1.4270e-03, 3.2810e-01],
         [1.1645e-03, 2.2308e-01],
         [3.0678e-04, 1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.339481, steer=0.002828, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.56610904078353
+++++++++++++: 2.424617642219576
23.042805394157767 seconds in game passed.
At 23.042805394157767 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6252],
         [-0.0009,  0.3301],
         [-0.0015,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.356185, steer=-0.000037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.424617642219576
Current reward: 0.6089724642200032
Current mitigation activation: 0
#############################
Total reward: 69.17508150500353
23.067805394530296 seconds in game passed.
Action: tensor([[[-0.0021,  0.6252],
         [-0.0009,  0.3301],
         [-0.0015,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.357930, steer=0.000325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.17508150500353
23.092805394902825 seconds in game passed.
Action: tensor([[[-0.0021,  0.6252],
         [-0.0009,  0.3301],
         [-0.0015,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.361230, steer=0.000226, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.17508150500353
23.117805395275354 seconds in game passed.
Action: tensor([[[-0.0021,  0.6252],
         [-0.0009,  0.3301],
         [-0.0015,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.364540, steer=0.000127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.17508150500353
+++++++++++++: 2.466364773092047
23.142805395647883 seconds in game passed.
At 23.142805395647883 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6072],
         [-0.0019,  0.3249],
         [-0.0026,  0.2211],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.373170, steer=-0.000763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.466364773092047
Current reward: 0.6111880229587957
Current mitigation activation: 0
#############################
Total reward: 69.78626952796233
23.167805396020412 seconds in game passed.
Action: tensor([[[-0.0023,  0.6072],
         [-0.0019,  0.3249],
         [-0.0026,  0.2211],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.375938, steer=-0.000707, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.78626952796233
23.19280539639294 seconds in game passed.
Action: tensor([[[-0.0023,  0.6072],
         [-0.0019,  0.3249],
         [-0.0026,  0.2211],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.379284, steer=-0.000786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.78626952796233
23.21780539676547 seconds in game passed.
Action: tensor([[[-0.0023,  0.6072],
         [-0.0019,  0.3249],
         [-0.0026,  0.2211],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.382603, steer=-0.000864, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.78626952796233
+++++++++++++: 2.5070816466469545
23.242805397138 seconds in game passed.
At 23.242805397138 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0028,  0.6154],
         [-0.0031,  0.3281],
         [-0.0034,  0.2231],
         [-0.0039,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.355012, steer=-0.001999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5070816466469545
Current reward: 0.6136843746768934
Current mitigation activation: 0
#############################
Total reward: 70.39995390263923
23.26780539751053 seconds in game passed.
Action: tensor([[[-0.0028,  0.6154],
         [-0.0031,  0.3281],
         [-0.0034,  0.2231],
         [-0.0039,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.360858, steer=-0.001920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.39995390263923
23.292805397883058 seconds in game passed.
Action: tensor([[[-0.0028,  0.6154],
         [-0.0031,  0.3281],
         [-0.0034,  0.2231],
         [-0.0039,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.363530, steer=-0.002014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.39995390263923
23.317805398255587 seconds in game passed.
Action: tensor([[[-0.0028,  0.6154],
         [-0.0031,  0.3281],
         [-0.0034,  0.2231],
         [-0.0039,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.366436, steer=-0.002108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.39995390263923
+++++++++++++: 2.5466928069547268
23.342805398628116 seconds in game passed.
At 23.342805398628116 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.9582e-04,  6.0534e-01],
         [-1.2677e-03,  3.2575e-01],
         [-1.3827e-03,  2.2209e-01],
         [-1.6810e-03,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.348177, steer=0.000005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5466928069547268
Current reward: 0.6164411404290271
Current mitigation activation: 0
#############################
Total reward: 71.01639504306826
23.367805399000645 seconds in game passed.
Action: tensor([[[-5.9582e-04,  6.0534e-01],
         [-1.2677e-03,  3.2575e-01],
         [-1.3827e-03,  2.2209e-01],
         [-1.6810e-03,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.353248, steer=-0.000415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.01639504306826
23.392805399373174 seconds in game passed.
Action: tensor([[[-5.9582e-04,  6.0534e-01],
         [-1.2677e-03,  3.2575e-01],
         [-1.3827e-03,  2.2209e-01],
         [-1.6810e-03,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.356223, steer=-0.000474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.01639504306826
23.417805399745703 seconds in game passed.
Action: tensor([[[-5.9582e-04,  6.0534e-01],
         [-1.2677e-03,  3.2575e-01],
         [-1.3827e-03,  2.2209e-01],
         [-1.6810e-03,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.359443, steer=-0.000532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.01639504306826
+++++++++++++: 2.5863568458385884
23.44280540011823 seconds in game passed.
At 23.44280540011823 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.0958e-05,  6.1261e-01],
         [ 1.5467e-04,  3.2848e-01],
         [-1.3547e-04,  2.2346e-01],
         [-7.8156e-04,  1.7019e-01]]])
agent 0 action: VehicleControl(throttle=0.339887, steer=0.000748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5863568458385884
Current reward: 0.6192988819082318
Current mitigation activation: 0
#############################
Total reward: 71.6356939249765
23.46780540049076 seconds in game passed.
Action: tensor([[[ 8.0958e-05,  6.1261e-01],
         [ 1.5467e-04,  3.2848e-01],
         [-1.3547e-04,  2.2346e-01],
         [-7.8156e-04,  1.7019e-01]]])
agent 0 action: VehicleControl(throttle=0.345890, steer=0.000506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.6356939249765
23.49280540086329 seconds in game passed.
Action: tensor([[[ 8.0958e-05,  6.1261e-01],
         [ 1.5467e-04,  3.2848e-01],
         [-1.3547e-04,  2.2346e-01],
         [-7.8156e-04,  1.7019e-01]]])
agent 0 action: VehicleControl(throttle=0.349586, steer=0.000480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.6356939249765
23.51780540123582 seconds in game passed.
Action: tensor([[[ 8.0958e-05,  6.1261e-01],
         [ 1.5467e-04,  3.2848e-01],
         [-1.3547e-04,  2.2346e-01],
         [-7.8156e-04,  1.7019e-01]]])
agent 0 action: VehicleControl(throttle=0.353527, steer=0.000455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.6356939249765
+++++++++++++: 2.626837334221367
23.542805401608348 seconds in game passed.
At 23.542805401608348 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.3393e-04,  6.1515e-01],
         [ 1.8539e-04,  3.2930e-01],
         [-5.1267e-04,  2.2397e-01],
         [-1.4932e-03,  1.7031e-01]]])
agent 0 action: VehicleControl(throttle=0.354144, steer=0.000329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.626837334221367
Current reward: 0.62216625338618
Current mitigation activation: 0
#############################
Total reward: 72.25786017836268
23.567805401980877 seconds in game passed.
Action: tensor([[[-2.3393e-04,  6.1515e-01],
         [ 1.8539e-04,  3.2930e-01],
         [-5.1267e-04,  2.2397e-01],
         [-1.4932e-03,  1.7031e-01]]])
agent 0 action: VehicleControl(throttle=0.358457, steer=0.000321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.25786017836268
23.592805402353406 seconds in game passed.
Action: tensor([[[-2.3393e-04,  6.1515e-01],
         [ 1.8539e-04,  3.2930e-01],
         [-5.1267e-04,  2.2397e-01],
         [-1.4932e-03,  1.7031e-01]]])
agent 0 action: VehicleControl(throttle=0.362486, steer=0.000296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.25786017836268
23.617805402725935 seconds in game passed.
Action: tensor([[[-2.3393e-04,  6.1515e-01],
         [ 1.8539e-04,  3.2930e-01],
         [-5.1267e-04,  2.2397e-01],
         [-1.4932e-03,  1.7031e-01]]])
agent 0 action: VehicleControl(throttle=0.366561, steer=0.000272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.25786017836268
+++++++++++++: 2.668280295260125
23.642805403098464 seconds in game passed.
At 23.642805403098464 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.5553e-03,  6.2460e-01],
         [ 1.0747e-03,  3.3127e-01],
         [ 3.9252e-04,  2.2570e-01],
         [-4.0992e-04,  1.7168e-01]]])
agent 0 action: VehicleControl(throttle=0.396420, steer=0.002382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.668280295260125
Current reward: 0.6250259741515924
Current mitigation activation: 0
#############################
Total reward: 72.88288615251427
23.667805403470993 seconds in game passed.
Action: tensor([[[ 3.5553e-03,  6.2460e-01],
         [ 1.0747e-03,  3.3127e-01],
         [ 3.9252e-04,  2.2570e-01],
         [-4.0992e-04,  1.7168e-01]]])
agent 0 action: VehicleControl(throttle=0.398367, steer=0.002003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.88288615251427
23.692805403843522 seconds in game passed.
Action: tensor([[[ 3.5553e-03,  6.2460e-01],
         [ 1.0747e-03,  3.3127e-01],
         [ 3.9252e-04,  2.2570e-01],
         [-4.0992e-04,  1.7168e-01]]])
agent 0 action: VehicleControl(throttle=0.402890, steer=0.001980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.88288615251427
23.71780540421605 seconds in game passed.
Action: tensor([[[ 3.5553e-03,  6.2460e-01],
         [ 1.0747e-03,  3.3127e-01],
         [ 3.9252e-04,  2.2570e-01],
         [-4.0992e-04,  1.7168e-01]]])
agent 0 action: VehicleControl(throttle=0.407110, steer=0.001956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.88288615251427
+++++++++++++: 2.7097990716087486
23.74280540458858 seconds in game passed.
At 23.74280540458858 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5868e-03,  6.1817e-01],
         [-4.3716e-04,  3.2810e-01],
         [-7.1885e-04,  2.2375e-01],
         [-9.8967e-04,  1.7010e-01]]])
agent 0 action: VehicleControl(throttle=0.460719, steer=0.000019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7097990716087486
Current reward: 0.627980641617396
Current mitigation activation: 0
#############################
Total reward: 73.51086679413167
23.76780540496111 seconds in game passed.
Action: tensor([[[ 1.5868e-03,  6.1817e-01],
         [-4.3716e-04,  3.2810e-01],
         [-7.1885e-04,  2.2375e-01],
         [-9.8967e-04,  1.7010e-01]]])
agent 0 action: VehicleControl(throttle=0.460203, steer=0.000276, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.51086679413167
23.792805405333638 seconds in game passed.
Action: tensor([[[ 1.5868e-03,  6.1817e-01],
         [-4.3716e-04,  3.2810e-01],
         [-7.1885e-04,  2.2375e-01],
         [-9.8967e-04,  1.7010e-01]]])
agent 0 action: VehicleControl(throttle=0.464504, steer=0.000220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.51086679413167
23.817805405706167 seconds in game passed.
Action: tensor([[[ 1.5868e-03,  6.1817e-01],
         [-4.3716e-04,  3.2810e-01],
         [-7.1885e-04,  2.2375e-01],
         [-9.8967e-04,  1.7010e-01]]])
agent 0 action: VehicleControl(throttle=0.468129, steer=0.000164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.51086679413167
+++++++++++++: 2.7493367692894983
23.842805406078696 seconds in game passed.
At 23.842805406078696 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0006,  0.6142],
         [-0.0029,  0.3274],
         [-0.0033,  0.2235],
         [-0.0036,  0.1697]]])
agent 0 action: VehicleControl(throttle=0.456118, steer=-0.002572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7493367692894983
Current reward: 0.6312420143856183
Current mitigation activation: 0
#############################
Total reward: 74.14210880851729
23.867805406451225 seconds in game passed.
Action: tensor([[[-0.0006,  0.6142],
         [-0.0029,  0.3274],
         [-0.0033,  0.2235],
         [-0.0036,  0.1697]]])
agent 0 action: VehicleControl(throttle=0.460553, steer=-0.002173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.14210880851729
23.892805406823754 seconds in game passed.
Action: tensor([[[-0.0006,  0.6142],
         [-0.0029,  0.3274],
         [-0.0033,  0.2235],
         [-0.0036,  0.1697]]])
agent 0 action: VehicleControl(throttle=0.462944, steer=-0.002222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.14210880851729
23.917805407196283 seconds in game passed.
Action: tensor([[[-0.0006,  0.6142],
         [-0.0029,  0.3274],
         [-0.0033,  0.2235],
         [-0.0036,  0.1697]]])
agent 0 action: VehicleControl(throttle=0.465034, steer=-0.002270, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.14210880851729
+++++++++++++: 2.7847510797880757
23.942805407568812 seconds in game passed.
At 23.942805407568812 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.6112],
         [-0.0029,  0.3266],
         [-0.0034,  0.2223],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.465467, steer=-0.002454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7847510797880757
Current reward: 0.6349990989539691
Current mitigation activation: 0
#############################
Total reward: 74.77710790747126
23.96780540794134 seconds in game passed.
Action: tensor([[[-0.0010,  0.6112],
         [-0.0029,  0.3266],
         [-0.0034,  0.2223],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.466268, steer=-0.002470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.77710790747126
23.99280540831387 seconds in game passed.
Action: tensor([[[-0.0010,  0.6112],
         [-0.0029,  0.3266],
         [-0.0034,  0.2223],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.466729, steer=-0.002510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.77710790747126
24.0178054086864 seconds in game passed.
Action: tensor([[[-0.0010,  0.6112],
         [-0.0029,  0.3266],
         [-0.0034,  0.2223],
         [-0.0038,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.466946, steer=-0.002550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.77710790747126
+++++++++++++: 2.8171867775941357
24.04280540905893 seconds in game passed.
At 24.04280540905893 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0043,  0.6137],
         [-0.0066,  0.3279],
         [-0.0073,  0.2228],
         [-0.0078,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.443175, steer=-0.006600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8171867775941357
Current reward: 0.6390822599070691
Current mitigation activation: 0
#############################
Total reward: 75.41619016737833
24.067805409431458 seconds in game passed.
Action: tensor([[[-0.0043,  0.6137],
         [-0.0066,  0.3279],
         [-0.0073,  0.2228],
         [-0.0078,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.445059, steer=-0.005987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.41619016737833
24.092805409803987 seconds in game passed.
Action: tensor([[[-0.0043,  0.6137],
         [-0.0066,  0.3279],
         [-0.0073,  0.2228],
         [-0.0078,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.444371, steer=-0.006039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.41619016737833
24.117805410176516 seconds in game passed.
Action: tensor([[[-0.0043,  0.6137],
         [-0.0066,  0.3279],
         [-0.0073,  0.2228],
         [-0.0078,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.443703, steer=-0.006092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.41619016737833
+++++++++++++: 2.8480369411063413
24.142805410549045 seconds in game passed.
At 24.142805410549045 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.6800e-04,  6.0456e-01],
         [ 1.4532e-04,  3.2512e-01],
         [ 6.0595e-04,  2.2187e-01],
         [ 7.8192e-04,  1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.449344, steer=0.000465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8480369411063413
Current reward: 0.6433130231058076
Current mitigation activation: 0
#############################
Total reward: 76.05950319048414
24.167805410921574 seconds in game passed.
Action: tensor([[[-2.6800e-04,  6.0456e-01],
         [ 1.4532e-04,  3.2512e-01],
         [ 6.0595e-04,  2.2187e-01],
         [ 7.8192e-04,  1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.448002, steer=-0.000600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.05950319048414
24.192805411294103 seconds in game passed.
Action: tensor([[[-2.6800e-04,  6.0456e-01],
         [ 1.4532e-04,  3.2512e-01],
         [ 6.0595e-04,  2.2187e-01],
         [ 7.8192e-04,  1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.447309, steer=-0.000576, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.05950319048414
24.21780541166663 seconds in game passed.
Action: tensor([[[-2.6800e-04,  6.0456e-01],
         [ 1.4532e-04,  3.2512e-01],
         [ 6.0595e-04,  2.2187e-01],
         [ 7.8192e-04,  1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.446552, steer=-0.000553, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.05950319048414
+++++++++++++: 2.8788801521030165
24.24280541203916 seconds in game passed.
At 24.24280541203916 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9605e-04, 6.0353e-01],
         [1.2592e-03, 3.2565e-01],
         [1.5719e-03, 2.2212e-01],
         [1.3257e-03, 1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.415224, steer=0.000488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8788801521030165
Current reward: 0.6475195091792517
Current mitigation activation: 0
#############################
Total reward: 76.70702269966338
24.26780541241169 seconds in game passed.
Action: tensor([[[1.9605e-04, 6.0353e-01],
         [1.2592e-03, 3.2565e-01],
         [1.5719e-03, 2.2212e-01],
         [1.3257e-03, 1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.417665, steer=0.000367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.70702269966338
24.29280541278422 seconds in game passed.
Action: tensor([[[1.9605e-04, 6.0353e-01],
         [1.2592e-03, 3.2565e-01],
         [1.5719e-03, 2.2212e-01],
         [1.3257e-03, 1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.416895, steer=0.000412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.70702269966338
24.317805413156748 seconds in game passed.
Action: tensor([[[1.9605e-04, 6.0353e-01],
         [1.2592e-03, 3.2565e-01],
         [1.5719e-03, 2.2212e-01],
         [1.3257e-03, 1.6846e-01]]])
agent 0 action: VehicleControl(throttle=0.416362, steer=0.000457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.70702269966338
+++++++++++++: 2.9100953045125246
24.342805413529277 seconds in game passed.
At 24.342805413529277 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.5521e-04, 6.0160e-01],
         [1.1685e-03, 3.2494e-01],
         [1.0527e-03, 2.2218e-01],
         [5.7262e-04, 1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.421855, steer=0.000675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9100953045125246
Current reward: 0.6516648415419054
Current mitigation activation: 0
#############################
Total reward: 77.35868754120528
24.367805413901806 seconds in game passed.
Action: tensor([[[8.5521e-04, 6.0160e-01],
         [1.1685e-03, 3.2494e-01],
         [1.0527e-03, 2.2218e-01],
         [5.7262e-04, 1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.421294, steer=0.000667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.35868754120528
24.392805414274335 seconds in game passed.
Action: tensor([[[8.5521e-04, 6.0160e-01],
         [1.1685e-03, 3.2494e-01],
         [1.0527e-03, 2.2218e-01],
         [5.7262e-04, 1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.421415, steer=0.000692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.35868754120528
24.417805414646864 seconds in game passed.
Action: tensor([[[8.5521e-04, 6.0160e-01],
         [1.1685e-03, 3.2494e-01],
         [1.0527e-03, 2.2218e-01],
         [5.7262e-04, 1.6848e-01]]])
agent 0 action: VehicleControl(throttle=0.421566, steer=0.000716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.35868754120528
+++++++++++++: 2.9427168740827594
24.442805415019393 seconds in game passed.
At 24.442805415019393 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.6070],
         [0.0022, 0.3260],
         [0.0023, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.440987, steer=0.002083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9427168740827594
Current reward: 0.6556439222653718
Current mitigation activation: 0
#############################
Total reward: 78.01433146347065
24.467805415391922 seconds in game passed.
Action: tensor([[[0.0023, 0.6070],
         [0.0022, 0.3260],
         [0.0023, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.439629, steer=0.001884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.01433146347065
24.49280541576445 seconds in game passed.
Action: tensor([[[0.0023, 0.6070],
         [0.0022, 0.3260],
         [0.0023, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.440234, steer=0.001909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.01433146347065
24.51780541613698 seconds in game passed.
Action: tensor([[[0.0023, 0.6070],
         [0.0022, 0.3260],
         [0.0023, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.440660, steer=0.001934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.01433146347065
+++++++++++++: 2.976239872622706
24.54280541650951 seconds in game passed.
At 24.54280541650951 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.6125],
         [0.0017, 0.3275],
         [0.0019, 0.2233],
         [0.0020, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.444053, steer=0.001730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.976239872622706
Current reward: 0.6595222598980047
Current mitigation activation: 0
#############################
Total reward: 78.67385372336867
24.567805416882038 seconds in game passed.
Action: tensor([[[0.0027, 0.6125],
         [0.0017, 0.3275],
         [0.0019, 0.2233],
         [0.0020, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.443972, steer=0.001791, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.67385372336867
24.592805417254567 seconds in game passed.
Action: tensor([[[0.0027, 0.6125],
         [0.0017, 0.3275],
         [0.0019, 0.2233],
         [0.0020, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.444093, steer=0.001815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.67385372336867
24.617805417627096 seconds in game passed.
Action: tensor([[[0.0027, 0.6125],
         [0.0017, 0.3275],
         [0.0019, 0.2233],
         [0.0020, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.444083, steer=0.001838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.67385372336867
+++++++++++++: 3.0092448589020373
24.642805417999625 seconds in game passed.
At 24.642805417999625 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.2731e-04,  6.2302e-01],
         [-1.6689e-04,  3.2797e-01],
         [-2.5581e-04,  2.2278e-01],
         [-2.9914e-04,  1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.534403, steer=-0.000484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0092448589020373
Current reward: 0.6634439799180119
Current mitigation activation: 0
#############################
Total reward: 79.33729770328668
24.667805418372154 seconds in game passed.
Action: tensor([[[ 3.2731e-04,  6.2302e-01],
         [-1.6689e-04,  3.2797e-01],
         [-2.5581e-04,  2.2278e-01],
         [-2.9914e-04,  1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.525284, steer=-0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.33729770328668
24.692805418744683 seconds in game passed.
Action: tensor([[[ 3.2731e-04,  6.2302e-01],
         [-1.6689e-04,  3.2797e-01],
         [-2.5581e-04,  2.2278e-01],
         [-2.9914e-04,  1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.525470, steer=-0.000146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.33729770328668
24.717805419117212 seconds in game passed.
Action: tensor([[[ 3.2731e-04,  6.2302e-01],
         [-1.6689e-04,  3.2797e-01],
         [-2.5581e-04,  2.2278e-01],
         [-2.9914e-04,  1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.524807, steer=-0.000169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.33729770328668
+++++++++++++: 3.0409452353910464
24.74280541948974 seconds in game passed.
At 24.74280541948974 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6122],
         [-0.0032,  0.3257],
         [-0.0036,  0.2221],
         [-0.0038,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.494898, steer=-0.003077, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0409452353910464
Current reward: 0.6674671403151973
Current mitigation activation: 0
#############################
Total reward: 80.00476484360188
24.76780541986227 seconds in game passed.
Action: tensor([[[-0.0013,  0.6122],
         [-0.0032,  0.3257],
         [-0.0036,  0.2221],
         [-0.0038,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.495254, steer=-0.002631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.00476484360188
24.7928054202348 seconds in game passed.
Action: tensor([[[-0.0013,  0.6122],
         [-0.0032,  0.3257],
         [-0.0036,  0.2221],
         [-0.0038,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.492302, steer=-0.002664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.00476484360188
24.81780542060733 seconds in game passed.
Action: tensor([[[-0.0013,  0.6122],
         [-0.0032,  0.3257],
         [-0.0036,  0.2221],
         [-0.0038,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.489240, steer=-0.002697, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.00476484360188
+++++++++++++: 3.0683348623167133
24.842805420979857 seconds in game passed.
At 24.842805420979857 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0038,  0.6262],
         [-0.0071,  0.3297],
         [-0.0077,  0.2235],
         [-0.0077,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.483186, steer=-0.006544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0683348623167133
Current reward: 0.6718180062748706
Current mitigation activation: 0
#############################
Total reward: 80.67658284987675
24.867805421352386 seconds in game passed.
Action: tensor([[[-0.0038,  0.6262],
         [-0.0071,  0.3297],
         [-0.0077,  0.2235],
         [-0.0077,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.480419, steer=-0.005955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.67658284987675
24.892805421724916 seconds in game passed.
Action: tensor([[[-0.0038,  0.6262],
         [-0.0071,  0.3297],
         [-0.0077,  0.2235],
         [-0.0077,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.477351, steer=-0.006000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.67658284987675
24.917805422097445 seconds in game passed.
Action: tensor([[[-0.0038,  0.6262],
         [-0.0071,  0.3297],
         [-0.0077,  0.2235],
         [-0.0077,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.474282, steer=-0.006044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.67658284987675
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:08:51 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:09:37 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 46.26s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.43s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.506               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 80.68, average_reward: 80.67658284987675 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00009/fi_lead_slowdown_data
