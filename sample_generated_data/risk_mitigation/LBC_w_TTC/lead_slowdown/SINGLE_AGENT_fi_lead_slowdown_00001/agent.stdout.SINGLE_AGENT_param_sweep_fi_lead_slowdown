New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185945-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185945-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185945-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185945-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185945-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185945-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 27.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 27}
1.5184086300432682 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003143, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5434086304157972 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5684086307883263 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5934086311608553 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6184086315333843 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6434086319059134 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0053, 0.5907],
         [0.0028, 0.3227],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.6684086322784424 seconds in game passed.
Action: tensor([[[0.0053, 0.5907],
         [0.0028, 0.3227],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6934086326509714 seconds in game passed.
Action: tensor([[[0.0053, 0.5907],
         [0.0028, 0.3227],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003733, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7184086330235004 seconds in game passed.
Action: tensor([[[0.0053, 0.5907],
         [0.0028, 0.3227],
         [0.0027, 0.2227],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7434086333960295 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7684086337685585 seconds in game passed.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7934086341410875 seconds in game passed.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8184086345136166 seconds in game passed.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8434086348861456 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8684086352586746 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002612, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8934086356312037 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9184086360037327 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002665, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9434086363762617 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9684086367487907 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9934086371213198 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.018408637493849 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.043408637866378 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4575e-03, 5.9042e-01],
         [1.3512e-03, 3.2228e-01],
         [1.1200e-03, 2.2209e-01],
         [5.7362e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.068408638238907 seconds in game passed.
Action: tensor([[[2.4575e-03, 5.9042e-01],
         [1.3512e-03, 3.2228e-01],
         [1.1200e-03, 2.2209e-01],
         [5.7362e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.093408638611436 seconds in game passed.
Action: tensor([[[2.4575e-03, 5.9042e-01],
         [1.3512e-03, 3.2228e-01],
         [1.1200e-03, 2.2209e-01],
         [5.7362e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.118408638983965 seconds in game passed.
Action: tensor([[[2.4575e-03, 5.9042e-01],
         [1.3512e-03, 3.2228e-01],
         [1.1200e-03, 2.2209e-01],
         [5.7362e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.143408639356494 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.168408639729023 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.193408640101552 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.218408640474081 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.24340864084661 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.268408641219139 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.293408641591668 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.318408641964197 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.343408642336726 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.368408642709255 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3934086430817842 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002714, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4184086434543133 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002736, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.4434086438268423 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4684086441993713 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4934086445719004 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5184086449444294 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5434086453169584 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5684086456894875 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5934086460620165 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6184086464345455 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6434086468070745 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6684086471796036 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6934086475521326 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7184086479246616 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7434086482971907 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.7684086486697197 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7934086490422487 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8184086494147778 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0016, 0.3214],
         [0.0015, 0.2215],
         [0.0008, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.843408649787307 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.868408650159836 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.893408650532365 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.918408650904894 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.943408651277423 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.968408651649952 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.993408652022481 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.01840865239501 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.043408652767539 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002553, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.068408653140068 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.093408653512597 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.118408653885126 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0017, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.143408654257655 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.168408654630184 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.193408655002713 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2184086553752422 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.2434086557477713 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.2684086561203003 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2934086564928293 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3184086568653584 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3434086572378874 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3684086576104164 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3934086579829454 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4184086583554745 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4434086587280035 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4684086591005325 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4934086594730616 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5184086598455906 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5434086602181196 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5684086605906487 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5934086609631777 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6184086613357067 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6434086617082357 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6684086620807648 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.693408662453294 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.718408662825823 seconds in game passed.
Action: tensor([[[0.0017, 0.5872],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.743408663198352 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.768408663570881 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.79340866394341 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.818408664315939 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.843408664688468 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.868408665060997 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.893408665433526 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.918408665806055 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3210],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.943408666178584 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.968408666551113 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.993408666923642 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.018408667296171 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.0434086676687 seconds in game passed.
At 4.0434086676687 seconds, saving state-action tuples.
Action: tensor([[[1.4095e-03, 5.8610e-01],
         [1.1332e-03, 3.2069e-01],
         [9.9716e-04, 2.2101e-01],
         [3.4310e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.068408668041229 seconds in game passed.
Action: tensor([[[1.4095e-03, 5.8610e-01],
         [1.1332e-03, 3.2069e-01],
         [9.9716e-04, 2.2101e-01],
         [3.4310e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.093408668413758 seconds in game passed.
Action: tensor([[[1.4095e-03, 5.8610e-01],
         [1.1332e-03, 3.2069e-01],
         [9.9716e-04, 2.2101e-01],
         [3.4310e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.118408668786287 seconds in game passed.
Action: tensor([[[1.4095e-03, 5.8610e-01],
         [1.1332e-03, 3.2069e-01],
         [9.9716e-04, 2.2101e-01],
         [3.4310e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.88373051633521
4.143408669158816 seconds in game passed.
At 4.143408669158816 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760848520400644
Current mitigation activation: 0
#############################
Total reward: 0.6561255113146287
4.168408669531345 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
4.193408669903874 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
4.218408670276403 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.6561255113146287
+++++++++++++: 8.843383940473686
4.2434086706489325 seconds in game passed.
At 4.2434086706489325 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383940473686
Current reward: 0.49259321983288007
Current mitigation activation: 0
#############################
Total reward: 1.1487187311475089
4.2684086710214615 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.2934086713939905 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
4.3184086717665195 seconds in game passed.
Action: tensor([[[0.0023, 0.5818],
         [0.0024, 0.3200],
         [0.0026, 0.2210],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487187311475089
+++++++++++++: 7.228544635198918
4.343408672139049 seconds in game passed.
At 4.343408672139049 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228544635198918
Current reward: 0.5118171169699093
Current mitigation activation: 0
#############################
Total reward: 1.6605358481174182
4.368408672511578 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605358481174182
4.393408672884107 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605358481174182
4.418408673256636 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605358481174182
+++++++++++++: 6.2159331184388575
4.443408673629165 seconds in game passed.
At 4.443408673629165 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.2159331184388575
Current reward: 0.5264941465786098
Current mitigation activation: 0
#############################
Total reward: 2.187029994696028
4.468408674001694 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029994696028
4.493408674374223 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002899, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029994696028
4.518408674746752 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029994696028
+++++++++++++: 5.508365853638963
4.543408675119281 seconds in game passed.
At 4.543408675119281 seconds, saving state-action tuples.
Action: tensor([[[-9.7916e-05,  5.8865e-01],
         [ 1.4635e-04,  3.2202e-01],
         [ 2.6718e-04,  2.2122e-01],
         [-1.0619e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508365853638963
Current reward: 0.537623498978236
Current mitigation activation: 0
#############################
Total reward: 2.724653493674264
4.56840867549181 seconds in game passed.
Action: tensor([[[-9.7916e-05,  5.8865e-01],
         [ 1.4635e-04,  3.2202e-01],
         [ 2.6718e-04,  2.2122e-01],
         [-1.0619e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653493674264
4.593408675864339 seconds in game passed.
Action: tensor([[[-9.7916e-05,  5.8865e-01],
         [ 1.4635e-04,  3.2202e-01],
         [ 2.6718e-04,  2.2122e-01],
         [-1.0619e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000864, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653493674264
4.618408676236868 seconds in game passed.
Action: tensor([[[-9.7916e-05,  5.8865e-01],
         [ 1.4635e-04,  3.2202e-01],
         [ 2.6718e-04,  2.2122e-01],
         [-1.0619e-04,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000846, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653493674264
+++++++++++++: 4.9761342678197185
4.643408676609397 seconds in game passed.
At 4.643408676609397 seconds, saving state-action tuples.
Action: tensor([[[ 2.2322e-04,  5.8917e-01],
         [-3.8522e-04,  3.2134e-01],
         [-2.9907e-04,  2.2101e-01],
         [-4.6030e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.9761342678197185
Current reward: 0.5459292659195056
Current mitigation activation: 0
#############################
Total reward: 3.2705827595937698
4.668408676981926 seconds in game passed.
Action: tensor([[[ 2.2322e-04,  5.8917e-01],
         [-3.8522e-04,  3.2134e-01],
         [-2.9907e-04,  2.2101e-01],
         [-4.6030e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705827595937698
4.693408677354455 seconds in game passed.
Action: tensor([[[ 2.2322e-04,  5.8917e-01],
         [-3.8522e-04,  3.2134e-01],
         [-2.9907e-04,  2.2101e-01],
         [-4.6030e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705827595937698
4.718408677726984 seconds in game passed.
Action: tensor([[[ 2.2322e-04,  5.8917e-01],
         [-3.8522e-04,  3.2134e-01],
         [-2.9907e-04,  2.2101e-01],
         [-4.6030e-04,  1.6748e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705827595937698
+++++++++++++: 4.552585584603673
4.743408678099513 seconds in game passed.
At 4.743408678099513 seconds, saving state-action tuples.
Action: tensor([[[-3.0726e-04,  5.9095e-01],
         [-9.8801e-04,  3.2155e-01],
         [-8.6666e-04,  2.2107e-01],
         [-1.0095e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552585584603673
Current reward: 0.5519989036455549
Current mitigation activation: 0
#############################
Total reward: 3.822581663239325
4.768408678472042 seconds in game passed.
Action: tensor([[[-3.0726e-04,  5.9095e-01],
         [-9.8801e-04,  3.2155e-01],
         [-8.6666e-04,  2.2107e-01],
         [-1.0095e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.822581663239325
4.793408678844571 seconds in game passed.
Action: tensor([[[-3.0726e-04,  5.9095e-01],
         [-9.8801e-04,  3.2155e-01],
         [-8.6666e-04,  2.2107e-01],
         [-1.0095e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.822581663239325
4.8184086792171 seconds in game passed.
Action: tensor([[[-3.0726e-04,  5.9095e-01],
         [-9.8801e-04,  3.2155e-01],
         [-8.6666e-04,  2.2107e-01],
         [-1.0095e-03,  1.6744e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.822581663239325
+++++++++++++: 4.199609653749305
4.843408679589629 seconds in game passed.
At 4.843408679589629 seconds, saving state-action tuples.
Action: tensor([[[ 5.0963e-04,  5.9008e-01],
         [-5.4716e-04,  3.2161e-01],
         [-4.0430e-04,  2.2125e-01],
         [-4.1831e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199609653749305
Current reward: 0.5563326550427872
Current mitigation activation: 0
#############################
Total reward: 4.378914318282112
4.868408679962158 seconds in game passed.
Action: tensor([[[ 5.0963e-04,  5.9008e-01],
         [-5.4716e-04,  3.2161e-01],
         [-4.0430e-04,  2.2125e-01],
         [-4.1831e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914318282112
4.893408680334687 seconds in game passed.
Action: tensor([[[ 5.0963e-04,  5.9008e-01],
         [-5.4716e-04,  3.2161e-01],
         [-4.0430e-04,  2.2125e-01],
         [-4.1831e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 4.378914318282112
4.918408680707216 seconds in game passed.
Action: tensor([[[ 5.0963e-04,  5.9008e-01],
         [-5.4716e-04,  3.2161e-01],
         [-4.0430e-04,  2.2125e-01],
         [-4.1831e-04,  1.6777e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914318282112
+++++++++++++: 3.89475956116383
4.943408681079745 seconds in game passed.
At 4.943408681079745 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.89475956116383
Current reward: 0.5593082003948288
Current mitigation activation: 0
#############################
Total reward: 4.93822251867694
4.968408681452274 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.93822251867694
4.993408681824803 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.93822251867694
5.018408682197332 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0007, 0.3215],
         [0.0011, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.93822251867694
+++++++++++++: 3.6246731449700413
5.043408682569861 seconds in game passed.
At 5.043408682569861 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3140e-03, 5.8981e-01],
         [1.0778e-03, 3.2206e-01],
         [9.4116e-04, 2.2278e-01],
         [5.8070e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6246731449700413
Current reward: 0.561177100124197
Current mitigation activation: 0
#############################
Total reward: 5.499399618801137
5.06840868294239 seconds in game passed.
Action: tensor([[[1.3140e-03, 5.8981e-01],
         [1.0778e-03, 3.2206e-01],
         [9.4116e-04, 2.2278e-01],
         [5.8070e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399618801137
5.0934086833149195 seconds in game passed.
Action: tensor([[[1.3140e-03, 5.8981e-01],
         [1.0778e-03, 3.2206e-01],
         [9.4116e-04, 2.2278e-01],
         [5.8070e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399618801137
5.1184086836874485 seconds in game passed.
Action: tensor([[[1.3140e-03, 5.8981e-01],
         [1.0778e-03, 3.2206e-01],
         [9.4116e-04, 2.2278e-01],
         [5.8070e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399618801137
+++++++++++++: 3.380481635661648
5.1434086840599775 seconds in game passed.
At 5.1434086840599775 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380481635661648
Current reward: 0.5621374409795563
Current mitigation activation: 0
#############################
Total reward: 6.061537059780694
5.168408684432507 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537059780694
5.193408684805036 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537059780694
5.218408685177565 seconds in game passed.
Action: tensor([[[0.0018, 0.5876],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061537059780694
+++++++++++++: 3.1565682077749084
5.243408685550094 seconds in game passed.
At 5.243408685550094 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1565682077749084
Current reward: 0.5623125761971145
Current mitigation activation: 0
#############################
Total reward: 6.623849635977808
5.268408685922623 seconds in game passed.
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849635977808
5.293408686295152 seconds in game passed.
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849635977808
5.318408686667681 seconds in game passed.
Action: tensor([[[0.0025, 0.5946],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0016, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849635977808
+++++++++++++: 2.9489486045113904
5.34340868704021 seconds in game passed.
At 5.34340868704021 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9489486045113904
Current reward: 0.5617967613241761
Current mitigation activation: 0
#############################
Total reward: 7.185646397301984
5.368408687412739 seconds in game passed.
Action: tensor([[[0.0022, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646397301984
5.393408687785268 seconds in game passed.
Action: tensor([[[0.0022, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646397301984
5.418408688157797 seconds in game passed.
Action: tensor([[[0.0022, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002916, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646397301984
+++++++++++++: 2.7880636939703614
5.443408688530326 seconds in game passed.
At 5.443408688530326 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.0680e-04,  5.8804e-01],
         [ 1.3699e-04,  3.2090e-01],
         [-1.8753e-05,  2.2104e-01],
         [-3.3352e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7880636939703614
Current reward: 0.5575288765619892
Current mitigation activation: 0
#############################
Total reward: 7.743175273863974
5.468408688902855 seconds in game passed.
Action: tensor([[[ 9.0680e-04,  5.8804e-01],
         [ 1.3699e-04,  3.2090e-01],
         [-1.8753e-05,  2.2104e-01],
         [-3.3352e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175273863974
5.493408689275384 seconds in game passed.
Action: tensor([[[ 9.0680e-04,  5.8804e-01],
         [ 1.3699e-04,  3.2090e-01],
         [-1.8753e-05,  2.2104e-01],
         [-3.3352e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175273863974
5.518408689647913 seconds in game passed.
Action: tensor([[[ 9.0680e-04,  5.8804e-01],
         [ 1.3699e-04,  3.2090e-01],
         [-1.8753e-05,  2.2104e-01],
         [-3.3352e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175273863974
+++++++++++++: 2.6913210746399905
5.543408690020442 seconds in game passed.
At 5.543408690020442 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0030,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6913210746399905
Current reward: 0.5472018565255001
Current mitigation activation: 0
#############################
Total reward: 8.290377130389475
5.568408690392971 seconds in game passed.
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0030,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377130389475
5.5934086907655 seconds in game passed.
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0030,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377130389475
5.618408691138029 seconds in game passed.
Action: tensor([[[-0.0010,  0.5935],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0030,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290377130389475
+++++++++++++: 2.595023601528374
5.643408691510558 seconds in game passed.
At 5.643408691510558 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.595023601528374
Current reward: 0.5368278318821259
Current mitigation activation: 0
#############################
Total reward: 8.827204962271601
5.668408691883087 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204962271601
5.693408692255616 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204962271601
5.718408692628145 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204962271601
+++++++++++++: 2.4986319002794293
5.743408693000674 seconds in game passed.
At 5.743408693000674 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0050,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4986319002794293
Current reward: 0.526462341986641
Current mitigation activation: 0
#############################
Total reward: 9.353667304258241
5.768408693373203 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0050,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667304258241
5.793408693745732 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0050,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667304258241
5.818408694118261 seconds in game passed.
Action: tensor([[[-0.0026,  0.5955],
         [-0.0045,  0.3232],
         [-0.0050,  0.2219],
         [-0.0054,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003543, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667304258241
+++++++++++++: 2.4021935153279905
5.84340869449079 seconds in game passed.
At 5.84340869449079 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6301e-04,  5.9067e-01],
         [-7.3997e-04,  3.2180e-01],
         [-7.6766e-04,  2.2151e-01],
         [-9.8159e-04,  1.6820e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4021935153279905
Current reward: 0.5161007084604978
Current mitigation activation: 0
#############################
Total reward: 9.869768012718739
5.868408694863319 seconds in game passed.
Action: tensor([[[-1.6301e-04,  5.9067e-01],
         [-7.3997e-04,  3.2180e-01],
         [-7.6766e-04,  2.2151e-01],
         [-9.8159e-04,  1.6820e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869768012718739
5.893408695235848 seconds in game passed.
Action: tensor([[[-1.6301e-04,  5.9067e-01],
         [-7.3997e-04,  3.2180e-01],
         [-7.6766e-04,  2.2151e-01],
         [-9.8159e-04,  1.6820e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869768012718739
5.9184086956083775 seconds in game passed.
Action: tensor([[[-1.6301e-04,  5.9067e-01],
         [-7.3997e-04,  3.2180e-01],
         [-7.6766e-04,  2.2151e-01],
         [-9.8159e-04,  1.6820e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869768012718739
+++++++++++++: 2.273733135311351
5.9434086959809065 seconds in game passed.
At 5.9434086959809065 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.9663e-06,  5.9316e-01],
         [ 2.1274e-04,  3.2264e-01],
         [ 2.6138e-04,  2.2194e-01],
         [-1.0992e-04,  1.6852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.273733135311351
Current reward: 0.5093356770754259
Current mitigation activation: 0
#############################
Total reward: 10.379103689794164
5.9684086963534355 seconds in game passed.
Action: tensor([[[ 6.9663e-06,  5.9316e-01],
         [ 2.1274e-04,  3.2264e-01],
         [ 2.6138e-04,  2.2194e-01],
         [-1.0992e-04,  1.6852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103689794164
5.9934086967259645 seconds in game passed.
Action: tensor([[[ 6.9663e-06,  5.9316e-01],
         [ 2.1274e-04,  3.2264e-01],
         [ 2.6138e-04,  2.2194e-01],
         [-1.0992e-04,  1.6852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103689794164
6.018408697098494 seconds in game passed.
Action: tensor([[[ 6.9663e-06,  5.9316e-01],
         [ 2.1274e-04,  3.2264e-01],
         [ 2.6138e-04,  2.2194e-01],
         [-1.0992e-04,  1.6852e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103689794164
+++++++++++++: 2.0694008991176105
6.043408697471023 seconds in game passed.
At 6.043408697471023 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0694008991176105
Current reward: 0.5122396593493599
Current mitigation activation: 0
#############################
Total reward: 10.891343349143524
6.068408697843552 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.872705, steer=0.003266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343349143524
6.093408698216081 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.819872, steer=0.003293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343349143524
6.11840869858861 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3259],
         [0.0034, 0.2244],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.768213, steer=0.003320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343349143524
+++++++++++++: 1.8865370881791312
6.143408698961139 seconds in game passed.
At 6.143408698961139 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2342],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.466769, steer=0.002032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865370881791312
Current reward: 0.5134807762285818
Current mitigation activation: 0
#############################
Total reward: 11.404824125372105
6.168408699333668 seconds in game passed.
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2342],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.441582, steer=0.002251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824125372105
6.193408699706197 seconds in game passed.
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2342],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.392113, steer=0.002254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824125372105
6.218408700078726 seconds in game passed.
Action: tensor([[[0.0020, 0.6211],
         [0.0025, 0.3401],
         [0.0020, 0.2342],
         [0.0008, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.363038, steer=0.002257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824125372105
+++++++++++++: 1.7242962701819358
6.243408700451255 seconds in game passed.
At 6.243408700451255 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.4929e-04,  6.3464e-01],
         [ 1.0997e-05,  3.4369e-01],
         [-6.9086e-04,  2.3581e-01],
         [-1.7988e-03,  1.8015e-01]]])
agent 0 action: VehicleControl(throttle=0.352138, steer=-0.000149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7242962701819358
Current reward: 0.5125370408154326
Current mitigation activation: 0
#############################
Total reward: 11.917361166187538
6.268408700823784 seconds in game passed.
Action: tensor([[[ 5.4929e-04,  6.3464e-01],
         [ 1.0997e-05,  3.4369e-01],
         [-6.9086e-04,  2.3581e-01],
         [-1.7988e-03,  1.8015e-01]]])
agent 0 action: VehicleControl(throttle=0.339517, steer=0.000225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917361166187538
6.293408701196313 seconds in game passed.
Action: tensor([[[ 5.4929e-04,  6.3464e-01],
         [ 1.0997e-05,  3.4369e-01],
         [-6.9086e-04,  2.3581e-01],
         [-1.7988e-03,  1.8015e-01]]])
agent 0 action: VehicleControl(throttle=0.327313, steer=0.000202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917361166187538
6.318408701568842 seconds in game passed.
Action: tensor([[[ 5.4929e-04,  6.3464e-01],
         [ 1.0997e-05,  3.4369e-01],
         [-6.9086e-04,  2.3581e-01],
         [-1.7988e-03,  1.8015e-01]]])
agent 0 action: VehicleControl(throttle=0.315524, steer=0.000179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917361166187538
+++++++++++++: 1.5889213830397324
6.343408701941371 seconds in game passed.
At 6.343408701941371 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3523e-03,  6.5352e-01],
         [-6.2355e-04,  3.5207e-01],
         [-1.7596e-03,  2.4157e-01],
         [-2.9704e-03,  1.8437e-01]]])
agent 0 action: VehicleControl(throttle=0.304517, steer=0.000000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5889213830397324
Current reward: 0.5075420482230438
Current mitigation activation: 0
#############################
Total reward: 12.424903214410582
6.3684087023139 seconds in game passed.
Action: tensor([[[ 1.3523e-03,  6.5352e-01],
         [-6.2355e-04,  3.5207e-01],
         [-1.7596e-03,  2.4157e-01],
         [-2.9704e-03,  1.8437e-01]]])
agent 0 action: VehicleControl(throttle=0.293919, steer=-0.000005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424903214410582
6.393408702686429 seconds in game passed.
Action: tensor([[[ 1.3523e-03,  6.5352e-01],
         [-6.2355e-04,  3.5207e-01],
         [-1.7596e-03,  2.4157e-01],
         [-2.9704e-03,  1.8437e-01]]])
agent 0 action: VehicleControl(throttle=0.283274, steer=-0.000034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424903214410582
6.418408703058958 seconds in game passed.
Action: tensor([[[ 1.3523e-03,  6.5352e-01],
         [-6.2355e-04,  3.5207e-01],
         [-1.7596e-03,  2.4157e-01],
         [-2.9704e-03,  1.8437e-01]]])
agent 0 action: VehicleControl(throttle=0.272603, steer=-0.000064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424903214410582
+++++++++++++: 1.477771239180799
6.443408703431487 seconds in game passed.
At 6.443408703431487 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6676],
         [-0.0048,  0.3562],
         [-0.0062,  0.2426],
         [-0.0072,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.261848, steer=-0.004357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.477771239180799
Current reward: 0.49812234147805123
Current mitigation activation: 0
#############################
Total reward: 12.923025555888634
6.468408703804016 seconds in game passed.
Action: tensor([[[-0.0015,  0.6676],
         [-0.0048,  0.3562],
         [-0.0062,  0.2426],
         [-0.0072,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.251074, steer=-0.003697, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923025555888634
6.493408704176545 seconds in game passed.
Action: tensor([[[-0.0015,  0.6676],
         [-0.0048,  0.3562],
         [-0.0062,  0.2426],
         [-0.0072,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.240281, steer=-0.003746, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923025555888634
6.518408704549074 seconds in game passed.
Action: tensor([[[-0.0015,  0.6676],
         [-0.0048,  0.3562],
         [-0.0062,  0.2426],
         [-0.0072,  0.1848]]])
agent 0 action: VehicleControl(throttle=0.229469, steer=-0.003794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.923025555888634
+++++++++++++: 1.3816333377136198
6.543408704921603 seconds in game passed.
At 6.543408704921603 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.1187e-04,  6.8526e-01],
         [-4.0659e-03,  3.6679e-01],
         [-5.8257e-03,  2.5092e-01],
         [-7.1207e-03,  1.9103e-01]]])
agent 0 action: VehicleControl(throttle=0.218687, steer=-0.002770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3816333377136198
Current reward: 0.48559944981039865
Current mitigation activation: 0
#############################
Total reward: 13.408625005699033
6.568408705294132 seconds in game passed.
Action: tensor([[[-3.1187e-04,  6.8526e-01],
         [-4.0659e-03,  3.6679e-01],
         [-5.8257e-03,  2.5092e-01],
         [-7.1207e-03,  1.9103e-01]]])
agent 0 action: VehicleControl(throttle=0.207886, steer=-0.002955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408625005699033
6.593408705666661 seconds in game passed.
Action: tensor([[[-3.1187e-04,  6.8526e-01],
         [-4.0659e-03,  3.6679e-01],
         [-5.8257e-03,  2.5092e-01],
         [-7.1207e-03,  1.9103e-01]]])
agent 0 action: VehicleControl(throttle=0.197066, steer=-0.002968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408625005699033
6.61840870603919 seconds in game passed.
Action: tensor([[[-3.1187e-04,  6.8526e-01],
         [-4.0659e-03,  3.6679e-01],
         [-5.8257e-03,  2.5092e-01],
         [-7.1207e-03,  1.9103e-01]]])
agent 0 action: VehicleControl(throttle=0.186228, steer=-0.002980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408625005699033
+++++++++++++: 1.2942979192198318
6.643408706411719 seconds in game passed.
At 6.643408706411719 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.3510e-04,  1.0000e+00],
         [-4.6190e-03,  1.0000e+00],
         [-5.8400e-03,  1.0000e+00],
         [-6.4045e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002964, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2942979192198318
Current reward: 0.47108220736708706
Current mitigation activation: 1
#############################
Total reward: 13.87970721306612
6.668408706784248 seconds in game passed.
Action: tensor([[[-3.3510e-04,  1.0000e+00],
         [-4.6190e-03,  1.0000e+00],
         [-5.8400e-03,  1.0000e+00],
         [-6.4045e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002960, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87970721306612
6.693408707156777 seconds in game passed.
Action: tensor([[[-3.3510e-04,  1.0000e+00],
         [-4.6190e-03,  1.0000e+00],
         [-5.8400e-03,  1.0000e+00],
         [-6.4045e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002953, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87970721306612
6.718408707529306 seconds in game passed.
Action: tensor([[[-3.3510e-04,  1.0000e+00],
         [-4.6190e-03,  1.0000e+00],
         [-5.8400e-03,  1.0000e+00],
         [-6.4045e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002947, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87970721306612
+++++++++++++: 1.2146710101532527
6.743408707901835 seconds in game passed.
At 6.743408707901835 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000780, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2146710101532527
Current reward: 0.45471185750148
Current mitigation activation: 1
#############################
Total reward: 14.334419070567598
6.7684087082743645 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001101, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334419070567598
6.7934087086468935 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001067, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334419070567598
6.8184087090194225 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0039,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001032, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334419070567598
+++++++++++++: 1.1618722045836611
6.843408709391952 seconds in game passed.
At 6.843408709391952 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.7740e-03,  1.0000e+00],
         [ 9.5559e-04,  1.0000e+00],
         [-1.3165e-03,  1.0000e+00],
         [-1.3551e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006153, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1618722045836611
Current reward: 0.43191501149519584
Current mitigation activation: 1
#############################
Total reward: 14.766334082062794
6.868408709764481 seconds in game passed.
Action: tensor([[[ 8.7740e-03,  1.0000e+00],
         [ 9.5559e-04,  1.0000e+00],
         [-1.3165e-03,  1.0000e+00],
         [-1.3551e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005037, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766334082062794
6.89340871013701 seconds in game passed.
Action: tensor([[[ 8.7740e-03,  1.0000e+00],
         [ 9.5559e-04,  1.0000e+00],
         [-1.3165e-03,  1.0000e+00],
         [-1.3551e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005107, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766334082062794
6.918408710509539 seconds in game passed.
Action: tensor([[[ 8.7740e-03,  1.0000e+00],
         [ 9.5559e-04,  1.0000e+00],
         [-1.3165e-03,  1.0000e+00],
         [-1.3551e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005178, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766334082062794
+++++++++++++: 1.143315157916467
6.943408710882068 seconds in game passed.
At 6.943408710882068 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0128,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0057,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011674, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.143315157916467
Current reward: 0.4017326229465482
Current mitigation activation: 1
#############################
Total reward: 15.168066705009343
6.968408711254597 seconds in game passed.
Action: tensor([[[-0.0128,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0057,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008996, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168066705009343
6.993408711627126 seconds in game passed.
Action: tensor([[[-0.0128,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0057,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009108, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168066705009343
7.018408711999655 seconds in game passed.
Action: tensor([[[-0.0128,  1.0000],
         [-0.0041,  1.0000],
         [-0.0060,  1.0000],
         [-0.0057,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009220, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168066705009343
+++++++++++++: 1.1453421257265677
7.043408712372184 seconds in game passed.
At 7.043408712372184 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0129,  1.0000],
         [-0.0075,  1.0000],
         [-0.0088,  1.0000],
         [-0.0084,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011632, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1453421257265677
Current reward: 0.3690083443780169
Current mitigation activation: 1
#############################
Total reward: 15.53707504938736
7.068408712744713 seconds in game passed.
Action: tensor([[[-0.0129,  1.0000],
         [-0.0075,  1.0000],
         [-0.0088,  1.0000],
         [-0.0084,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011434, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53707504938736
7.093408713117242 seconds in game passed.
Action: tensor([[[-0.0129,  1.0000],
         [-0.0075,  1.0000],
         [-0.0088,  1.0000],
         [-0.0084,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011608, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53707504938736
7.118408713489771 seconds in game passed.
Action: tensor([[[-0.0129,  1.0000],
         [-0.0075,  1.0000],
         [-0.0088,  1.0000],
         [-0.0084,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011783, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.53707504938736
+++++++++++++: 1.1650259962900258
7.1434087138623 seconds in game passed.
At 7.1434087138623 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0087,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016307, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1650259962900258
Current reward: 0.33575290455024565
Current mitigation activation: 1
#############################
Total reward: 15.872827953937605
7.168408714234829 seconds in game passed.
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0087,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015793, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872827953937605
7.193408714607358 seconds in game passed.
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0087,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.015999, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872827953937605
7.218408714979887 seconds in game passed.
Action: tensor([[[-0.0161,  1.0000],
         [-0.0112,  1.0000],
         [-0.0087,  1.0000],
         [-0.0050,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016205, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872827953937605
+++++++++++++: 1.2049735681309297
7.243408715352416 seconds in game passed.
At 7.243408715352416 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0131,  1.0000],
         [-0.0162,  1.0000],
         [-0.0208,  1.0000],
         [-0.0219,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017665, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2049735681309297
Current reward: 0.30276343328850297
Current mitigation activation: 1
#############################
Total reward: 16.17559138722611
7.268408715724945 seconds in game passed.
Action: tensor([[[-0.0131,  1.0000],
         [-0.0162,  1.0000],
         [-0.0208,  1.0000],
         [-0.0219,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017649, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.17559138722611
7.293408716097474 seconds in game passed.
Action: tensor([[[-0.0131,  1.0000],
         [-0.0162,  1.0000],
         [-0.0208,  1.0000],
         [-0.0219,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017843, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.17559138722611
7.318408716470003 seconds in game passed.
Action: tensor([[[-0.0131,  1.0000],
         [-0.0162,  1.0000],
         [-0.0208,  1.0000],
         [-0.0219,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.018037, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.17559138722611
+++++++++++++: 1.2706905867978382
7.343408716842532 seconds in game passed.
At 7.343408716842532 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0106,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021967, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2706905867978382
Current reward: 0.27053272896791647
Current mitigation activation: 1
#############################
Total reward: 16.446124116194028
7.368408717215061 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0106,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015559, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446124116194028
7.39340871758759 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0106,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015780, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446124116194028
7.418408717960119 seconds in game passed.
Action: tensor([[[ 0.0298,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0106,  1.0000],
         [-0.0098,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016002, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446124116194028
+++++++++++++: 1.369379873555644
7.443408718332648 seconds in game passed.
At 7.443408718332648 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.0472e-03, 9.5602e-01],
         [1.1538e-03, 9.5437e-01],
         [2.9989e-04, 9.5376e-01],
         [6.3874e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003288, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.369379873555644
Current reward: 0.23967062159996017
Current mitigation activation: 0
#############################
Total reward: 16.685794737793987
7.468408718705177 seconds in game passed.
Action: tensor([[[2.0472e-03, 9.5602e-01],
         [1.1538e-03, 9.5437e-01],
         [2.9989e-04, 9.5376e-01],
         [6.3874e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000002, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685794737793987
7.493408719077706 seconds in game passed.
Action: tensor([[[2.0472e-03, 9.5602e-01],
         [1.1538e-03, 9.5437e-01],
         [2.9989e-04, 9.5376e-01],
         [6.3874e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000066, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685794737793987
7.518408719450235 seconds in game passed.
Action: tensor([[[2.0472e-03, 9.5602e-01],
         [1.1538e-03, 9.5437e-01],
         [2.9989e-04, 9.5376e-01],
         [6.3874e-04, 9.5338e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000130, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.685794737793987
+++++++++++++: 1.5125007294424075
7.543408719822764 seconds in game passed.
At 7.543408719822764 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.8619e-04, 9.5597e-01],
         [1.0883e-03, 9.5435e-01],
         [1.0474e-03, 9.5378e-01],
         [1.4979e-03, 9.5345e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000715, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5125007294424075
Current reward: 0.2105726835052733
Current mitigation activation: 0
#############################
Total reward: 16.89636742129926
7.568408720195293 seconds in game passed.
Action: tensor([[[6.8619e-04, 9.5597e-01],
         [1.0883e-03, 9.5435e-01],
         [1.0474e-03, 9.5378e-01],
         [1.4979e-03, 9.5345e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000523, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89636742129926
7.5934087205678225 seconds in game passed.
Action: tensor([[[6.8619e-04, 9.5597e-01],
         [1.0883e-03, 9.5435e-01],
         [1.0474e-03, 9.5378e-01],
         [1.4979e-03, 9.5345e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000479, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89636742129926
7.6184087209403515 seconds in game passed.
Action: tensor([[[6.8619e-04, 9.5597e-01],
         [1.0883e-03, 9.5435e-01],
         [1.0474e-03, 9.5378e-01],
         [1.4979e-03, 9.5345e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000435, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89636742129926
+++++++++++++: 1.7373523914493219
7.6434087213128805 seconds in game passed.
At 7.6434087213128805 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.5184e-04, 9.5611e-01],
         [1.5277e-03, 9.5461e-01],
         [1.8448e-03, 9.5411e-01],
         [1.9474e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000072, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7373523914493219
Current reward: 0.18242111373440684
Current mitigation activation: 0
#############################
Total reward: 17.078788535033667
7.6684087216854095 seconds in game passed.
Action: tensor([[[7.5184e-04, 9.5611e-01],
         [1.5277e-03, 9.5461e-01],
         [1.8448e-03, 9.5411e-01],
         [1.9474e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000077, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078788535033667
7.693408722057939 seconds in game passed.
Action: tensor([[[7.5184e-04, 9.5611e-01],
         [1.5277e-03, 9.5461e-01],
         [1.8448e-03, 9.5411e-01],
         [1.9474e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000030, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078788535033667
7.718408722430468 seconds in game passed.
Action: tensor([[[7.5184e-04, 9.5611e-01],
         [1.5277e-03, 9.5461e-01],
         [1.8448e-03, 9.5411e-01],
         [1.9474e-03, 9.5383e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000018, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.078788535033667
+++++++++++++: 2.1120512412523453
7.743408722802997 seconds in game passed.
At 7.743408722802997 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.8897e-04, 9.5628e-01],
         [1.5093e-03, 9.5485e-01],
         [1.7536e-03, 9.5439e-01],
         [1.8116e-03, 9.5412e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000009, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1120512412523453
Current reward: 0.15516509443419918
Current mitigation activation: 0
#############################
Total reward: 17.233953629467866
7.768408723175526 seconds in game passed.
Action: tensor([[[6.8897e-04, 9.5628e-01],
         [1.5093e-03, 9.5485e-01],
         [1.7536e-03, 9.5439e-01],
         [1.8116e-03, 9.5412e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000025, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.233953629467866
7.793408723548055 seconds in game passed.
Action: tensor([[[6.8897e-04, 9.5628e-01],
         [1.5093e-03, 9.5485e-01],
         [1.7536e-03, 9.5439e-01],
         [1.8116e-03, 9.5412e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000049, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.233953629467866
7.818408723920584 seconds in game passed.
Action: tensor([[[6.8897e-04, 9.5628e-01],
         [1.5093e-03, 9.5485e-01],
         [1.7536e-03, 9.5439e-01],
         [1.8116e-03, 9.5412e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000074, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.233953629467866
+++++++++++++: 2.8046376079930284
7.843408724293113 seconds in game passed.
At 7.843408724293113 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000478, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8046376079930284
Current reward: 0.12880640971294272
Current mitigation activation: 0
#############################
Total reward: 17.36276003918081
7.868408724665642 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000358, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36276003918081
7.893408725038171 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000313, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36276003918081
7.9184087254107 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000269, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36276003918081
+++++++++++++: 4.333805610086599
7.943408725783229 seconds in game passed.
At 7.943408725783229 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000412, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.333805610086599
Current reward: 0.10379794382805849
Current mitigation activation: 0
#############################
Total reward: 17.46655798300887
7.968408726155758 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000539, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.46655798300887
7.993408726528287 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000669, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.46655798300887
8.018408726900816 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0016, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.004057, steer=0.000798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.46655798300887
+++++++++++++: 20.431286841475384
8.043408727273345 seconds in game passed.
At 8.043408727273345 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006308, steer=0.000893, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03936664394018018
Current mitigation activation: 0
#############################
Total reward: 17.50592462694905
8.068408727645874 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006315, steer=0.001055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50592462694905
8.093408728018403 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006476, steer=0.001207, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50592462694905
8.118408728390932 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006584, steer=0.001360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50592462694905
+++++++++++++: 1710.1357369682569
8.143408728763461 seconds in game passed.
At 8.143408728763461 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.009693, steer=0.001598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0004704448825430603
Current mitigation activation: 0
#############################
Total reward: 17.50639507183159
8.16840872913599 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001789, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50639507183159
8.19340872950852 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001986, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50639507183159
8.218408729881048 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006878, steer=0.002184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50639507183159
+++++++++++++: 191.55321070387464
8.243408730253577 seconds in game passed.
At 8.243408730253577 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006742, steer=0.002394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004197815874274692
Current mitigation activation: 0
#############################
Total reward: 17.510592887705865
8.268408730626106 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006736, steer=0.002605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.510592887705865
8.293408730998635 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002816, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.510592887705865
8.318408731371164 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003027, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.510592887705865
+++++++++++++: 406.12479217087696
8.343408731743693 seconds in game passed.
At 8.343408731743693 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.007121, steer=0.002866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.001984456545734472
Current mitigation activation: 0
#############################
Total reward: 17.5125773442516
8.368408732116222 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006767, steer=0.002656, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5125773442516
8.393408732488751 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006794, steer=0.002453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5125773442516
8.41840873286128 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.004828, steer=0.002250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5125773442516
+++++++++++++: 34163.81754444031
8.44340873323381 seconds in game passed.
At 8.44340873323381 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.004575, steer=0.002173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.4125378590065893e-05
Current mitigation activation: 0
#############################
Total reward: 17.51260146963019
8.468408733606339 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.004238, steer=0.002183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51260146963019
8.493408733978868 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.003962, steer=0.002181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51260146963019
8.518408734351397 seconds in game passed.
Action: tensor([[[0.0012, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.003740, steer=0.002179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51260146963019
+++++++++++++: 1088.3110532296291
8.543408734723926 seconds in game passed.
At 8.543408734723926 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.1610e-04, 9.5625e-01],
         [1.4821e-03, 9.5480e-01],
         [1.7194e-03, 9.5432e-01],
         [1.8132e-03, 9.5406e-01]]])
agent 0 action: VehicleControl(throttle=0.003770, steer=0.001770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00078407480415185
Current mitigation activation: 0
#############################
Total reward: 17.513385544434342
8.568408735096455 seconds in game passed.
Action: tensor([[[7.1610e-04, 9.5625e-01],
         [1.4821e-03, 9.5480e-01],
         [1.7194e-03, 9.5432e-01],
         [1.8132e-03, 9.5406e-01]]])
agent 0 action: VehicleControl(throttle=0.003620, steer=0.001841, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513385544434342
8.593408735468984 seconds in game passed.
Action: tensor([[[7.1610e-04, 9.5625e-01],
         [1.4821e-03, 9.5480e-01],
         [1.7194e-03, 9.5432e-01],
         [1.8132e-03, 9.5406e-01]]])
agent 0 action: VehicleControl(throttle=0.003528, steer=0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513385544434342
8.618408735841513 seconds in game passed.
Action: tensor([[[7.1610e-04, 9.5625e-01],
         [1.4821e-03, 9.5480e-01],
         [1.7194e-03, 9.5432e-01],
         [1.8132e-03, 9.5406e-01]]])
agent 0 action: VehicleControl(throttle=0.003468, steer=0.001847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513385544434342
+++++++++++++: 921.4458005986254
8.643408736214042 seconds in game passed.
At 8.643408736214042 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.7256e-04, 9.5612e-01],
         [1.5018e-03, 9.5463e-01],
         [1.7816e-03, 9.5414e-01],
         [1.9117e-03, 9.5387e-01]]])
agent 0 action: VehicleControl(throttle=0.003546, steer=0.001894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0009650151435331959
Current mitigation activation: 0
#############################
Total reward: 17.514350559577874
8.66840873658657 seconds in game passed.
Action: tensor([[[7.7256e-04, 9.5612e-01],
         [1.5018e-03, 9.5463e-01],
         [1.7816e-03, 9.5414e-01],
         [1.9117e-03, 9.5387e-01]]])
agent 0 action: VehicleControl(throttle=0.003526, steer=0.001886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.514350559577874
8.6934087369591 seconds in game passed.
Action: tensor([[[7.7256e-04, 9.5612e-01],
         [1.5018e-03, 9.5463e-01],
         [1.7816e-03, 9.5414e-01],
         [1.9117e-03, 9.5387e-01]]])
agent 0 action: VehicleControl(throttle=0.003538, steer=0.001886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.514350559577874
8.718408737331629 seconds in game passed.
Action: tensor([[[7.7256e-04, 9.5612e-01],
         [1.5018e-03, 9.5463e-01],
         [1.7816e-03, 9.5414e-01],
         [1.9117e-03, 9.5387e-01]]])
agent 0 action: VehicleControl(throttle=0.003567, steer=0.001886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.514350559577874
+++++++++++++: 940.3529037145528
8.743408737704158 seconds in game passed.
At 8.743408737704158 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.2817e-04, 9.5601e-01],
         [1.3894e-03, 9.5446e-01],
         [1.6761e-03, 9.5395e-01],
         [1.8333e-03, 9.5366e-01]]])
agent 0 action: VehicleControl(throttle=0.003621, steer=0.001851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0009891405220812737
Current mitigation activation: 0
#############################
Total reward: 17.515339700099954
8.768408738076687 seconds in game passed.
Action: tensor([[[8.2817e-04, 9.5601e-01],
         [1.3894e-03, 9.5446e-01],
         [1.6761e-03, 9.5395e-01],
         [1.8333e-03, 9.5366e-01]]])
agent 0 action: VehicleControl(throttle=0.003674, steer=0.001857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515339700099954
8.793408738449216 seconds in game passed.
Action: tensor([[[8.2817e-04, 9.5601e-01],
         [1.3894e-03, 9.5446e-01],
         [1.6761e-03, 9.5395e-01],
         [1.8333e-03, 9.5366e-01]]])
agent 0 action: VehicleControl(throttle=0.003738, steer=0.001857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515339700099954
8.818408738821745 seconds in game passed.
Action: tensor([[[8.2817e-04, 9.5601e-01],
         [1.3894e-03, 9.5446e-01],
         [1.6761e-03, 9.5395e-01],
         [1.8333e-03, 9.5366e-01]]])
agent 0 action: VehicleControl(throttle=0.003810, steer=0.001857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515339700099954
+++++++++++++: 1017.1044967863555
8.843408739194274 seconds in game passed.
At 8.843408739194274 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.8146e-03,  9.5591e-01],
         [ 1.1418e-03,  9.5418e-01],
         [-4.1506e-04,  9.5353e-01],
         [ 1.8601e-04,  9.5311e-01]]])
agent 0 action: VehicleControl(throttle=0.009362, steer=0.003577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0009589837988092529
Current mitigation activation: 0
#############################
Total reward: 17.516298683898764
8.868408739566803 seconds in game passed.
Action: tensor([[[ 3.8146e-03,  9.5591e-01],
         [ 1.1418e-03,  9.5418e-01],
         [-4.1506e-04,  9.5353e-01],
         [ 1.8601e-04,  9.5311e-01]]])
agent 0 action: VehicleControl(throttle=0.008926, steer=0.003306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516298683898764
8.893408739939332 seconds in game passed.
Action: tensor([[[ 3.8146e-03,  9.5591e-01],
         [ 1.1418e-03,  9.5418e-01],
         [-4.1506e-04,  9.5353e-01],
         [ 1.8601e-04,  9.5311e-01]]])
agent 0 action: VehicleControl(throttle=0.013216, steer=0.003319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516298683898764
8.918408740311861 seconds in game passed.
Action: tensor([[[ 3.8146e-03,  9.5591e-01],
         [ 1.1418e-03,  9.5418e-01],
         [-4.1506e-04,  9.5353e-01],
         [ 1.8601e-04,  9.5311e-01]]])
agent 0 action: VehicleControl(throttle=0.012386, steer=0.003333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516298683898764
+++++++++++++: 4143.774258637651
8.94340874068439 seconds in game passed.
At 8.94340874068439 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0205,  0.9553],
         [ 0.0026,  0.9528],
         [-0.0055,  0.9516],
         [-0.0017,  0.9501]]])
agent 0 action: VehicleControl(throttle=0.067437, steer=0.014751, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00024728513050804624
Current mitigation activation: 0
#############################
Total reward: 17.516545969029274
8.968408741056919 seconds in game passed.
Action: tensor([[[ 0.0205,  0.9553],
         [ 0.0026,  0.9528],
         [-0.0055,  0.9516],
         [-0.0017,  0.9501]]])
agent 0 action: VehicleControl(throttle=0.061999, steer=0.013000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516545969029274
8.993408741429448 seconds in game passed.
Action: tensor([[[ 0.0205,  0.9553],
         [ 0.0026,  0.9528],
         [-0.0055,  0.9516],
         [-0.0017,  0.9501]]])
agent 0 action: VehicleControl(throttle=0.062445, steer=0.013131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516545969029274
9.018408741801977 seconds in game passed.
Action: tensor([[[ 0.0205,  0.9553],
         [ 0.0026,  0.9528],
         [-0.0055,  0.9516],
         [-0.0017,  0.9501]]])
agent 0 action: VehicleControl(throttle=0.062829, steer=0.013261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516545969029274
+++++++++++++: 5105.902715892505
9.043408742174506 seconds in game passed.
At 9.043408742174506 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4501e-02,  9.5357e-01],
         [ 4.6759e-04,  9.4711e-01],
         [-1.2597e-02,  9.1206e-01],
         [-8.3219e-03,  5.9990e-01]]])
agent 0 action: VehicleControl(throttle=0.089661, steer=0.014540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0002110970626269866
Current mitigation activation: 0
#############################
Total reward: 17.516757066091902
9.068408742547035 seconds in game passed.
Action: tensor([[[ 2.4501e-02,  9.5357e-01],
         [ 4.6759e-04,  9.4711e-01],
         [-1.2597e-02,  9.1206e-01],
         [-8.3219e-03,  5.9990e-01]]])
agent 0 action: VehicleControl(throttle=0.087492, steer=0.014493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516757066091902
9.093408742919564 seconds in game passed.
Action: tensor([[[ 2.4501e-02,  9.5357e-01],
         [ 4.6759e-04,  9.4711e-01],
         [-1.2597e-02,  9.1206e-01],
         [-8.3219e-03,  5.9990e-01]]])
agent 0 action: VehicleControl(throttle=0.088115, steer=0.014637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516757066091902
9.118408743292093 seconds in game passed.
Action: tensor([[[ 2.4501e-02,  9.5357e-01],
         [ 4.6759e-04,  9.4711e-01],
         [-1.2597e-02,  9.1206e-01],
         [-8.3219e-03,  5.9990e-01]]])
agent 0 action: VehicleControl(throttle=0.088710, steer=0.014780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.516757066091902
+++++++++++++: 1939.5180241687788
9.143408743664622 seconds in game passed.
At 9.143408743664622 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0087,  0.9526],
         [-0.0043,  0.9415],
         [-0.0107,  0.8767],
         [-0.0051,  0.6139]]])
agent 0 action: VehicleControl(throttle=0.064014, steer=0.001911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0005850404306949952
Current mitigation activation: 0
#############################
Total reward: 17.517342106522598
9.168408744037151 seconds in game passed.
Action: tensor([[[ 0.0087,  0.9526],
         [-0.0043,  0.9415],
         [-0.0107,  0.8767],
         [-0.0051,  0.6139]]])
agent 0 action: VehicleControl(throttle=0.067049, steer=0.004066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517342106522598
9.19340874440968 seconds in game passed.
Action: tensor([[[ 0.0087,  0.9526],
         [-0.0043,  0.9415],
         [-0.0107,  0.8767],
         [-0.0051,  0.6139]]])
agent 0 action: VehicleControl(throttle=0.067409, steer=0.004074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517342106522598
9.21840874478221 seconds in game passed.
Action: tensor([[[ 0.0087,  0.9526],
         [-0.0043,  0.9415],
         [-0.0107,  0.8767],
         [-0.0051,  0.6139]]])
agent 0 action: VehicleControl(throttle=0.067715, steer=0.004083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517342106522598
+++++++++++++: 1165.65784138665
9.243408745154738 seconds in game passed.
At 9.243408745154738 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0353,  0.9510],
         [-0.0197,  0.9021],
         [-0.0118,  0.7325],
         [-0.0081,  0.5529]]])
agent 0 action: VehicleControl(throttle=0.229628, steer=-0.032739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0010253285898345732
Current mitigation activation: 0
#############################
Total reward: 17.51836743511243
9.268408745527267 seconds in game passed.
Action: tensor([[[-0.0353,  0.9510],
         [-0.0197,  0.9021],
         [-0.0118,  0.7325],
         [-0.0081,  0.5529]]])
agent 0 action: VehicleControl(throttle=0.214611, steer=-0.027035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51836743511243
9.293408745899796 seconds in game passed.
Action: tensor([[[-0.0353,  0.9510],
         [-0.0197,  0.9021],
         [-0.0118,  0.7325],
         [-0.0081,  0.5529]]])
agent 0 action: VehicleControl(throttle=0.216784, steer=-0.027407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51836743511243
9.318408746272326 seconds in game passed.
Action: tensor([[[-0.0353,  0.9510],
         [-0.0197,  0.9021],
         [-0.0118,  0.7325],
         [-0.0081,  0.5529]]])
agent 0 action: VehicleControl(throttle=0.218788, steer=-0.027778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51836743511243
+++++++++++++: 872.2298763003156
9.343408746644855 seconds in game passed.
At 9.343408746644855 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0390,  0.9499],
         [-0.0182,  0.8451],
         [-0.0084,  0.6423],
         [-0.0058,  0.5127]]])
agent 0 action: VehicleControl(throttle=0.507222, steer=-0.028855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0014441340470784294
Current mitigation activation: 0
#############################
Total reward: 17.519811569159508
9.368408747017384 seconds in game passed.
Action: tensor([[[-0.0390,  0.9499],
         [-0.0182,  0.8451],
         [-0.0084,  0.6423],
         [-0.0058,  0.5127]]])
agent 0 action: VehicleControl(throttle=0.481725, steer=-0.029118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519811569159508
9.393408747389913 seconds in game passed.
Action: tensor([[[-0.0390,  0.9499],
         [-0.0182,  0.8451],
         [-0.0084,  0.6423],
         [-0.0058,  0.5127]]])
agent 0 action: VehicleControl(throttle=0.486465, steer=-0.029497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519811569159508
9.418408747762442 seconds in game passed.
Action: tensor([[[-0.0390,  0.9499],
         [-0.0182,  0.8451],
         [-0.0084,  0.6423],
         [-0.0058,  0.5127]]])
agent 0 action: VehicleControl(throttle=0.490931, steer=-0.029876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519811569159508
+++++++++++++: 571.8431801725438
9.44340874813497 seconds in game passed.
At 9.44340874813497 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0359,  0.9491],
         [-0.0113,  0.8028],
         [-0.0053,  0.5949],
         [-0.0065,  0.4891]]])
agent 0 action: VehicleControl(throttle=0.736645, steer=-0.023329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.002318640013839872
Current mitigation activation: 0
#############################
Total reward: 17.522130209173348
9.4684087485075 seconds in game passed.
Action: tensor([[[-0.0359,  0.9491],
         [-0.0113,  0.8028],
         [-0.0053,  0.5949],
         [-0.0065,  0.4891]]])
agent 0 action: VehicleControl(throttle=0.717422, steer=-0.024778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.522130209173348
9.493408748880029 seconds in game passed.
Action: tensor([[[-0.0359,  0.9491],
         [-0.0113,  0.8028],
         [-0.0053,  0.5949],
         [-0.0065,  0.4891]]])
agent 0 action: VehicleControl(throttle=0.723352, steer=-0.025085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.522130209173348
9.518408749252558 seconds in game passed.
Action: tensor([[[-0.0359,  0.9491],
         [-0.0113,  0.8028],
         [-0.0053,  0.5949],
         [-0.0065,  0.4891]]])
agent 0 action: VehicleControl(throttle=0.728462, steer=-0.025392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.522130209173348
+++++++++++++: 305.34743976394935
9.543408749625087 seconds in game passed.
At 9.543408749625087 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.7898e-02,  9.4357e-01],
         [-5.3139e-03,  6.1712e-01],
         [-2.0105e-03,  4.8590e-01],
         [-6.8213e-04,  4.3310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004566643454908184
Current mitigation activation: 0
#############################
Total reward: 17.526696852628255
9.568408749997616 seconds in game passed.
Action: tensor([[[-2.7898e-02,  9.4357e-01],
         [-5.3139e-03,  6.1712e-01],
         [-2.0105e-03,  4.8590e-01],
         [-6.8213e-04,  4.3310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.016923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.526696852628255
9.593408750370145 seconds in game passed.
Action: tensor([[[-2.7898e-02,  9.4357e-01],
         [-5.3139e-03,  6.1712e-01],
         [-2.0105e-03,  4.8590e-01],
         [-6.8213e-04,  4.3310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.017115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.526696852628255
9.618408750742674 seconds in game passed.
Action: tensor([[[-2.7898e-02,  9.4357e-01],
         [-5.3139e-03,  6.1712e-01],
         [-2.0105e-03,  4.8590e-01],
         [-6.8213e-04,  4.3310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.017307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.526696852628255
+++++++++++++: 83.59301840897294
9.643408751115203 seconds in game passed.
At 9.643408751115203 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.4698e-02,  9.2793e-01],
         [-9.8050e-05,  5.5221e-01],
         [ 4.6508e-04,  4.3510e-01],
         [ 1.3644e-03,  3.8102e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.017513237623891374
Current mitigation activation: 0
#############################
Total reward: 17.544210090252147
9.668408751487732 seconds in game passed.
Action: tensor([[[-1.4698e-02,  9.2793e-01],
         [-9.8050e-05,  5.5221e-01],
         [ 4.6508e-04,  4.3510e-01],
         [ 1.3644e-03,  3.8102e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544210090252147
9.693408751860261 seconds in game passed.
Action: tensor([[[-1.4698e-02,  9.2793e-01],
         [-9.8050e-05,  5.5221e-01],
         [ 4.6508e-04,  4.3510e-01],
         [ 1.3644e-03,  3.8102e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544210090252147
9.71840875223279 seconds in game passed.
Action: tensor([[[-1.4698e-02,  9.2793e-01],
         [-9.8050e-05,  5.5221e-01],
         [ 4.6508e-04,  4.3510e-01],
         [ 1.3644e-03,  3.8102e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544210090252147
+++++++++++++: 28.685462587072514
9.743408752605319 seconds in game passed.
At 9.743408752605319 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0051,  0.8800],
         [-0.0030,  0.4967],
         [-0.0053,  0.3650],
         [-0.0057,  0.2969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.05337793302981074
Current mitigation activation: 0
#############################
Total reward: 17.597588023281958
9.768408752977848 seconds in game passed.
Action: tensor([[[-0.0051,  0.8800],
         [-0.0030,  0.4967],
         [-0.0053,  0.3650],
         [-0.0057,  0.2969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.597588023281958
9.793408753350377 seconds in game passed.
Action: tensor([[[-0.0051,  0.8800],
         [-0.0030,  0.4967],
         [-0.0053,  0.3650],
         [-0.0057,  0.2969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007268, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.597588023281958
9.818408753722906 seconds in game passed.
Action: tensor([[[-0.0051,  0.8800],
         [-0.0030,  0.4967],
         [-0.0053,  0.3650],
         [-0.0057,  0.2969]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.597588023281958
+++++++++++++: 14.063435068388458
9.843408754095435 seconds in game passed.
At 9.843408754095435 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.8325],
         [-0.0043,  0.4684],
         [-0.0073,  0.3322],
         [-0.0083,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.11331064906120848
Current mitigation activation: 0
#############################
Total reward: 17.710898672343166
9.868408754467964 seconds in game passed.
Action: tensor([[[ 0.0012,  0.8325],
         [-0.0043,  0.4684],
         [-0.0073,  0.3322],
         [-0.0083,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.710898672343166
9.893408754840493 seconds in game passed.
Action: tensor([[[ 0.0012,  0.8325],
         [-0.0043,  0.4684],
         [-0.0073,  0.3322],
         [-0.0083,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006110, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.710898672343166
9.918408755213022 seconds in game passed.
Action: tensor([[[ 0.0012,  0.8325],
         [-0.0043,  0.4684],
         [-0.0073,  0.3322],
         [-0.0083,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.710898672343166
+++++++++++++: 8.57950811005021
9.943408755585551 seconds in game passed.
At 9.943408755585551 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0050,  0.8197],
         [-0.0035,  0.4593],
         [-0.0071,  0.3217],
         [-0.0089,  0.2476]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.57950811005021
Current reward: 0.17081477071478698
Current mitigation activation: 0
#############################
Total reward: 17.881713443057954
9.96840875595808 seconds in game passed.
Action: tensor([[[ 0.0050,  0.8197],
         [-0.0035,  0.4593],
         [-0.0071,  0.3217],
         [-0.0089,  0.2476]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.881713443057954
9.99340875633061 seconds in game passed.
Action: tensor([[[ 0.0050,  0.8197],
         [-0.0035,  0.4593],
         [-0.0071,  0.3217],
         [-0.0089,  0.2476]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.881713443057954
10.018408756703138 seconds in game passed.
Action: tensor([[[ 0.0050,  0.8197],
         [-0.0035,  0.4593],
         [-0.0071,  0.3217],
         [-0.0089,  0.2476]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.881713443057954
+++++++++++++: 6.530149247346755
10.043408757075667 seconds in game passed.
At 10.043408757075667 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0064,  0.7848],
         [-0.0019,  0.4367],
         [-0.0048,  0.3022],
         [-0.0066,  0.2302]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.530149247346755
Current reward: 0.18939973663889853
Current mitigation activation: 0
#############################
Total reward: 18.07111317969685
10.068408757448196 seconds in game passed.
Action: tensor([[[ 0.0064,  0.7848],
         [-0.0019,  0.4367],
         [-0.0048,  0.3022],
         [-0.0066,  0.2302]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.07111317969685
10.093408757820725 seconds in game passed.
Action: tensor([[[ 0.0064,  0.7848],
         [-0.0019,  0.4367],
         [-0.0048,  0.3022],
         [-0.0066,  0.2302]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.07111317969685
10.118408758193254 seconds in game passed.
Action: tensor([[[ 0.0064,  0.7848],
         [-0.0019,  0.4367],
         [-0.0048,  0.3022],
         [-0.0066,  0.2302]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.07111317969685
+++++++++++++: 5.454871510276758
10.143408758565784 seconds in game passed.
At 10.143408758565784 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0069,  0.7574],
         [-0.0011,  0.4259],
         [-0.0035,  0.2959],
         [-0.0053,  0.2262]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.454871510276758
Current reward: 0.20568960855955815
Current mitigation activation: 0
#############################
Total reward: 18.27680278825641
10.168408758938313 seconds in game passed.
Action: tensor([[[ 0.0069,  0.7574],
         [-0.0011,  0.4259],
         [-0.0035,  0.2959],
         [-0.0053,  0.2262]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.27680278825641
10.193408759310842 seconds in game passed.
Action: tensor([[[ 0.0069,  0.7574],
         [-0.0011,  0.4259],
         [-0.0035,  0.2959],
         [-0.0053,  0.2262]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.27680278825641
10.21840875968337 seconds in game passed.
Action: tensor([[[ 0.0069,  0.7574],
         [-0.0011,  0.4259],
         [-0.0035,  0.2959],
         [-0.0053,  0.2262]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.27680278825641
+++++++++++++: 4.749319161715375
10.2434087600559 seconds in game passed.
At 10.2434087600559 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0041,  0.7347],
         [-0.0019,  0.4107],
         [-0.0039,  0.2843],
         [-0.0055,  0.2178]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004846, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.749319161715375
Current reward: 0.22075742645013854
Current mitigation activation: 0
#############################
Total reward: 18.49756021470655
10.268408760428429 seconds in game passed.
Action: tensor([[[ 0.0041,  0.7347],
         [-0.0019,  0.4107],
         [-0.0039,  0.2843],
         [-0.0055,  0.2178]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.49756021470655
10.293408760800958 seconds in game passed.
Action: tensor([[[ 0.0041,  0.7347],
         [-0.0019,  0.4107],
         [-0.0039,  0.2843],
         [-0.0055,  0.2178]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.49756021470655
10.318408761173487 seconds in game passed.
Action: tensor([[[ 0.0041,  0.7347],
         [-0.0019,  0.4107],
         [-0.0039,  0.2843],
         [-0.0055,  0.2178]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.49756021470655
+++++++++++++: 4.2283123734763715
10.343408761546016 seconds in game passed.
At 10.343408761546016 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.0542e-03,  7.2726e-01],
         [-6.8005e-04,  4.0773e-01],
         [-2.0254e-03,  2.8418e-01],
         [-3.0828e-03,  2.1926e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.2283123734763715
Current reward: 0.23510053117730384
Current mitigation activation: 0
#############################
Total reward: 18.73266074588385
10.368408761918545 seconds in game passed.
Action: tensor([[[ 6.0542e-03,  7.2726e-01],
         [-6.8005e-04,  4.0773e-01],
         [-2.0254e-03,  2.8418e-01],
         [-3.0828e-03,  2.1926e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.73266074588385
10.393408762291074 seconds in game passed.
Action: tensor([[[ 6.0542e-03,  7.2726e-01],
         [-6.8005e-04,  4.0773e-01],
         [-2.0254e-03,  2.8418e-01],
         [-3.0828e-03,  2.1926e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.73266074588385
10.418408762663603 seconds in game passed.
Action: tensor([[[ 6.0542e-03,  7.2726e-01],
         [-6.8005e-04,  4.0773e-01],
         [-2.0254e-03,  2.8418e-01],
         [-3.0828e-03,  2.1926e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.73266074588385
+++++++++++++: 3.8179491943835875
10.443408763036132 seconds in game passed.
At 10.443408763036132 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2431e-02,  7.3784e-01],
         [ 1.0593e-03,  4.1006e-01],
         [-4.0554e-04,  2.8468e-01],
         [-1.1603e-03,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.8179491943835875
Current reward: 0.2489100931061477
Current mitigation activation: 0
#############################
Total reward: 18.98157083899
10.468408763408661 seconds in game passed.
Action: tensor([[[ 1.2431e-02,  7.3784e-01],
         [ 1.0593e-03,  4.1006e-01],
         [-4.0554e-04,  2.8468e-01],
         [-1.1603e-03,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.98157083899
10.49340876378119 seconds in game passed.
Action: tensor([[[ 1.2431e-02,  7.3784e-01],
         [ 1.0593e-03,  4.1006e-01],
         [-4.0554e-04,  2.8468e-01],
         [-1.1603e-03,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.98157083899
10.518408764153719 seconds in game passed.
Action: tensor([[[ 1.2431e-02,  7.3784e-01],
         [ 1.0593e-03,  4.1006e-01],
         [-4.0554e-04,  2.8468e-01],
         [-1.1603e-03,  2.1874e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004071, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.98157083899
+++++++++++++: 3.4810388124339897
10.543408764526248 seconds in game passed.
At 10.543408764526248 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3910e-02, 7.3536e-01],
         [1.8493e-03, 4.1257e-01],
         [7.0991e-04, 2.8655e-01],
         [2.6856e-04, 2.1980e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.4810388124339897
Current reward: 0.2622726611356749
Current mitigation activation: 0
#############################
Total reward: 19.243843500125674
10.568408764898777 seconds in game passed.
Action: tensor([[[1.3910e-02, 7.3536e-01],
         [1.8493e-03, 4.1257e-01],
         [7.0991e-04, 2.8655e-01],
         [2.6856e-04, 2.1980e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.243843500125674
10.593408765271306 seconds in game passed.
Action: tensor([[[1.3910e-02, 7.3536e-01],
         [1.8493e-03, 4.1257e-01],
         [7.0991e-04, 2.8655e-01],
         [2.6856e-04, 2.1980e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005841, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.243843500125674
10.618408765643835 seconds in game passed.
Action: tensor([[[1.3910e-02, 7.3536e-01],
         [1.8493e-03, 4.1257e-01],
         [7.0991e-04, 2.8655e-01],
         [2.6856e-04, 2.1980e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.243843500125674
+++++++++++++: 3.2371859686188635
10.643408766016364 seconds in game passed.
At 10.643408766016364 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1736e-02,  7.1601e-01],
         [ 1.7371e-03,  3.9908e-01],
         [ 3.9889e-04,  2.7712e-01],
         [-3.9837e-04,  2.1346e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2371859686188635
Current reward: 0.2737125080126803
Current mitigation activation: 0
#############################
Total reward: 19.517556008138353
10.668408766388893 seconds in game passed.
Action: tensor([[[ 1.1736e-02,  7.1601e-01],
         [ 1.7371e-03,  3.9908e-01],
         [ 3.9889e-04,  2.7712e-01],
         [-3.9837e-04,  2.1346e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.517556008138353
10.693408766761422 seconds in game passed.
Action: tensor([[[ 1.1736e-02,  7.1601e-01],
         [ 1.7371e-03,  3.9908e-01],
         [ 3.9889e-04,  2.7712e-01],
         [-3.9837e-04,  2.1346e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.517556008138353
10.718408767133951 seconds in game passed.
Action: tensor([[[ 1.1736e-02,  7.1601e-01],
         [ 1.7371e-03,  3.9908e-01],
         [ 3.9889e-04,  2.7712e-01],
         [-3.9837e-04,  2.1346e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.517556008138353
+++++++++++++: 3.2380704414773307
10.74340876750648 seconds in game passed.
At 10.74340876750648 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0059, 0.6608],
         [0.0023, 0.3656],
         [0.0022, 0.2555],
         [0.0018, 0.1996]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2380704414773307
Current reward: 0.2762820655202496
Current mitigation activation: 0
#############################
Total reward: 19.793838073658602
10.76840876787901 seconds in game passed.
Action: tensor([[[0.0059, 0.6608],
         [0.0023, 0.3656],
         [0.0022, 0.2555],
         [0.0018, 0.1996]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.793838073658602
10.793408768251538 seconds in game passed.
Action: tensor([[[0.0059, 0.6608],
         [0.0023, 0.3656],
         [0.0022, 0.2555],
         [0.0018, 0.1996]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.793838073658602
10.818408768624067 seconds in game passed.
Action: tensor([[[0.0059, 0.6608],
         [0.0023, 0.3656],
         [0.0022, 0.2555],
         [0.0018, 0.1996]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.793838073658602
+++++++++++++: 3.2728170184578422
10.843408768996596 seconds in game passed.
At 10.843408768996596 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.3296e-03, 6.5582e-01],
         [1.7186e-03, 3.6173e-01],
         [1.3146e-03, 2.5272e-01],
         [6.3986e-04, 1.9750e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2728170184578422
Current reward: 0.27753712947098835
Current mitigation activation: 0
#############################
Total reward: 20.07137520312959
10.868408769369125 seconds in game passed.
Action: tensor([[[4.3296e-03, 6.5582e-01],
         [1.7186e-03, 3.6173e-01],
         [1.3146e-03, 2.5272e-01],
         [6.3986e-04, 1.9750e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.07137520312959
10.893408769741654 seconds in game passed.
Action: tensor([[[4.3296e-03, 6.5582e-01],
         [1.7186e-03, 3.6173e-01],
         [1.3146e-03, 2.5272e-01],
         [6.3986e-04, 1.9750e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.07137520312959
10.918408770114183 seconds in game passed.
Action: tensor([[[4.3296e-03, 6.5582e-01],
         [1.7186e-03, 3.6173e-01],
         [1.3146e-03, 2.5272e-01],
         [6.3986e-04, 1.9750e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.07137520312959
+++++++++++++: 3.307718284690577
10.943408770486712 seconds in game passed.
At 10.943408770486712 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.3924e-03, 6.5137e-01],
         [1.1713e-03, 3.6028e-01],
         [7.9736e-04, 2.5104e-01],
         [1.9218e-04, 1.9562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.307718284690577
Current reward: 0.2788067478467003
Current mitigation activation: 0
#############################
Total reward: 20.350181950976292
10.968408770859241 seconds in game passed.
Action: tensor([[[3.3924e-03, 6.5137e-01],
         [1.1713e-03, 3.6028e-01],
         [7.9736e-04, 2.5104e-01],
         [1.9218e-04, 1.9562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.350181950976292
10.99340877123177 seconds in game passed.
Action: tensor([[[3.3924e-03, 6.5137e-01],
         [1.1713e-03, 3.6028e-01],
         [7.9736e-04, 2.5104e-01],
         [1.9218e-04, 1.9562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.350181950976292
11.0184087716043 seconds in game passed.
Action: tensor([[[3.3924e-03, 6.5137e-01],
         [1.1713e-03, 3.6028e-01],
         [7.9736e-04, 2.5104e-01],
         [1.9218e-04, 1.9562e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.350181950976292
+++++++++++++: 3.3431286034773176
11.043408771976829 seconds in game passed.
At 11.043408771976829 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0952e-03,  6.3833e-01],
         [ 7.2447e-04,  3.5525e-01],
         [ 4.0649e-04,  2.4842e-01],
         [-2.3891e-04,  1.9392e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002420, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3431286034773176
Current reward: 0.2800760071306959
Current mitigation activation: 0
#############################
Total reward: 20.630257958106988
11.068408772349358 seconds in game passed.
Action: tensor([[[ 2.0952e-03,  6.3833e-01],
         [ 7.2447e-04,  3.5525e-01],
         [ 4.0649e-04,  2.4842e-01],
         [-2.3891e-04,  1.9392e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.630257958106988
11.093408772721887 seconds in game passed.
Action: tensor([[[ 2.0952e-03,  6.3833e-01],
         [ 7.2447e-04,  3.5525e-01],
         [ 4.0649e-04,  2.4842e-01],
         [-2.3891e-04,  1.9392e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.630257958106988
11.118408773094416 seconds in game passed.
Action: tensor([[[ 2.0952e-03,  6.3833e-01],
         [ 7.2447e-04,  3.5525e-01],
         [ 4.0649e-04,  2.4842e-01],
         [-2.3891e-04,  1.9392e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.630257958106988
+++++++++++++: 3.347295440192484
11.143408773466945 seconds in game passed.
At 11.143408773466945 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.6539e-03, 6.3036e-01],
         [1.0648e-03, 3.5066e-01],
         [6.7335e-04, 2.4493e-01],
         [3.5368e-05, 1.9070e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.347295440192484
Current reward: 0.28247232862055516
Current mitigation activation: 0
#############################
Total reward: 20.912730286727545
11.168408773839474 seconds in game passed.
Action: tensor([[[2.6539e-03, 6.3036e-01],
         [1.0648e-03, 3.5066e-01],
         [6.7335e-04, 2.4493e-01],
         [3.5368e-05, 1.9070e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002954, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.912730286727545
11.193408774212003 seconds in game passed.
Action: tensor([[[2.6539e-03, 6.3036e-01],
         [1.0648e-03, 3.5066e-01],
         [6.7335e-04, 2.4493e-01],
         [3.5368e-05, 1.9070e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.912730286727545
11.218408774584532 seconds in game passed.
Action: tensor([[[2.6539e-03, 6.3036e-01],
         [1.0648e-03, 3.5066e-01],
         [6.7335e-04, 2.4493e-01],
         [3.5368e-05, 1.9070e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.912730286727545
+++++++++++++: 3.096684590216027
11.24340877495706 seconds in game passed.
At 11.24340877495706 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8808e-03,  6.3164e-01],
         [ 6.8132e-04,  3.4937e-01],
         [ 2.8561e-04,  2.4256e-01],
         [-2.6798e-04,  1.8789e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.096684590216027
Current reward: 0.2947233516745773
Current mitigation activation: 0
#############################
Total reward: 21.20745363840212
11.26840877532959 seconds in game passed.
Action: tensor([[[ 1.8808e-03,  6.3164e-01],
         [ 6.8132e-04,  3.4937e-01],
         [ 2.8561e-04,  2.4256e-01],
         [-2.6798e-04,  1.8789e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.20745363840212
11.293408775702119 seconds in game passed.
Action: tensor([[[ 1.8808e-03,  6.3164e-01],
         [ 6.8132e-04,  3.4937e-01],
         [ 2.8561e-04,  2.4256e-01],
         [-2.6798e-04,  1.8789e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.20745363840212
11.318408776074648 seconds in game passed.
Action: tensor([[[ 1.8808e-03,  6.3164e-01],
         [ 6.8132e-04,  3.4937e-01],
         [ 2.8561e-04,  2.4256e-01],
         [-2.6798e-04,  1.8789e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.20745363840212
+++++++++++++: 2.8580728669055286
11.343408776447177 seconds in game passed.
At 11.343408776447177 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0088e-03,  6.4711e-01],
         [-3.2399e-04,  3.5521e-01],
         [-8.4552e-04,  2.4555e-01],
         [-1.5035e-03,  1.8971e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8580728669055286
Current reward: 0.30745566356630305
Current mitigation activation: 0
#############################
Total reward: 21.514909301968423
11.368408776819706 seconds in game passed.
Action: tensor([[[ 1.0088e-03,  6.4711e-01],
         [-3.2399e-04,  3.5521e-01],
         [-8.4552e-04,  2.4555e-01],
         [-1.5035e-03,  1.8971e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.514909301968423
11.393408777192235 seconds in game passed.
Action: tensor([[[ 1.0088e-03,  6.4711e-01],
         [-3.2399e-04,  3.5521e-01],
         [-8.4552e-04,  2.4555e-01],
         [-1.5035e-03,  1.8971e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.514909301968423
11.418408777564764 seconds in game passed.
Action: tensor([[[ 1.0088e-03,  6.4711e-01],
         [-3.2399e-04,  3.5521e-01],
         [-8.4552e-04,  2.4555e-01],
         [-1.5035e-03,  1.8971e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.514909301968423
+++++++++++++: 2.665234596088776
11.443408777937293 seconds in game passed.
At 11.443408777937293 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0283e-03,  6.6181e-01],
         [ 6.9961e-06,  3.5981e-01],
         [-5.3397e-04,  2.4746e-01],
         [-1.2769e-03,  1.9082e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.665234596088776
Current reward: 0.3187414390495429
Current mitigation activation: 0
#############################
Total reward: 21.833650741017966
11.468408778309822 seconds in game passed.
Action: tensor([[[ 2.0283e-03,  6.6181e-01],
         [ 6.9961e-06,  3.5981e-01],
         [-5.3397e-04,  2.4746e-01],
         [-1.2769e-03,  1.9082e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001948, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.833650741017966
11.493408778682351 seconds in game passed.
Action: tensor([[[ 2.0283e-03,  6.6181e-01],
         [ 6.9961e-06,  3.5981e-01],
         [-5.3397e-04,  2.4746e-01],
         [-1.2769e-03,  1.9082e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.833650741017966
11.51840877905488 seconds in game passed.
Action: tensor([[[ 2.0283e-03,  6.6181e-01],
         [ 6.9961e-06,  3.5981e-01],
         [-5.3397e-04,  2.4746e-01],
         [-1.2769e-03,  1.9082e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.833650741017966
+++++++++++++: 2.4989672848909517
11.54340877942741 seconds in game passed.
At 11.54340877942741 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.5158e-03,  6.7732e-01],
         [-2.4988e-04,  3.6524e-01],
         [-1.0746e-03,  2.4984e-01],
         [-1.9692e-03,  1.9198e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4989672848909517
Current reward: 0.3290958252166816
Current mitigation activation: 0
#############################
Total reward: 22.16274656623465
11.568408779799938 seconds in game passed.
Action: tensor([[[ 1.5158e-03,  6.7732e-01],
         [-2.4988e-04,  3.6524e-01],
         [-1.0746e-03,  2.4984e-01],
         [-1.9692e-03,  1.9198e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.16274656623465
11.593408780172467 seconds in game passed.
Action: tensor([[[ 1.5158e-03,  6.7732e-01],
         [-2.4988e-04,  3.6524e-01],
         [-1.0746e-03,  2.4984e-01],
         [-1.9692e-03,  1.9198e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.16274656623465
11.618408780544996 seconds in game passed.
Action: tensor([[[ 1.5158e-03,  6.7732e-01],
         [-2.4988e-04,  3.6524e-01],
         [-1.0746e-03,  2.4984e-01],
         [-1.9692e-03,  1.9198e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.16274656623465
+++++++++++++: 2.350053601806218
11.643408780917525 seconds in game passed.
At 11.643408780917525 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.7670e-04,  6.6494e-01],
         [-1.4341e-03,  3.6388e-01],
         [-2.2953e-03,  2.5160e-01],
         [-3.4020e-03,  1.9430e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.350053601806218
Current reward: 0.33878521657083754
Current mitigation activation: 0
#############################
Total reward: 22.501531782805486
11.668408781290054 seconds in game passed.
Action: tensor([[[-4.7670e-04,  6.6494e-01],
         [-1.4341e-03,  3.6388e-01],
         [-2.2953e-03,  2.5160e-01],
         [-3.4020e-03,  1.9430e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.501531782805486
11.693408781662583 seconds in game passed.
Action: tensor([[[-4.7670e-04,  6.6494e-01],
         [-1.4341e-03,  3.6388e-01],
         [-2.2953e-03,  2.5160e-01],
         [-3.4020e-03,  1.9430e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.501531782805486
11.718408782035112 seconds in game passed.
Action: tensor([[[-4.7670e-04,  6.6494e-01],
         [-1.4341e-03,  3.6388e-01],
         [-2.2953e-03,  2.5160e-01],
         [-3.4020e-03,  1.9430e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.501531782805486
+++++++++++++: 2.2136397219874935
11.743408782407641 seconds in game passed.
At 11.743408782407641 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.6706],
         [-0.0035,  0.3671],
         [-0.0043,  0.2550],
         [-0.0050,  0.1977]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2136397219874935
Current reward: 0.3479441660370106
Current mitigation activation: 0
#############################
Total reward: 22.849475948842496
11.76840878278017 seconds in game passed.
Action: tensor([[[-0.0019,  0.6706],
         [-0.0035,  0.3671],
         [-0.0043,  0.2550],
         [-0.0050,  0.1977]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.849475948842496
11.7934087831527 seconds in game passed.
Action: tensor([[[-0.0019,  0.6706],
         [-0.0035,  0.3671],
         [-0.0043,  0.2550],
         [-0.0050,  0.1977]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.849475948842496
11.818408783525229 seconds in game passed.
Action: tensor([[[-0.0019,  0.6706],
         [-0.0035,  0.3671],
         [-0.0043,  0.2550],
         [-0.0050,  0.1977]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.849475948842496
+++++++++++++: 2.0870940602946644
11.843408783897758 seconds in game passed.
At 11.843408783897758 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6729],
         [-0.0013,  0.3700],
         [-0.0023,  0.2568],
         [-0.0031,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0870940602946644
Current reward: 0.35662447145512177
Current mitigation activation: 0
#############################
Total reward: 23.206100420297616
11.868408784270287 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6729],
         [-0.0013,  0.3700],
         [-0.0023,  0.2568],
         [-0.0031,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.206100420297616
11.893408784642816 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6729],
         [-0.0013,  0.3700],
         [-0.0023,  0.2568],
         [-0.0031,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000180, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.206100420297616
11.918408785015345 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6729],
         [-0.0013,  0.3700],
         [-0.0023,  0.2568],
         [-0.0031,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.206100420297616
+++++++++++++: 1.9688862161972307
11.943408785387874 seconds in game passed.
At 11.943408785387874 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0016,  0.6732],
         [-0.0012,  0.3684],
         [-0.0020,  0.2544],
         [-0.0028,  0.1961]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9688862161972307
Current reward: 0.3648319633695384
Current mitigation activation: 0
#############################
Total reward: 23.570932383667156
11.968408785760403 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6732],
         [-0.0012,  0.3684],
         [-0.0020,  0.2544],
         [-0.0028,  0.1961]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.570932383667156
11.993408786132932 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6732],
         [-0.0012,  0.3684],
         [-0.0020,  0.2544],
         [-0.0028,  0.1961]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.570932383667156
12.01840878650546 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6732],
         [-0.0012,  0.3684],
         [-0.0020,  0.2544],
         [-0.0028,  0.1961]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.570932383667156
+++++++++++++: 1.857770016030703
12.04340878687799 seconds in game passed.
At 12.04340878687799 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.8852e-03,  6.6325e-01],
         [ 5.5768e-05,  3.7471e-01],
         [-6.3287e-04,  2.6333e-01],
         [-1.5158e-03,  2.0465e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.857770016030703
Current reward: 0.37257100987588315
Current mitigation activation: 0
#############################
Total reward: 23.94350339354304
12.068408787250519 seconds in game passed.
Action: tensor([[[ 2.8852e-03,  6.6325e-01],
         [ 5.5768e-05,  3.7471e-01],
         [-6.3287e-04,  2.6333e-01],
         [-1.5158e-03,  2.0465e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.94350339354304
12.093408787623048 seconds in game passed.
Action: tensor([[[ 2.8852e-03,  6.6325e-01],
         [ 5.5768e-05,  3.7471e-01],
         [-6.3287e-04,  2.6333e-01],
         [-1.5158e-03,  2.0465e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.94350339354304
12.118408787995577 seconds in game passed.
Action: tensor([[[ 2.8852e-03,  6.6325e-01],
         [ 5.5768e-05,  3.7471e-01],
         [-6.3287e-04,  2.6333e-01],
         [-1.5158e-03,  2.0465e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.94350339354304
+++++++++++++: 1.7527178332318056
12.143408788368106 seconds in game passed.
At 12.143408788368106 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.7946e-03,  6.7602e-01],
         [-3.8736e-05,  3.8533e-01],
         [-9.3456e-04,  2.7032e-01],
         [-1.7900e-03,  2.0927e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7527178332318056
Current reward: 0.3798473821505594
Current mitigation activation: 0
#############################
Total reward: 24.323350775693598
12.168408788740635 seconds in game passed.
Action: tensor([[[ 5.7946e-03,  6.7602e-01],
         [-3.8736e-05,  3.8533e-01],
         [-9.3456e-04,  2.7032e-01],
         [-1.7900e-03,  2.0927e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.323350775693598
12.193408789113164 seconds in game passed.
Action: tensor([[[ 5.7946e-03,  6.7602e-01],
         [-3.8736e-05,  3.8533e-01],
         [-9.3456e-04,  2.7032e-01],
         [-1.7900e-03,  2.0927e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002009, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.323350775693598
12.218408789485693 seconds in game passed.
Action: tensor([[[ 5.7946e-03,  6.7602e-01],
         [-3.8736e-05,  3.8533e-01],
         [-9.3456e-04,  2.7032e-01],
         [-1.7900e-03,  2.0927e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.323350775693598
+++++++++++++: 1.652925279794943
12.243408789858222 seconds in game passed.
At 12.243408789858222 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6819e-03,  7.0783e-01],
         [ 8.2732e-04,  3.9776e-01],
         [ 2.2352e-08,  2.7863e-01],
         [-3.8490e-04,  2.1561e-01]]])
agent 0 action: VehicleControl(throttle=0.896733, steer=0.003436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.652925279794943
Current reward: 0.3866625027273334
Current mitigation activation: 0
#############################
Total reward: 24.71001327842093
12.268408790230751 seconds in game passed.
Action: tensor([[[ 7.6819e-03,  7.0783e-01],
         [ 8.2732e-04,  3.9776e-01],
         [ 2.2352e-08,  2.7863e-01],
         [-3.8490e-04,  2.1561e-01]]])
agent 0 action: VehicleControl(throttle=0.842564, steer=0.003230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.71001327842093
12.29340879060328 seconds in game passed.
Action: tensor([[[ 7.6819e-03,  7.0783e-01],
         [ 8.2732e-04,  3.9776e-01],
         [ 2.2352e-08,  2.7863e-01],
         [-3.8490e-04,  2.1561e-01]]])
agent 0 action: VehicleControl(throttle=0.782546, steer=0.003256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.71001327842093
12.318408790975809 seconds in game passed.
Action: tensor([[[ 7.6819e-03,  7.0783e-01],
         [ 8.2732e-04,  3.9776e-01],
         [ 2.2352e-08,  2.7863e-01],
         [-3.8490e-04,  2.1561e-01]]])
agent 0 action: VehicleControl(throttle=0.722910, steer=0.003282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.71001327842093
+++++++++++++: 1.5577248606726322
12.343408791348338 seconds in game passed.
At 12.343408791348338 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.4642e-03,  7.4103e-01],
         [ 1.0401e-03,  4.1078e-01],
         [ 1.6242e-05,  2.8559e-01],
         [-3.9493e-04,  2.1990e-01]]])
agent 0 action: VehicleControl(throttle=0.600492, steer=0.004203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5577248606726322
Current reward: 0.39301719999420925
Current mitigation activation: 0
#############################
Total reward: 25.10303047841514
12.368408791720867 seconds in game passed.
Action: tensor([[[ 9.4642e-03,  7.4103e-01],
         [ 1.0401e-03,  4.1078e-01],
         [ 1.6242e-05,  2.8559e-01],
         [-3.9493e-04,  2.1990e-01]]])
agent 0 action: VehicleControl(throttle=0.549736, steer=0.004104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.10303047841514
12.393408792093396 seconds in game passed.
Action: tensor([[[ 9.4642e-03,  7.4103e-01],
         [ 1.0401e-03,  4.1078e-01],
         [ 1.6242e-05,  2.8559e-01],
         [-3.9493e-04,  2.1990e-01]]])
agent 0 action: VehicleControl(throttle=0.519192, steer=0.004151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.10303047841514
12.418408792465925 seconds in game passed.
Action: tensor([[[ 9.4642e-03,  7.4103e-01],
         [ 1.0401e-03,  4.1078e-01],
         [ 1.6242e-05,  2.8559e-01],
         [-3.9493e-04,  2.1990e-01]]])
agent 0 action: VehicleControl(throttle=0.495047, steer=0.004197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.10303047841514
+++++++++++++: 1.4704858438456252
12.443408792838454 seconds in game passed.
At 12.443408792838454 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1923e-02,  7.4388e-01],
         [ 1.3395e-03,  4.1329e-01],
         [-1.2068e-04,  2.8860e-01],
         [-7.7026e-04,  2.2276e-01]]])
agent 0 action: VehicleControl(throttle=0.470520, steer=0.005486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4704858438456252
Current reward: 0.39828259584615533
Current mitigation activation: 0
#############################
Total reward: 25.501313074261294
12.468408793210983 seconds in game passed.
Action: tensor([[[ 1.1923e-02,  7.4388e-01],
         [ 1.3395e-03,  4.1329e-01],
         [-1.2068e-04,  2.8860e-01],
         [-7.7026e-04,  2.2276e-01]]])
agent 0 action: VehicleControl(throttle=0.446472, steer=0.005332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.501313074261294
12.493408793583512 seconds in game passed.
Action: tensor([[[ 1.1923e-02,  7.4388e-01],
         [ 1.3395e-03,  4.1329e-01],
         [-1.2068e-04,  2.8860e-01],
         [-7.7026e-04,  2.2276e-01]]])
agent 0 action: VehicleControl(throttle=0.422899, steer=0.005385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.501313074261294
12.518408793956041 seconds in game passed.
Action: tensor([[[ 1.1923e-02,  7.4388e-01],
         [ 1.3395e-03,  4.1329e-01],
         [-1.2068e-04,  2.8860e-01],
         [-7.7026e-04,  2.2276e-01]]])
agent 0 action: VehicleControl(throttle=0.399800, steer=0.005438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.501313074261294
+++++++++++++: 1.3996846018356235
12.54340879432857 seconds in game passed.
At 12.54340879432857 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1902e-02,  7.7003e-01],
         [ 7.1370e-04,  4.1793e-01],
         [-1.2643e-03,  2.8984e-01],
         [-2.5399e-03,  2.2321e-01]]])
agent 0 action: VehicleControl(throttle=0.377461, steer=0.004961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3996846018356235
Current reward: 0.40081211858340116
Current mitigation activation: 0
#############################
Total reward: 25.902125192844696
12.5684087947011 seconds in game passed.
Action: tensor([[[ 1.1902e-02,  7.7003e-01],
         [ 7.1370e-04,  4.1793e-01],
         [-1.2643e-03,  2.8984e-01],
         [-2.5399e-03,  2.2321e-01]]])
agent 0 action: VehicleControl(throttle=0.355589, steer=0.005100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.902125192844696
12.593408795073628 seconds in game passed.
Action: tensor([[[ 1.1902e-02,  7.7003e-01],
         [ 7.1370e-04,  4.1793e-01],
         [-1.2643e-03,  2.8984e-01],
         [-2.5399e-03,  2.2321e-01]]])
agent 0 action: VehicleControl(throttle=0.334181, steer=0.005152, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.902125192844696
12.618408795446157 seconds in game passed.
Action: tensor([[[ 1.1902e-02,  7.7003e-01],
         [ 7.1370e-04,  4.1793e-01],
         [-1.2643e-03,  2.8984e-01],
         [-2.5399e-03,  2.2321e-01]]])
agent 0 action: VehicleControl(throttle=0.313236, steer=0.005203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.902125192844696
+++++++++++++: 1.3450888340891305
12.643408795818686 seconds in game passed.
At 12.643408795818686 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0537e-02,  7.9606e-01],
         [-6.8739e-04,  4.2977e-01],
         [-2.8197e-03,  2.9556e-01],
         [-4.0885e-03,  2.2539e-01]]])
agent 0 action: VehicleControl(throttle=0.293498, steer=0.003655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3450888340891305
Current reward: 0.4003477629996316
Current mitigation activation: 0
#############################
Total reward: 26.30247295584433
12.668408796191216 seconds in game passed.
Action: tensor([[[ 1.0537e-02,  7.9606e-01],
         [-6.8739e-04,  4.2977e-01],
         [-2.8197e-03,  2.9556e-01],
         [-4.0885e-03,  2.2539e-01]]])
agent 0 action: VehicleControl(throttle=0.274220, steer=0.003974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.30247295584433
12.693408796563745 seconds in game passed.
Action: tensor([[[ 1.0537e-02,  7.9606e-01],
         [-6.8739e-04,  4.2977e-01],
         [-2.8197e-03,  2.9556e-01],
         [-4.0885e-03,  2.2539e-01]]])
agent 0 action: VehicleControl(throttle=0.255399, steer=0.004026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.30247295584433
12.718408796936274 seconds in game passed.
Action: tensor([[[ 1.0537e-02,  7.9606e-01],
         [-6.8739e-04,  4.2977e-01],
         [-2.8197e-03,  2.9556e-01],
         [-4.0885e-03,  2.2539e-01]]])
agent 0 action: VehicleControl(throttle=0.237035, steer=0.004078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.30247295584433
+++++++++++++: 1.3035604937643095
12.743408797308803 seconds in game passed.
At 12.743408797308803 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0060,  0.8591],
         [-0.0047,  0.4590],
         [-0.0078,  0.3139],
         [-0.0091,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.219607, steer=-0.000781, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3035604937643095
Current reward: 0.39733944511466546
Current mitigation activation: 0
#############################
Total reward: 26.699812400958994
12.768408797681332 seconds in game passed.
Action: tensor([[[ 0.0060,  0.8591],
         [-0.0047,  0.4590],
         [-0.0078,  0.3139],
         [-0.0091,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.202632, steer=0.000055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.699812400958994
12.79340879805386 seconds in game passed.
Action: tensor([[[ 0.0060,  0.8591],
         [-0.0047,  0.4590],
         [-0.0078,  0.3139],
         [-0.0091,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.186109, steer=0.000078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.699812400958994
12.81840879842639 seconds in game passed.
Action: tensor([[[ 0.0060,  0.8591],
         [-0.0047,  0.4590],
         [-0.0078,  0.3139],
         [-0.0091,  0.2394]]])
agent 0 action: VehicleControl(throttle=0.170038, steer=0.000101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.699812400958994
+++++++++++++: 1.272749753919339
12.843408798798919 seconds in game passed.
At 12.843408798798919 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0059,  1.0000],
         [-0.0026,  1.0000],
         [-0.0067,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003379, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.272749753919339
Current reward: 0.39225383700831284
Current mitigation activation: 1
#############################
Total reward: 27.092066237967305
12.868408799171448 seconds in game passed.
Action: tensor([[[ 0.0059,  1.0000],
         [-0.0026,  1.0000],
         [-0.0067,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002864, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.092066237967305
12.893408799543977 seconds in game passed.
Action: tensor([[[ 0.0059,  1.0000],
         [-0.0026,  1.0000],
         [-0.0067,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002890, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.092066237967305
12.918408799916506 seconds in game passed.
Action: tensor([[[ 0.0059,  1.0000],
         [-0.0026,  1.0000],
         [-0.0067,  1.0000],
         [-0.0082,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002916, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.092066237967305
+++++++++++++: 1.254053912114197
12.943408800289035 seconds in game passed.
At 12.943408800289035 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0068,  1.0000],
         [-0.0099,  1.0000],
         [-0.0144,  1.0000],
         [-0.0146,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001171, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.254053912114197
Current reward: 0.3849539158334363
Current mitigation activation: 1
#############################
Total reward: 27.47702015380074
12.968408800661564 seconds in game passed.
Action: tensor([[[ 0.0068,  1.0000],
         [-0.0099,  1.0000],
         [-0.0144,  1.0000],
         [-0.0146,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000511, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.47702015380074
12.993408801034093 seconds in game passed.
Action: tensor([[[ 0.0068,  1.0000],
         [-0.0099,  1.0000],
         [-0.0144,  1.0000],
         [-0.0146,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000528, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.47702015380074
13.018408801406622 seconds in game passed.
Action: tensor([[[ 0.0068,  1.0000],
         [-0.0099,  1.0000],
         [-0.0144,  1.0000],
         [-0.0146,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000546, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.47702015380074
+++++++++++++: 1.2756742854727614
13.043408801779151 seconds in game passed.
At 13.043408801779151 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0073,  1.0000],
         [-0.0088,  1.0000],
         [-0.0106,  1.0000],
         [-0.0100,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000430, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2756742854727614
Current reward: 0.3705705733125313
Current mitigation activation: 1
#############################
Total reward: 27.84759072711327
13.06840880215168 seconds in game passed.
Action: tensor([[[ 0.0073,  1.0000],
         [-0.0088,  1.0000],
         [-0.0106,  1.0000],
         [-0.0100,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000241, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.84759072711327
13.093408802524209 seconds in game passed.
Action: tensor([[[ 0.0073,  1.0000],
         [-0.0088,  1.0000],
         [-0.0106,  1.0000],
         [-0.0100,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000218, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.84759072711327
13.118408802896738 seconds in game passed.
Action: tensor([[[ 0.0073,  1.0000],
         [-0.0088,  1.0000],
         [-0.0106,  1.0000],
         [-0.0100,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000196, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.84759072711327
+++++++++++++: 1.3655978512966485
13.143408803269267 seconds in game passed.
At 13.143408803269267 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0084,  0.9430],
         [-0.0110,  0.5721],
         [-0.0134,  0.3656],
         [-0.0126,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003262, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3655978512966485
Current reward: 0.3467502694925062
Current mitigation activation: 0
#############################
Total reward: 28.194340996605778
13.168408803641796 seconds in game passed.
Action: tensor([[[ 0.0084,  0.9430],
         [-0.0110,  0.5721],
         [-0.0134,  0.3656],
         [-0.0126,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002767, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.194340996605778
13.193408804014325 seconds in game passed.
Action: tensor([[[ 0.0084,  0.9430],
         [-0.0110,  0.5721],
         [-0.0134,  0.3656],
         [-0.0126,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002837, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.194340996605778
13.218408804386854 seconds in game passed.
Action: tensor([[[ 0.0084,  0.9430],
         [-0.0110,  0.5721],
         [-0.0134,  0.3656],
         [-0.0126,  0.2683]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002907, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.194340996605778
+++++++++++++: 1.5046456151850118
13.243408804759383 seconds in game passed.
At 13.243408804759383 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0100,  0.9459],
         [-0.0111,  0.5990],
         [-0.0126,  0.3747],
         [-0.0100,  0.2727]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002133, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5046456151850118
Current reward: 0.321086543644557
Current mitigation activation: 0
#############################
Total reward: 28.515427540250336
13.268408805131912 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9459],
         [-0.0111,  0.5990],
         [-0.0126,  0.3747],
         [-0.0100,  0.2727]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002350, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.515427540250336
13.293408805504441 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9459],
         [-0.0111,  0.5990],
         [-0.0126,  0.3747],
         [-0.0100,  0.2727]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002426, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.515427540250336
13.31840880587697 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9459],
         [-0.0111,  0.5990],
         [-0.0126,  0.3747],
         [-0.0100,  0.2727]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002502, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.515427540250336
+++++++++++++: 1.6931081475524516
13.3434088062495 seconds in game passed.
At 13.3434088062495 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0082,  0.9449],
         [-0.0111,  0.5973],
         [-0.0115,  0.3755],
         [-0.0088,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003410, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6931081475524516
Current reward: 0.29631982160463216
Current mitigation activation: 0
#############################
Total reward: 28.81174736185497
13.368408806622028 seconds in game passed.
Action: tensor([[[ 0.0082,  0.9449],
         [-0.0111,  0.5973],
         [-0.0115,  0.3755],
         [-0.0088,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.81174736185497
13.393408806994557 seconds in game passed.
Action: tensor([[[ 0.0082,  0.9449],
         [-0.0111,  0.5973],
         [-0.0115,  0.3755],
         [-0.0088,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.81174736185497
13.418408807367086 seconds in game passed.
Action: tensor([[[ 0.0082,  0.9449],
         [-0.0111,  0.5973],
         [-0.0115,  0.3755],
         [-0.0088,  0.2732]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.81174736185497
+++++++++++++: 1.9438558869756153
13.443408807739615 seconds in game passed.
At 13.443408807739615 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.5008e-03,  9.4624e-01],
         [-6.8566e-04,  6.0225e-01],
         [-3.1720e-03,  3.8195e-01],
         [-2.1525e-03,  2.7251e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001831, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9438558869756153
Current reward: 0.27316122617936534
Current mitigation activation: 0
#############################
Total reward: 29.084908588034335
13.468408808112144 seconds in game passed.
Action: tensor([[[ 3.5008e-03,  9.4624e-01],
         [-6.8566e-04,  6.0225e-01],
         [-3.1720e-03,  3.8195e-01],
         [-2.1525e-03,  2.7251e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.084908588034335
13.493408808484674 seconds in game passed.
Action: tensor([[[ 3.5008e-03,  9.4624e-01],
         [-6.8566e-04,  6.0225e-01],
         [-3.1720e-03,  3.8195e-01],
         [-2.1525e-03,  2.7251e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.084908588034335
13.518408808857203 seconds in game passed.
Action: tensor([[[ 3.5008e-03,  9.4624e-01],
         [-6.8566e-04,  6.0225e-01],
         [-3.1720e-03,  3.8195e-01],
         [-2.1525e-03,  2.7251e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000777, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.084908588034335
+++++++++++++: 2.0945890728809466
13.543408809229732 seconds in game passed.
At 13.543408809229732 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.1681e-03, 9.4301e-01],
         [3.7303e-03, 5.7237e-01],
         [5.7790e-04, 3.7123e-01],
         [1.0590e-04, 2.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.233170, steer=0.003366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0945890728809466
Current reward: 0.26306498125685096
Current mitigation activation: 0
#############################
Total reward: 29.347973569291185
13.56840880960226 seconds in game passed.
Action: tensor([[[2.1681e-03, 9.4301e-01],
         [3.7303e-03, 5.7237e-01],
         [5.7790e-04, 3.7123e-01],
         [1.0590e-04, 2.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.260283, steer=0.002915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.347973569291185
13.59340880997479 seconds in game passed.
Action: tensor([[[2.1681e-03, 9.4301e-01],
         [3.7303e-03, 5.7237e-01],
         [5.7790e-04, 3.7123e-01],
         [1.0590e-04, 2.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.313562, steer=0.002898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.347973569291185
13.618408810347319 seconds in game passed.
Action: tensor([[[2.1681e-03, 9.4301e-01],
         [3.7303e-03, 5.7237e-01],
         [5.7790e-04, 3.7123e-01],
         [1.0590e-04, 2.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.362188, steer=0.002881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.347973569291185
+++++++++++++: 2.2204616897592864
13.643408810719848 seconds in game passed.
At 13.643408810719848 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.9425],
         [ 0.0049,  0.5670],
         [ 0.0019,  0.3729],
         [ 0.0012,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.469076, steer=0.002265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2204616897592864
Current reward: 0.256585331660059
Current mitigation activation: 0
#############################
Total reward: 29.604558900951243
13.668408811092377 seconds in game passed.
Action: tensor([[[-0.0011,  0.9425],
         [ 0.0049,  0.5670],
         [ 0.0019,  0.3729],
         [ 0.0012,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.502871, steer=0.002360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.604558900951243
13.693408811464906 seconds in game passed.
Action: tensor([[[-0.0011,  0.9425],
         [ 0.0049,  0.5670],
         [ 0.0019,  0.3729],
         [ 0.0012,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.538604, steer=0.002353, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.604558900951243
13.718408811837435 seconds in game passed.
Action: tensor([[[-0.0011,  0.9425],
         [ 0.0049,  0.5670],
         [ 0.0019,  0.3729],
         [ 0.0012,  0.2729]]])
agent 0 action: VehicleControl(throttle=0.569196, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.604558900951243
+++++++++++++: 2.413289220941618
13.743408812209964 seconds in game passed.
At 13.743408812209964 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.4152e-03,  9.4424e-01],
         [ 3.2659e-03,  5.9446e-01],
         [ 1.1968e-03,  3.9048e-01],
         [ 5.6028e-04,  2.8813e-01]]])
agent 0 action: VehicleControl(throttle=0.282862, steer=0.000528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.413289220941618
Current reward: 0.24789242600706063
Current mitigation activation: 0
#############################
Total reward: 29.852451326958303
13.768408812582493 seconds in game passed.
Action: tensor([[[-2.4152e-03,  9.4424e-01],
         [ 3.2659e-03,  5.9446e-01],
         [ 1.1968e-03,  3.9048e-01],
         [ 5.6028e-04,  2.8813e-01]]])
agent 0 action: VehicleControl(throttle=0.333392, steer=0.000860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.852451326958303
13.793408812955022 seconds in game passed.
Action: tensor([[[-2.4152e-03,  9.4424e-01],
         [ 3.2659e-03,  5.9446e-01],
         [ 1.1968e-03,  3.9048e-01],
         [ 5.6028e-04,  2.8813e-01]]])
agent 0 action: VehicleControl(throttle=0.347527, steer=0.000886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.852451326958303
13.81840881332755 seconds in game passed.
Action: tensor([[[-2.4152e-03,  9.4424e-01],
         [ 3.2659e-03,  5.9446e-01],
         [ 1.1968e-03,  3.9048e-01],
         [ 5.6028e-04,  2.8813e-01]]])
agent 0 action: VehicleControl(throttle=0.361081, steer=0.000911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.852451326958303
+++++++++++++: 2.532004160795045
13.84340881370008 seconds in game passed.
At 13.84340881370008 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.0803e-04,  9.2966e-01],
         [ 1.0127e-03,  5.2377e-01],
         [-1.9761e-03,  3.5192e-01],
         [-2.3350e-03,  2.6086e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.532004160795045
Current reward: 0.24465425418806847
Current mitigation activation: 0
#############################
Total reward: 30.09710558114637
13.868408814072609 seconds in game passed.
Action: tensor([[[-5.0803e-04,  9.2966e-01],
         [ 1.0127e-03,  5.2377e-01],
         [-1.9761e-03,  3.5192e-01],
         [-2.3350e-03,  2.6086e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000270, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.09710558114637
13.893408814445138 seconds in game passed.
Action: tensor([[[-5.0803e-04,  9.2966e-01],
         [ 1.0127e-03,  5.2377e-01],
         [-1.9761e-03,  3.5192e-01],
         [-2.3350e-03,  2.6086e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.09710558114637
13.918408814817667 seconds in game passed.
Action: tensor([[[-5.0803e-04,  9.2966e-01],
         [ 1.0127e-03,  5.2377e-01],
         [-1.9761e-03,  3.5192e-01],
         [-2.3350e-03,  2.6086e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.09710558114637
+++++++++++++: 2.6081046596367092
13.943408815190196 seconds in game passed.
At 13.943408815190196 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.5768e-03,  9.1844e-01],
         [-8.5267e-04,  5.0707e-01],
         [-1.9640e-03,  3.4716e-01],
         [-9.7033e-04,  2.6201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6081046596367092
Current reward: 0.24401449385543172
Current mitigation activation: 0
#############################
Total reward: 30.3411200750018
13.968408815562725 seconds in game passed.
Action: tensor([[[-4.5768e-03,  9.1844e-01],
         [-8.5267e-04,  5.0707e-01],
         [-1.9640e-03,  3.4716e-01],
         [-9.7033e-04,  2.6201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.3411200750018
13.993408815935254 seconds in game passed.
Action: tensor([[[-4.5768e-03,  9.1844e-01],
         [-8.5267e-04,  5.0707e-01],
         [-1.9640e-03,  3.4716e-01],
         [-9.7033e-04,  2.6201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.3411200750018
14.018408816307783 seconds in game passed.
Action: tensor([[[-4.5768e-03,  9.1844e-01],
         [-8.5267e-04,  5.0707e-01],
         [-1.9640e-03,  3.4716e-01],
         [-9.7033e-04,  2.6201e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.3411200750018
+++++++++++++: 2.609545144839979
14.043408816680312 seconds in game passed.
At 14.043408816680312 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0120,  0.9211],
         [-0.0034,  0.5284],
         [-0.0047,  0.3679],
         [-0.0041,  0.2815]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.609545144839979
Current reward: 0.2469267639230153
Current mitigation activation: 0
#############################
Total reward: 30.588046838924814
14.068408817052841 seconds in game passed.
Action: tensor([[[-0.0120,  0.9211],
         [-0.0034,  0.5284],
         [-0.0047,  0.3679],
         [-0.0041,  0.2815]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.588046838924814
14.09340881742537 seconds in game passed.
Action: tensor([[[-0.0120,  0.9211],
         [-0.0034,  0.5284],
         [-0.0047,  0.3679],
         [-0.0041,  0.2815]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006853, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.588046838924814
14.1184088177979 seconds in game passed.
Action: tensor([[[-0.0120,  0.9211],
         [-0.0034,  0.5284],
         [-0.0047,  0.3679],
         [-0.0041,  0.2815]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.588046838924814
+++++++++++++: 2.5169160718103716
14.143408818170428 seconds in game passed.
At 14.143408818170428 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0085,  0.8989],
         [-0.0067,  0.5150],
         [-0.0081,  0.3750],
         [-0.0071,  0.2990]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5169160718103716
Current reward: 0.2541888980085958
Current mitigation activation: 0
#############################
Total reward: 30.84223573693341
14.168408818542957 seconds in game passed.
Action: tensor([[[-0.0085,  0.8989],
         [-0.0067,  0.5150],
         [-0.0081,  0.3750],
         [-0.0071,  0.2990]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.84223573693341
14.193408818915486 seconds in game passed.
Action: tensor([[[-0.0085,  0.8989],
         [-0.0067,  0.5150],
         [-0.0081,  0.3750],
         [-0.0071,  0.2990]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.84223573693341
14.218408819288015 seconds in game passed.
Action: tensor([[[-0.0085,  0.8989],
         [-0.0067,  0.5150],
         [-0.0081,  0.3750],
         [-0.0071,  0.2990]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.84223573693341
+++++++++++++: 2.3848985404572987
14.243408819660544 seconds in game passed.
At 14.243408819660544 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.7495e-04,  8.7001e-01],
         [-2.5016e-03,  4.9778e-01],
         [-4.4243e-03,  3.6194e-01],
         [-3.8362e-03,  2.8694e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3848985404572987
Current reward: 0.2635637815990104
Current mitigation activation: 0
#############################
Total reward: 31.10579951853242
14.268408820033073 seconds in game passed.
Action: tensor([[[ 1.7495e-04,  8.7001e-01],
         [-2.5016e-03,  4.9778e-01],
         [-4.4243e-03,  3.6194e-01],
         [-3.8362e-03,  2.8694e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.10579951853242
14.293408820405602 seconds in game passed.
Action: tensor([[[ 1.7495e-04,  8.7001e-01],
         [-2.5016e-03,  4.9778e-01],
         [-4.4243e-03,  3.6194e-01],
         [-3.8362e-03,  2.8694e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.10579951853242
14.318408820778131 seconds in game passed.
Action: tensor([[[ 1.7495e-04,  8.7001e-01],
         [-2.5016e-03,  4.9778e-01],
         [-4.4243e-03,  3.6194e-01],
         [-3.8362e-03,  2.8694e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.10579951853242
+++++++++++++: 2.2443505469577314
14.34340882115066 seconds in game passed.
At 14.34340882115066 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0054,  0.8860],
         [-0.0035,  0.4993],
         [-0.0044,  0.3557],
         [-0.0038,  0.2778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2443505469577314
Current reward: 0.2737389933705182
Current mitigation activation: 0
#############################
Total reward: 31.37953851190294
14.36840882152319 seconds in game passed.
Action: tensor([[[-0.0054,  0.8860],
         [-0.0035,  0.4993],
         [-0.0044,  0.3557],
         [-0.0038,  0.2778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.37953851190294
14.393408821895719 seconds in game passed.
Action: tensor([[[-0.0054,  0.8860],
         [-0.0035,  0.4993],
         [-0.0044,  0.3557],
         [-0.0038,  0.2778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.37953851190294
14.418408822268248 seconds in game passed.
Action: tensor([[[-0.0054,  0.8860],
         [-0.0035,  0.4993],
         [-0.0044,  0.3557],
         [-0.0038,  0.2778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004729, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.37953851190294
+++++++++++++: 2.107523368087543
14.443408822640777 seconds in game passed.
At 14.443408822640777 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.2049e-03,  9.1078e-01],
         [-6.9693e-04,  5.0098e-01],
         [-2.3658e-03,  3.4301e-01],
         [-1.9903e-03,  2.5867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.107523368087543
Current reward: 0.2840654077531748
Current mitigation activation: 0
#############################
Total reward: 31.663603919656115
14.468408823013306 seconds in game passed.
Action: tensor([[[-6.2049e-03,  9.1078e-01],
         [-6.9693e-04,  5.0098e-01],
         [-2.3658e-03,  3.4301e-01],
         [-1.9903e-03,  2.5867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.663603919656115
14.493408823385835 seconds in game passed.
Action: tensor([[[-6.2049e-03,  9.1078e-01],
         [-6.9693e-04,  5.0098e-01],
         [-2.3658e-03,  3.4301e-01],
         [-1.9903e-03,  2.5867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.663603919656115
14.518408823758364 seconds in game passed.
Action: tensor([[[-6.2049e-03,  9.1078e-01],
         [-6.9693e-04,  5.0098e-01],
         [-2.3658e-03,  3.4301e-01],
         [-1.9903e-03,  2.5867e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.663603919656115
+++++++++++++: 1.9784666182435833
14.543408824130893 seconds in game passed.
At 14.543408824130893 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0033,  0.9061],
         [-0.0023,  0.4880],
         [-0.0048,  0.3315],
         [-0.0044,  0.2477]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9784666182435833
Current reward: 0.29422089956077896
Current mitigation activation: 0
#############################
Total reward: 31.957824819216896
14.568408824503422 seconds in game passed.
Action: tensor([[[ 0.0033,  0.9061],
         [-0.0023,  0.4880],
         [-0.0048,  0.3315],
         [-0.0044,  0.2477]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.957824819216896
14.59340882487595 seconds in game passed.
Action: tensor([[[ 0.0033,  0.9061],
         [-0.0023,  0.4880],
         [-0.0048,  0.3315],
         [-0.0044,  0.2477]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.957824819216896
14.61840882524848 seconds in game passed.
Action: tensor([[[ 0.0033,  0.9061],
         [-0.0023,  0.4880],
         [-0.0048,  0.3315],
         [-0.0044,  0.2477]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.957824819216896
+++++++++++++: 1.8580363243711138
14.643408825621009 seconds in game passed.
At 14.643408825621009 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.9195],
         [-0.0014,  0.4905],
         [-0.0036,  0.3273],
         [-0.0024,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8580363243711138
Current reward: 0.3040382423677152
Current mitigation activation: 0
#############################
Total reward: 32.26186306158461
14.668408825993538 seconds in game passed.
Action: tensor([[[ 0.0057,  0.9195],
         [-0.0014,  0.4905],
         [-0.0036,  0.3273],
         [-0.0024,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000009, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.26186306158461
14.693408826366067 seconds in game passed.
Action: tensor([[[ 0.0057,  0.9195],
         [-0.0014,  0.4905],
         [-0.0036,  0.3273],
         [-0.0024,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.883809, steer=-0.000029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.26186306158461
14.718408826738596 seconds in game passed.
Action: tensor([[[ 0.0057,  0.9195],
         [-0.0014,  0.4905],
         [-0.0036,  0.3273],
         [-0.0024,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.845894, steer=-0.000049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.26186306158461
+++++++++++++: 1.7458085432845438
14.743408827111125 seconds in game passed.
At 14.743408827111125 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.6712e-03,  9.2933e-01],
         [-6.1438e-04,  5.0700e-01],
         [-2.1137e-03,  3.3582e-01],
         [-3.9077e-04,  2.4715e-01]]])
agent 0 action: VehicleControl(throttle=0.596249, steer=0.001021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7458085432845438
Current reward: 0.3134199617630227
Current mitigation activation: 0
#############################
Total reward: 32.57528302334764
14.768408827483654 seconds in game passed.
Action: tensor([[[ 6.6712e-03,  9.2933e-01],
         [-6.1438e-04,  5.0700e-01],
         [-2.1137e-03,  3.3582e-01],
         [-3.9077e-04,  2.4715e-01]]])
agent 0 action: VehicleControl(throttle=0.581389, steer=0.000855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.57528302334764
14.793408827856183 seconds in game passed.
Action: tensor([[[ 6.6712e-03,  9.2933e-01],
         [-6.1438e-04,  5.0700e-01],
         [-2.1137e-03,  3.3582e-01],
         [-3.9077e-04,  2.4715e-01]]])
agent 0 action: VehicleControl(throttle=0.544255, steer=0.000865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.57528302334764
14.818408828228712 seconds in game passed.
Action: tensor([[[ 6.6712e-03,  9.2933e-01],
         [-6.1438e-04,  5.0700e-01],
         [-2.1137e-03,  3.3582e-01],
         [-3.9077e-04,  2.4715e-01]]])
agent 0 action: VehicleControl(throttle=0.509662, steer=0.000876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.57528302334764
+++++++++++++: 1.6432684579003256
14.843408828601241 seconds in game passed.
At 14.843408828601241 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.4859e-03,  9.3497e-01],
         [ 6.4440e-04,  5.2213e-01],
         [-1.3288e-03,  3.4155e-01],
         [ 2.0622e-04,  2.4886e-01]]])
agent 0 action: VehicleControl(throttle=0.346372, steer=0.002683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6432684579003256
Current reward: 0.3220537178203402
Current mitigation activation: 0
#############################
Total reward: 32.897336741167976
14.86840882897377 seconds in game passed.
Action: tensor([[[ 8.4859e-03,  9.3497e-01],
         [ 6.4440e-04,  5.2213e-01],
         [-1.3288e-03,  3.4155e-01],
         [ 2.0622e-04,  2.4886e-01]]])
agent 0 action: VehicleControl(throttle=0.349715, steer=0.002425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.897336741167976
14.8934088293463 seconds in game passed.
Action: tensor([[[ 8.4859e-03,  9.3497e-01],
         [ 6.4440e-04,  5.2213e-01],
         [-1.3288e-03,  3.4155e-01],
         [ 2.0622e-04,  2.4886e-01]]])
agent 0 action: VehicleControl(throttle=0.336457, steer=0.002462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.897336741167976
14.918408829718828 seconds in game passed.
Action: tensor([[[ 8.4859e-03,  9.3497e-01],
         [ 6.4440e-04,  5.2213e-01],
         [-1.3288e-03,  3.4155e-01],
         [ 2.0622e-04,  2.4886e-01]]])
agent 0 action: VehicleControl(throttle=0.323151, steer=0.002498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.897336741167976
+++++++++++++: 1.5655476378344242
14.943408830091357 seconds in game passed.
At 14.943408830091357 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.9711e-04,  9.3370e-01],
         [-8.1147e-04,  5.1248e-01],
         [-1.5580e-03,  3.3702e-01],
         [ 2.0102e-05,  2.4853e-01]]])
agent 0 action: VehicleControl(throttle=0.307701, steer=-0.001790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5655476378344242
Current reward: 0.3278858704529994
Current mitigation activation: 0
#############################
Total reward: 33.22522261162098
14.968408830463886 seconds in game passed.
Action: tensor([[[ 8.9711e-04,  9.3370e-01],
         [-8.1147e-04,  5.1248e-01],
         [-1.5580e-03,  3.3702e-01],
         [ 2.0102e-05,  2.4853e-01]]])
agent 0 action: VehicleControl(throttle=0.292333, steer=-0.001048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.22522261162098
14.993408830836415 seconds in game passed.
Action: tensor([[[ 8.9711e-04,  9.3370e-01],
         [-8.1147e-04,  5.1248e-01],
         [-1.5580e-03,  3.3702e-01],
         [ 2.0102e-05,  2.4853e-01]]])
agent 0 action: VehicleControl(throttle=0.277114, steer=-0.001023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.22522261162098
15.018408831208944 seconds in game passed.
Action: tensor([[[ 8.9711e-04,  9.3370e-01],
         [-8.1147e-04,  5.1248e-01],
         [-1.5580e-03,  3.3702e-01],
         [ 2.0102e-05,  2.4853e-01]]])
agent 0 action: VehicleControl(throttle=0.262101, steer=-0.000999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.22522261162098
+++++++++++++: 1.5220003512482982
15.043408831581473 seconds in game passed.
At 15.043408831581473 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0074,  0.9324],
         [-0.0014,  0.5165],
         [-0.0025,  0.3446],
         [-0.0018,  0.2566]]])
agent 0 action: VehicleControl(throttle=0.250662, steer=-0.004894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5220003512482982
Current reward: 0.3292831273796646
Current mitigation activation: 0
#############################
Total reward: 33.554505739000646
15.068408831954002 seconds in game passed.
Action: tensor([[[-0.0074,  0.9324],
         [-0.0014,  0.5165],
         [-0.0025,  0.3446],
         [-0.0018,  0.2566]]])
agent 0 action: VehicleControl(throttle=0.239514, steer=-0.004203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.554505739000646
15.093408832326531 seconds in game passed.
Action: tensor([[[-0.0074,  0.9324],
         [-0.0014,  0.5165],
         [-0.0025,  0.3446],
         [-0.0018,  0.2566]]])
agent 0 action: VehicleControl(throttle=0.228691, steer=-0.004166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.554505739000646
15.11840883269906 seconds in game passed.
Action: tensor([[[-0.0074,  0.9324],
         [-0.0014,  0.5165],
         [-0.0025,  0.3446],
         [-0.0018,  0.2566]]])
agent 0 action: VehicleControl(throttle=0.218220, steer=-0.004130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.554505739000646
+++++++++++++: 1.500945030729099
15.14340883307159 seconds in game passed.
At 15.14340883307159 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.9162e-03,  9.4117e-01],
         [ 9.6913e-04,  5.5742e-01],
         [-2.1727e-04,  3.6406e-01],
         [-4.2342e-04,  2.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003109, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.500945030729099
Current reward: 0.3276194045377162
Current mitigation activation: 0
#############################
Total reward: 33.88212514353836
15.168408833444118 seconds in game passed.
Action: tensor([[[-8.9162e-03,  9.4117e-01],
         [ 9.6913e-04,  5.5742e-01],
         [-2.1727e-04,  3.6406e-01],
         [-4.2342e-04,  2.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003213, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.88212514353836
15.193408833816648 seconds in game passed.
Action: tensor([[[-8.9162e-03,  9.4117e-01],
         [ 9.6913e-04,  5.5742e-01],
         [-2.1727e-04,  3.6406e-01],
         [-4.2342e-04,  2.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003156, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.88212514353836
15.218408834189177 seconds in game passed.
Action: tensor([[[-8.9162e-03,  9.4117e-01],
         [ 9.6913e-04,  5.5742e-01],
         [-2.1727e-04,  3.6406e-01],
         [-4.2342e-04,  2.6861e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003100, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.88212514353836
+++++++++++++: 1.491004198386494
15.243408834561706 seconds in game passed.
At 15.243408834561706 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0133,  0.9442],
         [-0.0029,  0.5800],
         [-0.0030,  0.3669],
         [-0.0030,  0.2649]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.008133, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.491004198386494
Current reward: 0.3245273301801783
Current mitigation activation: 0
#############################
Total reward: 34.20665247371854
15.268408834934235 seconds in game passed.
Action: tensor([[[-0.0133,  0.9442],
         [-0.0029,  0.5800],
         [-0.0030,  0.3669],
         [-0.0030,  0.2649]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007372, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.20665247371854
15.293408835306764 seconds in game passed.
Action: tensor([[[-0.0133,  0.9442],
         [-0.0029,  0.5800],
         [-0.0030,  0.3669],
         [-0.0030,  0.2649]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007438, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.20665247371854
15.318408835679293 seconds in game passed.
Action: tensor([[[-0.0133,  0.9442],
         [-0.0029,  0.5800],
         [-0.0030,  0.3669],
         [-0.0030,  0.2649]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.007505, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.20665247371854
+++++++++++++: 1.5641371985481816
15.343408836051822 seconds in game passed.
At 15.343408836051822 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0182,  0.9467],
         [-0.0036,  0.6032],
         [-0.0033,  0.3780],
         [-0.0026,  0.2717]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010492, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5641371985481816
Current reward: 0.3114687096780714
Current mitigation activation: 0
#############################
Total reward: 34.518121183396616
15.36840883642435 seconds in game passed.
Action: tensor([[[-0.0182,  0.9467],
         [-0.0036,  0.6032],
         [-0.0033,  0.3780],
         [-0.0026,  0.2717]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010069, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.518121183396616
15.39340883679688 seconds in game passed.
Action: tensor([[[-0.0182,  0.9467],
         [-0.0036,  0.6032],
         [-0.0033,  0.3780],
         [-0.0026,  0.2717]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010134, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.518121183396616
15.418408837169409 seconds in game passed.
Action: tensor([[[-0.0182,  0.9467],
         [-0.0036,  0.6032],
         [-0.0033,  0.3780],
         [-0.0026,  0.2717]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010199, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.518121183396616
+++++++++++++: 1.7600075932460908
15.443408837541938 seconds in game passed.
At 15.443408837541938 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.2809e-02,  9.4904e-01],
         [-4.6306e-03,  6.6724e-01],
         [-1.1996e-03,  4.1141e-01],
         [ 1.6689e-04,  2.9513e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013844, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7600075932460908
Current reward: 0.2884383145823112
Current mitigation activation: 0
#############################
Total reward: 34.806559497978924
15.468408837914467 seconds in game passed.
Action: tensor([[[-2.2809e-02,  9.4904e-01],
         [-4.6306e-03,  6.6724e-01],
         [-1.1996e-03,  4.1141e-01],
         [ 1.6689e-04,  2.9513e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013377, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.806559497978924
15.493408838286996 seconds in game passed.
Action: tensor([[[-2.2809e-02,  9.4904e-01],
         [-4.6306e-03,  6.6724e-01],
         [-1.1996e-03,  4.1141e-01],
         [ 1.6689e-04,  2.9513e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013497, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.806559497978924
15.518408838659525 seconds in game passed.
Action: tensor([[[-2.2809e-02,  9.4904e-01],
         [-4.6306e-03,  6.6724e-01],
         [-1.1996e-03,  4.1141e-01],
         [ 1.6689e-04,  2.9513e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013617, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.806559497978924
+++++++++++++: 2.0479900532080326
15.543408839032054 seconds in game passed.
At 15.543408839032054 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6438e-02,  9.4717e-01],
         [-1.2817e-04,  6.1450e-01],
         [ 8.0078e-04,  3.9117e-01],
         [ 1.0057e-03,  2.8532e-01]]])
agent 0 action: VehicleControl(throttle=0.059610, steer=-0.006899, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0479900532080326
Current reward: 0.2648750260073429
Current mitigation activation: 0
#############################
Total reward: 35.07143452398627
15.568408839404583 seconds in game passed.
Action: tensor([[[-1.6438e-02,  9.4717e-01],
         [-1.2817e-04,  6.1450e-01],
         [ 8.0078e-04,  3.9117e-01],
         [ 1.0057e-03,  2.8532e-01]]])
agent 0 action: VehicleControl(throttle=0.051177, steer=-0.008109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.07143452398627
15.593408839777112 seconds in game passed.
Action: tensor([[[-1.6438e-02,  9.4717e-01],
         [-1.2817e-04,  6.1450e-01],
         [ 8.0078e-04,  3.9117e-01],
         [ 1.0057e-03,  2.8532e-01]]])
agent 0 action: VehicleControl(throttle=0.043215, steer=-0.008186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.07143452398627
15.618408840149641 seconds in game passed.
Action: tensor([[[-1.6438e-02,  9.4717e-01],
         [-1.2817e-04,  6.1450e-01],
         [ 8.0078e-04,  3.9117e-01],
         [ 1.0057e-03,  2.8532e-01]]])
agent 0 action: VehicleControl(throttle=0.035722, steer=-0.008264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.07143452398627
+++++++++++++: 2.2541366386214188
15.64340884052217 seconds in game passed.
At 15.64340884052217 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.4306e-03,  9.4200e-01],
         [ 2.3837e-03,  5.5286e-01],
         [ 6.9059e-04,  3.6141e-01],
         [ 1.0322e-03,  2.6394e-01]]])
agent 0 action: VehicleControl(throttle=0.638023, steer=0.000275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2541366386214188
Current reward: 0.2531573693827184
Current mitigation activation: 0
#############################
Total reward: 35.32459189336899
15.668408840894699 seconds in game passed.
Action: tensor([[[-2.4306e-03,  9.4200e-01],
         [ 2.3837e-03,  5.5286e-01],
         [ 6.9059e-04,  3.6141e-01],
         [ 1.0322e-03,  2.6394e-01]]])
agent 0 action: VehicleControl(throttle=0.556800, steer=-0.001155, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.32459189336899
15.693408841267228 seconds in game passed.
Action: tensor([[[-2.4306e-03,  9.4200e-01],
         [ 2.3837e-03,  5.5286e-01],
         [ 6.9059e-04,  3.6141e-01],
         [ 1.0322e-03,  2.6394e-01]]])
agent 0 action: VehicleControl(throttle=0.543561, steer=-0.001160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.32459189336899
15.718408841639757 seconds in game passed.
Action: tensor([[[-2.4306e-03,  9.4200e-01],
         [ 2.3837e-03,  5.5286e-01],
         [ 6.9059e-04,  3.6141e-01],
         [ 1.0322e-03,  2.6394e-01]]])
agent 0 action: VehicleControl(throttle=0.534775, steer=-0.001166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.32459189336899
+++++++++++++: 2.2174061062912633
15.743408842012286 seconds in game passed.
At 15.743408842012286 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.0070e-03,  9.3789e-01],
         [ 3.2295e-03,  5.3415e-01],
         [ 2.7996e-04,  3.5585e-01],
         [ 5.0217e-06,  2.6262e-01]]])
agent 0 action: VehicleControl(throttle=0.760505, steer=0.000115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2174061062912633
Current reward: 0.25744553263985825
Current mitigation activation: 0
#############################
Total reward: 35.582037426008846
15.768408842384815 seconds in game passed.
Action: tensor([[[-1.0070e-03,  9.3789e-01],
         [ 3.2295e-03,  5.3415e-01],
         [ 2.7996e-04,  3.5585e-01],
         [ 5.0217e-06,  2.6262e-01]]])
agent 0 action: VehicleControl(throttle=0.733700, steer=-0.000102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.582037426008846
15.793408842757344 seconds in game passed.
Action: tensor([[[-1.0070e-03,  9.3789e-01],
         [ 3.2295e-03,  5.3415e-01],
         [ 2.7996e-04,  3.5585e-01],
         [ 5.0217e-06,  2.6262e-01]]])
agent 0 action: VehicleControl(throttle=0.730531, steer=-0.000105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.582037426008846
15.818408843129873 seconds in game passed.
Action: tensor([[[-1.0070e-03,  9.3789e-01],
         [ 3.2295e-03,  5.3415e-01],
         [ 2.7996e-04,  3.5585e-01],
         [ 5.0217e-06,  2.6262e-01]]])
agent 0 action: VehicleControl(throttle=0.725363, steer=-0.000109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.582037426008846
+++++++++++++: 2.192307348212971
15.843408843502402 seconds in game passed.
At 15.843408843502402 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2913e-02,  9.3593e-01],
         [ 4.6324e-03,  5.2677e-01],
         [-1.3635e-05,  3.4671e-01],
         [-2.9565e-04,  2.5101e-01]]])
agent 0 action: VehicleControl(throttle=0.813615, steer=0.006924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.192307348212971
Current reward: 0.26085545163713453
Current mitigation activation: 0
#############################
Total reward: 35.84289287764598
15.868408843874931 seconds in game passed.
Action: tensor([[[ 1.2913e-02,  9.3593e-01],
         [ 4.6324e-03,  5.2677e-01],
         [-1.3635e-05,  3.4671e-01],
         [-2.9565e-04,  2.5101e-01]]])
agent 0 action: VehicleControl(throttle=0.797021, steer=0.005812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.84289287764598
15.89340884424746 seconds in game passed.
Action: tensor([[[ 1.2913e-02,  9.3593e-01],
         [ 4.6324e-03,  5.2677e-01],
         [-1.3635e-05,  3.4671e-01],
         [-2.9565e-04,  2.5101e-01]]])
agent 0 action: VehicleControl(throttle=0.788507, steer=0.005863, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.84289287764598
15.91840884461999 seconds in game passed.
Action: tensor([[[ 1.2913e-02,  9.3593e-01],
         [ 4.6324e-03,  5.2677e-01],
         [-1.3635e-05,  3.4671e-01],
         [-2.9565e-04,  2.5101e-01]]])
agent 0 action: VehicleControl(throttle=0.777741, steer=0.005914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.84289287764598
+++++++++++++: 2.1445826246726063
15.943408844992518 seconds in game passed.
At 15.943408844992518 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0175, 0.9302],
         [0.0057, 0.5207],
         [0.0013, 0.3446],
         [0.0010, 0.2486]]])
agent 0 action: VehicleControl(throttle=0.826007, steer=0.008764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1445826246726063
Current reward: 0.26555846164567026
Current mitigation activation: 0
#############################
Total reward: 36.10845133929165
15.968408845365047 seconds in game passed.
Action: tensor([[[0.0175, 0.9302],
         [0.0057, 0.5207],
         [0.0013, 0.3446],
         [0.0010, 0.2486]]])
agent 0 action: VehicleControl(throttle=0.806432, steer=0.008434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.10845133929165
15.993408845737576 seconds in game passed.
Action: tensor([[[0.0175, 0.9302],
         [0.0057, 0.5207],
         [0.0013, 0.3446],
         [0.0010, 0.2486]]])
agent 0 action: VehicleControl(throttle=0.791970, steer=0.008559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.10845133929165
16.018408846110106 seconds in game passed.
Action: tensor([[[0.0175, 0.9302],
         [0.0057, 0.5207],
         [0.0013, 0.3446],
         [0.0010, 0.2486]]])
agent 0 action: VehicleControl(throttle=0.776066, steer=0.008683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.10845133929165
+++++++++++++: 2.071990517421734
16.043408846482635 seconds in game passed.
At 16.043408846482635 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0192, 0.9314],
         [0.0046, 0.5211],
         [0.0015, 0.3440],
         [0.0017, 0.2478]]])
agent 0 action: VehicleControl(throttle=0.759121, steer=0.008700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.071990517421734
Current reward: 0.27180790129163984
Current mitigation activation: 0
#############################
Total reward: 36.380259240583285
16.068408846855164 seconds in game passed.
Action: tensor([[[0.0192, 0.9314],
         [0.0046, 0.5211],
         [0.0015, 0.3440],
         [0.0017, 0.2478]]])
agent 0 action: VehicleControl(throttle=0.741460, steer=0.008889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.380259240583285
16.093408847227693 seconds in game passed.
Action: tensor([[[0.0192, 0.9314],
         [0.0046, 0.5211],
         [0.0015, 0.3440],
         [0.0017, 0.2478]]])
agent 0 action: VehicleControl(throttle=0.723294, steer=0.009053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.380259240583285
16.11840884760022 seconds in game passed.
Action: tensor([[[0.0192, 0.9314],
         [0.0046, 0.5211],
         [0.0015, 0.3440],
         [0.0017, 0.2478]]])
agent 0 action: VehicleControl(throttle=0.704846, steer=0.009217, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.380259240583285
+++++++++++++: 1.9887279134762292
16.14340884797275 seconds in game passed.
At 16.14340884797275 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0199, 0.9326],
         [0.0044, 0.5178],
         [0.0015, 0.3424],
         [0.0021, 0.2481]]])
agent 0 action: VehicleControl(throttle=0.740145, steer=0.009509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9887279134762292
Current reward: 0.27876378301463134
Current mitigation activation: 0
#############################
Total reward: 36.65902302359792
16.16840884834528 seconds in game passed.
Action: tensor([[[0.0199, 0.9326],
         [0.0044, 0.5178],
         [0.0015, 0.3424],
         [0.0021, 0.2481]]])
agent 0 action: VehicleControl(throttle=0.716579, steer=0.009642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.65902302359792
16.19340884871781 seconds in game passed.
Action: tensor([[[0.0199, 0.9326],
         [0.0044, 0.5178],
         [0.0015, 0.3424],
         [0.0021, 0.2481]]])
agent 0 action: VehicleControl(throttle=0.698699, steer=0.009797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.65902302359792
16.218408849090338 seconds in game passed.
Action: tensor([[[0.0199, 0.9326],
         [0.0044, 0.5178],
         [0.0015, 0.3424],
         [0.0021, 0.2481]]])
agent 0 action: VehicleControl(throttle=0.680623, steer=0.009952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.65902302359792
+++++++++++++: 1.9076839208322334
16.243408849462867 seconds in game passed.
At 16.243408849462867 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.2184e-03,  9.3919e-01],
         [ 1.6704e-03,  5.3644e-01],
         [-6.2474e-04,  3.5063e-01],
         [-2.5385e-04,  2.5368e-01]]])
agent 0 action: VehicleControl(throttle=0.428375, steer=0.001874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9076839208322334
Current reward: 0.28551241750142703
Current mitigation activation: 0
#############################
Total reward: 36.94453544109935
16.268408849835396 seconds in game passed.
Action: tensor([[[ 5.2184e-03,  9.3919e-01],
         [ 1.6704e-03,  5.3644e-01],
         [-6.2474e-04,  3.5063e-01],
         [-2.5385e-04,  2.5368e-01]]])
agent 0 action: VehicleControl(throttle=0.432723, steer=0.003363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.94453544109935
16.293408850207925 seconds in game passed.
Action: tensor([[[ 5.2184e-03,  9.3919e-01],
         [ 1.6704e-03,  5.3644e-01],
         [-6.2474e-04,  3.5063e-01],
         [-2.5385e-04,  2.5368e-01]]])
agent 0 action: VehicleControl(throttle=0.413071, steer=0.003484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.94453544109935
16.318408850580454 seconds in game passed.
Action: tensor([[[ 5.2184e-03,  9.3919e-01],
         [ 1.6704e-03,  5.3644e-01],
         [-6.2474e-04,  3.5063e-01],
         [-2.5385e-04,  2.5368e-01]]])
agent 0 action: VehicleControl(throttle=0.396352, steer=0.003606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.94453544109935
+++++++++++++: 1.8346911049573282
16.343408850952983 seconds in game passed.
At 16.343408850952983 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.8541e-04,  9.4098e-01],
         [ 4.8234e-04,  5.4735e-01],
         [-1.6632e-03,  3.5845e-01],
         [-1.2775e-03,  2.6068e-01]]])
agent 0 action: VehicleControl(throttle=0.244043, steer=0.000464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8346911049573282
Current reward: 0.29151514515725935
Current mitigation activation: 0
#############################
Total reward: 37.23605058625661
16.368408851325512 seconds in game passed.
Action: tensor([[[-2.8541e-04,  9.4098e-01],
         [ 4.8234e-04,  5.4735e-01],
         [-1.6632e-03,  3.5845e-01],
         [-1.2775e-03,  2.6068e-01]]])
agent 0 action: VehicleControl(throttle=0.245159, steer=0.001125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.23605058625661
16.39340885169804 seconds in game passed.
Action: tensor([[[-2.8541e-04,  9.4098e-01],
         [ 4.8234e-04,  5.4735e-01],
         [-1.6632e-03,  3.5845e-01],
         [-1.2775e-03,  2.6068e-01]]])
agent 0 action: VehicleControl(throttle=0.234236, steer=0.001243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.23605058625661
16.41840885207057 seconds in game passed.
Action: tensor([[[-2.8541e-04,  9.4098e-01],
         [ 4.8234e-04,  5.4735e-01],
         [-1.6632e-03,  3.5845e-01],
         [-1.2775e-03,  2.6068e-01]]])
agent 0 action: VehicleControl(throttle=0.226763, steer=0.001361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.23605058625661
+++++++++++++: 1.786399346326154
16.4434088524431 seconds in game passed.
At 16.4434088524431 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3496e-03,  9.4287e-01],
         [-3.1519e-04,  5.6134e-01],
         [-3.5096e-03,  3.6732e-01],
         [-3.6992e-03,  2.6795e-01]]])
agent 0 action: VehicleControl(throttle=0.196291, steer=0.001644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.786399346326154
Current reward: 0.29514033300908665
Current mitigation activation: 0
#############################
Total reward: 37.5311909192657
16.468408852815628 seconds in game passed.
Action: tensor([[[ 1.3496e-03,  9.4287e-01],
         [-3.1519e-04,  5.6134e-01],
         [-3.5096e-03,  3.6732e-01],
         [-3.6992e-03,  2.6795e-01]]])
agent 0 action: VehicleControl(throttle=0.199661, steer=0.001779, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.5311909192657
16.493408853188157 seconds in game passed.
Action: tensor([[[ 1.3496e-03,  9.4287e-01],
         [-3.1519e-04,  5.6134e-01],
         [-3.5096e-03,  3.6732e-01],
         [-3.6992e-03,  2.6795e-01]]])
agent 0 action: VehicleControl(throttle=0.199661, steer=0.001935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.5311909192657
16.518408853560686 seconds in game passed.
Action: tensor([[[ 1.3496e-03,  9.4287e-01],
         [-3.1519e-04,  5.6134e-01],
         [-3.5096e-03,  3.6732e-01],
         [-3.6992e-03,  2.6795e-01]]])
agent 0 action: VehicleControl(throttle=0.199661, steer=0.002091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.5311909192657
+++++++++++++: 1.7690208781871453
16.543408853933215 seconds in game passed.
At 16.543408853933215 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.9416],
         [-0.0034,  0.5395],
         [-0.0071,  0.3489],
         [-0.0073,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.333689, steer=-0.001500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7690208781871453
Current reward: 0.2956862382963555
Current mitigation activation: 0
#############################
Total reward: 37.82687715756205
16.568408854305744 seconds in game passed.
Action: tensor([[[-0.0016,  0.9416],
         [-0.0034,  0.5395],
         [-0.0071,  0.3489],
         [-0.0073,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.326139, steer=-0.000846, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.82687715756205
16.593408854678273 seconds in game passed.
Action: tensor([[[-0.0016,  0.9416],
         [-0.0034,  0.5395],
         [-0.0071,  0.3489],
         [-0.0073,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.333195, steer=-0.000798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.82687715756205
16.618408855050802 seconds in game passed.
Action: tensor([[[-0.0016,  0.9416],
         [-0.0034,  0.5395],
         [-0.0071,  0.3489],
         [-0.0073,  0.2534]]])
agent 0 action: VehicleControl(throttle=0.339742, steer=-0.000751, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.82687715756205
+++++++++++++: 1.7718837294853333
16.64340885542333 seconds in game passed.
At 16.64340885542333 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.9442],
         [-0.0015,  0.5568],
         [-0.0052,  0.3582],
         [-0.0050,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.183233, steer=0.000597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7718837294853333
Current reward: 0.2942665226698061
Current mitigation activation: 0
#############################
Total reward: 38.12114368023186
16.66840885579586 seconds in game passed.
Action: tensor([[[-0.0017,  0.9442],
         [-0.0015,  0.5568],
         [-0.0052,  0.3582],
         [-0.0050,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.192672, steer=0.000341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.12114368023186
16.69340885616839 seconds in game passed.
Action: tensor([[[-0.0017,  0.9442],
         [-0.0015,  0.5568],
         [-0.0052,  0.3582],
         [-0.0050,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.186295, steer=0.000313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.12114368023186
16.71840885654092 seconds in game passed.
Action: tensor([[[-0.0017,  0.9442],
         [-0.0015,  0.5568],
         [-0.0052,  0.3582],
         [-0.0050,  0.2603]]])
agent 0 action: VehicleControl(throttle=0.180038, steer=0.000286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.12114368023186
+++++++++++++: 1.778832581353521
16.743408856913447 seconds in game passed.
At 16.743408856913447 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.7536e-04,  9.4564e-01],
         [-2.4129e-04,  5.7808e-01],
         [-5.7678e-03,  3.7297e-01],
         [-6.4076e-03,  2.7402e-01]]])
agent 0 action: VehicleControl(throttle=0.171338, steer=0.001905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.778832581353521
Current reward: 0.2925610140420204
Current mitigation activation: 0
#############################
Total reward: 38.41370469427388
16.768408857285976 seconds in game passed.
Action: tensor([[[-1.7536e-04,  9.4564e-01],
         [-2.4129e-04,  5.7808e-01],
         [-5.7678e-03,  3.7297e-01],
         [-6.4076e-03,  2.7402e-01]]])
agent 0 action: VehicleControl(throttle=0.162742, steer=0.001608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.41370469427388
16.793408857658505 seconds in game passed.
Action: tensor([[[-1.7536e-04,  9.4564e-01],
         [-2.4129e-04,  5.7808e-01],
         [-5.7678e-03,  3.7297e-01],
         [-6.4076e-03,  2.7402e-01]]])
agent 0 action: VehicleControl(throttle=0.154264, steer=0.001584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.41370469427388
16.818408858031034 seconds in game passed.
Action: tensor([[[-1.7536e-04,  9.4564e-01],
         [-2.4129e-04,  5.7808e-01],
         [-5.7678e-03,  3.7297e-01],
         [-6.4076e-03,  2.7402e-01]]])
agent 0 action: VehicleControl(throttle=0.145930, steer=0.001561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.41370469427388
+++++++++++++: 1.794600756519976
16.843408858403563 seconds in game passed.
At 16.843408858403563 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0054,  0.9448],
         [ 0.0018,  0.5728],
         [-0.0025,  0.3832],
         [-0.0036,  0.2900]]])
agent 0 action: VehicleControl(throttle=0.136729, steer=0.000679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.794600756519976
Current reward: 0.2901868555976871
Current mitigation activation: 0
#############################
Total reward: 38.70389154987157
16.868408858776093 seconds in game passed.
Action: tensor([[[-0.0054,  0.9448],
         [ 0.0018,  0.5728],
         [-0.0025,  0.3832],
         [-0.0036,  0.2900]]])
agent 0 action: VehicleControl(throttle=0.127721, steer=0.000704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.70389154987157
16.89340885914862 seconds in game passed.
Action: tensor([[[-0.0054,  0.9448],
         [ 0.0018,  0.5728],
         [-0.0025,  0.3832],
         [-0.0036,  0.2900]]])
agent 0 action: VehicleControl(throttle=0.118926, steer=0.000600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.70389154987157
16.91840885952115 seconds in game passed.
Action: tensor([[[-0.0054,  0.9448],
         [ 0.0018,  0.5728],
         [-0.0025,  0.3832],
         [-0.0036,  0.2900]]])
agent 0 action: VehicleControl(throttle=0.110371, steer=0.000495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.70389154987157
+++++++++++++: 1.8208971298788175
16.94340885989368 seconds in game passed.
At 16.94340885989368 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.1555e-04,  9.4449e-01],
         [-1.6658e-03,  5.8062e-01],
         [-7.3998e-03,  3.9879e-01],
         [-8.7746e-03,  3.0933e-01]]])
agent 0 action: VehicleControl(throttle=0.101402, steer=-0.000205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8208971298788175
Current reward: 0.2871012255654216
Current mitigation activation: 0
#############################
Total reward: 38.99099277543699
16.96840886026621 seconds in game passed.
Action: tensor([[[-8.1555e-04,  9.4449e-01],
         [-1.6658e-03,  5.8062e-01],
         [-7.3998e-03,  3.9879e-01],
         [-8.7746e-03,  3.0933e-01]]])
agent 0 action: VehicleControl(throttle=0.092704, steer=-0.000250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.99099277543699
16.993408860638738 seconds in game passed.
Action: tensor([[[-8.1555e-04,  9.4449e-01],
         [-1.6658e-03,  5.8062e-01],
         [-7.3998e-03,  3.9879e-01],
         [-8.7746e-03,  3.0933e-01]]])
agent 0 action: VehicleControl(throttle=0.084291, steer=-0.000388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.99099277543699
17.018408861011267 seconds in game passed.
Action: tensor([[[-8.1555e-04,  9.4449e-01],
         [-1.6658e-03,  5.8062e-01],
         [-7.3998e-03,  3.9879e-01],
         [-8.7746e-03,  3.0933e-01]]])
agent 0 action: VehicleControl(throttle=0.076177, steer=-0.000527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.99099277543699
+++++++++++++: 1.8548372914468876
17.043408861383796 seconds in game passed.
At 17.043408861383796 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0029,  0.9438],
         [-0.0014,  0.6039],
         [-0.0081,  0.4329],
         [-0.0100,  0.3491]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001293, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8548372914468876
Current reward: 0.2836910649356524
Current mitigation activation: 0
#############################
Total reward: 39.274683840372646
17.068408861756325 seconds in game passed.
Action: tensor([[[ 0.0029,  0.9438],
         [-0.0014,  0.6039],
         [-0.0081,  0.4329],
         [-0.0100,  0.3491]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000853, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.274683840372646
17.093408862128854 seconds in game passed.
Action: tensor([[[ 0.0029,  0.9438],
         [-0.0014,  0.6039],
         [-0.0081,  0.4329],
         [-0.0100,  0.3491]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000736, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.274683840372646
17.118408862501383 seconds in game passed.
Action: tensor([[[ 0.0029,  0.9438],
         [-0.0014,  0.6039],
         [-0.0081,  0.4329],
         [-0.0100,  0.3491]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000620, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.274683840372646
+++++++++++++: 1.8956830137523544
17.143408862873912 seconds in game passed.
At 17.143408862873912 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0047,  0.9442],
         [ 0.0030,  0.6022],
         [-0.0047,  0.4209],
         [-0.0067,  0.3304]]])
agent 0 action: VehicleControl(throttle=0.039702, steer=0.004596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8956830137523544
Current reward: 0.2801292472643579
Current mitigation activation: 0
#############################
Total reward: 39.554813087637
17.16840886324644 seconds in game passed.
Action: tensor([[[ 0.0047,  0.9442],
         [ 0.0030,  0.6022],
         [-0.0047,  0.4209],
         [-0.0067,  0.3304]]])
agent 0 action: VehicleControl(throttle=0.032871, steer=0.003844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.554813087637
17.19340886361897 seconds in game passed.
Action: tensor([[[ 0.0047,  0.9442],
         [ 0.0030,  0.6022],
         [-0.0047,  0.4209],
         [-0.0067,  0.3304]]])
agent 0 action: VehicleControl(throttle=0.026346, steer=0.003768, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.554813087637
17.2184088639915 seconds in game passed.
Action: tensor([[[ 0.0047,  0.9442],
         [ 0.0030,  0.6022],
         [-0.0047,  0.4209],
         [-0.0067,  0.3304]]])
agent 0 action: VehicleControl(throttle=0.020124, steer=0.003692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.554813087637
+++++++++++++: 2.0061878193776908
17.243408864364028 seconds in game passed.
At 17.243408864364028 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.9465],
         [ 0.0045,  0.6186],
         [-0.0010,  0.4050],
         [-0.0017,  0.3019]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001793, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0061878193776908
Current reward: 0.27201047658797145
Current mitigation activation: 0
#############################
Total reward: 39.82682356422497
17.268408864736557 seconds in game passed.
Action: tensor([[[-0.0015,  0.9465],
         [ 0.0045,  0.6186],
         [-0.0010,  0.4050],
         [-0.0017,  0.3019]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002097, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.82682356422497
17.293408865109086 seconds in game passed.
Action: tensor([[[-0.0015,  0.9465],
         [ 0.0045,  0.6186],
         [-0.0010,  0.4050],
         [-0.0017,  0.3019]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002087, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.82682356422497
17.318408865481615 seconds in game passed.
Action: tensor([[[-0.0015,  0.9465],
         [ 0.0045,  0.6186],
         [-0.0010,  0.4050],
         [-0.0017,  0.3019]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002076, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.82682356422497
+++++++++++++: 2.062698964300885
17.343408865854144 seconds in game passed.
At 17.343408865854144 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0045,  0.9466],
         [ 0.0017,  0.6176],
         [-0.0045,  0.4032],
         [-0.0059,  0.2980]]])
agent 0 action: VehicleControl(throttle=0.007690, steer=-0.001348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.062698964300885
Current reward: 0.2694200819794533
Current mitigation activation: 0
#############################
Total reward: 40.09624364620443
17.368408866226673 seconds in game passed.
Action: tensor([[[-0.0045,  0.9466],
         [ 0.0017,  0.6176],
         [-0.0045,  0.4032],
         [-0.0059,  0.2980]]])
agent 0 action: VehicleControl(throttle=0.007089, steer=-0.000791, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.09624364620443
17.393408866599202 seconds in game passed.
Action: tensor([[[-0.0045,  0.9466],
         [ 0.0017,  0.6176],
         [-0.0045,  0.4032],
         [-0.0059,  0.2980]]])
agent 0 action: VehicleControl(throttle=0.006635, steer=-0.000803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.09624364620443
17.41840886697173 seconds in game passed.
Action: tensor([[[-0.0045,  0.9466],
         [ 0.0017,  0.6176],
         [-0.0045,  0.4032],
         [-0.0059,  0.2980]]])
agent 0 action: VehicleControl(throttle=0.006284, steer=-0.000815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.09624364620443
+++++++++++++: 2.2073250196270755
17.44340886734426 seconds in game passed.
At 17.44340886734426 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0144, 0.9419],
         [0.0084, 0.5598],
         [0.0030, 0.3690],
         [0.0023, 0.2691]]])
agent 0 action: VehicleControl(throttle=0.475532, steer=0.012837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2073250196270755
Current reward: 0.26215224027144046
Current mitigation activation: 0
#############################
Total reward: 40.35839588647587
17.46840886771679 seconds in game passed.
Action: tensor([[[0.0144, 0.9419],
         [0.0084, 0.5598],
         [0.0030, 0.3690],
         [0.0023, 0.2691]]])
agent 0 action: VehicleControl(throttle=0.431820, steer=0.010710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.35839588647587
17.49340886808932 seconds in game passed.
Action: tensor([[[0.0144, 0.9419],
         [0.0084, 0.5598],
         [0.0030, 0.3690],
         [0.0023, 0.2691]]])
agent 0 action: VehicleControl(throttle=0.437926, steer=0.010838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.35839588647587
17.518408868461847 seconds in game passed.
Action: tensor([[[0.0144, 0.9419],
         [0.0084, 0.5598],
         [0.0030, 0.3690],
         [0.0023, 0.2691]]])
agent 0 action: VehicleControl(throttle=0.443887, steer=0.010966, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.35839588647587
+++++++++++++: 2.267724200489553
17.543408868834376 seconds in game passed.
At 17.543408868834376 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0127, 0.9306],
         [0.0034, 0.5205],
         [0.0011, 0.3479],
         [0.0013, 0.2543]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.267724200489553
Current reward: 0.261786331242416
Current mitigation activation: 0
#############################
Total reward: 40.62018221771829
17.568408869206905 seconds in game passed.
Action: tensor([[[0.0127, 0.9306],
         [0.0034, 0.5205],
         [0.0011, 0.3479],
         [0.0013, 0.2543]]])
agent 0 action: VehicleControl(throttle=0.886703, steer=0.007292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.62018221771829
17.593408869579434 seconds in game passed.
Action: tensor([[[0.0127, 0.9306],
         [0.0034, 0.5205],
         [0.0011, 0.3479],
         [0.0013, 0.2543]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.62018221771829
17.618408869951963 seconds in game passed.
Action: tensor([[[0.0127, 0.9306],
         [0.0034, 0.5205],
         [0.0011, 0.3479],
         [0.0013, 0.2543]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.62018221771829
+++++++++++++: 2.378712257955533
17.643408870324492 seconds in game passed.
At 17.643408870324492 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.1474e-02, 8.9715e-01],
         [2.7001e-03, 4.8775e-01],
         [1.8818e-04, 3.2844e-01],
         [2.5811e-04, 2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.378712257955533
Current reward: 0.2593820291551033
Current mitigation activation: 0
#############################
Total reward: 40.87956424687339
17.66840887069702 seconds in game passed.
Action: tensor([[[2.1474e-02, 8.9715e-01],
         [2.7001e-03, 4.8775e-01],
         [1.8818e-04, 3.2844e-01],
         [2.5811e-04, 2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.87956424687339
17.69340887106955 seconds in game passed.
Action: tensor([[[2.1474e-02, 8.9715e-01],
         [2.7001e-03, 4.8775e-01],
         [1.8818e-04, 3.2844e-01],
         [2.5811e-04, 2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.87956424687339
17.71840887144208 seconds in game passed.
Action: tensor([[[2.1474e-02, 8.9715e-01],
         [2.7001e-03, 4.8775e-01],
         [1.8818e-04, 3.2844e-01],
         [2.5811e-04, 2.4105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.010529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.87956424687339
+++++++++++++: 2.5744694054072146
17.74340887181461 seconds in game passed.
At 17.74340887181461 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0268, 0.8898],
         [0.0041, 0.4870],
         [0.0012, 0.3300],
         [0.0016, 0.2432]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.013989, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5744694054072146
Current reward: 0.25401511313638303
Current mitigation activation: 0
#############################
Total reward: 41.133579360009776
17.768408872187138 seconds in game passed.
Action: tensor([[[0.0268, 0.8898],
         [0.0041, 0.4870],
         [0.0012, 0.3300],
         [0.0016, 0.2432]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.013588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.133579360009776
17.793408872559667 seconds in game passed.
Action: tensor([[[0.0268, 0.8898],
         [0.0041, 0.4870],
         [0.0012, 0.3300],
         [0.0016, 0.2432]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.013739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.133579360009776
17.818408872932196 seconds in game passed.
Action: tensor([[[0.0268, 0.8898],
         [0.0041, 0.4870],
         [0.0012, 0.3300],
         [0.0016, 0.2432]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.013889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.133579360009776
+++++++++++++: 2.6118589306128617
17.843408873304725 seconds in game passed.
At 17.843408873304725 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0163,  0.8802],
         [ 0.0010,  0.4755],
         [-0.0016,  0.3227],
         [-0.0016,  0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6118589306128617
Current reward: 0.2578003138046411
Current mitigation activation: 0
#############################
Total reward: 41.39137967381442
17.868408873677254 seconds in game passed.
Action: tensor([[[ 0.0163,  0.8802],
         [ 0.0010,  0.4755],
         [-0.0016,  0.3227],
         [-0.0016,  0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.39137967381442
17.893408874049783 seconds in game passed.
Action: tensor([[[ 0.0163,  0.8802],
         [ 0.0010,  0.4755],
         [-0.0016,  0.3227],
         [-0.0016,  0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008543, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.39137967381442
17.918408874422312 seconds in game passed.
Action: tensor([[[ 0.0163,  0.8802],
         [ 0.0010,  0.4755],
         [-0.0016,  0.3227],
         [-0.0016,  0.2381]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.39137967381442
+++++++++++++: 2.5548432152423066
17.94340887479484 seconds in game passed.
At 17.94340887479484 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0805e-02,  8.5583e-01],
         [-7.4491e-05,  4.6466e-01],
         [-3.5302e-03,  3.1453e-01],
         [-4.1553e-03,  2.3129e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009728, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5548432152423066
Current reward: 0.266570989355928
Current mitigation activation: 0
#############################
Total reward: 41.65795066317035
17.96840887516737 seconds in game passed.
Action: tensor([[[ 2.0805e-02,  8.5583e-01],
         [-7.4491e-05,  4.6466e-01],
         [-3.5302e-03,  3.1453e-01],
         [-4.1553e-03,  2.3129e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.65795066317035
17.9934088755399 seconds in game passed.
Action: tensor([[[ 2.0805e-02,  8.5583e-01],
         [-7.4491e-05,  4.6466e-01],
         [-3.5302e-03,  3.1453e-01],
         [-4.1553e-03,  2.3129e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.65795066317035
18.018408875912428 seconds in game passed.
Action: tensor([[[ 2.0805e-02,  8.5583e-01],
         [-7.4491e-05,  4.6466e-01],
         [-3.5302e-03,  3.1453e-01],
         [-4.1553e-03,  2.3129e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.009877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.65795066317035
+++++++++++++: 2.461461048396579
18.043408876284957 seconds in game passed.
At 18.043408876284957 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0187,  0.8320],
         [-0.0016,  0.4471],
         [-0.0044,  0.3034],
         [-0.0046,  0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007832, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.461461048396579
Current reward: 0.27764853208266066
Current mitigation activation: 0
#############################
Total reward: 41.935599195253005
18.068408876657486 seconds in game passed.
Action: tensor([[[ 0.0187,  0.8320],
         [-0.0016,  0.4471],
         [-0.0044,  0.3034],
         [-0.0046,  0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.935599195253005
18.093408877030015 seconds in game passed.
Action: tensor([[[ 0.0187,  0.8320],
         [-0.0016,  0.4471],
         [-0.0044,  0.3034],
         [-0.0046,  0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.935599195253005
18.118408877402544 seconds in game passed.
Action: tensor([[[ 0.0187,  0.8320],
         [-0.0016,  0.4471],
         [-0.0044,  0.3034],
         [-0.0046,  0.2260]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.935599195253005
+++++++++++++: 2.359419016251603
18.143408877775073 seconds in game passed.
At 18.143408877775073 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0163,  0.8016],
         [-0.0026,  0.4343],
         [-0.0052,  0.2943],
         [-0.0057,  0.2199]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.359419016251603
Current reward: 0.289750732032237
Current mitigation activation: 0
#############################
Total reward: 42.225349927285244
18.168408878147602 seconds in game passed.
Action: tensor([[[ 0.0163,  0.8016],
         [-0.0026,  0.4343],
         [-0.0052,  0.2943],
         [-0.0057,  0.2199]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.225349927285244
18.19340887852013 seconds in game passed.
Action: tensor([[[ 0.0163,  0.8016],
         [-0.0026,  0.4343],
         [-0.0052,  0.2943],
         [-0.0057,  0.2199]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.225349927285244
18.21840887889266 seconds in game passed.
Action: tensor([[[ 0.0163,  0.8016],
         [-0.0026,  0.4343],
         [-0.0052,  0.2943],
         [-0.0057,  0.2199]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.225349927285244
+++++++++++++: 2.260002547199643
18.24340887926519 seconds in game passed.
At 18.24340887926519 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0074,  0.7865],
         [-0.0061,  0.4203],
         [-0.0089,  0.2820],
         [-0.0097,  0.2101]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.260002547199643
Current reward: 0.3022453926265182
Current mitigation activation: 0
#############################
Total reward: 42.52759531991176
18.268408879637718 seconds in game passed.
Action: tensor([[[ 0.0074,  0.7865],
         [-0.0061,  0.4203],
         [-0.0089,  0.2820],
         [-0.0097,  0.2101]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.52759531991176
18.293408880010247 seconds in game passed.
Action: tensor([[[ 0.0074,  0.7865],
         [-0.0061,  0.4203],
         [-0.0089,  0.2820],
         [-0.0097,  0.2101]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.52759531991176
18.318408880382776 seconds in game passed.
Action: tensor([[[ 0.0074,  0.7865],
         [-0.0061,  0.4203],
         [-0.0089,  0.2820],
         [-0.0097,  0.2101]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.52759531991176
+++++++++++++: 2.1670676993574953
18.343408880755305 seconds in game passed.
At 18.343408880755305 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.9182e-04,  8.0507e-01],
         [-9.8145e-03,  4.1625e-01],
         [-1.2980e-02,  2.7761e-01],
         [-1.3725e-02,  2.0713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1670676993574953
Current reward: 0.31481572265485686
Current mitigation activation: 0
#############################
Total reward: 42.84241104256662
18.368408881127834 seconds in game passed.
Action: tensor([[[ 4.9182e-04,  8.0507e-01],
         [-9.8145e-03,  4.1625e-01],
         [-1.2980e-02,  2.7761e-01],
         [-1.3725e-02,  2.0713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.84241104256662
18.393408881500363 seconds in game passed.
Action: tensor([[[ 4.9182e-04,  8.0507e-01],
         [-9.8145e-03,  4.1625e-01],
         [-1.2980e-02,  2.7761e-01],
         [-1.3725e-02,  2.0713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.84241104256662
18.418408881872892 seconds in game passed.
Action: tensor([[[ 4.9182e-04,  8.0507e-01],
         [-9.8145e-03,  4.1625e-01],
         [-1.2980e-02,  2.7761e-01],
         [-1.3725e-02,  2.0713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003390, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.84241104256662
+++++++++++++: 2.081762482752551
18.44340888224542 seconds in game passed.
At 18.44340888224542 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.3722e-04,  7.8988e-01],
         [-1.2047e-02,  4.1216e-01],
         [-1.5020e-02,  2.7855e-01],
         [-1.5821e-02,  2.1080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.081762482752551
Current reward: 0.32727420317222067
Current mitigation activation: 0
#############################
Total reward: 43.16968524573884
18.46840888261795 seconds in game passed.
Action: tensor([[[ 7.3722e-04,  7.8988e-01],
         [-1.2047e-02,  4.1216e-01],
         [-1.5020e-02,  2.7855e-01],
         [-1.5821e-02,  2.1080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.16968524573884
18.49340888299048 seconds in game passed.
Action: tensor([[[ 7.3722e-04,  7.8988e-01],
         [-1.2047e-02,  4.1216e-01],
         [-1.5020e-02,  2.7855e-01],
         [-1.5821e-02,  2.1080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.16968524573884
18.51840888336301 seconds in game passed.
Action: tensor([[[ 7.3722e-04,  7.8988e-01],
         [-1.2047e-02,  4.1216e-01],
         [-1.5020e-02,  2.7855e-01],
         [-1.5821e-02,  2.1080e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.16968524573884
+++++++++++++: 2.003863079727948
18.543408883735538 seconds in game passed.
At 18.543408883735538 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0044,  0.7695],
         [-0.0151,  0.4057],
         [-0.0186,  0.2765],
         [-0.0198,  0.2110]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.003863079727948
Current reward: 0.3395330843267494
Current mitigation activation: 0
#############################
Total reward: 43.509218330065586
18.568408884108067 seconds in game passed.
Action: tensor([[[-0.0044,  0.7695],
         [-0.0151,  0.4057],
         [-0.0186,  0.2765],
         [-0.0198,  0.2110]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.509218330065586
18.593408884480596 seconds in game passed.
Action: tensor([[[-0.0044,  0.7695],
         [-0.0151,  0.4057],
         [-0.0186,  0.2765],
         [-0.0198,  0.2110]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009819, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.509218330065586
18.618408884853125 seconds in game passed.
Action: tensor([[[-0.0044,  0.7695],
         [-0.0151,  0.4057],
         [-0.0186,  0.2765],
         [-0.0198,  0.2110]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.509218330065586
+++++++++++++: 1.932728774352395
18.643408885225654 seconds in game passed.
At 18.643408885225654 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0047,  0.7713],
         [-0.0170,  0.4014],
         [-0.0208,  0.2700],
         [-0.0223,  0.2040]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011890, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.932728774352395
Current reward: 0.35152807038470113
Current mitigation activation: 0
#############################
Total reward: 43.86074640045029
18.668408885598183 seconds in game passed.
Action: tensor([[[-0.0047,  0.7713],
         [-0.0170,  0.4014],
         [-0.0208,  0.2700],
         [-0.0223,  0.2040]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.86074640045029
18.69340888597071 seconds in game passed.
Action: tensor([[[-0.0047,  0.7713],
         [-0.0170,  0.4014],
         [-0.0208,  0.2700],
         [-0.0223,  0.2040]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.86074640045029
18.71840888634324 seconds in game passed.
Action: tensor([[[-0.0047,  0.7713],
         [-0.0170,  0.4014],
         [-0.0208,  0.2700],
         [-0.0223,  0.2040]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.86074640045029
+++++++++++++: 1.867579829109848
18.74340888671577 seconds in game passed.
At 18.74340888671577 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.7869],
         [-0.0113,  0.4022],
         [-0.0144,  0.2688],
         [-0.0153,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.867579829109848
Current reward: 0.363229851173018
Current mitigation activation: 0
#############################
Total reward: 44.223976251623306
18.7684088870883 seconds in game passed.
Action: tensor([[[-0.0023,  0.7869],
         [-0.0113,  0.4022],
         [-0.0144,  0.2688],
         [-0.0153,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.223976251623306
18.793408887460828 seconds in game passed.
Action: tensor([[[-0.0023,  0.7869],
         [-0.0113,  0.4022],
         [-0.0144,  0.2688],
         [-0.0153,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.223976251623306
18.818408887833357 seconds in game passed.
Action: tensor([[[-0.0023,  0.7869],
         [-0.0113,  0.4022],
         [-0.0144,  0.2688],
         [-0.0153,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009033, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.223976251623306
+++++++++++++: 1.8076708088671665
18.843408888205886 seconds in game passed.
At 18.843408888205886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.1790e-04,  7.9898e-01],
         [-1.4473e-02,  4.0470e-01],
         [-1.8062e-02,  2.6842e-01],
         [-1.9481e-02,  2.0005e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8076708088671665
Current reward: 0.3746316010407432
Current mitigation activation: 0
#############################
Total reward: 44.598607852664045
18.868408888578415 seconds in game passed.
Action: tensor([[[-4.1790e-04,  7.9898e-01],
         [-1.4473e-02,  4.0470e-01],
         [-1.8062e-02,  2.6842e-01],
         [-1.9481e-02,  2.0005e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.598607852664045
18.893408888950944 seconds in game passed.
Action: tensor([[[-4.1790e-04,  7.9898e-01],
         [-1.4473e-02,  4.0470e-01],
         [-1.8062e-02,  2.6842e-01],
         [-1.9481e-02,  2.0005e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.598607852664045
18.918408889323473 seconds in game passed.
Action: tensor([[[-4.1790e-04,  7.9898e-01],
         [-1.4473e-02,  4.0470e-01],
         [-1.8062e-02,  2.6842e-01],
         [-1.9481e-02,  2.0005e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.598607852664045
+++++++++++++: 1.752310602780915
18.943408889696002 seconds in game passed.
At 18.943408889696002 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.7634],
         [-0.0073,  0.3944],
         [-0.0094,  0.2632],
         [-0.0102,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.752310602780915
Current reward: 0.38571912109400086
Current mitigation activation: 0
#############################
Total reward: 44.984326973758044
18.96840889006853 seconds in game passed.
Action: tensor([[[-0.0023,  0.7634],
         [-0.0073,  0.3944],
         [-0.0094,  0.2632],
         [-0.0102,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.984326973758044
18.99340889044106 seconds in game passed.
Action: tensor([[[-0.0023,  0.7634],
         [-0.0073,  0.3944],
         [-0.0094,  0.2632],
         [-0.0102,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.984326973758044
19.01840889081359 seconds in game passed.
Action: tensor([[[-0.0023,  0.7634],
         [-0.0073,  0.3944],
         [-0.0094,  0.2632],
         [-0.0102,  0.1972]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.984326973758044
+++++++++++++: 1.7009126007600368
19.043408891186118 seconds in game passed.
At 19.043408891186118 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0052,  0.7085],
         [-0.0067,  0.3801],
         [-0.0078,  0.2619],
         [-0.0085,  0.2007]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7009126007600368
Current reward: 0.39648824627209933
Current mitigation activation: 0
#############################
Total reward: 45.380815220030144
19.068408891558647 seconds in game passed.
Action: tensor([[[-0.0052,  0.7085],
         [-0.0067,  0.3801],
         [-0.0078,  0.2619],
         [-0.0085,  0.2007]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.380815220030144
19.093408891931176 seconds in game passed.
Action: tensor([[[-0.0052,  0.7085],
         [-0.0067,  0.3801],
         [-0.0078,  0.2619],
         [-0.0085,  0.2007]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.380815220030144
19.118408892303705 seconds in game passed.
Action: tensor([[[-0.0052,  0.7085],
         [-0.0067,  0.3801],
         [-0.0078,  0.2619],
         [-0.0085,  0.2007]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.380815220030144
+++++++++++++: 1.669987095376363
19.143408892676234 seconds in game passed.
At 19.143408892676234 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.6794],
         [-0.0050,  0.3741],
         [-0.0063,  0.2587],
         [-0.0068,  0.1980]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.669987095376363
Current reward: 0.404575766410622
Current mitigation activation: 0
#############################
Total reward: 45.78539098644077
19.168408893048763 seconds in game passed.
Action: tensor([[[-0.0009,  0.6794],
         [-0.0050,  0.3741],
         [-0.0063,  0.2587],
         [-0.0068,  0.1980]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.78539098644077
19.193408893421292 seconds in game passed.
Action: tensor([[[-0.0009,  0.6794],
         [-0.0050,  0.3741],
         [-0.0063,  0.2587],
         [-0.0068,  0.1980]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.78539098644077
19.21840889379382 seconds in game passed.
Action: tensor([[[-0.0009,  0.6794],
         [-0.0050,  0.3741],
         [-0.0063,  0.2587],
         [-0.0068,  0.1980]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.78539098644077
+++++++++++++: 1.6869525052563747
19.24340889416635 seconds in game passed.
At 19.24340889416635 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0024,  0.6932],
         [-0.0024,  0.3804],
         [-0.0037,  0.2627],
         [-0.0046,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.890586, steer=-0.003586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6869525052563747
Current reward: 0.4060512673012452
Current mitigation activation: 0
#############################
Total reward: 46.19144225374201
19.26840889453888 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6932],
         [-0.0024,  0.3804],
         [-0.0037,  0.2627],
         [-0.0046,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.887102, steer=-0.004122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.19144225374201
19.29340889491141 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6932],
         [-0.0024,  0.3804],
         [-0.0037,  0.2627],
         [-0.0046,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.877967, steer=-0.004114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.19144225374201
19.318408895283937 seconds in game passed.
Action: tensor([[[ 0.0024,  0.6932],
         [-0.0024,  0.3804],
         [-0.0037,  0.2627],
         [-0.0046,  0.2012]]])
agent 0 action: VehicleControl(throttle=0.869329, steer=-0.004105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.19144225374201
+++++++++++++: 1.7081932106044362
19.343408895656466 seconds in game passed.
At 19.343408895656466 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.6905e-03,  6.8052e-01],
         [ 7.0542e-04,  3.7713e-01],
         [ 3.3855e-04,  2.5950e-01],
         [-2.5588e-04,  1.9831e-01]]])
agent 0 action: VehicleControl(throttle=0.841676, steer=-0.000388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7081932106044362
Current reward: 0.40741982285676315
Current mitigation activation: 0
#############################
Total reward: 46.59886207659878
19.368408896028996 seconds in game passed.
Action: tensor([[[ 5.6905e-03,  6.8052e-01],
         [ 7.0542e-04,  3.7713e-01],
         [ 3.3855e-04,  2.5950e-01],
         [-2.5588e-04,  1.9831e-01]]])
agent 0 action: VehicleControl(throttle=0.833363, steer=-0.000885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.59886207659878
19.393408896401525 seconds in game passed.
Action: tensor([[[ 5.6905e-03,  6.8052e-01],
         [ 7.0542e-04,  3.7713e-01],
         [ 3.3855e-04,  2.5950e-01],
         [-2.5588e-04,  1.9831e-01]]])
agent 0 action: VehicleControl(throttle=0.823705, steer=-0.000780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.59886207659878
19.418408896774054 seconds in game passed.
Action: tensor([[[ 5.6905e-03,  6.8052e-01],
         [ 7.0542e-04,  3.7713e-01],
         [ 3.3855e-04,  2.5950e-01],
         [-2.5588e-04,  1.9831e-01]]])
agent 0 action: VehicleControl(throttle=0.814527, steer=-0.000675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.59886207659878
+++++++++++++: 1.7316458607313532
19.443408897146583 seconds in game passed.
At 19.443408897146583 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0045, 0.6676],
         [0.0020, 0.3589],
         [0.0018, 0.2457],
         [0.0012, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7316458607313532
Current reward: 0.40898369433782444
Current mitigation activation: 0
#############################
Total reward: 47.007845770936605
19.46840889751911 seconds in game passed.
Action: tensor([[[0.0045, 0.6676],
         [0.0020, 0.3589],
         [0.0018, 0.2457],
         [0.0012, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.007845770936605
19.49340889789164 seconds in game passed.
Action: tensor([[[0.0045, 0.6676],
         [0.0020, 0.3589],
         [0.0018, 0.2457],
         [0.0012, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.007845770936605
19.51840889826417 seconds in game passed.
Action: tensor([[[0.0045, 0.6676],
         [0.0020, 0.3589],
         [0.0018, 0.2457],
         [0.0012, 0.1876]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.007845770936605
+++++++++++++: 1.757295258421414
19.5434088986367 seconds in game passed.
At 19.5434088986367 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6526],
         [0.0040, 0.3509],
         [0.0039, 0.2405],
         [0.0033, 0.1842]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.757295258421414
Current reward: 0.41073272171523567
Current mitigation activation: 0
#############################
Total reward: 47.41857849265184
19.568408899009228 seconds in game passed.
Action: tensor([[[0.0042, 0.6526],
         [0.0040, 0.3509],
         [0.0039, 0.2405],
         [0.0033, 0.1842]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001663, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.41857849265184
19.593408899381757 seconds in game passed.
Action: tensor([[[0.0042, 0.6526],
         [0.0040, 0.3509],
         [0.0039, 0.2405],
         [0.0033, 0.1842]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.41857849265184
19.618408899754286 seconds in game passed.
Action: tensor([[[0.0042, 0.6526],
         [0.0040, 0.3509],
         [0.0039, 0.2405],
         [0.0033, 0.1842]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.41857849265184
+++++++++++++: 1.7664819513247019
19.643408900126815 seconds in game passed.
At 19.643408900126815 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6574],
         [0.0018, 0.3510],
         [0.0019, 0.2405],
         [0.0015, 0.1843]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7664819513247019
Current reward: 0.41507944203066566
Current mitigation activation: 0
#############################
Total reward: 47.833657934682506
19.668408900499344 seconds in game passed.
Action: tensor([[[0.0025, 0.6574],
         [0.0018, 0.3510],
         [0.0019, 0.2405],
         [0.0015, 0.1843]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.833657934682506
19.693408900871873 seconds in game passed.
Action: tensor([[[0.0025, 0.6574],
         [0.0018, 0.3510],
         [0.0019, 0.2405],
         [0.0015, 0.1843]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.833657934682506
19.718408901244402 seconds in game passed.
Action: tensor([[[0.0025, 0.6574],
         [0.0018, 0.3510],
         [0.0019, 0.2405],
         [0.0015, 0.1843]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.833657934682506
+++++++++++++: 1.7006058158918225
19.74340890161693 seconds in game passed.
At 19.74340890161693 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.2436e-03, 6.5839e-01],
         [1.8924e-03, 3.5124e-01],
         [1.0985e-03, 2.4079e-01],
         [2.9506e-04, 1.8424e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7006058158918225
Current reward: 0.42991308975372866
Current mitigation activation: 0
#############################
Total reward: 48.26357102443623
19.76840890198946 seconds in game passed.
Action: tensor([[[5.2436e-03, 6.5839e-01],
         [1.8924e-03, 3.5124e-01],
         [1.0985e-03, 2.4079e-01],
         [2.9506e-04, 1.8424e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.26357102443623
19.79340890236199 seconds in game passed.
Action: tensor([[[5.2436e-03, 6.5839e-01],
         [1.8924e-03, 3.5124e-01],
         [1.0985e-03, 2.4079e-01],
         [2.9506e-04, 1.8424e-01]]])
agent 0 action: VehicleControl(throttle=0.878168, steer=0.002209, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.26357102443623
19.818408902734518 seconds in game passed.
Action: tensor([[[5.2436e-03, 6.5839e-01],
         [1.8924e-03, 3.5124e-01],
         [1.0985e-03, 2.4079e-01],
         [2.9506e-04, 1.8424e-01]]])
agent 0 action: VehicleControl(throttle=0.831434, steer=0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.26357102443623
+++++++++++++: 1.641055681072277
19.843408903107047 seconds in game passed.
At 19.843408903107047 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0028,  0.6751],
         [-0.0011,  0.3561],
         [-0.0021,  0.2424],
         [-0.0027,  0.1852]]])
agent 0 action: VehicleControl(throttle=0.779310, steer=-0.000695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.641055681072277
Current reward: 0.4439477374305878
Current mitigation activation: 0
#############################
Total reward: 48.70751876186682
19.868408903479576 seconds in game passed.
Action: tensor([[[ 0.0028,  0.6751],
         [-0.0011,  0.3561],
         [-0.0021,  0.2424],
         [-0.0027,  0.1852]]])
agent 0 action: VehicleControl(throttle=0.735327, steer=-0.000049, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.70751876186682
19.893408903852105 seconds in game passed.
Action: tensor([[[ 0.0028,  0.6751],
         [-0.0011,  0.3561],
         [-0.0021,  0.2424],
         [-0.0027,  0.1852]]])
agent 0 action: VehicleControl(throttle=0.692279, steer=0.000071, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.70751876186682
19.918408904224634 seconds in game passed.
Action: tensor([[[ 0.0028,  0.6751],
         [-0.0011,  0.3561],
         [-0.0021,  0.2424],
         [-0.0027,  0.1852]]])
agent 0 action: VehicleControl(throttle=0.651150, steer=0.000191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.70751876186682
+++++++++++++: 1.592590713605639
19.943408904597163 seconds in game passed.
At 19.943408904597163 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.5407e-03,  6.7964e-01],
         [-5.5657e-04,  3.5733e-01],
         [-1.6826e-03,  2.4292e-01],
         [-2.5330e-03,  1.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.614036, steer=0.000540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.592590713605639
Current reward: 0.4562447585422126
Current mitigation activation: 0
#############################
Total reward: 49.163763520409034
19.968408904969692 seconds in game passed.
Action: tensor([[[ 2.5407e-03,  6.7964e-01],
         [-5.5657e-04,  3.5733e-01],
         [-1.6826e-03,  2.4292e-01],
         [-2.5330e-03,  1.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.576989, steer=0.000567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.163763520409034
19.99340890534222 seconds in game passed.
Action: tensor([[[ 2.5407e-03,  6.7964e-01],
         [-5.5657e-04,  3.5733e-01],
         [-1.6826e-03,  2.4292e-01],
         [-2.5330e-03,  1.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.542729, steer=0.000640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.163763520409034
20.01840890571475 seconds in game passed.
Action: tensor([[[ 2.5407e-03,  6.7964e-01],
         [-5.5657e-04,  3.5733e-01],
         [-1.6826e-03,  2.4292e-01],
         [-2.5330e-03,  1.8610e-01]]])
agent 0 action: VehicleControl(throttle=0.511167, steer=0.000713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.163763520409034
+++++++++++++: 1.557005806505534
20.04340890608728 seconds in game passed.
At 20.04340890608728 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.6863],
         [-0.0024,  0.3538],
         [-0.0030,  0.2396],
         [-0.0031,  0.1836]]])
agent 0 action: VehicleControl(throttle=0.648874, steer=-0.002253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.557005806505534
Current reward: 0.46628450540115907
Current mitigation activation: 0
#############################
Total reward: 49.6300480258102
20.06840890645981 seconds in game passed.
Action: tensor([[[-0.0017,  0.6863],
         [-0.0024,  0.3538],
         [-0.0030,  0.2396],
         [-0.0031,  0.1836]]])
agent 0 action: VehicleControl(throttle=0.607528, steer=-0.001703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.6300480258102
20.093408906832337 seconds in game passed.
Action: tensor([[[-0.0017,  0.6863],
         [-0.0024,  0.3538],
         [-0.0030,  0.2396],
         [-0.0031,  0.1836]]])
agent 0 action: VehicleControl(throttle=0.586124, steer=-0.001656, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.6300480258102
20.118408907204866 seconds in game passed.
Action: tensor([[[-0.0017,  0.6863],
         [-0.0024,  0.3538],
         [-0.0030,  0.2396],
         [-0.0031,  0.1836]]])
agent 0 action: VehicleControl(throttle=0.565610, steer=-0.001608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.6300480258102
+++++++++++++: 1.5363808360552478
20.143408907577395 seconds in game passed.
At 20.143408907577395 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.8408e-04,  6.6197e-01],
         [ 2.9553e-04,  3.4627e-01],
         [-2.2322e-04,  2.3589e-01],
         [-5.2428e-04,  1.8055e-01]]])
agent 0 action: VehicleControl(throttle=0.577754, steer=0.001241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5363808360552478
Current reward: 0.4735495937240053
Current mitigation activation: 0
#############################
Total reward: 50.1035976195342
20.168408907949924 seconds in game passed.
Action: tensor([[[ 3.8408e-04,  6.6197e-01],
         [ 2.9553e-04,  3.4627e-01],
         [-2.2322e-04,  2.3589e-01],
         [-5.2428e-04,  1.8055e-01]]])
agent 0 action: VehicleControl(throttle=0.557477, steer=0.000820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.1035976195342
20.193408908322453 seconds in game passed.
Action: tensor([[[ 3.8408e-04,  6.6197e-01],
         [ 2.9553e-04,  3.4627e-01],
         [-2.2322e-04,  2.3589e-01],
         [-5.2428e-04,  1.8055e-01]]])
agent 0 action: VehicleControl(throttle=0.541626, steer=0.000866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.1035976195342
20.218408908694983 seconds in game passed.
Action: tensor([[[ 3.8408e-04,  6.6197e-01],
         [ 2.9553e-04,  3.4627e-01],
         [-2.2322e-04,  2.3589e-01],
         [-5.2428e-04,  1.8055e-01]]])
agent 0 action: VehicleControl(throttle=0.526730, steer=0.000912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.1035976195342
+++++++++++++: 1.5260947431963872
20.24340890906751 seconds in game passed.
At 20.24340890906751 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6328],
         [0.0023, 0.3452],
         [0.0023, 0.2383],
         [0.0019, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.275334, steer=0.003898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5260947431963872
Current reward: 0.47887398664837477
Current mitigation activation: 0
#############################
Total reward: 50.58247160618257
20.26840890944004 seconds in game passed.
Action: tensor([[[0.0040, 0.6328],
         [0.0023, 0.3452],
         [0.0023, 0.2383],
         [0.0019, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.285841, steer=0.003450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.58247160618257
20.29340890981257 seconds in game passed.
Action: tensor([[[0.0040, 0.6328],
         [0.0023, 0.3452],
         [0.0023, 0.2383],
         [0.0019, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.272594, steer=0.003493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.58247160618257
20.3184089101851 seconds in game passed.
Action: tensor([[[0.0040, 0.6328],
         [0.0023, 0.3452],
         [0.0023, 0.2383],
         [0.0019, 0.1835]]])
agent 0 action: VehicleControl(throttle=0.262803, steer=0.003536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.58247160618257
+++++++++++++: 1.5239459275617604
20.343408910557628 seconds in game passed.
At 20.343408910557628 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0041, 0.6475],
         [0.0029, 0.3494],
         [0.0027, 0.2421],
         [0.0022, 0.1870]]])
agent 0 action: VehicleControl(throttle=0.261076, steer=0.003952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5239459275617604
Current reward: 0.482733582443692
Current mitigation activation: 0
#############################
Total reward: 51.065205188626265
20.368408910930157 seconds in game passed.
Action: tensor([[[0.0041, 0.6475],
         [0.0029, 0.3494],
         [0.0027, 0.2421],
         [0.0022, 0.1870]]])
agent 0 action: VehicleControl(throttle=0.256921, steer=0.003894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.065205188626265
20.393408911302686 seconds in game passed.
Action: tensor([[[0.0041, 0.6475],
         [0.0029, 0.3494],
         [0.0027, 0.2421],
         [0.0022, 0.1870]]])
agent 0 action: VehicleControl(throttle=0.255784, steer=0.003903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.065205188626265
20.418408911675215 seconds in game passed.
Action: tensor([[[0.0041, 0.6475],
         [0.0029, 0.3494],
         [0.0027, 0.2421],
         [0.0022, 0.1870]]])
agent 0 action: VehicleControl(throttle=0.256803, steer=0.003912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.065205188626265
+++++++++++++: 1.536053311792675
20.443408912047744 seconds in game passed.
At 20.443408912047744 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0054, 0.6604],
         [0.0017, 0.3467],
         [0.0015, 0.2382],
         [0.0015, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.459731, steer=0.003538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.536053311792675
Current reward: 0.4840884781889353
Current mitigation activation: 0
#############################
Total reward: 51.5492936668152
20.468408912420273 seconds in game passed.
Action: tensor([[[0.0054, 0.6604],
         [0.0017, 0.3467],
         [0.0015, 0.2382],
         [0.0015, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.440253, steer=0.003601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.5492936668152
20.493408912792802 seconds in game passed.
Action: tensor([[[0.0054, 0.6604],
         [0.0017, 0.3467],
         [0.0015, 0.2382],
         [0.0015, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.443600, steer=0.003601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.5492936668152
20.51840891316533 seconds in game passed.
Action: tensor([[[0.0054, 0.6604],
         [0.0017, 0.3467],
         [0.0015, 0.2382],
         [0.0015, 0.1834]]])
agent 0 action: VehicleControl(throttle=0.446508, steer=0.003602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.5492936668152
+++++++++++++: 1.561217860383739
20.54340891353786 seconds in game passed.
At 20.54340891353786 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.2519e-03,  6.3348e-01],
         [-1.7405e-05,  3.4097e-01],
         [-2.6155e-04,  2.3653e-01],
         [-5.4193e-04,  1.8318e-01]]])
agent 0 action: VehicleControl(throttle=0.385753, steer=0.001494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.561217860383739
Current reward: 0.4834473070154813
Current mitigation activation: 0
#############################
Total reward: 52.032740973830684
20.56840891391039 seconds in game passed.
Action: tensor([[[ 3.2519e-03,  6.3348e-01],
         [-1.7405e-05,  3.4097e-01],
         [-2.6155e-04,  2.3653e-01],
         [-5.4193e-04,  1.8318e-01]]])
agent 0 action: VehicleControl(throttle=0.392060, steer=0.001805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.032740973830684
20.593408914282918 seconds in game passed.
Action: tensor([[[ 3.2519e-03,  6.3348e-01],
         [-1.7405e-05,  3.4097e-01],
         [-2.6155e-04,  2.3653e-01],
         [-5.4193e-04,  1.8318e-01]]])
agent 0 action: VehicleControl(throttle=0.391537, steer=0.001770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.032740973830684
20.618408914655447 seconds in game passed.
Action: tensor([[[ 3.2519e-03,  6.3348e-01],
         [-1.7405e-05,  3.4097e-01],
         [-2.6155e-04,  2.3653e-01],
         [-5.4193e-04,  1.8318e-01]]])
agent 0 action: VehicleControl(throttle=0.391989, steer=0.001736, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.032740973830684
+++++++++++++: 1.5897930819439972
20.643408915027976 seconds in game passed.
At 20.643408915027976 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6312],
         [-0.0034,  0.3381],
         [-0.0040,  0.2330],
         [-0.0045,  0.1796]]])
agent 0 action: VehicleControl(throttle=0.467427, steer=-0.002622, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5897930819439972
Current reward: 0.4828294416345522
Current mitigation activation: 0
#############################
Total reward: 52.515570415465234
20.668408915400505 seconds in game passed.
Action: tensor([[[-0.0013,  0.6312],
         [-0.0034,  0.3381],
         [-0.0040,  0.2330],
         [-0.0045,  0.1796]]])
agent 0 action: VehicleControl(throttle=0.461870, steer=-0.001961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.515570415465234
20.693408915773034 seconds in game passed.
Action: tensor([[[-0.0013,  0.6312],
         [-0.0034,  0.3381],
         [-0.0040,  0.2330],
         [-0.0045,  0.1796]]])
agent 0 action: VehicleControl(throttle=0.464692, steer=-0.002017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.515570415465234
20.718408916145563 seconds in game passed.
Action: tensor([[[-0.0013,  0.6312],
         [-0.0034,  0.3381],
         [-0.0040,  0.2330],
         [-0.0045,  0.1796]]])
agent 0 action: VehicleControl(throttle=0.467373, steer=-0.002072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.515570415465234
+++++++++++++: 1.619531786691714
20.743408916518092 seconds in game passed.
At 20.743408916518092 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.5890e-04,  6.2516e-01],
         [-3.0587e-03,  3.3455e-01],
         [-3.9033e-03,  2.2891e-01],
         [-4.5705e-03,  1.7541e-01]]])
agent 0 action: VehicleControl(throttle=0.533993, steer=-0.001567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.619531786691714
Current reward: 0.48264814808960965
Current mitigation activation: 0
#############################
Total reward: 52.99821856355484
20.76840891689062 seconds in game passed.
Action: tensor([[[-5.5890e-04,  6.2516e-01],
         [-3.0587e-03,  3.3455e-01],
         [-3.9033e-03,  2.2891e-01],
         [-4.5705e-03,  1.7541e-01]]])
agent 0 action: VehicleControl(throttle=0.530748, steer=-0.001723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.99821856355484
20.79340891726315 seconds in game passed.
Action: tensor([[[-5.5890e-04,  6.2516e-01],
         [-3.0587e-03,  3.3455e-01],
         [-3.9033e-03,  2.2891e-01],
         [-4.5705e-03,  1.7541e-01]]])
agent 0 action: VehicleControl(throttle=0.534153, steer=-0.001785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.99821856355484
20.81840891763568 seconds in game passed.
Action: tensor([[[-5.5890e-04,  6.2516e-01],
         [-3.0587e-03,  3.3455e-01],
         [-3.9033e-03,  2.2891e-01],
         [-4.5705e-03,  1.7541e-01]]])
agent 0 action: VehicleControl(throttle=0.536971, steer=-0.001847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.99821856355484
+++++++++++++: 1.648588782182471
20.84340891800821 seconds in game passed.
At 20.84340891800821 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.6320],
         [-0.0049,  0.3355],
         [-0.0054,  0.2290],
         [-0.0056,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.576074, steer=-0.004233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.648588782182471
Current reward: 0.4831794231816263
Current mitigation activation: 0
#############################
Total reward: 53.48139798673647
20.868408918380737 seconds in game passed.
Action: tensor([[[-0.0030,  0.6320],
         [-0.0049,  0.3355],
         [-0.0054,  0.2290],
         [-0.0056,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.574841, steer=-0.003898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.48139798673647
20.893408918753266 seconds in game passed.
Action: tensor([[[-0.0030,  0.6320],
         [-0.0049,  0.3355],
         [-0.0054,  0.2290],
         [-0.0056,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.577125, steer=-0.003951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.48139798673647
20.918408919125795 seconds in game passed.
Action: tensor([[[-0.0030,  0.6320],
         [-0.0049,  0.3355],
         [-0.0054,  0.2290],
         [-0.0056,  0.1757]]])
agent 0 action: VehicleControl(throttle=0.578801, steer=-0.004004, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.48139798673647
+++++++++++++: 1.6742115410179277
20.943408919498324 seconds in game passed.
At 20.943408919498324 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0007,  0.6417],
         [-0.0028,  0.3378],
         [-0.0034,  0.2303],
         [-0.0039,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.593301, steer=-0.001564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6742115410179277
Current reward: 0.48479498663431175
Current mitigation activation: 0
#############################
Total reward: 53.96619297337078
20.968408919870853 seconds in game passed.
Action: tensor([[[-0.0007,  0.6417],
         [-0.0028,  0.3378],
         [-0.0034,  0.2303],
         [-0.0039,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.592891, steer=-0.002006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.96619297337078
20.993408920243382 seconds in game passed.
Action: tensor([[[-0.0007,  0.6417],
         [-0.0028,  0.3378],
         [-0.0034,  0.2303],
         [-0.0039,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.593520, steer=-0.002036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.96619297337078
21.01840892061591 seconds in game passed.
Action: tensor([[[-0.0007,  0.6417],
         [-0.0028,  0.3378],
         [-0.0034,  0.2303],
         [-0.0039,  0.1766]]])
agent 0 action: VehicleControl(throttle=0.593735, steer=-0.002067, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.96619297337078
+++++++++++++: 1.695680210457307
21.04340892098844 seconds in game passed.
At 21.04340892098844 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.6333e-03, 6.1886e-01],
         [2.1055e-03, 3.3525e-01],
         [1.5098e-03, 2.3142e-01],
         [4.6826e-04, 1.7817e-01]]])
agent 0 action: VehicleControl(throttle=0.453307, steer=0.003294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.695680210457307
Current reward: 0.4874810684938359
Current mitigation activation: 0
#############################
Total reward: 54.453674041864616
21.06840892136097 seconds in game passed.
Action: tensor([[[3.6333e-03, 6.1886e-01],
         [2.1055e-03, 3.3525e-01],
         [1.5098e-03, 2.3142e-01],
         [4.6826e-04, 1.7817e-01]]])
agent 0 action: VehicleControl(throttle=0.464213, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.453674041864616
21.0934089217335 seconds in game passed.
Action: tensor([[[3.6333e-03, 6.1886e-01],
         [2.1055e-03, 3.3525e-01],
         [1.5098e-03, 2.3142e-01],
         [4.6826e-04, 1.7817e-01]]])
agent 0 action: VehicleControl(throttle=0.460627, steer=0.002523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.453674041864616
21.118408922106028 seconds in game passed.
Action: tensor([[[3.6333e-03, 6.1886e-01],
         [2.1055e-03, 3.3525e-01],
         [1.5098e-03, 2.3142e-01],
         [4.6826e-04, 1.7817e-01]]])
agent 0 action: VehicleControl(throttle=0.463894, steer=0.002579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.453674041864616
+++++++++++++: 1.7157438803252447
21.143408922478557 seconds in game passed.
At 21.143408922478557 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0043, 0.6287],
         [0.0029, 0.3388],
         [0.0024, 0.2331],
         [0.0015, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.441822, steer=0.003478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7157438803252447
Current reward: 0.490677140238575
Current mitigation activation: 0
#############################
Total reward: 54.94435118210319
21.168408922851086 seconds in game passed.
Action: tensor([[[0.0043, 0.6287],
         [0.0029, 0.3388],
         [0.0024, 0.2331],
         [0.0015, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.446177, steer=0.003371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.94435118210319
21.193408923223615 seconds in game passed.
Action: tensor([[[0.0043, 0.6287],
         [0.0029, 0.3388],
         [0.0024, 0.2331],
         [0.0015, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.448179, steer=0.003407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.94435118210319
21.218408923596144 seconds in game passed.
Action: tensor([[[0.0043, 0.6287],
         [0.0029, 0.3388],
         [0.0024, 0.2331],
         [0.0015, 0.1792]]])
agent 0 action: VehicleControl(throttle=0.450349, steer=0.003443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.94435118210319
+++++++++++++: 1.7424765697516886
21.243408923968673 seconds in game passed.
At 21.243408923968673 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.5929e-03, 6.3877e-01],
         [1.9159e-03, 3.4281e-01],
         [1.3676e-03, 2.3553e-01],
         [5.1588e-04, 1.8116e-01]]])
agent 0 action: VehicleControl(throttle=0.418652, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7424765697516886
Current reward: 0.4930404831273193
Current mitigation activation: 0
#############################
Total reward: 55.43739166523051
21.268408924341202 seconds in game passed.
Action: tensor([[[3.5929e-03, 6.3877e-01],
         [1.9159e-03, 3.4281e-01],
         [1.3676e-03, 2.3553e-01],
         [5.1588e-04, 1.8116e-01]]])
agent 0 action: VehicleControl(throttle=0.427230, steer=0.002587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.43739166523051
21.29340892471373 seconds in game passed.
Action: tensor([[[3.5929e-03, 6.3877e-01],
         [1.9159e-03, 3.4281e-01],
         [1.3676e-03, 2.3553e-01],
         [5.1588e-04, 1.8116e-01]]])
agent 0 action: VehicleControl(throttle=0.432042, steer=0.002582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.43739166523051
21.31840892508626 seconds in game passed.
Action: tensor([[[3.5929e-03, 6.3877e-01],
         [1.9159e-03, 3.4281e-01],
         [1.3676e-03, 2.3553e-01],
         [5.1588e-04, 1.8116e-01]]])
agent 0 action: VehicleControl(throttle=0.436938, steer=0.002576, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.43739166523051
+++++++++++++: 1.771089710734992
21.34340892545879 seconds in game passed.
At 21.34340892545879 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9814e-03, 6.3230e-01],
         [1.6133e-03, 3.3889e-01],
         [1.2326e-03, 2.3247e-01],
         [2.5652e-04, 1.7857e-01]]])
agent 0 action: VehicleControl(throttle=0.511599, steer=0.001699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.771089710734992
Current reward: 0.49543135725757176
Current mitigation activation: 0
#############################
Total reward: 55.93282302248808
21.368408925831318 seconds in game passed.
Action: tensor([[[1.9814e-03, 6.3230e-01],
         [1.6133e-03, 3.3889e-01],
         [1.2326e-03, 2.3247e-01],
         [2.5652e-04, 1.7857e-01]]])
agent 0 action: VehicleControl(throttle=0.509868, steer=0.001824, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.93282302248808
21.393408926203847 seconds in game passed.
Action: tensor([[[1.9814e-03, 6.3230e-01],
         [1.6133e-03, 3.3889e-01],
         [1.2326e-03, 2.3247e-01],
         [2.5652e-04, 1.7857e-01]]])
agent 0 action: VehicleControl(throttle=0.515503, steer=0.001805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.93282302248808
21.418408926576376 seconds in game passed.
Action: tensor([[[1.9814e-03, 6.3230e-01],
         [1.6133e-03, 3.3889e-01],
         [1.2326e-03, 2.3247e-01],
         [2.5652e-04, 1.7857e-01]]])
agent 0 action: VehicleControl(throttle=0.521087, steer=0.001787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.93282302248808
+++++++++++++: 1.8009709213742213
21.443408926948905 seconds in game passed.
At 21.443408926948905 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.5153e-04,  6.2358e-01],
         [-1.8311e-04,  3.3450e-01],
         [-6.3199e-04,  2.3012e-01],
         [-1.6358e-03,  1.7721e-01]]])
agent 0 action: VehicleControl(throttle=0.589596, steer=-0.000448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8009709213742213
Current reward: 0.4979516505613436
Current mitigation activation: 0
#############################
Total reward: 56.43077467304942
21.468408927321434 seconds in game passed.
Action: tensor([[[-2.5153e-04,  6.2358e-01],
         [-1.8311e-04,  3.3450e-01],
         [-6.3199e-04,  2.3012e-01],
         [-1.6358e-03,  1.7721e-01]]])
agent 0 action: VehicleControl(throttle=0.586558, steer=-0.000119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.43077467304942
21.493408927693963 seconds in game passed.
Action: tensor([[[-2.5153e-04,  6.2358e-01],
         [-1.8311e-04,  3.3450e-01],
         [-6.3199e-04,  2.3012e-01],
         [-1.6358e-03,  1.7721e-01]]])
agent 0 action: VehicleControl(throttle=0.590328, steer=-0.000156, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.43077467304942
21.518408928066492 seconds in game passed.
Action: tensor([[[-2.5153e-04,  6.2358e-01],
         [-1.8311e-04,  3.3450e-01],
         [-6.3199e-04,  2.3012e-01],
         [-1.6358e-03,  1.7721e-01]]])
agent 0 action: VehicleControl(throttle=0.593993, steer=-0.000194, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.43077467304942
+++++++++++++: 1.8321061251188948
21.54340892843902 seconds in game passed.
At 21.54340892843902 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6287],
         [-0.0015,  0.3360],
         [-0.0018,  0.2304],
         [-0.0025,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.595832, steer=-0.001912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8321061251188948
Current reward: 0.5005972438659032
Current mitigation activation: 0
#############################
Total reward: 56.931371916915325
21.56840892881155 seconds in game passed.
Action: tensor([[[-0.0020,  0.6287],
         [-0.0015,  0.3360],
         [-0.0018,  0.2304],
         [-0.0025,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.600226, steer=-0.001664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.931371916915325
21.59340892918408 seconds in game passed.
Action: tensor([[[-0.0020,  0.6287],
         [-0.0015,  0.3360],
         [-0.0018,  0.2304],
         [-0.0025,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.604287, steer=-0.001698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.931371916915325
21.618408929556608 seconds in game passed.
Action: tensor([[[-0.0020,  0.6287],
         [-0.0015,  0.3360],
         [-0.0018,  0.2304],
         [-0.0025,  0.1771]]])
agent 0 action: VehicleControl(throttle=0.594244, steer=-0.001731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.931371916915325
+++++++++++++: 1.8605837255780326
21.643408929929137 seconds in game passed.
At 21.643408929929137 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.6309],
         [-0.0032,  0.3369],
         [-0.0034,  0.2302],
         [-0.0036,  0.1767]]])
agent 0 action: VehicleControl(throttle=0.565162, steer=-0.003475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8605837255780326
Current reward: 0.5039427485096354
Current mitigation activation: 0
#############################
Total reward: 57.43531466542496
21.668408930301666 seconds in game passed.
Action: tensor([[[-0.0034,  0.6309],
         [-0.0032,  0.3369],
         [-0.0034,  0.2302],
         [-0.0036,  0.1767]]])
agent 0 action: VehicleControl(throttle=0.549218, steer=-0.003192, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.43531466542496
21.693408930674195 seconds in game passed.
Action: tensor([[[-0.0034,  0.6309],
         [-0.0032,  0.3369],
         [-0.0034,  0.2302],
         [-0.0036,  0.1767]]])
agent 0 action: VehicleControl(throttle=0.533420, steer=-0.003198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.43531466542496
21.718408931046724 seconds in game passed.
Action: tensor([[[-0.0034,  0.6309],
         [-0.0032,  0.3369],
         [-0.0034,  0.2302],
         [-0.0036,  0.1767]]])
agent 0 action: VehicleControl(throttle=0.518816, steer=-0.003205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.43531466542496
+++++++++++++: 1.8645221424711251
21.743408931419253 seconds in game passed.
At 21.743408931419253 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.7601e-04,  6.1331e-01],
         [-5.9256e-04,  3.3283e-01],
         [-4.8581e-04,  2.2926e-01],
         [-5.3041e-04,  1.7641e-01]]])
agent 0 action: VehicleControl(throttle=0.470158, steer=-0.000110, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8645221424711251
Current reward: 0.511156035394375
Current mitigation activation: 0
#############################
Total reward: 57.94647070081933
21.768408931791782 seconds in game passed.
Action: tensor([[[-3.7601e-04,  6.1331e-01],
         [-5.9256e-04,  3.3283e-01],
         [-4.8581e-04,  2.2926e-01],
         [-5.3041e-04,  1.7641e-01]]])
agent 0 action: VehicleControl(throttle=0.460316, steer=-0.000603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.94647070081933
21.79340893216431 seconds in game passed.
Action: tensor([[[-3.7601e-04,  6.1331e-01],
         [-5.9256e-04,  3.3283e-01],
         [-4.8581e-04,  2.2926e-01],
         [-5.3041e-04,  1.7641e-01]]])
agent 0 action: VehicleControl(throttle=0.447927, steer=-0.000584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.94647070081933
21.81840893253684 seconds in game passed.
Action: tensor([[[-3.7601e-04,  6.1331e-01],
         [-5.9256e-04,  3.3283e-01],
         [-4.8581e-04,  2.2926e-01],
         [-5.3041e-04,  1.7641e-01]]])
agent 0 action: VehicleControl(throttle=0.436809, steer=-0.000564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.94647070081933
+++++++++++++: 1.8721912732646473
21.84340893290937 seconds in game passed.
At 21.84340893290937 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.9059e-04, 6.1344e-01],
         [1.0636e-03, 3.2887e-01],
         [1.2556e-03, 2.2460e-01],
         [1.1904e-03, 1.7156e-01]]])
agent 0 action: VehicleControl(throttle=0.569766, steer=0.001089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8721912732646473
Current reward: 0.5176906613446445
Current mitigation activation: 0
#############################
Total reward: 58.46416136216398
21.8684089332819 seconds in game passed.
Action: tensor([[[5.9059e-04, 6.1344e-01],
         [1.0636e-03, 3.2887e-01],
         [1.2556e-03, 2.2460e-01],
         [1.1904e-03, 1.7156e-01]]])
agent 0 action: VehicleControl(throttle=0.546809, steer=0.000884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.46416136216398
21.893408933654428 seconds in game passed.
Action: tensor([[[5.9059e-04, 6.1344e-01],
         [1.0636e-03, 3.2887e-01],
         [1.2556e-03, 2.2460e-01],
         [1.1904e-03, 1.7156e-01]]])
agent 0 action: VehicleControl(throttle=0.539775, steer=0.000944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.46416136216398
21.918408934026957 seconds in game passed.
Action: tensor([[[5.9059e-04, 6.1344e-01],
         [1.0636e-03, 3.2887e-01],
         [1.2556e-03, 2.2460e-01],
         [1.1904e-03, 1.7156e-01]]])
agent 0 action: VehicleControl(throttle=0.532454, steer=0.001005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.46416136216398
+++++++++++++: 1.8879628219185718
21.943408934399486 seconds in game passed.
At 21.943408934399486 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6248],
         [0.0033, 0.3362],
         [0.0029, 0.2298],
         [0.0020, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.382490, steer=0.003642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8879628219185718
Current reward: 0.5229255972784402
Current mitigation activation: 0
#############################
Total reward: 58.987086959442415
21.968408934772015 seconds in game passed.
Action: tensor([[[0.0031, 0.6248],
         [0.0033, 0.3362],
         [0.0029, 0.2298],
         [0.0020, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.388520, steer=0.003274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.987086959442415
21.993408935144544 seconds in game passed.
Action: tensor([[[0.0031, 0.6248],
         [0.0033, 0.3362],
         [0.0029, 0.2298],
         [0.0020, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.379885, steer=0.003336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.987086959442415
22.018408935517073 seconds in game passed.
Action: tensor([[[0.0031, 0.6248],
         [0.0033, 0.3362],
         [0.0029, 0.2298],
         [0.0020, 0.1755]]])
agent 0 action: VehicleControl(throttle=0.372592, steer=0.003397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.987086959442415
+++++++++++++: 1.9069796951330402
22.0434089358896 seconds in game passed.
At 22.0434089358896 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6226],
         [0.0034, 0.3301],
         [0.0033, 0.2248],
         [0.0027, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.559224, steer=0.003146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9069796951330402
Current reward: 0.527699403879772
Current mitigation activation: 0
#############################
Total reward: 59.51478636332219
22.06840893626213 seconds in game passed.
Action: tensor([[[0.0022, 0.6226],
         [0.0034, 0.3301],
         [0.0033, 0.2248],
         [0.0027, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.537277, steer=0.003192, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.51478636332219
22.09340893663466 seconds in game passed.
Action: tensor([[[0.0022, 0.6226],
         [0.0034, 0.3301],
         [0.0033, 0.2248],
         [0.0027, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.536232, steer=0.003196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.51478636332219
22.11840893700719 seconds in game passed.
Action: tensor([[[0.0022, 0.6226],
         [0.0034, 0.3301],
         [0.0033, 0.2248],
         [0.0027, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.534508, steer=0.003199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.51478636332219
+++++++++++++: 1.9309552774044998
22.143408937379718 seconds in game passed.
At 22.143408937379718 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0007, 0.6102],
         [0.0026, 0.3257],
         [0.0024, 0.2219],
         [0.0014, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.566065, steer=0.002063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9309552774044998
Current reward: 0.5317991700464944
Current mitigation activation: 0
#############################
Total reward: 60.046585533368685
22.168408937752247 seconds in game passed.
Action: tensor([[[0.0007, 0.6102],
         [0.0026, 0.3257],
         [0.0024, 0.2219],
         [0.0014, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.560264, steer=0.002232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.046585533368685
22.193408938124776 seconds in game passed.
Action: tensor([[[0.0007, 0.6102],
         [0.0026, 0.3257],
         [0.0024, 0.2219],
         [0.0014, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.557507, steer=0.002215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.046585533368685
22.218408938497305 seconds in game passed.
Action: tensor([[[0.0007, 0.6102],
         [0.0026, 0.3257],
         [0.0024, 0.2219],
         [0.0014, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.554113, steer=0.002198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.046585533368685
+++++++++++++: 1.955154436975388
22.243408938869834 seconds in game passed.
At 22.243408938869834 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.0012e-04, 6.2364e-01],
         [2.9136e-03, 3.3104e-01],
         [2.8110e-03, 2.2444e-01],
         [1.7559e-03, 1.7162e-01]]])
agent 0 action: VehicleControl(throttle=0.494767, steer=0.002360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.955154436975388
Current reward: 0.5359939954975265
Current mitigation activation: 0
#############################
Total reward: 60.58257952886621
22.268408939242363 seconds in game passed.
Action: tensor([[[6.0012e-04, 6.2364e-01],
         [2.9136e-03, 3.3104e-01],
         [2.8110e-03, 2.2444e-01],
         [1.7559e-03, 1.7162e-01]]])
agent 0 action: VehicleControl(throttle=0.496223, steer=0.002328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.58257952886621
22.293408939614892 seconds in game passed.
Action: tensor([[[6.0012e-04, 6.2364e-01],
         [2.9136e-03, 3.3104e-01],
         [2.8110e-03, 2.2444e-01],
         [1.7559e-03, 1.7162e-01]]])
agent 0 action: VehicleControl(throttle=0.491609, steer=0.002323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.58257952886621
22.31840893998742 seconds in game passed.
Action: tensor([[[6.0012e-04, 6.2364e-01],
         [2.9136e-03, 3.3104e-01],
         [2.8110e-03, 2.2444e-01],
         [1.7559e-03, 1.7162e-01]]])
agent 0 action: VehicleControl(throttle=0.487241, steer=0.002318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.58257952886621
+++++++++++++: 1.9769224889997241
22.34340894035995 seconds in game passed.
At 22.34340894035995 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0029, 0.6256],
         [0.0049, 0.3295],
         [0.0050, 0.2232],
         [0.0042, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.556453, steer=0.004743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9769224889997241
Current reward: 0.5406553409116795
Current mitigation activation: 0
#############################
Total reward: 61.12323486977789
22.36840894073248 seconds in game passed.
Action: tensor([[[0.0029, 0.6256],
         [0.0049, 0.3295],
         [0.0050, 0.2232],
         [0.0042, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.544571, steer=0.004373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.12323486977789
22.393408941105008 seconds in game passed.
Action: tensor([[[0.0029, 0.6256],
         [0.0049, 0.3295],
         [0.0050, 0.2232],
         [0.0042, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.540521, steer=0.004403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.12323486977789
22.418408941477537 seconds in game passed.
Action: tensor([[[0.0029, 0.6256],
         [0.0049, 0.3295],
         [0.0050, 0.2232],
         [0.0042, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.535976, steer=0.004432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.12323486977789
+++++++++++++: 1.9990434341136791
22.443408941850066 seconds in game passed.
At 22.443408941850066 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0060, 0.6385],
         [0.0084, 0.3335],
         [0.0088, 0.2247],
         [0.0080, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.515561, steer=0.008327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9990434341136791
Current reward: 0.5453173248570053
Current mitigation activation: 0
#############################
Total reward: 61.66855219463489
22.468408942222595 seconds in game passed.
Action: tensor([[[0.0060, 0.6385],
         [0.0084, 0.3335],
         [0.0088, 0.2247],
         [0.0080, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.511245, steer=0.007785, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.66855219463489
22.493408942595124 seconds in game passed.
Action: tensor([[[0.0060, 0.6385],
         [0.0084, 0.3335],
         [0.0088, 0.2247],
         [0.0080, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.505306, steer=0.007876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.66855219463489
22.518408942967653 seconds in game passed.
Action: tensor([[[0.0060, 0.6385],
         [0.0084, 0.3335],
         [0.0088, 0.2247],
         [0.0080, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.499377, steer=0.007968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.66855219463489
+++++++++++++: 2.0207371226266186
22.543408943340182 seconds in game passed.
At 22.543408943340182 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0103, 0.6532],
         [0.0147, 0.3391],
         [0.0161, 0.2272],
         [0.0155, 0.1732]]])
agent 0 action: VehicleControl(throttle=0.438694, steer=0.014475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0207371226266186
Current reward: 0.5500779645372804
Current mitigation activation: 0
#############################
Total reward: 62.21863015917217
22.56840894371271 seconds in game passed.
Action: tensor([[[0.0103, 0.6532],
         [0.0147, 0.3391],
         [0.0161, 0.2272],
         [0.0155, 0.1732]]])
agent 0 action: VehicleControl(throttle=0.438138, steer=0.013595, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.21863015917217
22.59340894408524 seconds in game passed.
Action: tensor([[[0.0103, 0.6532],
         [0.0147, 0.3391],
         [0.0161, 0.2272],
         [0.0155, 0.1732]]])
agent 0 action: VehicleControl(throttle=0.432183, steer=0.013770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.21863015917217
22.61840894445777 seconds in game passed.
Action: tensor([[[0.0103, 0.6532],
         [0.0147, 0.3391],
         [0.0161, 0.2272],
         [0.0155, 0.1732]]])
agent 0 action: VehicleControl(throttle=0.426900, steer=0.013945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.21863015917217
+++++++++++++: 2.0430624477581056
22.6434089448303 seconds in game passed.
At 22.6434089448303 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0085, 0.6453],
         [0.0086, 0.3374],
         [0.0087, 0.2278],
         [0.0078, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.405514, steer=0.008808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0430624477581056
Current reward: 0.5547607818777739
Current mitigation activation: 0
#############################
Total reward: 62.773390941049946
22.668408945202827 seconds in game passed.
Action: tensor([[[0.0085, 0.6453],
         [0.0086, 0.3374],
         [0.0087, 0.2278],
         [0.0078, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.403352, steer=0.009826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.773390941049946
22.693408945575356 seconds in game passed.
Action: tensor([[[0.0085, 0.6453],
         [0.0086, 0.3374],
         [0.0087, 0.2278],
         [0.0078, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.399989, steer=0.009964, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.773390941049946
22.718408945947886 seconds in game passed.
Action: tensor([[[0.0085, 0.6453],
         [0.0086, 0.3374],
         [0.0087, 0.2278],
         [0.0078, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.397397, steer=0.010103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.773390941049946
+++++++++++++: 2.068600010340116
22.743408946320415 seconds in game passed.
At 22.743408946320415 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0036, 0.6450],
         [0.0049, 0.3382],
         [0.0047, 0.2285],
         [0.0036, 0.1739]]])
agent 0 action: VehicleControl(throttle=0.366703, steer=0.005575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.068600010340116
Current reward: 0.5589878858281755
Current mitigation activation: 0
#############################
Total reward: 63.33237882687812
22.768408946692944 seconds in game passed.
Action: tensor([[[0.0036, 0.6450],
         [0.0049, 0.3382],
         [0.0047, 0.2285],
         [0.0036, 0.1739]]])
agent 0 action: VehicleControl(throttle=0.368446, steer=0.006398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.33237882687812
22.793408947065473 seconds in game passed.
Action: tensor([[[0.0036, 0.6450],
         [0.0049, 0.3382],
         [0.0047, 0.2285],
         [0.0036, 0.1739]]])
agent 0 action: VehicleControl(throttle=0.367642, steer=0.006456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.33237882687812
22.818408947438 seconds in game passed.
Action: tensor([[[0.0036, 0.6450],
         [0.0049, 0.3382],
         [0.0047, 0.2285],
         [0.0036, 0.1739]]])
agent 0 action: VehicleControl(throttle=0.367543, steer=0.006515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.33237882687812
+++++++++++++: 2.0978875426286683
22.84340894781053 seconds in game passed.
At 22.84340894781053 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0049, 0.6391],
         [0.0059, 0.3352],
         [0.0056, 0.2266],
         [0.0046, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.412435, steer=0.007772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0978875426286683
Current reward: 0.5627133515140954
Current mitigation activation: 0
#############################
Total reward: 63.89509217839222
22.86840894818306 seconds in game passed.
Action: tensor([[[0.0049, 0.6391],
         [0.0059, 0.3352],
         [0.0056, 0.2266],
         [0.0046, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.407384, steer=0.007626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.89509217839222
22.89340894855559 seconds in game passed.
Action: tensor([[[0.0049, 0.6391],
         [0.0059, 0.3352],
         [0.0056, 0.2266],
         [0.0046, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.407483, steer=0.007681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.89509217839222
22.918408948928118 seconds in game passed.
Action: tensor([[[0.0049, 0.6391],
         [0.0059, 0.3352],
         [0.0056, 0.2266],
         [0.0046, 0.1727]]])
agent 0 action: VehicleControl(throttle=0.407530, steer=0.007735, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.89509217839222
+++++++++++++: 2.1305450825065146
22.943408949300647 seconds in game passed.
At 22.943408949300647 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6172],
         [0.0048, 0.3266],
         [0.0046, 0.2219],
         [0.0036, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.501466, steer=0.006341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1305450825065146
Current reward: 0.5660414835447575
Current mitigation activation: 0
#############################
Total reward: 64.46113366193697
22.968408949673176 seconds in game passed.
Action: tensor([[[0.0033, 0.6172],
         [0.0048, 0.3266],
         [0.0046, 0.2219],
         [0.0036, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.494430, steer=0.006589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.46113366193697
22.993408950045705 seconds in game passed.
Action: tensor([[[0.0033, 0.6172],
         [0.0048, 0.3266],
         [0.0046, 0.2219],
         [0.0036, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.496990, steer=0.006602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.46113366193697
23.018408950418234 seconds in game passed.
Action: tensor([[[0.0033, 0.6172],
         [0.0048, 0.3266],
         [0.0046, 0.2219],
         [0.0036, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.498802, steer=0.006615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.46113366193697
+++++++++++++: 2.163782980578347
23.043408950790763 seconds in game passed.
At 23.043408950790763 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0021, 0.6148],
         [0.0026, 0.3273],
         [0.0023, 0.2228],
         [0.0015, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.447254, steer=0.004485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.163782980578347
Current reward: 0.5693950879078876
Current mitigation activation: 0
#############################
Total reward: 65.03052874984486
23.068408951163292 seconds in game passed.
Action: tensor([[[0.0021, 0.6148],
         [0.0026, 0.3273],
         [0.0023, 0.2228],
         [0.0015, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.450745, steer=0.004833, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.03052874984486
23.09340895153582 seconds in game passed.
Action: tensor([[[0.0021, 0.6148],
         [0.0026, 0.3273],
         [0.0023, 0.2228],
         [0.0015, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.448573, steer=0.004826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.03052874984486
23.11840895190835 seconds in game passed.
Action: tensor([[[0.0021, 0.6148],
         [0.0026, 0.3273],
         [0.0023, 0.2228],
         [0.0015, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.446515, steer=0.004820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.03052874984486
+++++++++++++: 2.1943371657471973
23.14340895228088 seconds in game passed.
At 23.14340895228088 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.6314e-03, 6.1758e-01],
         [2.4042e-03, 3.2729e-01],
         [1.7923e-03, 2.2264e-01],
         [5.4350e-04, 1.7046e-01]]])
agent 0 action: VehicleControl(throttle=0.471859, steer=0.004902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1943371657471973
Current reward: 0.5732005365199373
Current mitigation activation: 0
#############################
Total reward: 65.6037292863648
23.168408952653408 seconds in game passed.
Action: tensor([[[2.6314e-03, 6.1758e-01],
         [2.4042e-03, 3.2729e-01],
         [1.7923e-03, 2.2264e-01],
         [5.4350e-04, 1.7046e-01]]])
agent 0 action: VehicleControl(throttle=0.466892, steer=0.004895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.6037292863648
23.193408953025937 seconds in game passed.
Action: tensor([[[2.6314e-03, 6.1758e-01],
         [2.4042e-03, 3.2729e-01],
         [1.7923e-03, 2.2264e-01],
         [5.4350e-04, 1.7046e-01]]])
agent 0 action: VehicleControl(throttle=0.464865, steer=0.004901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.6037292863648
23.218408953398466 seconds in game passed.
Action: tensor([[[2.6314e-03, 6.1758e-01],
         [2.4042e-03, 3.2729e-01],
         [1.7923e-03, 2.2264e-01],
         [5.4350e-04, 1.7046e-01]]])
agent 0 action: VehicleControl(throttle=0.462696, steer=0.004907, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.6037292863648
+++++++++++++: 2.2238486766711723
23.243408953770995 seconds in game passed.
At 23.243408953770995 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6231],
         [0.0039, 0.3297],
         [0.0038, 0.2241],
         [0.0028, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.429668, steer=0.006028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2238486766711723
Current reward: 0.5771822346712304
Current mitigation activation: 0
#############################
Total reward: 66.18091152103602
23.268408954143524 seconds in game passed.
Action: tensor([[[0.0026, 0.6231],
         [0.0039, 0.3297],
         [0.0038, 0.2241],
         [0.0028, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.431044, steer=0.005860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.18091152103602
23.293408954516053 seconds in game passed.
Action: tensor([[[0.0026, 0.6231],
         [0.0039, 0.3297],
         [0.0038, 0.2241],
         [0.0028, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.429206, steer=0.005876, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.18091152103602
23.318408954888582 seconds in game passed.
Action: tensor([[[0.0026, 0.6231],
         [0.0039, 0.3297],
         [0.0038, 0.2241],
         [0.0028, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.427664, steer=0.005892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.18091152103602
+++++++++++++: 2.253068744448339
23.34340895526111 seconds in game passed.
At 23.34340895526111 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6273],
         [0.0054, 0.3316],
         [0.0052, 0.2249],
         [0.0043, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.398466, steer=0.007305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.253068744448339
Current reward: 0.5812176653199599
Current mitigation activation: 0
#############################
Total reward: 66.76212918635598
23.36840895563364 seconds in game passed.
Action: tensor([[[0.0035, 0.6273],
         [0.0054, 0.3316],
         [0.0052, 0.2249],
         [0.0043, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.399107, steer=0.007076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.76212918635598
23.39340895600617 seconds in game passed.
Action: tensor([[[0.0035, 0.6273],
         [0.0054, 0.3316],
         [0.0052, 0.2249],
         [0.0043, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.397172, steer=0.007081, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.76212918635598
23.4184089563787 seconds in game passed.
Action: tensor([[[0.0035, 0.6273],
         [0.0054, 0.3316],
         [0.0052, 0.2249],
         [0.0043, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.395658, steer=0.007087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.76212918635598
+++++++++++++: 2.283388737598705
23.443408956751227 seconds in game passed.
At 23.443408956751227 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.6126],
         [0.0028, 0.3289],
         [0.0024, 0.2244],
         [0.0015, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.342083, steer=0.004716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.283388737598705
Current reward: 0.5851155904009198
Current mitigation activation: 0
#############################
Total reward: 67.3472447767569
23.468408957123756 seconds in game passed.
Action: tensor([[[0.0024, 0.6126],
         [0.0028, 0.3289],
         [0.0024, 0.2244],
         [0.0015, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.346385, steer=0.005043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.3472447767569
23.493408957496285 seconds in game passed.
Action: tensor([[[0.0024, 0.6126],
         [0.0028, 0.3289],
         [0.0024, 0.2244],
         [0.0015, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.345539, steer=0.004985, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.3472447767569
23.518408957868814 seconds in game passed.
Action: tensor([[[0.0024, 0.6126],
         [0.0028, 0.3289],
         [0.0024, 0.2244],
         [0.0015, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.345417, steer=0.004927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.3472447767569
+++++++++++++: 2.316064910170689
23.543408958241343 seconds in game passed.
At 23.543408958241343 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0017e-03, 6.1423e-01],
         [1.5379e-03, 3.2786e-01],
         [1.2309e-03, 2.2330e-01],
         [2.6568e-04, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.402221, steer=0.003315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.316064910170689
Current reward: 0.588721821900803
Current mitigation activation: 0
#############################
Total reward: 67.9359665986577
23.568408958613873 seconds in game passed.
Action: tensor([[[1.0017e-03, 6.1423e-01],
         [1.5379e-03, 3.2786e-01],
         [1.2309e-03, 2.2330e-01],
         [2.6568e-04, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.398398, steer=0.003421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.9359665986577
23.5934089589864 seconds in game passed.
Action: tensor([[[1.0017e-03, 6.1423e-01],
         [1.5379e-03, 3.2786e-01],
         [1.2309e-03, 2.2330e-01],
         [2.6568e-04, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.400708, steer=0.003281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.9359665986577
23.61840895935893 seconds in game passed.
Action: tensor([[[1.0017e-03, 6.1423e-01],
         [1.5379e-03, 3.2786e-01],
         [1.2309e-03, 2.2330e-01],
         [2.6568e-04, 1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.402864, steer=0.003142, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.9359665986577
+++++++++++++: 2.3520319187641707
23.64340895973146 seconds in game passed.
At 23.64340895973146 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.6244],
         [-0.0007,  0.3301],
         [-0.0011,  0.2238],
         [-0.0019,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.428801, steer=0.000334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3520319187641707
Current reward: 0.591944993425004
Current mitigation activation: 0
#############################
Total reward: 68.5279115920827
23.66840896010399 seconds in game passed.
Action: tensor([[[-0.0017,  0.6244],
         [-0.0007,  0.3301],
         [-0.0011,  0.2238],
         [-0.0019,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.428776, steer=0.000671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.5279115920827
23.693408960476518 seconds in game passed.
Action: tensor([[[-0.0017,  0.6244],
         [-0.0007,  0.3301],
         [-0.0011,  0.2238],
         [-0.0019,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.431114, steer=0.000558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.5279115920827
23.718408960849047 seconds in game passed.
Action: tensor([[[-0.0017,  0.6244],
         [-0.0007,  0.3301],
         [-0.0011,  0.2238],
         [-0.0019,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.433169, steer=0.000446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.5279115920827
+++++++++++++: 2.388369899020049
23.743408961221576 seconds in game passed.
At 23.743408961221576 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6108],
         [-0.0016,  0.3257],
         [-0.0022,  0.2213],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.457291, steer=-0.000427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.388369899020049
Current reward: 0.5951916671830735
Current mitigation activation: 0
#############################
Total reward: 69.12310325926578
23.768408961594105 seconds in game passed.
Action: tensor([[[-0.0021,  0.6108],
         [-0.0016,  0.3257],
         [-0.0022,  0.2213],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.457156, steer=-0.000367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.12310325926578
23.793408961966634 seconds in game passed.
Action: tensor([[[-0.0021,  0.6108],
         [-0.0016,  0.3257],
         [-0.0022,  0.2213],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.459093, steer=-0.000440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.12310325926578
23.818408962339163 seconds in game passed.
Action: tensor([[[-0.0021,  0.6108],
         [-0.0016,  0.3257],
         [-0.0022,  0.2213],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.460655, steer=-0.000513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.12310325926578
+++++++++++++: 2.423042677028191
23.843408962711692 seconds in game passed.
At 23.843408962711692 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0032,  0.6143],
         [-0.0029,  0.3271],
         [-0.0032,  0.2224],
         [-0.0038,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.442897, steer=-0.002024, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.423042677028191
Current reward: 0.5987078858689532
Current mitigation activation: 0
#############################
Total reward: 69.72181114513472
23.86840896308422 seconds in game passed.
Action: tensor([[[-0.0032,  0.6143],
         [-0.0029,  0.3271],
         [-0.0032,  0.2224],
         [-0.0038,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.445130, steer=-0.001889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.72181114513472
23.89340896345675 seconds in game passed.
Action: tensor([[[-0.0032,  0.6143],
         [-0.0029,  0.3271],
         [-0.0032,  0.2224],
         [-0.0038,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.445214, steer=-0.001989, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.72181114513472
23.91840896382928 seconds in game passed.
Action: tensor([[[-0.0032,  0.6143],
         [-0.0029,  0.3271],
         [-0.0032,  0.2224],
         [-0.0038,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.445238, steer=-0.002090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.72181114513472
+++++++++++++: 2.455555863374432
23.943408964201808 seconds in game passed.
At 23.943408964201808 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.6451e-04,  6.0542e-01],
         [-9.7468e-04,  3.2577e-01],
         [-1.0350e-03,  2.2226e-01],
         [-1.3979e-03,  1.6939e-01]]])
agent 0 action: VehicleControl(throttle=0.400938, steer=0.000380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.455555863374432
Current reward: 0.6025217571945548
Current mitigation activation: 0
#############################
Total reward: 70.32433290232927
23.968408964574337 seconds in game passed.
Action: tensor([[[-3.6451e-04,  6.0542e-01],
         [-9.7468e-04,  3.2577e-01],
         [-1.0350e-03,  2.2226e-01],
         [-1.3979e-03,  1.6939e-01]]])
agent 0 action: VehicleControl(throttle=0.403899, steer=-0.000101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.32433290232927
23.993408964946866 seconds in game passed.
Action: tensor([[[-3.6451e-04,  6.0542e-01],
         [-9.7468e-04,  3.2577e-01],
         [-1.0350e-03,  2.2226e-01],
         [-1.3979e-03,  1.6939e-01]]])
agent 0 action: VehicleControl(throttle=0.402349, steer=-0.000160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.32433290232927
24.018408965319395 seconds in game passed.
Action: tensor([[[-3.6451e-04,  6.0542e-01],
         [-9.7468e-04,  3.2577e-01],
         [-1.0350e-03,  2.2226e-01],
         [-1.3979e-03,  1.6939e-01]]])
agent 0 action: VehicleControl(throttle=0.401144, steer=-0.000220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.32433290232927
+++++++++++++: 2.487335923122942
24.043408965691924 seconds in game passed.
At 24.043408965691924 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.0365e-04,  6.0936e-01],
         [-5.8041e-04,  3.2767e-01],
         [-1.1673e-03,  2.2325e-01],
         [-1.8841e-03,  1.6980e-01]]])
agent 0 action: VehicleControl(throttle=0.372503, steer=0.000018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.487335923122942
Current reward: 0.6064333395668227
Current mitigation activation: 0
#############################
Total reward: 70.9307662418961
24.068408966064453 seconds in game passed.
Action: tensor([[[-4.0365e-04,  6.0936e-01],
         [-5.8041e-04,  3.2767e-01],
         [-1.1673e-03,  2.2325e-01],
         [-1.8841e-03,  1.6980e-01]]])
agent 0 action: VehicleControl(throttle=0.374998, steer=-0.000061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.9307662418961
24.093408966436982 seconds in game passed.
Action: tensor([[[-4.0365e-04,  6.0936e-01],
         [-5.8041e-04,  3.2767e-01],
         [-1.1673e-03,  2.2325e-01],
         [-1.8841e-03,  1.6980e-01]]])
agent 0 action: VehicleControl(throttle=0.374786, steer=-0.000096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.9307662418961
24.11840896680951 seconds in game passed.
Action: tensor([[[-4.0365e-04,  6.0936e-01],
         [-5.8041e-04,  3.2767e-01],
         [-1.1673e-03,  2.2325e-01],
         [-1.8841e-03,  1.6980e-01]]])
agent 0 action: VehicleControl(throttle=0.374990, steer=-0.000130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.9307662418961
+++++++++++++: 2.5207033912708905
24.14340896718204 seconds in game passed.
At 24.14340896718204 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.9994e-04,  6.1589e-01],
         [ 8.7906e-04,  3.2951e-01],
         [ 3.8566e-04,  2.2394e-01],
         [-4.4660e-04,  1.7053e-01]]])
agent 0 action: VehicleControl(throttle=0.376890, steer=0.001432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5207033912708905
Current reward: 0.6101581477820173
Current mitigation activation: 0
#############################
Total reward: 71.54092438967811
24.16840896755457 seconds in game passed.
Action: tensor([[[ 8.9994e-04,  6.1589e-01],
         [ 8.7906e-04,  3.2951e-01],
         [ 3.8566e-04,  2.2394e-01],
         [-4.4660e-04,  1.7053e-01]]])
agent 0 action: VehicleControl(throttle=0.377201, steer=0.001150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.54092438967811
24.1934089679271 seconds in game passed.
Action: tensor([[[ 8.9994e-04,  6.1589e-01],
         [ 8.7906e-04,  3.2951e-01],
         [ 3.8566e-04,  2.2394e-01],
         [-4.4660e-04,  1.7053e-01]]])
agent 0 action: VehicleControl(throttle=0.377914, steer=0.001131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.54092438967811
24.218408968299627 seconds in game passed.
Action: tensor([[[ 8.9994e-04,  6.1589e-01],
         [ 8.7906e-04,  3.2951e-01],
         [ 3.8566e-04,  2.2394e-01],
         [-4.4660e-04,  1.7053e-01]]])
agent 0 action: VehicleControl(throttle=0.378801, steer=0.001112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.54092438967811
+++++++++++++: 2.556569157175805
24.243408968672156 seconds in game passed.
At 24.243408968672156 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.4555e-03, 6.2519e-01],
         [2.3704e-03, 3.3264e-01],
         [1.4752e-03, 2.2655e-01],
         [3.3561e-04, 1.7231e-01]]])
agent 0 action: VehicleControl(throttle=0.362635, steer=0.003596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.556569157175805
Current reward: 0.6136086480903504
Current mitigation activation: 0
#############################
Total reward: 72.15453303776846
24.268408969044685 seconds in game passed.
Action: tensor([[[4.4555e-03, 6.2519e-01],
         [2.3704e-03, 3.3264e-01],
         [1.4752e-03, 2.2655e-01],
         [3.3561e-04, 1.7231e-01]]])
agent 0 action: VehicleControl(throttle=0.365814, steer=0.003177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.15453303776846
24.293408969417214 seconds in game passed.
Action: tensor([[[4.4555e-03, 6.2519e-01],
         [2.3704e-03, 3.3264e-01],
         [1.4752e-03, 2.2655e-01],
         [3.3561e-04, 1.7231e-01]]])
agent 0 action: VehicleControl(throttle=0.367298, steer=0.003173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.15453303776846
24.318408969789743 seconds in game passed.
Action: tensor([[[4.4555e-03, 6.2519e-01],
         [2.3704e-03, 3.3264e-01],
         [1.4752e-03, 2.2655e-01],
         [3.3561e-04, 1.7231e-01]]])
agent 0 action: VehicleControl(throttle=0.369002, steer=0.003168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.15453303776846
+++++++++++++: 2.594187049605397
24.343408970162272 seconds in game passed.
At 24.343408970162272 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.7399e-03,  6.1559e-01],
         [-2.3054e-04,  3.2717e-01],
         [-6.2265e-04,  2.2332e-01],
         [-1.1088e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.470504, steer=0.000143, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.594187049605397
Current reward: 0.6169050030109386
Current mitigation activation: 0
#############################
Total reward: 72.7714380407794
24.3684089705348 seconds in game passed.
Action: tensor([[[ 1.7399e-03,  6.1559e-01],
         [-2.3054e-04,  3.2717e-01],
         [-6.2265e-04,  2.2332e-01],
         [-1.1088e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.463345, steer=0.000589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.7714380407794
24.39340897090733 seconds in game passed.
Action: tensor([[[ 1.7399e-03,  6.1559e-01],
         [-2.3054e-04,  3.2717e-01],
         [-6.2265e-04,  2.2332e-01],
         [-1.1088e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.466584, steer=0.000539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.7714380407794
24.41840897127986 seconds in game passed.
Action: tensor([[[ 1.7399e-03,  6.1559e-01],
         [-2.3054e-04,  3.2717e-01],
         [-6.2265e-04,  2.2332e-01],
         [-1.1088e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.469050, steer=0.000489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.7714380407794
+++++++++++++: 2.632677336649343
24.44340897165239 seconds in game passed.
At 24.44340897165239 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6170],
         [-0.0023,  0.3282],
         [-0.0024,  0.2236],
         [-0.0026,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.450153, steer=-0.002337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.632677336649343
Current reward: 0.6201597118987043
Current mitigation activation: 0
#############################
Total reward: 73.39159775267811
24.468408972024918 seconds in game passed.
Action: tensor([[[-0.0015,  0.6170],
         [-0.0023,  0.3282],
         [-0.0024,  0.2236],
         [-0.0026,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.454180, steer=-0.001930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.39159775267811
24.493408972397447 seconds in game passed.
Action: tensor([[[-0.0015,  0.6170],
         [-0.0023,  0.3282],
         [-0.0024,  0.2236],
         [-0.0026,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.455572, steer=-0.001985, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.39159775267811
24.518408972769976 seconds in game passed.
Action: tensor([[[-0.0015,  0.6170],
         [-0.0023,  0.3282],
         [-0.0024,  0.2236],
         [-0.0026,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.456741, steer=-0.002039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.39159775267811
+++++++++++++: 2.668010410201201
24.543408973142505 seconds in game passed.
At 24.543408973142505 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.6811e-04,  6.1445e-01],
         [-2.7486e-03,  3.2683e-01],
         [-3.2792e-03,  2.2238e-01],
         [-3.7051e-03,  1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.479345, steer=-0.002057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.668010410201201
Current reward: 0.6238200990911451
Current mitigation activation: 0
#############################
Total reward: 74.01541785176926
24.568408973515034 seconds in game passed.
Action: tensor([[[-5.6811e-04,  6.1445e-01],
         [-2.7486e-03,  3.2683e-01],
         [-3.2792e-03,  2.2238e-01],
         [-3.7051e-03,  1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.477330, steer=-0.002100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.01541785176926
24.593408973887563 seconds in game passed.
Action: tensor([[[-5.6811e-04,  6.1445e-01],
         [-2.7486e-03,  3.2683e-01],
         [-3.2792e-03,  2.2238e-01],
         [-3.7051e-03,  1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.477415, steer=-0.002139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.01541785176926
24.618408974260092 seconds in game passed.
Action: tensor([[[-5.6811e-04,  6.1445e-01],
         [-2.7486e-03,  3.2683e-01],
         [-3.2792e-03,  2.2238e-01],
         [-3.7051e-03,  1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.477140, steer=-0.002178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.01541785176926
+++++++++++++: 2.7004692042720864
24.64340897463262 seconds in game passed.
At 24.64340897463262 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.6146],
         [-0.0066,  0.3279],
         [-0.0072,  0.2229],
         [-0.0076,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.440371, steer=-0.006113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7004692042720864
Current reward: 0.627815853498298
Current mitigation activation: 0
#############################
Total reward: 74.64323370526756
24.66840897500515 seconds in game passed.
Action: tensor([[[-0.0034,  0.6146],
         [-0.0066,  0.3279],
         [-0.0072,  0.2229],
         [-0.0076,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.442739, steer=-0.005518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.64323370526756
24.69340897537768 seconds in game passed.
Action: tensor([[[-0.0034,  0.6146],
         [-0.0066,  0.3279],
         [-0.0072,  0.2229],
         [-0.0076,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.441237, steer=-0.005569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.64323370526756
24.718408975750208 seconds in game passed.
Action: tensor([[[-0.0034,  0.6146],
         [-0.0066,  0.3279],
         [-0.0072,  0.2229],
         [-0.0076,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.439861, steer=-0.005621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.64323370526756
+++++++++++++: 2.7309086432539393
24.743408976122737 seconds in game passed.
At 24.743408976122737 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6009],
         [-0.0022,  0.3246],
         [-0.0024,  0.2215],
         [-0.0029,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.412761, steer=-0.002029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7309086432539393
Current reward: 0.6320175858250161
Current mitigation activation: 0
#############################
Total reward: 75.27525129109257
24.768408976495266 seconds in game passed.
Action: tensor([[[-0.0022,  0.6009],
         [-0.0022,  0.3246],
         [-0.0024,  0.2215],
         [-0.0029,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.413724, steer=-0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.27525129109257
24.793408976867795 seconds in game passed.
Action: tensor([[[-0.0022,  0.6009],
         [-0.0022,  0.3246],
         [-0.0024,  0.2215],
         [-0.0029,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.412117, steer=-0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.27525129109257
24.818408977240324 seconds in game passed.
Action: tensor([[[-0.0022,  0.6009],
         [-0.0022,  0.3246],
         [-0.0024,  0.2215],
         [-0.0029,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.410819, steer=-0.002646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.27525129109257
+++++++++++++: 2.761588039949803
24.843408977612853 seconds in game passed.
At 24.843408977612853 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.4300e-04,  6.0429e-01],
         [ 4.3239e-04,  3.2559e-01],
         [ 4.5951e-04,  2.2209e-01],
         [-6.6616e-05,  1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.409712, steer=0.000019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.761588039949803
Current reward: 0.6361646445110514
Current mitigation activation: 0
#############################
Total reward: 75.91141593560363
24.868408977985382 seconds in game passed.
Action: tensor([[[-5.4300e-04,  6.0429e-01],
         [ 4.3239e-04,  3.2559e-01],
         [ 4.5951e-04,  2.2209e-01],
         [-6.6616e-05,  1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.409082, steer=-0.000383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.91141593560363
24.89340897835791 seconds in game passed.
Action: tensor([[[-5.4300e-04,  6.0429e-01],
         [ 4.3239e-04,  3.2559e-01],
         [ 4.5951e-04,  2.2209e-01],
         [-6.6616e-05,  1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.408615, steer=-0.000347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.91141593560363
24.91840897873044 seconds in game passed.
Action: tensor([[[-5.4300e-04,  6.0429e-01],
         [ 4.3239e-04,  3.2559e-01],
         [ 4.5951e-04,  2.2209e-01],
         [-6.6616e-05,  1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.408313, steer=-0.000310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.91141593560363
+++++++++++++: 2.7941652538476363
24.94340897910297 seconds in game passed.
At 24.94340897910297 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.6054],
         [0.0016, 0.3264],
         [0.0017, 0.2225],
         [0.0014, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.391845, steer=0.001281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7941652538476363
Current reward: 0.640089150042211
Current mitigation activation: 0
#############################
Total reward: 76.55150508564584
24.968408979475498 seconds in game passed.
Action: tensor([[[0.0012, 0.6054],
         [0.0016, 0.3264],
         [0.0017, 0.2225],
         [0.0014, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.393888, steer=0.001046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.55150508564584
24.993408979848027 seconds in game passed.
Action: tensor([[[0.0012, 0.6054],
         [0.0016, 0.3264],
         [0.0017, 0.2225],
         [0.0014, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.394313, steer=0.001072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.55150508564584
25.018408980220556 seconds in game passed.
Action: tensor([[[0.0012, 0.6054],
         [0.0016, 0.3264],
         [0.0017, 0.2225],
         [0.0014, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.394966, steer=0.001099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.55150508564584
+++++++++++++: 2.8283929568157506
25.043408980593085 seconds in game passed.
At 25.043408980593085 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.6038],
         [0.0029, 0.3254],
         [0.0029, 0.2229],
         [0.0023, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.414227, steer=0.002835, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8283929568157506
Current reward: 0.6438336802011889
Current mitigation activation: 0
#############################
Total reward: 77.19533876584703
25.068408980965614 seconds in game passed.
Action: tensor([[[0.0031, 0.6038],
         [0.0029, 0.3254],
         [0.0029, 0.2229],
         [0.0023, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.413760, steer=0.002593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.19533876584703
25.093408981338143 seconds in game passed.
Action: tensor([[[0.0031, 0.6038],
         [0.0029, 0.3254],
         [0.0029, 0.2229],
         [0.0023, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.415267, steer=0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.19533876584703
25.118408981710672 seconds in game passed.
Action: tensor([[[0.0031, 0.6038],
         [0.0029, 0.3254],
         [0.0029, 0.2229],
         [0.0023, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.416683, steer=0.002675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.19533876584703
+++++++++++++: 2.8640805255869006
25.1434089820832 seconds in game passed.
At 25.1434089820832 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6123],
         [0.0022, 0.3277],
         [0.0024, 0.2235],
         [0.0024, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.424237, steer=0.002220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8640805255869006
Current reward: 0.6474346950503816
Current mitigation activation: 0
#############################
Total reward: 77.8427734608974
25.16840898245573 seconds in game passed.
Action: tensor([[[0.0032, 0.6123],
         [0.0022, 0.3277],
         [0.0024, 0.2235],
         [0.0024, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.424915, steer=0.002319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.8427734608974
25.19340898282826 seconds in game passed.
Action: tensor([[[0.0032, 0.6123],
         [0.0022, 0.3277],
         [0.0024, 0.2235],
         [0.0024, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.426160, steer=0.002339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.8427734608974
25.21840898320079 seconds in game passed.
Action: tensor([[[0.0032, 0.6123],
         [0.0022, 0.3277],
         [0.0024, 0.2235],
         [0.0024, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.427276, steer=0.002358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.8427734608974
+++++++++++++: 2.899792727321321
25.243408983573318 seconds in game passed.
At 25.243408983573318 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.0922e-04,  6.2418e-01],
         [ 4.6179e-05,  3.2910e-01],
         [-5.3898e-05,  2.2335e-01],
         [-1.7415e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.499186, steer=-0.000213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.899792727321321
Current reward: 0.6510481982301458
Current mitigation activation: 0
#############################
Total reward: 78.49382165912755
25.268408983945847 seconds in game passed.
Action: tensor([[[ 8.0922e-04,  6.2418e-01],
         [ 4.6179e-05,  3.2910e-01],
         [-5.3898e-05,  2.2335e-01],
         [-1.7415e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.493561, steer=0.000178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.49382165912755
25.293408984318376 seconds in game passed.
Action: tensor([[[ 8.0922e-04,  6.2418e-01],
         [ 4.6179e-05,  3.2910e-01],
         [-5.3898e-05,  2.2335e-01],
         [-1.7415e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.495118, steer=0.000145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.49382165912755
25.318408984690905 seconds in game passed.
Action: tensor([[[ 8.0922e-04,  6.2418e-01],
         [ 4.6179e-05,  3.2910e-01],
         [-5.3898e-05,  2.2335e-01],
         [-1.7415e-04,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.495958, steer=0.000112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.49382165912755
+++++++++++++: 2.934307497784691
25.343408985063434 seconds in game passed.
At 25.343408985063434 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6102],
         [-0.0033,  0.3251],
         [-0.0040,  0.2215],
         [-0.0045,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.497793, steer=-0.003227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.934307497784691
Current reward: 0.6547812873748958
Current mitigation activation: 0
#############################
Total reward: 79.14860294650245
25.368408985435963 seconds in game passed.
Action: tensor([[[-0.0013,  0.6102],
         [-0.0033,  0.3251],
         [-0.0040,  0.2215],
         [-0.0045,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.496338, steer=-0.002712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.14860294650245
25.39340898580849 seconds in game passed.
Action: tensor([[[-0.0013,  0.6102],
         [-0.0033,  0.3251],
         [-0.0040,  0.2215],
         [-0.0045,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.494782, steer=-0.002748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.14860294650245
25.41840898618102 seconds in game passed.
Action: tensor([[[-0.0013,  0.6102],
         [-0.0033,  0.3251],
         [-0.0040,  0.2215],
         [-0.0045,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.492876, steer=-0.002784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.14860294650245
+++++++++++++: 2.964883481837168
25.44340898655355 seconds in game passed.
At 25.44340898655355 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0047,  0.6155],
         [-0.0091,  0.3270],
         [-0.0098,  0.2225],
         [-0.0100,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.475472, steer=-0.008417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.964883481837168
Current reward: 0.6588454210464936
Current mitigation activation: 0
#############################
Total reward: 79.80744836754894
25.46840898692608 seconds in game passed.
Action: tensor([[[-0.0047,  0.6155],
         [-0.0091,  0.3270],
         [-0.0098,  0.2225],
         [-0.0100,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.474795, steer=-0.007554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.80744836754894
25.493408987298608 seconds in game passed.
Action: tensor([[[-0.0047,  0.6155],
         [-0.0091,  0.3270],
         [-0.0098,  0.2225],
         [-0.0100,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.472437, steer=-0.007619, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.80744836754894
25.518408987671137 seconds in game passed.
Action: tensor([[[-0.0047,  0.6155],
         [-0.0091,  0.3270],
         [-0.0098,  0.2225],
         [-0.0100,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.470041, steer=-0.007685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.80744836754894
+++++++++++++: 2.9923673147848007
25.543408988043666 seconds in game passed.
At 25.543408988043666 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0038,  0.6157],
         [-0.0059,  0.3269],
         [-0.0063,  0.2224],
         [-0.0067,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.474071, steer=-0.004999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9923673147848007
Current reward: 0.6626606915837178
Current mitigation activation: 0
#############################
Total reward: 80.47010905913267
25.568408988416195 seconds in game passed.
Action: tensor([[[-0.0038,  0.6157],
         [-0.0059,  0.3269],
         [-0.0063,  0.2224],
         [-0.0067,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.470823, steer=-0.005490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.47010905913267
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 18:59:50 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:00:37 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 47.0s               │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 24.08s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.512               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 80.47, average_reward: 80.47010905913267 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00001/fi_lead_slowdown_data
