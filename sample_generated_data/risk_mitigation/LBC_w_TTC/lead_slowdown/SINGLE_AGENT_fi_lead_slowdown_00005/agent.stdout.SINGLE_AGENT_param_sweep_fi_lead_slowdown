New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190418-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190418-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190418-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190418-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190418-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_logs/routes_fi_route_highway-1127_190418-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 35.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 35}
1.5603705085814 seconds in game passed.
Action: tensor([[[0.0034, 0.5921],
         [0.0024, 0.3305],
         [0.0022, 0.2342],
         [0.0015, 0.1816]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.585370508953929 seconds in game passed.
Action: tensor([[[0.0034, 0.5921],
         [0.0024, 0.3305],
         [0.0022, 0.2342],
         [0.0015, 0.1816]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.610370509326458 seconds in game passed.
Action: tensor([[[0.0034, 0.5921],
         [0.0024, 0.3305],
         [0.0022, 0.2342],
         [0.0015, 0.1816]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.635370509698987 seconds in game passed.
Action: tensor([[[0.0034, 0.5921],
         [0.0024, 0.3305],
         [0.0022, 0.2342],
         [0.0015, 0.1816]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002697, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.660370510071516 seconds in game passed.
Action: tensor([[[0.0034, 0.5921],
         [0.0024, 0.3305],
         [0.0022, 0.2342],
         [0.0015, 0.1816]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002729, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.685370510444045 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0055, 0.5911],
         [0.0028, 0.3229],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.710370510816574 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0028, 0.3229],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003768, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7353705111891031 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0028, 0.3229],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003812, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7603705115616322 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0028, 0.3229],
         [0.0027, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7853705119341612 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.8103705123066902 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8353705126792192 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8603705130517483 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8853705134242773 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9103705137968063 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9353705141693354 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9603705145418644 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0008, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9853705149143934 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0103705152869225 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0353705156594515 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0603705160319805 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0853705164045095 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4525e-03, 5.9055e-01],
         [1.3269e-03, 3.2231e-01],
         [1.1017e-03, 2.2210e-01],
         [5.6275e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.1103705167770386 seconds in game passed.
Action: tensor([[[2.4525e-03, 5.9055e-01],
         [1.3269e-03, 3.2231e-01],
         [1.1017e-03, 2.2210e-01],
         [5.6275e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1353705171495676 seconds in game passed.
Action: tensor([[[2.4525e-03, 5.9055e-01],
         [1.3269e-03, 3.2231e-01],
         [1.1017e-03, 2.2210e-01],
         [5.6275e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1603705175220966 seconds in game passed.
Action: tensor([[[2.4525e-03, 5.9055e-01],
         [1.3269e-03, 3.2231e-01],
         [1.1017e-03, 2.2210e-01],
         [5.6275e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.1853705178946257 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.2103705182671547 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002473, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2353705186396837 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2603705190122128 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.285370519384742 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.310370519757271 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3353705201298 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.360370520502329 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.385370520874858 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.410370521247387 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.435370521619916 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.460370521992445 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.485370522364974 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.510370522737503 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002775, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.535370523110032 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.560370523482561 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.58537052385509 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.610370524227619 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.635370524600148 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6603705249726772 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6853705253452063 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.7103705257177353 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7353705260902643 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7603705264627934 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7853705268353224 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.8103705272078514 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8353705275803804 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8603705279529095 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.8853705283254385 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.9103705286979675 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9353705290704966 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9603705294430256 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.9853705298155546 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.0103705301880836 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0353705305606127 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0603705309331417 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.0853705313056707 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.1103705316781998 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.135370532050729 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.160370532423258 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.185370532795787 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.210370533168316 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.235370533540845 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.260370533913374 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.285370534285903 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.310370534658432 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.335370535030961 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.36037053540349 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.385370535776019 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.410370536148548 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.435370536521077 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.460370536893606 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.485370537266135 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5103705376386642 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5353705380111933 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5603705383837223 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5853705387562513 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6103705391287804 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6353705395013094 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6603705398738384 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6853705402463675 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7103705406188965 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7353705409914255 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7603705413639545 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7853705417364836 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8103705421090126 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8353705424815416 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8603705428540707 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8853705432265997 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.9103705435991287 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9353705439716578 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.960370544344187 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.985370544716716 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
4.010370545089245 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.035370545461774 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.060370545834303 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.085370546206832 seconds in game passed.
At 4.085370546206832 seconds, saving state-action tuples.
Action: tensor([[[1.4114e-03, 5.8603e-01],
         [1.1374e-03, 3.2065e-01],
         [1.0057e-03, 2.2099e-01],
         [3.5582e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.110370546579361 seconds in game passed.
Action: tensor([[[1.4114e-03, 5.8603e-01],
         [1.1374e-03, 3.2065e-01],
         [1.0057e-03, 2.2099e-01],
         [3.5582e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.13537054695189 seconds in game passed.
Action: tensor([[[1.4114e-03, 5.8603e-01],
         [1.1374e-03, 3.2065e-01],
         [1.0057e-03, 2.2099e-01],
         [3.5582e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.160370547324419 seconds in game passed.
Action: tensor([[[1.4114e-03, 5.8603e-01],
         [1.1374e-03, 3.2065e-01],
         [1.0057e-03, 2.2099e-01],
         [3.5582e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.883738821806649
4.185370547696948 seconds in game passed.
At 4.185370547696948 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2207],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.65612528475237
4.210370548069477 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2207],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
4.235370548442006 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2207],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 0.65612528475237
4.260370548814535 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2207],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
+++++++++++++: 8.843383999601484
4.285370549187064 seconds in game passed.
At 4.285370549187064 seconds, saving state-action tuples.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383999601484
Current reward: 0.49259322239340864
Current mitigation activation: 0
#############################
Total reward: 1.1487185071457786
4.310370549559593 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.335370549932122 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.360370550304651 seconds in game passed.
Action: tensor([[[0.0022, 0.5818],
         [0.0023, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
+++++++++++++: 7.228541501275198
4.38537055067718 seconds in game passed.
At 4.38537055067718 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228541501275198
Current reward: 0.5118171195076244
Current mitigation activation: 0
#############################
Total reward: 1.660535626653403
4.410370551049709 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003551, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535626653403
4.435370551422238 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535626653403
4.460370551794767 seconds in game passed.
Action: tensor([[[0.0028, 0.5862],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.660535626653403
+++++++++++++: 6.2159331184388575
4.485370552167296 seconds in game passed.
At 4.485370552167296 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5899],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.2159331184388575
Current reward: 0.5264941465786098
Current mitigation activation: 0
#############################
Total reward: 2.187029773232013
4.510370552539825 seconds in game passed.
Action: tensor([[[0.0021, 0.5899],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029773232013
4.5353705529123545 seconds in game passed.
Action: tensor([[[0.0021, 0.5899],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029773232013
4.5603705532848835 seconds in game passed.
Action: tensor([[[0.0021, 0.5899],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.187029773232013
+++++++++++++: 5.508365853638963
4.5853705536574125 seconds in game passed.
At 4.5853705536574125 seconds, saving state-action tuples.
Action: tensor([[[-8.4914e-05,  5.8867e-01],
         [ 1.6838e-04,  3.2201e-01],
         [ 2.8555e-04,  2.2121e-01],
         [-9.4429e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508365853638963
Current reward: 0.537623498978236
Current mitigation activation: 0
#############################
Total reward: 2.724653272210249
4.610370554029942 seconds in game passed.
Action: tensor([[[-8.4914e-05,  5.8867e-01],
         [ 1.6838e-04,  3.2201e-01],
         [ 2.8555e-04,  2.2121e-01],
         [-9.4429e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000900, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653272210249
4.635370554402471 seconds in game passed.
Action: tensor([[[-8.4914e-05,  5.8867e-01],
         [ 1.6838e-04,  3.2201e-01],
         [ 2.8555e-04,  2.2121e-01],
         [-9.4429e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653272210249
4.660370554775 seconds in game passed.
Action: tensor([[[-8.4914e-05,  5.8867e-01],
         [ 1.6838e-04,  3.2201e-01],
         [ 2.8555e-04,  2.2121e-01],
         [-9.4429e-05,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000864, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653272210249
+++++++++++++: 4.9761342678197185
4.685370555147529 seconds in game passed.
At 4.685370555147529 seconds, saving state-action tuples.
Action: tensor([[[ 2.1727e-04,  5.8919e-01],
         [-3.7898e-04,  3.2137e-01],
         [-2.9469e-04,  2.2103e-01],
         [-4.5846e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.9761342678197185
Current reward: 0.5459292659195056
Current mitigation activation: 0
#############################
Total reward: 3.2705825381297546
4.710370555520058 seconds in game passed.
Action: tensor([[[ 2.1727e-04,  5.8919e-01],
         [-3.7898e-04,  3.2137e-01],
         [-2.9469e-04,  2.2103e-01],
         [-4.5846e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000589, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825381297546
4.735370555892587 seconds in game passed.
Action: tensor([[[ 2.1727e-04,  5.8919e-01],
         [-3.7898e-04,  3.2137e-01],
         [-2.9469e-04,  2.2103e-01],
         [-4.5846e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825381297546
4.760370556265116 seconds in game passed.
Action: tensor([[[ 2.1727e-04,  5.8919e-01],
         [-3.7898e-04,  3.2137e-01],
         [-2.9469e-04,  2.2103e-01],
         [-4.5846e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825381297546
+++++++++++++: 4.552586993339842
4.785370556637645 seconds in game passed.
At 4.785370556637645 seconds, saving state-action tuples.
Action: tensor([[[-3.0077e-04,  5.9098e-01],
         [-9.7933e-04,  3.2156e-01],
         [-8.6482e-04,  2.2108e-01],
         [-1.0094e-03,  1.6746e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552586993339842
Current reward: 0.5519989037830756
Current mitigation activation: 0
#############################
Total reward: 3.8225814419128303
4.810370557010174 seconds in game passed.
Action: tensor([[[-3.0077e-04,  5.9098e-01],
         [-9.7933e-04,  3.2156e-01],
         [-8.6482e-04,  2.2108e-01],
         [-1.0094e-03,  1.6746e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225814419128303
4.835370557382703 seconds in game passed.
Action: tensor([[[-3.0077e-04,  5.9098e-01],
         [-9.7933e-04,  3.2156e-01],
         [-8.6482e-04,  2.2108e-01],
         [-1.0094e-03,  1.6746e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225814419128303
4.860370557755232 seconds in game passed.
Action: tensor([[[-3.0077e-04,  5.9098e-01],
         [-9.7933e-04,  3.2156e-01],
         [-8.6482e-04,  2.2108e-01],
         [-1.0094e-03,  1.6746e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225814419128303
+++++++++++++: 4.199612167061068
4.885370558127761 seconds in game passed.
At 4.885370558127761 seconds, saving state-action tuples.
Action: tensor([[[ 5.0288e-04,  5.9006e-01],
         [-5.6238e-04,  3.2161e-01],
         [-4.3523e-04,  2.2126e-01],
         [-4.6320e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199612167061068
Current reward: 0.5563326538922417
Current mitigation activation: 0
#############################
Total reward: 4.378914095805072
4.91037055850029 seconds in game passed.
Action: tensor([[[ 5.0288e-04,  5.9006e-01],
         [-5.6238e-04,  3.2161e-01],
         [-4.3523e-04,  2.2126e-01],
         [-4.6320e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914095805072
4.935370558872819 seconds in game passed.
Action: tensor([[[ 5.0288e-04,  5.9006e-01],
         [-5.6238e-04,  3.2161e-01],
         [-4.3523e-04,  2.2126e-01],
         [-4.6320e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914095805072
4.960370559245348 seconds in game passed.
Action: tensor([[[ 5.0288e-04,  5.9006e-01],
         [-5.6238e-04,  3.2161e-01],
         [-4.3523e-04,  2.2126e-01],
         [-4.6320e-04,  1.6779e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914095805072
+++++++++++++: 3.894759667354877
4.985370559617877 seconds in game passed.
At 4.985370559617877 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.894759667354877
Current reward: 0.5593082095049673
Current mitigation activation: 0
#############################
Total reward: 4.93822230531004
5.010370559990406 seconds in game passed.
Action: tensor([[[0.0017, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.93822230531004
5.035370560362935 seconds in game passed.
Action: tensor([[[0.0017, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.93822230531004
5.060370560735464 seconds in game passed.
Action: tensor([[[0.0017, 0.5881],
         [0.0007, 0.3215],
         [0.0010, 0.2218],
         [0.0012, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.93822230531004
+++++++++++++: 3.6246722565637404
5.085370561107993 seconds in game passed.
At 5.085370561107993 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3012e-03, 5.8977e-01],
         [1.0638e-03, 3.2202e-01],
         [9.2899e-04, 2.2276e-01],
         [5.7134e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6246722565637404
Current reward: 0.5611771108271344
Current mitigation activation: 0
#############################
Total reward: 5.499399416137175
5.110370561480522 seconds in game passed.
Action: tensor([[[1.3012e-03, 5.8977e-01],
         [1.0638e-03, 3.2202e-01],
         [9.2899e-04, 2.2276e-01],
         [5.7134e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399416137175
5.135370561853051 seconds in game passed.
Action: tensor([[[1.3012e-03, 5.8977e-01],
         [1.0638e-03, 3.2202e-01],
         [9.2899e-04, 2.2276e-01],
         [5.7134e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399416137175
5.16037056222558 seconds in game passed.
Action: tensor([[[1.3012e-03, 5.8977e-01],
         [1.0638e-03, 3.2202e-01],
         [9.2899e-04, 2.2276e-01],
         [5.7134e-04, 1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.499399416137175
+++++++++++++: 3.380483513702236
5.185370562598109 seconds in game passed.
At 5.185370562598109 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.380483513702236
Current reward: 0.5621374500618734
Current mitigation activation: 0
#############################
Total reward: 6.061536866199049
5.210370562970638 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061536866199049
5.235370563343167 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061536866199049
5.260370563715696 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3201],
         [0.0021, 0.2211],
         [0.0018, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061536866199049
+++++++++++++: 3.1565683521747494
5.285370564088225 seconds in game passed.
At 5.285370564088225 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1565683521747494
Current reward: 0.5623125899999608
Current mitigation activation: 0
#############################
Total reward: 6.623849456199009
5.310370564460754 seconds in game passed.
Action: tensor([[[0.0025, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849456199009
5.335370564833283 seconds in game passed.
Action: tensor([[[0.0025, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849456199009
5.3603705652058125 seconds in game passed.
Action: tensor([[[0.0025, 0.5945],
         [0.0020, 0.3221],
         [0.0019, 0.2215],
         [0.0015, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849456199009
+++++++++++++: 2.9489487536000487
5.3853705655783415 seconds in game passed.
At 5.3853705655783415 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9489487536000487
Current reward: 0.5617967759647733
Current mitigation activation: 0
#############################
Total reward: 7.185646232163783
5.4103705659508705 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646232163783
5.4353705663233995 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646232163783
5.460370566695929 seconds in game passed.
Action: tensor([[[0.0023, 0.5892],
         [0.0028, 0.3214],
         [0.0028, 0.2215],
         [0.0024, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185646232163783
+++++++++++++: 2.788063850207496
5.485370567068458 seconds in game passed.
At 5.485370567068458 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.0590e-04,  5.8799e-01],
         [ 1.2445e-04,  3.2087e-01],
         [-3.4019e-05,  2.2103e-01],
         [-3.4779e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.788063850207496
Current reward: 0.5575288921122173
Current mitigation activation: 0
#############################
Total reward: 7.743175124276
5.510370567440987 seconds in game passed.
Action: tensor([[[ 9.0590e-04,  5.8799e-01],
         [ 1.2445e-04,  3.2087e-01],
         [-3.4019e-05,  2.2103e-01],
         [-3.4779e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175124276
5.535370567813516 seconds in game passed.
Action: tensor([[[ 9.0590e-04,  5.8799e-01],
         [ 1.2445e-04,  3.2087e-01],
         [-3.4019e-05,  2.2103e-01],
         [-3.4779e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175124276
5.560370568186045 seconds in game passed.
Action: tensor([[[ 9.0590e-04,  5.8799e-01],
         [ 1.2445e-04,  3.2087e-01],
         [-3.4019e-05,  2.2103e-01],
         [-3.4779e-04,  1.6778e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175124276
+++++++++++++: 2.691321238669932
5.585370568558574 seconds in game passed.
At 5.585370568558574 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5936],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.691321238669932
Current reward: 0.5472018727786123
Current mitigation activation: 0
#############################
Total reward: 8.290376997054612
5.610370568931103 seconds in game passed.
Action: tensor([[[-0.0010,  0.5936],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290376997054612
5.635370569303632 seconds in game passed.
Action: tensor([[[-0.0010,  0.5936],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290376997054612
5.660370569676161 seconds in game passed.
Action: tensor([[[-0.0010,  0.5936],
         [-0.0021,  0.3226],
         [-0.0025,  0.2216],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290376997054612
+++++++++++++: 2.59502519063293
5.68537057004869 seconds in game passed.
At 5.68537057004869 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.59502519063293
Current reward: 0.5368278727505822
Current mitigation activation: 0
#############################
Total reward: 8.827204869805193
5.710370570421219 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204869805193
5.735370570793748 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204869805193
5.760370571166277 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0045,  0.2211],
         [-0.0050,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.827204869805193
+++++++++++++: 2.498632145404135
5.785370571538806 seconds in game passed.
At 5.785370571538806 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.498632145404135
Current reward: 0.5264623664862362
Current mitigation activation: 0
#############################
Total reward: 9.353667236291429
5.810370571911335 seconds in game passed.
Action: tensor([[[-0.0027,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667236291429
5.835370572283864 seconds in game passed.
Action: tensor([[[-0.0027,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667236291429
5.860370572656393 seconds in game passed.
Action: tensor([[[-0.0027,  0.5956],
         [-0.0045,  0.3232],
         [-0.0051,  0.2218],
         [-0.0054,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.353667236291429
+++++++++++++: 2.4021937534372073
5.885370573028922 seconds in game passed.
At 5.885370573028922 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.3984e-04,  5.9067e-01],
         [-6.9642e-04,  3.2177e-01],
         [-7.1968e-04,  2.2147e-01],
         [-9.2603e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4021937534372073
Current reward: 0.5161007324800869
Current mitigation activation: 0
#############################
Total reward: 9.869767968771516
5.910370573401451 seconds in game passed.
Action: tensor([[[-1.3984e-04,  5.9067e-01],
         [-6.9642e-04,  3.2177e-01],
         [-7.1968e-04,  2.2147e-01],
         [-9.2603e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869767968771516
5.93537057377398 seconds in game passed.
Action: tensor([[[-1.3984e-04,  5.9067e-01],
         [-6.9642e-04,  3.2177e-01],
         [-7.1968e-04,  2.2147e-01],
         [-9.2603e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869767968771516
5.960370574146509 seconds in game passed.
Action: tensor([[[-1.3984e-04,  5.9067e-01],
         [-6.9642e-04,  3.2177e-01],
         [-7.1968e-04,  2.2147e-01],
         [-9.2603e-04,  1.6816e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869767968771516
+++++++++++++: 2.2737327152893694
5.985370574519038 seconds in game passed.
At 5.985370574519038 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2226e-05,  5.9319e-01],
         [ 2.3253e-04,  3.2264e-01],
         [ 2.8209e-04,  2.2193e-01],
         [-8.9206e-05,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2737327152893694
Current reward: 0.5093357010253898
Current mitigation activation: 0
#############################
Total reward: 10.379103669796905
6.010370574891567 seconds in game passed.
Action: tensor([[[ 1.2226e-05,  5.9319e-01],
         [ 2.3253e-04,  3.2264e-01],
         [ 2.8209e-04,  2.2193e-01],
         [-8.9206e-05,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000128, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103669796905
6.035370575264096 seconds in game passed.
Action: tensor([[[ 1.2226e-05,  5.9319e-01],
         [ 2.3253e-04,  3.2264e-01],
         [ 2.8209e-04,  2.2193e-01],
         [-8.9206e-05,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103669796905
6.060370575636625 seconds in game passed.
Action: tensor([[[ 1.2226e-05,  5.9319e-01],
         [ 2.3253e-04,  3.2264e-01],
         [ 2.8209e-04,  2.2193e-01],
         [-8.9206e-05,  1.6849e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379103669796905
+++++++++++++: 2.0694028606908943
6.085370576009154 seconds in game passed.
At 6.085370576009154 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0694028606908943
Current reward: 0.5122396814683376
Current mitigation activation: 0
#############################
Total reward: 10.891343351265242
6.110370576381683 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.873344, steer=0.003257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343351265242
6.135370576754212 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.820505, steer=0.003284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343351265242
6.160370577126741 seconds in game passed.
Action: tensor([[[0.0031, 0.5972],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.768839, steer=0.003311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.891343351265242
+++++++++++++: 1.8865374124674632
6.18537057749927 seconds in game passed.
At 6.18537057749927 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6206],
         [0.0024, 0.3397],
         [0.0020, 0.2339],
         [0.0008, 0.1789]]])
agent 0 action: VehicleControl(throttle=0.474115, steer=0.002003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865374124674632
Current reward: 0.5134808121820353
Current mitigation activation: 0
#############################
Total reward: 11.404824163447277
6.2103705778717995 seconds in game passed.
Action: tensor([[[0.0020, 0.6206],
         [0.0024, 0.3397],
         [0.0020, 0.2339],
         [0.0008, 0.1789]]])
agent 0 action: VehicleControl(throttle=0.448292, steer=0.002225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824163447277
6.2353705782443285 seconds in game passed.
Action: tensor([[[0.0020, 0.6206],
         [0.0024, 0.3397],
         [0.0020, 0.2339],
         [0.0008, 0.1789]]])
agent 0 action: VehicleControl(throttle=0.398895, steer=0.002228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824163447277
6.2603705786168575 seconds in game passed.
Action: tensor([[[0.0020, 0.6206],
         [0.0024, 0.3397],
         [0.0020, 0.2339],
         [0.0008, 0.1789]]])
agent 0 action: VehicleControl(throttle=0.362734, steer=0.002231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404824163447277
+++++++++++++: 1.7242658647252178
6.285370578989387 seconds in game passed.
At 6.285370578989387 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.1855e-04,  6.3441e-01],
         [ 6.0163e-05,  3.4355e-01],
         [-6.4408e-04,  2.3573e-01],
         [-1.7491e-03,  1.8010e-01]]])
agent 0 action: VehicleControl(throttle=0.352589, steer=-0.000081, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7242658647252178
Current reward: 0.5125421304118227
Current mitigation activation: 0
#############################
Total reward: 11.9173662938591
6.310370579361916 seconds in game passed.
Action: tensor([[[ 6.1855e-04,  6.3441e-01],
         [ 6.0163e-05,  3.4355e-01],
         [-6.4408e-04,  2.3573e-01],
         [-1.7491e-03,  1.8010e-01]]])
agent 0 action: VehicleControl(throttle=0.339964, steer=0.000278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.9173662938591
6.335370579734445 seconds in game passed.
Action: tensor([[[ 6.1855e-04,  6.3441e-01],
         [ 6.0163e-05,  3.4355e-01],
         [-6.4408e-04,  2.3573e-01],
         [-1.7491e-03,  1.8010e-01]]])
agent 0 action: VehicleControl(throttle=0.327756, steer=0.000256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.9173662938591
6.360370580106974 seconds in game passed.
Action: tensor([[[ 6.1855e-04,  6.3441e-01],
         [ 6.0163e-05,  3.4355e-01],
         [-6.4408e-04,  2.3573e-01],
         [-1.7491e-03,  1.8010e-01]]])
agent 0 action: VehicleControl(throttle=0.315962, steer=0.000233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.9173662938591
+++++++++++++: 1.5887564250037483
6.385370580479503 seconds in game passed.
At 6.385370580479503 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0013,  0.6538],
         [-0.0007,  0.3520],
         [-0.0018,  0.2414],
         [-0.0030,  0.1842]]])
agent 0 action: VehicleControl(throttle=0.304961, steer=-0.000047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5887564250037483
Current reward: 0.5075722423644665
Current mitigation activation: 0
#############################
Total reward: 12.424938536223566
6.410370580852032 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6538],
         [-0.0007,  0.3520],
         [-0.0018,  0.2414],
         [-0.0030,  0.1842]]])
agent 0 action: VehicleControl(throttle=0.294369, steer=-0.000036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424938536223566
6.435370581224561 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6538],
         [-0.0007,  0.3520],
         [-0.0018,  0.2414],
         [-0.0030,  0.1842]]])
agent 0 action: VehicleControl(throttle=0.283730, steer=-0.000066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424938536223566
6.46037058159709 seconds in game passed.
Action: tensor([[[ 0.0013,  0.6538],
         [-0.0007,  0.3520],
         [-0.0018,  0.2414],
         [-0.0030,  0.1842]]])
agent 0 action: VehicleControl(throttle=0.273066, steer=-0.000096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424938536223566
+++++++++++++: 1.4774795865691823
6.485370581969619 seconds in game passed.
At 6.485370581969619 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.6669],
         [-0.0049,  0.3560],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.262304, steer=-0.004468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4774795865691823
Current reward: 0.49817667390848364
Current mitigation activation: 0
#############################
Total reward: 12.92311521013205
6.510370582342148 seconds in game passed.
Action: tensor([[[-0.0016,  0.6669],
         [-0.0049,  0.3560],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.251523, steer=-0.003797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92311521013205
6.535370582714677 seconds in game passed.
Action: tensor([[[-0.0016,  0.6669],
         [-0.0049,  0.3560],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.240723, steer=-0.003847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92311521013205
6.560370583087206 seconds in game passed.
Action: tensor([[[-0.0016,  0.6669],
         [-0.0049,  0.3560],
         [-0.0063,  0.2424],
         [-0.0072,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.229905, steer=-0.003896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92311521013205
+++++++++++++: 1.3812572526693692
6.585370583459735 seconds in game passed.
At 6.585370583459735 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.7473e-04,  6.8409e-01],
         [-4.1524e-03,  3.6616e-01],
         [-5.9122e-03,  2.5052e-01],
         [-7.2181e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.219119, steer=-0.002845, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3812572526693692
Current reward: 0.4856694033941144
Current mitigation activation: 0
#############################
Total reward: 13.408784613526164
6.610370583832264 seconds in game passed.
Action: tensor([[[-3.7473e-04,  6.8409e-01],
         [-4.1524e-03,  3.6616e-01],
         [-5.9122e-03,  2.5052e-01],
         [-7.2181e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.208315, steer=-0.003036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408784613526164
6.635370584204793 seconds in game passed.
Action: tensor([[[-3.7473e-04,  6.8409e-01],
         [-4.1524e-03,  3.6616e-01],
         [-5.9122e-03,  2.5052e-01],
         [-7.2181e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.197492, steer=-0.003050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408784613526164
6.660370584577322 seconds in game passed.
Action: tensor([[[-3.7473e-04,  6.8409e-01],
         [-4.1524e-03,  3.6616e-01],
         [-5.9122e-03,  2.5052e-01],
         [-7.2181e-03,  1.9080e-01]]])
agent 0 action: VehicleControl(throttle=0.186651, steer=-0.003064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408784613526164
+++++++++++++: 1.293868592391219
6.685370584949851 seconds in game passed.
At 6.685370584949851 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.7321e-04,  1.0000e+00],
         [-4.7462e-03,  1.0000e+00],
         [-5.9608e-03,  1.0000e+00],
         [-6.5124e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003064, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.293868592391219
Current reward: 0.4711595359655271
Current mitigation activation: 1
#############################
Total reward: 13.87994414949169
6.71037058532238 seconds in game passed.
Action: tensor([[[-3.7321e-04,  1.0000e+00],
         [-4.7462e-03,  1.0000e+00],
         [-5.9608e-03,  1.0000e+00],
         [-6.5124e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003058, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87994414949169
6.735370585694909 seconds in game passed.
Action: tensor([[[-3.7321e-04,  1.0000e+00],
         [-4.7462e-03,  1.0000e+00],
         [-5.9608e-03,  1.0000e+00],
         [-6.5124e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003053, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87994414949169
6.760370586067438 seconds in game passed.
Action: tensor([[[-3.7321e-04,  1.0000e+00],
         [-4.7462e-03,  1.0000e+00],
         [-5.9608e-03,  1.0000e+00],
         [-6.5124e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003048, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87994414949169
+++++++++++++: 1.2141399241050332
6.785370586439967 seconds in game passed.
At 6.785370586439967 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000808, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2141399241050332
Current reward: 0.4548062908678345
Current mitigation activation: 1
#############################
Total reward: 14.334750440359525
6.810370586812496 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001141, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334750440359525
6.835370587185025 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001106, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334750440359525
6.860370587557554 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0054,  1.0000],
         [-0.0059,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001072, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334750440359525
+++++++++++++: 1.1613156550836892
6.885370587930083 seconds in game passed.
At 6.885370587930083 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.4458e-03,  1.0000e+00],
         [ 6.1614e-04,  1.0000e+00],
         [-1.6123e-03,  1.0000e+00],
         [-1.6032e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005721, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1613156550836892
Current reward: 0.43200299755367433
Current mitigation activation: 1
#############################
Total reward: 14.766753437913199
6.910370588302612 seconds in game passed.
Action: tensor([[[ 8.4458e-03,  1.0000e+00],
         [ 6.1614e-04,  1.0000e+00],
         [-1.6123e-03,  1.0000e+00],
         [-1.6032e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004665, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766753437913199
6.935370588675141 seconds in game passed.
Action: tensor([[[ 8.4458e-03,  1.0000e+00],
         [ 6.1614e-04,  1.0000e+00],
         [-1.6123e-03,  1.0000e+00],
         [-1.6032e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004730, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766753437913199
6.96037058904767 seconds in game passed.
Action: tensor([[[ 8.4458e-03,  1.0000e+00],
         [ 6.1614e-04,  1.0000e+00],
         [-1.6123e-03,  1.0000e+00],
         [-1.6032e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004796, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766753437913199
+++++++++++++: 1.1426741337075914
6.985370589420199 seconds in game passed.
At 6.985370589420199 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0147,  1.0000],
         [-0.0045,  1.0000],
         [-0.0063,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013094, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1426741337075914
Current reward: 0.4018192799964798
Current mitigation activation: 1
#############################
Total reward: 15.168572717909678
7.010370589792728 seconds in game passed.
Action: tensor([[[-0.0147,  1.0000],
         [-0.0045,  1.0000],
         [-0.0063,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010261, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168572717909678
7.0353705901652575 seconds in game passed.
Action: tensor([[[-0.0147,  1.0000],
         [-0.0045,  1.0000],
         [-0.0063,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010388, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168572717909678
7.0603705905377865 seconds in game passed.
Action: tensor([[[-0.0147,  1.0000],
         [-0.0045,  1.0000],
         [-0.0063,  1.0000],
         [-0.0061,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010516, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168572717909678
+++++++++++++: 1.1445738600073803
7.0853705909103155 seconds in game passed.
At 7.0853705909103155 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0124,  1.0000],
         [-0.0066,  1.0000],
         [-0.0077,  1.0000],
         [-0.0071,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010583, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1445738600073803
Current reward: 0.36909480738607603
Current mitigation activation: 1
#############################
Total reward: 15.537667525295754
7.1103705912828445 seconds in game passed.
Action: tensor([[[-0.0124,  1.0000],
         [-0.0066,  1.0000],
         [-0.0077,  1.0000],
         [-0.0071,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010765, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537667525295754
7.135370591655374 seconds in game passed.
Action: tensor([[[-0.0124,  1.0000],
         [-0.0066,  1.0000],
         [-0.0077,  1.0000],
         [-0.0071,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010930, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537667525295754
7.160370592027903 seconds in game passed.
Action: tensor([[[-0.0124,  1.0000],
         [-0.0066,  1.0000],
         [-0.0077,  1.0000],
         [-0.0071,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011095, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537667525295754
+++++++++++++: 1.164140528222694
7.185370592400432 seconds in game passed.
At 7.185370592400432 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0176,  1.0000],
         [-0.0118,  1.0000],
         [-0.0087,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017858, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.164140528222694
Current reward: 0.3358316065603345
Current mitigation activation: 1
#############################
Total reward: 15.87349913185609
7.210370592772961 seconds in game passed.
Action: tensor([[[-0.0176,  1.0000],
         [-0.0118,  1.0000],
         [-0.0087,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016987, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.87349913185609
7.23537059314549 seconds in game passed.
Action: tensor([[[-0.0176,  1.0000],
         [-0.0118,  1.0000],
         [-0.0087,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017206, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.87349913185609
7.260370593518019 seconds in game passed.
Action: tensor([[[-0.0176,  1.0000],
         [-0.0118,  1.0000],
         [-0.0087,  1.0000],
         [-0.0045,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.017426, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.87349913185609
+++++++++++++: 1.2039256242940568
7.285370593890548 seconds in game passed.
At 7.285370593890548 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0064,  1.0000],
         [-0.0123,  1.0000],
         [-0.0181,  1.0000],
         [-0.0207,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010797, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2039256242940568
Current reward: 0.3028358419474031
Current mitigation activation: 1
#############################
Total reward: 16.176334973803492
7.310370594263077 seconds in game passed.
Action: tensor([[[-0.0064,  1.0000],
         [-0.0123,  1.0000],
         [-0.0181,  1.0000],
         [-0.0207,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012048, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176334973803492
7.335370594635606 seconds in game passed.
Action: tensor([[[-0.0064,  1.0000],
         [-0.0123,  1.0000],
         [-0.0181,  1.0000],
         [-0.0207,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012173, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176334973803492
7.360370595008135 seconds in game passed.
Action: tensor([[[-0.0064,  1.0000],
         [-0.0123,  1.0000],
         [-0.0181,  1.0000],
         [-0.0207,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012299, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.176334973803492
+++++++++++++: 1.2693535152913753
7.385370595380664 seconds in game passed.
At 7.385370595380664 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0108,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021222, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2693535152913753
Current reward: 0.2706129241222055
Current mitigation activation: 1
#############################
Total reward: 16.446947897925696
7.410370595753193 seconds in game passed.
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0108,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015896, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446947897925696
7.435370596125722 seconds in game passed.
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0108,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016120, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446947897925696
7.460370596498251 seconds in game passed.
Action: tensor([[[ 0.0301,  1.0000],
         [ 0.0041,  1.0000],
         [-0.0108,  1.0000],
         [-0.0089,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016345, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446947897925696
+++++++++++++: 1.367628013667018
7.48537059687078 seconds in game passed.
At 7.48537059687078 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.0142e-03, 9.5602e-01],
         [1.1165e-03, 9.5436e-01],
         [2.6928e-04, 9.5375e-01],
         [6.2712e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003188, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.367628013667018
Current reward: 0.23975578767654698
Current mitigation activation: 0
#############################
Total reward: 16.686703685602243
7.510370597243309 seconds in game passed.
Action: tensor([[[2.0142e-03, 9.5602e-01],
         [1.1165e-03, 9.5436e-01],
         [2.6928e-04, 9.5375e-01],
         [6.2712e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000143, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686703685602243
7.535370597615838 seconds in game passed.
Action: tensor([[[2.0142e-03, 9.5602e-01],
         [1.1165e-03, 9.5436e-01],
         [2.6928e-04, 9.5375e-01],
         [6.2712e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000208, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686703685602243
7.560370597988367 seconds in game passed.
Action: tensor([[[2.0142e-03, 9.5602e-01],
         [1.1165e-03, 9.5436e-01],
         [2.6928e-04, 9.5375e-01],
         [6.2712e-04, 9.5337e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000273, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686703685602243
+++++++++++++: 1.5101406280742695
7.585370598360896 seconds in game passed.
At 7.585370598360896 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.1302e-04, 9.5595e-01],
         [1.1270e-03, 9.5432e-01],
         [1.0265e-03, 9.5375e-01],
         [1.4890e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000423, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5101406280742695
Current reward: 0.2106578156509614
Current mitigation activation: 0
#############################
Total reward: 16.897361501253204
7.610370598733425 seconds in game passed.
Action: tensor([[[8.1302e-04, 9.5595e-01],
         [1.1270e-03, 9.5432e-01],
         [1.0265e-03, 9.5375e-01],
         [1.4890e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000253, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.897361501253204
7.635370599105954 seconds in game passed.
Action: tensor([[[8.1302e-04, 9.5595e-01],
         [1.1270e-03, 9.5432e-01],
         [1.0265e-03, 9.5375e-01],
         [1.4890e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000207, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.897361501253204
7.660370599478483 seconds in game passed.
Action: tensor([[[8.1302e-04, 9.5595e-01],
         [1.1270e-03, 9.5432e-01],
         [1.0265e-03, 9.5375e-01],
         [1.4890e-03, 9.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000161, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.897361501253204
+++++++++++++: 1.7384749132835808
7.685370599851012 seconds in game passed.
At 7.685370599851012 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.9671e-04, 9.5610e-01],
         [1.5286e-03, 9.5459e-01],
         [1.8316e-03, 9.5409e-01],
         [1.9244e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000129, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7384749132835808
Current reward: 0.1826720419729364
Current mitigation activation: 0
#############################
Total reward: 17.08003354322614
7.710370600223541 seconds in game passed.
Action: tensor([[[7.9671e-04, 9.5610e-01],
         [1.5286e-03, 9.5459e-01],
         [1.8316e-03, 9.5409e-01],
         [1.9244e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000137, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.08003354322614
7.73537060059607 seconds in game passed.
Action: tensor([[[7.9671e-04, 9.5610e-01],
         [1.5286e-03, 9.5459e-01],
         [1.8316e-03, 9.5409e-01],
         [1.9244e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000186, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.08003354322614
7.760370600968599 seconds in game passed.
Action: tensor([[[7.9671e-04, 9.5610e-01],
         [1.5286e-03, 9.5459e-01],
         [1.8316e-03, 9.5409e-01],
         [1.9244e-03, 9.5380e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000235, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.08003354322614
+++++++++++++: 2.157217107590645
7.785370601341128 seconds in game passed.
At 7.785370601341128 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.6515e-04, 9.5621e-01],
         [1.5196e-03, 9.5476e-01],
         [1.7792e-03, 9.5429e-01],
         [1.8587e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000235, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.157217107590645
Current reward: 0.15683059681404604
Current mitigation activation: 0
#############################
Total reward: 17.236864140040186
7.810370601713657 seconds in game passed.
Action: tensor([[[7.6515e-04, 9.5621e-01],
         [1.5196e-03, 9.5476e-01],
         [1.7792e-03, 9.5429e-01],
         [1.8587e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000264, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.236864140040186
7.835370602086186 seconds in game passed.
Action: tensor([[[7.6515e-04, 9.5621e-01],
         [1.5196e-03, 9.5476e-01],
         [1.7792e-03, 9.5429e-01],
         [1.8587e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000290, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.236864140040186
7.860370602458715 seconds in game passed.
Action: tensor([[[7.6515e-04, 9.5621e-01],
         [1.5196e-03, 9.5476e-01],
         [1.7792e-03, 9.5429e-01],
         [1.8587e-03, 9.5402e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000315, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.236864140040186
+++++++++++++: 2.9642288460927646
7.8853706028312445 seconds in game passed.
At 7.8853706028312445 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.7804e-04, 9.5620e-01],
         [1.5330e-03, 9.5475e-01],
         [1.8003e-03, 9.5427e-01],
         [1.9174e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000287, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9642288460927646
Current reward: 0.13274473930757788
Current mitigation activation: 0
#############################
Total reward: 17.369608879347766
7.9103706032037735 seconds in game passed.
Action: tensor([[[7.7804e-04, 9.5620e-01],
         [1.5330e-03, 9.5475e-01],
         [1.8003e-03, 9.5427e-01],
         [1.9174e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000240, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369608879347766
7.9353706035763025 seconds in game passed.
Action: tensor([[[7.7804e-04, 9.5620e-01],
         [1.5330e-03, 9.5475e-01],
         [1.8003e-03, 9.5427e-01],
         [1.9174e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000196, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369608879347766
7.960370603948832 seconds in game passed.
Action: tensor([[[7.7804e-04, 9.5620e-01],
         [1.5330e-03, 9.5475e-01],
         [1.8003e-03, 9.5427e-01],
         [1.9174e-03, 9.5401e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000151, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.369608879347766
+++++++++++++: 4.774318676532552
7.985370604321361 seconds in game passed.
At 7.985370604321361 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.0941e-04, 9.5606e-01],
         [1.5073e-03, 9.5455e-01],
         [1.7875e-03, 9.5406e-01],
         [1.9183e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000358, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.774318676532552
Current reward: 0.11053776640286142
Current mitigation activation: 0
#############################
Total reward: 17.480146645750626
8.01037060469389 seconds in game passed.
Action: tensor([[[9.0941e-04, 9.5606e-01],
         [1.5073e-03, 9.5455e-01],
         [1.7875e-03, 9.5406e-01],
         [1.9183e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000489, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.480146645750626
8.035370605066419 seconds in game passed.
Action: tensor([[[9.0941e-04, 9.5606e-01],
         [1.5073e-03, 9.5455e-01],
         [1.7875e-03, 9.5406e-01],
         [1.9183e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000630, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.480146645750626
8.060370605438948 seconds in game passed.
Action: tensor([[[9.0941e-04, 9.5606e-01],
         [1.5073e-03, 9.5455e-01],
         [1.7875e-03, 9.5406e-01],
         [1.9183e-03, 9.5378e-01]]])
agent 0 action: VehicleControl(throttle=0.004343, steer=0.000771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.480146645750626
+++++++++++++: 23.4587900751866
8.085370605811477 seconds in game passed.
At 8.085370605811477 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006652, steer=0.000839, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03964332464528939
Current mitigation activation: 0
#############################
Total reward: 17.519789970395916
8.110370606184006 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006655, steer=0.000991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519789970395916
8.135370606556535 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006821, steer=0.001130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519789970395916
8.160370606929064 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0013, 0.9544],
         [0.0016, 0.9538],
         [0.0018, 0.9535]]])
agent 0 action: VehicleControl(throttle=0.006934, steer=0.001270, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.519789970395916
+++++++++++++: 2098.007638622772
8.185370607301593 seconds in game passed.
At 8.185370607301593 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0013e-02,  9.5572e-01],
         [ 1.7529e-03,  9.5379e-01],
         [-1.8780e-03,  9.5302e-01],
         [-4.0893e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.035067, steer=0.007438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.000464933023241316
Current mitigation activation: 0
#############################
Total reward: 17.520254903419158
8.210370607674122 seconds in game passed.
Action: tensor([[[ 1.0013e-02,  9.5572e-01],
         [ 1.7529e-03,  9.5379e-01],
         [-1.8780e-03,  9.5302e-01],
         [-4.0893e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.009399, steer=0.006724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520254903419158
8.23537060804665 seconds in game passed.
Action: tensor([[[ 1.0013e-02,  9.5572e-01],
         [ 1.7529e-03,  9.5379e-01],
         [-1.8780e-03,  9.5302e-01],
         [-4.0893e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.012638, steer=0.006993, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520254903419158
8.26037060841918 seconds in game passed.
Action: tensor([[[ 1.0013e-02,  9.5572e-01],
         [ 1.7529e-03,  9.5379e-01],
         [-1.8780e-03,  9.5302e-01],
         [-4.0893e-04,  9.5246e-01]]])
agent 0 action: VehicleControl(throttle=0.013420, steer=0.007262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520254903419158
+++++++++++++: 165.6793696967199
8.285370608791709 seconds in game passed.
At 8.285370608791709 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0243,  0.9551],
         [ 0.0025,  0.9522],
         [-0.0078,  0.9506],
         [-0.0027,  0.9443]]])
agent 0 action: VehicleControl(throttle=0.064841, steer=0.016935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006182128227599783
Current mitigation activation: 0
#############################
Total reward: 17.526437031646758
8.310370609164238 seconds in game passed.
Action: tensor([[[ 0.0243,  0.9551],
         [ 0.0025,  0.9522],
         [-0.0078,  0.9506],
         [-0.0027,  0.9443]]])
agent 0 action: VehicleControl(throttle=0.060762, steer=0.015669, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.526437031646758
8.335370609536767 seconds in game passed.
Action: tensor([[[ 0.0243,  0.9551],
         [ 0.0025,  0.9522],
         [-0.0078,  0.9506],
         [-0.0027,  0.9443]]])
agent 0 action: VehicleControl(throttle=0.061992, steer=0.015965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.526437031646758
8.360370609909296 seconds in game passed.
Action: tensor([[[ 0.0243,  0.9551],
         [ 0.0025,  0.9522],
         [-0.0078,  0.9506],
         [-0.0027,  0.9443]]])
agent 0 action: VehicleControl(throttle=0.063139, steer=0.016262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.526437031646758
+++++++++++++: 206.87347353375478
8.385370610281825 seconds in game passed.
At 8.385370610281825 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.5419e-02,  9.5362e-01],
         [ 6.7734e-04,  9.4726e-01],
         [-1.2984e-02,  9.1305e-01],
         [-8.9773e-03,  5.9880e-01]]])
agent 0 action: VehicleControl(throttle=0.078256, steer=0.015710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0052051235655383695
Current mitigation activation: 0
#############################
Total reward: 17.531642155212296
8.410370610654354 seconds in game passed.
Action: tensor([[[ 2.5419e-02,  9.5362e-01],
         [ 6.7734e-04,  9.4726e-01],
         [-1.2984e-02,  9.1305e-01],
         [-8.9773e-03,  5.9880e-01]]])
agent 0 action: VehicleControl(throttle=0.077954, steer=0.015737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.531642155212296
8.435370611026883 seconds in game passed.
Action: tensor([[[ 2.5419e-02,  9.5362e-01],
         [ 6.7734e-04,  9.4726e-01],
         [-1.2984e-02,  9.1305e-01],
         [-8.9773e-03,  5.9880e-01]]])
agent 0 action: VehicleControl(throttle=0.079089, steer=0.015681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.531642155212296
8.460370611399412 seconds in game passed.
Action: tensor([[[ 2.5419e-02,  9.5362e-01],
         [ 6.7734e-04,  9.4726e-01],
         [-1.2984e-02,  9.1305e-01],
         [-8.9773e-03,  5.9880e-01]]])
agent 0 action: VehicleControl(throttle=0.080173, steer=0.015626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.531642155212296
+++++++++++++: 245.57795246398283
8.485370611771941 seconds in game passed.
At 8.485370611771941 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0099,  0.9527],
         [-0.0035,  0.9418],
         [-0.0103,  0.8737],
         [-0.0045,  0.6019]]])
agent 0 action: VehicleControl(throttle=0.054187, steer=0.003374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004614234887144757
Current mitigation activation: 0
#############################
Total reward: 17.536256390099442
8.51037061214447 seconds in game passed.
Action: tensor([[[ 0.0099,  0.9527],
         [-0.0035,  0.9418],
         [-0.0103,  0.8737],
         [-0.0045,  0.6019]]])
agent 0 action: VehicleControl(throttle=0.057764, steer=0.005440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.536256390099442
8.535370612517 seconds in game passed.
Action: tensor([[[ 0.0099,  0.9527],
         [-0.0035,  0.9418],
         [-0.0103,  0.8737],
         [-0.0045,  0.6019]]])
agent 0 action: VehicleControl(throttle=0.058463, steer=0.005461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.536256390099442
8.560370612889528 seconds in game passed.
Action: tensor([[[ 0.0099,  0.9527],
         [-0.0035,  0.9418],
         [-0.0103,  0.8737],
         [-0.0045,  0.6019]]])
agent 0 action: VehicleControl(throttle=0.059169, steer=0.005482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.536256390099442
+++++++++++++: 273.6978418801118
8.585370613262057 seconds in game passed.
At 8.585370613262057 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0292,  0.9513],
         [-0.0175,  0.9098],
         [-0.0121,  0.7397],
         [-0.0077,  0.5375]]])
agent 0 action: VehicleControl(throttle=0.182848, steer=-0.027585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004360662154458709
Current mitigation activation: 0
#############################
Total reward: 17.5406170522539
8.610370613634586 seconds in game passed.
Action: tensor([[[-0.0292,  0.9513],
         [-0.0175,  0.9098],
         [-0.0121,  0.7397],
         [-0.0077,  0.5375]]])
agent 0 action: VehicleControl(throttle=0.171883, steer=-0.022439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5406170522539
8.635370614007115 seconds in game passed.
Action: tensor([[[-0.0292,  0.9513],
         [-0.0175,  0.9098],
         [-0.0121,  0.7397],
         [-0.0077,  0.5375]]])
agent 0 action: VehicleControl(throttle=0.173908, steer=-0.022751, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5406170522539
8.660370614379644 seconds in game passed.
Action: tensor([[[-0.0292,  0.9513],
         [-0.0175,  0.9098],
         [-0.0121,  0.7397],
         [-0.0077,  0.5375]]])
agent 0 action: VehicleControl(throttle=0.175805, steer=-0.023064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.5406170522539
+++++++++++++: 296.8370664162881
8.685370614752173 seconds in game passed.
At 8.685370614752173 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0382,  0.9497],
         [-0.0172,  0.8182],
         [-0.0073,  0.6054],
         [-0.0042,  0.4851]]])
agent 0 action: VehicleControl(throttle=0.652584, steer=-0.027672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004234277894465852
Current mitigation activation: 0
#############################
Total reward: 17.544851330148365
8.710370615124702 seconds in game passed.
Action: tensor([[[-0.0382,  0.9497],
         [-0.0172,  0.8182],
         [-0.0073,  0.6054],
         [-0.0042,  0.4851]]])
agent 0 action: VehicleControl(throttle=0.609204, steer=-0.027323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544851330148365
8.735370615497231 seconds in game passed.
Action: tensor([[[-0.0382,  0.9497],
         [-0.0172,  0.8182],
         [-0.0073,  0.6054],
         [-0.0042,  0.4851]]])
agent 0 action: VehicleControl(throttle=0.616034, steer=-0.027683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544851330148365
8.76037061586976 seconds in game passed.
Action: tensor([[[-0.0382,  0.9497],
         [-0.0172,  0.8182],
         [-0.0073,  0.6054],
         [-0.0042,  0.4851]]])
agent 0 action: VehicleControl(throttle=0.622571, steer=-0.028042, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.544851330148365
+++++++++++++: 291.6756663131053
8.78537061624229 seconds in game passed.
At 8.78537061624229 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0335,  0.9492],
         [-0.0105,  0.8003],
         [-0.0053,  0.5859],
         [-0.0063,  0.4782]]])
agent 0 action: VehicleControl(throttle=0.734452, steer=-0.021032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.004536973330573855
Current mitigation activation: 0
#############################
Total reward: 17.54938830347894
8.810370616614819 seconds in game passed.
Action: tensor([[[-0.0335,  0.9492],
         [-0.0105,  0.8003],
         [-0.0053,  0.5859],
         [-0.0063,  0.4782]]])
agent 0 action: VehicleControl(throttle=0.729763, steer=-0.022531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54938830347894
8.835370616987348 seconds in game passed.
Action: tensor([[[-0.0335,  0.9492],
         [-0.0105,  0.8003],
         [-0.0053,  0.5859],
         [-0.0063,  0.4782]]])
agent 0 action: VehicleControl(throttle=0.735428, steer=-0.022814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54938830347894
8.860370617359877 seconds in game passed.
Action: tensor([[[-0.0335,  0.9492],
         [-0.0105,  0.8003],
         [-0.0053,  0.5859],
         [-0.0063,  0.4782]]])
agent 0 action: VehicleControl(throttle=0.739724, steer=-0.023097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.54938830347894
+++++++++++++: 200.4484658792602
8.885370617732406 seconds in game passed.
At 8.885370617732406 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.4898e-02,  9.4333e-01],
         [-4.9570e-03,  6.0682e-01],
         [-1.9316e-03,  4.7235e-01],
         [-3.4750e-04,  4.1715e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.012750, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0069444121518035164
Current mitigation activation: 0
#############################
Total reward: 17.55633271563074
8.910370618104935 seconds in game passed.
Action: tensor([[[-2.4898e-02,  9.4333e-01],
         [-4.9570e-03,  6.0682e-01],
         [-1.9316e-03,  4.7235e-01],
         [-3.4750e-04,  4.1715e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55633271563074
8.935370618477464 seconds in game passed.
Action: tensor([[[-2.4898e-02,  9.4333e-01],
         [-4.9570e-03,  6.0682e-01],
         [-1.9316e-03,  4.7235e-01],
         [-3.4750e-04,  4.1715e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.014851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55633271563074
8.960370618849993 seconds in game passed.
Action: tensor([[[-2.4898e-02,  9.4333e-01],
         [-4.9570e-03,  6.0682e-01],
         [-1.9316e-03,  4.7235e-01],
         [-3.4750e-04,  4.1715e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.015025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.55633271563074
+++++++++++++: 45.270804540129845
8.985370619222522 seconds in game passed.
At 8.985370619222522 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.3463e-02,  9.3046e-01],
         [-5.5147e-04,  5.5705e-01],
         [ 1.0888e-04,  4.3600e-01],
         [ 1.2261e-03,  3.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.032250614799686377
Current mitigation activation: 0
#############################
Total reward: 17.588583330430428
9.01037061959505 seconds in game passed.
Action: tensor([[[-1.3463e-02,  9.3046e-01],
         [-5.5147e-04,  5.5705e-01],
         [ 1.0888e-04,  4.3600e-01],
         [ 1.2261e-03,  3.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.588583330430428
9.03537061996758 seconds in game passed.
Action: tensor([[[-1.3463e-02,  9.3046e-01],
         [-5.5147e-04,  5.5705e-01],
         [ 1.0888e-04,  4.3600e-01],
         [ 1.2261e-03,  3.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.588583330430428
9.060370620340109 seconds in game passed.
Action: tensor([[[-1.3463e-02,  9.3046e-01],
         [-5.5147e-04,  5.5705e-01],
         [ 1.0888e-04,  4.3600e-01],
         [ 1.2261e-03,  3.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.588583330430428
+++++++++++++: 21.64547305262869
9.085370620712638 seconds in game passed.
At 9.085370620712638 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0102,  0.8802],
         [-0.0035,  0.4947],
         [-0.0057,  0.3608],
         [-0.0060,  0.2911]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.07048011945934002
Current mitigation activation: 0
#############################
Total reward: 17.659063449889768
9.110370621085167 seconds in game passed.
Action: tensor([[[-0.0102,  0.8802],
         [-0.0035,  0.4947],
         [-0.0057,  0.3608],
         [-0.0060,  0.2911]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.659063449889768
9.135370621457696 seconds in game passed.
Action: tensor([[[-0.0102,  0.8802],
         [-0.0035,  0.4947],
         [-0.0057,  0.3608],
         [-0.0060,  0.2911]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.659063449889768
9.160370621830225 seconds in game passed.
Action: tensor([[[-0.0102,  0.8802],
         [-0.0035,  0.4947],
         [-0.0057,  0.3608],
         [-0.0060,  0.2911]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.659063449889768
+++++++++++++: 11.482894404221687
9.185370622202754 seconds in game passed.
At 9.185370622202754 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0009,  0.8326],
         [-0.0040,  0.4693],
         [-0.0069,  0.3341],
         [-0.0080,  0.2614]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.13807142628512675
Current mitigation activation: 0
#############################
Total reward: 17.797134876174894
9.210370622575283 seconds in game passed.
Action: tensor([[[ 0.0009,  0.8326],
         [-0.0040,  0.4693],
         [-0.0069,  0.3341],
         [-0.0080,  0.2614]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.797134876174894
9.235370622947812 seconds in game passed.
Action: tensor([[[ 0.0009,  0.8326],
         [-0.0040,  0.4693],
         [-0.0069,  0.3341],
         [-0.0080,  0.2614]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.797134876174894
9.260370623320341 seconds in game passed.
Action: tensor([[[ 0.0009,  0.8326],
         [-0.0040,  0.4693],
         [-0.0069,  0.3341],
         [-0.0080,  0.2614]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.797134876174894
+++++++++++++: 7.561221488419875
9.28537062369287 seconds in game passed.
At 9.28537062369287 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0034,  0.8134],
         [-0.0033,  0.4579],
         [-0.0065,  0.3235],
         [-0.0080,  0.2512]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.561221488419875
Current reward: 0.17531416874585856
Current mitigation activation: 0
#############################
Total reward: 17.972449044920754
9.3103706240654 seconds in game passed.
Action: tensor([[[ 0.0034,  0.8134],
         [-0.0033,  0.4579],
         [-0.0065,  0.3235],
         [-0.0080,  0.2512]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.972449044920754
9.335370624437928 seconds in game passed.
Action: tensor([[[ 0.0034,  0.8134],
         [-0.0033,  0.4579],
         [-0.0065,  0.3235],
         [-0.0080,  0.2512]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.972449044920754
9.360370624810457 seconds in game passed.
Action: tensor([[[ 0.0034,  0.8134],
         [-0.0033,  0.4579],
         [-0.0065,  0.3235],
         [-0.0080,  0.2512]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.972449044920754
+++++++++++++: 6.0335135519642495
9.385370625182986 seconds in game passed.
At 9.385370625182986 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0076,  0.7988],
         [-0.0014,  0.4469],
         [-0.0043,  0.3108],
         [-0.0059,  0.2377]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.0335135519642495
Current reward: 0.19262794772362224
Current mitigation activation: 0
#############################
Total reward: 18.165076992644376
9.410370625555515 seconds in game passed.
Action: tensor([[[ 0.0076,  0.7988],
         [-0.0014,  0.4469],
         [-0.0043,  0.3108],
         [-0.0059,  0.2377]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.165076992644376
9.435370625928044 seconds in game passed.
Action: tensor([[[ 0.0076,  0.7988],
         [-0.0014,  0.4469],
         [-0.0043,  0.3108],
         [-0.0059,  0.2377]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.165076992644376
9.460370626300573 seconds in game passed.
Action: tensor([[[ 0.0076,  0.7988],
         [-0.0014,  0.4469],
         [-0.0043,  0.3108],
         [-0.0059,  0.2377]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.165076992644376
+++++++++++++: 5.139259848447709
9.485370626673102 seconds in game passed.
At 9.485370626673102 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0055,  0.7610],
         [-0.0017,  0.4289],
         [-0.0042,  0.2991],
         [-0.0059,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.139259848447709
Current reward: 0.20824646493443513
Current mitigation activation: 0
#############################
Total reward: 18.373323457578813
9.510370627045631 seconds in game passed.
Action: tensor([[[ 0.0055,  0.7610],
         [-0.0017,  0.4289],
         [-0.0042,  0.2991],
         [-0.0059,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.373323457578813
9.53537062741816 seconds in game passed.
Action: tensor([[[ 0.0055,  0.7610],
         [-0.0017,  0.4289],
         [-0.0042,  0.2991],
         [-0.0059,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003962, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.373323457578813
9.56037062779069 seconds in game passed.
Action: tensor([[[ 0.0055,  0.7610],
         [-0.0017,  0.4289],
         [-0.0042,  0.2991],
         [-0.0059,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.373323457578813
+++++++++++++: 4.516864329516345
9.585370628163218 seconds in game passed.
At 9.585370628163218 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0049,  0.7496],
         [-0.0019,  0.4207],
         [-0.0041,  0.2927],
         [-0.0055,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004067, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.516864329516345
Current reward: 0.2229624745597043
Current mitigation activation: 0
#############################
Total reward: 18.596285932138517
9.610370628535748 seconds in game passed.
Action: tensor([[[ 0.0049,  0.7496],
         [-0.0019,  0.4207],
         [-0.0041,  0.2927],
         [-0.0055,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003696, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.596285932138517
9.635370628908277 seconds in game passed.
Action: tensor([[[ 0.0049,  0.7496],
         [-0.0019,  0.4207],
         [-0.0041,  0.2927],
         [-0.0055,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003389, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.596285932138517
9.660370629280806 seconds in game passed.
Action: tensor([[[ 0.0049,  0.7496],
         [-0.0019,  0.4207],
         [-0.0041,  0.2927],
         [-0.0055,  0.2250]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003082, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.596285932138517
+++++++++++++: 4.043627454981978
9.685370629653335 seconds in game passed.
At 9.685370629653335 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1003e-02,  7.5179e-01],
         [ 2.8896e-04,  4.1846e-01],
         [-1.3020e-03,  2.9166e-01],
         [-2.0454e-03,  2.2491e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.043627454981978
Current reward: 0.23707938031791137
Current mitigation activation: 0
#############################
Total reward: 18.83336531245643
9.710370630025864 seconds in game passed.
Action: tensor([[[ 1.1003e-02,  7.5179e-01],
         [ 2.8896e-04,  4.1846e-01],
         [-1.3020e-03,  2.9166e-01],
         [-2.0454e-03,  2.2491e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.83336531245643
9.735370630398393 seconds in game passed.
Action: tensor([[[ 1.1003e-02,  7.5179e-01],
         [ 2.8896e-04,  4.1846e-01],
         [-1.3020e-03,  2.9166e-01],
         [-2.0454e-03,  2.2491e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.83336531245643
9.760370630770922 seconds in game passed.
Action: tensor([[[ 1.1003e-02,  7.5179e-01],
         [ 2.8896e-04,  4.1846e-01],
         [-1.3020e-03,  2.9166e-01],
         [-2.0454e-03,  2.2491e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.83336531245643
+++++++++++++: 3.6642592896375947
9.78537063114345 seconds in game passed.
At 9.78537063114345 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4724e-02,  7.4462e-01],
         [ 1.2286e-03,  4.1650e-01],
         [-1.7926e-04,  2.9096e-01],
         [-6.7315e-04,  2.2457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6642592896375947
Current reward: 0.2507253115637401
Current mitigation activation: 0
#############################
Total reward: 19.08409062402017
9.81037063151598 seconds in game passed.
Action: tensor([[[ 1.4724e-02,  7.4462e-01],
         [ 1.2286e-03,  4.1650e-01],
         [-1.7926e-04,  2.9096e-01],
         [-6.7315e-04,  2.2457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.08409062402017
9.835370631888509 seconds in game passed.
Action: tensor([[[ 1.4724e-02,  7.4462e-01],
         [ 1.2286e-03,  4.1650e-01],
         [-1.7926e-04,  2.9096e-01],
         [-6.7315e-04,  2.2457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.08409062402017
9.860370632261038 seconds in game passed.
Action: tensor([[[ 1.4724e-02,  7.4462e-01],
         [ 1.2286e-03,  4.1650e-01],
         [-1.7926e-04,  2.9096e-01],
         [-6.7315e-04,  2.2457e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.08409062402017
+++++++++++++: 3.3493404275157883
9.885370632633567 seconds in game passed.
At 9.885370632633567 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4579e-02, 7.3777e-01],
         [2.2364e-03, 4.1449e-01],
         [1.0168e-03, 2.8909e-01],
         [5.2077e-04, 2.2260e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3493404275157883
Current reward: 0.2639496616382389
Current mitigation activation: 0
#############################
Total reward: 19.34804028565841
9.910370633006096 seconds in game passed.
Action: tensor([[[1.4579e-02, 7.3777e-01],
         [2.2364e-03, 4.1449e-01],
         [1.0168e-03, 2.8909e-01],
         [5.2077e-04, 2.2260e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.34804028565841
9.935370633378625 seconds in game passed.
Action: tensor([[[1.4579e-02, 7.3777e-01],
         [2.2364e-03, 4.1449e-01],
         [1.0168e-03, 2.8909e-01],
         [5.2077e-04, 2.2260e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.34804028565841
9.960370633751154 seconds in game passed.
Action: tensor([[[1.4579e-02, 7.3777e-01],
         [2.2364e-03, 4.1449e-01],
         [1.0168e-03, 2.8909e-01],
         [5.2077e-04, 2.2260e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.34804028565841
+++++++++++++: 3.1984810323029573
9.985370634123683 seconds in game passed.
At 9.985370634123683 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1442e-02, 7.0942e-01],
         [1.4499e-03, 3.9728e-01],
         [4.5490e-04, 2.7757e-01],
         [7.5392e-05, 2.1503e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1984810323029573
Current reward: 0.27227066857344406
Current mitigation activation: 0
#############################
Total reward: 19.620310954231854
10.010370634496212 seconds in game passed.
Action: tensor([[[1.1442e-02, 7.0942e-01],
         [1.4499e-03, 3.9728e-01],
         [4.5490e-04, 2.7757e-01],
         [7.5392e-05, 2.1503e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.620310954231854
10.035370634868741 seconds in game passed.
Action: tensor([[[1.1442e-02, 7.0942e-01],
         [1.4499e-03, 3.9728e-01],
         [4.5490e-04, 2.7757e-01],
         [7.5392e-05, 2.1503e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.620310954231854
10.06037063524127 seconds in game passed.
Action: tensor([[[1.1442e-02, 7.0942e-01],
         [1.4499e-03, 3.9728e-01],
         [4.5490e-04, 2.7757e-01],
         [7.5392e-05, 2.1503e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.620310954231854
+++++++++++++: 3.2331938103632414
10.085370635613799 seconds in game passed.
At 10.085370635613799 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.7693e-03, 6.7608e-01],
         [1.2250e-03, 3.7564e-01],
         [7.7525e-04, 2.6285e-01],
         [4.3657e-04, 2.0521e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2331938103632414
Current reward: 0.27359401979838516
Current mitigation activation: 0
#############################
Total reward: 19.89390497403024
10.110370635986328 seconds in game passed.
Action: tensor([[[6.7693e-03, 6.7608e-01],
         [1.2250e-03, 3.7564e-01],
         [7.7525e-04, 2.6285e-01],
         [4.3657e-04, 2.0521e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.89390497403024
10.135370636358857 seconds in game passed.
Action: tensor([[[6.7693e-03, 6.7608e-01],
         [1.2250e-03, 3.7564e-01],
         [7.7525e-04, 2.6285e-01],
         [4.3657e-04, 2.0521e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.89390497403024
10.160370636731386 seconds in game passed.
Action: tensor([[[6.7693e-03, 6.7608e-01],
         [1.2250e-03, 3.7564e-01],
         [7.7525e-04, 2.6285e-01],
         [4.3657e-04, 2.0521e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.89390497403024
+++++++++++++: 3.2690361182187573
10.185370637103915 seconds in game passed.
At 10.185370637103915 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.7915e-03, 6.5884e-01],
         [1.3167e-03, 3.6464e-01],
         [9.0939e-04, 2.5444e-01],
         [2.3375e-04, 1.9866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2690361182187573
Current reward: 0.27489399577897705
Current mitigation activation: 0
#############################
Total reward: 20.168798969809217
10.210370637476444 seconds in game passed.
Action: tensor([[[3.7915e-03, 6.5884e-01],
         [1.3167e-03, 3.6464e-01],
         [9.0939e-04, 2.5444e-01],
         [2.3375e-04, 1.9866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.168798969809217
10.235370637848973 seconds in game passed.
Action: tensor([[[3.7915e-03, 6.5884e-01],
         [1.3167e-03, 3.6464e-01],
         [9.0939e-04, 2.5444e-01],
         [2.3375e-04, 1.9866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.168798969809217
10.260370638221502 seconds in game passed.
Action: tensor([[[3.7915e-03, 6.5884e-01],
         [1.3167e-03, 3.6464e-01],
         [9.0939e-04, 2.5444e-01],
         [2.3375e-04, 1.9866e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.168798969809217
+++++++++++++: 3.3051801947623103
10.285370638594031 seconds in game passed.
At 10.285370638594031 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.9389e-03, 6.5780e-01],
         [1.1138e-03, 3.6337e-01],
         [8.2989e-04, 2.5306e-01],
         [2.3422e-04, 1.9709e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3051801947623103
Current reward: 0.27620329816745004
Current mitigation activation: 0
#############################
Total reward: 20.445002267976665
10.31037063896656 seconds in game passed.
Action: tensor([[[2.9389e-03, 6.5780e-01],
         [1.1138e-03, 3.6337e-01],
         [8.2989e-04, 2.5306e-01],
         [2.3422e-04, 1.9709e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.445002267976665
10.33537063933909 seconds in game passed.
Action: tensor([[[2.9389e-03, 6.5780e-01],
         [1.1138e-03, 3.6337e-01],
         [8.2989e-04, 2.5306e-01],
         [2.3422e-04, 1.9709e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.445002267976665
10.360370639711618 seconds in game passed.
Action: tensor([[[2.9389e-03, 6.5780e-01],
         [1.1138e-03, 3.6337e-01],
         [8.2989e-04, 2.5306e-01],
         [2.3422e-04, 1.9709e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.445002267976665
+++++++++++++: 3.3417707752009957
10.385370640084147 seconds in game passed.
At 10.385370640084147 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.8086e-03,  6.4543e-01],
         [ 5.1598e-04,  3.5922e-01],
         [ 1.6727e-04,  2.5158e-01],
         [-4.3942e-04,  1.9632e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3417707752009957
Current reward: 0.2775147850594788
Current mitigation activation: 0
#############################
Total reward: 20.722517053036142
10.410370640456676 seconds in game passed.
Action: tensor([[[ 2.8086e-03,  6.4543e-01],
         [ 5.1598e-04,  3.5922e-01],
         [ 1.6727e-04,  2.5158e-01],
         [-4.3942e-04,  1.9632e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.722517053036142
10.435370640829206 seconds in game passed.
Action: tensor([[[ 2.8086e-03,  6.4543e-01],
         [ 5.1598e-04,  3.5922e-01],
         [ 1.6727e-04,  2.5158e-01],
         [-4.3942e-04,  1.9632e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.722517053036142
10.460370641201735 seconds in game passed.
Action: tensor([[[ 2.8086e-03,  6.4543e-01],
         [ 5.1598e-04,  3.5922e-01],
         [ 1.6727e-04,  2.5158e-01],
         [-4.3942e-04,  1.9632e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002779, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.722517053036142
+++++++++++++: 3.26294720172794
10.485370641574264 seconds in game passed.
At 10.485370641574264 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.6757e-03,  6.3866e-01],
         [-2.2635e-05,  3.5406e-01],
         [-4.5504e-04,  2.4720e-01],
         [-1.0631e-03,  1.9256e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.26294720172794
Current reward: 0.28300714207410993
Current mitigation activation: 0
#############################
Total reward: 21.00552419511025
10.510370641946793 seconds in game passed.
Action: tensor([[[ 1.6757e-03,  6.3866e-01],
         [-2.2635e-05,  3.5406e-01],
         [-4.5504e-04,  2.4720e-01],
         [-1.0631e-03,  1.9256e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.00552419511025
10.535370642319322 seconds in game passed.
Action: tensor([[[ 1.6757e-03,  6.3866e-01],
         [-2.2635e-05,  3.5406e-01],
         [-4.5504e-04,  2.4720e-01],
         [-1.0631e-03,  1.9256e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.00552419511025
10.56037064269185 seconds in game passed.
Action: tensor([[[ 1.6757e-03,  6.3866e-01],
         [-2.2635e-05,  3.5406e-01],
         [-4.5504e-04,  2.4720e-01],
         [-1.0631e-03,  1.9256e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.00552419511025
+++++++++++++: 2.9863744260785534
10.58537064306438 seconds in game passed.
At 10.58537064306438 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2374e-03,  6.4436e-01],
         [ 4.9969e-04,  3.5560e-01],
         [-1.4991e-05,  2.4664e-01],
         [-7.3824e-04,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9863744260785534
Current reward: 0.2967232470673976
Current mitigation activation: 0
#############################
Total reward: 21.30224744217765
10.610370643436909 seconds in game passed.
Action: tensor([[[ 2.2374e-03,  6.4436e-01],
         [ 4.9969e-04,  3.5560e-01],
         [-1.4991e-05,  2.4664e-01],
         [-7.3824e-04,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.30224744217765
10.635370643809438 seconds in game passed.
Action: tensor([[[ 2.2374e-03,  6.4436e-01],
         [ 4.9969e-04,  3.5560e-01],
         [-1.4991e-05,  2.4664e-01],
         [-7.3824e-04,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002576, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.30224744217765
10.660370644181967 seconds in game passed.
Action: tensor([[[ 2.2374e-03,  6.4436e-01],
         [ 4.9969e-04,  3.5560e-01],
         [-1.4991e-05,  2.4664e-01],
         [-7.3824e-04,  1.9105e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.30224744217765
+++++++++++++: 2.768904058352085
10.685370644554496 seconds in game passed.
At 10.685370644554496 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.7043e-05,  6.5805e-01],
         [-1.3218e-03,  3.6141e-01],
         [-1.9977e-03,  2.4984e-01],
         [-2.7574e-03,  1.9310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.768904058352085
Current reward: 0.3088433082582583
Current mitigation activation: 0
#############################
Total reward: 21.611090750435906
10.710370644927025 seconds in game passed.
Action: tensor([[[-4.7043e-05,  6.5805e-01],
         [-1.3218e-03,  3.6141e-01],
         [-1.9977e-03,  2.4984e-01],
         [-2.7574e-03,  1.9310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.611090750435906
10.735370645299554 seconds in game passed.
Action: tensor([[[-4.7043e-05,  6.5805e-01],
         [-1.3218e-03,  3.6141e-01],
         [-1.9977e-03,  2.4984e-01],
         [-2.7574e-03,  1.9310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.611090750435906
10.760370645672083 seconds in game passed.
Action: tensor([[[-4.7043e-05,  6.5805e-01],
         [-1.3218e-03,  3.6141e-01],
         [-1.9977e-03,  2.4984e-01],
         [-2.7574e-03,  1.9310e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.611090750435906
+++++++++++++: 2.588090354745542
10.785370646044612 seconds in game passed.
At 10.785370646044612 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6700],
         [-0.0015,  0.3646],
         [-0.0021,  0.2504],
         [-0.0028,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.588090354745542
Current reward: 0.31976111781305233
Current mitigation activation: 0
#############################
Total reward: 21.930851868248958
10.810370646417141 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6700],
         [-0.0015,  0.3646],
         [-0.0021,  0.2504],
         [-0.0028,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.930851868248958
10.83537064678967 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6700],
         [-0.0015,  0.3646],
         [-0.0021,  0.2504],
         [-0.0028,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.930851868248958
10.860370647162199 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6700],
         [-0.0015,  0.3646],
         [-0.0021,  0.2504],
         [-0.0028,  0.1930]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.930851868248958
+++++++++++++: 2.4295355521968762
10.885370647534728 seconds in game passed.
At 10.885370647534728 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.4632e-04,  6.7675e-01],
         [-1.8396e-03,  3.6502e-01],
         [-2.7764e-03,  2.5011e-01],
         [-3.6387e-03,  1.9243e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4295355521968762
Current reward: 0.32987725797237544
Current mitigation activation: 0
#############################
Total reward: 22.26072912622133
10.910370647907257 seconds in game passed.
Action: tensor([[[ 2.4632e-04,  6.7675e-01],
         [-1.8396e-03,  3.6502e-01],
         [-2.7764e-03,  2.5011e-01],
         [-3.6387e-03,  1.9243e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.26072912622133
10.935370648279786 seconds in game passed.
Action: tensor([[[ 2.4632e-04,  6.7675e-01],
         [-1.8396e-03,  3.6502e-01],
         [-2.7764e-03,  2.5011e-01],
         [-3.6387e-03,  1.9243e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.26072912622133
10.960370648652315 seconds in game passed.
Action: tensor([[[ 2.4632e-04,  6.7675e-01],
         [-1.8396e-03,  3.6502e-01],
         [-2.7764e-03,  2.5011e-01],
         [-3.6387e-03,  1.9243e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.26072912622133
+++++++++++++: 2.286265277938378
10.985370649024844 seconds in game passed.
At 10.985370649024844 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6825],
         [-0.0025,  0.3674],
         [-0.0033,  0.2530],
         [-0.0043,  0.1951]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.286265277938378
Current reward: 0.33938517140421604
Current mitigation activation: 0
#############################
Total reward: 22.60011429762555
11.010370649397373 seconds in game passed.
Action: tensor([[[-0.0012,  0.6825],
         [-0.0025,  0.3674],
         [-0.0033,  0.2530],
         [-0.0043,  0.1951]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.60011429762555
11.035370649769902 seconds in game passed.
Action: tensor([[[-0.0012,  0.6825],
         [-0.0025,  0.3674],
         [-0.0033,  0.2530],
         [-0.0043,  0.1951]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.60011429762555
11.060370650142431 seconds in game passed.
Action: tensor([[[-0.0012,  0.6825],
         [-0.0025,  0.3674],
         [-0.0033,  0.2530],
         [-0.0043,  0.1951]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.60011429762555
+++++++++++++: 2.1541447414561916
11.08537065051496 seconds in game passed.
At 11.08537065051496 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.6803],
         [-0.0038,  0.3699],
         [-0.0047,  0.2555],
         [-0.0053,  0.1971]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002835, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1541447414561916
Current reward: 0.3484049808794355
Current mitigation activation: 0
#############################
Total reward: 22.948519278504985
11.11037065088749 seconds in game passed.
Action: tensor([[[-0.0015,  0.6803],
         [-0.0038,  0.3699],
         [-0.0047,  0.2555],
         [-0.0053,  0.1971]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.948519278504985
11.135370651260018 seconds in game passed.
Action: tensor([[[-0.0015,  0.6803],
         [-0.0038,  0.3699],
         [-0.0047,  0.2555],
         [-0.0053,  0.1971]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.948519278504985
11.160370651632547 seconds in game passed.
Action: tensor([[[-0.0015,  0.6803],
         [-0.0038,  0.3699],
         [-0.0047,  0.2555],
         [-0.0053,  0.1971]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.948519278504985
+++++++++++++: 2.031205979493084
11.185370652005076 seconds in game passed.
At 11.185370652005076 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0025,  0.6771],
         [-0.0010,  0.3716],
         [-0.0020,  0.2574],
         [-0.0029,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.031205979493084
Current reward: 0.35695513028220965
Current mitigation activation: 0
#############################
Total reward: 23.305474408787195
11.210370652377605 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6771],
         [-0.0010,  0.3716],
         [-0.0020,  0.2574],
         [-0.0029,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.305474408787195
11.235370652750134 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6771],
         [-0.0010,  0.3716],
         [-0.0020,  0.2574],
         [-0.0029,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.305474408787195
11.260370653122663 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6771],
         [-0.0010,  0.3716],
         [-0.0020,  0.2574],
         [-0.0029,  0.1987]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.305474408787195
+++++++++++++: 1.9161329329444885
11.285370653495193 seconds in game passed.
At 11.285370653495193 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6787],
         [-0.0012,  0.3742],
         [-0.0019,  0.2594],
         [-0.0026,  0.2000]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9161329329444885
Current reward: 0.36503359823799963
Current mitigation activation: 0
#############################
Total reward: 23.670508007025195
11.310370653867722 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6787],
         [-0.0012,  0.3742],
         [-0.0019,  0.2594],
         [-0.0026,  0.2000]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.670508007025195
11.33537065424025 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6787],
         [-0.0012,  0.3742],
         [-0.0019,  0.2594],
         [-0.0026,  0.2000]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.670508007025195
11.36037065461278 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6787],
         [-0.0012,  0.3742],
         [-0.0019,  0.2594],
         [-0.0026,  0.2000]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000540, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.670508007025195
+++++++++++++: 1.8076949292571531
11.385370654985309 seconds in game passed.
At 11.385370654985309 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.6216e-03,  6.7721e-01],
         [ 1.8638e-04,  3.8451e-01],
         [-5.7530e-04,  2.7105e-01],
         [-1.1506e-03,  2.1096e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8076949292571531
Current reward: 0.37265042414015737
Current mitigation activation: 0
#############################
Total reward: 24.043158431165352
11.410370655357838 seconds in game passed.
Action: tensor([[[ 5.6216e-03,  6.7721e-01],
         [ 1.8638e-04,  3.8451e-01],
         [-5.7530e-04,  2.7105e-01],
         [-1.1506e-03,  2.1096e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.043158431165352
11.435370655730367 seconds in game passed.
Action: tensor([[[ 5.6216e-03,  6.7721e-01],
         [ 1.8638e-04,  3.8451e-01],
         [-5.7530e-04,  2.7105e-01],
         [-1.1506e-03,  2.1096e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.043158431165352
11.460370656102896 seconds in game passed.
Action: tensor([[[ 5.6216e-03,  6.7721e-01],
         [ 1.8638e-04,  3.8451e-01],
         [-5.7530e-04,  2.7105e-01],
         [-1.1506e-03,  2.1096e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001863, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.043158431165352
+++++++++++++: 1.704982212637027
11.485370656475425 seconds in game passed.
At 11.485370656475425 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.7554e-03,  7.0105e-01],
         [ 1.5676e-04,  3.9416e-01],
         [-7.5417e-04,  2.7600e-01],
         [-1.1818e-03,  2.1329e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.704982212637027
Current reward: 0.3798081169272424
Current mitigation activation: 0
#############################
Total reward: 24.422966548092596
11.510370656847954 seconds in game passed.
Action: tensor([[[ 6.7554e-03,  7.0105e-01],
         [ 1.5676e-04,  3.9416e-01],
         [-7.5417e-04,  2.7600e-01],
         [-1.1818e-03,  2.1329e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.422966548092596
11.535370657220483 seconds in game passed.
Action: tensor([[[ 6.7554e-03,  7.0105e-01],
         [ 1.5676e-04,  3.9416e-01],
         [-7.5417e-04,  2.7600e-01],
         [-1.1818e-03,  2.1329e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.422966548092596
11.560370657593012 seconds in game passed.
Action: tensor([[[ 6.7554e-03,  7.0105e-01],
         [ 1.5676e-04,  3.9416e-01],
         [-7.5417e-04,  2.7600e-01],
         [-1.1818e-03,  2.1329e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.422966548092596
+++++++++++++: 1.6072684992099115
11.58537065796554 seconds in game passed.
At 11.58537065796554 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.2833e-03,  7.2478e-01],
         [ 5.5020e-04,  4.0672e-01],
         [-2.7336e-04,  2.8456e-01],
         [-3.9340e-04,  2.1964e-01]]])
agent 0 action: VehicleControl(throttle=0.736982, steer=0.003685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6072684992099115
Current reward: 0.3865044872089016
Current mitigation activation: 0
#############################
Total reward: 24.8094710353015
11.61037065833807 seconds in game passed.
Action: tensor([[[ 9.2833e-03,  7.2478e-01],
         [ 5.5020e-04,  4.0672e-01],
         [-2.7336e-04,  2.8456e-01],
         [-3.9340e-04,  2.1964e-01]]])
agent 0 action: VehicleControl(throttle=0.689995, steer=0.003494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.8094710353015
11.635370658710599 seconds in game passed.
Action: tensor([[[ 9.2833e-03,  7.2478e-01],
         [ 5.5020e-04,  4.0672e-01],
         [-2.7336e-04,  2.8456e-01],
         [-3.9340e-04,  2.1964e-01]]])
agent 0 action: VehicleControl(throttle=0.630426, steer=0.003525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.8094710353015
11.660370659083128 seconds in game passed.
Action: tensor([[[ 9.2833e-03,  7.2478e-01],
         [ 5.5020e-04,  4.0672e-01],
         [-2.7336e-04,  2.8456e-01],
         [-3.9340e-04,  2.1964e-01]]])
agent 0 action: VehicleControl(throttle=0.572781, steer=0.003555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.8094710353015
+++++++++++++: 1.5145693273472098
11.685370659455657 seconds in game passed.
At 11.685370659455657 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0836e-02, 7.4905e-01],
         [2.1694e-03, 4.1372e-01],
         [1.0451e-03, 2.8939e-01],
         [5.0858e-04, 2.2415e-01]]])
agent 0 action: VehicleControl(throttle=0.529971, steer=0.005433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5145693273472098
Current reward: 0.392641839614833
Current mitigation activation: 0
#############################
Total reward: 25.20211287491633
11.710370659828186 seconds in game passed.
Action: tensor([[[1.0836e-02, 7.4905e-01],
         [2.1694e-03, 4.1372e-01],
         [1.0451e-03, 2.8939e-01],
         [5.0858e-04, 2.2415e-01]]])
agent 0 action: VehicleControl(throttle=0.507726, steer=0.005205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.20211287491633
11.735370660200715 seconds in game passed.
Action: tensor([[[1.0836e-02, 7.4905e-01],
         [2.1694e-03, 4.1372e-01],
         [1.0451e-03, 2.8939e-01],
         [5.0858e-04, 2.2415e-01]]])
agent 0 action: VehicleControl(throttle=0.483654, steer=0.005278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.20211287491633
11.760370660573244 seconds in game passed.
Action: tensor([[[1.0836e-02, 7.4905e-01],
         [2.1694e-03, 4.1372e-01],
         [1.0451e-03, 2.8939e-01],
         [5.0858e-04, 2.2415e-01]]])
agent 0 action: VehicleControl(throttle=0.460063, steer=0.005351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.20211287491633
+++++++++++++: 1.4343796777372997
11.785370660945773 seconds in game passed.
At 11.785370660945773 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4750e-02,  7.6019e-01],
         [ 1.4099e-03,  4.2303e-01],
         [-1.3007e-04,  2.9735e-01],
         [-6.3679e-04,  2.3059e-01]]])
agent 0 action: VehicleControl(throttle=0.436826, steer=0.006510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4343796777372997
Current reward: 0.39687813774441216
Current mitigation activation: 0
#############################
Total reward: 25.598991012660743
11.810370661318302 seconds in game passed.
Action: tensor([[[ 1.4750e-02,  7.6019e-01],
         [ 1.4099e-03,  4.2303e-01],
         [-1.3007e-04,  2.9735e-01],
         [-6.3679e-04,  2.3059e-01]]])
agent 0 action: VehicleControl(throttle=0.414062, steer=0.006411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.598991012660743
11.835370661690831 seconds in game passed.
Action: tensor([[[ 1.4750e-02,  7.6019e-01],
         [ 1.4099e-03,  4.2303e-01],
         [-1.3007e-04,  2.9735e-01],
         [-6.3679e-04,  2.3059e-01]]])
agent 0 action: VehicleControl(throttle=0.391769, steer=0.006493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.598991012660743
11.86037066206336 seconds in game passed.
Action: tensor([[[ 1.4750e-02,  7.6019e-01],
         [ 1.4099e-03,  4.2303e-01],
         [-1.3007e-04,  2.9735e-01],
         [-6.3679e-04,  2.3059e-01]]])
agent 0 action: VehicleControl(throttle=0.369944, steer=0.006574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.598991012660743
+++++++++++++: 1.3713583218942433
11.88537066243589 seconds in game passed.
At 11.88537066243589 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0092,  0.7901],
         [-0.0011,  0.4263],
         [-0.0030,  0.2955],
         [-0.0041,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.348075, steer=0.002415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3713583218942433
Current reward: 0.398117265171795
Current mitigation activation: 0
#############################
Total reward: 25.997108277832538
11.910370662808418 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7901],
         [-0.0011,  0.4263],
         [-0.0030,  0.2955],
         [-0.0041,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.326669, steer=0.003158, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.997108277832538
11.935370663180947 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7901],
         [-0.0011,  0.4263],
         [-0.0030,  0.2955],
         [-0.0041,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.305724, steer=0.003202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.997108277832538
11.960370663553476 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7901],
         [-0.0011,  0.4263],
         [-0.0030,  0.2955],
         [-0.0041,  0.2271]]])
agent 0 action: VehicleControl(throttle=0.285239, steer=0.003245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.997108277832538
+++++++++++++: 1.3226434298225211
11.985370663926005 seconds in game passed.
At 11.985370663926005 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0285e-02,  8.2176e-01],
         [-7.9242e-04,  4.4474e-01],
         [-3.0985e-03,  3.0773e-01],
         [-4.0541e-03,  2.3576e-01]]])
agent 0 action: VehicleControl(throttle=0.265456, steer=0.003988, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3226434298225211
Current reward: 0.39663795761953646
Current mitigation activation: 0
#############################
Total reward: 26.393746235452074
12.010370664298534 seconds in game passed.
Action: tensor([[[ 1.0285e-02,  8.2176e-01],
         [-7.9242e-04,  4.4474e-01],
         [-3.0985e-03,  3.0773e-01],
         [-4.0541e-03,  2.3576e-01]]])
agent 0 action: VehicleControl(throttle=0.246131, steer=0.003935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.393746235452074
12.035370664671063 seconds in game passed.
Action: tensor([[[ 1.0285e-02,  8.2176e-01],
         [-7.9242e-04,  4.4474e-01],
         [-3.0985e-03,  3.0773e-01],
         [-4.0541e-03,  2.3576e-01]]])
agent 0 action: VehicleControl(throttle=0.227262, steer=0.003997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.393746235452074
12.060370665043592 seconds in game passed.
Action: tensor([[[ 1.0285e-02,  8.2176e-01],
         [-7.9242e-04,  4.4474e-01],
         [-3.0985e-03,  3.0773e-01],
         [-4.0541e-03,  2.3576e-01]]])
agent 0 action: VehicleControl(throttle=0.208848, steer=0.004058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.393746235452074
+++++++++++++: 1.2857358195705935
12.085370665416121 seconds in game passed.
At 12.085370665416121 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 4.6065e-04,  1.0000e+00],
         [-5.0397e-03,  1.0000e+00],
         [-8.3732e-03,  1.0000e+00],
         [-9.4385e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002406, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2857358195705935
Current reward: 0.39285319396558627
Current mitigation activation: 1
#############################
Total reward: 26.78659942941766
12.11037066578865 seconds in game passed.
Action: tensor([[[ 4.6065e-04,  1.0000e+00],
         [-5.0397e-03,  1.0000e+00],
         [-8.3732e-03,  1.0000e+00],
         [-9.4385e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001322, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.78659942941766
12.13537066616118 seconds in game passed.
Action: tensor([[[ 4.6065e-04,  1.0000e+00],
         [-5.0397e-03,  1.0000e+00],
         [-8.3732e-03,  1.0000e+00],
         [-9.4385e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001317, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.78659942941766
12.160370666533709 seconds in game passed.
Action: tensor([[[ 4.6065e-04,  1.0000e+00],
         [-5.0397e-03,  1.0000e+00],
         [-8.3732e-03,  1.0000e+00],
         [-9.4385e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001311, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.78659942941766
+++++++++++++: 1.2620684302260503
12.185370666906238 seconds in game passed.
At 12.185370666906238 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0010,  1.0000],
         [-0.0033,  1.0000],
         [-0.0074,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000151, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2620684302260503
Current reward: 0.3865588196251397
Current mitigation activation: 1
#############################
Total reward: 27.1731582490428
12.210370667278767 seconds in game passed.
Action: tensor([[[ 0.0010,  1.0000],
         [-0.0033,  1.0000],
         [-0.0074,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000113, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.1731582490428
12.235370667651296 seconds in game passed.
Action: tensor([[[ 0.0010,  1.0000],
         [-0.0033,  1.0000],
         [-0.0074,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000131, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.1731582490428
12.260370668023825 seconds in game passed.
Action: tensor([[[ 0.0010,  1.0000],
         [-0.0033,  1.0000],
         [-0.0074,  1.0000],
         [-0.0085,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000149, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.1731582490428
+++++++++++++: 1.2804017680452267
12.285370668396354 seconds in game passed.
At 12.285370668396354 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0052,  1.0000],
         [-0.0157,  1.0000],
         [-0.0191,  1.0000],
         [-0.0178,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005450, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2804017680452267
Current reward: 0.37274810947415393
Current mitigation activation: 1
#############################
Total reward: 27.545906358516955
12.310370668768883 seconds in game passed.
Action: tensor([[[ 0.0052,  1.0000],
         [-0.0157,  1.0000],
         [-0.0191,  1.0000],
         [-0.0178,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004642, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.545906358516955
12.335370669141412 seconds in game passed.
Action: tensor([[[ 0.0052,  1.0000],
         [-0.0157,  1.0000],
         [-0.0191,  1.0000],
         [-0.0178,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004707, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.545906358516955
12.36037066951394 seconds in game passed.
Action: tensor([[[ 0.0052,  1.0000],
         [-0.0157,  1.0000],
         [-0.0191,  1.0000],
         [-0.0178,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004773, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.545906358516955
+++++++++++++: 1.3654797796146316
12.38537066988647 seconds in game passed.
At 12.38537066988647 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0045,  0.9407],
         [-0.0092,  0.5603],
         [-0.0108,  0.3664],
         [-0.0099,  0.2736]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003052, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3654797796146316
Current reward: 0.3495425728596551
Current mitigation activation: 0
#############################
Total reward: 27.89544893137661
12.410370670258999 seconds in game passed.
Action: tensor([[[ 0.0045,  0.9407],
         [-0.0092,  0.5603],
         [-0.0108,  0.3664],
         [-0.0099,  0.2736]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003428, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.89544893137661
12.435370670631528 seconds in game passed.
Action: tensor([[[ 0.0045,  0.9407],
         [-0.0092,  0.5603],
         [-0.0108,  0.3664],
         [-0.0099,  0.2736]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003504, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.89544893137661
12.460370671004057 seconds in game passed.
Action: tensor([[[ 0.0045,  0.9407],
         [-0.0092,  0.5603],
         [-0.0108,  0.3664],
         [-0.0099,  0.2736]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003580, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.89544893137661
+++++++++++++: 1.5025372597635156
12.485370671376586 seconds in game passed.
At 12.485370671376586 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0083,  0.9434],
         [-0.0123,  0.5719],
         [-0.0139,  0.3659],
         [-0.0129,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004212, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5025372597635156
Current reward: 0.323786337117153
Current mitigation activation: 0
#############################
Total reward: 28.21923526849376
12.510370671749115 seconds in game passed.
Action: tensor([[[ 0.0083,  0.9434],
         [-0.0123,  0.5719],
         [-0.0139,  0.3659],
         [-0.0129,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004207, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.21923526849376
12.535370672121644 seconds in game passed.
Action: tensor([[[ 0.0083,  0.9434],
         [-0.0123,  0.5719],
         [-0.0139,  0.3659],
         [-0.0129,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.006714, steer=-0.004294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.21923526849376
12.560370672494173 seconds in game passed.
Action: tensor([[[ 0.0083,  0.9434],
         [-0.0123,  0.5719],
         [-0.0139,  0.3659],
         [-0.0129,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.003430, steer=-0.004380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.21923526849376
+++++++++++++: 1.6869493826983966
12.585370672866702 seconds in game passed.
At 12.585370672866702 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0108,  0.9457],
         [-0.0127,  0.5949],
         [-0.0141,  0.3719],
         [-0.0114,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003409, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6869493826983966
Current reward: 0.2990421369313824
Current mitigation activation: 0
#############################
Total reward: 28.518277405425145
12.610370673239231 seconds in game passed.
Action: tensor([[[ 0.0108,  0.9457],
         [-0.0127,  0.5949],
         [-0.0141,  0.3719],
         [-0.0114,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003674, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.518277405425145
12.63537067361176 seconds in game passed.
Action: tensor([[[ 0.0108,  0.9457],
         [-0.0127,  0.5949],
         [-0.0141,  0.3719],
         [-0.0114,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.000241, steer=-0.003763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.518277405425145
12.66037067398429 seconds in game passed.
Action: tensor([[[ 0.0108,  0.9457],
         [-0.0127,  0.5949],
         [-0.0141,  0.3719],
         [-0.0114,  0.2703]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003853, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.518277405425145
+++++++++++++: 1.8733766161123449
12.685370674356818 seconds in game passed.
At 12.685370674356818 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0142,  0.9436],
         [-0.0089,  0.5811],
         [-0.0104,  0.3668],
         [-0.0078,  0.2661]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8733766161123449
Current reward: 0.2805187543477388
Current mitigation activation: 0
#############################
Total reward: 28.798796159772884
12.710370674729347 seconds in game passed.
Action: tensor([[[ 0.0142,  0.9436],
         [-0.0089,  0.5811],
         [-0.0104,  0.3668],
         [-0.0078,  0.2661]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.798796159772884
12.735370675101876 seconds in game passed.
Action: tensor([[[ 0.0142,  0.9436],
         [-0.0089,  0.5811],
         [-0.0104,  0.3668],
         [-0.0078,  0.2661]]])
agent 0 action: VehicleControl(throttle=0.013446, steer=-0.000542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.798796159772884
12.760370675474405 seconds in game passed.
Action: tensor([[[ 0.0142,  0.9436],
         [-0.0089,  0.5811],
         [-0.0104,  0.3668],
         [-0.0078,  0.2661]]])
agent 0 action: VehicleControl(throttle=0.014008, steer=-0.000606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.798796159772884
+++++++++++++: 2.0010258645367176
12.785370675846934 seconds in game passed.
At 12.785370675846934 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0850e-02, 9.4423e-01],
         [3.1037e-03, 5.7441e-01],
         [3.4842e-04, 3.6995e-01],
         [1.6093e-03, 2.6565e-01]]])
agent 0 action: VehicleControl(throttle=0.093653, steer=0.006693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0010258645367176
Current reward: 0.27070293375678295
Current mitigation activation: 0
#############################
Total reward: 29.069499093529668
12.810370676219463 seconds in game passed.
Action: tensor([[[1.0850e-02, 9.4423e-01],
         [3.1037e-03, 5.7441e-01],
         [3.4842e-04, 3.6995e-01],
         [1.6093e-03, 2.6565e-01]]])
agent 0 action: VehicleControl(throttle=0.108014, steer=0.005477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.069499093529668
12.835370676591992 seconds in game passed.
Action: tensor([[[1.0850e-02, 9.4423e-01],
         [3.1037e-03, 5.7441e-01],
         [3.4842e-04, 3.6995e-01],
         [1.6093e-03, 2.6565e-01]]])
agent 0 action: VehicleControl(throttle=0.168980, steer=0.005478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.069499093529668
12.860370676964521 seconds in game passed.
Action: tensor([[[1.0850e-02, 9.4423e-01],
         [3.1037e-03, 5.7441e-01],
         [3.4842e-04, 3.6995e-01],
         [1.6093e-03, 2.6565e-01]]])
agent 0 action: VehicleControl(throttle=0.222104, steer=0.005479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.069499093529668
+++++++++++++: 2.09780397381586
12.88537067733705 seconds in game passed.
At 12.88537067733705 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0080, 0.9406],
         [0.0057, 0.5564],
         [0.0024, 0.3661],
         [0.0022, 0.2666]]])
agent 0 action: VehicleControl(throttle=0.476896, steer=0.006118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.09780397381586
Current reward: 0.2648393682222953
Current mitigation activation: 0
#############################
Total reward: 29.334338461751962
12.91037067770958 seconds in game passed.
Action: tensor([[[0.0080, 0.9406],
         [0.0057, 0.5564],
         [0.0024, 0.3661],
         [0.0022, 0.2666]]])
agent 0 action: VehicleControl(throttle=0.503857, steer=0.006070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.334338461751962
12.935370678082108 seconds in game passed.
Action: tensor([[[0.0080, 0.9406],
         [0.0057, 0.5564],
         [0.0024, 0.3661],
         [0.0022, 0.2666]]])
agent 0 action: VehicleControl(throttle=0.548650, steer=0.006121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.334338461751962
12.960370678454638 seconds in game passed.
Action: tensor([[[0.0080, 0.9406],
         [0.0057, 0.5564],
         [0.0024, 0.3661],
         [0.0022, 0.2666]]])
agent 0 action: VehicleControl(throttle=0.588367, steer=0.006171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.334338461751962
+++++++++++++: 2.2991466856872913
12.985370678827167 seconds in game passed.
At 12.985370678827167 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.9372],
         [0.0046, 0.5417],
         [0.0013, 0.3586],
         [0.0010, 0.2627]]])
agent 0 action: VehicleControl(throttle=0.798227, steer=0.003625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2991466856872913
Current reward: 0.253904746724944
Current mitigation activation: 0
#############################
Total reward: 29.588243208476907
13.010370679199696 seconds in game passed.
Action: tensor([[[0.0040, 0.9372],
         [0.0046, 0.5417],
         [0.0013, 0.3586],
         [0.0010, 0.2627]]])
agent 0 action: VehicleControl(throttle=0.809656, steer=0.004069, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.588243208476907
13.035370679572225 seconds in game passed.
Action: tensor([[[0.0040, 0.9372],
         [0.0046, 0.5417],
         [0.0013, 0.3586],
         [0.0010, 0.2627]]])
agent 0 action: VehicleControl(throttle=0.833885, steer=0.004086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.588243208476907
13.060370679944754 seconds in game passed.
Action: tensor([[[0.0040, 0.9372],
         [0.0046, 0.5417],
         [0.0013, 0.3586],
         [0.0010, 0.2627]]])
agent 0 action: VehicleControl(throttle=0.851185, steer=0.004103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.588243208476907
+++++++++++++: 2.4324101917981555
13.085370680317283 seconds in game passed.
At 13.085370680317283 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3081e-05, 9.3869e-01],
         [4.6405e-03, 5.4682e-01],
         [2.1606e-03, 3.6175e-01],
         [1.6568e-03, 2.6581e-01]]])
agent 0 action: VehicleControl(throttle=0.801087, steer=0.002447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4324101917981555
Current reward: 0.248975357449491
Current mitigation activation: 0
#############################
Total reward: 29.8372185659264
13.110370680689812 seconds in game passed.
Action: tensor([[[1.3081e-05, 9.3869e-01],
         [4.6405e-03, 5.4682e-01],
         [2.1606e-03, 3.6175e-01],
         [1.6568e-03, 2.6581e-01]]])
agent 0 action: VehicleControl(throttle=0.811290, steer=0.002800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.8372185659264
13.13537068106234 seconds in game passed.
Action: tensor([[[1.3081e-05, 9.3869e-01],
         [4.6405e-03, 5.4682e-01],
         [2.1606e-03, 3.6175e-01],
         [1.6568e-03, 2.6581e-01]]])
agent 0 action: VehicleControl(throttle=0.810292, steer=0.002866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.8372185659264
13.16037068143487 seconds in game passed.
Action: tensor([[[1.3081e-05, 9.3869e-01],
         [4.6405e-03, 5.4682e-01],
         [2.1606e-03, 3.6175e-01],
         [1.6568e-03, 2.6581e-01]]])
agent 0 action: VehicleControl(throttle=0.805622, steer=0.002932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.8372185659264
+++++++++++++: 2.4481626864949373
13.185370681807399 seconds in game passed.
At 13.185370681807399 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.3215e-04,  9.3120e-01],
         [ 2.2960e-03,  5.2249e-01],
         [-8.7484e-04,  3.4918e-01],
         [-1.1099e-03,  2.5770e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4481626864949373
Current reward: 0.25074958047985785
Current mitigation activation: 0
#############################
Total reward: 30.087968146406258
13.210370682179928 seconds in game passed.
Action: tensor([[[ 4.3215e-04,  9.3120e-01],
         [ 2.2960e-03,  5.2249e-01],
         [-8.7484e-04,  3.4918e-01],
         [-1.1099e-03,  2.5770e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.087968146406258
13.235370682552457 seconds in game passed.
Action: tensor([[[ 4.3215e-04,  9.3120e-01],
         [ 2.2960e-03,  5.2249e-01],
         [-8.7484e-04,  3.4918e-01],
         [-1.1099e-03,  2.5770e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.087968146406258
13.260370682924986 seconds in game passed.
Action: tensor([[[ 4.3215e-04,  9.3120e-01],
         [ 2.2960e-03,  5.2249e-01],
         [-8.7484e-04,  3.4918e-01],
         [-1.1099e-03,  2.5770e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.087968146406258
+++++++++++++: 2.3826278841641977
13.285370683297515 seconds in game passed.
At 13.285370683297515 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.7131e-03,  9.1922e-01],
         [-8.2612e-04,  5.1011e-01],
         [-1.9723e-03,  3.4866e-01],
         [-9.0793e-04,  2.6233e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3826278841641977
Current reward: 0.2567007572759557
Current mitigation activation: 0
#############################
Total reward: 30.344668903682212
13.310370683670044 seconds in game passed.
Action: tensor([[[-5.7131e-03,  9.1922e-01],
         [-8.2612e-04,  5.1011e-01],
         [-1.9723e-03,  3.4866e-01],
         [-9.0793e-04,  2.6233e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.344668903682212
13.335370684042573 seconds in game passed.
Action: tensor([[[-5.7131e-03,  9.1922e-01],
         [-8.2612e-04,  5.1011e-01],
         [-1.9723e-03,  3.4866e-01],
         [-9.0793e-04,  2.6233e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.344668903682212
13.360370684415102 seconds in game passed.
Action: tensor([[[-5.7131e-03,  9.1922e-01],
         [-8.2612e-04,  5.1011e-01],
         [-1.9723e-03,  3.4866e-01],
         [-9.0793e-04,  2.6233e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002192, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.344668903682212
+++++++++++++: 2.2742516033238847
13.385370684787631 seconds in game passed.
At 13.385370684787631 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0124,  0.9237],
         [-0.0031,  0.5305],
         [-0.0044,  0.3699],
         [-0.0040,  0.2846]]])
agent 0 action: VehicleControl(throttle=0.779837, steer=-0.006834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2742516033238847
Current reward: 0.2650213279913879
Current mitigation activation: 0
#############################
Total reward: 30.6096902316736
13.41037068516016 seconds in game passed.
Action: tensor([[[-0.0124,  0.9237],
         [-0.0031,  0.5305],
         [-0.0044,  0.3699],
         [-0.0040,  0.2846]]])
agent 0 action: VehicleControl(throttle=0.782701, steer=-0.006094, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.6096902316736
13.435370685532689 seconds in game passed.
Action: tensor([[[-0.0124,  0.9237],
         [-0.0031,  0.5305],
         [-0.0044,  0.3699],
         [-0.0040,  0.2846]]])
agent 0 action: VehicleControl(throttle=0.755785, steer=-0.006123, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.6096902316736
13.460370685905218 seconds in game passed.
Action: tensor([[[-0.0124,  0.9237],
         [-0.0031,  0.5305],
         [-0.0044,  0.3699],
         [-0.0040,  0.2846]]])
agent 0 action: VehicleControl(throttle=0.729094, steer=-0.006152, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.6096902316736
+++++++++++++: 2.151028019321981
13.485370686277747 seconds in game passed.
At 13.485370686277747 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0116,  0.9133],
         [-0.0058,  0.5371],
         [-0.0070,  0.3949],
         [-0.0056,  0.3187]]])
agent 0 action: VehicleControl(throttle=0.563451, steer=-0.007937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.151028019321981
Current reward: 0.27441871167145565
Current mitigation activation: 0
#############################
Total reward: 30.884108943345055
13.510370686650276 seconds in game passed.
Action: tensor([[[-0.0116,  0.9133],
         [-0.0058,  0.5371],
         [-0.0070,  0.3949],
         [-0.0056,  0.3187]]])
agent 0 action: VehicleControl(throttle=0.550715, steer=-0.007688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.884108943345055
13.535370687022805 seconds in game passed.
Action: tensor([[[-0.0116,  0.9133],
         [-0.0058,  0.5371],
         [-0.0070,  0.3949],
         [-0.0056,  0.3187]]])
agent 0 action: VehicleControl(throttle=0.524511, steer=-0.007730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.884108943345055
13.560370687395334 seconds in game passed.
Action: tensor([[[-0.0116,  0.9133],
         [-0.0058,  0.5371],
         [-0.0070,  0.3949],
         [-0.0056,  0.3187]]])
agent 0 action: VehicleControl(throttle=0.500697, steer=-0.007771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.884108943345055
+++++++++++++: 2.0410293103199537
13.585370687767863 seconds in game passed.
At 13.585370687767863 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0054,  0.8975],
         [-0.0026,  0.5154],
         [-0.0039,  0.3728],
         [-0.0029,  0.2959]]])
agent 0 action: VehicleControl(throttle=0.711890, steer=-0.002701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0410293103199537
Current reward: 0.28310913280550504
Current mitigation activation: 0
#############################
Total reward: 31.16721807615056
13.610370688140392 seconds in game passed.
Action: tensor([[[-0.0054,  0.8975],
         [-0.0026,  0.5154],
         [-0.0039,  0.3728],
         [-0.0029,  0.2959]]])
agent 0 action: VehicleControl(throttle=0.670697, steer=-0.003546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.16721807615056
13.635370688512921 seconds in game passed.
Action: tensor([[[-0.0054,  0.8975],
         [-0.0026,  0.5154],
         [-0.0039,  0.3728],
         [-0.0029,  0.2959]]])
agent 0 action: VehicleControl(throttle=0.655921, steer=-0.003545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.16721807615056
13.66037068888545 seconds in game passed.
Action: tensor([[[-0.0054,  0.8975],
         [-0.0026,  0.5154],
         [-0.0039,  0.3728],
         [-0.0029,  0.2959]]])
agent 0 action: VehicleControl(throttle=0.641298, steer=-0.003545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.16721807615056
+++++++++++++: 1.962834201166358
13.68537068925798 seconds in game passed.
At 13.68537068925798 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0082,  0.9083],
         [-0.0011,  0.5102],
         [-0.0019,  0.3579],
         [-0.0014,  0.2767]]])
agent 0 action: VehicleControl(throttle=0.755608, steer=-0.003529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.962834201166358
Current reward: 0.2894249613129658
Current mitigation activation: 0
#############################
Total reward: 31.45664303746353
13.710370689630508 seconds in game passed.
Action: tensor([[[-0.0082,  0.9083],
         [-0.0011,  0.5102],
         [-0.0019,  0.3579],
         [-0.0014,  0.2767]]])
agent 0 action: VehicleControl(throttle=0.728898, steer=-0.003582, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.45664303746353
13.735370690003037 seconds in game passed.
Action: tensor([[[-0.0082,  0.9083],
         [-0.0011,  0.5102],
         [-0.0019,  0.3579],
         [-0.0014,  0.2767]]])
agent 0 action: VehicleControl(throttle=0.715763, steer=-0.003625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.45664303746353
13.760370690375566 seconds in game passed.
Action: tensor([[[-0.0082,  0.9083],
         [-0.0011,  0.5102],
         [-0.0019,  0.3579],
         [-0.0014,  0.2767]]])
agent 0 action: VehicleControl(throttle=0.701552, steer=-0.003668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.45664303746353
+++++++++++++: 1.8996575573149626
13.785370690748096 seconds in game passed.
At 13.785370690748096 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.9273],
         [-0.0029,  0.5181],
         [-0.0046,  0.3537],
         [-0.0038,  0.2675]]])
agent 0 action: VehicleControl(throttle=0.658409, steer=-0.003122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8996575573149626
Current reward: 0.29441099196149223
Current mitigation activation: 0
#############################
Total reward: 31.75105402942502
13.810370691120625 seconds in game passed.
Action: tensor([[[-0.0033,  0.9273],
         [-0.0029,  0.5181],
         [-0.0046,  0.3537],
         [-0.0038,  0.2675]]])
agent 0 action: VehicleControl(throttle=0.644764, steer=-0.003343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.75105402942502
13.835370691493154 seconds in game passed.
Action: tensor([[[-0.0033,  0.9273],
         [-0.0029,  0.5181],
         [-0.0046,  0.3537],
         [-0.0038,  0.2675]]])
agent 0 action: VehicleControl(throttle=0.627477, steer=-0.003455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.75105402942502
13.860370691865683 seconds in game passed.
Action: tensor([[[-0.0033,  0.9273],
         [-0.0029,  0.5181],
         [-0.0046,  0.3537],
         [-0.0038,  0.2675]]])
agent 0 action: VehicleControl(throttle=0.609941, steer=-0.003568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.75105402942502
+++++++++++++: 1.8365055179276475
13.885370692238212 seconds in game passed.
At 13.885370692238212 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0049,  0.9336],
         [-0.0045,  0.5149],
         [-0.0074,  0.3423],
         [-0.0063,  0.2532]]])
agent 0 action: VehicleControl(throttle=0.666048, steer=-0.001427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8365055179276475
Current reward: 0.2992736160999173
Current mitigation activation: 0
#############################
Total reward: 32.05032764552494
13.91037069261074 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9336],
         [-0.0045,  0.5149],
         [-0.0074,  0.3423],
         [-0.0063,  0.2532]]])
agent 0 action: VehicleControl(throttle=0.638993, steer=-0.001895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.05032764552494
13.93537069298327 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9336],
         [-0.0045,  0.5149],
         [-0.0074,  0.3423],
         [-0.0063,  0.2532]]])
agent 0 action: VehicleControl(throttle=0.619962, steer=-0.001990, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.05032764552494
13.960370693355799 seconds in game passed.
Action: tensor([[[ 0.0049,  0.9336],
         [-0.0045,  0.5149],
         [-0.0074,  0.3423],
         [-0.0063,  0.2532]]])
agent 0 action: VehicleControl(throttle=0.600470, steer=-0.002085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.05032764552494
+++++++++++++: 1.7785496597346244
13.985370693728328 seconds in game passed.
At 13.985370693728328 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0051,  0.9391],
         [-0.0019,  0.5304],
         [-0.0036,  0.3446],
         [-0.0015,  0.2524]]])
agent 0 action: VehicleControl(throttle=0.380280, steer=-0.000001, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7785496597346244
Current reward: 0.3035225213463223
Current mitigation activation: 0
#############################
Total reward: 32.35385016687126
14.010370694100857 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9391],
         [-0.0019,  0.5304],
         [-0.0036,  0.3446],
         [-0.0015,  0.2524]]])
agent 0 action: VehicleControl(throttle=0.377992, steer=-0.000402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.35385016687126
14.035370694473386 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9391],
         [-0.0019,  0.5304],
         [-0.0036,  0.3446],
         [-0.0015,  0.2524]]])
agent 0 action: VehicleControl(throttle=0.355572, steer=-0.000448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.35385016687126
14.060370694845915 seconds in game passed.
Action: tensor([[[ 0.0051,  0.9391],
         [-0.0019,  0.5304],
         [-0.0036,  0.3446],
         [-0.0015,  0.2524]]])
agent 0 action: VehicleControl(throttle=0.336287, steer=-0.000494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.35385016687126
+++++++++++++: 1.7289102274001709
14.085370695218444 seconds in game passed.
At 14.085370695218444 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.3277e-03,  9.4060e-01],
         [ 2.0839e-04,  5.4057e-01],
         [-1.6180e-03,  3.5100e-01],
         [ 5.1443e-04,  2.5573e-01]]])
agent 0 action: VehicleControl(throttle=0.234758, steer=0.002483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7289102274001709
Current reward: 0.30680569386269274
Current mitigation activation: 0
#############################
Total reward: 32.660655860733954
14.110370695590973 seconds in game passed.
Action: tensor([[[ 8.3277e-03,  9.4060e-01],
         [ 2.0839e-04,  5.4057e-01],
         [-1.6180e-03,  3.5100e-01],
         [ 5.1443e-04,  2.5573e-01]]])
agent 0 action: VehicleControl(throttle=0.235757, steer=0.001990, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.660655860733954
14.135370695963502 seconds in game passed.
Action: tensor([[[ 8.3277e-03,  9.4060e-01],
         [ 2.0839e-04,  5.4057e-01],
         [-1.6180e-03,  3.5100e-01],
         [ 5.1443e-04,  2.5573e-01]]])
agent 0 action: VehicleControl(throttle=0.226829, steer=0.001993, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.660655860733954
14.160370696336031 seconds in game passed.
Action: tensor([[[ 8.3277e-03,  9.4060e-01],
         [ 2.0839e-04,  5.4057e-01],
         [-1.6180e-03,  3.5100e-01],
         [ 5.1443e-04,  2.5573e-01]]])
agent 0 action: VehicleControl(throttle=0.218064, steer=0.001996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.660655860733954
+++++++++++++: 1.7032710769905692
14.18537069670856 seconds in game passed.
At 14.18537069670856 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0054,  0.9407],
         [-0.0023,  0.5468],
         [-0.0043,  0.3533],
         [-0.0025,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.206183, steer=-0.001139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7032710769905692
Current reward: 0.30746532739774807
Current mitigation activation: 0
#############################
Total reward: 32.968121188131704
14.210370697081089 seconds in game passed.
Action: tensor([[[ 0.0054,  0.9407],
         [-0.0023,  0.5468],
         [-0.0043,  0.3533],
         [-0.0025,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.194534, steer=-0.000632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.968121188131704
14.235370697453618 seconds in game passed.
Action: tensor([[[ 0.0054,  0.9407],
         [-0.0023,  0.5468],
         [-0.0043,  0.3533],
         [-0.0025,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.183151, steer=-0.000646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.968121188131704
14.260370697826147 seconds in game passed.
Action: tensor([[[ 0.0054,  0.9407],
         [-0.0023,  0.5468],
         [-0.0043,  0.3533],
         [-0.0025,  0.2565]]])
agent 0 action: VehicleControl(throttle=0.172067, steer=-0.000659, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.968121188131704
+++++++++++++: 1.7090643754508434
14.285370698198676 seconds in game passed.
At 14.285370698198676 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.9351],
         [-0.0011,  0.5195],
         [-0.0026,  0.3438],
         [-0.0018,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.435428, steer=-0.002766, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7090643754508434
Current reward: 0.3048126264498827
Current mitigation activation: 0
#############################
Total reward: 33.272933814581584
14.310370698571205 seconds in game passed.
Action: tensor([[[-0.0016,  0.9351],
         [-0.0011,  0.5195],
         [-0.0026,  0.3438],
         [-0.0018,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.416067, steer=-0.002397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.272933814581584
14.335370698943734 seconds in game passed.
Action: tensor([[[-0.0016,  0.9351],
         [-0.0011,  0.5195],
         [-0.0026,  0.3438],
         [-0.0018,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.426051, steer=-0.002381, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.272933814581584
14.360370699316263 seconds in game passed.
Action: tensor([[[-0.0016,  0.9351],
         [-0.0011,  0.5195],
         [-0.0026,  0.3438],
         [-0.0018,  0.2552]]])
agent 0 action: VehicleControl(throttle=0.435853, steer=-0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.272933814581584
+++++++++++++: 1.7385787332579203
14.385370699688792 seconds in game passed.
At 14.385370699688792 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0042,  0.9375],
         [-0.0011,  0.5346],
         [-0.0022,  0.3521],
         [-0.0015,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.243838, steer=-0.003463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7385787332579203
Current reward: 0.3000105608070298
Current mitigation activation: 0
#############################
Total reward: 33.572944375388616
14.410370700061321 seconds in game passed.
Action: tensor([[[-0.0042,  0.9375],
         [-0.0011,  0.5346],
         [-0.0022,  0.3521],
         [-0.0015,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.274158, steer=-0.003219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.572944375388616
14.43537070043385 seconds in game passed.
Action: tensor([[[-0.0042,  0.9375],
         [-0.0011,  0.5346],
         [-0.0022,  0.3521],
         [-0.0015,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.282650, steer=-0.003167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.572944375388616
14.46037070080638 seconds in game passed.
Action: tensor([[[-0.0042,  0.9375],
         [-0.0011,  0.5346],
         [-0.0022,  0.3521],
         [-0.0015,  0.2593]]])
agent 0 action: VehicleControl(throttle=0.292861, steer=-0.003115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.572944375388616
+++++++++++++: 1.7713776322138577
14.485370701178908 seconds in game passed.
At 14.485370701178908 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2994e-03,  9.3967e-01],
         [ 2.7276e-03,  5.5320e-01],
         [ 2.1998e-04,  3.6335e-01],
         [-1.9374e-04,  2.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.093722, steer=0.001106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7713776322138577
Current reward: 0.2953971136084074
Current mitigation activation: 0
#############################
Total reward: 33.868341488997025
14.510370701551437 seconds in game passed.
Action: tensor([[[-1.2994e-03,  9.3967e-01],
         [ 2.7276e-03,  5.5320e-01],
         [ 2.1998e-04,  3.6335e-01],
         [-1.9374e-04,  2.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.110405, steer=0.000534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.868341488997025
14.535370701923966 seconds in game passed.
Action: tensor([[[-1.2994e-03,  9.3967e-01],
         [ 2.7276e-03,  5.5320e-01],
         [ 2.1998e-04,  3.6335e-01],
         [-1.9374e-04,  2.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.117120, steer=0.000647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.868341488997025
14.560370702296495 seconds in game passed.
Action: tensor([[[-1.2994e-03,  9.3967e-01],
         [ 2.7276e-03,  5.5320e-01],
         [ 2.1998e-04,  3.6335e-01],
         [-1.9374e-04,  2.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.133329, steer=0.000760, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.868341488997025
+++++++++++++: 1.8090597528005068
14.585370702669024 seconds in game passed.
At 14.585370702669024 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0092,  0.9426],
         [-0.0017,  0.5587],
         [-0.0022,  0.3546],
         [-0.0020,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.095152, steer=-0.005987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8090597528005068
Current reward: 0.2908495688647943
Current mitigation activation: 0
#############################
Total reward: 34.15919105786182
14.610370703041553 seconds in game passed.
Action: tensor([[[-0.0092,  0.9426],
         [-0.0017,  0.5587],
         [-0.0022,  0.3546],
         [-0.0020,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.113924, steer=-0.004874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.15919105786182
14.635370703414083 seconds in game passed.
Action: tensor([[[-0.0092,  0.9426],
         [-0.0017,  0.5587],
         [-0.0022,  0.3546],
         [-0.0020,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.132565, steer=-0.004884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.15919105786182
14.660370703786612 seconds in game passed.
Action: tensor([[[-0.0092,  0.9426],
         [-0.0017,  0.5587],
         [-0.0022,  0.3546],
         [-0.0020,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.152765, steer=-0.004894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.15919105786182
+++++++++++++: 1.8679792488068252
14.68537070415914 seconds in game passed.
At 14.68537070415914 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0170,  0.9439],
         [-0.0033,  0.5647],
         [-0.0028,  0.3572],
         [-0.0019,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.103845, steer=-0.009665, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8679792488068252
Current reward: 0.2850261653598902
Current mitigation activation: 0
#############################
Total reward: 34.444217223221706
14.71037070453167 seconds in game passed.
Action: tensor([[[-0.0170,  0.9439],
         [-0.0033,  0.5647],
         [-0.0028,  0.3572],
         [-0.0019,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.131278, steer=-0.008940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.444217223221706
14.735370704904199 seconds in game passed.
Action: tensor([[[-0.0170,  0.9439],
         [-0.0033,  0.5647],
         [-0.0028,  0.3572],
         [-0.0019,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.152382, steer=-0.008999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.444217223221706
14.760370705276728 seconds in game passed.
Action: tensor([[[-0.0170,  0.9439],
         [-0.0033,  0.5647],
         [-0.0028,  0.3572],
         [-0.0019,  0.2575]]])
agent 0 action: VehicleControl(throttle=0.174511, steer=-0.009059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.444217223221706
+++++++++++++: 1.9483972750855243
14.785370705649257 seconds in game passed.
At 14.785370705649257 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0172,  0.9481],
         [-0.0053,  0.6222],
         [-0.0031,  0.3815],
         [-0.0014,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011156, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9483972750855243
Current reward: 0.2783232407211699
Current mitigation activation: 0
#############################
Total reward: 34.72254046394288
14.810370706021786 seconds in game passed.
Action: tensor([[[-0.0172,  0.9481],
         [-0.0053,  0.6222],
         [-0.0031,  0.3815],
         [-0.0014,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010909, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.72254046394288
14.835370706394315 seconds in game passed.
Action: tensor([[[-0.0172,  0.9481],
         [-0.0053,  0.6222],
         [-0.0031,  0.3815],
         [-0.0014,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.010996, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.72254046394288
14.860370706766844 seconds in game passed.
Action: tensor([[[-0.0172,  0.9481],
         [-0.0053,  0.6222],
         [-0.0031,  0.3815],
         [-0.0014,  0.2740]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011084, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.72254046394288
+++++++++++++: 2.052211272198207
14.885370707139373 seconds in game passed.
At 14.885370707139373 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2732e-02,  9.4650e-01],
         [ 3.2733e-04,  5.9248e-01],
         [ 7.2217e-04,  3.7609e-01],
         [ 1.4813e-03,  2.7248e-01]]])
agent 0 action: VehicleControl(throttle=0.043966, steer=-0.004737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.052211272198207
Current reward: 0.2710238915404765
Current mitigation activation: 0
#############################
Total reward: 34.99356435548335
14.910370707511902 seconds in game passed.
Action: tensor([[[-1.2732e-02,  9.4650e-01],
         [ 3.2733e-04,  5.9248e-01],
         [ 7.2217e-04,  3.7609e-01],
         [ 1.4813e-03,  2.7248e-01]]])
agent 0 action: VehicleControl(throttle=0.077553, steer=-0.005846, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.99356435548335
14.93537070788443 seconds in game passed.
Action: tensor([[[-1.2732e-02,  9.4650e-01],
         [ 3.2733e-04,  5.9248e-01],
         [ 7.2217e-04,  3.7609e-01],
         [ 1.4813e-03,  2.7248e-01]]])
agent 0 action: VehicleControl(throttle=0.123784, steer=-0.005891, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.99356435548335
14.96037070825696 seconds in game passed.
Action: tensor([[[-1.2732e-02,  9.4650e-01],
         [ 3.2733e-04,  5.9248e-01],
         [ 7.2217e-04,  3.7609e-01],
         [ 1.4813e-03,  2.7248e-01]]])
agent 0 action: VehicleControl(throttle=0.161101, steer=-0.005935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.99356435548335
+++++++++++++: 2.231037954756065
14.985370708629489 seconds in game passed.
At 14.985370708629489 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.1505e-03,  9.4057e-01],
         [ 2.5133e-03,  5.3774e-01],
         [ 7.1701e-04,  3.4812e-01],
         [ 9.8229e-04,  2.5229e-01]]])
agent 0 action: VehicleControl(throttle=0.842420, steer=0.000201, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.231037954756065
Current reward: 0.2603934588712966
Current mitigation activation: 0
#############################
Total reward: 35.25395781435465
15.010370709002018 seconds in game passed.
Action: tensor([[[-3.1505e-03,  9.4057e-01],
         [ 2.5133e-03,  5.3774e-01],
         [ 7.1701e-04,  3.4812e-01],
         [ 9.8229e-04,  2.5229e-01]]])
agent 0 action: VehicleControl(throttle=0.813275, steer=-0.000825, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.25395781435465
15.035370709374547 seconds in game passed.
Action: tensor([[[-3.1505e-03,  9.4057e-01],
         [ 2.5133e-03,  5.3774e-01],
         [ 7.1701e-04,  3.4812e-01],
         [ 9.8229e-04,  2.5229e-01]]])
agent 0 action: VehicleControl(throttle=0.851129, steer=-0.000827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.25395781435465
15.060370709747076 seconds in game passed.
Action: tensor([[[-3.1505e-03,  9.4057e-01],
         [ 2.5133e-03,  5.3774e-01],
         [ 7.1701e-04,  3.4812e-01],
         [ 9.8229e-04,  2.5229e-01]]])
agent 0 action: VehicleControl(throttle=0.885740, steer=-0.000830, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.25395781435465
+++++++++++++: 2.4055558557266146
15.085370710119605 seconds in game passed.
At 15.085370710119605 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.1176e-03,  9.3004e-01],
         [ 1.8139e-03,  5.0597e-01],
         [ 1.6436e-05,  3.3167e-01],
         [ 2.8291e-04,  2.4040e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4055558557266146
Current reward: 0.2524170599071943
Current mitigation activation: 0
#############################
Total reward: 35.506374874261844
15.110370710492134 seconds in game passed.
Action: tensor([[[-3.1176e-03,  9.3004e-01],
         [ 1.8139e-03,  5.0597e-01],
         [ 1.6436e-05,  3.3167e-01],
         [ 2.8291e-04,  2.4040e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.506374874261844
15.135370710864663 seconds in game passed.
Action: tensor([[[-3.1176e-03,  9.3004e-01],
         [ 1.8139e-03,  5.0597e-01],
         [ 1.6436e-05,  3.3167e-01],
         [ 2.8291e-04,  2.4040e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.506374874261844
15.160370711237192 seconds in game passed.
Action: tensor([[[-3.1176e-03,  9.3004e-01],
         [ 1.8139e-03,  5.0597e-01],
         [ 1.6436e-05,  3.3167e-01],
         [ 2.8291e-04,  2.4040e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.506374874261844
+++++++++++++: 2.5089699616486683
15.185370711609721 seconds in game passed.
At 15.185370711609721 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.1130e-03, 9.2138e-01],
         [3.5107e-03, 4.9604e-01],
         [6.1586e-04, 3.2847e-01],
         [4.9675e-04, 2.3915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5089699616486683
Current reward: 0.24959819098100972
Current mitigation activation: 0
#############################
Total reward: 35.755973065242856
15.21037071198225 seconds in game passed.
Action: tensor([[[3.1130e-03, 9.2138e-01],
         [3.5107e-03, 4.9604e-01],
         [6.1586e-04, 3.2847e-01],
         [4.9675e-04, 2.3915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.755973065242856
15.23537071235478 seconds in game passed.
Action: tensor([[[3.1130e-03, 9.2138e-01],
         [3.5107e-03, 4.9604e-01],
         [6.1586e-04, 3.2847e-01],
         [4.9675e-04, 2.3915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001970, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.755973065242856
15.260370712727308 seconds in game passed.
Action: tensor([[[3.1130e-03, 9.2138e-01],
         [3.5107e-03, 4.9604e-01],
         [6.1586e-04, 3.2847e-01],
         [4.9675e-04, 2.3915e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.755973065242856
+++++++++++++: 2.483957400974085
15.285370713099837 seconds in game passed.
At 15.285370713099837 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2461e-02,  9.0530e-01],
         [ 3.1138e-03,  4.8483e-01],
         [-1.9909e-04,  3.2305e-01],
         [-1.3303e-04,  2.3490e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.483957400974085
Current reward: 0.25348579028790896
Current mitigation activation: 0
#############################
Total reward: 36.00945885553077
15.310370713472366 seconds in game passed.
Action: tensor([[[ 1.2461e-02,  9.0530e-01],
         [ 3.1138e-03,  4.8483e-01],
         [-1.9909e-04,  3.2305e-01],
         [-1.3303e-04,  2.3490e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.00945885553077
15.335370713844895 seconds in game passed.
Action: tensor([[[ 1.2461e-02,  9.0530e-01],
         [ 3.1138e-03,  4.8483e-01],
         [-1.9909e-04,  3.2305e-01],
         [-1.3303e-04,  2.3490e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.00945885553077
15.360370714217424 seconds in game passed.
Action: tensor([[[ 1.2461e-02,  9.0530e-01],
         [ 3.1138e-03,  4.8483e-01],
         [-1.9909e-04,  3.2305e-01],
         [-1.3303e-04,  2.3490e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.00945885553077
+++++++++++++: 2.388793277954936
15.385370714589953 seconds in game passed.
At 15.385370714589953 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4386e-02, 8.9693e-01],
         [3.3907e-03, 4.8478e-01],
         [5.6115e-04, 3.2498e-01],
         [7.3782e-04, 2.3654e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.388793277954936
Current reward: 0.26093597364754295
Current mitigation activation: 0
#############################
Total reward: 36.27039482917831
15.410370714962482 seconds in game passed.
Action: tensor([[[1.4386e-02, 8.9693e-01],
         [3.3907e-03, 4.8478e-01],
         [5.6115e-04, 3.2498e-01],
         [7.3782e-04, 2.3654e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.27039482917831
15.435370715335011 seconds in game passed.
Action: tensor([[[1.4386e-02, 8.9693e-01],
         [3.3907e-03, 4.8478e-01],
         [5.6115e-04, 3.2498e-01],
         [7.3782e-04, 2.3654e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.27039482917831
15.46037071570754 seconds in game passed.
Action: tensor([[[1.4386e-02, 8.9693e-01],
         [3.3907e-03, 4.8478e-01],
         [5.6115e-04, 3.2498e-01],
         [7.3782e-04, 2.3654e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.27039482917831
+++++++++++++: 2.373191697042791
15.48537071608007 seconds in game passed.
At 15.48537071608007 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0147, 0.9033],
         [0.0031, 0.4873],
         [0.0011, 0.3260],
         [0.0014, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.373191697042791
Current reward: 0.2638300623450011
Current mitigation activation: 0
#############################
Total reward: 36.53422489152331
15.510370716452599 seconds in game passed.
Action: tensor([[[0.0147, 0.9033],
         [0.0031, 0.4873],
         [0.0011, 0.3260],
         [0.0014, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.53422489152331
15.535370716825128 seconds in game passed.
Action: tensor([[[0.0147, 0.9033],
         [0.0031, 0.4873],
         [0.0011, 0.3260],
         [0.0014, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.53422489152331
15.560370717197657 seconds in game passed.
Action: tensor([[[0.0147, 0.9033],
         [0.0031, 0.4873],
         [0.0011, 0.3260],
         [0.0014, 0.2373]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.53422489152331
+++++++++++++: 2.394684917217118
15.585370717570186 seconds in game passed.
At 15.585370717570186 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0118, 0.8949],
         [0.0031, 0.4732],
         [0.0015, 0.3176],
         [0.0021, 0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.394684917217118
Current reward: 0.26453208024620917
Current mitigation activation: 0
#############################
Total reward: 36.79875697176952
15.610370717942715 seconds in game passed.
Action: tensor([[[0.0118, 0.8949],
         [0.0031, 0.4732],
         [0.0015, 0.3176],
         [0.0021, 0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.79875697176952
15.635370718315244 seconds in game passed.
Action: tensor([[[0.0118, 0.8949],
         [0.0031, 0.4732],
         [0.0015, 0.3176],
         [0.0021, 0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.79875697176952
15.660370718687773 seconds in game passed.
Action: tensor([[[0.0118, 0.8949],
         [0.0031, 0.4732],
         [0.0015, 0.3176],
         [0.0021, 0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.79875697176952
+++++++++++++: 2.4159871042608825
15.685370719060302 seconds in game passed.
At 15.685370719060302 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.6606e-03, 8.8793e-01],
         [1.3788e-03, 4.6576e-01],
         [7.3823e-04, 3.1272e-01],
         [1.5348e-03, 2.2992e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4159871042608825
Current reward: 0.2652629595730659
Current mitigation activation: 0
#############################
Total reward: 37.064019931342585
15.71037071943283 seconds in game passed.
Action: tensor([[[3.6606e-03, 8.8793e-01],
         [1.3788e-03, 4.6576e-01],
         [7.3823e-04, 3.1272e-01],
         [1.5348e-03, 2.2992e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002714, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.064019931342585
15.73537071980536 seconds in game passed.
Action: tensor([[[3.6606e-03, 8.8793e-01],
         [1.3788e-03, 4.6576e-01],
         [7.3823e-04, 3.1272e-01],
         [1.5348e-03, 2.2992e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.064019931342585
15.760370720177889 seconds in game passed.
Action: tensor([[[3.6606e-03, 8.8793e-01],
         [1.3788e-03, 4.6576e-01],
         [7.3823e-04, 3.1272e-01],
         [1.5348e-03, 2.2992e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.064019931342585
+++++++++++++: 2.4375217329041874
15.785370720550418 seconds in game passed.
At 15.785370720550418 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0027,  0.8819],
         [-0.0013,  0.4633],
         [-0.0022,  0.3123],
         [-0.0016,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4375217329041874
Current reward: 0.2659963264354101
Current mitigation activation: 0
#############################
Total reward: 37.330016257778
15.810370720922947 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8819],
         [-0.0013,  0.4633],
         [-0.0022,  0.3123],
         [-0.0016,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.330016257778
15.835370721295476 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8819],
         [-0.0013,  0.4633],
         [-0.0022,  0.3123],
         [-0.0016,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.330016257778
15.860370721668005 seconds in game passed.
Action: tensor([[[ 0.0027,  0.8819],
         [-0.0013,  0.4633],
         [-0.0022,  0.3123],
         [-0.0016,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.330016257778
+++++++++++++: 2.4567513266479764
15.885370722040534 seconds in game passed.
At 15.885370722040534 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0026,  0.8790],
         [-0.0009,  0.4631],
         [-0.0023,  0.3109],
         [-0.0016,  0.2293]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4567513266479764
Current reward: 0.2668694227702322
Current mitigation activation: 0
#############################
Total reward: 37.59688568054823
15.910370722413063 seconds in game passed.
Action: tensor([[[ 0.0026,  0.8790],
         [-0.0009,  0.4631],
         [-0.0023,  0.3109],
         [-0.0016,  0.2293]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.59688568054823
15.935370722785592 seconds in game passed.
Action: tensor([[[ 0.0026,  0.8790],
         [-0.0009,  0.4631],
         [-0.0023,  0.3109],
         [-0.0016,  0.2293]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.59688568054823
15.960370723158121 seconds in game passed.
Action: tensor([[[ 0.0026,  0.8790],
         [-0.0009,  0.4631],
         [-0.0023,  0.3109],
         [-0.0016,  0.2293]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.59688568054823
+++++++++++++: 2.3394436426659864
15.98537072353065 seconds in game passed.
At 15.98537072353065 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0038,  0.8946],
         [-0.0011,  0.4673],
         [-0.0035,  0.3112],
         [-0.0039,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3394436426659864
Current reward: 0.2753867116766272
Current mitigation activation: 0
#############################
Total reward: 37.87227239222486
16.01037072390318 seconds in game passed.
Action: tensor([[[ 0.0038,  0.8946],
         [-0.0011,  0.4673],
         [-0.0035,  0.3112],
         [-0.0039,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.87227239222486
16.035370724275708 seconds in game passed.
Action: tensor([[[ 0.0038,  0.8946],
         [-0.0011,  0.4673],
         [-0.0035,  0.3112],
         [-0.0039,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.87227239222486
16.060370724648237 seconds in game passed.
Action: tensor([[[ 0.0038,  0.8946],
         [-0.0011,  0.4673],
         [-0.0035,  0.3112],
         [-0.0039,  0.2288]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.87227239222486
+++++++++++++: 2.1757502882649296
16.085370725020766 seconds in game passed.
At 16.085370725020766 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.8788],
         [-0.0021,  0.4528],
         [-0.0039,  0.3013],
         [-0.0037,  0.2217]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1757502882649296
Current reward: 0.28716234148360725
Current mitigation activation: 0
#############################
Total reward: 38.159434733708466
16.110370725393295 seconds in game passed.
Action: tensor([[[-0.0035,  0.8788],
         [-0.0021,  0.4528],
         [-0.0039,  0.3013],
         [-0.0037,  0.2217]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000883, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.159434733708466
16.135370725765824 seconds in game passed.
Action: tensor([[[-0.0035,  0.8788],
         [-0.0021,  0.4528],
         [-0.0039,  0.3013],
         [-0.0037,  0.2217]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.159434733708466
16.160370726138353 seconds in game passed.
Action: tensor([[[-0.0035,  0.8788],
         [-0.0021,  0.4528],
         [-0.0039,  0.3013],
         [-0.0037,  0.2217]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000946, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.159434733708466
+++++++++++++: 2.036650718350503
16.185370726510882 seconds in game passed.
At 16.185370726510882 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0036,  0.8758],
         [-0.0032,  0.4538],
         [-0.0048,  0.3057],
         [-0.0041,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.036650718350503
Current reward: 0.2977892826531601
Current mitigation activation: 0
#############################
Total reward: 38.45722401636163
16.21037072688341 seconds in game passed.
Action: tensor([[[ 0.0036,  0.8758],
         [-0.0032,  0.4538],
         [-0.0048,  0.3057],
         [-0.0041,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.45722401636163
16.23537072725594 seconds in game passed.
Action: tensor([[[ 0.0036,  0.8758],
         [-0.0032,  0.4538],
         [-0.0048,  0.3057],
         [-0.0041,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.45722401636163
16.26037072762847 seconds in game passed.
Action: tensor([[[ 0.0036,  0.8758],
         [-0.0032,  0.4538],
         [-0.0048,  0.3057],
         [-0.0041,  0.2265]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.45722401636163
+++++++++++++: 1.9123623780240697
16.285370728001 seconds in game passed.
At 16.285370728001 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0029,  0.8849],
         [-0.0022,  0.4597],
         [-0.0043,  0.3065],
         [-0.0041,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9123623780240697
Current reward: 0.3076537829247713
Current mitigation activation: 0
#############################
Total reward: 38.7648777992864
16.310370728373528 seconds in game passed.
Action: tensor([[[ 0.0029,  0.8849],
         [-0.0022,  0.4597],
         [-0.0043,  0.3065],
         [-0.0041,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.7648777992864
16.335370728746057 seconds in game passed.
Action: tensor([[[ 0.0029,  0.8849],
         [-0.0022,  0.4597],
         [-0.0043,  0.3065],
         [-0.0041,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.7648777992864
16.360370729118586 seconds in game passed.
Action: tensor([[[ 0.0029,  0.8849],
         [-0.0022,  0.4597],
         [-0.0043,  0.3065],
         [-0.0041,  0.2261]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.7648777992864
+++++++++++++: 1.7982077263378815
16.385370729491115 seconds in game passed.
At 16.385370729491115 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.4639e-05,  8.8137e-01],
         [-1.3814e-03,  4.5879e-01],
         [-3.4505e-03,  3.0942e-01],
         [-3.5875e-03,  2.3091e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7982077263378815
Current reward: 0.3169385379752529
Current mitigation activation: 0
#############################
Total reward: 39.08181633726166
16.410370729863644 seconds in game passed.
Action: tensor([[[ 7.4639e-05,  8.8137e-01],
         [-1.3814e-03,  4.5879e-01],
         [-3.4505e-03,  3.0942e-01],
         [-3.5875e-03,  2.3091e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000088, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.08181633726166
16.435370730236173 seconds in game passed.
Action: tensor([[[ 7.4639e-05,  8.8137e-01],
         [-1.3814e-03,  4.5879e-01],
         [-3.4505e-03,  3.0942e-01],
         [-3.5875e-03,  2.3091e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.08181633726166
16.4603707306087 seconds in game passed.
Action: tensor([[[ 7.4639e-05,  8.8137e-01],
         [-1.3814e-03,  4.5879e-01],
         [-3.4505e-03,  3.0942e-01],
         [-3.5875e-03,  2.3091e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.08181633726166
+++++++++++++: 1.6918943541523783
16.48537073098123 seconds in game passed.
At 16.48537073098123 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.3205e-04,  9.0901e-01],
         [ 5.7406e-04,  4.7399e-01],
         [-2.2321e-03,  3.1527e-01],
         [-2.8940e-03,  2.3254e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6918943541523783
Current reward: 0.3257216600067363
Current mitigation activation: 0
#############################
Total reward: 39.40753799726839
16.51037073135376 seconds in game passed.
Action: tensor([[[-4.3205e-04,  9.0901e-01],
         [ 5.7406e-04,  4.7399e-01],
         [-2.2321e-03,  3.1527e-01],
         [-2.8940e-03,  2.3254e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.40753799726839
16.53537073172629 seconds in game passed.
Action: tensor([[[-4.3205e-04,  9.0901e-01],
         [ 5.7406e-04,  4.7399e-01],
         [-2.2321e-03,  3.1527e-01],
         [-2.8940e-03,  2.3254e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.40753799726839
16.560370732098818 seconds in game passed.
Action: tensor([[[-4.3205e-04,  9.0901e-01],
         [ 5.7406e-04,  4.7399e-01],
         [-2.2321e-03,  3.1527e-01],
         [-2.8940e-03,  2.3254e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.40753799726839
+++++++++++++: 1.5931035703406702
16.585370732471347 seconds in game passed.
At 16.585370732471347 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0110,  0.9031],
         [ 0.0025,  0.4942],
         [-0.0022,  0.3381],
         [-0.0041,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.528397, steer=0.006675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5931035703406702
Current reward: 0.3341084132399478
Current mitigation activation: 0
#############################
Total reward: 39.74164641050834
16.610370732843876 seconds in game passed.
Action: tensor([[[ 0.0110,  0.9031],
         [ 0.0025,  0.4942],
         [-0.0022,  0.3381],
         [-0.0041,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.527113, steer=0.005630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.74164641050834
16.635370733216405 seconds in game passed.
Action: tensor([[[ 0.0110,  0.9031],
         [ 0.0025,  0.4942],
         [-0.0022,  0.3381],
         [-0.0041,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.512663, steer=0.005624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.74164641050834
16.660370733588934 seconds in game passed.
Action: tensor([[[ 0.0110,  0.9031],
         [ 0.0025,  0.4942],
         [-0.0022,  0.3381],
         [-0.0041,  0.2527]]])
agent 0 action: VehicleControl(throttle=0.495297, steer=0.005617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.74164641050834
+++++++++++++: 1.503123781855998
16.685370733961463 seconds in game passed.
At 16.685370733961463 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.3178e-03, 9.2850e-01],
         [5.2104e-03, 5.2455e-01],
         [1.3844e-03, 3.5418e-01],
         [3.0886e-04, 2.6306e-01]]])
agent 0 action: VehicleControl(throttle=0.476846, steer=0.004487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.503123781855998
Current reward: 0.34202598271605344
Current mitigation activation: 0
#############################
Total reward: 40.08367239322439
16.710370734333992 seconds in game passed.
Action: tensor([[[3.3178e-03, 9.2850e-01],
         [5.2104e-03, 5.2455e-01],
         [1.3844e-03, 3.5418e-01],
         [3.0886e-04, 2.6306e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004709, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.08367239322439
16.73537073470652 seconds in game passed.
Action: tensor([[[3.3178e-03, 9.2850e-01],
         [5.2104e-03, 5.2455e-01],
         [1.3844e-03, 3.5418e-01],
         [3.0886e-04, 2.6306e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004739, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.08367239322439
16.76037073507905 seconds in game passed.
Action: tensor([[[3.3178e-03, 9.2850e-01],
         [5.2104e-03, 5.2455e-01],
         [1.3844e-03, 3.5418e-01],
         [3.0886e-04, 2.6306e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004768, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.08367239322439
+++++++++++++: 1.4357143740156675
16.78537073545158 seconds in game passed.
At 16.78537073545158 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.9357],
         [0.0073, 0.5350],
         [0.0035, 0.3617],
         [0.0024, 0.2678]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006372, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4357143740156675
Current reward: 0.3474100227035568
Current mitigation activation: 0
#############################
Total reward: 40.431082415927946
16.810370735824108 seconds in game passed.
Action: tensor([[[0.0031, 0.9357],
         [0.0073, 0.5350],
         [0.0035, 0.3617],
         [0.0024, 0.2678]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006187, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.431082415927946
16.835370736196637 seconds in game passed.
Action: tensor([[[0.0031, 0.9357],
         [0.0073, 0.5350],
         [0.0035, 0.3617],
         [0.0024, 0.2678]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006257, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.431082415927946
16.860370736569166 seconds in game passed.
Action: tensor([[[0.0031, 0.9357],
         [0.0073, 0.5350],
         [0.0035, 0.3617],
         [0.0024, 0.2678]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.006327, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.431082415927946
+++++++++++++: 1.4305177133802038
16.885370736941695 seconds in game passed.
At 16.885370736941695 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0182, 0.9320],
         [0.0073, 0.5291],
         [0.0036, 0.3557],
         [0.0029, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.328436, steer=0.012902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4305177133802038
Current reward: 0.34410581585994715
Current mitigation activation: 0
#############################
Total reward: 40.775188231787894
16.910370737314224 seconds in game passed.
Action: tensor([[[0.0182, 0.9320],
         [0.0073, 0.5291],
         [0.0036, 0.3557],
         [0.0029, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.310637, steer=0.011964, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.775188231787894
16.935370737686753 seconds in game passed.
Action: tensor([[[0.0182, 0.9320],
         [0.0073, 0.5291],
         [0.0036, 0.3557],
         [0.0029, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.293398, steer=0.012099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.775188231787894
16.960370738059282 seconds in game passed.
Action: tensor([[[0.0182, 0.9320],
         [0.0073, 0.5291],
         [0.0036, 0.3557],
         [0.0029, 0.2607]]])
agent 0 action: VehicleControl(throttle=0.276703, steer=0.012234, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.775188231787894
+++++++++++++: 1.5139076890428766
16.98537073843181 seconds in game passed.
At 16.98537073843181 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0253, 0.9298],
         [0.0060, 0.5305],
         [0.0013, 0.3565],
         [0.0012, 0.2616]]])
agent 0 action: VehicleControl(throttle=0.260532, steer=0.014426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5139076890428766
Current reward: 0.32972690851619846
Current mitigation activation: 0
#############################
Total reward: 41.104915140304094
17.01037073880434 seconds in game passed.
Action: tensor([[[0.0253, 0.9298],
         [0.0060, 0.5305],
         [0.0013, 0.3565],
         [0.0012, 0.2616]]])
agent 0 action: VehicleControl(throttle=0.244881, steer=0.014239, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.104915140304094
17.03537073917687 seconds in game passed.
Action: tensor([[[0.0253, 0.9298],
         [0.0060, 0.5305],
         [0.0013, 0.3565],
         [0.0012, 0.2616]]])
agent 0 action: VehicleControl(throttle=0.229740, steer=0.014392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.104915140304094
17.0603707395494 seconds in game passed.
Action: tensor([[[0.0253, 0.9298],
         [0.0060, 0.5305],
         [0.0013, 0.3565],
         [0.0012, 0.2616]]])
agent 0 action: VehicleControl(throttle=0.215101, steer=0.014545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.104915140304094
+++++++++++++: 1.5831098999707565
17.085370739921927 seconds in game passed.
At 17.085370739921927 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0126,  0.9358],
         [-0.0015,  0.5488],
         [-0.0059,  0.3684],
         [-0.0054,  0.2709]]])
agent 0 action: VehicleControl(throttle=0.198854, steer=0.003625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5831098999707565
Current reward: 0.3202252046654772
Current mitigation activation: 0
#############################
Total reward: 41.42514034496957
17.110370740294456 seconds in game passed.
Action: tensor([[[ 0.0126,  0.9358],
         [-0.0015,  0.5488],
         [-0.0059,  0.3684],
         [-0.0054,  0.2709]]])
agent 0 action: VehicleControl(throttle=0.183097, steer=0.005534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.42514034496957
17.135370740666986 seconds in game passed.
Action: tensor([[[ 0.0126,  0.9358],
         [-0.0015,  0.5488],
         [-0.0059,  0.3684],
         [-0.0054,  0.2709]]])
agent 0 action: VehicleControl(throttle=0.167822, steer=0.005610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.42514034496957
17.160370741039515 seconds in game passed.
Action: tensor([[[ 0.0126,  0.9358],
         [-0.0015,  0.5488],
         [-0.0059,  0.3684],
         [-0.0054,  0.2709]]])
agent 0 action: VehicleControl(throttle=0.153029, steer=0.005686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.42514034496957
+++++++++++++: 1.6233482951390508
17.185370741412044 seconds in game passed.
At 17.185370741412044 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0183,  0.9365],
         [ 0.0014,  0.5317],
         [-0.0044,  0.3494],
         [-0.0052,  0.2554]]])
agent 0 action: VehicleControl(throttle=0.139100, steer=0.010273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6233482951390508
Current reward: 0.31611007422909587
Current mitigation activation: 0
#############################
Total reward: 41.741250419198664
17.210370741784573 seconds in game passed.
Action: tensor([[[ 0.0183,  0.9365],
         [ 0.0014,  0.5317],
         [-0.0044,  0.3494],
         [-0.0052,  0.2554]]])
agent 0 action: VehicleControl(throttle=0.125642, steer=0.009628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.741250419198664
17.2353707421571 seconds in game passed.
Action: tensor([[[ 0.0183,  0.9365],
         [ 0.0014,  0.5317],
         [-0.0044,  0.3494],
         [-0.0052,  0.2554]]])
agent 0 action: VehicleControl(throttle=0.112654, steer=0.009730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.741250419198664
17.26037074252963 seconds in game passed.
Action: tensor([[[ 0.0183,  0.9365],
         [ 0.0014,  0.5317],
         [-0.0044,  0.3494],
         [-0.0052,  0.2554]]])
agent 0 action: VehicleControl(throttle=0.100132, steer=0.009832, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.741250419198664
+++++++++++++: 1.6673292577890944
17.28537074290216 seconds in game passed.
At 17.28537074290216 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0470e-02,  9.3214e-01],
         [-5.1235e-04,  5.2619e-01],
         [-5.3390e-03,  3.5024e-01],
         [-6.1722e-03,  2.5845e-01]]])
agent 0 action: VehicleControl(throttle=0.147580, steer=0.005112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6673292577890944
Current reward: 0.31283053204356753
Current mitigation activation: 0
#############################
Total reward: 42.054080951242234
17.31037074327469 seconds in game passed.
Action: tensor([[[ 1.0470e-02,  9.3214e-01],
         [-5.1235e-04,  5.2619e-01],
         [-5.3390e-03,  3.5024e-01],
         [-6.1722e-03,  2.5845e-01]]])
agent 0 action: VehicleControl(throttle=0.148529, steer=0.005954, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.054080951242234
17.335370743647218 seconds in game passed.
Action: tensor([[[ 1.0470e-02,  9.3214e-01],
         [-5.1235e-04,  5.2619e-01],
         [-5.3390e-03,  3.5024e-01],
         [-6.1722e-03,  2.5845e-01]]])
agent 0 action: VehicleControl(throttle=0.154668, steer=0.006002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.054080951242234
17.360370744019747 seconds in game passed.
Action: tensor([[[ 1.0470e-02,  9.3214e-01],
         [-5.1235e-04,  5.2619e-01],
         [-5.3390e-03,  3.5024e-01],
         [-6.1722e-03,  2.5845e-01]]])
agent 0 action: VehicleControl(throttle=0.161246, steer=0.006050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.054080951242234
+++++++++++++: 1.7203564158557787
17.385370744392276 seconds in game passed.
At 17.385370744392276 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0026,  0.9227],
         [-0.0085,  0.5180],
         [-0.0129,  0.3449],
         [-0.0129,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.243307, steer=-0.003353, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7203564158557787
Current reward: 0.309797811112444
Current mitigation activation: 0
#############################
Total reward: 42.36387876235468
17.410370744764805 seconds in game passed.
Action: tensor([[[ 0.0026,  0.9227],
         [-0.0085,  0.5180],
         [-0.0129,  0.3449],
         [-0.0129,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.229016, steer=-0.001837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.36387876235468
17.435370745137334 seconds in game passed.
Action: tensor([[[ 0.0026,  0.9227],
         [-0.0085,  0.5180],
         [-0.0129,  0.3449],
         [-0.0129,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.224620, steer=-0.001882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.36387876235468
17.460370745509863 seconds in game passed.
Action: tensor([[[ 0.0026,  0.9227],
         [-0.0085,  0.5180],
         [-0.0129,  0.3449],
         [-0.0129,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.220565, steer=-0.001926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.36387876235468
+++++++++++++: 1.7573268342108164
17.485370745882392 seconds in game passed.
At 17.485370745882392 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.9283],
         [-0.0065,  0.5013],
         [-0.0111,  0.3296],
         [-0.0121,  0.2424]]])
agent 0 action: VehicleControl(throttle=0.496678, steer=-0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7573268342108164
Current reward: 0.3094991457663248
Current mitigation activation: 0
#############################
Total reward: 42.673377908121005
17.51037074625492 seconds in game passed.
Action: tensor([[[-0.0019,  0.9283],
         [-0.0065,  0.5013],
         [-0.0111,  0.3296],
         [-0.0121,  0.2424]]])
agent 0 action: VehicleControl(throttle=0.468285, steer=-0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.673377908121005
17.53537074662745 seconds in game passed.
Action: tensor([[[-0.0019,  0.9283],
         [-0.0065,  0.5013],
         [-0.0111,  0.3296],
         [-0.0121,  0.2424]]])
agent 0 action: VehicleControl(throttle=0.469713, steer=-0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.673377908121005
17.56037074699998 seconds in game passed.
Action: tensor([[[-0.0019,  0.9283],
         [-0.0065,  0.5013],
         [-0.0111,  0.3296],
         [-0.0121,  0.2424]]])
agent 0 action: VehicleControl(throttle=0.471508, steer=-0.002591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.673377908121005
+++++++++++++: 1.7847598847551354
17.585370747372508 seconds in game passed.
At 17.585370747372508 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0043,  0.9169],
         [-0.0099,  0.4822],
         [-0.0143,  0.3234],
         [-0.0151,  0.2438]]])
agent 0 action: VehicleControl(throttle=0.735002, steer=-0.006236, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7847598847551354
Current reward: 0.3109097972480769
Current mitigation activation: 0
#############################
Total reward: 42.984287705369084
17.610370747745037 seconds in game passed.
Action: tensor([[[-0.0043,  0.9169],
         [-0.0099,  0.4822],
         [-0.0143,  0.3234],
         [-0.0151,  0.2438]]])
agent 0 action: VehicleControl(throttle=0.717115, steer=-0.005820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.984287705369084
17.635370748117566 seconds in game passed.
Action: tensor([[[-0.0043,  0.9169],
         [-0.0099,  0.4822],
         [-0.0143,  0.3234],
         [-0.0151,  0.2438]]])
agent 0 action: VehicleControl(throttle=0.726490, steer=-0.005985, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.984287705369084
17.660370748490095 seconds in game passed.
Action: tensor([[[-0.0043,  0.9169],
         [-0.0099,  0.4822],
         [-0.0143,  0.3234],
         [-0.0151,  0.2438]]])
agent 0 action: VehicleControl(throttle=0.735864, steer=-0.006149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.984287705369084
+++++++++++++: 1.8158502427443772
17.685370748862624 seconds in game passed.
At 17.685370748862624 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0064,  0.8572],
         [-0.0118,  0.4570],
         [-0.0163,  0.3157],
         [-0.0177,  0.2425]]])
agent 0 action: VehicleControl(throttle=0.896066, steer=-0.008557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8158502427443772
Current reward: 0.3125651337438832
Current mitigation activation: 0
#############################
Total reward: 43.296852839112965
17.710370749235153 seconds in game passed.
Action: tensor([[[-0.0064,  0.8572],
         [-0.0118,  0.4570],
         [-0.0163,  0.3157],
         [-0.0177,  0.2425]]])
agent 0 action: VehicleControl(throttle=0.891131, steer=-0.008361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.296852839112965
17.735370749607682 seconds in game passed.
Action: tensor([[[-0.0064,  0.8572],
         [-0.0118,  0.4570],
         [-0.0163,  0.3157],
         [-0.0177,  0.2425]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.296852839112965
17.76037074998021 seconds in game passed.
Action: tensor([[[-0.0064,  0.8572],
         [-0.0118,  0.4570],
         [-0.0163,  0.3157],
         [-0.0177,  0.2425]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008711, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.296852839112965
+++++++++++++: 1.8504880187956547
17.78537075035274 seconds in game passed.
At 17.78537075035274 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0065,  0.8619],
         [-0.0135,  0.4578],
         [-0.0176,  0.3120],
         [-0.0185,  0.2363]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8504880187956547
Current reward: 0.3144574017665752
Current mitigation activation: 0
#############################
Total reward: 43.61131024087954
17.81037075072527 seconds in game passed.
Action: tensor([[[-0.0065,  0.8619],
         [-0.0135,  0.4578],
         [-0.0176,  0.3120],
         [-0.0185,  0.2363]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.61131024087954
17.8353707510978 seconds in game passed.
Action: tensor([[[-0.0065,  0.8619],
         [-0.0135,  0.4578],
         [-0.0176,  0.3120],
         [-0.0185,  0.2363]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.61131024087954
17.860370751470327 seconds in game passed.
Action: tensor([[[-0.0065,  0.8619],
         [-0.0135,  0.4578],
         [-0.0176,  0.3120],
         [-0.0185,  0.2363]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.61131024087954
+++++++++++++: 1.8886137000201046
17.885370751842856 seconds in game passed.
At 17.885370751842856 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.8490],
         [-0.0101,  0.4516],
         [-0.0134,  0.3097],
         [-0.0141,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8886137000201046
Current reward: 0.3165858087424141
Current mitigation activation: 0
#############################
Total reward: 43.92789604962196
17.910370752215385 seconds in game passed.
Action: tensor([[[-0.0021,  0.8490],
         [-0.0101,  0.4516],
         [-0.0134,  0.3097],
         [-0.0141,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.92789604962196
17.935370752587914 seconds in game passed.
Action: tensor([[[-0.0021,  0.8490],
         [-0.0101,  0.4516],
         [-0.0134,  0.3097],
         [-0.0141,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.92789604962196
17.960370752960443 seconds in game passed.
Action: tensor([[[-0.0021,  0.8490],
         [-0.0101,  0.4516],
         [-0.0134,  0.3097],
         [-0.0141,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007970, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.92789604962196
+++++++++++++: 2.011349916325976
17.985370753332973 seconds in game passed.
At 17.985370753332973 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0010,  0.8624],
         [-0.0102,  0.4527],
         [-0.0149,  0.3049],
         [-0.0172,  0.2276]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.011349916325976
Current reward: 0.3119753489278872
Current mitigation activation: 0
#############################
Total reward: 44.239871398549845
18.0103707537055 seconds in game passed.
Action: tensor([[[ 0.0010,  0.8624],
         [-0.0102,  0.4527],
         [-0.0149,  0.3049],
         [-0.0172,  0.2276]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.239871398549845
18.03537075407803 seconds in game passed.
Action: tensor([[[ 0.0010,  0.8624],
         [-0.0102,  0.4527],
         [-0.0149,  0.3049],
         [-0.0172,  0.2276]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007735, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.239871398549845
18.06037075445056 seconds in game passed.
Action: tensor([[[ 0.0010,  0.8624],
         [-0.0102,  0.4527],
         [-0.0149,  0.3049],
         [-0.0172,  0.2276]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007972, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.239871398549845
+++++++++++++: 2.1821657711781213
18.08537075482309 seconds in game passed.
At 18.08537075482309 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0015,  0.8502],
         [-0.0109,  0.4381],
         [-0.0147,  0.2901],
         [-0.0159,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1821657711781213
Current reward: 0.3056728197602779
Current mitigation activation: 0
#############################
Total reward: 44.54554421831012
18.110370755195618 seconds in game passed.
Action: tensor([[[ 0.0015,  0.8502],
         [-0.0109,  0.4381],
         [-0.0147,  0.2901],
         [-0.0159,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.54554421831012
18.135370755568147 seconds in game passed.
Action: tensor([[[ 0.0015,  0.8502],
         [-0.0109,  0.4381],
         [-0.0147,  0.2901],
         [-0.0159,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.54554421831012
18.160370755940676 seconds in game passed.
Action: tensor([[[ 0.0015,  0.8502],
         [-0.0109,  0.4381],
         [-0.0147,  0.2901],
         [-0.0159,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.54554421831012
+++++++++++++: 2.2510742495451272
18.185370756313205 seconds in game passed.
At 18.185370756313205 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.7949],
         [-0.0068,  0.4173],
         [-0.0095,  0.2789],
         [-0.0108,  0.2081]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2510742495451272
Current reward: 0.30867638795032243
Current mitigation activation: 0
#############################
Total reward: 44.85422060626044
18.210370756685734 seconds in game passed.
Action: tensor([[[-0.0012,  0.7949],
         [-0.0068,  0.4173],
         [-0.0095,  0.2789],
         [-0.0108,  0.2081]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.85422060626044
18.235370757058263 seconds in game passed.
Action: tensor([[[-0.0012,  0.7949],
         [-0.0068,  0.4173],
         [-0.0095,  0.2789],
         [-0.0108,  0.2081]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007424, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.85422060626044
18.260370757430792 seconds in game passed.
Action: tensor([[[-0.0012,  0.7949],
         [-0.0068,  0.4173],
         [-0.0095,  0.2789],
         [-0.0108,  0.2081]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.85422060626044
+++++++++++++: 2.2538712237684027
18.28537075780332 seconds in game passed.
At 18.28537075780332 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.7548],
         [-0.0069,  0.4029],
         [-0.0094,  0.2757],
         [-0.0106,  0.2097]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2538712237684027
Current reward: 0.31680550652000194
Current mitigation activation: 0
#############################
Total reward: 45.171026112780446
18.31037075817585 seconds in game passed.
Action: tensor([[[-0.0020,  0.7548],
         [-0.0069,  0.4029],
         [-0.0094,  0.2757],
         [-0.0106,  0.2097]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.171026112780446
18.33537075854838 seconds in game passed.
Action: tensor([[[-0.0020,  0.7548],
         [-0.0069,  0.4029],
         [-0.0094,  0.2757],
         [-0.0106,  0.2097]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.171026112780446
18.360370758920908 seconds in game passed.
Action: tensor([[[-0.0020,  0.7548],
         [-0.0069,  0.4029],
         [-0.0094,  0.2757],
         [-0.0106,  0.2097]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.171026112780446
+++++++++++++: 2.224463395892391
18.385370759293437 seconds in game passed.
At 18.385370759293437 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.7156],
         [-0.0060,  0.3868],
         [-0.0074,  0.2654],
         [-0.0081,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.224463395892391
Current reward: 0.3274050040032278
Current mitigation activation: 0
#############################
Total reward: 45.49843111678367
18.410370759665966 seconds in game passed.
Action: tensor([[[-0.0021,  0.7156],
         [-0.0060,  0.3868],
         [-0.0074,  0.2654],
         [-0.0081,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.49843111678367
18.435370760038495 seconds in game passed.
Action: tensor([[[-0.0021,  0.7156],
         [-0.0060,  0.3868],
         [-0.0074,  0.2654],
         [-0.0081,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.49843111678367
18.460370760411024 seconds in game passed.
Action: tensor([[[-0.0021,  0.7156],
         [-0.0060,  0.3868],
         [-0.0074,  0.2654],
         [-0.0081,  0.2021]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007714, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.49843111678367
+++++++++++++: 2.180408375343034
18.485370760783553 seconds in game passed.
At 18.485370760783553 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.8928e-04,  6.9020e-01],
         [-4.0824e-03,  3.8051e-01],
         [-5.3580e-03,  2.6334e-01],
         [-6.0993e-03,  2.0186e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.180408375343034
Current reward: 0.3392253778463433
Current mitigation activation: 0
#############################
Total reward: 45.83765649463001
18.510370761156082 seconds in game passed.
Action: tensor([[[-4.8928e-04,  6.9020e-01],
         [-4.0824e-03,  3.8051e-01],
         [-5.3580e-03,  2.6334e-01],
         [-6.0993e-03,  2.0186e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.83765649463001
18.53537076152861 seconds in game passed.
Action: tensor([[[-4.8928e-04,  6.9020e-01],
         [-4.0824e-03,  3.8051e-01],
         [-5.3580e-03,  2.6334e-01],
         [-6.0993e-03,  2.0186e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.83765649463001
18.56037076190114 seconds in game passed.
Action: tensor([[[-4.8928e-04,  6.9020e-01],
         [-4.0824e-03,  3.8051e-01],
         [-5.3580e-03,  2.6334e-01],
         [-6.0993e-03,  2.0186e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.83765649463001
+++++++++++++: 2.130804554870716
18.58537076227367 seconds in game passed.
At 18.58537076227367 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0032,  0.6913],
         [-0.0018,  0.3815],
         [-0.0031,  0.2644],
         [-0.0041,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.130804554870716
Current reward: 0.35160059549190065
Current mitigation activation: 0
#############################
Total reward: 46.18925709012191
18.6103707626462 seconds in game passed.
Action: tensor([[[ 0.0032,  0.6913],
         [-0.0018,  0.3815],
         [-0.0031,  0.2644],
         [-0.0041,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.18925709012191
18.635370763018727 seconds in game passed.
Action: tensor([[[ 0.0032,  0.6913],
         [-0.0018,  0.3815],
         [-0.0031,  0.2644],
         [-0.0041,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.18925709012191
18.660370763391256 seconds in game passed.
Action: tensor([[[ 0.0032,  0.6913],
         [-0.0018,  0.3815],
         [-0.0031,  0.2644],
         [-0.0041,  0.2030]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.18925709012191
+++++++++++++: 2.080156541052107
18.685370763763785 seconds in game passed.
At 18.685370763763785 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.7524e-03,  6.7611e-01],
         [ 2.6974e-04,  3.7194e-01],
         [-1.4099e-04,  2.5548e-01],
         [-7.7096e-04,  1.9523e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.080156541052107
Current reward: 0.3641634559168669
Current mitigation activation: 0
#############################
Total reward: 46.55342054603878
18.710370764136314 seconds in game passed.
Action: tensor([[[ 4.7524e-03,  6.7611e-01],
         [ 2.6974e-04,  3.7194e-01],
         [-1.4099e-04,  2.5548e-01],
         [-7.7096e-04,  1.9523e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.55342054603878
18.735370764508843 seconds in game passed.
Action: tensor([[[ 4.7524e-03,  6.7611e-01],
         [ 2.6974e-04,  3.7194e-01],
         [-1.4099e-04,  2.5548e-01],
         [-7.7096e-04,  1.9523e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.55342054603878
18.760370764881372 seconds in game passed.
Action: tensor([[[ 4.7524e-03,  6.7611e-01],
         [ 2.6974e-04,  3.7194e-01],
         [-1.4099e-04,  2.5548e-01],
         [-7.7096e-04,  1.9523e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000504, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.55342054603878
+++++++++++++: 2.030566985903387
18.7853707652539 seconds in game passed.
At 18.7853707652539 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6526],
         [0.0019, 0.3494],
         [0.0018, 0.2390],
         [0.0010, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.030566985903387
Current reward: 0.37670474381731356
Current mitigation activation: 0
#############################
Total reward: 46.93012528985609
18.81037076562643 seconds in game passed.
Action: tensor([[[0.0032, 0.6526],
         [0.0019, 0.3494],
         [0.0018, 0.2390],
         [0.0010, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93012528985609
18.83537076599896 seconds in game passed.
Action: tensor([[[0.0032, 0.6526],
         [0.0019, 0.3494],
         [0.0018, 0.2390],
         [0.0010, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93012528985609
18.86037076637149 seconds in game passed.
Action: tensor([[[0.0032, 0.6526],
         [0.0019, 0.3494],
         [0.0018, 0.2390],
         [0.0010, 0.1825]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93012528985609
+++++++++++++: 1.982980793708365
18.885370766744018 seconds in game passed.
At 18.885370766744018 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0051, 0.6438],
         [0.0044, 0.3451],
         [0.0042, 0.2369],
         [0.0034, 0.1814]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.982980793708365
Current reward: 0.38909745273268825
Current mitigation activation: 0
#############################
Total reward: 47.31922274258878
18.910370767116547 seconds in game passed.
Action: tensor([[[0.0051, 0.6438],
         [0.0044, 0.3451],
         [0.0042, 0.2369],
         [0.0034, 0.1814]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003062, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.31922274258878
18.935370767489076 seconds in game passed.
Action: tensor([[[0.0051, 0.6438],
         [0.0044, 0.3451],
         [0.0042, 0.2369],
         [0.0034, 0.1814]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.31922274258878
18.960370767861605 seconds in game passed.
Action: tensor([[[0.0051, 0.6438],
         [0.0044, 0.3451],
         [0.0042, 0.2369],
         [0.0034, 0.1814]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.31922274258878
+++++++++++++: 1.9377318952518896
18.985370768234134 seconds in game passed.
At 18.985370768234134 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6355],
         [0.0021, 0.3413],
         [0.0023, 0.2346],
         [0.0019, 0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000872, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9377318952518896
Current reward: 0.4012713844056136
Current mitigation activation: 0
#############################
Total reward: 47.72049412699439
19.010370768606663 seconds in game passed.
Action: tensor([[[0.0028, 0.6355],
         [0.0021, 0.3413],
         [0.0023, 0.2346],
         [0.0019, 0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.72049412699439
19.035370768979192 seconds in game passed.
Action: tensor([[[0.0028, 0.6355],
         [0.0021, 0.3413],
         [0.0023, 0.2346],
         [0.0019, 0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.72049412699439
19.06037076935172 seconds in game passed.
Action: tensor([[[0.0028, 0.6355],
         [0.0021, 0.3413],
         [0.0023, 0.2346],
         [0.0019, 0.1799]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001618, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.72049412699439
+++++++++++++: 1.8948570905200768
19.08537076972425 seconds in game passed.
At 19.08537076972425 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6656],
         [0.0017, 0.3519],
         [0.0013, 0.2408],
         [0.0007, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8948570905200768
Current reward: 0.41317745186111254
Current mitigation activation: 0
#############################
Total reward: 48.1336715788555
19.11037077009678 seconds in game passed.
Action: tensor([[[0.0028, 0.6656],
         [0.0017, 0.3519],
         [0.0013, 0.2408],
         [0.0007, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.1336715788555
19.135370770469308 seconds in game passed.
Action: tensor([[[0.0028, 0.6656],
         [0.0017, 0.3519],
         [0.0013, 0.2408],
         [0.0007, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.1336715788555
19.160370770841837 seconds in game passed.
Action: tensor([[[0.0028, 0.6656],
         [0.0017, 0.3519],
         [0.0013, 0.2408],
         [0.0007, 0.1845]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.1336715788555
+++++++++++++: 1.8542353002307461
19.185370771214366 seconds in game passed.
At 19.185370771214366 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.3227e-03,  6.7732e-01],
         [ 1.4008e-04,  3.5576e-01],
         [-8.7363e-04,  2.4217e-01],
         [-1.6309e-03,  1.8475e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8542353002307461
Current reward: 0.42479127963899654
Current mitigation activation: 0
#############################
Total reward: 48.558462858494494
19.210370771586895 seconds in game passed.
Action: tensor([[[ 2.3227e-03,  6.7732e-01],
         [ 1.4008e-04,  3.5576e-01],
         [-8.7363e-04,  2.4217e-01],
         [-1.6309e-03,  1.8475e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000773, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.558462858494494
19.235370771959424 seconds in game passed.
Action: tensor([[[ 2.3227e-03,  6.7732e-01],
         [ 1.4008e-04,  3.5576e-01],
         [-8.7363e-04,  2.4217e-01],
         [-1.6309e-03,  1.8475e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.558462858494494
19.260370772331953 seconds in game passed.
Action: tensor([[[ 2.3227e-03,  6.7732e-01],
         [ 1.4008e-04,  3.5576e-01],
         [-8.7363e-04,  2.4217e-01],
         [-1.6309e-03,  1.8475e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.558462858494494
+++++++++++++: 1.8157068561045602
19.285370772704482 seconds in game passed.
At 19.285370772704482 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6719],
         [-0.0028,  0.3497],
         [-0.0040,  0.2374],
         [-0.0047,  0.1816]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001841, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8157068561045602
Current reward: 0.43609789399136945
Current mitigation activation: 0
#############################
Total reward: 48.99456075248586
19.31037077307701 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6719],
         [-0.0028,  0.3497],
         [-0.0040,  0.2374],
         [-0.0047,  0.1816]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.99456075248586
19.33537077344954 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6719],
         [-0.0028,  0.3497],
         [-0.0040,  0.2374],
         [-0.0047,  0.1816]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.99456075248586
19.36037077382207 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6719],
         [-0.0028,  0.3497],
         [-0.0040,  0.2374],
         [-0.0047,  0.1816]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.99456075248586
+++++++++++++: 1.7790945844978505
19.385370774194598 seconds in game passed.
At 19.385370774194598 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.5287e-04,  6.8196e-01],
         [-9.8928e-04,  3.5232e-01],
         [-1.6699e-03,  2.3854e-01],
         [-2.0168e-03,  1.8241e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7790945844978505
Current reward: 0.44708606578472254
Current mitigation activation: 0
#############################
Total reward: 49.441646818270584
19.410370774567127 seconds in game passed.
Action: tensor([[[ 3.5287e-04,  6.8196e-01],
         [-9.8928e-04,  3.5232e-01],
         [-1.6699e-03,  2.3854e-01],
         [-2.0168e-03,  1.8241e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.441646818270584
19.435370774939656 seconds in game passed.
Action: tensor([[[ 3.5287e-04,  6.8196e-01],
         [-9.8928e-04,  3.5232e-01],
         [-1.6699e-03,  2.3854e-01],
         [-2.0168e-03,  1.8241e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.441646818270584
19.460370775312185 seconds in game passed.
Action: tensor([[[ 3.5287e-04,  6.8196e-01],
         [-9.8928e-04,  3.5232e-01],
         [-1.6699e-03,  2.3854e-01],
         [-2.0168e-03,  1.8241e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.441646818270584
+++++++++++++: 1.7719920719631448
19.485370775684714 seconds in game passed.
At 19.485370775684714 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.9011e-04,  6.6506e-01],
         [-1.5220e-03,  3.4698e-01],
         [-2.0357e-03,  2.3572e-01],
         [-2.2665e-03,  1.8077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7719920719631448
Current reward: 0.4537328176356823
Current mitigation activation: 0
#############################
Total reward: 49.89537963590627
19.510370776057243 seconds in game passed.
Action: tensor([[[-3.9011e-04,  6.6506e-01],
         [-1.5220e-03,  3.4698e-01],
         [-2.0357e-03,  2.3572e-01],
         [-2.2665e-03,  1.8077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89537963590627
19.535370776429772 seconds in game passed.
Action: tensor([[[-3.9011e-04,  6.6506e-01],
         [-1.5220e-03,  3.4698e-01],
         [-2.0357e-03,  2.3572e-01],
         [-2.2665e-03,  1.8077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89537963590627
19.5603707768023 seconds in game passed.
Action: tensor([[[-3.9011e-04,  6.6506e-01],
         [-1.5220e-03,  3.4698e-01],
         [-2.0357e-03,  2.3572e-01],
         [-2.2665e-03,  1.8077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.89537963590627
+++++++++++++: 1.7981433979897534
19.58537077717483 seconds in game passed.
At 19.58537077717483 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.4853e-04, 6.3608e-01],
         [7.0247e-04, 3.3762e-01],
         [6.5546e-04, 2.3139e-01],
         [6.0833e-04, 1.7761e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7981433979897534
Current reward: 0.4556320394505985
Current mitigation activation: 0
#############################
Total reward: 50.351011675356865
19.61037077754736 seconds in game passed.
Action: tensor([[[7.4853e-04, 6.3608e-01],
         [7.0247e-04, 3.3762e-01],
         [6.5546e-04, 2.3139e-01],
         [6.0833e-04, 1.7761e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.351011675356865
19.63537077791989 seconds in game passed.
Action: tensor([[[7.4853e-04, 6.3608e-01],
         [7.0247e-04, 3.3762e-01],
         [6.5546e-04, 2.3139e-01],
         [6.0833e-04, 1.7761e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001217, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.351011675356865
19.660370778292418 seconds in game passed.
Action: tensor([[[7.4853e-04, 6.3608e-01],
         [7.0247e-04, 3.3762e-01],
         [6.5546e-04, 2.3139e-01],
         [6.0833e-04, 1.7761e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.351011675356865
+++++++++++++: 1.8256894896550226
19.685370778664947 seconds in game passed.
At 19.685370778664947 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6259],
         [0.0025, 0.3399],
         [0.0024, 0.2341],
         [0.0021, 0.1798]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8256894896550226
Current reward: 0.45773878026401604
Current mitigation activation: 0
#############################
Total reward: 50.80875045562088
19.710370779037476 seconds in game passed.
Action: tensor([[[0.0042, 0.6259],
         [0.0025, 0.3399],
         [0.0024, 0.2341],
         [0.0021, 0.1798]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.80875045562088
19.735370779410005 seconds in game passed.
Action: tensor([[[0.0042, 0.6259],
         [0.0025, 0.3399],
         [0.0024, 0.2341],
         [0.0021, 0.1798]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.80875045562088
19.760370779782534 seconds in game passed.
Action: tensor([[[0.0042, 0.6259],
         [0.0025, 0.3399],
         [0.0024, 0.2341],
         [0.0021, 0.1798]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.80875045562088
+++++++++++++: 1.8549428685374991
19.785370780155063 seconds in game passed.
At 19.785370780155063 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0038, 0.6353],
         [0.0024, 0.3414],
         [0.0023, 0.2356],
         [0.0020, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8549428685374991
Current reward: 0.46000081102594087
Current mitigation activation: 0
#############################
Total reward: 51.268751266646824
19.81037078052759 seconds in game passed.
Action: tensor([[[0.0038, 0.6353],
         [0.0024, 0.3414],
         [0.0023, 0.2356],
         [0.0020, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.268751266646824
19.83537078090012 seconds in game passed.
Action: tensor([[[0.0038, 0.6353],
         [0.0024, 0.3414],
         [0.0023, 0.2356],
         [0.0020, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.268751266646824
19.86037078127265 seconds in game passed.
Action: tensor([[[0.0038, 0.6353],
         [0.0024, 0.3414],
         [0.0023, 0.2356],
         [0.0020, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.268751266646824
+++++++++++++: 1.885875451707124
19.88537078164518 seconds in game passed.
At 19.88537078164518 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6308],
         [0.0009, 0.3349],
         [0.0009, 0.2297],
         [0.0007, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.885875451707124
Current reward: 0.4624125337629892
Current mitigation activation: 0
#############################
Total reward: 51.73116380040981
19.910370782017708 seconds in game passed.
Action: tensor([[[0.0033, 0.6308],
         [0.0009, 0.3349],
         [0.0009, 0.2297],
         [0.0007, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.73116380040981
19.935370782390237 seconds in game passed.
Action: tensor([[[0.0033, 0.6308],
         [0.0009, 0.3349],
         [0.0009, 0.2297],
         [0.0007, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.73116380040981
19.960370782762766 seconds in game passed.
Action: tensor([[[0.0033, 0.6308],
         [0.0009, 0.3349],
         [0.0009, 0.2297],
         [0.0007, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.73116380040981
+++++++++++++: 1.8816764375726849
19.985370783135295 seconds in game passed.
At 19.985370783135295 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0025,  0.6176],
         [-0.0006,  0.3304],
         [-0.0007,  0.2273],
         [-0.0007,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8816764375726849
Current reward: 0.46988757457190344
Current mitigation activation: 0
#############################
Total reward: 52.201051374981716
20.010370783507824 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6176],
         [-0.0006,  0.3304],
         [-0.0007,  0.2273],
         [-0.0007,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000893, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.201051374981716
20.035370783880353 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6176],
         [-0.0006,  0.3304],
         [-0.0007,  0.2273],
         [-0.0007,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.201051374981716
20.060370784252882 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6176],
         [-0.0006,  0.3304],
         [-0.0007,  0.2273],
         [-0.0007,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.201051374981716
+++++++++++++: 1.8179353565274632
20.08537078462541 seconds in game passed.
At 20.08537078462541 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0007,  0.6055],
         [-0.0022,  0.3280],
         [-0.0026,  0.2263],
         [-0.0030,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.861221, steer=-0.001610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8179353565274632
Current reward: 0.4858185346937256
Current mitigation activation: 0
#############################
Total reward: 52.686869909675444
20.11037078499794 seconds in game passed.
Action: tensor([[[-0.0007,  0.6055],
         [-0.0022,  0.3280],
         [-0.0026,  0.2263],
         [-0.0030,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.815915, steer=-0.001252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.686869909675444
20.13537078537047 seconds in game passed.
Action: tensor([[[-0.0007,  0.6055],
         [-0.0022,  0.3280],
         [-0.0026,  0.2263],
         [-0.0030,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.767595, steer=-0.001295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.686869909675444
20.160370785742998 seconds in game passed.
Action: tensor([[[-0.0007,  0.6055],
         [-0.0022,  0.3280],
         [-0.0026,  0.2263],
         [-0.0030,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.720750, steer=-0.001339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.686869909675444
+++++++++++++: 1.7663529772587512
20.185370786115527 seconds in game passed.
At 20.185370786115527 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6143],
         [-0.0072,  0.3312],
         [-0.0083,  0.2273],
         [-0.0091,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.651983, steer=-0.006092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7663529772587512
Current reward: 0.49983944461524477
Current mitigation activation: 0
#############################
Total reward: 53.18670935429069
20.210370786488056 seconds in game passed.
Action: tensor([[[-0.0033,  0.6143],
         [-0.0072,  0.3312],
         [-0.0083,  0.2273],
         [-0.0091,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.611478, steer=-0.005392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18670935429069
20.235370786860585 seconds in game passed.
Action: tensor([[[-0.0033,  0.6143],
         [-0.0072,  0.3312],
         [-0.0083,  0.2273],
         [-0.0091,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.570888, steer=-0.005471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18670935429069
20.260370787233114 seconds in game passed.
Action: tensor([[[-0.0033,  0.6143],
         [-0.0072,  0.3312],
         [-0.0083,  0.2273],
         [-0.0091,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.533040, steer=-0.005550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18670935429069
+++++++++++++: 1.7269611560966356
20.285370787605643 seconds in game passed.
At 20.285370787605643 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0047,  0.6281],
         [-0.0074,  0.3329],
         [-0.0080,  0.2269],
         [-0.0083,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.577762, steer=-0.006317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7269611560966356
Current reward: 0.5117160153533706
Current mitigation activation: 0
#############################
Total reward: 53.69842536964406
20.310370787978172 seconds in game passed.
Action: tensor([[[-0.0047,  0.6281],
         [-0.0074,  0.3329],
         [-0.0080,  0.2269],
         [-0.0083,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.536608, steer=-0.006256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.69842536964406
20.3353707883507 seconds in game passed.
Action: tensor([[[-0.0047,  0.6281],
         [-0.0074,  0.3329],
         [-0.0080,  0.2269],
         [-0.0083,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.507031, steer=-0.006313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.69842536964406
20.36037078872323 seconds in game passed.
Action: tensor([[[-0.0047,  0.6281],
         [-0.0074,  0.3329],
         [-0.0080,  0.2269],
         [-0.0083,  0.1736]]])
agent 0 action: VehicleControl(throttle=0.479881, steer=-0.006370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.69842536964406
+++++++++++++: 1.7036224417498393
20.38537078909576 seconds in game passed.
At 20.38537078909576 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6321],
         [-0.0046,  0.3333],
         [-0.0053,  0.2269],
         [-0.0057,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.479748, steer=-0.003367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7036224417498393
Current reward: 0.5206307313356834
Current mitigation activation: 0
#############################
Total reward: 54.21905610097975
20.41037078946829 seconds in game passed.
Action: tensor([[[-0.0022,  0.6321],
         [-0.0046,  0.3333],
         [-0.0053,  0.2269],
         [-0.0057,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.455376, steer=-0.003911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.21905610097975
20.435370789840817 seconds in game passed.
Action: tensor([[[-0.0022,  0.6321],
         [-0.0046,  0.3333],
         [-0.0053,  0.2269],
         [-0.0057,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.435823, steer=-0.003949, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.21905610097975
20.460370790213346 seconds in game passed.
Action: tensor([[[-0.0022,  0.6321],
         [-0.0046,  0.3333],
         [-0.0053,  0.2269],
         [-0.0057,  0.1739]]])
agent 0 action: VehicleControl(throttle=0.418324, steer=-0.003987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.21905610097975
+++++++++++++: 1.6955639578883306
20.485370790585876 seconds in game passed.
At 20.485370790585876 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.2608e-03, 6.0712e-01],
         [1.4039e-03, 3.2822e-01],
         [9.4295e-04, 2.2610e-01],
         [1.2878e-04, 1.7363e-01]]])
agent 0 action: VehicleControl(throttle=0.329344, steer=0.002191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6955639578883306
Current reward: 0.5266834784634639
Current mitigation activation: 0
#############################
Total reward: 54.74573957944321
20.510370790958405 seconds in game passed.
Action: tensor([[[2.2608e-03, 6.0712e-01],
         [1.4039e-03, 3.2822e-01],
         [9.4295e-04, 2.2610e-01],
         [1.2878e-04, 1.7363e-01]]])
agent 0 action: VehicleControl(throttle=0.322617, steer=0.001200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.74573957944321
20.535370791330934 seconds in game passed.
Action: tensor([[[2.2608e-03, 6.0712e-01],
         [1.4039e-03, 3.2822e-01],
         [9.4295e-04, 2.2610e-01],
         [1.2878e-04, 1.7363e-01]]])
agent 0 action: VehicleControl(throttle=0.310351, steer=0.001233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.74573957944321
20.560370791703463 seconds in game passed.
Action: tensor([[[2.2608e-03, 6.0712e-01],
         [1.4039e-03, 3.2822e-01],
         [9.4295e-04, 2.2610e-01],
         [1.2878e-04, 1.7363e-01]]])
agent 0 action: VehicleControl(throttle=0.300761, steer=0.001267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.74573957944321
+++++++++++++: 1.7011527026365374
20.58537079207599 seconds in game passed.
At 20.58537079207599 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6166],
         [0.0027, 0.3327],
         [0.0024, 0.2288],
         [0.0015, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.232471, steer=0.002767, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7011527026365374
Current reward: 0.5302685615123859
Current mitigation activation: 0
#############################
Total reward: 55.2760081409556
20.61037079244852 seconds in game passed.
Action: tensor([[[0.0035, 0.6166],
         [0.0027, 0.3327],
         [0.0024, 0.2288],
         [0.0015, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.232699, steer=0.002548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.2760081409556
20.63537079282105 seconds in game passed.
Action: tensor([[[0.0035, 0.6166],
         [0.0027, 0.3327],
         [0.0024, 0.2288],
         [0.0015, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.228687, steer=0.002575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.2760081409556
20.66037079319358 seconds in game passed.
Action: tensor([[[0.0035, 0.6166],
         [0.0027, 0.3327],
         [0.0024, 0.2288],
         [0.0015, 0.1759]]])
agent 0 action: VehicleControl(throttle=0.227098, steer=0.002602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.2760081409556
+++++++++++++: 1.7211789492593859
20.685370793566108 seconds in game passed.
At 20.685370793566108 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0029, 0.6288],
         [0.0020, 0.3365],
         [0.0015, 0.2306],
         [0.0008, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.219263, steer=0.001772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7211789492593859
Current reward: 0.5314468446858616
Current mitigation activation: 0
#############################
Total reward: 55.807454985641456
20.710370793938637 seconds in game passed.
Action: tensor([[[0.0029, 0.6288],
         [0.0020, 0.3365],
         [0.0015, 0.2306],
         [0.0008, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.224422, steer=0.001899, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.807454985641456
20.735370794311166 seconds in game passed.
Action: tensor([[[0.0029, 0.6288],
         [0.0020, 0.3365],
         [0.0015, 0.2306],
         [0.0008, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.230081, steer=0.001890, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.807454985641456
20.760370794683695 seconds in game passed.
Action: tensor([[[0.0029, 0.6288],
         [0.0020, 0.3365],
         [0.0015, 0.2306],
         [0.0008, 0.1770]]])
agent 0 action: VehicleControl(throttle=0.237166, steer=0.001880, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.807454985641456
+++++++++++++: 1.7550133476735807
20.785370795056224 seconds in game passed.
At 20.785370795056224 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.6216],
         [0.0019, 0.3338],
         [0.0017, 0.2290],
         [0.0009, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.267495, steer=0.001323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7550133476735807
Current reward: 0.5306334142185138
Current mitigation activation: 0
#############################
Total reward: 56.33808839985997
20.810370795428753 seconds in game passed.
Action: tensor([[[0.0016, 0.6216],
         [0.0019, 0.3338],
         [0.0017, 0.2290],
         [0.0009, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.274110, steer=0.001401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.33808839985997
20.835370795801282 seconds in game passed.
Action: tensor([[[0.0016, 0.6216],
         [0.0019, 0.3338],
         [0.0017, 0.2290],
         [0.0009, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.283809, steer=0.001387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.33808839985997
20.86037079617381 seconds in game passed.
Action: tensor([[[0.0016, 0.6216],
         [0.0019, 0.3338],
         [0.0017, 0.2290],
         [0.0009, 0.1757]]])
agent 0 action: VehicleControl(throttle=0.293871, steer=0.001374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.33808839985997
+++++++++++++: 1.7990755061976345
20.88537079654634 seconds in game passed.
At 20.88537079654634 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.3699e-04,  6.1994e-01],
         [ 3.2037e-06,  3.3185e-01],
         [-2.7387e-04,  2.2776e-01],
         [-1.2364e-03,  1.7529e-01]]])
agent 0 action: VehicleControl(throttle=0.353519, steer=-0.000922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7990755061976345
Current reward: 0.5287708556302952
Current mitigation activation: 0
#############################
Total reward: 56.86685925549027
20.91037079691887 seconds in game passed.
Action: tensor([[[-6.3699e-04,  6.1994e-01],
         [ 3.2037e-06,  3.3185e-01],
         [-2.7387e-04,  2.2776e-01],
         [-1.2364e-03,  1.7529e-01]]])
agent 0 action: VehicleControl(throttle=0.357168, steer=-0.000566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.86685925549027
20.935370797291398 seconds in game passed.
Action: tensor([[[-6.3699e-04,  6.1994e-01],
         [ 3.2037e-06,  3.3185e-01],
         [-2.7387e-04,  2.2776e-01],
         [-1.2364e-03,  1.7529e-01]]])
agent 0 action: VehicleControl(throttle=0.366845, steer=-0.000590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.86685925549027
20.960370797663927 seconds in game passed.
Action: tensor([[[-6.3699e-04,  6.1994e-01],
         [ 3.2037e-06,  3.3185e-01],
         [-2.7387e-04,  2.2776e-01],
         [-1.2364e-03,  1.7529e-01]]])
agent 0 action: VehicleControl(throttle=0.376638, steer=-0.000613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.86685925549027
+++++++++++++: 1.8484022254199985
20.985370798036456 seconds in game passed.
At 20.985370798036456 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6163],
         [-0.0022,  0.3314],
         [-0.0026,  0.2272],
         [-0.0034,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.364295, steer=-0.002947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8484022254199985
Current reward: 0.526889716747226
Current mitigation activation: 0
#############################
Total reward: 57.393748972237496
21.010370798408985 seconds in game passed.
Action: tensor([[[-0.0024,  0.6163],
         [-0.0022,  0.3314],
         [-0.0026,  0.2272],
         [-0.0034,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.376179, steer=-0.002595, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.393748972237496
21.035370798781514 seconds in game passed.
Action: tensor([[[-0.0024,  0.6163],
         [-0.0022,  0.3314],
         [-0.0026,  0.2272],
         [-0.0034,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.385883, steer=-0.002627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.393748972237496
21.060370799154043 seconds in game passed.
Action: tensor([[[-0.0024,  0.6163],
         [-0.0022,  0.3314],
         [-0.0026,  0.2272],
         [-0.0034,  0.1744]]])
agent 0 action: VehicleControl(throttle=0.395854, steer=-0.002659, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.393748972237496
+++++++++++++: 1.8983473800406983
21.085370799526572 seconds in game passed.
At 21.085370799526572 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6198],
         [-0.0019,  0.3306],
         [-0.0018,  0.2258],
         [-0.0018,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.470855, steer=-0.002470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8983473800406983
Current reward: 0.5257615346704538
Current mitigation activation: 0
#############################
Total reward: 57.91951050690795
21.1103707998991 seconds in game passed.
Action: tensor([[[-0.0024,  0.6198],
         [-0.0019,  0.3306],
         [-0.0018,  0.2258],
         [-0.0018,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.475415, steer=-0.002507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.91951050690795
21.13537080027163 seconds in game passed.
Action: tensor([[[-0.0024,  0.6198],
         [-0.0019,  0.3306],
         [-0.0018,  0.2258],
         [-0.0018,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.486634, steer=-0.002512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.91951050690795
21.16037080064416 seconds in game passed.
Action: tensor([[[-0.0024,  0.6198],
         [-0.0019,  0.3306],
         [-0.0018,  0.2258],
         [-0.0018,  0.1731]]])
agent 0 action: VehicleControl(throttle=0.497152, steer=-0.002517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.91951050690795
+++++++++++++: 1.9472708005457848
21.18537080101669 seconds in game passed.
At 21.18537080101669 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0007, 0.6049],
         [0.0011, 0.3264],
         [0.0015, 0.2238],
         [0.0019, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.503388, steer=0.000989, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9472708005457848
Current reward: 0.5255484804556807
Current mitigation activation: 0
#############################
Total reward: 58.44505898736363
21.210370801389217 seconds in game passed.
Action: tensor([[[0.0007, 0.6049],
         [0.0011, 0.3264],
         [0.0015, 0.2238],
         [0.0019, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.513441, steer=0.000497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.44505898736363
21.235370801761746 seconds in game passed.
Action: tensor([[[0.0007, 0.6049],
         [0.0011, 0.3264],
         [0.0015, 0.2238],
         [0.0019, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.522523, steer=0.000577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.44505898736363
21.260370802134275 seconds in game passed.
Action: tensor([[[0.0007, 0.6049],
         [0.0011, 0.3264],
         [0.0015, 0.2238],
         [0.0019, 0.1714]]])
agent 0 action: VehicleControl(throttle=0.531086, steer=0.000656, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.44505898736363
+++++++++++++: 1.9918686833009525
21.285370802506804 seconds in game passed.
At 21.285370802506804 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6036],
         [0.0027, 0.3254],
         [0.0029, 0.2227],
         [0.0028, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.563246, steer=0.002512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9918686833009525
Current reward: 0.5266063974351598
Current mitigation activation: 0
#############################
Total reward: 58.97166538479879
21.310370802879333 seconds in game passed.
Action: tensor([[[0.0022, 0.6036],
         [0.0027, 0.3254],
         [0.0029, 0.2227],
         [0.0028, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.567444, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.97166538479879
21.335370803251863 seconds in game passed.
Action: tensor([[[0.0022, 0.6036],
         [0.0027, 0.3254],
         [0.0029, 0.2227],
         [0.0028, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.573654, steer=0.002430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.97166538479879
21.36037080362439 seconds in game passed.
Action: tensor([[[0.0022, 0.6036],
         [0.0027, 0.3254],
         [0.0029, 0.2227],
         [0.0028, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.579034, steer=0.002536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.97166538479879
+++++++++++++: 2.03094899346627
21.38537080399692 seconds in game passed.
At 21.38537080399692 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0021, 0.6208],
         [0.0034, 0.3317],
         [0.0030, 0.2264],
         [0.0022, 0.1728]]])
agent 0 action: VehicleControl(throttle=0.532954, steer=0.003104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.03094899346627
Current reward: 0.528926139095793
Current mitigation activation: 0
#############################
Total reward: 59.500591523894585
21.41037080436945 seconds in game passed.
Action: tensor([[[0.0021, 0.6208],
         [0.0034, 0.3317],
         [0.0030, 0.2264],
         [0.0022, 0.1728]]])
agent 0 action: VehicleControl(throttle=0.541413, steer=0.003101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.500591523894585
21.43537080474198 seconds in game passed.
Action: tensor([[[0.0021, 0.6208],
         [0.0034, 0.3317],
         [0.0030, 0.2264],
         [0.0022, 0.1728]]])
agent 0 action: VehicleControl(throttle=0.546819, steer=0.003179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.500591523894585
21.460370805114508 seconds in game passed.
Action: tensor([[[0.0021, 0.6208],
         [0.0034, 0.3317],
         [0.0030, 0.2264],
         [0.0022, 0.1728]]])
agent 0 action: VehicleControl(throttle=0.551959, steer=0.003258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.500591523894585
+++++++++++++: 2.0660624181274008
21.485370805487037 seconds in game passed.
At 21.485370805487037 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6148],
         [0.0037, 0.3274],
         [0.0035, 0.2231],
         [0.0028, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.652681, steer=0.003797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0660624181274008
Current reward: 0.5321329303007559
Current mitigation activation: 0
#############################
Total reward: 60.03272445419534
21.510370805859566 seconds in game passed.
Action: tensor([[[0.0028, 0.6148],
         [0.0037, 0.3274],
         [0.0035, 0.2231],
         [0.0028, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.649855, steer=0.003731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.03272445419534
21.535370806232095 seconds in game passed.
Action: tensor([[[0.0028, 0.6148],
         [0.0037, 0.3274],
         [0.0035, 0.2231],
         [0.0028, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.657131, steer=0.003751, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.03272445419534
21.560370806604624 seconds in game passed.
Action: tensor([[[0.0028, 0.6148],
         [0.0037, 0.3274],
         [0.0035, 0.2231],
         [0.0028, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.664440, steer=0.003771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.03272445419534
+++++++++++++: 2.10278951659663
21.585370806977153 seconds in game passed.
At 21.585370806977153 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6112],
         [0.0050, 0.3248],
         [0.0051, 0.2208],
         [0.0041, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.732827, steer=0.004315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.10278951659663
Current reward: 0.5353740705034284
Current mitigation activation: 0
#############################
Total reward: 60.56809852469877
21.610370807349682 seconds in game passed.
Action: tensor([[[0.0018, 0.6112],
         [0.0050, 0.3248],
         [0.0051, 0.2208],
         [0.0041, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.735054, steer=0.004236, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.56809852469877
21.63537080772221 seconds in game passed.
Action: tensor([[[0.0018, 0.6112],
         [0.0050, 0.3248],
         [0.0051, 0.2208],
         [0.0041, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.743637, steer=0.004246, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.56809852469877
21.66037080809474 seconds in game passed.
Action: tensor([[[0.0018, 0.6112],
         [0.0050, 0.3248],
         [0.0051, 0.2208],
         [0.0041, 0.1691]]])
agent 0 action: VehicleControl(throttle=0.752140, steer=0.004256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.56809852469877
+++++++++++++: 2.1405673609310165
21.68537080846727 seconds in game passed.
At 21.68537080846727 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.3953e-04, 6.2215e-01],
         [3.3548e-03, 3.2930e-01],
         [3.3486e-03, 2.2336e-01],
         [2.2242e-03, 1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.706782, steer=0.002572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1405673609310165
Current reward: 0.5387202792432972
Current mitigation activation: 0
#############################
Total reward: 61.10681880394207
21.710370808839798 seconds in game passed.
Action: tensor([[[5.3953e-04, 6.2215e-01],
         [3.3548e-03, 3.2930e-01],
         [3.3486e-03, 2.2336e-01],
         [2.2242e-03, 1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.720286, steer=0.002854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.10681880394207
21.735370809212327 seconds in game passed.
Action: tensor([[[5.3953e-04, 6.2215e-01],
         [3.3548e-03, 3.2930e-01],
         [3.3486e-03, 2.2336e-01],
         [2.2242e-03, 1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.727932, steer=0.002855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.10681880394207
21.760370809584856 seconds in game passed.
Action: tensor([[[5.3953e-04, 6.2215e-01],
         [3.3548e-03, 3.2930e-01],
         [3.3486e-03, 2.2336e-01],
         [2.2242e-03, 1.7102e-01]]])
agent 0 action: VehicleControl(throttle=0.735425, steer=0.002856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.10681880394207
+++++++++++++: 2.1793246065378122
21.785370809957385 seconds in game passed.
At 21.785370809957385 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6290],
         [0.0047, 0.3300],
         [0.0049, 0.2234],
         [0.0042, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.787044, steer=0.004778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1793246065378122
Current reward: 0.5421636404205881
Current mitigation activation: 0
#############################
Total reward: 61.64898244436266
21.810370810329914 seconds in game passed.
Action: tensor([[[0.0028, 0.6290],
         [0.0047, 0.3300],
         [0.0049, 0.2234],
         [0.0042, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.789710, steer=0.004489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.64898244436266
21.835370810702443 seconds in game passed.
Action: tensor([[[0.0028, 0.6290],
         [0.0047, 0.3300],
         [0.0049, 0.2234],
         [0.0042, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.796921, steer=0.004515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.64898244436266
21.860370811074972 seconds in game passed.
Action: tensor([[[0.0028, 0.6290],
         [0.0047, 0.3300],
         [0.0049, 0.2234],
         [0.0042, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.803934, steer=0.004542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.64898244436266
+++++++++++++: 2.218994868942742
21.8853708114475 seconds in game passed.
At 21.8853708114475 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0065, 0.6358],
         [0.0094, 0.3322],
         [0.0098, 0.2240],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.797813, steer=0.009541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.218994868942742
Current reward: 0.5456954745328652
Current mitigation activation: 0
#############################
Total reward: 62.19467791889552
21.91037081182003 seconds in game passed.
Action: tensor([[[0.0065, 0.6358],
         [0.0094, 0.3322],
         [0.0098, 0.2240],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.805050, steer=0.008826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.19467791889552
21.93537081219256 seconds in game passed.
Action: tensor([[[0.0065, 0.6358],
         [0.0094, 0.3322],
         [0.0098, 0.2240],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.797974, steer=0.008927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.19467791889552
21.96037081256509 seconds in game passed.
Action: tensor([[[0.0065, 0.6358],
         [0.0094, 0.3322],
         [0.0098, 0.2240],
         [0.0089, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.781486, steer=0.009028, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.19467791889552
+++++++++++++: 2.248685495143041
21.985370812937617 seconds in game passed.
At 21.985370812937617 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0109, 0.6450],
         [0.0162, 0.3360],
         [0.0177, 0.2257],
         [0.0170, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.719767, steer=0.015963, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.248685495143041
Current reward: 0.5506529457395827
Current mitigation activation: 0
#############################
Total reward: 62.74533086463511
22.010370813310146 seconds in game passed.
Action: tensor([[[0.0109, 0.6450],
         [0.0162, 0.3360],
         [0.0177, 0.2257],
         [0.0170, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.707790, steer=0.015035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.74533086463511
22.035370813682675 seconds in game passed.
Action: tensor([[[0.0109, 0.6450],
         [0.0162, 0.3360],
         [0.0177, 0.2257],
         [0.0170, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.690933, steer=0.015231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.74533086463511
22.060370814055204 seconds in game passed.
Action: tensor([[[0.0109, 0.6450],
         [0.0162, 0.3360],
         [0.0177, 0.2257],
         [0.0170, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.674154, steer=0.015426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.74533086463511
+++++++++++++: 2.2472165680393346
22.085370814427733 seconds in game passed.
At 22.085370814427733 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0089, 0.6343],
         [0.0094, 0.3330],
         [0.0098, 0.2251],
         [0.0090, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.659527, steer=0.009777, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2472165680393346
Current reward: 0.5595413399670583
Current mitigation activation: 0
#############################
Total reward: 63.30487220460216
22.110370814800262 seconds in game passed.
Action: tensor([[[0.0089, 0.6343],
         [0.0094, 0.3330],
         [0.0098, 0.2251],
         [0.0090, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.642283, steer=0.010874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.30487220460216
22.13537081517279 seconds in game passed.
Action: tensor([[[0.0089, 0.6343],
         [0.0094, 0.3330],
         [0.0098, 0.2251],
         [0.0090, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.625566, steer=0.011007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.30487220460216
22.16037081554532 seconds in game passed.
Action: tensor([[[0.0089, 0.6343],
         [0.0094, 0.3330],
         [0.0098, 0.2251],
         [0.0090, 0.1716]]])
agent 0 action: VehicleControl(throttle=0.609314, steer=0.011141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.30487220460216
+++++++++++++: 2.2464516263115386
22.18537081591785 seconds in game passed.
At 22.18537081591785 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6254],
         [0.0043, 0.3306],
         [0.0042, 0.2242],
         [0.0031, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.588930, steer=0.005195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2464516263115386
Current reward: 0.568063750573879
Current mitigation activation: 0
#############################
Total reward: 63.87293595517604
22.21037081629038 seconds in game passed.
Action: tensor([[[0.0033, 0.6254],
         [0.0043, 0.3306],
         [0.0042, 0.2242],
         [0.0031, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.574176, steer=0.006227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.87293595517604
22.235370816662908 seconds in game passed.
Action: tensor([[[0.0033, 0.6254],
         [0.0043, 0.3306],
         [0.0042, 0.2242],
         [0.0031, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.559459, steer=0.006262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.87293595517604
22.260370817035437 seconds in game passed.
Action: tensor([[[0.0033, 0.6254],
         [0.0043, 0.3306],
         [0.0042, 0.2242],
         [0.0031, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.545406, steer=0.006298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.87293595517604
+++++++++++++: 2.250488006031654
22.285370817407966 seconds in game passed.
At 22.285370817407966 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6223],
         [0.0053, 0.3289],
         [0.0053, 0.2231],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.563854, steer=0.007410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.250488006031654
Current reward: 0.5756791176807124
Current mitigation activation: 0
#############################
Total reward: 64.44861507285675
22.310370817780495 seconds in game passed.
Action: tensor([[[0.0042, 0.6223],
         [0.0053, 0.3289],
         [0.0053, 0.2231],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.547805, steer=0.007257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.44861507285675
22.335370818153024 seconds in game passed.
Action: tensor([[[0.0042, 0.6223],
         [0.0053, 0.3289],
         [0.0053, 0.2231],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.535762, steer=0.007286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.44861507285675
22.360370818525553 seconds in game passed.
Action: tensor([[[0.0042, 0.6223],
         [0.0053, 0.3289],
         [0.0053, 0.2231],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.524110, steer=0.007314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.44861507285675
+++++++++++++: 2.2600449399105007
22.385370818898082 seconds in game passed.
At 22.385370818898082 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6118],
         [0.0051, 0.3254],
         [0.0049, 0.2215],
         [0.0040, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.531194, steer=0.006895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2600449399105007
Current reward: 0.5823257583641012
Current mitigation activation: 0
#############################
Total reward: 65.03094083122086
22.41037081927061 seconds in game passed.
Action: tensor([[[0.0035, 0.6118],
         [0.0051, 0.3254],
         [0.0049, 0.2215],
         [0.0040, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.519426, steer=0.006987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.03094083122086
22.43537081964314 seconds in game passed.
Action: tensor([[[0.0035, 0.6118],
         [0.0051, 0.3254],
         [0.0049, 0.2215],
         [0.0040, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.509975, steer=0.007005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.03094083122086
22.46037082001567 seconds in game passed.
Action: tensor([[[0.0035, 0.6118],
         [0.0051, 0.3254],
         [0.0049, 0.2215],
         [0.0040, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.500870, steer=0.007024, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.03094083122086
+++++++++++++: 2.27408503146765
22.485370820388198 seconds in game passed.
At 22.485370820388198 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6112],
         [0.0025, 0.3261],
         [0.0021, 0.2222],
         [0.0011, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.461642, steer=0.004477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.27408503146765
Current reward: 0.5881900976484518
Current mitigation activation: 0
#############################
Total reward: 65.61913092886931
22.510370820760727 seconds in game passed.
Action: tensor([[[0.0018, 0.6112],
         [0.0025, 0.3261],
         [0.0021, 0.2222],
         [0.0011, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.455069, steer=0.004886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.61913092886931
22.535370821133256 seconds in game passed.
Action: tensor([[[0.0018, 0.6112],
         [0.0025, 0.3261],
         [0.0021, 0.2222],
         [0.0011, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.445837, steer=0.004873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.61913092886931
22.560370821505785 seconds in game passed.
Action: tensor([[[0.0018, 0.6112],
         [0.0025, 0.3261],
         [0.0021, 0.2222],
         [0.0011, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.437285, steer=0.004860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.61913092886931
+++++++++++++: 2.2917549571354914
22.585370821878314 seconds in game passed.
At 22.585370821878314 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6140],
         [0.0024, 0.3263],
         [0.0018, 0.2223],
         [0.0006, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.449909, steer=0.004977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2917549571354914
Current reward: 0.593426275794969
Current mitigation activation: 0
#############################
Total reward: 66.21255720466428
22.610370822250843 seconds in game passed.
Action: tensor([[[0.0025, 0.6140],
         [0.0024, 0.3263],
         [0.0018, 0.2223],
         [0.0006, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.439830, steer=0.004937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.21255720466428
22.635370822623372 seconds in game passed.
Action: tensor([[[0.0025, 0.6140],
         [0.0024, 0.3263],
         [0.0018, 0.2223],
         [0.0006, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.432486, steer=0.004920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.21255720466428
22.6603708229959 seconds in game passed.
Action: tensor([[[0.0025, 0.6140],
         [0.0024, 0.3263],
         [0.0018, 0.2223],
         [0.0006, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.425475, steer=0.004903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.21255720466428
+++++++++++++: 2.313782563194977
22.68537082336843 seconds in game passed.
At 22.68537082336843 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.6183],
         [0.0038, 0.3283],
         [0.0038, 0.2233],
         [0.0029, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.391599, steer=0.005944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.313782563194977
Current reward: 0.5979803740706152
Current mitigation activation: 0
#############################
Total reward: 66.8105375787349
22.71037082374096 seconds in game passed.
Action: tensor([[[0.0024, 0.6183],
         [0.0038, 0.3283],
         [0.0038, 0.2233],
         [0.0029, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.388566, steer=0.005783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.8105375787349
22.735370824113488 seconds in game passed.
Action: tensor([[[0.0024, 0.6183],
         [0.0038, 0.3283],
         [0.0038, 0.2233],
         [0.0029, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.383032, steer=0.005794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.8105375787349
22.760370824486017 seconds in game passed.
Action: tensor([[[0.0024, 0.6183],
         [0.0038, 0.3283],
         [0.0038, 0.2233],
         [0.0029, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.378080, steer=0.005805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.8105375787349
+++++++++++++: 2.3395582346157857
22.785370824858546 seconds in game passed.
At 22.785370824858546 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0039, 0.6209],
         [0.0059, 0.3299],
         [0.0060, 0.2241],
         [0.0051, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.341416, steer=0.007923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3395582346157857
Current reward: 0.6019903649938353
Current mitigation activation: 0
#############################
Total reward: 67.41252794372873
22.810370825231075 seconds in game passed.
Action: tensor([[[0.0039, 0.6209],
         [0.0059, 0.3299],
         [0.0060, 0.2241],
         [0.0051, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.339931, steer=0.007585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.41252794372873
22.835370825603604 seconds in game passed.
Action: tensor([[[0.0039, 0.6209],
         [0.0059, 0.3299],
         [0.0060, 0.2241],
         [0.0051, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.335623, steer=0.007598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.41252794372873
22.860370825976133 seconds in game passed.
Action: tensor([[[0.0039, 0.6209],
         [0.0059, 0.3299],
         [0.0060, 0.2241],
         [0.0051, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.331966, steer=0.007611, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.41252794372873
+++++++++++++: 2.369470206373297
22.885370826348662 seconds in game passed.
At 22.885370826348662 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6102],
         [0.0029, 0.3280],
         [0.0024, 0.2238],
         [0.0013, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.285353, steer=0.004808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.369470206373297
Current reward: 0.605457159158845
Current mitigation activation: 0
#############################
Total reward: 68.01798510288758
22.91037082672119 seconds in game passed.
Action: tensor([[[0.0025, 0.6102],
         [0.0029, 0.3280],
         [0.0024, 0.2238],
         [0.0013, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.286999, steer=0.005198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.01798510288758
22.93537082709372 seconds in game passed.
Action: tensor([[[0.0025, 0.6102],
         [0.0029, 0.3280],
         [0.0024, 0.2238],
         [0.0013, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.284702, steer=0.005131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.01798510288758
22.96037082746625 seconds in game passed.
Action: tensor([[[0.0025, 0.6102],
         [0.0029, 0.3280],
         [0.0024, 0.2238],
         [0.0013, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.283431, steer=0.005065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.01798510288758
+++++++++++++: 2.4041895744555064
22.98537082783878 seconds in game passed.
At 22.98537082783878 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1677e-03, 6.1284e-01],
         [1.6101e-03, 3.2728e-01],
         [1.2606e-03, 2.2290e-01],
         [2.6184e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.338403, steer=0.003455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4041895744555064
Current reward: 0.6083489318608624
Current mitigation activation: 0
#############################
Total reward: 68.62633403474844
23.010370828211308 seconds in game passed.
Action: tensor([[[1.1677e-03, 6.1284e-01],
         [1.6101e-03, 3.2728e-01],
         [1.2606e-03, 2.2290e-01],
         [2.6184e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.334046, steer=0.003546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.62633403474844
23.035370828583837 seconds in game passed.
Action: tensor([[[1.1677e-03, 6.1284e-01],
         [1.6101e-03, 3.2728e-01],
         [1.2606e-03, 2.2290e-01],
         [2.6184e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.336036, steer=0.003394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.62633403474844
23.060370828956366 seconds in game passed.
Action: tensor([[[1.1677e-03, 6.1284e-01],
         [1.6101e-03, 3.2728e-01],
         [1.2606e-03, 2.2290e-01],
         [2.6184e-04, 1.6932e-01]]])
agent 0 action: VehicleControl(throttle=0.338184, steer=0.003243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.62633403474844
+++++++++++++: 2.4436911484997963
23.085370829328895 seconds in game passed.
At 23.085370829328895 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.6265],
         [-0.0011,  0.3305],
         [-0.0016,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.362844, steer=-0.000020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4436911484997963
Current reward: 0.6107324916305286
Current mitigation activation: 0
#############################
Total reward: 69.23706652637897
23.110370829701424 seconds in game passed.
Action: tensor([[[-0.0019,  0.6265],
         [-0.0011,  0.3305],
         [-0.0016,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.363301, steer=0.000379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.23706652637897
23.135370830073953 seconds in game passed.
Action: tensor([[[-0.0019,  0.6265],
         [-0.0011,  0.3305],
         [-0.0016,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.366251, steer=0.000255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.23706652637897
23.16037083044648 seconds in game passed.
Action: tensor([[[-0.0019,  0.6265],
         [-0.0011,  0.3305],
         [-0.0016,  0.2238],
         [-0.0024,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.369191, steer=0.000131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.23706652637897
+++++++++++++: 2.4846624423852455
23.18537083081901 seconds in game passed.
At 23.18537083081901 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6118],
         [-0.0016,  0.3258],
         [-0.0022,  0.2213],
         [-0.0032,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.395489, steer=-0.000438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4846624423852455
Current reward: 0.6130752427794202
Current mitigation activation: 0
#############################
Total reward: 69.85014176915838
23.21037083119154 seconds in game passed.
Action: tensor([[[-0.0021,  0.6118],
         [-0.0016,  0.3258],
         [-0.0022,  0.2213],
         [-0.0032,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.396327, steer=-0.000421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.85014176915838
23.23537083156407 seconds in game passed.
Action: tensor([[[-0.0021,  0.6118],
         [-0.0016,  0.3258],
         [-0.0022,  0.2213],
         [-0.0032,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.399589, steer=-0.000488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.85014176915838
23.260370831936598 seconds in game passed.
Action: tensor([[[-0.0021,  0.6118],
         [-0.0016,  0.3258],
         [-0.0022,  0.2213],
         [-0.0032,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.402669, steer=-0.000556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.85014176915838
+++++++++++++: 2.52477342486994
23.285370832309127 seconds in game passed.
At 23.285370832309127 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0036,  0.6161],
         [-0.0038,  0.3280],
         [-0.0041,  0.2229],
         [-0.0048,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.366007, steer=-0.002862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.52477342486994
Current reward: 0.6156627024039332
Current mitigation activation: 0
#############################
Total reward: 70.46580447156232
23.310370832681656 seconds in game passed.
Action: tensor([[[-0.0036,  0.6161],
         [-0.0038,  0.3280],
         [-0.0041,  0.2229],
         [-0.0048,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.372225, steer=-0.002596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46580447156232
23.335370833054185 seconds in game passed.
Action: tensor([[[-0.0036,  0.6161],
         [-0.0038,  0.3280],
         [-0.0041,  0.2229],
         [-0.0048,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.374301, steer=-0.002697, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46580447156232
23.360370833426714 seconds in game passed.
Action: tensor([[[-0.0036,  0.6161],
         [-0.0038,  0.3280],
         [-0.0041,  0.2229],
         [-0.0048,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.376621, steer=-0.002799, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46580447156232
+++++++++++++: 2.5631704100818284
23.385370833799243 seconds in game passed.
At 23.385370833799243 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.8445e-04,  6.0278e-01],
         [-8.8254e-04,  3.2500e-01],
         [-1.1382e-03,  2.2187e-01],
         [-1.7419e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.349699, steer=0.000629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5631704100818284
Current reward: 0.6185697673548813
Current mitigation activation: 0
#############################
Total reward: 71.0843742389172
23.410370834171772 seconds in game passed.
Action: tensor([[[-1.8445e-04,  6.0278e-01],
         [-8.8254e-04,  3.2500e-01],
         [-1.1382e-03,  2.2187e-01],
         [-1.7419e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.354853, steer=-0.000013, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.0843742389172
23.4353708345443 seconds in game passed.
Action: tensor([[[-1.8445e-04,  6.0278e-01],
         [-8.8254e-04,  3.2500e-01],
         [-1.1382e-03,  2.2187e-01],
         [-1.7419e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.357091, steer=-0.000073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.0843742389172
23.46037083491683 seconds in game passed.
Action: tensor([[[-1.8445e-04,  6.0278e-01],
         [-8.8254e-04,  3.2500e-01],
         [-1.1382e-03,  2.2187e-01],
         [-1.7419e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.359653, steer=-0.000134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.0843742389172
+++++++++++++: 2.6015215516016243
23.48537083528936 seconds in game passed.
At 23.48537083528936 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.6100],
         [-0.0009,  0.3275],
         [-0.0014,  0.2228],
         [-0.0021,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.346447, steer=-0.000450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6015215516016243
Current reward: 0.6215738740118878
Current mitigation activation: 0
#############################
Total reward: 71.7059481129291
23.510370835661888 seconds in game passed.
Action: tensor([[[-0.0008,  0.6100],
         [-0.0009,  0.3275],
         [-0.0014,  0.2228],
         [-0.0021,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.351278, steer=-0.000440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.7059481129291
23.535370836034417 seconds in game passed.
Action: tensor([[[-0.0008,  0.6100],
         [-0.0009,  0.3275],
         [-0.0014,  0.2228],
         [-0.0021,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.354564, steer=-0.000478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.7059481129291
23.560370836406946 seconds in game passed.
Action: tensor([[[-0.0008,  0.6100],
         [-0.0009,  0.3275],
         [-0.0014,  0.2228],
         [-0.0021,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.358082, steer=-0.000515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.7059481129291
+++++++++++++: 2.6410890302470165
23.585370836779475 seconds in game passed.
At 23.585370836779475 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.8772e-04,  6.1877e-01],
         [ 3.9130e-04,  3.3063e-01],
         [-3.5515e-04,  2.2426e-01],
         [-1.3963e-03,  1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.340251, steer=0.000937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6410890302470165
Current reward: 0.6245246603141037
Current mitigation activation: 0
#############################
Total reward: 72.3304727732432
23.610370837152004 seconds in game passed.
Action: tensor([[[ 4.8772e-04,  6.1877e-01],
         [ 3.9130e-04,  3.3063e-01],
         [-3.5515e-04,  2.2426e-01],
         [-1.3963e-03,  1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.345807, steer=0.000668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.3304727732432
23.635370837524533 seconds in game passed.
Action: tensor([[[ 4.8772e-04,  6.1877e-01],
         [ 3.9130e-04,  3.3063e-01],
         [-3.5515e-04,  2.2426e-01],
         [-1.3963e-03,  1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.349234, steer=0.000645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.3304727732432
23.660370837897062 seconds in game passed.
Action: tensor([[[ 4.8772e-04,  6.1877e-01],
         [ 3.9130e-04,  3.3063e-01],
         [-3.5515e-04,  2.2426e-01],
         [-1.3963e-03,  1.7048e-01]]])
agent 0 action: VehicleControl(throttle=0.352874, steer=0.000622, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.3304727732432
+++++++++++++: 2.6818782605386464
23.68537083826959 seconds in game passed.
At 23.68537083826959 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.5807e-03, 6.2492e-01],
         [2.0741e-03, 3.3219e-01],
         [1.2072e-03, 2.2636e-01],
         [2.3074e-04, 1.7213e-01]]])
agent 0 action: VehicleControl(throttle=0.363804, steer=0.003455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6818782605386464
Current reward: 0.627429274955422
Current mitigation activation: 0
#############################
Total reward: 72.95790204819862
23.71037083864212 seconds in game passed.
Action: tensor([[[4.5807e-03, 6.2492e-01],
         [2.0741e-03, 3.3219e-01],
         [1.2072e-03, 2.2636e-01],
         [2.3074e-04, 1.7213e-01]]])
agent 0 action: VehicleControl(throttle=0.367297, steer=0.002978, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.95790204819862
23.73537083901465 seconds in game passed.
Action: tensor([[[4.5807e-03, 6.2492e-01],
         [2.0741e-03, 3.3219e-01],
         [1.2072e-03, 2.2636e-01],
         [2.3074e-04, 1.7213e-01]]])
agent 0 action: VehicleControl(throttle=0.371546, steer=0.002973, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.95790204819862
23.76037083938718 seconds in game passed.
Action: tensor([[[4.5807e-03, 6.2492e-01],
         [2.0741e-03, 3.3219e-01],
         [1.2072e-03, 2.2636e-01],
         [2.3074e-04, 1.7213e-01]]])
agent 0 action: VehicleControl(throttle=0.375728, steer=0.002969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.95790204819862
+++++++++++++: 2.7236705440104862
23.785370839759707 seconds in game passed.
At 23.785370839759707 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.7704e-03,  6.1600e-01],
         [-4.3849e-04,  3.2796e-01],
         [-8.1377e-04,  2.2391e-01],
         [-1.2327e-03,  1.7032e-01]]])
agent 0 action: VehicleControl(throttle=0.441555, steer=-0.000034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7236705440104862
Current reward: 0.6303247152080016
Current mitigation activation: 0
#############################
Total reward: 73.58822676340662
23.810370840132236 seconds in game passed.
Action: tensor([[[ 1.7704e-03,  6.1600e-01],
         [-4.3849e-04,  3.2796e-01],
         [-8.1377e-04,  2.2391e-01],
         [-1.2327e-03,  1.7032e-01]]])
agent 0 action: VehicleControl(throttle=0.440090, steer=0.000401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.58822676340662
23.835370840504766 seconds in game passed.
Action: tensor([[[ 1.7704e-03,  6.1600e-01],
         [-4.3849e-04,  3.2796e-01],
         [-8.1377e-04,  2.2391e-01],
         [-1.2327e-03,  1.7032e-01]]])
agent 0 action: VehicleControl(throttle=0.444827, steer=0.000344, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.58822676340662
23.860370840877295 seconds in game passed.
Action: tensor([[[ 1.7704e-03,  6.1600e-01],
         [-4.3849e-04,  3.2796e-01],
         [-8.1377e-04,  2.2391e-01],
         [-1.2327e-03,  1.7032e-01]]])
agent 0 action: VehicleControl(throttle=0.448899, steer=0.000287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.58822676340662
+++++++++++++: 2.7649057628208693
23.885370841249824 seconds in game passed.
At 23.885370841249824 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.4663e-04,  6.1720e-01],
         [-2.4774e-03,  3.2848e-01],
         [-2.8974e-03,  2.2388e-01],
         [-3.3024e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.446551, steer=-0.002130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7649057628208693
Current reward: 0.6333771607213201
Current mitigation activation: 0
#############################
Total reward: 74.22160392412795
23.910370841622353 seconds in game passed.
Action: tensor([[[-4.4663e-04,  6.1720e-01],
         [-2.4774e-03,  3.2848e-01],
         [-2.8974e-03,  2.2388e-01],
         [-3.3024e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.450734, steer=-0.001789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.22160392412795
23.93537084199488 seconds in game passed.
Action: tensor([[[-4.4663e-04,  6.1720e-01],
         [-2.4774e-03,  3.2848e-01],
         [-2.8974e-03,  2.2388e-01],
         [-3.3024e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.453827, steer=-0.001842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.22160392412795
23.96037084236741 seconds in game passed.
Action: tensor([[[-4.4663e-04,  6.1720e-01],
         [-2.4774e-03,  3.2848e-01],
         [-2.8974e-03,  2.2388e-01],
         [-3.3024e-03,  1.6989e-01]]])
agent 0 action: VehicleControl(throttle=0.456555, steer=-0.001895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.22160392412795
+++++++++++++: 2.8025078326698534
23.98537084273994 seconds in game passed.
At 23.98537084273994 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.6796e-04,  6.1281e-01],
         [-2.2673e-03,  3.2729e-01],
         [-2.5992e-03,  2.2282e-01],
         [-2.9386e-03,  1.6892e-01]]])
agent 0 action: VehicleControl(throttle=0.456034, steer=-0.001783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8025078326698534
Current reward: 0.6368894577292098
Current mitigation activation: 0
#############################
Total reward: 74.85849338185716
24.01037084311247 seconds in game passed.
Action: tensor([[[-4.6796e-04,  6.1281e-01],
         [-2.2673e-03,  3.2729e-01],
         [-2.5992e-03,  2.2282e-01],
         [-2.9386e-03,  1.6892e-01]]])
agent 0 action: VehicleControl(throttle=0.457687, steer=-0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.85849338185716
24.035370843484998 seconds in game passed.
Action: tensor([[[-4.6796e-04,  6.1281e-01],
         [-2.2673e-03,  3.2729e-01],
         [-2.5992e-03,  2.2282e-01],
         [-2.9386e-03,  1.6892e-01]]])
agent 0 action: VehicleControl(throttle=0.458790, steer=-0.001881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.85849338185716
24.060370843857527 seconds in game passed.
Action: tensor([[[-4.6796e-04,  6.1281e-01],
         [-2.2673e-03,  3.2729e-01],
         [-2.5992e-03,  2.2282e-01],
         [-2.9386e-03,  1.6892e-01]]])
agent 0 action: VehicleControl(throttle=0.459629, steer=-0.001917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.85849338185716
+++++++++++++: 2.836827035133229
24.085370844230056 seconds in game passed.
At 24.085370844230056 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0037,  0.6130],
         [-0.0066,  0.3275],
         [-0.0072,  0.2227],
         [-0.0075,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.453423, steer=-0.006432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.836827035133229
Current reward: 0.6407816691205601
Current mitigation activation: 0
#############################
Total reward: 75.49927505097772
24.110370844602585 seconds in game passed.
Action: tensor([[[-0.0037,  0.6130],
         [-0.0066,  0.3275],
         [-0.0072,  0.2227],
         [-0.0075,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.454166, steer=-0.005738, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.49927505097772
24.135370844975114 seconds in game passed.
Action: tensor([[[-0.0037,  0.6130],
         [-0.0066,  0.3275],
         [-0.0072,  0.2227],
         [-0.0075,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.454075, steer=-0.005788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.49927505097772
24.160370845347643 seconds in game passed.
Action: tensor([[[-0.0037,  0.6130],
         [-0.0066,  0.3275],
         [-0.0072,  0.2227],
         [-0.0075,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.453828, steer=-0.005838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.49927505097772
+++++++++++++: 2.8690636683980806
24.185370845720172 seconds in game passed.
At 24.185370845720172 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6050],
         [-0.0023,  0.3255],
         [-0.0023,  0.2218],
         [-0.0027,  0.1682]]])
agent 0 action: VehicleControl(throttle=0.442742, steer=-0.002177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8690636683980806
Current reward: 0.6448882845127162
Current mitigation activation: 0
#############################
Total reward: 76.14416333549043
24.2103708460927 seconds in game passed.
Action: tensor([[[-0.0025,  0.6050],
         [-0.0023,  0.3255],
         [-0.0023,  0.2218],
         [-0.0027,  0.1682]]])
agent 0 action: VehicleControl(throttle=0.442997, steer=-0.002795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.14416333549043
24.23537084646523 seconds in game passed.
Action: tensor([[[-0.0025,  0.6050],
         [-0.0023,  0.3255],
         [-0.0023,  0.2218],
         [-0.0027,  0.1682]]])
agent 0 action: VehicleControl(throttle=0.442062, steer=-0.002802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.14416333549043
24.26037084683776 seconds in game passed.
Action: tensor([[[-0.0025,  0.6050],
         [-0.0023,  0.3255],
         [-0.0023,  0.2218],
         [-0.0027,  0.1682]]])
agent 0 action: VehicleControl(throttle=0.441147, steer=-0.002809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.14416333549043
+++++++++++++: 2.9003972241001184
24.285370847210288 seconds in game passed.
At 24.285370847210288 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.4945e-04,  6.0357e-01],
         [ 7.3182e-04,  3.2549e-01],
         [ 8.2288e-04,  2.2190e-01],
         [ 3.6813e-04,  1.6833e-01]]])
agent 0 action: VehicleControl(throttle=0.426116, steer=0.000279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9003972241001184
Current reward: 0.649071107577061
Current mitigation activation: 0
#############################
Total reward: 76.79323444306749
24.310370847582817 seconds in game passed.
Action: tensor([[[-3.4945e-04,  6.0357e-01],
         [ 7.3182e-04,  3.2549e-01],
         [ 8.2288e-04,  2.2190e-01],
         [ 3.6813e-04,  1.6833e-01]]])
agent 0 action: VehicleControl(throttle=0.427017, steer=-0.000180, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.79323444306749
24.335370847955346 seconds in game passed.
Action: tensor([[[-3.4945e-04,  6.0357e-01],
         [ 7.3182e-04,  3.2549e-01],
         [ 8.2288e-04,  2.2190e-01],
         [ 3.6813e-04,  1.6833e-01]]])
agent 0 action: VehicleControl(throttle=0.426424, steer=-0.000132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.79323444306749
24.360370848327875 seconds in game passed.
Action: tensor([[[-3.4945e-04,  6.0357e-01],
         [ 7.3182e-04,  3.2549e-01],
         [ 8.2288e-04,  2.2190e-01],
         [ 3.6813e-04,  1.6833e-01]]])
agent 0 action: VehicleControl(throttle=0.425954, steer=-0.000084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.79323444306749
+++++++++++++: 2.931924126416502
24.385370848700404 seconds in game passed.
At 24.385370848700404 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.6042],
         [0.0020, 0.3261],
         [0.0019, 0.2226],
         [0.0015, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.408651, steer=0.001612, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.931924126416502
Current reward: 0.6532151199806712
Current mitigation activation: 0
#############################
Total reward: 77.44644956304816
24.410370849072933 seconds in game passed.
Action: tensor([[[0.0016, 0.6042],
         [0.0020, 0.3261],
         [0.0019, 0.2226],
         [0.0015, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.410284, steer=0.001363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.44644956304816
24.435370849445462 seconds in game passed.
Action: tensor([[[0.0016, 0.6042],
         [0.0020, 0.3261],
         [0.0019, 0.2226],
         [0.0015, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.410199, steer=0.001392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.44644956304816
24.46037084981799 seconds in game passed.
Action: tensor([[[0.0016, 0.6042],
         [0.0020, 0.3261],
         [0.0019, 0.2226],
         [0.0015, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.410295, steer=0.001421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.44644956304816
+++++++++++++: 2.964535975792348
24.48537085019052 seconds in game passed.
At 24.48537085019052 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0029, 0.6066],
         [0.0026, 0.3260],
         [0.0024, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.442255, steer=0.002393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.964535975792348
Current reward: 0.6572294700938031
Current mitigation activation: 0
#############################
Total reward: 78.10367903314196
24.51037085056305 seconds in game passed.
Action: tensor([[[0.0029, 0.6066],
         [0.0026, 0.3260],
         [0.0024, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.439749, steer=0.002279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.10367903314196
24.53537085093558 seconds in game passed.
Action: tensor([[[0.0029, 0.6066],
         [0.0026, 0.3260],
         [0.0024, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.440571, steer=0.002321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.10367903314196
24.560370851308107 seconds in game passed.
Action: tensor([[[0.0029, 0.6066],
         [0.0026, 0.3260],
         [0.0024, 0.2229],
         [0.0019, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.441166, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.10367903314196
+++++++++++++: 2.9984697549118535
24.585370851680636 seconds in game passed.
At 24.585370851680636 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0030, 0.6091],
         [0.0019, 0.3266],
         [0.0020, 0.2231],
         [0.0020, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.445358, steer=0.001932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9984697549118535
Current reward: 0.6610990305209158
Current mitigation activation: 0
#############################
Total reward: 78.76477806366287
24.610370852053165 seconds in game passed.
Action: tensor([[[0.0030, 0.6091],
         [0.0019, 0.3266],
         [0.0020, 0.2231],
         [0.0020, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.445560, steer=0.002029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.76477806366287
24.635370852425694 seconds in game passed.
Action: tensor([[[0.0030, 0.6091],
         [0.0019, 0.3266],
         [0.0020, 0.2231],
         [0.0020, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.445991, steer=0.002050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.76477806366287
24.660370852798223 seconds in game passed.
Action: tensor([[[0.0030, 0.6091],
         [0.0019, 0.3266],
         [0.0020, 0.2231],
         [0.0020, 0.1693]]])
agent 0 action: VehicleControl(throttle=0.446266, steer=0.002072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.76477806366287
+++++++++++++: 3.031920262389042
24.685370853170753 seconds in game passed.
At 24.685370853170753 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.3140e-04, 6.2615e-01],
         [1.2787e-04, 3.2971e-01],
         [4.6574e-05, 2.2370e-01],
         [5.4315e-06, 1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.508505, steer=-0.000044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.031920262389042
Current reward: 0.6650073865127
Current mitigation activation: 0
#############################
Total reward: 79.42978545017557
24.71037085354328 seconds in game passed.
Action: tensor([[[9.3140e-04, 6.2615e-01],
         [1.2787e-04, 3.2971e-01],
         [4.6574e-05, 2.2370e-01],
         [5.4315e-06, 1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.502539, steer=0.000274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.42978545017557
24.73537085391581 seconds in game passed.
Action: tensor([[[9.3140e-04, 6.2615e-01],
         [1.2787e-04, 3.2971e-01],
         [4.6574e-05, 2.2370e-01],
         [5.4315e-06, 1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.502865, steer=0.000244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.42978545017557
24.76037085428834 seconds in game passed.
Action: tensor([[[9.3140e-04, 6.2615e-01],
         [1.2787e-04, 3.2971e-01],
         [4.6574e-05, 2.2370e-01],
         [5.4315e-06, 1.6951e-01]]])
agent 0 action: VehicleControl(throttle=0.502549, steer=0.000215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.42978545017557
+++++++++++++: 3.0639381404057624
24.78537085466087 seconds in game passed.
At 24.78537085466087 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6067],
         [-0.0036,  0.3247],
         [-0.0043,  0.2216],
         [-0.0047,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.483933, steer=-0.003476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0639381404057624
Current reward: 0.6690248765744644
Current mitigation activation: 0
#############################
Total reward: 80.09881032675004
24.810370855033398 seconds in game passed.
Action: tensor([[[-0.0014,  0.6067],
         [-0.0036,  0.3247],
         [-0.0043,  0.2216],
         [-0.0047,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.483726, steer=-0.002904, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.09881032675004
24.835370855405927 seconds in game passed.
Action: tensor([[[-0.0014,  0.6067],
         [-0.0036,  0.3247],
         [-0.0043,  0.2216],
         [-0.0047,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.481441, steer=-0.002941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.09881032675004
24.860370855778456 seconds in game passed.
Action: tensor([[[-0.0014,  0.6067],
         [-0.0036,  0.3247],
         [-0.0043,  0.2216],
         [-0.0047,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.479023, steer=-0.002978, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.09881032675004
+++++++++++++: 3.0925582290338762
24.885370856150985 seconds in game passed.
At 24.885370856150985 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0051,  0.6199],
         [-0.0093,  0.3281],
         [-0.0100,  0.2227],
         [-0.0102,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.490471, steer=-0.008682, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0925582290338762
Current reward: 0.6732660159574638
Current mitigation activation: 0
#############################
Total reward: 80.7720763427075
24.910370856523514 seconds in game passed.
Action: tensor([[[-0.0051,  0.6199],
         [-0.0093,  0.3281],
         [-0.0100,  0.2227],
         [-0.0102,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.486623, steer=-0.007814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.7720763427075
24.935370856896043 seconds in game passed.
Action: tensor([[[-0.0051,  0.6199],
         [-0.0093,  0.3281],
         [-0.0100,  0.2227],
         [-0.0102,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.484242, steer=-0.007885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.7720763427075
24.960370857268572 seconds in game passed.
Action: tensor([[[-0.0051,  0.6199],
         [-0.0093,  0.3281],
         [-0.0100,  0.2227],
         [-0.0102,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.481670, steer=-0.007957, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.7720763427075
+++++++++++++: 3.1192841236521325
24.9853708576411 seconds in game passed.
At 24.9853708576411 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0038,  0.6137],
         [-0.0061,  0.3265],
         [-0.0064,  0.2223],
         [-0.0066,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.471419, steer=-0.005118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1192841236521325
Current reward: 0.676934008585282
Current mitigation activation: 0
#############################
Total reward: 81.44901035129278
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 19:04:24 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 19:05:10 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 46.62s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 23.45s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.503               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 81.45, average_reward: 81.44901035129278 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00005/fi_lead_slowdown_data
