New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185837-fi_lead_slowdown_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185837-fi_lead_slowdown_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185837-fi_lead_slowdown_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185837-fi_lead_slowdown_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185837-fi_lead_slowdown_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_logs/routes_fi_route_highway-1127_185837-fi_lead_slowdown_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_data/route_highway.xml_fi_lead_slowdown.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key first_vehicle_location's value from 50 to 30.
Replacing key first_vehicle_speed's value from 10 to 0.
Replacing key event_trigger_distance's value from 35 to 25.
Config for LeadSlowDown scenario is {'first_vehicle_location': 30, 'first_vehicle_speed': 0, 'other_actor_max_brake': 1.0, 'event_trigger_distance': 25}
1.5212857313454151 seconds in game passed.
Action: tensor([[[0.0033, 0.5921],
         [0.0022, 0.3306],
         [0.0019, 0.2345],
         [0.0012, 0.1819]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002928, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5462857317179441 seconds in game passed.
Action: tensor([[[0.0033, 0.5921],
         [0.0022, 0.3306],
         [0.0019, 0.2345],
         [0.0012, 0.1819]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5712857320904732 seconds in game passed.
Action: tensor([[[0.0033, 0.5921],
         [0.0022, 0.3306],
         [0.0019, 0.2345],
         [0.0012, 0.1819]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002505, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5962857324630022 seconds in game passed.
Action: tensor([[[0.0033, 0.5921],
         [0.0022, 0.3306],
         [0.0019, 0.2345],
         [0.0012, 0.1819]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6212857328355312 seconds in game passed.
Action: tensor([[[0.0033, 0.5921],
         [0.0022, 0.3306],
         [0.0019, 0.2345],
         [0.0012, 0.1819]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6462857332080603 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.6712857335805893 seconds in game passed.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6962857339531183 seconds in game passed.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003721, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7212857343256474 seconds in game passed.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7462857346981764 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7712857350707054 seconds in game passed.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7962857354432344 seconds in game passed.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8212857358157635 seconds in game passed.
Action: tensor([[[0.0048, 0.5949],
         [0.0021, 0.3242],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8462857361882925 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8712857365608215 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8962857369333506 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9212857373058796 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002669, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9462857376784086 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9712857380509377 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002405, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9962857384234667 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0212857387959957 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0462857391685247 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4557e-03, 5.9047e-01],
         [1.3427e-03, 3.2230e-01],
         [1.1138e-03, 2.2210e-01],
         [5.7025e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0712857395410538 seconds in game passed.
Action: tensor([[[2.4557e-03, 5.9047e-01],
         [1.3427e-03, 3.2230e-01],
         [1.1138e-03, 2.2210e-01],
         [5.7025e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.096285739913583 seconds in game passed.
Action: tensor([[[2.4557e-03, 5.9047e-01],
         [1.3427e-03, 3.2230e-01],
         [1.1138e-03, 2.2210e-01],
         [5.7025e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002347, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.121285740286112 seconds in game passed.
Action: tensor([[[2.4557e-03, 5.9047e-01],
         [1.3427e-03, 3.2230e-01],
         [1.1138e-03, 2.2210e-01],
         [5.7025e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.146285740658641 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.17128574103117 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.196285741403699 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.221285741776228 seconds in game passed.
Action: tensor([[[0.0023, 0.5894],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.246285742148757 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.271285742521286 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.296285742893815 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.321285743266344 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.346285743638873 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.371285744011402 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.396285744383931 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.42128574475646 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.446285745128989 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4712857455015182 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4962857458740473 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5212857462465763 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5462857466191053 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5712857469916344 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5962857473641634 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6212857477366924 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6462857481092215 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6712857484817505 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6962857488542795 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7212857492268085 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002591, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7462857495993376 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.7712857499718666 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7962857503443956 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8212857507169247 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.8462857510894537 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.8712857514619827 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8962857518345118 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.921285752207041 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.94628575257957 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.971285752952099 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.996285753324628 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.021285753697157 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.046285754069686 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.071285754442215 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.096285754814744 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.121285755187273 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.146285755559802 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.171285755932331 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.19628575630486 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.221285756677389 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.246285757049918 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.271285757422447 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2962857577949762 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3212857581675053 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3462857585400343 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3712857589125633 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3962857592850924 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4212857596576214 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4462857600301504 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4712857604026794 seconds in game passed.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4962857607752085 seconds in game passed.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5212857611477375 seconds in game passed.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5462857615202665 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5712857618927956 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5962857622653246 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6212857626378536 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6462857630103827 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6712857633829117 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6962857637554407 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7212857641279697 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7462857645004988 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.771285764873028 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.796285765245557 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.821285765618086 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.846285765990615 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.871285766363144 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.896285766735673 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.921285767108202 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 74.3611691738909
3.946285767480731 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0
3.97128576785326 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.996285768225789 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.021285768598318 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 19.655274201662667
4.046285768970847 seconds in game passed.
At 4.046285768970847 seconds, saving state-action tuples.
Action: tensor([[[1.4136e-03, 5.8607e-01],
         [1.1369e-03, 3.2067e-01],
         [1.0024e-03, 2.2100e-01],
         [3.5026e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.2485170261106222
4.071285769343376 seconds in game passed.
Action: tensor([[[1.4136e-03, 5.8607e-01],
         [1.1369e-03, 3.2067e-01],
         [1.0024e-03, 2.2100e-01],
         [3.5026e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.096285769715905 seconds in game passed.
Action: tensor([[[1.4136e-03, 5.8607e-01],
         [1.1369e-03, 3.2067e-01],
         [1.0024e-03, 2.2100e-01],
         [3.5026e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
4.121285770088434 seconds in game passed.
Action: tensor([[[1.4136e-03, 5.8607e-01],
         [1.1369e-03, 3.2067e-01],
         [1.0024e-03, 2.2100e-01],
         [3.5026e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001907, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.2485170261106222
+++++++++++++: 11.883738821806649
4.146285770460963 seconds in game passed.
At 4.146285770460963 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5837],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002134, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.65612528475237
4.171285770833492 seconds in game passed.
Action: tensor([[[0.0017, 0.5837],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002094, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
4.196285771206021 seconds in game passed.
Action: tensor([[[0.0017, 0.5837],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
4.22128577157855 seconds in game passed.
Action: tensor([[[0.0017, 0.5837],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.65612528475237
+++++++++++++: 8.843383999601484
4.246285771951079 seconds in game passed.
At 4.246285771951079 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 8.843383999601484
Current reward: 0.49259322239340864
Current mitigation activation: 0
#############################
Total reward: 1.1487185071457786
4.271285772323608 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.296285772696137 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002951, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
4.3212857730686665 seconds in game passed.
Action: tensor([[[0.0023, 0.5817],
         [0.0024, 0.3200],
         [0.0026, 0.2209],
         [0.0023, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002958, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.1487185071457786
+++++++++++++: 7.228547872515916
4.3462857734411955 seconds in game passed.
At 4.3462857734411955 seconds, saving state-action tuples.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.228547872515916
Current reward: 0.5118171203336291
Current mitigation activation: 0
#############################
Total reward: 1.6605356274794079
4.3712857738137245 seconds in game passed.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
4.3962857741862535 seconds in game passed.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
4.421285774558783 seconds in game passed.
Action: tensor([[[0.0028, 0.5861],
         [0.0030, 0.3216],
         [0.0034, 0.2215],
         [0.0032, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6605356274794079
+++++++++++++: 6.215940449165687
4.446285774931312 seconds in game passed.
At 4.446285774931312 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002781, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 6.215940449165687
Current reward: 0.5264941677236088
Current mitigation activation: 0
#############################
Total reward: 2.1870297952030167
4.471285775303841 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
4.49628577567637 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
4.521285776048899 seconds in game passed.
Action: tensor([[[0.0021, 0.5898],
         [0.0023, 0.3221],
         [0.0024, 0.2213],
         [0.0022, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.1870297952030167
+++++++++++++: 5.508366078862486
4.546285776421428 seconds in game passed.
At 4.546285776421428 seconds, saving state-action tuples.
Action: tensor([[[-1.0405e-04,  5.8862e-01],
         [ 1.6533e-04,  3.2202e-01],
         [ 2.8570e-04,  2.2122e-01],
         [-9.3430e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.508366078862486
Current reward: 0.5376235138087542
Current mitigation activation: 0
#############################
Total reward: 2.724653309011771
4.571285776793957 seconds in game passed.
Action: tensor([[[-1.0405e-04,  5.8862e-01],
         [ 1.6533e-04,  3.2202e-01],
         [ 2.8570e-04,  2.2122e-01],
         [-9.3430e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
4.596285777166486 seconds in game passed.
Action: tensor([[[-1.0405e-04,  5.8862e-01],
         [ 1.6533e-04,  3.2202e-01],
         [ 2.8570e-04,  2.2122e-01],
         [-9.3430e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
4.621285777539015 seconds in game passed.
Action: tensor([[[-1.0405e-04,  5.8862e-01],
         [ 1.6533e-04,  3.2202e-01],
         [ 2.8570e-04,  2.2122e-01],
         [-9.3430e-05,  1.6750e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.724653309011771
+++++++++++++: 4.97613284310945
4.646285777911544 seconds in game passed.
At 4.646285777911544 seconds, saving state-action tuples.
Action: tensor([[[ 2.9222e-04,  5.8912e-01],
         [-2.9161e-04,  3.2136e-01],
         [-1.9711e-04,  2.2103e-01],
         [-3.5939e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000663, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.97613284310945
Current reward: 0.5459292759962195
Current mitigation activation: 0
#############################
Total reward: 3.2705825850079906
4.671285778284073 seconds in game passed.
Action: tensor([[[ 2.9222e-04,  5.8912e-01],
         [-2.9161e-04,  3.2136e-01],
         [-1.9711e-04,  2.2103e-01],
         [-3.5939e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825850079906
4.696285778656602 seconds in game passed.
Action: tensor([[[ 2.9222e-04,  5.8912e-01],
         [-2.9161e-04,  3.2136e-01],
         [-1.9711e-04,  2.2103e-01],
         [-3.5939e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825850079906
4.721285779029131 seconds in game passed.
Action: tensor([[[ 2.9222e-04,  5.8912e-01],
         [-2.9161e-04,  3.2136e-01],
         [-1.9711e-04,  2.2103e-01],
         [-3.5939e-04,  1.6751e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.2705825850079906
+++++++++++++: 4.552591376135179
4.74628577940166 seconds in game passed.
At 4.74628577940166 seconds, saving state-action tuples.
Action: tensor([[[-2.6516e-04,  5.9080e-01],
         [-9.5794e-04,  3.2155e-01],
         [-8.3447e-04,  2.2111e-01],
         [-9.6729e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.552591376135179
Current reward: 0.5519989175021012
Current mitigation activation: 0
#############################
Total reward: 3.8225815025100918
4.771285779774189 seconds in game passed.
Action: tensor([[[-2.6516e-04,  5.9080e-01],
         [-9.5794e-04,  3.2155e-01],
         [-8.3447e-04,  2.2111e-01],
         [-9.6729e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225815025100918
4.796285780146718 seconds in game passed.
Action: tensor([[[-2.6516e-04,  5.9080e-01],
         [-9.5794e-04,  3.2155e-01],
         [-8.3447e-04,  2.2111e-01],
         [-9.6729e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225815025100918
4.821285780519247 seconds in game passed.
Action: tensor([[[-2.6516e-04,  5.9080e-01],
         [-9.5794e-04,  3.2155e-01],
         [-8.3447e-04,  2.2111e-01],
         [-9.6729e-04,  1.6749e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8225815025100918
+++++++++++++: 4.199611186046198
4.846285780891776 seconds in game passed.
At 4.846285780891776 seconds, saving state-action tuples.
Action: tensor([[[ 5.5845e-04,  5.9001e-01],
         [-5.6878e-04,  3.2161e-01],
         [-4.3822e-04,  2.2127e-01],
         [-4.6369e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.199611186046198
Current reward: 0.5563326768472109
Current mitigation activation: 0
#############################
Total reward: 4.378914179357302
4.871285781264305 seconds in game passed.
Action: tensor([[[ 5.5845e-04,  5.9001e-01],
         [-5.6878e-04,  3.2161e-01],
         [-4.3822e-04,  2.2127e-01],
         [-4.6369e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914179357302
4.896285781636834 seconds in game passed.
Action: tensor([[[ 5.5845e-04,  5.9001e-01],
         [-5.6878e-04,  3.2161e-01],
         [-4.3822e-04,  2.2127e-01],
         [-4.6369e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914179357302
4.921285782009363 seconds in game passed.
Action: tensor([[[ 5.5845e-04,  5.9001e-01],
         [-5.6878e-04,  3.2161e-01],
         [-4.3822e-04,  2.2127e-01],
         [-4.6369e-04,  1.6781e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.378914179357302
+++++++++++++: 3.8947631908725375
4.946285782381892 seconds in game passed.
At 4.946285782381892 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5880],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.8947631908725375
Current reward: 0.5593082190793719
Current mitigation activation: 0
#############################
Total reward: 4.938222398436674
4.971285782754421 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222398436674
4.99628578312695 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222398436674
5.021285783499479 seconds in game passed.
Action: tensor([[[0.0016, 0.5880],
         [0.0008, 0.3215],
         [0.0011, 0.2218],
         [0.0013, 0.1684]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.938222398436674
+++++++++++++: 3.6246755571702436
5.046285783872008 seconds in game passed.
At 5.046285783872008 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2810e-03, 5.8981e-01],
         [1.0696e-03, 3.2204e-01],
         [9.3266e-04, 2.2280e-01],
         [5.7973e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.6246755571702436
Current reward: 0.5611771359376196
Current mitigation activation: 0
#############################
Total reward: 5.4993995343742945
5.071285784244537 seconds in game passed.
Action: tensor([[[1.2810e-03, 5.8981e-01],
         [1.0696e-03, 3.2204e-01],
         [9.3266e-04, 2.2280e-01],
         [5.7973e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001553, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993995343742945
5.096285784617066 seconds in game passed.
Action: tensor([[[1.2810e-03, 5.8981e-01],
         [1.0696e-03, 3.2204e-01],
         [9.3266e-04, 2.2280e-01],
         [5.7973e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993995343742945
5.121285784989595 seconds in game passed.
Action: tensor([[[1.2810e-03, 5.8981e-01],
         [1.0696e-03, 3.2204e-01],
         [9.3266e-04, 2.2280e-01],
         [5.7973e-04, 1.6913e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.4993995343742945
+++++++++++++: 3.3804497559993685
5.146285785362124 seconds in game passed.
At 5.146285785362124 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3804497559993685
Current reward: 0.5621400206991365
Current mitigation activation: 0
#############################
Total reward: 6.061539555073431
5.1712857857346535 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 6.061539555073431
5.1962857861071825 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061539555073431
5.2212857864797115 seconds in game passed.
Action: tensor([[[0.0018, 0.5875],
         [0.0022, 0.3202],
         [0.0021, 0.2211],
         [0.0018, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.061539555073431
+++++++++++++: 3.1566036189456304
5.246285786852241 seconds in game passed.
At 5.246285786852241 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.5947],
         [0.0020, 0.3222],
         [0.0018, 0.2215],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.1566036189456304
Current reward: 0.5623100343120228
Current mitigation activation: 0
#############################
Total reward: 6.623849589385453
5.27128578722477 seconds in game passed.
Action: tensor([[[0.0026, 0.5947],
         [0.0020, 0.3222],
         [0.0018, 0.2215],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849589385453
5.296285787597299 seconds in game passed.
Action: tensor([[[0.0026, 0.5947],
         [0.0020, 0.3222],
         [0.0018, 0.2215],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849589385453
5.321285787969828 seconds in game passed.
Action: tensor([[[0.0026, 0.5947],
         [0.0020, 0.3222],
         [0.0018, 0.2215],
         [0.0015, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.623849589385453
+++++++++++++: 2.948920851244772
5.346285788342357 seconds in game passed.
At 5.346285788342357 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.948920851244772
Current reward: 0.5617993781111474
Current mitigation activation: 0
#############################
Total reward: 7.185648967496601
5.371285788714886 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185648967496601
5.396285789087415 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185648967496601
5.421285789459944 seconds in game passed.
Action: tensor([[[0.0023, 0.5893],
         [0.0028, 0.3215],
         [0.0029, 0.2216],
         [0.0025, 0.1682]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.185648967496601
+++++++++++++: 2.7880945010303355
5.446285789832473 seconds in game passed.
At 5.446285789832473 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.6012e-04,  5.8842e-01],
         [ 7.5243e-05,  3.2102e-01],
         [-8.2813e-05,  2.2110e-01],
         [-3.8355e-04,  1.6785e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7880945010303355
Current reward: 0.5575264054895118
Current mitigation activation: 0
#############################
Total reward: 7.743175372986112
5.471285790205002 seconds in game passed.
Action: tensor([[[ 8.6012e-04,  5.8842e-01],
         [ 7.5243e-05,  3.2102e-01],
         [-8.2813e-05,  2.2110e-01],
         [-3.8355e-04,  1.6785e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175372986112
5.496285790577531 seconds in game passed.
Action: tensor([[[ 8.6012e-04,  5.8842e-01],
         [ 7.5243e-05,  3.2102e-01],
         [-8.2813e-05,  2.2110e-01],
         [-3.8355e-04,  1.6785e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000749, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175372986112
5.52128579095006 seconds in game passed.
Action: tensor([[[ 8.6012e-04,  5.8842e-01],
         [ 7.5243e-05,  3.2102e-01],
         [-8.2813e-05,  2.2110e-01],
         [-3.8355e-04,  1.6785e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.743175372986112
+++++++++++++: 2.6912973301647134
5.546285791322589 seconds in game passed.
At 5.546285791322589 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5934],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6912973301647134
Current reward: 0.5472045275128883
Current mitigation activation: 0
#############################
Total reward: 8.290379900499001
5.571285791695118 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290379900499001
5.596285792067647 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001231, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290379900499001
5.621285792440176 seconds in game passed.
Action: tensor([[[-0.0010,  0.5934],
         [-0.0020,  0.3227],
         [-0.0025,  0.2217],
         [-0.0029,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.290379900499001
+++++++++++++: 2.5950260369794913
5.646285792812705 seconds in game passed.
At 5.646285792812705 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5950260369794913
Current reward: 0.5368278978696187
Current mitigation activation: 0
#############################
Total reward: 8.82720779836862
5.671285793185234 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002907, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.82720779836862
5.696285793557763 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.82720779836862
5.721285793930292 seconds in game passed.
Action: tensor([[[-0.0023,  0.5915],
         [-0.0039,  0.3221],
         [-0.0046,  0.2211],
         [-0.0051,  0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002984, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.82720779836862
+++++++++++++: 2.49863230375497
5.746285794302821 seconds in game passed.
At 5.746285794302821 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0052,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.49863230375497
Current reward: 0.5264623824724294
Current mitigation activation: 0
#############################
Total reward: 9.35367018084105
5.77128579467535 seconds in game passed.
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0052,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003585, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.35367018084105
5.796285795047879 seconds in game passed.
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0052,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.35367018084105
5.821285795420408 seconds in game passed.
Action: tensor([[[-0.0027,  0.5949],
         [-0.0046,  0.3231],
         [-0.0052,  0.2219],
         [-0.0055,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.35367018084105
+++++++++++++: 2.402194567705003
5.846285795792937 seconds in game passed.
At 5.846285795792937 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1588e-04,  5.9066e-01],
         [-7.2144e-04,  3.2167e-01],
         [-7.5889e-04,  2.2135e-01],
         [-9.5456e-04,  1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.402194567705003
Current reward: 0.5161007487280524
Current mitigation activation: 0
#############################
Total reward: 9.869770929569102
5.871285796165466 seconds in game passed.
Action: tensor([[[-1.1588e-04,  5.9066e-01],
         [-7.2144e-04,  3.2167e-01],
         [-7.5889e-04,  2.2135e-01],
         [-9.5456e-04,  1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869770929569102
5.896285796537995 seconds in game passed.
Action: tensor([[[-1.1588e-04,  5.9066e-01],
         [-7.2144e-04,  3.2167e-01],
         [-7.5889e-04,  2.2135e-01],
         [-9.5456e-04,  1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000475, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869770929569102
5.921285796910524 seconds in game passed.
Action: tensor([[[-1.1588e-04,  5.9066e-01],
         [-7.2144e-04,  3.2167e-01],
         [-7.5889e-04,  2.2135e-01],
         [-9.5456e-04,  1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.869770929569102
+++++++++++++: 2.2737335465803175
5.946285797283053 seconds in game passed.
At 5.946285797283053 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.4093e-05,  5.9305e-01],
         [ 2.1140e-04,  3.2258e-01],
         [ 2.5542e-04,  2.2191e-01],
         [-1.0519e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2737335465803175
Current reward: 0.5093357207062945
Current mitigation activation: 0
#############################
Total reward: 10.379106650275396
5.971285797655582 seconds in game passed.
Action: tensor([[[ 4.4093e-05,  5.9305e-01],
         [ 2.1140e-04,  3.2258e-01],
         [ 2.5542e-04,  2.2191e-01],
         [-1.0519e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379106650275396
5.9962857980281115 seconds in game passed.
Action: tensor([[[ 4.4093e-05,  5.9305e-01],
         [ 2.1140e-04,  3.2258e-01],
         [ 2.5542e-04,  2.2191e-01],
         [-1.0519e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000107, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379106650275396
6.0212857984006405 seconds in game passed.
Action: tensor([[[ 4.4093e-05,  5.9305e-01],
         [ 2.1140e-04,  3.2258e-01],
         [ 2.5542e-04,  2.2191e-01],
         [-1.0519e-04,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.379106650275396
+++++++++++++: 2.069403113000254
6.0462857987731695 seconds in game passed.
At 6.0462857987731695 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0031, 0.5970],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.069403113000254
Current reward: 0.5122397097902242
Current mitigation activation: 0
#############################
Total reward: 10.89134636006562
6.0712857991456985 seconds in game passed.
Action: tensor([[[0.0031, 0.5970],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.873536, steer=0.003261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.89134636006562
6.096285799518228 seconds in game passed.
Action: tensor([[[0.0031, 0.5970],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.820711, steer=0.003289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.89134636006562
6.121285799890757 seconds in game passed.
Action: tensor([[[0.0031, 0.5970],
         [0.0037, 0.3258],
         [0.0034, 0.2243],
         [0.0025, 0.1708]]])
agent 0 action: VehicleControl(throttle=0.769058, steer=0.003316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.89134636006562
+++++++++++++: 1.8865377323267705
6.146285800263286 seconds in game passed.
At 6.146285800263286 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6216],
         [0.0025, 0.3402],
         [0.0020, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.467223, steer=0.001997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8865377323267705
Current reward: 0.5134808483106175
Current mitigation activation: 0
#############################
Total reward: 11.404827208376238
6.171285800635815 seconds in game passed.
Action: tensor([[[0.0020, 0.6216],
         [0.0025, 0.3402],
         [0.0020, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.442105, steer=0.002221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404827208376238
6.196285801008344 seconds in game passed.
Action: tensor([[[0.0020, 0.6216],
         [0.0025, 0.3402],
         [0.0020, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.392653, steer=0.002224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404827208376238
6.221285801380873 seconds in game passed.
Action: tensor([[[0.0020, 0.6216],
         [0.0025, 0.3402],
         [0.0020, 0.2342],
         [0.0008, 0.1791]]])
agent 0 action: VehicleControl(throttle=0.362934, steer=0.002227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.404827208376238
+++++++++++++: 1.72428140184412
6.246285801753402 seconds in game passed.
At 6.246285801753402 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.3607e-04,  6.3612e-01],
         [ 4.0829e-05,  3.4393e-01],
         [-6.7325e-04,  2.3573e-01],
         [-1.7688e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.352110, steer=-0.000055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.72428140184412
Current reward: 0.5125396489276689
Current mitigation activation: 0
#############################
Total reward: 11.917366857303907
6.271285802125931 seconds in game passed.
Action: tensor([[[ 7.3607e-04,  6.3612e-01],
         [ 4.0829e-05,  3.4393e-01],
         [-6.7325e-04,  2.3573e-01],
         [-1.7688e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.339492, steer=0.000299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917366857303907
6.29628580249846 seconds in game passed.
Action: tensor([[[ 7.3607e-04,  6.3612e-01],
         [ 4.0829e-05,  3.4393e-01],
         [-6.7325e-04,  2.3573e-01],
         [-1.7688e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.327292, steer=0.000277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917366857303907
6.321285802870989 seconds in game passed.
Action: tensor([[[ 7.3607e-04,  6.3612e-01],
         [ 4.0829e-05,  3.4393e-01],
         [-6.7325e-04,  2.3573e-01],
         [-1.7688e-03,  1.7995e-01]]])
agent 0 action: VehicleControl(throttle=0.315506, steer=0.000255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.917366857303907
+++++++++++++: 1.5888541840606591
6.346285803243518 seconds in game passed.
At 6.346285803243518 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6519],
         [-0.0007,  0.3512],
         [-0.0018,  0.2409],
         [-0.0030,  0.1839]]])
agent 0 action: VehicleControl(throttle=0.304521, steer=-0.000135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5888541840606591
Current reward: 0.5075547010794775
Current mitigation activation: 0
#############################
Total reward: 12.424921558383385
6.371285803616047 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6519],
         [-0.0007,  0.3512],
         [-0.0018,  0.2409],
         [-0.0030,  0.1839]]])
agent 0 action: VehicleControl(throttle=0.293945, steer=-0.000106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424921558383385
6.396285803988576 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6519],
         [-0.0007,  0.3512],
         [-0.0018,  0.2409],
         [-0.0030,  0.1839]]])
agent 0 action: VehicleControl(throttle=0.283323, steer=-0.000137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424921558383385
6.421285804361105 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6519],
         [-0.0007,  0.3512],
         [-0.0018,  0.2409],
         [-0.0030,  0.1839]]])
agent 0 action: VehicleControl(throttle=0.272675, steer=-0.000168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.424921558383385
+++++++++++++: 1.4776637923345164
6.446285804733634 seconds in game passed.
At 6.446285804733634 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.6669],
         [-0.0050,  0.3560],
         [-0.0064,  0.2425],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.261922, steer=-0.004601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4776637923345164
Current reward: 0.49814209380119456
Current mitigation activation: 0
#############################
Total reward: 12.92306365218458
6.471285805106163 seconds in game passed.
Action: tensor([[[-0.0018,  0.6669],
         [-0.0050,  0.3560],
         [-0.0064,  0.2425],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.251151, steer=-0.003921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92306365218458
6.496285805478692 seconds in game passed.
Action: tensor([[[-0.0018,  0.6669],
         [-0.0050,  0.3560],
         [-0.0064,  0.2425],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.240361, steer=-0.003971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92306365218458
6.521285805851221 seconds in game passed.
Action: tensor([[[-0.0018,  0.6669],
         [-0.0050,  0.3560],
         [-0.0064,  0.2425],
         [-0.0073,  0.1847]]])
agent 0 action: VehicleControl(throttle=0.229552, steer=-0.004021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.92306365218458
+++++++++++++: 1.3815625322281357
6.54628580622375 seconds in game passed.
At 6.54628580622375 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.7404e-04,  6.8418e-01],
         [-4.1071e-03,  3.6623e-01],
         [-5.8665e-03,  2.5060e-01],
         [-7.1649e-03,  1.9085e-01]]])
agent 0 action: VehicleControl(throttle=0.218799, steer=-0.002761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3815625322281357
Current reward: 0.48561086575342904
Current mitigation activation: 0
#############################
Total reward: 13.408674517938008
6.571285806596279 seconds in game passed.
Action: tensor([[[-2.7404e-04,  6.8418e-01],
         [-4.1071e-03,  3.6623e-01],
         [-5.8665e-03,  2.5060e-01],
         [-7.1649e-03,  1.9085e-01]]])
agent 0 action: VehicleControl(throttle=0.208026, steer=-0.002986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408674517938008
6.596285806968808 seconds in game passed.
Action: tensor([[[-2.7404e-04,  6.8418e-01],
         [-4.1071e-03,  3.6623e-01],
         [-5.8665e-03,  2.5060e-01],
         [-7.1649e-03,  1.9085e-01]]])
agent 0 action: VehicleControl(throttle=0.197235, steer=-0.002999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408674517938008
6.621285807341337 seconds in game passed.
Action: tensor([[[-2.7404e-04,  6.8418e-01],
         [-4.1071e-03,  3.6623e-01],
         [-5.8665e-03,  2.5060e-01],
         [-7.1649e-03,  1.9085e-01]]])
agent 0 action: VehicleControl(throttle=0.186426, steer=-0.003012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.408674517938008
+++++++++++++: 1.2941895791270228
6.646285807713866 seconds in game passed.
At 6.646285807713866 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-3.9091e-04,  1.0000e+00],
         [-4.7629e-03,  1.0000e+00],
         [-5.9553e-03,  1.0000e+00],
         [-6.5055e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003107, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2941895791270228
Current reward: 0.4711007345834019
Current mitigation activation: 1
#############################
Total reward: 13.87977525252141
6.671285808086395 seconds in game passed.
Action: tensor([[[-3.9091e-04,  1.0000e+00],
         [-4.7629e-03,  1.0000e+00],
         [-5.9553e-03,  1.0000e+00],
         [-6.5055e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003085, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87977525252141
6.696285808458924 seconds in game passed.
Action: tensor([[[-3.9091e-04,  1.0000e+00],
         [-4.7629e-03,  1.0000e+00],
         [-5.9553e-03,  1.0000e+00],
         [-6.5055e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003079, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87977525252141
6.721285808831453 seconds in game passed.
Action: tensor([[[-3.9091e-04,  1.0000e+00],
         [-4.7629e-03,  1.0000e+00],
         [-5.9553e-03,  1.0000e+00],
         [-6.5055e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003074, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.87977525252141
+++++++++++++: 1.2145471704347748
6.746285809203982 seconds in game passed.
At 6.746285809203982 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0055,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000831, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2145471704347748
Current reward: 0.4547321417807323
Current mitigation activation: 1
#############################
Total reward: 14.334507394302143
6.771285809576511 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0055,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001164, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334507394302143
6.79628580994904 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0055,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001129, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334507394302143
6.821285810321569 seconds in game passed.
Action: tensor([[[ 0.0024,  1.0000],
         [-0.0040,  1.0000],
         [-0.0055,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001094, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.334507394302143
+++++++++++++: 1.1617295155841045
6.8462858106940985 seconds in game passed.
At 6.8462858106940985 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 8.5843e-03,  1.0000e+00],
         [ 7.3527e-04,  1.0000e+00],
         [-1.5550e-03,  1.0000e+00],
         [-1.6091e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005882, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1617295155841045
Current reward: 0.4319369250195704
Current mitigation activation: 1
#############################
Total reward: 14.766444319321714
6.8712858110666275 seconds in game passed.
Action: tensor([[[ 8.5843e-03,  1.0000e+00],
         [ 7.3527e-04,  1.0000e+00],
         [-1.5550e-03,  1.0000e+00],
         [-1.6091e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004798, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766444319321714
6.8962858114391565 seconds in game passed.
Action: tensor([[[ 8.5843e-03,  1.0000e+00],
         [ 7.3527e-04,  1.0000e+00],
         [-1.5550e-03,  1.0000e+00],
         [-1.6091e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004865, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766444319321714
6.921285811811686 seconds in game passed.
Action: tensor([[[ 8.5843e-03,  1.0000e+00],
         [ 7.3527e-04,  1.0000e+00],
         [-1.5550e-03,  1.0000e+00],
         [-1.6091e-03,  1.0000e+00]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004932, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.766444319321714
+++++++++++++: 1.1431628374712492
6.946285812184215 seconds in game passed.
At 6.946285812184215 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0139,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012472, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1431628374712492
Current reward: 0.4017509745236187
Current mitigation activation: 1
#############################
Total reward: 15.168195293845333
6.971285812556744 seconds in game passed.
Action: tensor([[[-0.0139,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009712, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168195293845333
6.996285812929273 seconds in game passed.
Action: tensor([[[-0.0139,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009833, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168195293845333
7.021285813301802 seconds in game passed.
Action: tensor([[[-0.0139,  1.0000],
         [-0.0042,  1.0000],
         [-0.0061,  1.0000],
         [-0.0060,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.009953, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.168195293845333
+++++++++++++: 1.1451253334892324
7.046285813674331 seconds in game passed.
At 7.046285813674331 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0130,  1.0000],
         [-0.0071,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011370, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.1451253334892324
Current reward: 0.3690333322797601
Current mitigation activation: 1
#############################
Total reward: 15.537228626125092
7.07128581404686 seconds in game passed.
Action: tensor([[[-0.0130,  1.0000],
         [-0.0071,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011335, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537228626125092
7.096285814419389 seconds in game passed.
Action: tensor([[[-0.0130,  1.0000],
         [-0.0071,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011507, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537228626125092
7.121285814791918 seconds in game passed.
Action: tensor([[[-0.0130,  1.0000],
         [-0.0071,  1.0000],
         [-0.0080,  1.0000],
         [-0.0075,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.011680, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.537228626125092
+++++++++++++: 1.164827998668018
7.146285815164447 seconds in game passed.
At 7.146285815164447 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0162,  1.0000],
         [-0.0115,  1.0000],
         [-0.0089,  1.0000],
         [-0.0049,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016724, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.164827998668018
Current reward: 0.3357654413589553
Current mitigation activation: 1
#############################
Total reward: 15.872994067484047
7.171285815536976 seconds in game passed.
Action: tensor([[[-0.0162,  1.0000],
         [-0.0115,  1.0000],
         [-0.0089,  1.0000],
         [-0.0049,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016127, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872994067484047
7.196285815909505 seconds in game passed.
Action: tensor([[[-0.0162,  1.0000],
         [-0.0115,  1.0000],
         [-0.0089,  1.0000],
         [-0.0049,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016336, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872994067484047
7.221285816282034 seconds in game passed.
Action: tensor([[[-0.0162,  1.0000],
         [-0.0115,  1.0000],
         [-0.0089,  1.0000],
         [-0.0049,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.016546, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.872994067484047
+++++++++++++: 1.2047073744450527
7.246285816654563 seconds in game passed.
At 7.246285816654563 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0077,  1.0000],
         [-0.0130,  1.0000],
         [-0.0185,  1.0000],
         [-0.0206,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.012233, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2047073744450527
Current reward: 0.30278035811849513
Current mitigation activation: 1
#############################
Total reward: 16.17577442560254
7.271285817027092 seconds in game passed.
Action: tensor([[[-0.0077,  1.0000],
         [-0.0130,  1.0000],
         [-0.0185,  1.0000],
         [-0.0206,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013114, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.17577442560254
7.296285817399621 seconds in game passed.
Action: tensor([[[-0.0077,  1.0000],
         [-0.0130,  1.0000],
         [-0.0185,  1.0000],
         [-0.0206,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013253, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.17577442560254
7.32128581777215 seconds in game passed.
Action: tensor([[[-0.0077,  1.0000],
         [-0.0130,  1.0000],
         [-0.0185,  1.0000],
         [-0.0206,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.013392, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.17577442560254
+++++++++++++: 1.2703491428569071
7.346285818144679 seconds in game passed.
At 7.346285818144679 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0297,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0080,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.021095, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2703491428569071
Current reward: 0.2705553283957246
Current mitigation activation: 1
#############################
Total reward: 16.446329753998263
7.371285818517208 seconds in game passed.
Action: tensor([[[ 0.0297,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0080,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015605, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446329753998263
7.396285818889737 seconds in game passed.
Action: tensor([[[ 0.0297,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0080,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015827, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446329753998263
7.421285819262266 seconds in game passed.
Action: tensor([[[ 0.0297,  1.0000],
         [ 0.0040,  1.0000],
         [-0.0107,  1.0000],
         [-0.0080,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.016048, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.446329753998263
+++++++++++++: 1.3688408544350863
7.446285819634795 seconds in game passed.
At 7.446285819634795 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.3976e-03, 9.5601e-01],
         [1.1332e-03, 9.5434e-01],
         [1.2825e-04, 9.5372e-01],
         [5.0165e-04, 9.5334e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002906, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3688408544350863
Current reward: 0.2397051247621127
Current mitigation activation: 0
#############################
Total reward: 16.686034878760378
7.471285820007324 seconds in game passed.
Action: tensor([[[2.3976e-03, 9.5601e-01],
         [1.1332e-03, 9.5434e-01],
         [1.2825e-04, 9.5372e-01],
         [5.0165e-04, 9.5334e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000334, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686034878760378
7.496285820379853 seconds in game passed.
Action: tensor([[[2.3976e-03, 9.5601e-01],
         [1.1332e-03, 9.5434e-01],
         [1.2825e-04, 9.5372e-01],
         [5.0165e-04, 9.5334e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000403, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686034878760378
7.521285820752382 seconds in game passed.
Action: tensor([[[2.3976e-03, 9.5601e-01],
         [1.1332e-03, 9.5434e-01],
         [1.2825e-04, 9.5372e-01],
         [5.0165e-04, 9.5334e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000472, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.686034878760378
+++++++++++++: 1.5117470881403492
7.546285821124911 seconds in game passed.
At 7.546285821124911 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.3452e-04, 9.5592e-01],
         [1.1132e-03, 9.5428e-01],
         [9.6578e-04, 9.5371e-01],
         [1.4475e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000470, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5117470881403492
Current reward: 0.21060744565784126
Current mitigation activation: 0
#############################
Total reward: 16.89664232441822
7.57128582149744 seconds in game passed.
Action: tensor([[[8.3452e-04, 9.5592e-01],
         [1.1132e-03, 9.5428e-01],
         [9.6578e-04, 9.5371e-01],
         [1.4475e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000260, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89664232441822
7.596285821869969 seconds in game passed.
Action: tensor([[[8.3452e-04, 9.5592e-01],
         [1.1132e-03, 9.5428e-01],
         [9.6578e-04, 9.5371e-01],
         [1.4475e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000215, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89664232441822
7.621285822242498 seconds in game passed.
Action: tensor([[[8.3452e-04, 9.5592e-01],
         [1.1132e-03, 9.5428e-01],
         [9.6578e-04, 9.5371e-01],
         [1.4475e-03, 9.5336e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000169, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.89664232441822
+++++++++++++: 1.7363245632753717
7.646285822615027 seconds in game passed.
At 7.646285822615027 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.6843e-04, 9.5610e-01],
         [1.5341e-03, 9.5460e-01],
         [1.8427e-03, 9.5410e-01],
         [1.9438e-03, 9.5382e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000101, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7363245632753717
Current reward: 0.1824529678420162
Current mitigation activation: 0
#############################
Total reward: 17.079095292260238
7.6712858229875565 seconds in game passed.
Action: tensor([[[7.6843e-04, 9.5610e-01],
         [1.5341e-03, 9.5460e-01],
         [1.8427e-03, 9.5410e-01],
         [1.9438e-03, 9.5382e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000113, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.079095292260238
7.6962858233600855 seconds in game passed.
Action: tensor([[[7.6843e-04, 9.5610e-01],
         [1.5341e-03, 9.5460e-01],
         [1.8427e-03, 9.5410e-01],
         [1.9438e-03, 9.5382e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000162, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.079095292260238
7.7212858237326145 seconds in game passed.
Action: tensor([[[7.6843e-04, 9.5610e-01],
         [1.5341e-03, 9.5460e-01],
         [1.8427e-03, 9.5410e-01],
         [1.9438e-03, 9.5382e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000211, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.079095292260238
+++++++++++++: 2.1103883008770636
7.7462858241051435 seconds in game passed.
At 7.7462858241051435 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[7.1579e-04, 9.5626e-01],
         [1.5203e-03, 9.5482e-01],
         [1.7566e-03, 9.5435e-01],
         [1.8103e-03, 9.5409e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000195, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1103883008770636
Current reward: 0.15519922194779864
Current mitigation activation: 0
#############################
Total reward: 17.234294514208038
7.771285824477673 seconds in game passed.
Action: tensor([[[7.1579e-04, 9.5626e-01],
         [1.5203e-03, 9.5482e-01],
         [1.7566e-03, 9.5435e-01],
         [1.8103e-03, 9.5409e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000227, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.234294514208038
7.796285824850202 seconds in game passed.
Action: tensor([[[7.1579e-04, 9.5626e-01],
         [1.5203e-03, 9.5482e-01],
         [1.7566e-03, 9.5435e-01],
         [1.8103e-03, 9.5409e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000252, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.234294514208038
7.821285825222731 seconds in game passed.
Action: tensor([[[7.1579e-04, 9.5626e-01],
         [1.5203e-03, 9.5482e-01],
         [1.7566e-03, 9.5435e-01],
         [1.8103e-03, 9.5409e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000278, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.234294514208038
+++++++++++++: 2.8020592284789725
7.84628582559526 seconds in game passed.
At 7.84628582559526 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9545],
         [0.0018, 0.9540],
         [0.0020, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000725, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8020592284789725
Current reward: 0.12883263800662192
Current mitigation activation: 0
#############################
Total reward: 17.36312715221466
7.871285825967789 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9545],
         [0.0018, 0.9540],
         [0.0020, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000602, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36312715221466
7.896285826340318 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9545],
         [0.0018, 0.9540],
         [0.0020, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000560, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36312715221466
7.921285826712847 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9545],
         [0.0018, 0.9540],
         [0.0020, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000519, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.36312715221466
+++++++++++++: 4.3279317973423534
7.946285827085376 seconds in game passed.
At 7.946285827085376 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000681, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.3279317973423534
Current reward: 0.10382255490211124
Current mitigation activation: 0
#############################
Total reward: 17.466949707116772
7.971285827457905 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000816, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.466949707116772
7.996285827830434 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000955, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.466949707116772
8.021285828202963 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9546],
         [0.0019, 0.9541],
         [0.0021, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.004003, steer=0.001094, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.466949707116772
+++++++++++++: 20.3728724524907
8.046285828575492 seconds in game passed.
At 8.046285828575492 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006293, steer=0.001263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.039468089121964776
Current mitigation activation: 0
#############################
Total reward: 17.506417796238736
8.071285828948021 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006297, steer=0.001412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506417796238736
8.09628582932055 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006458, steer=0.001564, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506417796238736
8.121285829693079 seconds in game passed.
Action: tensor([[[0.0014, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006566, steer=0.001716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.506417796238736
+++++++++++++: 1707.3159727573163
8.146285830065608 seconds in game passed.
At 8.146285830065608 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.009711, steer=0.001850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00047095810777422807
Current mitigation activation: 0
#############################
Total reward: 17.50688875434651
8.171285830438137 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002062, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50688875434651
8.196285830810666 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002264, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50688875434651
8.221285831183195 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006896, steer=0.002466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.50688875434651
+++++++++++++: 191.49421128107733
8.246285831555724 seconds in game passed.
At 8.246285831555724 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006762, steer=0.002624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00419781583439488
Current mitigation activation: 0
#############################
Total reward: 17.511086570180904
8.271285831928253 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.006755, steer=0.002779, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.511086570180904
8.296285832300782 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002934, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.511086570180904
8.321285832673311 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003089, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.511086570180904
+++++++++++++: 402.55859150955376
8.34628583304584 seconds in game passed.
At 8.34628583304584 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0011, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.007203, steer=0.002796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.001996375059009002
Current mitigation activation: 0
#############################
Total reward: 17.513082945239912
8.37128583341837 seconds in game passed.
Action: tensor([[[0.0011, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.006841, steer=0.002608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513082945239912
8.396285833790898 seconds in game passed.
Action: tensor([[[0.0011, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.006869, steer=0.002406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513082945239912
8.421285834163427 seconds in game passed.
Action: tensor([[[0.0011, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.004898, steer=0.002203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513082945239912
+++++++++++++: 26649.278826644757
8.446285834535956 seconds in game passed.
At 8.446285834535956 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.004485, steer=0.002215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.0156722945717797e-05
Current mitigation activation: 0
#############################
Total reward: 17.51311310196286
8.471285834908485 seconds in game passed.
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.004165, steer=0.002208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51311310196286
8.496285835281014 seconds in game passed.
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.003888, steer=0.002204, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51311310196286
8.521285835653543 seconds in game passed.
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.003665, steer=0.002200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51311310196286
+++++++++++++: 1009.3424485165168
8.546285836026073 seconds in game passed.
At 8.546285836026073 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.003489, steer=0.002213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0007961374857408
Current mitigation activation: 0
#############################
Total reward: 17.513909239448598
8.571285836398602 seconds in game passed.
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.003358, steer=0.002218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513909239448598
8.59628583677113 seconds in game passed.
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.003263, steer=0.002224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513909239448598
8.62128583714366 seconds in game passed.
Action: tensor([[[0.0012, 0.9562],
         [0.0017, 0.9547],
         [0.0020, 0.9542],
         [0.0021, 0.9540]]])
agent 0 action: VehicleControl(throttle=0.003201, steer=0.002230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.513909239448598
+++++++++++++: 838.1069626371306
8.646285837516189 seconds in game passed.
At 8.646285837516189 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.003101, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0009650151341928515
Current mitigation activation: 0
#############################
Total reward: 17.51487425458279
8.671285837888718 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.003096, steer=0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51487425458279
8.696285838261247 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.003104, steer=0.002288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51487425458279
8.721285838633776 seconds in game passed.
Action: tensor([[[0.0013, 0.9561],
         [0.0017, 0.9547],
         [0.0019, 0.9542],
         [0.0022, 0.9539]]])
agent 0 action: VehicleControl(throttle=0.003129, steer=0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51487425458279
+++++++++++++: 839.2913806720074
8.746285839006305 seconds in game passed.
At 8.746285839006305 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.003391, steer=0.002144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.000989140512507306
Current mitigation activation: 0
#############################
Total reward: 17.515863395095298
8.771285839378834 seconds in game passed.
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.003421, steer=0.002172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515863395095298
8.796285839751363 seconds in game passed.
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.003484, steer=0.002175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515863395095298
8.821285840123892 seconds in game passed.
Action: tensor([[[0.0011, 0.9561],
         [0.0016, 0.9546],
         [0.0018, 0.9541],
         [0.0019, 0.9538]]])
agent 0 action: VehicleControl(throttle=0.003555, steer=0.002178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.515863395095298
+++++++++++++: 909.5077687520721
8.84628584049642 seconds in game passed.
At 8.84628584049642 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.7790e-04, 9.5631e-01],
         [1.4760e-03, 9.5489e-01],
         [1.7351e-03, 9.5443e-01],
         [1.8488e-03, 9.5417e-01]]])
agent 0 action: VehicleControl(throttle=0.003867, steer=0.001757, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0009469211003510966
Current mitigation activation: 0
#############################
Total reward: 17.51681031619565
8.87128584086895 seconds in game passed.
Action: tensor([[[5.7790e-04, 9.5631e-01],
         [1.4760e-03, 9.5489e-01],
         [1.7351e-03, 9.5443e-01],
         [1.8488e-03, 9.5417e-01]]])
agent 0 action: VehicleControl(throttle=0.003927, steer=0.001820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51681031619565
8.896285841241479 seconds in game passed.
Action: tensor([[[5.7790e-04, 9.5631e-01],
         [1.4760e-03, 9.5489e-01],
         [1.7351e-03, 9.5443e-01],
         [1.8488e-03, 9.5417e-01]]])
agent 0 action: VehicleControl(throttle=0.008143, steer=0.001814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51681031619565
8.921285841614008 seconds in game passed.
Action: tensor([[[5.7790e-04, 9.5631e-01],
         [1.4760e-03, 9.5489e-01],
         [1.7351e-03, 9.5443e-01],
         [1.8488e-03, 9.5417e-01]]])
agent 0 action: VehicleControl(throttle=0.007265, steer=0.001807, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51681031619565
+++++++++++++: 3633.7194579373545
8.946285841986537 seconds in game passed.
At 8.946285841986537 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.9560],
         [0.0015, 0.9545],
         [0.0018, 0.9540],
         [0.0019, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.006823, steer=0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00024728512811464235
Current mitigation activation: 0
#############################
Total reward: 17.517057601323764
8.971285842359066 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0015, 0.9545],
         [0.0018, 0.9540],
         [0.0019, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.006604, steer=0.002043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517057601323764
8.996285842731595 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0015, 0.9545],
         [0.0018, 0.9540],
         [0.0019, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.006417, steer=0.002040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517057601323764
9.021285843104124 seconds in game passed.
Action: tensor([[[0.0010, 0.9560],
         [0.0015, 0.9545],
         [0.0018, 0.9540],
         [0.0019, 0.9537]]])
agent 0 action: VehicleControl(throttle=0.006227, steer=0.002036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517057601323764
+++++++++++++: 5360.415549916769
9.046285843476653 seconds in game passed.
At 9.046285843476653 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.6335e-04, 9.5602e-01],
         [1.3115e-03, 9.5446e-01],
         [1.5542e-03, 9.5394e-01],
         [1.7771e-03, 9.5364e-01]]])
agent 0 action: VehicleControl(throttle=0.006139, steer=0.001814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00017623440760397853
Current mitigation activation: 0
#############################
Total reward: 17.517233835731368
9.071285843849182 seconds in game passed.
Action: tensor([[[8.6335e-04, 9.5602e-01],
         [1.3115e-03, 9.5446e-01],
         [1.5542e-03, 9.5394e-01],
         [1.7771e-03, 9.5364e-01]]])
agent 0 action: VehicleControl(throttle=0.005970, steer=0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517233835731368
9.096285844221711 seconds in game passed.
Action: tensor([[[8.6335e-04, 9.5602e-01],
         [1.3115e-03, 9.5446e-01],
         [1.5542e-03, 9.5394e-01],
         [1.7771e-03, 9.5364e-01]]])
agent 0 action: VehicleControl(throttle=0.005833, steer=0.001838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517233835731368
9.12128584459424 seconds in game passed.
Action: tensor([[[8.6335e-04, 9.5602e-01],
         [1.3115e-03, 9.5446e-01],
         [1.5542e-03, 9.5394e-01],
         [1.7771e-03, 9.5364e-01]]])
agent 0 action: VehicleControl(throttle=0.005716, steer=0.001832, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517233835731368
+++++++++++++: 2773.7212768413187
9.14628584496677 seconds in game passed.
At 9.14628584496677 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.0014e-03,  9.5589e-01],
         [ 1.3752e-03,  9.5414e-01],
         [-5.3776e-04,  9.5348e-01],
         [ 1.4245e-04,  9.5304e-01]]])
agent 0 action: VehicleControl(throttle=0.014166, steer=0.004474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0003558493307568955
Current mitigation activation: 0
#############################
Total reward: 17.517589685062124
9.171285845339298 seconds in game passed.
Action: tensor([[[ 5.0014e-03,  9.5589e-01],
         [ 1.3752e-03,  9.5414e-01],
         [-5.3776e-04,  9.5348e-01],
         [ 1.4245e-04,  9.5304e-01]]])
agent 0 action: VehicleControl(throttle=0.013344, steer=0.004060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517589685062124
9.196285845711827 seconds in game passed.
Action: tensor([[[ 5.0014e-03,  9.5589e-01],
         [ 1.3752e-03,  9.5414e-01],
         [-5.3776e-04,  9.5348e-01],
         [ 1.4245e-04,  9.5304e-01]]])
agent 0 action: VehicleControl(throttle=0.013440, steer=0.004082, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517589685062124
9.221285846084356 seconds in game passed.
Action: tensor([[[ 5.0014e-03,  9.5589e-01],
         [ 1.3752e-03,  9.5414e-01],
         [-5.3776e-04,  9.5348e-01],
         [ 1.4245e-04,  9.5304e-01]]])
agent 0 action: VehicleControl(throttle=0.013468, steer=0.004104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.517589685062124
+++++++++++++: 2324.082101548223
9.246285846456885 seconds in game passed.
At 9.246285846456885 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0016,  0.9505],
         [-0.0139,  0.9437],
         [-0.0130,  0.7663]]])
agent 0 action: VehicleControl(throttle=0.106132, steer=0.020041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0004463194995851757
Current mitigation activation: 0
#############################
Total reward: 17.518036004561708
9.271285846829414 seconds in game passed.
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0016,  0.9505],
         [-0.0139,  0.9437],
         [-0.0130,  0.7663]]])
agent 0 action: VehicleControl(throttle=0.097366, steer=0.017602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518036004561708
9.296285847201943 seconds in game passed.
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0016,  0.9505],
         [-0.0139,  0.9437],
         [-0.0130,  0.7663]]])
agent 0 action: VehicleControl(throttle=0.098468, steer=0.017788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518036004561708
9.321285847574472 seconds in game passed.
Action: tensor([[[ 0.0301,  0.9545],
         [ 0.0016,  0.9505],
         [-0.0139,  0.9437],
         [-0.0130,  0.7663]]])
agent 0 action: VehicleControl(throttle=0.102419, steer=0.017974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518036004561708
+++++++++++++: 4650.41551175653
9.346285847947001 seconds in game passed.
At 9.346285847947001 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0203,  0.9534],
         [-0.0018,  0.9465],
         [-0.0132,  0.9062],
         [-0.0076,  0.5982]]])
agent 0 action: VehicleControl(throttle=0.082683, steer=0.009843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.00023615872518177063
Current mitigation activation: 0
#############################
Total reward: 17.51827216328689
9.37128584831953 seconds in game passed.
Action: tensor([[[ 0.0203,  0.9534],
         [-0.0018,  0.9465],
         [-0.0132,  0.9062],
         [-0.0076,  0.5982]]])
agent 0 action: VehicleControl(throttle=0.085122, steer=0.011316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51827216328689
9.39628584869206 seconds in game passed.
Action: tensor([[[ 0.0203,  0.9534],
         [-0.0018,  0.9465],
         [-0.0132,  0.9062],
         [-0.0076,  0.5982]]])
agent 0 action: VehicleControl(throttle=0.085454, steer=0.011417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51827216328689
9.421285849064589 seconds in game passed.
Action: tensor([[[ 0.0203,  0.9534],
         [-0.0018,  0.9465],
         [-0.0132,  0.9062],
         [-0.0076,  0.5982]]])
agent 0 action: VehicleControl(throttle=0.085828, steer=0.011519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51827216328689
+++++++++++++: 3888.4650465409436
9.446285849437118 seconds in game passed.
At 9.446285849437118 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.8347e-04,  9.5233e-01],
         [-7.7265e-03,  9.3783e-01],
         [-1.1947e-02,  8.5472e-01],
         [-7.5986e-03,  6.0136e-01]]])
agent 0 action: VehicleControl(throttle=0.067297, steer=-0.005258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0002955358848015522
Current mitigation activation: 0
#############################
Total reward: 17.518567699171694
9.471285849809647 seconds in game passed.
Action: tensor([[[-5.8347e-04,  9.5233e-01],
         [-7.7265e-03,  9.3783e-01],
         [-1.1947e-02,  8.5472e-01],
         [-7.5986e-03,  6.0136e-01]]])
agent 0 action: VehicleControl(throttle=0.069505, steer=-0.002547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518567699171694
9.496285850182176 seconds in game passed.
Action: tensor([[[-5.8347e-04,  9.5233e-01],
         [-7.7265e-03,  9.3783e-01],
         [-1.1947e-02,  8.5472e-01],
         [-7.5986e-03,  6.0136e-01]]])
agent 0 action: VehicleControl(throttle=0.069733, steer=-0.002620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518567699171694
9.521285850554705 seconds in game passed.
Action: tensor([[[-5.8347e-04,  9.5233e-01],
         [-7.7265e-03,  9.3783e-01],
         [-1.1947e-02,  8.5472e-01],
         [-7.5986e-03,  6.0136e-01]]])
agent 0 action: VehicleControl(throttle=0.069992, steer=-0.002693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.518567699171694
+++++++++++++: 1347.0718647649053
9.546285850927234 seconds in game passed.
At 9.546285850927234 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0356,  0.9506],
         [-0.0170,  0.8837],
         [-0.0097,  0.6960],
         [-0.0084,  0.5369]]])
agent 0 action: VehicleControl(throttle=0.320478, steer=-0.029969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0008986703435469077
Current mitigation activation: 0
#############################
Total reward: 17.51946636951524
9.571285851299763 seconds in game passed.
Action: tensor([[[-0.0356,  0.9506],
         [-0.0170,  0.8837],
         [-0.0097,  0.6960],
         [-0.0084,  0.5369]]])
agent 0 action: VehicleControl(throttle=0.297036, steer=-0.025836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51946636951524
9.596285851672292 seconds in game passed.
Action: tensor([[[-0.0356,  0.9506],
         [-0.0170,  0.8837],
         [-0.0097,  0.6960],
         [-0.0084,  0.5369]]])
agent 0 action: VehicleControl(throttle=0.300099, steer=-0.026189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51946636951524
9.62128585204482 seconds in game passed.
Action: tensor([[[-0.0356,  0.9506],
         [-0.0170,  0.8837],
         [-0.0097,  0.6960],
         [-0.0084,  0.5369]]])
agent 0 action: VehicleControl(throttle=0.302973, steer=-0.026542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.51946636951524
+++++++++++++: 876.1181566170097
9.64628585241735 seconds in game passed.
At 9.64628585241735 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0396,  0.9494],
         [-0.0164,  0.8073],
         [-0.0075,  0.5922],
         [-0.0063,  0.4796]]])
agent 0 action: VehicleControl(throttle=0.718110, steer=-0.027991, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0014561759799347758
Current mitigation activation: 0
#############################
Total reward: 17.520922545495175
9.671285852789879 seconds in game passed.
Action: tensor([[[-0.0396,  0.9494],
         [-0.0164,  0.8073],
         [-0.0075,  0.5922],
         [-0.0063,  0.4796]]])
agent 0 action: VehicleControl(throttle=0.681450, steer=-0.028176, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520922545495175
9.696285853162408 seconds in game passed.
Action: tensor([[[-0.0396,  0.9494],
         [-0.0164,  0.8073],
         [-0.0075,  0.5922],
         [-0.0063,  0.4796]]])
agent 0 action: VehicleControl(throttle=0.688291, steer=-0.028541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520922545495175
9.721285853534937 seconds in game passed.
Action: tensor([[[-0.0396,  0.9494],
         [-0.0164,  0.8073],
         [-0.0075,  0.5922],
         [-0.0063,  0.4796]]])
agent 0 action: VehicleControl(throttle=0.694739, steer=-0.028906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.520922545495175
+++++++++++++: 520.8300808727968
9.746285853907466 seconds in game passed.
At 9.746285853907466 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0311,  0.9481],
         [-0.0080,  0.7623],
         [-0.0054,  0.5729],
         [-0.0073,  0.4865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.018271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.0025777409007828717
Current mitigation activation: 0
#############################
Total reward: 17.523500286395958
9.771285854279995 seconds in game passed.
Action: tensor([[[-0.0311,  0.9481],
         [-0.0080,  0.7623],
         [-0.0054,  0.5729],
         [-0.0073,  0.4865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.020336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.523500286395958
9.796285854652524 seconds in game passed.
Action: tensor([[[-0.0311,  0.9481],
         [-0.0080,  0.7623],
         [-0.0054,  0.5729],
         [-0.0073,  0.4865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.020586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.523500286395958
9.821285855025053 seconds in game passed.
Action: tensor([[[-0.0311,  0.9481],
         [-0.0080,  0.7623],
         [-0.0054,  0.5729],
         [-0.0073,  0.4865]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.020836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.523500286395958
+++++++++++++: 215.22133634882675
9.846285855397582 seconds in game passed.
At 9.846285855397582 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.2205e-02,  9.4133e-01],
         [-3.5101e-03,  5.9332e-01],
         [-9.4716e-04,  4.6765e-01],
         [ 6.0541e-04,  4.1542e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.006558529741665756
Current mitigation activation: 0
#############################
Total reward: 17.530058816137625
9.871285855770111 seconds in game passed.
Action: tensor([[[-2.2205e-02,  9.4133e-01],
         [-3.5101e-03,  5.9332e-01],
         [-9.4716e-04,  4.6765e-01],
         [ 6.0541e-04,  4.1542e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530058816137625
9.89628585614264 seconds in game passed.
Action: tensor([[[-2.2205e-02,  9.4133e-01],
         [-3.5101e-03,  5.9332e-01],
         [-9.4716e-04,  4.6765e-01],
         [ 6.0541e-04,  4.1542e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530058816137625
9.92128585651517 seconds in game passed.
Action: tensor([[[-2.2205e-02,  9.4133e-01],
         [-3.5101e-03,  5.9332e-01],
         [-9.4716e-04,  4.6765e-01],
         [ 6.0541e-04,  4.1542e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.530058816137625
+++++++++++++: 39.33891234809826
9.946285856887698 seconds in game passed.
At 9.946285856887698 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5358e-02,  9.1564e-01],
         [-1.6325e-03,  5.3552e-01],
         [-1.5502e-03,  4.2183e-01],
         [-8.5080e-04,  3.6812e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.03761217398159877
Current mitigation activation: 0
#############################
Total reward: 17.567670990119225
9.971285857260227 seconds in game passed.
Action: tensor([[[-1.5358e-02,  9.1564e-01],
         [-1.6325e-03,  5.3552e-01],
         [-1.5502e-03,  4.2183e-01],
         [-8.5080e-04,  3.6812e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.567670990119225
9.996285857632756 seconds in game passed.
Action: tensor([[[-1.5358e-02,  9.1564e-01],
         [-1.6325e-03,  5.3552e-01],
         [-1.5502e-03,  4.2183e-01],
         [-8.5080e-04,  3.6812e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.567670990119225
10.021285858005285 seconds in game passed.
Action: tensor([[[-1.5358e-02,  9.1564e-01],
         [-1.6325e-03,  5.3552e-01],
         [-1.5502e-03,  4.2183e-01],
         [-8.5080e-04,  3.6812e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.567670990119225
+++++++++++++: 15.54541430298067
10.046285858377814 seconds in game passed.
At 10.046285858377814 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0062,  0.8632],
         [-0.0040,  0.4852],
         [-0.0067,  0.3511],
         [-0.0075,  0.2804]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007560, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.09921745393900376
Current mitigation activation: 0
#############################
Total reward: 17.66688844405823
10.071285858750343 seconds in game passed.
Action: tensor([[[-0.0062,  0.8632],
         [-0.0040,  0.4852],
         [-0.0067,  0.3511],
         [-0.0075,  0.2804]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66688844405823
10.096285859122872 seconds in game passed.
Action: tensor([[[-0.0062,  0.8632],
         [-0.0040,  0.4852],
         [-0.0067,  0.3511],
         [-0.0075,  0.2804]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66688844405823
10.121285859495401 seconds in game passed.
Action: tensor([[[-0.0062,  0.8632],
         [-0.0040,  0.4852],
         [-0.0067,  0.3511],
         [-0.0075,  0.2804]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.66688844405823
+++++++++++++: 9.71026165722699
10.14628585986793 seconds in game passed.
At 10.14628585986793 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0015,  0.8317],
         [-0.0041,  0.4680],
         [-0.0075,  0.3339],
         [-0.0089,  0.2621]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 9.71026165722699
Current reward: 0.1610194095954902
Current mitigation activation: 0
#############################
Total reward: 17.82790785365372
10.17128586024046 seconds in game passed.
Action: tensor([[[ 0.0015,  0.8317],
         [-0.0041,  0.4680],
         [-0.0075,  0.3339],
         [-0.0089,  0.2621]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.82790785365372
10.196285860612988 seconds in game passed.
Action: tensor([[[ 0.0015,  0.8317],
         [-0.0041,  0.4680],
         [-0.0075,  0.3339],
         [-0.0089,  0.2621]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005721, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.82790785365372
10.221285860985518 seconds in game passed.
Action: tensor([[[ 0.0015,  0.8317],
         [-0.0041,  0.4680],
         [-0.0075,  0.3339],
         [-0.0089,  0.2621]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.82790785365372
+++++++++++++: 7.09113143286473
10.246285861358047 seconds in game passed.
At 10.246285861358047 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0055,  0.8036],
         [-0.0026,  0.4508],
         [-0.0056,  0.3165],
         [-0.0072,  0.2445]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.09113143286473
Current reward: 0.17984218324753562
Current mitigation activation: 0
#############################
Total reward: 18.007750036901257
10.271285861730576 seconds in game passed.
Action: tensor([[[ 0.0055,  0.8036],
         [-0.0026,  0.4508],
         [-0.0056,  0.3165],
         [-0.0072,  0.2445]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003877, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.007750036901257
10.296285862103105 seconds in game passed.
Action: tensor([[[ 0.0055,  0.8036],
         [-0.0026,  0.4508],
         [-0.0056,  0.3165],
         [-0.0072,  0.2445]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.007750036901257
10.321285862475634 seconds in game passed.
Action: tensor([[[ 0.0055,  0.8036],
         [-0.0026,  0.4508],
         [-0.0056,  0.3165],
         [-0.0072,  0.2445]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.007750036901257
+++++++++++++: 5.783306103070122
10.346285862848163 seconds in game passed.
At 10.346285862848163 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0068,  0.7855],
         [-0.0009,  0.4397],
         [-0.0036,  0.3060],
         [-0.0054,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.783306103070122
Current reward: 0.1966013656743407
Current mitigation activation: 0
#############################
Total reward: 18.204351402575597
10.371285863220692 seconds in game passed.
Action: tensor([[[ 0.0068,  0.7855],
         [-0.0009,  0.4397],
         [-0.0036,  0.3060],
         [-0.0054,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003008, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.204351402575597
10.39628586359322 seconds in game passed.
Action: tensor([[[ 0.0068,  0.7855],
         [-0.0009,  0.4397],
         [-0.0036,  0.3060],
         [-0.0054,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.204351402575597
10.42128586396575 seconds in game passed.
Action: tensor([[[ 0.0068,  0.7855],
         [-0.0009,  0.4397],
         [-0.0036,  0.3060],
         [-0.0054,  0.2342]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.204351402575597
+++++++++++++: 4.973764361881893
10.446285864338279 seconds in game passed.
At 10.446285864338279 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0052,  0.7570],
         [-0.0015,  0.4236],
         [-0.0039,  0.2944],
         [-0.0055,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.973764361881893
Current reward: 0.21194382214729468
Current mitigation activation: 0
#############################
Total reward: 18.41629522472289
10.471285864710808 seconds in game passed.
Action: tensor([[[ 0.0052,  0.7570],
         [-0.0015,  0.4236],
         [-0.0039,  0.2944],
         [-0.0055,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003959, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.41629522472289
10.496285865083337 seconds in game passed.
Action: tensor([[[ 0.0052,  0.7570],
         [-0.0015,  0.4236],
         [-0.0039,  0.2944],
         [-0.0055,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003894, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.41629522472289
10.521285865455866 seconds in game passed.
Action: tensor([[[ 0.0052,  0.7570],
         [-0.0015,  0.4236],
         [-0.0039,  0.2944],
         [-0.0055,  0.2257]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.41629522472289
+++++++++++++: 4.394647960994577
10.546285865828395 seconds in game passed.
At 10.546285865828395 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0048,  0.7352],
         [-0.0017,  0.4122],
         [-0.0034,  0.2864],
         [-0.0047,  0.2201]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.394647960994577
Current reward: 0.22649291277652744
Current mitigation activation: 0
#############################
Total reward: 18.64278813749942
10.571285866200924 seconds in game passed.
Action: tensor([[[ 0.0048,  0.7352],
         [-0.0017,  0.4122],
         [-0.0034,  0.2864],
         [-0.0047,  0.2201]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.64278813749942
10.596285866573453 seconds in game passed.
Action: tensor([[[ 0.0048,  0.7352],
         [-0.0017,  0.4122],
         [-0.0034,  0.2864],
         [-0.0047,  0.2201]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.64278813749942
10.621285866945982 seconds in game passed.
Action: tensor([[[ 0.0048,  0.7352],
         [-0.0017,  0.4122],
         [-0.0034,  0.2864],
         [-0.0047,  0.2201]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.64278813749942
+++++++++++++: 3.947536490338373
10.646285867318511 seconds in game passed.
At 10.646285867318511 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1799e-02,  7.5289e-01],
         [ 5.4143e-04,  4.1718e-01],
         [-9.2569e-04,  2.8934e-01],
         [-1.5996e-03,  2.2216e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.947536490338373
Current reward: 0.24048573680517638
Current mitigation activation: 0
#############################
Total reward: 18.883273874304596
10.67128586769104 seconds in game passed.
Action: tensor([[[ 1.1799e-02,  7.5289e-01],
         [ 5.4143e-04,  4.1718e-01],
         [-9.2569e-04,  2.8934e-01],
         [-1.5996e-03,  2.2216e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.883273874304596
10.696285868063569 seconds in game passed.
Action: tensor([[[ 1.1799e-02,  7.5289e-01],
         [ 5.4143e-04,  4.1718e-01],
         [-9.2569e-04,  2.8934e-01],
         [-1.5996e-03,  2.2216e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.883273874304596
10.721285868436098 seconds in game passed.
Action: tensor([[[ 1.1799e-02,  7.5289e-01],
         [ 5.4143e-04,  4.1718e-01],
         [-9.2569e-04,  2.8934e-01],
         [-1.5996e-03,  2.2216e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.883273874304596
+++++++++++++: 3.585660566787576
10.746285868808627 seconds in game passed.
At 10.746285868808627 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.6511e-02, 7.5442e-01],
         [1.8970e-03, 4.2207e-01],
         [5.6988e-04, 2.9432e-01],
         [2.1812e-04, 2.2659e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.585660566787576
Current reward: 0.2540240476528148
Current mitigation activation: 0
#############################
Total reward: 19.137297921957412
10.771285869181156 seconds in game passed.
Action: tensor([[[1.6511e-02, 7.5442e-01],
         [1.8970e-03, 4.2207e-01],
         [5.6988e-04, 2.9432e-01],
         [2.1812e-04, 2.2659e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.137297921957412
10.796285869553685 seconds in game passed.
Action: tensor([[[1.6511e-02, 7.5442e-01],
         [1.8970e-03, 4.2207e-01],
         [5.6988e-04, 2.9432e-01],
         [2.1812e-04, 2.2659e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.137297921957412
10.821285869926214 seconds in game passed.
Action: tensor([[[1.6511e-02, 7.5442e-01],
         [1.8970e-03, 4.2207e-01],
         [5.6988e-04, 2.9432e-01],
         [2.1812e-04, 2.2659e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.137297921957412
+++++++++++++: 3.286292789731283
10.846285870298743 seconds in game passed.
At 10.846285870298743 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4217e-02, 7.3473e-01],
         [2.3609e-03, 4.1313e-01],
         [1.0045e-03, 2.8782e-01],
         [5.2302e-04, 2.2163e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005985, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.286292789731283
Current reward: 0.26703940779409796
Current mitigation activation: 0
#############################
Total reward: 19.40433732975151
10.871285870671272 seconds in game passed.
Action: tensor([[[1.4217e-02, 7.3473e-01],
         [2.3609e-03, 4.1313e-01],
         [1.0045e-03, 2.8782e-01],
         [5.2302e-04, 2.2163e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.40433732975151
10.896285871043801 seconds in game passed.
Action: tensor([[[1.4217e-02, 7.3473e-01],
         [2.3609e-03, 4.1313e-01],
         [1.0045e-03, 2.8782e-01],
         [5.2302e-04, 2.2163e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.40433732975151
10.92128587141633 seconds in game passed.
Action: tensor([[[1.4217e-02, 7.3473e-01],
         [2.3609e-03, 4.1313e-01],
         [1.0045e-03, 2.8782e-01],
         [5.2302e-04, 2.2163e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.40433732975151
+++++++++++++: 3.2105650927847362
10.94628587178886 seconds in game passed.
At 10.94628587178886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.2396e-03, 6.9653e-01],
         [1.7695e-03, 3.8865e-01],
         [9.7044e-04, 2.7120e-01],
         [3.4978e-04, 2.1045e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2105650927847362
Current reward: 0.27260702932400005
Current mitigation activation: 0
#############################
Total reward: 19.67694435907551
10.971285872161388 seconds in game passed.
Action: tensor([[[9.2396e-03, 6.9653e-01],
         [1.7695e-03, 3.8865e-01],
         [9.7044e-04, 2.7120e-01],
         [3.4978e-04, 2.1045e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.67694435907551
10.996285872533917 seconds in game passed.
Action: tensor([[[9.2396e-03, 6.9653e-01],
         [1.7695e-03, 3.8865e-01],
         [9.7044e-04, 2.7120e-01],
         [3.4978e-04, 2.1045e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.67694435907551
11.021285872906446 seconds in game passed.
Action: tensor([[[9.2396e-03, 6.9653e-01],
         [1.7695e-03, 3.8865e-01],
         [9.7044e-04, 2.7120e-01],
         [3.4978e-04, 2.1045e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.67694435907551
+++++++++++++: 3.2469290944107936
11.046285873278975 seconds in game passed.
At 11.046285873278975 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.2799e-03, 6.7158e-01],
         [9.9494e-04, 3.7244e-01],
         [5.3976e-04, 2.6055e-01],
         [1.0806e-04, 2.0364e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2469290944107936
Current reward: 0.27387980362670566
Current mitigation activation: 0
#############################
Total reward: 19.950824162702215
11.071285873651505 seconds in game passed.
Action: tensor([[[6.2799e-03, 6.7158e-01],
         [9.9494e-04, 3.7244e-01],
         [5.3976e-04, 2.6055e-01],
         [1.0806e-04, 2.0364e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.950824162702215
11.096285874024034 seconds in game passed.
Action: tensor([[[6.2799e-03, 6.7158e-01],
         [9.9494e-04, 3.7244e-01],
         [5.3976e-04, 2.6055e-01],
         [1.0806e-04, 2.0364e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.950824162702215
11.121285874396563 seconds in game passed.
Action: tensor([[[6.2799e-03, 6.7158e-01],
         [9.9494e-04, 3.7244e-01],
         [5.3976e-04, 2.6055e-01],
         [1.0806e-04, 2.0364e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.950824162702215
+++++++++++++: 3.2828672511631316
11.146285874769092 seconds in game passed.
At 11.146285874769092 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.4182e-03,  6.5834e-01],
         [ 1.3084e-03,  3.6315e-01],
         [ 7.1730e-04,  2.5325e-01],
         [-1.0257e-04,  1.9749e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2828672511631316
Current reward: 0.27519028060262196
Current mitigation activation: 0
#############################
Total reward: 20.226014443304837
11.17128587514162 seconds in game passed.
Action: tensor([[[ 4.4182e-03,  6.5834e-01],
         [ 1.3084e-03,  3.6315e-01],
         [ 7.1730e-04,  2.5325e-01],
         [-1.0257e-04,  1.9749e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.226014443304837
11.19628587551415 seconds in game passed.
Action: tensor([[[ 4.4182e-03,  6.5834e-01],
         [ 1.3084e-03,  3.6315e-01],
         [ 7.1730e-04,  2.5325e-01],
         [-1.0257e-04,  1.9749e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.226014443304837
11.221285875886679 seconds in game passed.
Action: tensor([[[ 4.4182e-03,  6.5834e-01],
         [ 1.3084e-03,  3.6315e-01],
         [ 7.1730e-04,  2.5325e-01],
         [-1.0257e-04,  1.9749e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.226014443304837
+++++++++++++: 3.3192566958881082
11.246285876259208 seconds in game passed.
At 11.246285876259208 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.6383e-03,  6.5161e-01],
         [ 9.7527e-04,  3.6114e-01],
         [ 5.8836e-04,  2.5217e-01],
         [-1.5069e-04,  1.9679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3192566958881082
Current reward: 0.27650466047662936
Current mitigation activation: 0
#############################
Total reward: 20.502519103781466
11.271285876631737 seconds in game passed.
Action: tensor([[[ 2.6383e-03,  6.5161e-01],
         [ 9.7527e-04,  3.6114e-01],
         [ 5.8836e-04,  2.5217e-01],
         [-1.5069e-04,  1.9679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.502519103781466
11.296285877004266 seconds in game passed.
Action: tensor([[[ 2.6383e-03,  6.5161e-01],
         [ 9.7527e-04,  3.6114e-01],
         [ 5.8836e-04,  2.5217e-01],
         [-1.5069e-04,  1.9679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.502519103781466
11.321285877376795 seconds in game passed.
Action: tensor([[[ 2.6383e-03,  6.5161e-01],
         [ 9.7527e-04,  3.6114e-01],
         [ 5.8836e-04,  2.5217e-01],
         [-1.5069e-04,  1.9679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.502519103781466
+++++++++++++: 3.3561563457960455
11.346285877749324 seconds in game passed.
At 11.346285877749324 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2704e-03,  6.4138e-01],
         [ 3.5033e-04,  3.5778e-01],
         [ 2.8208e-05,  2.5048e-01],
         [-5.8386e-04,  1.9540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.3561563457960455
Current reward: 0.2778185286395972
Current mitigation activation: 0
#############################
Total reward: 20.780337632421062
11.371285878121853 seconds in game passed.
Action: tensor([[[ 2.2704e-03,  6.4138e-01],
         [ 3.5033e-04,  3.5778e-01],
         [ 2.8208e-05,  2.5048e-01],
         [-5.8386e-04,  1.9540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.780337632421062
11.396285878494382 seconds in game passed.
Action: tensor([[[ 2.2704e-03,  6.4138e-01],
         [ 3.5033e-04,  3.5778e-01],
         [ 2.8208e-05,  2.5048e-01],
         [-5.8386e-04,  1.9540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.780337632421062
11.421285878866911 seconds in game passed.
Action: tensor([[[ 2.2704e-03,  6.4138e-01],
         [ 3.5033e-04,  3.5778e-01],
         [ 2.8208e-05,  2.5048e-01],
         [-5.8386e-04,  1.9540e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.780337632421062
+++++++++++++: 3.196843726795439
11.44628587923944 seconds in game passed.
At 11.44628587923944 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1175e-03,  6.3238e-01],
         [ 2.2247e-04,  3.5253e-01],
         [-2.6584e-04,  2.4662e-01],
         [-8.9005e-04,  1.9206e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.196843726795439
Current reward: 0.28635970480707146
Current mitigation activation: 0
#############################
Total reward: 21.066697337228135
11.471285879611969 seconds in game passed.
Action: tensor([[[ 2.1175e-03,  6.3238e-01],
         [ 2.2247e-04,  3.5253e-01],
         [-2.6584e-04,  2.4662e-01],
         [-8.9005e-04,  1.9206e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.066697337228135
11.496285879984498 seconds in game passed.
Action: tensor([[[ 2.1175e-03,  6.3238e-01],
         [ 2.2247e-04,  3.5253e-01],
         [-2.6584e-04,  2.4662e-01],
         [-8.9005e-04,  1.9206e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.066697337228135
11.521285880357027 seconds in game passed.
Action: tensor([[[ 2.1175e-03,  6.3238e-01],
         [ 2.2247e-04,  3.5253e-01],
         [-2.6584e-04,  2.4662e-01],
         [-8.9005e-04,  1.9206e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.066697337228135
+++++++++++++: 2.931564871085898
11.546285880729556 seconds in game passed.
At 11.546285880729556 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0007,  0.6407],
         [-0.0007,  0.3548],
         [-0.0012,  0.2461],
         [-0.0018,  0.1905]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.931564871085898
Current reward: 0.2998838081012808
Current mitigation activation: 0
#############################
Total reward: 21.366581145329416
11.571285881102085 seconds in game passed.
Action: tensor([[[ 0.0007,  0.6407],
         [-0.0007,  0.3548],
         [-0.0012,  0.2461],
         [-0.0018,  0.1905]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.366581145329416
11.596285881474614 seconds in game passed.
Action: tensor([[[ 0.0007,  0.6407],
         [-0.0007,  0.3548],
         [-0.0012,  0.2461],
         [-0.0018,  0.1905]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.366581145329416
11.621285881847143 seconds in game passed.
Action: tensor([[[ 0.0007,  0.6407],
         [-0.0007,  0.3548],
         [-0.0012,  0.2461],
         [-0.0018,  0.1905]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.366581145329416
+++++++++++++: 2.7249739151014265
11.646285882219672 seconds in game passed.
At 11.646285882219672 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6610],
         [-0.0009,  0.3641],
         [-0.0016,  0.2514],
         [-0.0025,  0.1942]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7249739151014265
Current reward: 0.3116493006559311
Current mitigation activation: 0
#############################
Total reward: 21.678230445985346
11.671285882592201 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6610],
         [-0.0009,  0.3641],
         [-0.0016,  0.2514],
         [-0.0025,  0.1942]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.678230445985346
11.69628588296473 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6610],
         [-0.0009,  0.3641],
         [-0.0016,  0.2514],
         [-0.0025,  0.1942]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.678230445985346
11.72128588333726 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6610],
         [-0.0009,  0.3641],
         [-0.0016,  0.2514],
         [-0.0025,  0.1942]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.678230445985346
+++++++++++++: 2.5504333473898058
11.746285883709788 seconds in game passed.
At 11.746285883709788 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0015,  0.6746],
         [-0.0016,  0.3670],
         [-0.0023,  0.2515],
         [-0.0030,  0.1935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5504333473898058
Current reward: 0.3223405541292583
Current mitigation activation: 0
#############################
Total reward: 22.000571000114604
11.771285884082317 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6746],
         [-0.0016,  0.3670],
         [-0.0023,  0.2515],
         [-0.0030,  0.1935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.000571000114604
11.796285884454846 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6746],
         [-0.0016,  0.3670],
         [-0.0023,  0.2515],
         [-0.0030,  0.1935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.000571000114604
11.821285884827375 seconds in game passed.
Action: tensor([[[ 0.0015,  0.6746],
         [-0.0016,  0.3670],
         [-0.0023,  0.2515],
         [-0.0030,  0.1935]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.000571000114604
+++++++++++++: 2.3959283269034954
11.846285885199904 seconds in game passed.
At 11.846285885199904 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.1805e-04,  6.7290e-01],
         [-2.2227e-03,  3.6436e-01],
         [-3.0964e-03,  2.5024e-01],
         [-3.9667e-03,  1.9286e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3959283269034954
Current reward: 0.3322969125719776
Current mitigation activation: 0
#############################
Total reward: 22.33286791268658
11.871285885572433 seconds in game passed.
Action: tensor([[[-4.1805e-04,  6.7290e-01],
         [-2.2227e-03,  3.6436e-01],
         [-3.0964e-03,  2.5024e-01],
         [-3.9667e-03,  1.9286e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.33286791268658
11.896285885944963 seconds in game passed.
Action: tensor([[[-4.1805e-04,  6.7290e-01],
         [-2.2227e-03,  3.6436e-01],
         [-3.0964e-03,  2.5024e-01],
         [-3.9667e-03,  1.9286e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.33286791268658
11.921285886317492 seconds in game passed.
Action: tensor([[[-4.1805e-04,  6.7290e-01],
         [-2.2227e-03,  3.6436e-01],
         [-3.0964e-03,  2.5024e-01],
         [-3.9667e-03,  1.9286e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000993, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.33286791268658
+++++++++++++: 2.2554750028296975
11.94628588669002 seconds in game passed.
At 11.94628588669002 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6816],
         [-0.0036,  0.3690],
         [-0.0045,  0.2548],
         [-0.0054,  0.1966]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2554750028296975
Current reward: 0.3416832240529092
Current mitigation activation: 0
#############################
Total reward: 22.67455113673949
11.97128588706255 seconds in game passed.
Action: tensor([[[-0.0022,  0.6816],
         [-0.0036,  0.3690],
         [-0.0045,  0.2548],
         [-0.0054,  0.1966]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.67455113673949
11.996285887435079 seconds in game passed.
Action: tensor([[[-0.0022,  0.6816],
         [-0.0036,  0.3690],
         [-0.0045,  0.2548],
         [-0.0054,  0.1966]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.67455113673949
12.021285887807608 seconds in game passed.
Action: tensor([[[-0.0022,  0.6816],
         [-0.0036,  0.3690],
         [-0.0045,  0.2548],
         [-0.0054,  0.1966]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.67455113673949
+++++++++++++: 2.1256596754373236
12.046285888180137 seconds in game passed.
At 12.046285888180137 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.3898e-04,  6.7913e-01],
         [-3.0262e-03,  3.7184e-01],
         [-3.9864e-03,  2.5739e-01],
         [-4.7446e-03,  1.9869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001714, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1256596754373236
Current reward: 0.3505852087503666
Current mitigation activation: 0
#############################
Total reward: 23.025136345489855
12.071285888552666 seconds in game passed.
Action: tensor([[[-4.3898e-04,  6.7913e-01],
         [-3.0262e-03,  3.7184e-01],
         [-3.9864e-03,  2.5739e-01],
         [-4.7446e-03,  1.9869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001967, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.025136345489855
12.096285888925195 seconds in game passed.
Action: tensor([[[-4.3898e-04,  6.7913e-01],
         [-3.0262e-03,  3.7184e-01],
         [-3.9864e-03,  2.5739e-01],
         [-4.7446e-03,  1.9869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.025136345489855
12.121285889297724 seconds in game passed.
Action: tensor([[[-4.3898e-04,  6.7913e-01],
         [-3.0262e-03,  3.7184e-01],
         [-3.9864e-03,  2.5739e-01],
         [-4.7446e-03,  1.9869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.025136345489855
+++++++++++++: 2.004657172909206
12.146285889670253 seconds in game passed.
At 12.146285889670253 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0025,  0.6796],
         [-0.0011,  0.3723],
         [-0.0018,  0.2574],
         [-0.0025,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.004657172909206
Current reward: 0.3590209688174305
Current mitigation activation: 0
#############################
Total reward: 23.384157314307284
12.171285890042782 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6796],
         [-0.0011,  0.3723],
         [-0.0018,  0.2574],
         [-0.0025,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000038, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.384157314307284
12.19628589041531 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6796],
         [-0.0011,  0.3723],
         [-0.0018,  0.2574],
         [-0.0025,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.384157314307284
12.22128589078784 seconds in game passed.
Action: tensor([[[ 0.0025,  0.6796],
         [-0.0011,  0.3723],
         [-0.0018,  0.2574],
         [-0.0025,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.384157314307284
+++++++++++++: 1.891176069580503
12.246285891160369 seconds in game passed.
At 12.246285891160369 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0016,  0.6749],
         [-0.0012,  0.3752],
         [-0.0020,  0.2616],
         [-0.0028,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.891176069580503
Current reward: 0.3669912738447546
Current mitigation activation: 0
#############################
Total reward: 23.751148588152038
12.271285891532898 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6749],
         [-0.0012,  0.3752],
         [-0.0020,  0.2616],
         [-0.0028,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.751148588152038
12.296285891905427 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6749],
         [-0.0012,  0.3752],
         [-0.0020,  0.2616],
         [-0.0028,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000417, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.751148588152038
12.321285892277956 seconds in game passed.
Action: tensor([[[ 0.0016,  0.6749],
         [-0.0012,  0.3752],
         [-0.0020,  0.2616],
         [-0.0028,  0.2026]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.751148588152038
+++++++++++++: 1.784141812743149
12.346285892650485 seconds in game passed.
At 12.346285892650485 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.6890e-03,  6.7710e-01],
         [ 2.4283e-04,  3.8776e-01],
         [-5.8512e-04,  2.7485e-01],
         [-1.1803e-03,  2.1456e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.784141812743149
Current reward: 0.37449571657224107
Current mitigation activation: 0
#############################
Total reward: 24.12564430472428
12.371285893023014 seconds in game passed.
Action: tensor([[[ 6.6890e-03,  6.7710e-01],
         [ 2.4283e-04,  3.8776e-01],
         [-5.8512e-04,  2.7485e-01],
         [-1.1803e-03,  2.1456e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.12564430472428
12.396285893395543 seconds in game passed.
Action: tensor([[[ 6.6890e-03,  6.7710e-01],
         [ 2.4283e-04,  3.8776e-01],
         [-5.8512e-04,  2.7485e-01],
         [-1.1803e-03,  2.1456e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.12564430472428
12.421285893768072 seconds in game passed.
Action: tensor([[[ 6.6890e-03,  6.7710e-01],
         [ 2.4283e-04,  3.8776e-01],
         [-5.8512e-04,  2.7485e-01],
         [-1.1803e-03,  2.1456e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002259, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.12564430472428
+++++++++++++: 1.6826093414706695
12.446285894140601 seconds in game passed.
At 12.446285894140601 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.2425e-03,  7.0814e-01],
         [ 5.0876e-04,  3.9750e-01],
         [-3.9522e-04,  2.7835e-01],
         [-8.4245e-04,  2.1521e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6826093414706695
Current reward: 0.38154598384721006
Current mitigation activation: 0
#############################
Total reward: 24.50719028857149
12.47128589451313 seconds in game passed.
Action: tensor([[[ 7.2425e-03,  7.0814e-01],
         [ 5.0876e-04,  3.9750e-01],
         [-3.9522e-04,  2.7835e-01],
         [-8.4245e-04,  2.1521e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.50719028857149
12.49628589488566 seconds in game passed.
Action: tensor([[[ 7.2425e-03,  7.0814e-01],
         [ 5.0876e-04,  3.9750e-01],
         [-3.9522e-04,  2.7835e-01],
         [-8.4245e-04,  2.1521e-01]]])
agent 0 action: VehicleControl(throttle=0.887217, steer=0.002662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.50719028857149
12.521285895258188 seconds in game passed.
Action: tensor([[[ 7.2425e-03,  7.0814e-01],
         [ 5.0876e-04,  3.9750e-01],
         [-3.9522e-04,  2.7835e-01],
         [-8.4245e-04,  2.1521e-01]]])
agent 0 action: VehicleControl(throttle=0.828155, steer=0.002686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.50719028857149
+++++++++++++: 1.5859281366225286
12.546285895630717 seconds in game passed.
At 12.546285895630717 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.8962e-03,  7.3100e-01],
         [ 7.9698e-04,  4.1035e-01],
         [-6.4179e-05,  2.8756e-01],
         [-2.0949e-04,  2.2235e-01]]])
agent 0 action: VehicleControl(throttle=0.633325, steer=0.004053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5859281366225286
Current reward: 0.3881346179018109
Current mitigation activation: 0
#############################
Total reward: 24.895324906473302
12.571285896003246 seconds in game passed.
Action: tensor([[[ 9.8962e-03,  7.3100e-01],
         [ 7.9698e-04,  4.1035e-01],
         [-6.4179e-05,  2.8756e-01],
         [-2.0949e-04,  2.2235e-01]]])
agent 0 action: VehicleControl(throttle=0.587790, steer=0.003885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.895324906473302
12.596285896375775 seconds in game passed.
Action: tensor([[[ 9.8962e-03,  7.3100e-01],
         [ 7.9698e-04,  4.1035e-01],
         [-6.4179e-05,  2.8756e-01],
         [-2.0949e-04,  2.2235e-01]]])
agent 0 action: VehicleControl(throttle=0.545470, steer=0.003936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.895324906473302
12.621285896748304 seconds in game passed.
Action: tensor([[[ 9.8962e-03,  7.3100e-01],
         [ 7.9698e-04,  4.1035e-01],
         [-6.4179e-05,  2.8756e-01],
         [-2.0949e-04,  2.2235e-01]]])
agent 0 action: VehicleControl(throttle=0.522122, steer=0.003987, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.895324906473302
+++++++++++++: 1.4950205569009642
12.646285897120833 seconds in game passed.
At 12.646285897120833 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[9.7573e-03, 7.5017e-01],
         [1.6251e-03, 4.1580e-01],
         [5.6530e-04, 2.9043e-01],
         [1.7028e-04, 2.2442e-01]]])
agent 0 action: VehicleControl(throttle=0.498147, steer=0.004575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4950205569009642
Current reward: 0.39402491879322754
Current mitigation activation: 0
#############################
Total reward: 25.28934982526653
12.671285897493362 seconds in game passed.
Action: tensor([[[9.7573e-03, 7.5017e-01],
         [1.6251e-03, 4.1580e-01],
         [5.6530e-04, 2.9043e-01],
         [1.7028e-04, 2.2442e-01]]])
agent 0 action: VehicleControl(throttle=0.474658, steer=0.004542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.28934982526653
12.696285897865891 seconds in game passed.
Action: tensor([[[9.7573e-03, 7.5017e-01],
         [1.6251e-03, 4.1580e-01],
         [5.6530e-04, 2.9043e-01],
         [1.7028e-04, 2.2442e-01]]])
agent 0 action: VehicleControl(throttle=0.451650, steer=0.004598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.28934982526653
12.72128589823842 seconds in game passed.
Action: tensor([[[9.7573e-03, 7.5017e-01],
         [1.6251e-03, 4.1580e-01],
         [5.6530e-04, 2.9043e-01],
         [1.7028e-04, 2.2442e-01]]])
agent 0 action: VehicleControl(throttle=0.429119, steer=0.004654, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.28934982526653
+++++++++++++: 1.4195172649827723
12.74628589861095 seconds in game passed.
At 12.74628589861095 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4902e-02,  7.6067e-01],
         [ 1.2981e-03,  4.2339e-01],
         [-4.8716e-04,  2.9674e-01],
         [-1.2605e-03,  2.2943e-01]]])
agent 0 action: VehicleControl(throttle=0.406654, steer=0.006626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.4195172649827723
Current reward: 0.3974720811528212
Current mitigation activation: 0
#############################
Total reward: 25.68682190641935
12.771285898983479 seconds in game passed.
Action: tensor([[[ 1.4902e-02,  7.6067e-01],
         [ 1.2981e-03,  4.2339e-01],
         [-4.8716e-04,  2.9674e-01],
         [-1.2605e-03,  2.2943e-01]]])
agent 0 action: VehicleControl(throttle=0.384659, steer=0.006391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.68682190641935
12.796285899356008 seconds in game passed.
Action: tensor([[[ 1.4902e-02,  7.6067e-01],
         [ 1.2981e-03,  4.2339e-01],
         [-4.8716e-04,  2.9674e-01],
         [-1.2605e-03,  2.2943e-01]]])
agent 0 action: VehicleControl(throttle=0.363132, steer=0.006471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.68682190641935
12.821285899728537 seconds in game passed.
Action: tensor([[[ 1.4902e-02,  7.6067e-01],
         [ 1.2981e-03,  4.2339e-01],
         [-4.8716e-04,  2.9674e-01],
         [-1.2605e-03,  2.2943e-01]]])
agent 0 action: VehicleControl(throttle=0.342070, steer=0.006551, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.68682190641935
+++++++++++++: 1.361128978152544
12.846285900101066 seconds in game passed.
At 12.846285900101066 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0087,  0.7912],
         [-0.0021,  0.4275],
         [-0.0038,  0.2961],
         [-0.0045,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.320792, steer=0.001479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.361128978152544
Current reward: 0.3978601782631524
Current mitigation activation: 0
#############################
Total reward: 26.084682084682502
12.871285900473595 seconds in game passed.
Action: tensor([[[ 0.0087,  0.7912],
         [-0.0021,  0.4275],
         [-0.0038,  0.2961],
         [-0.0045,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.299975, steer=0.002370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.084682084682502
12.896285900846124 seconds in game passed.
Action: tensor([[[ 0.0087,  0.7912],
         [-0.0021,  0.4275],
         [-0.0038,  0.2961],
         [-0.0045,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.279618, steer=0.002410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.084682084682502
12.921285901218653 seconds in game passed.
Action: tensor([[[ 0.0087,  0.7912],
         [-0.0021,  0.4275],
         [-0.0038,  0.2961],
         [-0.0045,  0.2273]]])
agent 0 action: VehicleControl(throttle=0.259719, steer=0.002449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.084682084682502
+++++++++++++: 1.3163920124440713
12.946285901591182 seconds in game passed.
At 12.946285901591182 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0099,  0.8156],
         [-0.0017,  0.4446],
         [-0.0043,  0.3080],
         [-0.0056,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.240962, steer=0.003311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3163920124440713
Current reward: 0.3956329842465491
Current mitigation activation: 0
#############################
Total reward: 26.480315068929052
12.97128590196371 seconds in game passed.
Action: tensor([[[ 0.0099,  0.8156],
         [-0.0017,  0.4446],
         [-0.0043,  0.3080],
         [-0.0056,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.222660, steer=0.003245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.480315068929052
12.99628590233624 seconds in game passed.
Action: tensor([[[ 0.0099,  0.8156],
         [-0.0017,  0.4446],
         [-0.0043,  0.3080],
         [-0.0056,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.204814, steer=0.003311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.480315068929052
13.021285902708769 seconds in game passed.
Action: tensor([[[ 0.0099,  0.8156],
         [-0.0017,  0.4446],
         [-0.0043,  0.3080],
         [-0.0056,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.187420, steer=0.003377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.480315068929052
+++++++++++++: 1.2828981504307981
13.046285903081298 seconds in game passed.
At 13.046285903081298 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[-0.0014,  1.0000],
         [-0.0054,  1.0000],
         [-0.0096,  1.0000],
         [-0.0113,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003694, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2828981504307981
Current reward: 0.39122990237680383
Current mitigation activation: 1
#############################
Total reward: 26.871544971305855
13.071285903453827 seconds in game passed.
Action: tensor([[[-0.0014,  1.0000],
         [-0.0054,  1.0000],
         [-0.0096,  1.0000],
         [-0.0113,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002539, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.871544971305855
13.096285903826356 seconds in game passed.
Action: tensor([[[-0.0014,  1.0000],
         [-0.0054,  1.0000],
         [-0.0096,  1.0000],
         [-0.0113,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002558, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.871544971305855
13.121285904198885 seconds in game passed.
Action: tensor([[[-0.0014,  1.0000],
         [-0.0054,  1.0000],
         [-0.0096,  1.0000],
         [-0.0113,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002578, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.871544971305855
+++++++++++++: 1.2621645260813572
13.146285904571414 seconds in game passed.
At 13.146285904571414 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0040,  1.0000],
         [-0.0049,  1.0000],
         [-0.0096,  1.0000],
         [-0.0112,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001173, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2621645260813572
Current reward: 0.3844618405837985
Current mitigation activation: 1
#############################
Total reward: 27.256006811889655
13.171285904943943 seconds in game passed.
Action: tensor([[[ 0.0040,  1.0000],
         [-0.0049,  1.0000],
         [-0.0096,  1.0000],
         [-0.0112,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000539, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.256006811889655
13.196285905316472 seconds in game passed.
Action: tensor([[[ 0.0040,  1.0000],
         [-0.0049,  1.0000],
         [-0.0096,  1.0000],
         [-0.0112,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000531, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.256006811889655
13.221285905689001 seconds in game passed.
Action: tensor([[[ 0.0040,  1.0000],
         [-0.0049,  1.0000],
         [-0.0096,  1.0000],
         [-0.0112,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000523, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.256006811889655
+++++++++++++: 1.2829425301431323
13.24628590606153 seconds in game passed.
At 13.24628590606153 seconds, saving state-action tuples.
Mitigation action constant threshold: 1
Action: tensor([[[ 0.0079,  1.0000],
         [-0.0142,  1.0000],
         [-0.0175,  1.0000],
         [-0.0165,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002954, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.2829425301431323
Current reward: 0.37039099582708235
Current mitigation activation: 1
#############################
Total reward: 27.62639780771674
13.27128590643406 seconds in game passed.
Action: tensor([[[ 0.0079,  1.0000],
         [-0.0142,  1.0000],
         [-0.0175,  1.0000],
         [-0.0165,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002420, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.62639780771674
13.296285906806588 seconds in game passed.
Action: tensor([[[ 0.0079,  1.0000],
         [-0.0142,  1.0000],
         [-0.0175,  1.0000],
         [-0.0165,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002459, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.62639780771674
13.321285907179117 seconds in game passed.
Action: tensor([[[ 0.0079,  1.0000],
         [-0.0142,  1.0000],
         [-0.0175,  1.0000],
         [-0.0165,  1.0000]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.002498, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.62639780771674
+++++++++++++: 1.373549061841683
13.346285907551646 seconds in game passed.
At 13.346285907551646 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0078,  0.9396],
         [-0.0080,  0.5539],
         [-0.0105,  0.3607],
         [-0.0101,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001101, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.373549061841683
Current reward: 0.34666044356395875
Current mitigation activation: 0
#############################
Total reward: 27.973058251280698
13.371285907924175 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9396],
         [-0.0080,  0.5539],
         [-0.0105,  0.3607],
         [-0.0101,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001400, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.973058251280698
13.396285908296704 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9396],
         [-0.0080,  0.5539],
         [-0.0105,  0.3607],
         [-0.0101,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001457, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.973058251280698
13.421285908669233 seconds in game passed.
Action: tensor([[[ 0.0078,  0.9396],
         [-0.0080,  0.5539],
         [-0.0105,  0.3607],
         [-0.0101,  0.2677]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.001514, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.973058251280698
+++++++++++++: 1.5140682911459131
13.446285909041762 seconds in game passed.
At 13.446285909041762 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0091,  0.9441],
         [-0.0149,  0.5748],
         [-0.0167,  0.3665],
         [-0.0150,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006005, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5140682911459131
Current reward: 0.32101819546748955
Current mitigation activation: 0
#############################
Total reward: 28.294076446748186
13.471285909414291 seconds in game passed.
Action: tensor([[[ 0.0091,  0.9441],
         [-0.0149,  0.5748],
         [-0.0167,  0.3665],
         [-0.0150,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005381, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.294076446748186
13.49628590978682 seconds in game passed.
Action: tensor([[[ 0.0091,  0.9441],
         [-0.0149,  0.5748],
         [-0.0167,  0.3665],
         [-0.0150,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.003448, steer=-0.005488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.294076446748186
13.52128591015935 seconds in game passed.
Action: tensor([[[ 0.0091,  0.9441],
         [-0.0149,  0.5748],
         [-0.0167,  0.3665],
         [-0.0150,  0.2694]]])
agent 0 action: VehicleControl(throttle=0.000875, steer=-0.005594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.294076446748186
+++++++++++++: 1.703667777453227
13.546285910531878 seconds in game passed.
At 13.546285910531878 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0083,  0.9463],
         [-0.0112,  0.6126],
         [-0.0127,  0.3799],
         [-0.0103,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003059, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.703667777453227
Current reward: 0.29635500501027157
Current mitigation activation: 0
#############################
Total reward: 28.59043145175846
13.571285910904408 seconds in game passed.
Action: tensor([[[ 0.0083,  0.9463],
         [-0.0112,  0.6126],
         [-0.0127,  0.3799],
         [-0.0103,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003590, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.59043145175846
13.596285911276937 seconds in game passed.
Action: tensor([[[ 0.0083,  0.9463],
         [-0.0112,  0.6126],
         [-0.0127,  0.3799],
         [-0.0103,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003683, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.59043145175846
13.621285911649466 seconds in game passed.
Action: tensor([[[ 0.0083,  0.9463],
         [-0.0112,  0.6126],
         [-0.0127,  0.3799],
         [-0.0103,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003776, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.59043145175846
+++++++++++++: 1.898553314571938
13.646285912021995 seconds in game passed.
At 13.646285912021995 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0024,  0.9450],
         [-0.0110,  0.5989],
         [-0.0107,  0.3730],
         [-0.0078,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.898553314571938
Current reward: 0.2777168376127582
Current mitigation activation: 0
#############################
Total reward: 28.868148289371216
13.671285912394524 seconds in game passed.
Action: tensor([[[ 0.0024,  0.9450],
         [-0.0110,  0.5989],
         [-0.0107,  0.3730],
         [-0.0078,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.868148289371216
13.696285912767053 seconds in game passed.
Action: tensor([[[ 0.0024,  0.9450],
         [-0.0110,  0.5989],
         [-0.0107,  0.3730],
         [-0.0078,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.002766, steer=-0.006377, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.868148289371216
13.721285913139582 seconds in game passed.
Action: tensor([[[ 0.0024,  0.9450],
         [-0.0110,  0.5989],
         [-0.0107,  0.3730],
         [-0.0078,  0.2695]]])
agent 0 action: VehicleControl(throttle=0.063609, steer=-0.006503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.868148289371216
+++++++++++++: 2.166592858928989
13.74628591351211 seconds in game passed.
At 13.74628591351211 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1053e-02,  9.4364e-01],
         [ 3.0809e-03,  5.7126e-01],
         [-1.6154e-04,  3.6873e-01],
         [ 8.4651e-04,  2.6485e-01]]])
agent 0 action: VehicleControl(throttle=0.403815, steer=0.007658, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.166592858928989
Current reward: 0.25910439118856476
Current mitigation activation: 0
#############################
Total reward: 29.12725268055978
13.77128591388464 seconds in game passed.
Action: tensor([[[ 1.1053e-02,  9.4364e-01],
         [ 3.0809e-03,  5.7126e-01],
         [-1.6154e-04,  3.6873e-01],
         [ 8.4651e-04,  2.6485e-01]]])
agent 0 action: VehicleControl(throttle=0.421003, steer=0.005300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.12725268055978
13.796285914257169 seconds in game passed.
Action: tensor([[[ 1.1053e-02,  9.4364e-01],
         [ 3.0809e-03,  5.7126e-01],
         [-1.6154e-04,  3.6873e-01],
         [ 8.4651e-04,  2.6485e-01]]])
agent 0 action: VehicleControl(throttle=0.469434, steer=0.005301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.12725268055978
13.821285914629698 seconds in game passed.
Action: tensor([[[ 1.1053e-02,  9.4364e-01],
         [ 3.0809e-03,  5.7126e-01],
         [-1.6154e-04,  3.6873e-01],
         [ 8.4651e-04,  2.6485e-01]]])
agent 0 action: VehicleControl(throttle=0.513468, steer=0.005303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.12725268055978
+++++++++++++: 2.3900102318943253
13.846285915002227 seconds in game passed.
At 13.846285915002227 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0086, 0.9403],
         [0.0058, 0.5525],
         [0.0017, 0.3610],
         [0.0011, 0.2614]]])
agent 0 action: VehicleControl(throttle=0.770444, steer=0.006184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3900102318943253
Current reward: 0.2481560751695812
Current mitigation activation: 0
#############################
Total reward: 29.375408755729364
13.871285915374756 seconds in game passed.
Action: tensor([[[0.0086, 0.9403],
         [0.0058, 0.5525],
         [0.0017, 0.3610],
         [0.0011, 0.2614]]])
agent 0 action: VehicleControl(throttle=0.782750, steer=0.006111, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.375408755729364
13.896285915747285 seconds in game passed.
Action: tensor([[[0.0086, 0.9403],
         [0.0058, 0.5525],
         [0.0017, 0.3610],
         [0.0011, 0.2614]]])
agent 0 action: VehicleControl(throttle=0.812322, steer=0.006174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.375408755729364
13.921285916119814 seconds in game passed.
Action: tensor([[[0.0086, 0.9403],
         [0.0058, 0.5525],
         [0.0017, 0.3610],
         [0.0011, 0.2614]]])
agent 0 action: VehicleControl(throttle=0.834914, steer=0.006238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.375408755729364
+++++++++++++: 2.5688630101342738
13.946285916492343 seconds in game passed.
At 13.946285916492343 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.4909e-03, 9.3174e-01],
         [4.2805e-03, 5.2338e-01],
         [1.2313e-03, 3.4786e-01],
         [8.8159e-04, 2.5496e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5688630101342738
Current reward: 0.24200777582618105
Current mitigation activation: 0
#############################
Total reward: 29.617416531555545
13.971285916864872 seconds in game passed.
Action: tensor([[[5.4909e-03, 9.3174e-01],
         [4.2805e-03, 5.2338e-01],
         [1.2313e-03, 3.4786e-01],
         [8.8159e-04, 2.5496e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.617416531555545
13.996285917237401 seconds in game passed.
Action: tensor([[[5.4909e-03, 9.3174e-01],
         [4.2805e-03, 5.2338e-01],
         [1.2313e-03, 3.4786e-01],
         [8.8159e-04, 2.5496e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.617416531555545
14.02128591760993 seconds in game passed.
Action: tensor([[[5.4909e-03, 9.3174e-01],
         [4.2805e-03, 5.2338e-01],
         [1.2313e-03, 3.4786e-01],
         [8.8159e-04, 2.5496e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.617416531555545
+++++++++++++: 2.6125882215109644
14.046285917982459 seconds in game passed.
At 14.046285917982459 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5456e-03,  9.2800e-01],
         [ 2.7445e-03,  5.1603e-01],
         [ 5.3053e-04,  3.4517e-01],
         [ 4.2365e-04,  2.5482e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000204, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6125882215109644
Current reward: 0.24304242789551536
Current mitigation activation: 0
#############################
Total reward: 29.86045895945106
14.071285918354988 seconds in game passed.
Action: tensor([[[-1.5456e-03,  9.2800e-01],
         [ 2.7445e-03,  5.1603e-01],
         [ 5.3053e-04,  3.4517e-01],
         [ 4.2365e-04,  2.5482e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.86045895945106
14.096285918727517 seconds in game passed.
Action: tensor([[[-1.5456e-03,  9.2800e-01],
         [ 2.7445e-03,  5.1603e-01],
         [ 5.3053e-04,  3.4517e-01],
         [ 4.2365e-04,  2.5482e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.86045895945106
14.121285919100046 seconds in game passed.
Action: tensor([[[-1.5456e-03,  9.2800e-01],
         [ 2.7445e-03,  5.1603e-01],
         [ 5.3053e-04,  3.4517e-01],
         [ 4.2365e-04,  2.5482e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001071, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.86045895945106
+++++++++++++: 2.537962495973329
14.146285919472575 seconds in game passed.
At 14.146285919472575 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0014,  0.9115],
         [ 0.0010,  0.4916],
         [-0.0018,  0.3305],
         [-0.0018,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.537962495973329
Current reward: 0.24951979361396576
Current mitigation activation: 0
#############################
Total reward: 30.109978753065025
14.171285919845104 seconds in game passed.
Action: tensor([[[ 0.0014,  0.9115],
         [ 0.0010,  0.4916],
         [-0.0018,  0.3305],
         [-0.0018,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.109978753065025
14.196285920217633 seconds in game passed.
Action: tensor([[[ 0.0014,  0.9115],
         [ 0.0010,  0.4916],
         [-0.0018,  0.3305],
         [-0.0018,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.109978753065025
14.221285920590162 seconds in game passed.
Action: tensor([[[ 0.0014,  0.9115],
         [ 0.0010,  0.4916],
         [-0.0018,  0.3305],
         [-0.0018,  0.2451]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001056, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.109978753065025
+++++++++++++: 2.411619170093524
14.246285920962691 seconds in game passed.
At 14.246285920962691 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0028,  0.8960],
         [-0.0015,  0.4851],
         [-0.0028,  0.3328],
         [-0.0019,  0.2505]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.411619170093524
Current reward: 0.2586007402871165
Current mitigation activation: 0
#############################
Total reward: 30.368579493352144
14.27128592133522 seconds in game passed.
Action: tensor([[[-0.0028,  0.8960],
         [-0.0015,  0.4851],
         [-0.0028,  0.3328],
         [-0.0019,  0.2505]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001883, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.368579493352144
14.29628592170775 seconds in game passed.
Action: tensor([[[-0.0028,  0.8960],
         [-0.0015,  0.4851],
         [-0.0028,  0.3328],
         [-0.0019,  0.2505]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.368579493352144
14.321285922080278 seconds in game passed.
Action: tensor([[[-0.0028,  0.8960],
         [-0.0015,  0.4851],
         [-0.0028,  0.3328],
         [-0.0019,  0.2505]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.368579493352144
+++++++++++++: 2.271213094768142
14.346285922452807 seconds in game passed.
At 14.346285922452807 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0106,  0.9048],
         [-0.0023,  0.5049],
         [-0.0036,  0.3511],
         [-0.0033,  0.2679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.271213094768142
Current reward: 0.2687268292846889
Current mitigation activation: 0
#############################
Total reward: 30.63730632263683
14.371285922825336 seconds in game passed.
Action: tensor([[[-0.0106,  0.9048],
         [-0.0023,  0.5049],
         [-0.0036,  0.3511],
         [-0.0033,  0.2679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.63730632263683
14.396285923197865 seconds in game passed.
Action: tensor([[[-0.0106,  0.9048],
         [-0.0023,  0.5049],
         [-0.0036,  0.3511],
         [-0.0033,  0.2679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.63730632263683
14.421285923570395 seconds in game passed.
Action: tensor([[[-0.0106,  0.9048],
         [-0.0023,  0.5049],
         [-0.0036,  0.3511],
         [-0.0033,  0.2679]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.63730632263683
+++++++++++++: 2.132711766381316
14.446285923942924 seconds in game passed.
At 14.446285923942924 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0058,  0.8957],
         [-0.0034,  0.5160],
         [-0.0046,  0.3732],
         [-0.0037,  0.2949]]])
agent 0 action: VehicleControl(throttle=0.793298, steer=-0.004059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.132711766381316
Current reward: 0.27911613482101977
Current mitigation activation: 0
#############################
Total reward: 30.916422457457852
14.471285924315453 seconds in game passed.
Action: tensor([[[-0.0058,  0.8957],
         [-0.0034,  0.5160],
         [-0.0046,  0.3732],
         [-0.0037,  0.2949]]])
agent 0 action: VehicleControl(throttle=0.783731, steer=-0.004235, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.916422457457852
14.496285924687982 seconds in game passed.
Action: tensor([[[-0.0058,  0.8957],
         [-0.0034,  0.5160],
         [-0.0046,  0.3732],
         [-0.0037,  0.2949]]])
agent 0 action: VehicleControl(throttle=0.751630, steer=-0.004215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.916422457457852
14.52128592506051 seconds in game passed.
Action: tensor([[[-0.0058,  0.8957],
         [-0.0034,  0.5160],
         [-0.0046,  0.3732],
         [-0.0037,  0.2949]]])
agent 0 action: VehicleControl(throttle=0.720192, steer=-0.004195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.916422457457852
+++++++++++++: 2.0027356596105466
14.54628592543304 seconds in game passed.
At 14.54628592543304 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.7027e-04,  8.8193e-01],
         [-2.3810e-03,  5.0164e-01],
         [-4.1322e-03,  3.5983e-01],
         [-3.4164e-03,  2.8210e-01]]])
agent 0 action: VehicleControl(throttle=0.839116, steer=-0.001036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0027356596105466
Current reward: 0.2893047958315172
Current mitigation activation: 0
#############################
Total reward: 31.205727253289368
14.571285925805569 seconds in game passed.
Action: tensor([[[-1.7027e-04,  8.8193e-01],
         [-2.3810e-03,  5.0164e-01],
         [-4.1322e-03,  3.5983e-01],
         [-3.4164e-03,  2.8210e-01]]])
agent 0 action: VehicleControl(throttle=0.794851, steer=-0.001533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.205727253289368
14.596285926178098 seconds in game passed.
Action: tensor([[[-1.7027e-04,  8.8193e-01],
         [-2.3810e-03,  5.0164e-01],
         [-4.1322e-03,  3.5983e-01],
         [-3.4164e-03,  2.8210e-01]]])
agent 0 action: VehicleControl(throttle=0.767423, steer=-0.001508, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.205727253289368
14.621285926550627 seconds in game passed.
Action: tensor([[[-1.7027e-04,  8.8193e-01],
         [-2.3810e-03,  5.0164e-01],
         [-4.1322e-03,  3.5983e-01],
         [-3.4164e-03,  2.8210e-01]]])
agent 0 action: VehicleControl(throttle=0.739742, steer=-0.001483, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.205727253289368
+++++++++++++: 1.8907174477881181
14.646285926923156 seconds in game passed.
At 14.646285926923156 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0079,  0.9027],
         [-0.0012,  0.5008],
         [-0.0024,  0.3510],
         [-0.0021,  0.2711]]])
agent 0 action: VehicleControl(throttle=0.827923, steer=-0.003817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8907174477881181
Current reward: 0.2983703355623968
Current mitigation activation: 0
#############################
Total reward: 31.504097588851764
14.671285927295685 seconds in game passed.
Action: tensor([[[-0.0079,  0.9027],
         [-0.0012,  0.5008],
         [-0.0024,  0.3510],
         [-0.0021,  0.2711]]])
agent 0 action: VehicleControl(throttle=0.790042, steer=-0.003395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.504097588851764
14.696285927668214 seconds in game passed.
Action: tensor([[[-0.0079,  0.9027],
         [-0.0012,  0.5008],
         [-0.0024,  0.3510],
         [-0.0021,  0.2711]]])
agent 0 action: VehicleControl(throttle=0.764778, steer=-0.003367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.504097588851764
14.721285928040743 seconds in game passed.
Action: tensor([[[-0.0079,  0.9027],
         [-0.0012,  0.5008],
         [-0.0024,  0.3510],
         [-0.0021,  0.2711]]])
agent 0 action: VehicleControl(throttle=0.738485, steer=-0.003339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.504097588851764
+++++++++++++: 1.7937588619653062
14.746285928413272 seconds in game passed.
At 14.746285928413272 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0016,  0.9224],
         [-0.0030,  0.5065],
         [-0.0057,  0.3463],
         [-0.0051,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.713707, steer=-0.000823, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7937588619653062
Current reward: 0.30625704875158993
Current mitigation activation: 0
#############################
Total reward: 31.810354637603353
14.771285928785801 seconds in game passed.
Action: tensor([[[ 0.0016,  0.9224],
         [-0.0030,  0.5065],
         [-0.0057,  0.3463],
         [-0.0051,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.683097, steer=-0.001350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.810354637603353
14.79628592915833 seconds in game passed.
Action: tensor([[[ 0.0016,  0.9224],
         [-0.0030,  0.5065],
         [-0.0057,  0.3463],
         [-0.0051,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.653110, steer=-0.001442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.810354637603353
14.821285929530859 seconds in game passed.
Action: tensor([[[ 0.0016,  0.9224],
         [-0.0030,  0.5065],
         [-0.0057,  0.3463],
         [-0.0051,  0.2618]]])
agent 0 action: VehicleControl(throttle=0.623465, steer=-0.001534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.810354637603353
+++++++++++++: 1.7071151898851915
14.846285929903388 seconds in game passed.
At 14.846285929903388 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0071,  0.9324],
         [-0.0021,  0.5144],
         [-0.0047,  0.3410],
         [-0.0034,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.517635, steer=0.001374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7071151898851915
Current reward: 0.31319356406254617
Current mitigation activation: 0
#############################
Total reward: 32.1235482016659
14.871285930275917 seconds in game passed.
Action: tensor([[[ 0.0071,  0.9324],
         [-0.0021,  0.5144],
         [-0.0047,  0.3410],
         [-0.0034,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.494255, steer=0.000808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.1235482016659
14.896285930648446 seconds in game passed.
Action: tensor([[[ 0.0071,  0.9324],
         [-0.0021,  0.5144],
         [-0.0047,  0.3410],
         [-0.0034,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.464490, steer=0.000739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.1235482016659
14.921285931020975 seconds in game passed.
Action: tensor([[[ 0.0071,  0.9324],
         [-0.0021,  0.5144],
         [-0.0047,  0.3410],
         [-0.0034,  0.2514]]])
agent 0 action: VehicleControl(throttle=0.437125, steer=0.000669, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.1235482016659
+++++++++++++: 1.6350873011652063
14.946285931393504 seconds in game passed.
At 14.946285931393504 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0031,  0.9403],
         [-0.0037,  0.5358],
         [-0.0054,  0.3479],
         [-0.0031,  0.2551]]])
agent 0 action: VehicleControl(throttle=0.327201, steer=-0.002254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6350873011652063
Current reward: 0.3185316189134063
Current mitigation activation: 0
#############################
Total reward: 32.4420798205793
14.971285931766033 seconds in game passed.
Action: tensor([[[ 0.0031,  0.9403],
         [-0.0037,  0.5358],
         [-0.0054,  0.3479],
         [-0.0031,  0.2551]]])
agent 0 action: VehicleControl(throttle=0.324066, steer=-0.001852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.4420798205793
14.996285932138562 seconds in game passed.
Action: tensor([[[ 0.0031,  0.9403],
         [-0.0037,  0.5358],
         [-0.0054,  0.3479],
         [-0.0031,  0.2551]]])
agent 0 action: VehicleControl(throttle=0.310459, steer=-0.001926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.4420798205793
15.021285932511091 seconds in game passed.
Action: tensor([[[ 0.0031,  0.9403],
         [-0.0037,  0.5358],
         [-0.0054,  0.3479],
         [-0.0031,  0.2551]]])
agent 0 action: VehicleControl(throttle=0.297005, steer=-0.001999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.4420798205793
+++++++++++++: 1.5864008798943663
15.04628593288362 seconds in game passed.
At 15.04628593288362 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0070,  0.9430],
         [-0.0026,  0.5568],
         [-0.0050,  0.3593],
         [-0.0028,  0.2613]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000633, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5864008798943663
Current reward: 0.32103320792066353
Current mitigation activation: 0
#############################
Total reward: 32.763113028499966
15.07128593325615 seconds in game passed.
Action: tensor([[[ 0.0070,  0.9430],
         [-0.0026,  0.5568],
         [-0.0050,  0.3593],
         [-0.0028,  0.2613]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000191, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.763113028499966
15.096285933628678 seconds in game passed.
Action: tensor([[[ 0.0070,  0.9430],
         [-0.0026,  0.5568],
         [-0.0050,  0.3593],
         [-0.0028,  0.2613]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000188, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.763113028499966
15.121285934001207 seconds in game passed.
Action: tensor([[[ 0.0070,  0.9430],
         [-0.0026,  0.5568],
         [-0.0050,  0.3593],
         [-0.0028,  0.2613]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000185, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.763113028499966
+++++++++++++: 1.5701546971368219
15.146285934373736 seconds in game passed.
At 15.146285934373736 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0028,  0.9423],
         [-0.0035,  0.5540],
         [-0.0060,  0.3587],
         [-0.0046,  0.2624]]])
agent 0 action: VehicleControl(throttle=0.225402, steer=-0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5701546971368219
Current reward: 0.3194936542595652
Current mitigation activation: 0
#############################
Total reward: 33.08260668275953
15.171285934746265 seconds in game passed.
Action: tensor([[[ 0.0028,  0.9423],
         [-0.0035,  0.5540],
         [-0.0060,  0.3587],
         [-0.0046,  0.2624]]])
agent 0 action: VehicleControl(throttle=0.209446, steer=-0.001943, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.08260668275953
15.196285935118794 seconds in game passed.
Action: tensor([[[ 0.0028,  0.9423],
         [-0.0035,  0.5540],
         [-0.0060,  0.3587],
         [-0.0046,  0.2624]]])
agent 0 action: VehicleControl(throttle=0.193885, steer=-0.001971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.08260668275953
15.221285935491323 seconds in game passed.
Action: tensor([[[ 0.0028,  0.9423],
         [-0.0035,  0.5540],
         [-0.0060,  0.3587],
         [-0.0046,  0.2624]]])
agent 0 action: VehicleControl(throttle=0.178735, steer=-0.001999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.08260668275953
+++++++++++++: 1.6143842395961188
15.246285935863853 seconds in game passed.
At 15.246285935863853 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0061,  0.9422],
         [-0.0021,  0.5690],
         [-0.0034,  0.3701],
         [-0.0026,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004965, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6143842395961188
Current reward: 0.31103643023366606
Current mitigation activation: 0
#############################
Total reward: 33.393643112993196
15.271285936236382 seconds in game passed.
Action: tensor([[[-0.0061,  0.9422],
         [-0.0021,  0.5690],
         [-0.0034,  0.3701],
         [-0.0026,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.004495, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.393643112993196
15.29628593660891 seconds in game passed.
Action: tensor([[[-0.0061,  0.9422],
         [-0.0021,  0.5690],
         [-0.0034,  0.3701],
         [-0.0026,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.134787, steer=-0.004516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.393643112993196
15.32128593698144 seconds in game passed.
Action: tensor([[[-0.0061,  0.9422],
         [-0.0021,  0.5690],
         [-0.0034,  0.3701],
         [-0.0026,  0.2707]]])
agent 0 action: VehicleControl(throttle=0.121028, steer=-0.004537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.393643112993196
+++++++++++++: 1.6762666972317686
15.346285937353969 seconds in game passed.
At 15.346285937353969 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0038,  0.9448],
         [ 0.0022,  0.5881],
         [ 0.0016,  0.3793],
         [ 0.0018,  0.2777]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000295, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6762666972317686
Current reward: 0.3017850021630019
Current mitigation activation: 0
#############################
Total reward: 33.6954281151562
15.371285937726498 seconds in game passed.
Action: tensor([[[-0.0038,  0.9448],
         [ 0.0022,  0.5881],
         [ 0.0016,  0.3793],
         [ 0.0018,  0.2777]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000928, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.6954281151562
15.396285938099027 seconds in game passed.
Action: tensor([[[-0.0038,  0.9448],
         [ 0.0022,  0.5881],
         [ 0.0016,  0.3793],
         [ 0.0018,  0.2777]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000865, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.6954281151562
15.421285938471556 seconds in game passed.
Action: tensor([[[-0.0038,  0.9448],
         [ 0.0022,  0.5881],
         [ 0.0016,  0.3793],
         [ 0.0018,  0.2777]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.000802, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.6954281151562
+++++++++++++: 1.7616286627170574
15.446285938844085 seconds in game passed.
At 15.446285938844085 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.6878e-03,  9.4275e-01],
         [ 1.3501e-03,  6.0710e-01],
         [ 5.1191e-04,  4.1293e-01],
         [-3.8556e-04,  3.1660e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003769, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7616286627170574
Current reward: 0.29164394402486526
Current mitigation activation: 0
#############################
Total reward: 33.98707205918106
15.471285939216614 seconds in game passed.
Action: tensor([[[-8.6878e-03,  9.4275e-01],
         [ 1.3501e-03,  6.0710e-01],
         [ 5.1191e-04,  4.1293e-01],
         [-3.8556e-04,  3.1660e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003251, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98707205918106
15.496285939589143 seconds in game passed.
Action: tensor([[[-8.6878e-03,  9.4275e-01],
         [ 1.3501e-03,  6.0710e-01],
         [ 5.1191e-04,  4.1293e-01],
         [-3.8556e-04,  3.1660e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003232, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98707205918106
15.521285939961672 seconds in game passed.
Action: tensor([[[-8.6878e-03,  9.4275e-01],
         [ 1.3501e-03,  6.0710e-01],
         [ 5.1191e-04,  4.1293e-01],
         [-3.8556e-04,  3.1660e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.003212, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98707205918106
+++++++++++++: 1.913163460801031
15.5462859403342 seconds in game passed.
At 15.5462859403342 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0187,  0.9428],
         [-0.0052,  0.5735],
         [-0.0044,  0.3702],
         [-0.0035,  0.2700]]])
agent 0 action: VehicleControl(throttle=0.158098, steer=-0.012461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.913163460801031
Current reward: 0.27777091076344107
Current mitigation activation: 0
#############################
Total reward: 34.2648429699445
15.57128594070673 seconds in game passed.
Action: tensor([[[-0.0187,  0.9428],
         [-0.0052,  0.5735],
         [-0.0044,  0.3702],
         [-0.0035,  0.2700]]])
agent 0 action: VehicleControl(throttle=0.227064, steer=-0.011046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.2648429699445
15.596285941079259 seconds in game passed.
Action: tensor([[[-0.0187,  0.9428],
         [-0.0052,  0.5735],
         [-0.0044,  0.3702],
         [-0.0035,  0.2700]]])
agent 0 action: VehicleControl(throttle=0.296676, steer=-0.011154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.2648429699445
15.621285941451788 seconds in game passed.
Action: tensor([[[-0.0187,  0.9428],
         [-0.0052,  0.5735],
         [-0.0044,  0.3702],
         [-0.0035,  0.2700]]])
agent 0 action: VehicleControl(throttle=0.358685, steer=-0.011262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.2648429699445
+++++++++++++: 2.1755676645976876
15.646285941824317 seconds in game passed.
At 15.646285941824317 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0166,  0.9470],
         [-0.0047,  0.6024],
         [-0.0032,  0.3722],
         [-0.0022,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.099825, steer=-0.010242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1755676645976876
Current reward: 0.25971201761529167
Current mitigation activation: 0
#############################
Total reward: 34.524554987559796
15.671285942196846 seconds in game passed.
Action: tensor([[[-0.0166,  0.9470],
         [-0.0047,  0.6024],
         [-0.0032,  0.3722],
         [-0.0022,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.169394, steer=-0.010496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.524554987559796
15.696285942569375 seconds in game passed.
Action: tensor([[[-0.0166,  0.9470],
         [-0.0047,  0.6024],
         [-0.0032,  0.3722],
         [-0.0022,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.199901, steer=-0.010568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.524554987559796
15.721285942941904 seconds in game passed.
Action: tensor([[[-0.0166,  0.9470],
         [-0.0047,  0.6024],
         [-0.0032,  0.3722],
         [-0.0022,  0.2673]]])
agent 0 action: VehicleControl(throttle=0.229609, steer=-0.010640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.524554987559796
+++++++++++++: 2.4132498910017515
15.746285943314433 seconds in game passed.
At 15.746285943314433 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5106e-02,  9.4726e-01],
         [-3.8959e-03,  5.9795e-01],
         [-2.2873e-03,  3.6874e-01],
         [-7.4105e-04,  2.6409e-01]]])
agent 0 action: VehicleControl(throttle=0.307401, steer=-0.009416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4132498910017515
Current reward: 0.24805100327911003
Current mitigation activation: 0
#############################
Total reward: 34.772605990838905
15.771285943686962 seconds in game passed.
Action: tensor([[[-1.5106e-02,  9.4726e-01],
         [-3.8959e-03,  5.9795e-01],
         [-2.2873e-03,  3.6874e-01],
         [-7.4105e-04,  2.6409e-01]]])
agent 0 action: VehicleControl(throttle=0.329113, steer=-0.009720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.772605990838905
15.796285944059491 seconds in game passed.
Action: tensor([[[-1.5106e-02,  9.4726e-01],
         [-3.8959e-03,  5.9795e-01],
         [-2.2873e-03,  3.6874e-01],
         [-7.4105e-04,  2.6409e-01]]])
agent 0 action: VehicleControl(throttle=0.354039, steer=-0.009806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.772605990838905
15.82128594443202 seconds in game passed.
Action: tensor([[[-1.5106e-02,  9.4726e-01],
         [-3.8959e-03,  5.9795e-01],
         [-2.2873e-03,  3.6874e-01],
         [-7.4105e-04,  2.6409e-01]]])
agent 0 action: VehicleControl(throttle=0.376582, steer=-0.009891, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.772605990838905
+++++++++++++: 2.5936010610222495
15.84628594480455 seconds in game passed.
At 15.84628594480455 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2175e-02,  9.4494e-01],
         [-9.0896e-04,  5.6693e-01],
         [-4.4629e-06,  3.5599e-01],
         [ 1.1227e-03,  2.5532e-01]]])
agent 0 action: VehicleControl(throttle=0.746743, steer=-0.006241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5936010610222495
Current reward: 0.24197587908310286
Current mitigation activation: 0
#############################
Total reward: 35.014581869922004
15.871285945177078 seconds in game passed.
Action: tensor([[[-1.2175e-02,  9.4494e-01],
         [-9.0896e-04,  5.6693e-01],
         [-4.4629e-06,  3.5599e-01],
         [ 1.1227e-03,  2.5532e-01]]])
agent 0 action: VehicleControl(throttle=0.732461, steer=-0.006940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.014581869922004
15.896285945549607 seconds in game passed.
Action: tensor([[[-1.2175e-02,  9.4494e-01],
         [-9.0896e-04,  5.6693e-01],
         [-4.4629e-06,  3.5599e-01],
         [ 1.1227e-03,  2.5532e-01]]])
agent 0 action: VehicleControl(throttle=0.752531, steer=-0.007018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.014581869922004
15.921285945922136 seconds in game passed.
Action: tensor([[[-1.2175e-02,  9.4494e-01],
         [-9.0896e-04,  5.6693e-01],
         [-4.4629e-06,  3.5599e-01],
         [ 1.1227e-03,  2.5532e-01]]])
agent 0 action: VehicleControl(throttle=0.768429, steer=-0.007096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.014581869922004
+++++++++++++: 2.72930308842722
15.946285946294665 seconds in game passed.
At 15.946285946294665 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.0031e-03,  9.3473e-01],
         [ 1.2089e-03,  5.1174e-01],
         [-2.0102e-05,  3.3194e-01],
         [ 2.4449e-04,  2.4058e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003001, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.72930308842722
Current reward: 0.23915633011141102
Current mitigation activation: 0
#############################
Total reward: 35.25373820003342
15.971285946667194 seconds in game passed.
Action: tensor([[[-7.0031e-03,  9.3473e-01],
         [ 1.2089e-03,  5.1174e-01],
         [-2.0102e-05,  3.3194e-01],
         [ 2.4449e-04,  2.4058e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.25373820003342
15.996285947039723 seconds in game passed.
Action: tensor([[[-7.0031e-03,  9.3473e-01],
         [ 1.2089e-03,  5.1174e-01],
         [-2.0102e-05,  3.3194e-01],
         [ 2.4449e-04,  2.4058e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.25373820003342
16.021285947412252 seconds in game passed.
Action: tensor([[[-7.0031e-03,  9.3473e-01],
         [ 1.2089e-03,  5.1174e-01],
         [-2.0102e-05,  3.3194e-01],
         [ 2.4449e-04,  2.4058e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.25373820003342
+++++++++++++: 2.7613077693944144
16.04628594778478 seconds in game passed.
At 16.04628594778478 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9375e-04, 9.1016e-01],
         [2.1715e-03, 4.7718e-01],
         [6.9420e-04, 3.1445e-01],
         [7.7324e-04, 2.2876e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7613077693944144
Current reward: 0.24112055384279507
Current mitigation activation: 0
#############################
Total reward: 35.494858753876215
16.07128594815731 seconds in game passed.
Action: tensor([[[1.9375e-04, 9.1016e-01],
         [2.1715e-03, 4.7718e-01],
         [6.9420e-04, 3.1445e-01],
         [7.7324e-04, 2.2876e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.494858753876215
16.09628594852984 seconds in game passed.
Action: tensor([[[1.9375e-04, 9.1016e-01],
         [2.1715e-03, 4.7718e-01],
         [6.9420e-04, 3.1445e-01],
         [7.7324e-04, 2.2876e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.494858753876215
16.12128594890237 seconds in game passed.
Action: tensor([[[1.9375e-04, 9.1016e-01],
         [2.1715e-03, 4.7718e-01],
         [6.9420e-04, 3.1445e-01],
         [7.7324e-04, 2.2876e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000561, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.494858753876215
+++++++++++++: 2.6770540417980224
16.146285949274898 seconds in game passed.
At 16.146285949274898 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8959e-03,  8.9416e-01],
         [ 2.6538e-03,  4.7177e-01],
         [ 3.5683e-04,  3.1671e-01],
         [-3.5264e-05,  2.3356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6770540417980224
Current reward: 0.24794945979167354
Current mitigation activation: 0
#############################
Total reward: 35.74280821366789
16.171285949647427 seconds in game passed.
Action: tensor([[[ 1.8959e-03,  8.9416e-01],
         [ 2.6538e-03,  4.7177e-01],
         [ 3.5683e-04,  3.1671e-01],
         [-3.5264e-05,  2.3356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.74280821366789
16.196285950019956 seconds in game passed.
Action: tensor([[[ 1.8959e-03,  8.9416e-01],
         [ 2.6538e-03,  4.7177e-01],
         [ 3.5683e-04,  3.1671e-01],
         [-3.5264e-05,  2.3356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.74280821366789
16.221285950392485 seconds in game passed.
Action: tensor([[[ 1.8959e-03,  8.9416e-01],
         [ 2.6538e-03,  4.7177e-01],
         [ 3.5683e-04,  3.1671e-01],
         [-3.5264e-05,  2.3356e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.74280821366789
+++++++++++++: 2.5452548987249175
16.246285950765014 seconds in game passed.
At 16.246285950765014 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.4846e-03,  8.8707e-01],
         [ 2.1860e-03,  4.6651e-01],
         [-3.8482e-04,  3.1146e-01],
         [-5.6633e-04,  2.2834e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002867, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5452548987249175
Current reward: 0.25699982751887623
Current mitigation activation: 0
#############################
Total reward: 35.99980804118677
16.271285951137543 seconds in game passed.
Action: tensor([[[ 8.4846e-03,  8.8707e-01],
         [ 2.1860e-03,  4.6651e-01],
         [-3.8482e-04,  3.1146e-01],
         [-5.6633e-04,  2.2834e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.99980804118677
16.29628595151007 seconds in game passed.
Action: tensor([[[ 8.4846e-03,  8.8707e-01],
         [ 2.1860e-03,  4.6651e-01],
         [-3.8482e-04,  3.1146e-01],
         [-5.6633e-04,  2.2834e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.99980804118677
16.3212859518826 seconds in game passed.
Action: tensor([[[ 8.4846e-03,  8.8707e-01],
         [ 2.1860e-03,  4.6651e-01],
         [-3.8482e-04,  3.1146e-01],
         [-5.6633e-04,  2.2834e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.99980804118677
+++++++++++++: 2.5256773375201242
16.34628595225513 seconds in game passed.
At 16.34628595225513 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0123, 0.8792],
         [0.0035, 0.4686],
         [0.0011, 0.3134],
         [0.0009, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5256773375201242
Current reward: 0.2603904607723631
Current mitigation activation: 0
#############################
Total reward: 36.26019850195913
16.37128595262766 seconds in game passed.
Action: tensor([[[0.0123, 0.8792],
         [0.0035, 0.4686],
         [0.0011, 0.3134],
         [0.0009, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.26019850195913
16.396285953000188 seconds in game passed.
Action: tensor([[[0.0123, 0.8792],
         [0.0035, 0.4686],
         [0.0011, 0.3134],
         [0.0009, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.26019850195913
16.421285953372717 seconds in game passed.
Action: tensor([[[0.0123, 0.8792],
         [0.0035, 0.4686],
         [0.0011, 0.3134],
         [0.0009, 0.2290]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.26019850195913
+++++++++++++: 2.5523874350547238
16.446285953745246 seconds in game passed.
At 16.446285953745246 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0130, 0.8933],
         [0.0040, 0.4771],
         [0.0018, 0.3189],
         [0.0017, 0.2326]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5523874350547238
Current reward: 0.2613175936437713
Current mitigation activation: 0
#############################
Total reward: 36.521516095602905
16.471285954117775 seconds in game passed.
Action: tensor([[[0.0130, 0.8933],
         [0.0040, 0.4771],
         [0.0018, 0.3189],
         [0.0017, 0.2326]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.521516095602905
16.496285954490304 seconds in game passed.
Action: tensor([[[0.0130, 0.8933],
         [0.0040, 0.4771],
         [0.0018, 0.3189],
         [0.0017, 0.2326]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.521516095602905
16.521285954862833 seconds in game passed.
Action: tensor([[[0.0130, 0.8933],
         [0.0040, 0.4771],
         [0.0018, 0.3189],
         [0.0017, 0.2326]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.521516095602905
+++++++++++++: 2.5789625617656955
16.546285955235362 seconds in game passed.
At 16.546285955235362 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0156, 0.8893],
         [0.0040, 0.4736],
         [0.0021, 0.3171],
         [0.0021, 0.2327]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5789625617656955
Current reward: 0.2622699078084124
Current mitigation activation: 0
#############################
Total reward: 36.783786003411315
16.57128595560789 seconds in game passed.
Action: tensor([[[0.0156, 0.8893],
         [0.0040, 0.4736],
         [0.0021, 0.3171],
         [0.0021, 0.2327]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.783786003411315
16.59628595598042 seconds in game passed.
Action: tensor([[[0.0156, 0.8893],
         [0.0040, 0.4736],
         [0.0021, 0.3171],
         [0.0021, 0.2327]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007833, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.783786003411315
16.62128595635295 seconds in game passed.
Action: tensor([[[0.0156, 0.8893],
         [0.0040, 0.4736],
         [0.0021, 0.3171],
         [0.0021, 0.2327]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.783786003411315
+++++++++++++: 2.6057033069211246
16.646285956725478 seconds in game passed.
At 16.646285956725478 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0125, 0.8679],
         [0.0047, 0.4603],
         [0.0037, 0.3100],
         [0.0041, 0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6057033069211246
Current reward: 0.2632310090445997
Current mitigation activation: 0
#############################
Total reward: 37.04701701245592
16.671285957098007 seconds in game passed.
Action: tensor([[[0.0125, 0.8679],
         [0.0047, 0.4603],
         [0.0037, 0.3100],
         [0.0041, 0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.007802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.04701701245592
16.696285957470536 seconds in game passed.
Action: tensor([[[0.0125, 0.8679],
         [0.0047, 0.4603],
         [0.0037, 0.3100],
         [0.0041, 0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.04701701245592
16.721285957843065 seconds in game passed.
Action: tensor([[[0.0125, 0.8679],
         [0.0047, 0.4603],
         [0.0037, 0.3100],
         [0.0041, 0.2284]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.008213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.04701701245592
+++++++++++++: 2.6298793326344767
16.746285958215594 seconds in game passed.
At 16.746285958215594 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0238e-02, 8.5285e-01],
         [1.7253e-03, 4.5318e-01],
         [2.8034e-04, 3.0572e-01],
         [2.3956e-04, 2.2612e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6298793326344767
Current reward: 0.26433169598940165
Current mitigation activation: 0
#############################
Total reward: 37.31134870844532
16.771285958588123 seconds in game passed.
Action: tensor([[[1.0238e-02, 8.5285e-01],
         [1.7253e-03, 4.5318e-01],
         [2.8034e-04, 3.0572e-01],
         [2.3956e-04, 2.2612e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.31134870844532
16.796285958960652 seconds in game passed.
Action: tensor([[[1.0238e-02, 8.5285e-01],
         [1.7253e-03, 4.5318e-01],
         [2.8034e-04, 3.0572e-01],
         [2.3956e-04, 2.2612e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006069, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.31134870844532
16.82128595933318 seconds in game passed.
Action: tensor([[[1.0238e-02, 8.5285e-01],
         [1.7253e-03, 4.5318e-01],
         [2.8034e-04, 3.0572e-01],
         [2.3956e-04, 2.2612e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.31134870844532
+++++++++++++: 2.4970597058465884
16.84628595970571 seconds in game passed.
At 16.84628595970571 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.5987e-03,  8.6420e-01],
         [-2.3162e-04,  4.5545e-01],
         [-1.8046e-03,  3.0539e-01],
         [-1.7916e-03,  2.2519e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4970597058465884
Current reward: 0.2733442500955118
Current mitigation activation: 0
#############################
Total reward: 37.584692958540835
16.87128596007824 seconds in game passed.
Action: tensor([[[ 4.5987e-03,  8.6420e-01],
         [-2.3162e-04,  4.5545e-01],
         [-1.8046e-03,  3.0539e-01],
         [-1.7916e-03,  2.2519e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.584692958540835
16.89628596045077 seconds in game passed.
Action: tensor([[[ 4.5987e-03,  8.6420e-01],
         [-2.3162e-04,  4.5545e-01],
         [-1.8046e-03,  3.0539e-01],
         [-1.7916e-03,  2.2519e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.584692958540835
16.921285960823298 seconds in game passed.
Action: tensor([[[ 4.5987e-03,  8.6420e-01],
         [-2.3162e-04,  4.5545e-01],
         [-1.8046e-03,  3.0539e-01],
         [-1.7916e-03,  2.2519e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.584692958540835
+++++++++++++: 2.315022671973848
16.946285961195827 seconds in game passed.
At 16.946285961195827 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.7856e-03,  8.5540e-01],
         [-3.7635e-04,  4.5615e-01],
         [-2.2354e-03,  3.0784e-01],
         [-2.2941e-03,  2.2774e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.315022671973848
Current reward: 0.2855893452178764
Current mitigation activation: 0
#############################
Total reward: 37.870282303758714
16.971285961568356 seconds in game passed.
Action: tensor([[[ 8.7856e-03,  8.5540e-01],
         [-3.7635e-04,  4.5615e-01],
         [-2.2354e-03,  3.0784e-01],
         [-2.2941e-03,  2.2774e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004855, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.870282303758714
16.996285961940885 seconds in game passed.
Action: tensor([[[ 8.7856e-03,  8.5540e-01],
         [-3.7635e-04,  4.5615e-01],
         [-2.2354e-03,  3.0784e-01],
         [-2.2941e-03,  2.2774e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.870282303758714
17.021285962313414 seconds in game passed.
Action: tensor([[[ 8.7856e-03,  8.5540e-01],
         [-3.7635e-04,  4.5615e-01],
         [-2.2354e-03,  3.0784e-01],
         [-2.2941e-03,  2.2774e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.870282303758714
+++++++++++++: 2.1637667251572474
17.046285962685943 seconds in game passed.
At 17.046285962685943 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0062,  0.8439],
         [-0.0018,  0.4441],
         [-0.0039,  0.2973],
         [-0.0043,  0.2194]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1637667251572474
Current reward: 0.29654357501615336
Current mitigation activation: 0
#############################
Total reward: 38.166825878774866
17.07128596305847 seconds in game passed.
Action: tensor([[[ 0.0062,  0.8439],
         [-0.0018,  0.4441],
         [-0.0039,  0.2973],
         [-0.0043,  0.2194]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003131, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.166825878774866
17.096285963431 seconds in game passed.
Action: tensor([[[ 0.0062,  0.8439],
         [-0.0018,  0.4441],
         [-0.0039,  0.2973],
         [-0.0043,  0.2194]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.166825878774866
17.12128596380353 seconds in game passed.
Action: tensor([[[ 0.0062,  0.8439],
         [-0.0018,  0.4441],
         [-0.0039,  0.2973],
         [-0.0043,  0.2194]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.166825878774866
+++++++++++++: 2.0303612731479417
17.14628596417606 seconds in game passed.
At 17.14628596417606 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0090,  0.8557],
         [-0.0017,  0.4467],
         [-0.0040,  0.3000],
         [-0.0040,  0.2218]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0303612731479417
Current reward: 0.30667096163170404
Current mitigation activation: 0
#############################
Total reward: 38.47349684040657
17.171285964548588 seconds in game passed.
Action: tensor([[[ 0.0090,  0.8557],
         [-0.0017,  0.4467],
         [-0.0040,  0.3000],
         [-0.0040,  0.2218]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.47349684040657
17.196285964921117 seconds in game passed.
Action: tensor([[[ 0.0090,  0.8557],
         [-0.0017,  0.4467],
         [-0.0040,  0.3000],
         [-0.0040,  0.2218]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.47349684040657
17.221285965293646 seconds in game passed.
Action: tensor([[[ 0.0090,  0.8557],
         [-0.0017,  0.4467],
         [-0.0040,  0.3000],
         [-0.0040,  0.2218]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.47349684040657
+++++++++++++: 1.9090050947439203
17.246285965666175 seconds in game passed.
At 17.246285965666175 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0020,  0.8702],
         [-0.0035,  0.4496],
         [-0.0054,  0.2998],
         [-0.0053,  0.2210]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9090050947439203
Current reward: 0.3161754590316087
Current mitigation activation: 0
#############################
Total reward: 38.78967229943818
17.271285966038704 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8702],
         [-0.0035,  0.4496],
         [-0.0054,  0.2998],
         [-0.0053,  0.2210]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.78967229943818
17.296285966411233 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8702],
         [-0.0035,  0.4496],
         [-0.0054,  0.2998],
         [-0.0053,  0.2210]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.78967229943818
17.321285966783762 seconds in game passed.
Action: tensor([[[ 0.0020,  0.8702],
         [-0.0035,  0.4496],
         [-0.0054,  0.2998],
         [-0.0053,  0.2210]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.78967229943818
+++++++++++++: 1.7964147973443825
17.34628596715629 seconds in game passed.
At 17.34628596715629 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.8767],
         [-0.0017,  0.4546],
         [-0.0037,  0.3045],
         [-0.0039,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000042, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7964147973443825
Current reward: 0.32517095900805304
Current mitigation activation: 0
#############################
Total reward: 39.114843258446236
17.37128596752882 seconds in game passed.
Action: tensor([[[-0.0020,  0.8767],
         [-0.0017,  0.4546],
         [-0.0037,  0.3045],
         [-0.0039,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.114843258446236
17.39628596790135 seconds in game passed.
Action: tensor([[[-0.0020,  0.8767],
         [-0.0017,  0.4546],
         [-0.0037,  0.3045],
         [-0.0039,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.114843258446236
17.421285968273878 seconds in game passed.
Action: tensor([[[-0.0020,  0.8767],
         [-0.0017,  0.4546],
         [-0.0037,  0.3045],
         [-0.0039,  0.2259]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.114843258446236
+++++++++++++: 1.6911927789254588
17.446285968646407 seconds in game passed.
At 17.446285968646407 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.0764e-03,  8.8909e-01],
         [-2.2858e-04,  4.5986e-01],
         [-2.9786e-03,  3.0738e-01],
         [-3.7552e-03,  2.2746e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6911927789254588
Current reward: 0.33370298672162235
Current mitigation activation: 0
#############################
Total reward: 39.44854624516786
17.471285969018936 seconds in game passed.
Action: tensor([[[-1.0764e-03,  8.8909e-01],
         [-2.2858e-04,  4.5986e-01],
         [-2.9786e-03,  3.0738e-01],
         [-3.7552e-03,  2.2746e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.44854624516786
17.496285969391465 seconds in game passed.
Action: tensor([[[-1.0764e-03,  8.8909e-01],
         [-2.2858e-04,  4.5986e-01],
         [-2.9786e-03,  3.0738e-01],
         [-3.7552e-03,  2.2746e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000721, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.44854624516786
17.521285969763994 seconds in game passed.
Action: tensor([[[-1.0764e-03,  8.8909e-01],
         [-2.2858e-04,  4.5986e-01],
         [-2.9786e-03,  3.0738e-01],
         [-3.7552e-03,  2.2746e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.44854624516786
+++++++++++++: 1.5934828596387818
17.546285970136523 seconds in game passed.
At 17.546285970136523 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.8593e-03,  8.8122e-01],
         [-5.3681e-04,  4.7146e-01],
         [-4.3774e-03,  3.2174e-01],
         [-6.0139e-03,  2.4049e-01]]])
agent 0 action: VehicleControl(throttle=0.714301, steer=0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5934828596387818
Current reward: 0.3418776263752743
Current mitigation activation: 0
#############################
Total reward: 39.79042387154313
17.571285970509052 seconds in game passed.
Action: tensor([[[ 3.8593e-03,  8.8122e-01],
         [-5.3681e-04,  4.7146e-01],
         [-4.3774e-03,  3.2174e-01],
         [-6.0139e-03,  2.4049e-01]]])
agent 0 action: VehicleControl(throttle=0.689406, steer=0.001926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.79042387154313
17.59628597088158 seconds in game passed.
Action: tensor([[[ 3.8593e-03,  8.8122e-01],
         [-5.3681e-04,  4.7146e-01],
         [-4.3774e-03,  3.2174e-01],
         [-6.0139e-03,  2.4049e-01]]])
agent 0 action: VehicleControl(throttle=0.638117, steer=0.001840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.79042387154313
17.62128597125411 seconds in game passed.
Action: tensor([[[ 3.8593e-03,  8.8122e-01],
         [-5.3681e-04,  4.7146e-01],
         [-4.3774e-03,  3.2174e-01],
         [-6.0139e-03,  2.4049e-01]]])
agent 0 action: VehicleControl(throttle=0.588411, steer=0.001755, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.79042387154313
+++++++++++++: 1.5040016368624332
17.64628597162664 seconds in game passed.
At 17.64628597162664 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.5514e-04,  9.0603e-01],
         [ 1.5919e-03,  4.9204e-01],
         [-1.5641e-03,  3.3509e-01],
         [-2.4937e-03,  2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.468250, steer=0.001999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5040016368624332
Current reward: 0.3496565939496185
Current mitigation activation: 0
#############################
Total reward: 40.14008046549275
17.67128597199917 seconds in game passed.
Action: tensor([[[ 6.5514e-04,  9.0603e-01],
         [ 1.5919e-03,  4.9204e-01],
         [-1.5641e-03,  3.3509e-01],
         [-2.4937e-03,  2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.459932, steer=0.001872, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.14008046549275
17.696285972371697 seconds in game passed.
Action: tensor([[[ 6.5514e-04,  9.0603e-01],
         [ 1.5919e-03,  4.9204e-01],
         [-1.5641e-03,  3.3509e-01],
         [-2.4937e-03,  2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.440397, steer=0.001798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.14008046549275
17.721285972744226 seconds in game passed.
Action: tensor([[[ 6.5514e-04,  9.0603e-01],
         [ 1.5919e-03,  4.9204e-01],
         [-1.5641e-03,  3.3509e-01],
         [-2.4937e-03,  2.5087e-01]]])
agent 0 action: VehicleControl(throttle=0.420854, steer=0.001724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.14008046549275
+++++++++++++: 1.431415207349653
17.746285973116755 seconds in game passed.
At 17.746285973116755 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.9961e-04,  9.2707e-01],
         [ 4.6741e-03,  5.1069e-01],
         [ 1.1316e-03,  3.4395e-01],
         [-1.9448e-04,  2.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.400895, steer=0.004023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.431415207349653
Current reward: 0.35568084914251064
Current mitigation activation: 0
#############################
Total reward: 40.49576131463526
17.771285973489285 seconds in game passed.
Action: tensor([[[ 5.9961e-04,  9.2707e-01],
         [ 4.6741e-03,  5.1069e-01],
         [ 1.1316e-03,  3.4395e-01],
         [-1.9448e-04,  2.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.381536, steer=0.003620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49576131463526
17.796285973861814 seconds in game passed.
Action: tensor([[[ 5.9961e-04,  9.2707e-01],
         [ 4.6741e-03,  5.1069e-01],
         [ 1.1316e-03,  3.4395e-01],
         [-1.9448e-04,  2.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.362755, steer=0.003603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49576131463526
17.821285974234343 seconds in game passed.
Action: tensor([[[ 5.9961e-04,  9.2707e-01],
         [ 4.6741e-03,  5.1069e-01],
         [ 1.1316e-03,  3.4395e-01],
         [-1.9448e-04,  2.5341e-01]]])
agent 0 action: VehicleControl(throttle=0.344536, steer=0.003586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49576131463526
+++++++++++++: 1.3820348101268407
17.84628597460687 seconds in game passed.
At 17.84628597460687 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0142, 0.9170],
         [0.0063, 0.4998],
         [0.0038, 0.3367],
         [0.0034, 0.2475]]])
agent 0 action: VehicleControl(throttle=0.326672, steer=0.010500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3820348101268407
Current reward: 0.3586783932787429
Current mitigation activation: 0
#############################
Total reward: 40.854439707914004
17.8712859749794 seconds in game passed.
Action: tensor([[[0.0142, 0.9170],
         [0.0063, 0.4998],
         [0.0038, 0.3367],
         [0.0034, 0.2475]]])
agent 0 action: VehicleControl(throttle=0.309341, steer=0.009456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.854439707914004
17.89628597535193 seconds in game passed.
Action: tensor([[[0.0142, 0.9170],
         [0.0063, 0.4998],
         [0.0038, 0.3367],
         [0.0034, 0.2475]]])
agent 0 action: VehicleControl(throttle=0.292530, steer=0.009549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.854439707914004
17.92128597572446 seconds in game passed.
Action: tensor([[[0.0142, 0.9170],
         [0.0063, 0.4998],
         [0.0038, 0.3367],
         [0.0034, 0.2475]]])
agent 0 action: VehicleControl(throttle=0.276230, steer=0.009643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.854439707914004
+++++++++++++: 1.3520070643239108
17.946285976096988 seconds in game passed.
At 17.946285976096988 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0241, 0.9262],
         [0.0057, 0.5187],
         [0.0013, 0.3486],
         [0.0014, 0.2557]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.013635, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3520070643239108
Current reward: 0.35908378545868463
Current mitigation activation: 0
#############################
Total reward: 41.21352349337269
17.971285976469517 seconds in game passed.
Action: tensor([[[0.0241, 0.9262],
         [0.0057, 0.5187],
         [0.0013, 0.3486],
         [0.0014, 0.2557]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.013106, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.21352349337269
17.996285976842046 seconds in game passed.
Action: tensor([[[0.0241, 0.9262],
         [0.0057, 0.5187],
         [0.0013, 0.3486],
         [0.0014, 0.2557]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.013223, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.21352349337269
18.021285977214575 seconds in game passed.
Action: tensor([[[0.0241, 0.9262],
         [0.0057, 0.5187],
         [0.0013, 0.3486],
         [0.0014, 0.2557]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.013340, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.21352349337269
+++++++++++++: 1.3419445554398723
18.046285977587104 seconds in game passed.
At 18.046285977587104 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0143,  0.9399],
         [-0.0019,  0.5623],
         [-0.0072,  0.3730],
         [-0.0070,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003796, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.3419445554398723
Current reward: 0.3568468819765931
Current mitigation activation: 0
#############################
Total reward: 41.570370375349285
18.071285977959633 seconds in game passed.
Action: tensor([[[ 0.0143,  0.9399],
         [-0.0019,  0.5623],
         [-0.0072,  0.3730],
         [-0.0070,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005433, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.570370375349285
18.096285978332162 seconds in game passed.
Action: tensor([[[ 0.0143,  0.9399],
         [-0.0019,  0.5623],
         [-0.0072,  0.3730],
         [-0.0070,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005473, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.570370375349285
18.12128597870469 seconds in game passed.
Action: tensor([[[ 0.0143,  0.9399],
         [-0.0019,  0.5623],
         [-0.0072,  0.3730],
         [-0.0070,  0.2728]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005513, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.570370375349285
+++++++++++++: 1.38898456121819
18.14628597907722 seconds in game passed.
At 18.14628597907722 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0129,  0.9366],
         [-0.0024,  0.5470],
         [-0.0079,  0.3646],
         [-0.0081,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004459, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.38898456121819
Current reward: 0.34653037159981326
Current mitigation activation: 0
#############################
Total reward: 41.916900746949096
18.17128597944975 seconds in game passed.
Action: tensor([[[ 0.0129,  0.9366],
         [-0.0024,  0.5470],
         [-0.0079,  0.3646],
         [-0.0081,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004654, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.916900746949096
18.196285979822278 seconds in game passed.
Action: tensor([[[ 0.0129,  0.9366],
         [-0.0024,  0.5470],
         [-0.0079,  0.3646],
         [-0.0081,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004670, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.916900746949096
18.221285980194807 seconds in game passed.
Action: tensor([[[ 0.0129,  0.9366],
         [-0.0024,  0.5470],
         [-0.0079,  0.3646],
         [-0.0081,  0.2697]]])
agent 0 action: VehicleControl(throttle=0.110618, steer=0.004686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.916900746949096
+++++++++++++: 1.5162480453977594
18.246285980567336 seconds in game passed.
At 18.246285980567336 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0100,  0.9355],
         [-0.0031,  0.5490],
         [-0.0084,  0.3693],
         [-0.0090,  0.2755]]])
agent 0 action: VehicleControl(throttle=0.098914, steer=0.002942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5162480453977594
Current reward: 0.3277347725164476
Current mitigation activation: 0
#############################
Total reward: 42.24463551946555
18.271285980939865 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9355],
         [-0.0031,  0.5490],
         [-0.0084,  0.3693],
         [-0.0090,  0.2755]]])
agent 0 action: VehicleControl(throttle=0.087668, steer=0.003280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.24463551946555
18.296285981312394 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9355],
         [-0.0031,  0.5490],
         [-0.0084,  0.3693],
         [-0.0090,  0.2755]]])
agent 0 action: VehicleControl(throttle=0.076878, steer=0.003321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.24463551946555
18.321285981684923 seconds in game passed.
Action: tensor([[[ 0.0100,  0.9355],
         [-0.0031,  0.5490],
         [-0.0084,  0.3693],
         [-0.0090,  0.2755]]])
agent 0 action: VehicleControl(throttle=0.066544, steer=0.003362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.24463551946555
+++++++++++++: 1.6777786016702336
18.346285982057452 seconds in game passed.
At 18.346285982057452 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0031,  0.9358],
         [-0.0048,  0.5422],
         [-0.0090,  0.3656],
         [-0.0098,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.057357, steer=-0.000937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6777786016702336
Current reward: 0.31031258209641377
Current mitigation activation: 0
#############################
Total reward: 42.55494810156196
18.37128598242998 seconds in game passed.
Action: tensor([[[ 0.0031,  0.9358],
         [-0.0048,  0.5422],
         [-0.0090,  0.3656],
         [-0.0098,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.048622, steer=-0.000223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.55494810156196
18.39628598280251 seconds in game passed.
Action: tensor([[[ 0.0031,  0.9358],
         [-0.0048,  0.5422],
         [-0.0090,  0.3656],
         [-0.0098,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.040338, steer=-0.000224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.55494810156196
18.42128598317504 seconds in game passed.
Action: tensor([[[ 0.0031,  0.9358],
         [-0.0048,  0.5422],
         [-0.0090,  0.3656],
         [-0.0098,  0.2743]]])
agent 0 action: VehicleControl(throttle=0.032503, steer=-0.000226, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.55494810156196
+++++++++++++: 1.7285144859125516
18.44628598354757 seconds in game passed.
At 18.44628598354757 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0045,  0.9318],
         [-0.0042,  0.5052],
         [-0.0081,  0.3390],
         [-0.0088,  0.2553]]])
agent 0 action: VehicleControl(throttle=0.452635, steer=0.000710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7285144859125516
Current reward: 0.30850416905857636
Current mitigation activation: 0
#############################
Total reward: 42.86345227062054
18.471285983920097 seconds in game passed.
Action: tensor([[[ 0.0045,  0.9318],
         [-0.0042,  0.5052],
         [-0.0081,  0.3390],
         [-0.0088,  0.2553]]])
agent 0 action: VehicleControl(throttle=0.406551, steer=0.000546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.86345227062054
18.496285984292626 seconds in game passed.
Action: tensor([[[ 0.0045,  0.9318],
         [-0.0042,  0.5052],
         [-0.0081,  0.3390],
         [-0.0088,  0.2553]]])
agent 0 action: VehicleControl(throttle=0.406139, steer=0.000538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.86345227062054
18.521285984665155 seconds in game passed.
Action: tensor([[[ 0.0045,  0.9318],
         [-0.0042,  0.5052],
         [-0.0081,  0.3390],
         [-0.0088,  0.2553]]])
agent 0 action: VehicleControl(throttle=0.406241, steer=0.000531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.86345227062054
+++++++++++++: 1.7565702901049949
18.546285985037684 seconds in game passed.
At 18.546285985037684 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0041,  0.9055],
         [-0.0067,  0.4878],
         [-0.0114,  0.3397],
         [-0.0131,  0.2636]]])
agent 0 action: VehicleControl(throttle=0.564769, steer=-0.005032, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7565702901049949
Current reward: 0.3099402337839849
Current mitigation activation: 0
#############################
Total reward: 43.173392504404525
18.571285985410213 seconds in game passed.
Action: tensor([[[-0.0041,  0.9055],
         [-0.0067,  0.4878],
         [-0.0114,  0.3397],
         [-0.0131,  0.2636]]])
agent 0 action: VehicleControl(throttle=0.553876, steer=-0.004202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.173392504404525
18.596285985782743 seconds in game passed.
Action: tensor([[[-0.0041,  0.9055],
         [-0.0067,  0.4878],
         [-0.0114,  0.3397],
         [-0.0131,  0.2636]]])
agent 0 action: VehicleControl(throttle=0.559927, steer=-0.004284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.173392504404525
18.62128598615527 seconds in game passed.
Action: tensor([[[-0.0041,  0.9055],
         [-0.0067,  0.4878],
         [-0.0114,  0.3397],
         [-0.0131,  0.2636]]])
agent 0 action: VehicleControl(throttle=0.566341, steer=-0.004367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.173392504404525
+++++++++++++: 1.7883930608909218
18.6462859865278 seconds in game passed.
At 18.6462859865278 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0060,  0.8806],
         [-0.0140,  0.4713],
         [-0.0194,  0.3236],
         [-0.0209,  0.2473]]])
agent 0 action: VehicleControl(throttle=0.734303, steer=-0.010801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7883930608909218
Current reward: 0.3116029587804183
Current mitigation activation: 0
#############################
Total reward: 43.484995463184944
18.67128598690033 seconds in game passed.
Action: tensor([[[-0.0060,  0.8806],
         [-0.0140,  0.4713],
         [-0.0194,  0.3236],
         [-0.0209,  0.2473]]])
agent 0 action: VehicleControl(throttle=0.726653, steer=-0.009905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.484995463184944
18.69628598727286 seconds in game passed.
Action: tensor([[[-0.0060,  0.8806],
         [-0.0140,  0.4713],
         [-0.0194,  0.3236],
         [-0.0209,  0.2473]]])
agent 0 action: VehicleControl(throttle=0.736109, steer=-0.010057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.484995463184944
18.721285987645388 seconds in game passed.
Action: tensor([[[-0.0060,  0.8806],
         [-0.0140,  0.4713],
         [-0.0194,  0.3236],
         [-0.0209,  0.2473]]])
agent 0 action: VehicleControl(throttle=0.745463, steer=-0.010208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.484995463184944
+++++++++++++: 1.8235854682292185
18.746285988017917 seconds in game passed.
At 18.746285988017917 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0057,  0.8938],
         [-0.0096,  0.4820],
         [-0.0138,  0.3294],
         [-0.0150,  0.2484]]])
agent 0 action: VehicleControl(throttle=0.634328, steer=-0.006926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8235854682292185
Current reward: 0.31351171346503653
Current mitigation activation: 0
#############################
Total reward: 43.798507176649984
18.771285988390446 seconds in game passed.
Action: tensor([[[-0.0057,  0.8938],
         [-0.0096,  0.4820],
         [-0.0138,  0.3294],
         [-0.0150,  0.2484]]])
agent 0 action: VehicleControl(throttle=0.708840, steer=-0.007636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.798507176649984
18.796285988762975 seconds in game passed.
Action: tensor([[[-0.0057,  0.8938],
         [-0.0096,  0.4820],
         [-0.0138,  0.3294],
         [-0.0150,  0.2484]]])
agent 0 action: VehicleControl(throttle=0.787970, steer=-0.007776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.798507176649984
18.821285989135504 seconds in game passed.
Action: tensor([[[-0.0057,  0.8938],
         [-0.0096,  0.4820],
         [-0.0138,  0.3294],
         [-0.0150,  0.2484]]])
agent 0 action: VehicleControl(throttle=0.861122, steer=-0.007916, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.798507176649984
+++++++++++++: 1.957349243146712
18.846285989508033 seconds in game passed.
At 18.846285989508033 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.8739],
         [-0.0131,  0.4568],
         [-0.0181,  0.3099],
         [-0.0198,  0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009413, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.957349243146712
Current reward: 0.30724275188883865
Current mitigation activation: 0
#############################
Total reward: 44.10574992853882
18.871285989880562 seconds in game passed.
Action: tensor([[[-0.0023,  0.8739],
         [-0.0131,  0.4568],
         [-0.0181,  0.3099],
         [-0.0198,  0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.10574992853882
18.89628599025309 seconds in game passed.
Action: tensor([[[-0.0023,  0.8739],
         [-0.0131,  0.4568],
         [-0.0181,  0.3099],
         [-0.0198,  0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.10574992853882
18.92128599062562 seconds in game passed.
Action: tensor([[[-0.0023,  0.8739],
         [-0.0131,  0.4568],
         [-0.0181,  0.3099],
         [-0.0198,  0.2332]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.10574992853882
+++++++++++++: 2.1732948813398445
18.94628599099815 seconds in game passed.
At 18.94628599099815 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0014,  0.8749],
         [-0.0086,  0.4534],
         [-0.0127,  0.3015],
         [-0.0144,  0.2234]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005180, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1732948813398445
Current reward: 0.29721135472725113
Current mitigation activation: 0
#############################
Total reward: 44.40296128326607
18.971285991370678 seconds in game passed.
Action: tensor([[[ 0.0014,  0.8749],
         [-0.0086,  0.4534],
         [-0.0127,  0.3015],
         [-0.0144,  0.2234]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.40296128326607
18.996285991743207 seconds in game passed.
Action: tensor([[[ 0.0014,  0.8749],
         [-0.0086,  0.4534],
         [-0.0127,  0.3015],
         [-0.0144,  0.2234]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006425, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.40296128326607
19.021285992115736 seconds in game passed.
Action: tensor([[[ 0.0014,  0.8749],
         [-0.0086,  0.4534],
         [-0.0127,  0.3015],
         [-0.0144,  0.2234]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.40296128326607
+++++++++++++: 2.285562686952333
19.046285992488265 seconds in game passed.
At 19.046285992488265 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.8224],
         [-0.0118,  0.4324],
         [-0.0157,  0.2899],
         [-0.0171,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.285562686952333
Current reward: 0.2974389486792034
Current mitigation activation: 0
#############################
Total reward: 44.700400231945274
19.071285992860794 seconds in game passed.
Action: tensor([[[-0.0014,  0.8224],
         [-0.0118,  0.4324],
         [-0.0157,  0.2899],
         [-0.0171,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.700400231945274
19.096285993233323 seconds in game passed.
Action: tensor([[[-0.0014,  0.8224],
         [-0.0118,  0.4324],
         [-0.0157,  0.2899],
         [-0.0171,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010001, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.700400231945274
19.121285993605852 seconds in game passed.
Action: tensor([[[-0.0014,  0.8224],
         [-0.0118,  0.4324],
         [-0.0157,  0.2899],
         [-0.0171,  0.2170]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.700400231945274
+++++++++++++: 2.3088700268195455
19.14628599397838 seconds in game passed.
At 19.14628599397838 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.7039e-05,  7.8246e-01],
         [-5.5165e-03,  4.0805e-01],
         [-7.9924e-03,  2.7299e-01],
         [-9.3594e-03,  2.0451e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3088700268195455
Current reward: 0.30437445642463573
Current mitigation activation: 0
#############################
Total reward: 45.004774688369906
19.17128599435091 seconds in game passed.
Action: tensor([[[-4.7039e-05,  7.8246e-01],
         [-5.5165e-03,  4.0805e-01],
         [-7.9924e-03,  2.7299e-01],
         [-9.3594e-03,  2.0451e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.004774688369906
19.19628599472344 seconds in game passed.
Action: tensor([[[-4.7039e-05,  7.8246e-01],
         [-5.5165e-03,  4.0805e-01],
         [-7.9924e-03,  2.7299e-01],
         [-9.3594e-03,  2.0451e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.004774688369906
19.22128599509597 seconds in game passed.
Action: tensor([[[-4.7039e-05,  7.8246e-01],
         [-5.5165e-03,  4.0805e-01],
         [-7.9924e-03,  2.7299e-01],
         [-9.3594e-03,  2.0451e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006051, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.004774688369906
+++++++++++++: 2.2858157730425694
19.246285995468497 seconds in game passed.
At 19.246285995468497 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.7430],
         [-0.0076,  0.4021],
         [-0.0098,  0.2778],
         [-0.0110,  0.2128]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.009208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2858157730425694
Current reward: 0.31462245004041456
Current mitigation activation: 0
#############################
Total reward: 45.319397138410324
19.271285995841026 seconds in game passed.
Action: tensor([[[-0.0039,  0.7430],
         [-0.0076,  0.4021],
         [-0.0098,  0.2778],
         [-0.0110,  0.2128]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008795, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.319397138410324
19.296285996213555 seconds in game passed.
Action: tensor([[[-0.0039,  0.7430],
         [-0.0076,  0.4021],
         [-0.0098,  0.2778],
         [-0.0110,  0.2128]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008892, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.319397138410324
19.321285996586084 seconds in game passed.
Action: tensor([[[-0.0039,  0.7430],
         [-0.0076,  0.4021],
         [-0.0098,  0.2778],
         [-0.0110,  0.2128]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008988, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.319397138410324
+++++++++++++: 2.2423860121097507
19.346285996958613 seconds in game passed.
At 19.346285996958613 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6980],
         [-0.0062,  0.3862],
         [-0.0078,  0.2679],
         [-0.0085,  0.2055]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2423860121097507
Current reward: 0.32642220307530856
Current mitigation activation: 0
#############################
Total reward: 45.645819341485634
19.371285997331142 seconds in game passed.
Action: tensor([[[-0.0011,  0.6980],
         [-0.0062,  0.3862],
         [-0.0078,  0.2679],
         [-0.0085,  0.2055]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.645819341485634
19.39628599770367 seconds in game passed.
Action: tensor([[[-0.0011,  0.6980],
         [-0.0062,  0.3862],
         [-0.0078,  0.2679],
         [-0.0085,  0.2055]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.645819341485634
19.4212859980762 seconds in game passed.
Action: tensor([[[-0.0011,  0.6980],
         [-0.0062,  0.3862],
         [-0.0078,  0.2679],
         [-0.0085,  0.2055]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007226, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.645819341485634
+++++++++++++: 2.1906449963028614
19.44628599844873 seconds in game passed.
At 19.44628599844873 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0014,  0.7027],
         [-0.0030,  0.3857],
         [-0.0043,  0.2656],
         [-0.0051,  0.2025]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1906449963028614
Current reward: 0.3389651377049583
Current mitigation activation: 0
#############################
Total reward: 45.984784479190594
19.47128599882126 seconds in game passed.
Action: tensor([[[ 0.0014,  0.7027],
         [-0.0030,  0.3857],
         [-0.0043,  0.2656],
         [-0.0051,  0.2025]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.984784479190594
19.496285999193788 seconds in game passed.
Action: tensor([[[ 0.0014,  0.7027],
         [-0.0030,  0.3857],
         [-0.0043,  0.2656],
         [-0.0051,  0.2025]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.984784479190594
19.521285999566317 seconds in game passed.
Action: tensor([[[ 0.0014,  0.7027],
         [-0.0030,  0.3857],
         [-0.0043,  0.2656],
         [-0.0051,  0.2025]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.984784479190594
+++++++++++++: 2.136833796769402
19.546285999938846 seconds in game passed.
At 19.546285999938846 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0050,  0.6909],
         [-0.0009,  0.3802],
         [-0.0022,  0.2618],
         [-0.0035,  0.2004]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.136833796769402
Current reward: 0.3517968603617486
Current mitigation activation: 0
#############################
Total reward: 46.336581339552346
19.571286000311375 seconds in game passed.
Action: tensor([[[ 0.0050,  0.6909],
         [-0.0009,  0.3802],
         [-0.0022,  0.2618],
         [-0.0035,  0.2004]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.336581339552346
19.596286000683904 seconds in game passed.
Action: tensor([[[ 0.0050,  0.6909],
         [-0.0009,  0.3802],
         [-0.0022,  0.2618],
         [-0.0035,  0.2004]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001708, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.336581339552346
19.621286001056433 seconds in game passed.
Action: tensor([[[ 0.0050,  0.6909],
         [-0.0009,  0.3802],
         [-0.0022,  0.2618],
         [-0.0035,  0.2004]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.336581339552346
+++++++++++++: 2.0838944422851204
19.64628600142896 seconds in game passed.
At 19.64628600142896 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.3499e-03, 6.6855e-01],
         [2.2610e-04, 3.6497e-01],
         [2.8921e-04, 2.4970e-01],
         [3.4906e-05, 1.9077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0838944422851204
Current reward: 0.3646564932109808
Current mitigation activation: 0
#############################
Total reward: 46.701237832763326
19.67128600180149 seconds in game passed.
Action: tensor([[[4.3499e-03, 6.6855e-01],
         [2.2610e-04, 3.6497e-01],
         [2.8921e-04, 2.4970e-01],
         [3.4906e-05, 1.9077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000840, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.701237832763326
19.69628600217402 seconds in game passed.
Action: tensor([[[4.3499e-03, 6.6855e-01],
         [2.2610e-04, 3.6497e-01],
         [2.8921e-04, 2.4970e-01],
         [3.4906e-05, 1.9077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.701237832763326
19.72128600254655 seconds in game passed.
Action: tensor([[[4.3499e-03, 6.6855e-01],
         [2.2610e-04, 3.6497e-01],
         [2.8921e-04, 2.4970e-01],
         [3.4906e-05, 1.9077e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.701237832763326
+++++++++++++: 2.0331090108816956
19.746286002919078 seconds in game passed.
At 19.746286002919078 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0049, 0.6630],
         [0.0022, 0.3536],
         [0.0018, 0.2420],
         [0.0010, 0.1849]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0331090108816956
Current reward: 0.37739296362348856
Current mitigation activation: 0
#############################
Total reward: 47.07863079638681
19.771286003291607 seconds in game passed.
Action: tensor([[[0.0049, 0.6630],
         [0.0022, 0.3536],
         [0.0018, 0.2420],
         [0.0010, 0.1849]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001071, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.07863079638681
19.796286003664136 seconds in game passed.
Action: tensor([[[0.0049, 0.6630],
         [0.0022, 0.3536],
         [0.0018, 0.2420],
         [0.0010, 0.1849]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.07863079638681
19.821286004036665 seconds in game passed.
Action: tensor([[[0.0049, 0.6630],
         [0.0022, 0.3536],
         [0.0018, 0.2420],
         [0.0010, 0.1849]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.07863079638681
+++++++++++++: 1.9849462398438515
19.846286004409194 seconds in game passed.
At 19.846286004409194 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0042, 0.6460],
         [0.0039, 0.3449],
         [0.0038, 0.2364],
         [0.0030, 0.1811]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9849462398438515
Current reward: 0.38991852778579245
Current mitigation activation: 0
#############################
Total reward: 47.468549324172606
19.871286004781723 seconds in game passed.
Action: tensor([[[0.0042, 0.6460],
         [0.0039, 0.3449],
         [0.0038, 0.2364],
         [0.0030, 0.1811]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.468549324172606
19.896286005154252 seconds in game passed.
Action: tensor([[[0.0042, 0.6460],
         [0.0039, 0.3449],
         [0.0038, 0.2364],
         [0.0030, 0.1811]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.468549324172606
19.92128600552678 seconds in game passed.
Action: tensor([[[0.0042, 0.6460],
         [0.0039, 0.3449],
         [0.0038, 0.2364],
         [0.0030, 0.1811]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.468549324172606
+++++++++++++: 1.9394758560910734
19.94628600589931 seconds in game passed.
At 19.94628600589931 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9922e-03, 6.4733e-01],
         [9.6138e-04, 3.4662e-01],
         [9.5857e-04, 2.3845e-01],
         [4.6354e-04, 1.8294e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9394758560910734
Current reward: 0.40218302928412375
Current mitigation activation: 0
#############################
Total reward: 47.87073235345673
19.97128600627184 seconds in game passed.
Action: tensor([[[1.9922e-03, 6.4733e-01],
         [9.6138e-04, 3.4662e-01],
         [9.5857e-04, 2.3845e-01],
         [4.6354e-04, 1.8294e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.87073235345673
19.996286006644368 seconds in game passed.
Action: tensor([[[1.9922e-03, 6.4733e-01],
         [9.6138e-04, 3.4662e-01],
         [9.5857e-04, 2.3845e-01],
         [4.6354e-04, 1.8294e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.87073235345673
20.021286007016897 seconds in game passed.
Action: tensor([[[1.9922e-03, 6.4733e-01],
         [9.6138e-04, 3.4662e-01],
         [9.5857e-04, 2.3845e-01],
         [4.6354e-04, 1.8294e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.87073235345673
+++++++++++++: 1.8965612452667933
20.046286007389426 seconds in game passed.
At 20.046286007389426 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.3770e-03, 6.4958e-01],
         [1.6939e-03, 3.4777e-01],
         [1.1493e-03, 2.3894e-01],
         [6.2366e-04, 1.8296e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001839, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8965612452667933
Current reward: 0.414153284302762
Current mitigation activation: 0
#############################
Total reward: 48.284885637759494
20.071286007761955 seconds in game passed.
Action: tensor([[[3.3770e-03, 6.4958e-01],
         [1.6939e-03, 3.4777e-01],
         [1.1493e-03, 2.3894e-01],
         [6.2366e-04, 1.8296e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.284885637759494
20.096286008134484 seconds in game passed.
Action: tensor([[[3.3770e-03, 6.4958e-01],
         [1.6939e-03, 3.4777e-01],
         [1.1493e-03, 2.3894e-01],
         [6.2366e-04, 1.8296e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.284885637759494
20.121286008507013 seconds in game passed.
Action: tensor([[[3.3770e-03, 6.4958e-01],
         [1.6939e-03, 3.4777e-01],
         [1.1493e-03, 2.3894e-01],
         [6.2366e-04, 1.8296e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.284885637759494
+++++++++++++: 1.8560230252973842
20.146286008879542 seconds in game passed.
At 20.146286008879542 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6700],
         [-0.0020,  0.3541],
         [-0.0029,  0.2416],
         [-0.0036,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8560230252973842
Current reward: 0.4258128726774445
Current mitigation activation: 0
#############################
Total reward: 48.71069851043694
20.17128600925207 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6700],
         [-0.0020,  0.3541],
         [-0.0029,  0.2416],
         [-0.0036,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.71069851043694
20.1962860096246 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6700],
         [-0.0020,  0.3541],
         [-0.0029,  0.2416],
         [-0.0036,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.71069851043694
20.22128600999713 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6700],
         [-0.0020,  0.3541],
         [-0.0029,  0.2416],
         [-0.0036,  0.1846]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.71069851043694
+++++++++++++: 1.817644184019148
20.24628601036966 seconds in game passed.
At 20.24628601036966 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.6751],
         [-0.0028,  0.3515],
         [-0.0043,  0.2387],
         [-0.0051,  0.1826]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001015, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.817644184019148
Current reward: 0.43715110037663946
Current mitigation activation: 0
#############################
Total reward: 49.14784961081358
20.271286010742188 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6751],
         [-0.0028,  0.3515],
         [-0.0043,  0.2387],
         [-0.0051,  0.1826]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.14784961081358
20.296286011114717 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6751],
         [-0.0028,  0.3515],
         [-0.0043,  0.2387],
         [-0.0051,  0.1826]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000864, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.14784961081358
20.321286011487246 seconds in game passed.
Action: tensor([[[ 0.0021,  0.6751],
         [-0.0028,  0.3515],
         [-0.0043,  0.2387],
         [-0.0051,  0.1826]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.14784961081358
+++++++++++++: 1.8110566858874648
20.346286011859775 seconds in game passed.
At 20.346286011859775 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0007,  0.6755],
         [-0.0022,  0.3498],
         [-0.0029,  0.2374],
         [-0.0031,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8110566858874648
Current reward: 0.4440514045178374
Current mitigation activation: 0
#############################
Total reward: 49.591901015331416
20.371286012232304 seconds in game passed.
Action: tensor([[[-0.0007,  0.6755],
         [-0.0022,  0.3498],
         [-0.0029,  0.2374],
         [-0.0031,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001276, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.591901015331416
20.396286012604833 seconds in game passed.
Action: tensor([[[-0.0007,  0.6755],
         [-0.0022,  0.3498],
         [-0.0029,  0.2374],
         [-0.0031,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.591901015331416
20.42128601297736 seconds in game passed.
Action: tensor([[[-0.0007,  0.6755],
         [-0.0022,  0.3498],
         [-0.0029,  0.2374],
         [-0.0031,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.591901015331416
+++++++++++++: 1.839890412367231
20.44628601334989 seconds in game passed.
At 20.44628601334989 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6627],
         [-0.0015,  0.3441],
         [-0.0020,  0.2340],
         [-0.0022,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000925, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.839890412367231
Current reward: 0.44614383558899695
Current mitigation activation: 0
#############################
Total reward: 50.038044850920414
20.47128601372242 seconds in game passed.
Action: tensor([[[-0.0013,  0.6627],
         [-0.0015,  0.3441],
         [-0.0020,  0.2340],
         [-0.0022,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000973, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.038044850920414
20.49628601409495 seconds in game passed.
Action: tensor([[[-0.0013,  0.6627],
         [-0.0015,  0.3441],
         [-0.0020,  0.2340],
         [-0.0022,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000973, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.038044850920414
20.521286014467478 seconds in game passed.
Action: tensor([[[-0.0013,  0.6627],
         [-0.0015,  0.3441],
         [-0.0020,  0.2340],
         [-0.0022,  0.1794]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000973, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.038044850920414
+++++++++++++: 1.8701587817351772
20.546286014840007 seconds in game passed.
At 20.546286014840007 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6335],
         [0.0016, 0.3381],
         [0.0015, 0.2318],
         [0.0013, 0.1778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8701587817351772
Current reward: 0.4484477460409073
Current mitigation activation: 0
#############################
Total reward: 50.48649259696132
20.571286015212536 seconds in game passed.
Action: tensor([[[0.0020, 0.6335],
         [0.0016, 0.3381],
         [0.0015, 0.2318],
         [0.0013, 0.1778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.48649259696132
20.596286015585065 seconds in game passed.
Action: tensor([[[0.0020, 0.6335],
         [0.0016, 0.3381],
         [0.0015, 0.2318],
         [0.0013, 0.1778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002038, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.48649259696132
20.621286015957594 seconds in game passed.
Action: tensor([[[0.0020, 0.6335],
         [0.0016, 0.3381],
         [0.0015, 0.2318],
         [0.0013, 0.1778]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.48649259696132
+++++++++++++: 1.902213349558899
20.646286016330123 seconds in game passed.
At 20.646286016330123 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0048, 0.6289],
         [0.0023, 0.3401],
         [0.0021, 0.2341],
         [0.0018, 0.1796]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.902213349558899
Current reward: 0.4509080736083959
Current mitigation activation: 0
#############################
Total reward: 50.937400670569716
20.671286016702652 seconds in game passed.
Action: tensor([[[0.0048, 0.6289],
         [0.0023, 0.3401],
         [0.0021, 0.2341],
         [0.0018, 0.1796]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.937400670569716
20.69628601707518 seconds in game passed.
Action: tensor([[[0.0048, 0.6289],
         [0.0023, 0.3401],
         [0.0021, 0.2341],
         [0.0018, 0.1796]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.937400670569716
20.72128601744771 seconds in game passed.
Action: tensor([[[0.0048, 0.6289],
         [0.0023, 0.3401],
         [0.0021, 0.2341],
         [0.0018, 0.1796]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.937400670569716
+++++++++++++: 1.9360360925271414
20.74628601782024 seconds in game passed.
At 20.74628601782024 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0046, 0.6308],
         [0.0023, 0.3404],
         [0.0022, 0.2353],
         [0.0019, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9360360925271414
Current reward: 0.4535218486314286
Current mitigation activation: 0
#############################
Total reward: 51.39092251920115
20.771286018192768 seconds in game passed.
Action: tensor([[[0.0046, 0.6308],
         [0.0023, 0.3404],
         [0.0022, 0.2353],
         [0.0019, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.39092251920115
20.796286018565297 seconds in game passed.
Action: tensor([[[0.0046, 0.6308],
         [0.0023, 0.3404],
         [0.0022, 0.2353],
         [0.0019, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.39092251920115
20.821286018937826 seconds in game passed.
Action: tensor([[[0.0046, 0.6308],
         [0.0023, 0.3404],
         [0.0022, 0.2353],
         [0.0019, 0.1809]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.39092251920115
+++++++++++++: 1.9325667930502082
20.846286019310355 seconds in game passed.
At 20.846286019310355 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0034, 0.6315],
         [0.0008, 0.3346],
         [0.0008, 0.2293],
         [0.0010, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001775, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9325667930502082
Current reward: 0.4612217244612726
Current mitigation activation: 0
#############################
Total reward: 51.85214424366242
20.871286019682884 seconds in game passed.
Action: tensor([[[0.0034, 0.6315],
         [0.0008, 0.3346],
         [0.0008, 0.2293],
         [0.0010, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002011, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.85214424366242
20.896286020055413 seconds in game passed.
Action: tensor([[[0.0034, 0.6315],
         [0.0008, 0.3346],
         [0.0008, 0.2293],
         [0.0010, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.85214424366242
20.921286020427942 seconds in game passed.
Action: tensor([[[0.0034, 0.6315],
         [0.0008, 0.3346],
         [0.0008, 0.2293],
         [0.0010, 0.1756]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.85214424366242
+++++++++++++: 1.866228879140237
20.94628602080047 seconds in game passed.
At 20.94628602080047 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2789e-03,  6.1832e-01],
         [-2.4968e-04,  3.3139e-01],
         [-3.6716e-04,  2.2842e-01],
         [-4.5796e-04,  1.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.866228879140237
Current reward: 0.4773827654875811
Current mitigation activation: 0
#############################
Total reward: 52.329527009150006
20.971286021173 seconds in game passed.
Action: tensor([[[ 2.2789e-03,  6.1832e-01],
         [-2.4968e-04,  3.3139e-01],
         [-3.6716e-04,  2.2842e-01],
         [-4.5796e-04,  1.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.329527009150006
20.99628602154553 seconds in game passed.
Action: tensor([[[ 2.2789e-03,  6.1832e-01],
         [-2.4968e-04,  3.3139e-01],
         [-3.6716e-04,  2.2842e-01],
         [-4.5796e-04,  1.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.329527009150006
21.02128602191806 seconds in game passed.
Action: tensor([[[ 2.2789e-03,  6.1832e-01],
         [-2.4968e-04,  3.3139e-01],
         [-3.6716e-04,  2.2842e-01],
         [-4.5796e-04,  1.7571e-01]]])
agent 0 action: VehicleControl(throttle=0.896811, steer=0.000936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.329527009150006
+++++++++++++: 1.812710694458127
21.046286022290587 seconds in game passed.
At 21.046286022290587 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.6047],
         [-0.0039,  0.3282],
         [-0.0045,  0.2270],
         [-0.0050,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.821740, steer=-0.003389, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.812710694458127
Current reward: 0.4916628012681181
Current mitigation activation: 0
#############################
Total reward: 52.821189810418126
21.071286022663116 seconds in game passed.
Action: tensor([[[-0.0017,  0.6047],
         [-0.0039,  0.3282],
         [-0.0045,  0.2270],
         [-0.0050,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.778901, steer=-0.002742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.821189810418126
21.096286023035645 seconds in game passed.
Action: tensor([[[-0.0017,  0.6047],
         [-0.0039,  0.3282],
         [-0.0045,  0.2270],
         [-0.0050,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.734045, steer=-0.002806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.821189810418126
21.121286023408175 seconds in game passed.
Action: tensor([[[-0.0017,  0.6047],
         [-0.0039,  0.3282],
         [-0.0045,  0.2270],
         [-0.0050,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.690714, steer=-0.002870, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 52.821189810418126
+++++++++++++: 1.7683171801828443
21.146286023780704 seconds in game passed.
At 21.146286023780704 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.6140],
         [-0.0064,  0.3307],
         [-0.0074,  0.2265],
         [-0.0080,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.658499, steer=-0.005262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7683171801828443
Current reward: 0.5044084290740753
Current mitigation activation: 0
#############################
Total reward: 53.3255982394922
21.171286024153233 seconds in game passed.
Action: tensor([[[-0.0030,  0.6140],
         [-0.0064,  0.3307],
         [-0.0074,  0.2265],
         [-0.0080,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.618367, steer=-0.004922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.3255982394922
21.19628602452576 seconds in game passed.
Action: tensor([[[-0.0030,  0.6140],
         [-0.0064,  0.3307],
         [-0.0074,  0.2265],
         [-0.0080,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.581497, steer=-0.004971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.3255982394922
21.22128602489829 seconds in game passed.
Action: tensor([[[-0.0030,  0.6140],
         [-0.0064,  0.3307],
         [-0.0074,  0.2265],
         [-0.0080,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.547012, steer=-0.005021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.3255982394922
+++++++++++++: 1.7344851197212185
21.24628602527082 seconds in game passed.
At 21.24628602527082 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0046,  0.6225],
         [-0.0072,  0.3313],
         [-0.0079,  0.2261],
         [-0.0082,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.579251, steer=-0.006275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7344851197212185
Current reward: 0.5152406573228749
Current mitigation activation: 0
#############################
Total reward: 53.84083889681508
21.27128602564335 seconds in game passed.
Action: tensor([[[-0.0046,  0.6225],
         [-0.0072,  0.3313],
         [-0.0079,  0.2261],
         [-0.0082,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.542188, steer=-0.006137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.84083889681508
21.296286026015878 seconds in game passed.
Action: tensor([[[-0.0046,  0.6225],
         [-0.0072,  0.3313],
         [-0.0079,  0.2261],
         [-0.0082,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.514314, steer=-0.006197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.84083889681508
21.321286026388407 seconds in game passed.
Action: tensor([[[-0.0046,  0.6225],
         [-0.0072,  0.3313],
         [-0.0079,  0.2261],
         [-0.0082,  0.1733]]])
agent 0 action: VehicleControl(throttle=0.488238, steer=-0.006258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.84083889681508
+++++++++++++: 1.714861594995678
21.346286026760936 seconds in game passed.
At 21.346286026760936 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6316],
         [-0.0049,  0.3330],
         [-0.0055,  0.2266],
         [-0.0059,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.493904, steer=-0.003757, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.714861594995678
Current reward: 0.5234374800015196
Current mitigation activation: 0
#############################
Total reward: 54.3642763768166
21.371286027133465 seconds in game passed.
Action: tensor([[[-0.0025,  0.6316],
         [-0.0049,  0.3330],
         [-0.0055,  0.2266],
         [-0.0059,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.468351, steer=-0.004206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.3642763768166
21.396286027505994 seconds in game passed.
Action: tensor([[[-0.0025,  0.6316],
         [-0.0049,  0.3330],
         [-0.0055,  0.2266],
         [-0.0059,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.447997, steer=-0.004233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.3642763768166
21.421286027878523 seconds in game passed.
Action: tensor([[[-0.0025,  0.6316],
         [-0.0049,  0.3330],
         [-0.0055,  0.2266],
         [-0.0059,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.429431, steer=-0.004260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.3642763768166
+++++++++++++: 1.7088074577854766
21.446286028251052 seconds in game passed.
At 21.446286028251052 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6061],
         [0.0020, 0.3283],
         [0.0016, 0.2261],
         [0.0008, 0.1736]]])
agent 0 action: VehicleControl(throttle=0.317854, steer=0.002829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7088074577854766
Current reward: 0.5291087660888566
Current mitigation activation: 0
#############################
Total reward: 54.89338514290545
21.47128602862358 seconds in game passed.
Action: tensor([[[0.0026, 0.6061],
         [0.0020, 0.3283],
         [0.0016, 0.2261],
         [0.0008, 0.1736]]])
agent 0 action: VehicleControl(throttle=0.311104, steer=0.001698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.89338514290545
21.49628602899611 seconds in game passed.
Action: tensor([[[0.0026, 0.6061],
         [0.0020, 0.3283],
         [0.0016, 0.2261],
         [0.0008, 0.1736]]])
agent 0 action: VehicleControl(throttle=0.296537, steer=0.001741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.89338514290545
21.52128602936864 seconds in game passed.
Action: tensor([[[0.0026, 0.6061],
         [0.0020, 0.3283],
         [0.0016, 0.2261],
         [0.0008, 0.1736]]])
agent 0 action: VehicleControl(throttle=0.284754, steer=0.001784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.89338514290545
+++++++++++++: 1.7152502812801582
21.546286029741168 seconds in game passed.
At 21.546286029741168 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6233],
         [0.0027, 0.3356],
         [0.0023, 0.2302],
         [0.0013, 0.1768]]])
agent 0 action: VehicleControl(throttle=0.222614, steer=0.002912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7152502812801582
Current reward: 0.5325548484266067
Current mitigation activation: 0
#############################
Total reward: 55.42593999133206
21.571286030113697 seconds in game passed.
Action: tensor([[[0.0040, 0.6233],
         [0.0027, 0.3356],
         [0.0023, 0.2302],
         [0.0013, 0.1768]]])
agent 0 action: VehicleControl(throttle=0.217041, steer=0.002744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.42593999133206
21.596286030486226 seconds in game passed.
Action: tensor([[[0.0040, 0.6233],
         [0.0027, 0.3356],
         [0.0023, 0.2302],
         [0.0013, 0.1768]]])
agent 0 action: VehicleControl(throttle=0.205964, steer=0.002761, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.42593999133206
21.621286030858755 seconds in game passed.
Action: tensor([[[0.0040, 0.6233],
         [0.0027, 0.3356],
         [0.0023, 0.2302],
         [0.0013, 0.1768]]])
agent 0 action: VehicleControl(throttle=0.194869, steer=0.002778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.42593999133206
+++++++++++++: 1.736237431252515
21.646286031231284 seconds in game passed.
At 21.646286031231284 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6253],
         [0.0023, 0.3354],
         [0.0018, 0.2297],
         [0.0008, 0.1762]]])
agent 0 action: VehicleControl(throttle=0.218390, steer=0.002153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.736237431252515
Current reward: 0.5336063069101742
Current mitigation activation: 0
#############################
Total reward: 55.95954629824223
21.671286031603813 seconds in game passed.
Action: tensor([[[0.0033, 0.6253],
         [0.0023, 0.3354],
         [0.0018, 0.2297],
         [0.0008, 0.1762]]])
agent 0 action: VehicleControl(throttle=0.219303, steer=0.002250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.95954629824223
21.696286031976342 seconds in game passed.
Action: tensor([[[0.0033, 0.6253],
         [0.0023, 0.3354],
         [0.0018, 0.2297],
         [0.0008, 0.1762]]])
agent 0 action: VehicleControl(throttle=0.224193, steer=0.002244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.95954629824223
21.72128603234887 seconds in game passed.
Action: tensor([[[0.0033, 0.6253],
         [0.0023, 0.3354],
         [0.0018, 0.2297],
         [0.0008, 0.1762]]])
agent 0 action: VehicleControl(throttle=0.230360, steer=0.002237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 55.95954629824223
+++++++++++++: 1.7716416986228554
21.7462860327214 seconds in game passed.
At 21.7462860327214 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3739e-03, 6.2066e-01],
         [1.6619e-03, 3.3372e-01],
         [1.4267e-03, 2.2908e-01],
         [5.1384e-04, 1.7590e-01]]])
agent 0 action: VehicleControl(throttle=0.249642, steer=0.000997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.7716416986228554
Current reward: 0.5325964266934637
Current mitigation activation: 0
#############################
Total reward: 56.4921427249357
21.77128603309393 seconds in game passed.
Action: tensor([[[1.3739e-03, 6.2066e-01],
         [1.6619e-03, 3.3372e-01],
         [1.4267e-03, 2.2908e-01],
         [5.1384e-04, 1.7590e-01]]])
agent 0 action: VehicleControl(throttle=0.256582, steer=0.001183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.4921427249357
21.79628603346646 seconds in game passed.
Action: tensor([[[1.3739e-03, 6.2066e-01],
         [1.6619e-03, 3.3372e-01],
         [1.4267e-03, 2.2908e-01],
         [5.1384e-04, 1.7590e-01]]])
agent 0 action: VehicleControl(throttle=0.266226, steer=0.001165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.4921427249357
21.821286033838987 seconds in game passed.
Action: tensor([[[1.3739e-03, 6.2066e-01],
         [1.6619e-03, 3.3372e-01],
         [1.4267e-03, 2.2908e-01],
         [5.1384e-04, 1.7590e-01]]])
agent 0 action: VehicleControl(throttle=0.277010, steer=0.001147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.4921427249357
+++++++++++++: 1.8174583494616587
21.846286034211516 seconds in game passed.
At 21.846286034211516 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6227],
         [-0.0007,  0.3321],
         [-0.0008,  0.2274],
         [-0.0015,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.364623, steer=-0.001704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8174583494616587
Current reward: 0.5305511035738819
Current mitigation activation: 0
#############################
Total reward: 57.02269382850958
21.871286034584045 seconds in game passed.
Action: tensor([[[-0.0014,  0.6227],
         [-0.0007,  0.3321],
         [-0.0008,  0.2274],
         [-0.0015,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.367564, steer=-0.001265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.02269382850958
21.896286034956574 seconds in game passed.
Action: tensor([[[-0.0014,  0.6227],
         [-0.0007,  0.3321],
         [-0.0008,  0.2274],
         [-0.0015,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.379273, steer=-0.001296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.02269382850958
21.921286035329103 seconds in game passed.
Action: tensor([[[-0.0014,  0.6227],
         [-0.0007,  0.3321],
         [-0.0008,  0.2274],
         [-0.0015,  0.1748]]])
agent 0 action: VehicleControl(throttle=0.390777, steer=-0.001327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.02269382850958
+++++++++++++: 1.8687779402173599
21.946286035701632 seconds in game passed.
At 21.946286035701632 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.6169],
         [-0.0016,  0.3313],
         [-0.0022,  0.2268],
         [-0.0031,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.371363, steer=-0.002218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8687779402173599
Current reward: 0.5284873584897092
Current mitigation activation: 0
#############################
Total reward: 57.55118118699929
21.97128603607416 seconds in game passed.
Action: tensor([[[-0.0018,  0.6169],
         [-0.0016,  0.3313],
         [-0.0022,  0.2268],
         [-0.0031,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.385757, steer=-0.002101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55118118699929
21.99628603644669 seconds in game passed.
Action: tensor([[[-0.0018,  0.6169],
         [-0.0016,  0.3313],
         [-0.0022,  0.2268],
         [-0.0031,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.396784, steer=-0.002129, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55118118699929
22.02128603681922 seconds in game passed.
Action: tensor([[[-0.0018,  0.6169],
         [-0.0016,  0.3313],
         [-0.0022,  0.2268],
         [-0.0031,  0.1740]]])
agent 0 action: VehicleControl(throttle=0.407925, steer=-0.002156, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55118118699929
+++++++++++++: 1.920031448008982
22.04628603719175 seconds in game passed.
At 22.04628603719175 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6168],
         [-0.0021,  0.3297],
         [-0.0019,  0.2253],
         [-0.0018,  0.1727]]])
agent 0 action: VehicleControl(throttle=0.477674, steer=-0.002650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.920031448008982
Current reward: 0.5273111957309353
Current mitigation activation: 0
#############################
Total reward: 58.078492382730225
22.071286037564278 seconds in game passed.
Action: tensor([[[-0.0023,  0.6168],
         [-0.0021,  0.3297],
         [-0.0019,  0.2253],
         [-0.0018,  0.1727]]])
agent 0 action: VehicleControl(throttle=0.483534, steer=-0.002554, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.078492382730225
22.096286037936807 seconds in game passed.
Action: tensor([[[-0.0023,  0.6168],
         [-0.0021,  0.3297],
         [-0.0019,  0.2253],
         [-0.0018,  0.1727]]])
agent 0 action: VehicleControl(throttle=0.495272, steer=-0.002542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.078492382730225
22.121286038309336 seconds in game passed.
Action: tensor([[[-0.0023,  0.6168],
         [-0.0021,  0.3297],
         [-0.0019,  0.2253],
         [-0.0018,  0.1727]]])
agent 0 action: VehicleControl(throttle=0.506222, steer=-0.002531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.078492382730225
+++++++++++++: 1.9693542837066642
22.146286038681865 seconds in game passed.
At 22.146286038681865 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.6992e-04, 6.0549e-01],
         [7.0766e-04, 3.2624e-01],
         [1.1222e-03, 2.2324e-01],
         [1.4417e-03, 1.7077e-01]]])
agent 0 action: VehicleControl(throttle=0.521938, steer=0.000631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9693542837066642
Current reward: 0.5271892399650782
Current mitigation activation: 0
#############################
Total reward: 58.6056816226953
22.171286039054394 seconds in game passed.
Action: tensor([[[3.6992e-04, 6.0549e-01],
         [7.0766e-04, 3.2624e-01],
         [1.1222e-03, 2.2324e-01],
         [1.4417e-03, 1.7077e-01]]])
agent 0 action: VehicleControl(throttle=0.530960, steer=0.000184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.6056816226953
22.196286039426923 seconds in game passed.
Action: tensor([[[3.6992e-04, 6.0549e-01],
         [7.0766e-04, 3.2624e-01],
         [1.1222e-03, 2.2324e-01],
         [1.4417e-03, 1.7077e-01]]])
agent 0 action: VehicleControl(throttle=0.539894, steer=0.000252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.6056816226953
22.221286039799452 seconds in game passed.
Action: tensor([[[3.6992e-04, 6.0549e-01],
         [7.0766e-04, 3.2624e-01],
         [1.1222e-03, 2.2324e-01],
         [1.4417e-03, 1.7077e-01]]])
agent 0 action: VehicleControl(throttle=0.548124, steer=0.000320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 58.6056816226953
+++++++++++++: 2.0137346392039888
22.24628604017198 seconds in game passed.
At 22.24628604017198 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0026, 0.6056],
         [0.0031, 0.3265],
         [0.0033, 0.2234],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.547868, steer=0.003102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0137346392039888
Current reward: 0.5284055745182161
Current mitigation activation: 0
#############################
Total reward: 59.13408719721352
22.27128604054451 seconds in game passed.
Action: tensor([[[0.0026, 0.6056],
         [0.0031, 0.3265],
         [0.0033, 0.2234],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.554698, steer=0.002765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.13408719721352
22.29628604091704 seconds in game passed.
Action: tensor([[[0.0026, 0.6056],
         [0.0031, 0.3265],
         [0.0033, 0.2234],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.559260, steer=0.002874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.13408719721352
22.321286041289568 seconds in game passed.
Action: tensor([[[0.0026, 0.6056],
         [0.0031, 0.3265],
         [0.0033, 0.2234],
         [0.0031, 0.1703]]])
agent 0 action: VehicleControl(throttle=0.564417, steer=0.002982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.13408719721352
+++++++++++++: 2.051810506322869
22.346286041662097 seconds in game passed.
At 22.346286041662097 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.6198],
         [0.0027, 0.3306],
         [0.0025, 0.2256],
         [0.0018, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.567722, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.051810506322869
Current reward: 0.5309637566015795
Current mitigation activation: 0
#############################
Total reward: 59.6650509538151
22.371286042034626 seconds in game passed.
Action: tensor([[[0.0016, 0.6198],
         [0.0027, 0.3306],
         [0.0025, 0.2256],
         [0.0018, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.573128, steer=0.002502, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.6650509538151
22.396286042407155 seconds in game passed.
Action: tensor([[[0.0016, 0.6198],
         [0.0027, 0.3306],
         [0.0025, 0.2256],
         [0.0018, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.578511, steer=0.002577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.6650509538151
22.421286042779684 seconds in game passed.
Action: tensor([[[0.0016, 0.6198],
         [0.0027, 0.3306],
         [0.0025, 0.2256],
         [0.0018, 0.1722]]])
agent 0 action: VehicleControl(throttle=0.584037, steer=0.002651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.6650509538151
+++++++++++++: 2.0878201040872475
22.446286043152213 seconds in game passed.
At 22.446286043152213 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0019, 0.6063],
         [0.0029, 0.3252],
         [0.0028, 0.2219],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.648466, steer=0.002977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.0878201040872475
Current reward: 0.5341210491279431
Current mitigation activation: 0
#############################
Total reward: 60.19917200294304
22.471286043524742 seconds in game passed.
Action: tensor([[[0.0019, 0.6063],
         [0.0029, 0.3252],
         [0.0028, 0.2219],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.649757, steer=0.002927, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.19917200294304
22.49628604389727 seconds in game passed.
Action: tensor([[[0.0019, 0.6063],
         [0.0029, 0.3252],
         [0.0028, 0.2219],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.657233, steer=0.002932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.19917200294304
22.5212860442698 seconds in game passed.
Action: tensor([[[0.0019, 0.6063],
         [0.0029, 0.3252],
         [0.0028, 0.2219],
         [0.0021, 0.1695]]])
agent 0 action: VehicleControl(throttle=0.664739, steer=0.002936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.19917200294304
+++++++++++++: 2.124906172471557
22.54628604464233 seconds in game passed.
At 22.54628604464233 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6099],
         [0.0057, 0.3247],
         [0.0060, 0.2207],
         [0.0052, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.727560, steer=0.005107, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.124906172471557
Current reward: 0.5373902032559482
Current mitigation activation: 0
#############################
Total reward: 60.73656220619898
22.57128604501486 seconds in game passed.
Action: tensor([[[0.0022, 0.6099],
         [0.0057, 0.3247],
         [0.0060, 0.2207],
         [0.0052, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.730483, steer=0.004763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.73656220619898
22.596286045387387 seconds in game passed.
Action: tensor([[[0.0022, 0.6099],
         [0.0057, 0.3247],
         [0.0060, 0.2207],
         [0.0052, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.739239, steer=0.004778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.73656220619898
22.621286045759916 seconds in game passed.
Action: tensor([[[0.0022, 0.6099],
         [0.0057, 0.3247],
         [0.0060, 0.2207],
         [0.0052, 0.1689]]])
agent 0 action: VehicleControl(throttle=0.748004, steer=0.004793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.73656220619898
+++++++++++++: 2.1630166247885048
22.646286046132445 seconds in game passed.
At 22.646286046132445 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6222],
         [0.0051, 0.3293],
         [0.0054, 0.2232],
         [0.0043, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.715146, steer=0.004289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.1630166247885048
Current reward: 0.5407650675670551
Current mitigation activation: 0
#############################
Total reward: 61.27732727376604
22.671286046504974 seconds in game passed.
Action: tensor([[[0.0020, 0.6222],
         [0.0051, 0.3293],
         [0.0054, 0.2232],
         [0.0043, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.727344, steer=0.004392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.27732727376604
22.696286046877503 seconds in game passed.
Action: tensor([[[0.0020, 0.6222],
         [0.0051, 0.3293],
         [0.0054, 0.2232],
         [0.0043, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.735011, steer=0.004408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.27732727376604
22.721286047250032 seconds in game passed.
Action: tensor([[[0.0020, 0.6222],
         [0.0051, 0.3293],
         [0.0054, 0.2232],
         [0.0043, 0.1711]]])
agent 0 action: VehicleControl(throttle=0.742511, steer=0.004424, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.27732727376604
+++++++++++++: 2.2020793399572667
22.74628604762256 seconds in game passed.
At 22.74628604762256 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6260],
         [0.0050, 0.3291],
         [0.0050, 0.2229],
         [0.0043, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.795834, steer=0.004886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2020793399572667
Current reward: 0.5442367358586289
Current mitigation activation: 0
#############################
Total reward: 61.821564009624666
22.77128604799509 seconds in game passed.
Action: tensor([[[0.0033, 0.6260],
         [0.0050, 0.3291],
         [0.0050, 0.2229],
         [0.0043, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.798451, steer=0.004848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.821564009624666
22.79628604836762 seconds in game passed.
Action: tensor([[[0.0033, 0.6260],
         [0.0050, 0.3291],
         [0.0050, 0.2229],
         [0.0043, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.794114, steer=0.004881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.821564009624666
22.82128604874015 seconds in game passed.
Action: tensor([[[0.0033, 0.6260],
         [0.0050, 0.3291],
         [0.0050, 0.2229],
         [0.0043, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.781218, steer=0.004915, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.821564009624666
+++++++++++++: 2.2322916830590174
22.846286049112678 seconds in game passed.
At 22.846286049112678 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0066, 0.6329],
         [0.0098, 0.3313],
         [0.0104, 0.2235],
         [0.0096, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.756357, steer=0.009845, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2322916830590174
Current reward: 0.5490150753913299
Current mitigation activation: 0
#############################
Total reward: 62.370579085016
22.871286049485207 seconds in game passed.
Action: tensor([[[0.0066, 0.6329],
         [0.0098, 0.3313],
         [0.0104, 0.2235],
         [0.0096, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.742943, steer=0.009155, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.370579085016
22.896286049857736 seconds in game passed.
Action: tensor([[[0.0066, 0.6329],
         [0.0098, 0.3313],
         [0.0104, 0.2235],
         [0.0096, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.727894, steer=0.009268, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.370579085016
22.921286050230265 seconds in game passed.
Action: tensor([[[0.0066, 0.6329],
         [0.0098, 0.3313],
         [0.0104, 0.2235],
         [0.0096, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.712464, steer=0.009381, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.370579085016
+++++++++++++: 2.2334454553861214
22.946286050602794 seconds in game passed.
At 22.946286050602794 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0108, 0.6437],
         [0.0163, 0.3355],
         [0.0178, 0.2255],
         [0.0169, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.653362, steer=0.016035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2334454553861214
Current reward: 0.5575048867339619
Current mitigation activation: 0
#############################
Total reward: 62.928083971749956
22.971286050975323 seconds in game passed.
Action: tensor([[[0.0108, 0.6437],
         [0.0163, 0.3355],
         [0.0178, 0.2255],
         [0.0169, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.642125, steer=0.015147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.928083971749956
22.99628605134785 seconds in game passed.
Action: tensor([[[0.0108, 0.6437],
         [0.0163, 0.3355],
         [0.0178, 0.2255],
         [0.0169, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.626550, steer=0.015336, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.928083971749956
23.02128605172038 seconds in game passed.
Action: tensor([[[0.0108, 0.6437],
         [0.0163, 0.3355],
         [0.0178, 0.2255],
         [0.0169, 0.1720]]])
agent 0 action: VehicleControl(throttle=0.611330, steer=0.015525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 62.928083971749956
+++++++++++++: 2.2329684468131754
23.04628605209291 seconds in game passed.
At 23.04628605209291 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0072, 0.6269],
         [0.0072, 0.3307],
         [0.0073, 0.2242],
         [0.0066, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.600512, steer=0.007497, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2329684468131754
Current reward: 0.5659606690939555
Current mitigation activation: 0
#############################
Total reward: 63.49404464084391
23.07128605246544 seconds in game passed.
Action: tensor([[[0.0072, 0.6269],
         [0.0072, 0.3307],
         [0.0073, 0.2242],
         [0.0066, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.585129, steer=0.008963, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.49404464084391
23.096286052837968 seconds in game passed.
Action: tensor([[[0.0072, 0.6269],
         [0.0072, 0.3307],
         [0.0073, 0.2242],
         [0.0066, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.570616, steer=0.009073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.49404464084391
23.121286053210497 seconds in game passed.
Action: tensor([[[0.0072, 0.6269],
         [0.0072, 0.3307],
         [0.0073, 0.2242],
         [0.0066, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.556666, steer=0.009183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.49404464084391
+++++++++++++: 2.2366340759944254
23.146286053583026 seconds in game passed.
At 23.146286053583026 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0038, 0.6232],
         [0.0050, 0.3298],
         [0.0050, 0.2237],
         [0.0040, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.539664, steer=0.006310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2366340759944254
Current reward: 0.5736099347169408
Current mitigation activation: 0
#############################
Total reward: 64.06765457556085
23.171286053955555 seconds in game passed.
Action: tensor([[[0.0038, 0.6232],
         [0.0050, 0.3298],
         [0.0050, 0.2237],
         [0.0040, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.527127, steer=0.006844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.06765457556085
23.196286054328084 seconds in game passed.
Action: tensor([[[0.0038, 0.6232],
         [0.0050, 0.3298],
         [0.0050, 0.2237],
         [0.0040, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.514787, steer=0.006891, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.06765457556085
23.221286054700613 seconds in game passed.
Action: tensor([[[0.0038, 0.6232],
         [0.0050, 0.3298],
         [0.0050, 0.2237],
         [0.0040, 0.1705]]])
agent 0 action: VehicleControl(throttle=0.503100, steer=0.006938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.06765457556085
+++++++++++++: 2.2456540530872036
23.246286055073142 seconds in game passed.
At 23.246286055073142 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0043, 0.6193],
         [0.0056, 0.3281],
         [0.0054, 0.2229],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.513770, steer=0.007529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2456540530872036
Current reward: 0.5803107367433307
Current mitigation activation: 0
#############################
Total reward: 64.64796531230418
23.27128605544567 seconds in game passed.
Action: tensor([[[0.0043, 0.6193],
         [0.0056, 0.3281],
         [0.0054, 0.2229],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.501376, steer=0.007460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.64796531230418
23.2962860558182 seconds in game passed.
Action: tensor([[[0.0043, 0.6193],
         [0.0056, 0.3281],
         [0.0054, 0.2229],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.491863, steer=0.007485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.64796531230418
23.32128605619073 seconds in game passed.
Action: tensor([[[0.0043, 0.6193],
         [0.0056, 0.3281],
         [0.0054, 0.2229],
         [0.0045, 0.1702]]])
agent 0 action: VehicleControl(throttle=0.482772, steer=0.007510, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.64796531230418
+++++++++++++: 2.260072152416096
23.346286056563258 seconds in game passed.
At 23.346286056563258 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.6102],
         [0.0043, 0.3251],
         [0.0040, 0.2215],
         [0.0030, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.488797, steer=0.005952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.260072152416096
Current reward: 0.5861066142578948
Current mitigation activation: 0
#############################
Total reward: 65.23407192656208
23.371286056935787 seconds in game passed.
Action: tensor([[[0.0027, 0.6102],
         [0.0043, 0.3251],
         [0.0040, 0.2215],
         [0.0030, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.479263, steer=0.006232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.23407192656208
23.396286057308316 seconds in game passed.
Action: tensor([[[0.0027, 0.6102],
         [0.0043, 0.3251],
         [0.0040, 0.2215],
         [0.0030, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.471676, steer=0.006248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.23407192656208
23.421286057680845 seconds in game passed.
Action: tensor([[[0.0027, 0.6102],
         [0.0043, 0.3251],
         [0.0040, 0.2215],
         [0.0030, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.464415, steer=0.006265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.23407192656208
+++++++++++++: 2.2787337530333613
23.446286058053374 seconds in game passed.
At 23.446286058053374 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.6150e-03, 6.1254e-01],
         [2.1943e-03, 3.2630e-01],
         [1.6600e-03, 2.2227e-01],
         [4.7637e-04, 1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.438610, steer=0.004318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.2787337530333613
Current reward: 0.5912033646850344
Current mitigation activation: 0
#############################
Total reward: 65.82527529124711
23.471286058425903 seconds in game passed.
Action: tensor([[[1.6150e-03, 6.1254e-01],
         [2.1943e-03, 3.2630e-01],
         [1.6600e-03, 2.2227e-01],
         [4.7637e-04, 1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.433139, steer=0.004635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.82527529124711
23.496286058798432 seconds in game passed.
Action: tensor([[[1.6150e-03, 6.1254e-01],
         [2.1943e-03, 3.2630e-01],
         [1.6600e-03, 2.2227e-01],
         [4.7637e-04, 1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.426115, steer=0.004628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.82527529124711
23.52128605917096 seconds in game passed.
Action: tensor([[[1.6150e-03, 6.1254e-01],
         [2.1943e-03, 3.2630e-01],
         [1.6600e-03, 2.2227e-01],
         [4.7637e-04, 1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.419606, steer=0.004621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 65.82527529124711
+++++++++++++: 2.3006820609406167
23.54628605954349 seconds in game passed.
At 23.54628605954349 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6108],
         [0.0023, 0.3255],
         [0.0020, 0.2221],
         [0.0010, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.425124, steer=0.004906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3006820609406167
Current reward: 0.5957731290141874
Current mitigation activation: 0
#############################
Total reward: 66.4210484202613
23.57128605991602 seconds in game passed.
Action: tensor([[[0.0022, 0.6108],
         [0.0023, 0.3255],
         [0.0020, 0.2221],
         [0.0010, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.417740, steer=0.004828, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.4210484202613
23.59628606028855 seconds in game passed.
Action: tensor([[[0.0022, 0.6108],
         [0.0023, 0.3255],
         [0.0020, 0.2221],
         [0.0010, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.412025, steer=0.004802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.4210484202613
23.621286060661077 seconds in game passed.
Action: tensor([[[0.0022, 0.6108],
         [0.0023, 0.3255],
         [0.0020, 0.2221],
         [0.0010, 0.1700]]])
agent 0 action: VehicleControl(throttle=0.406601, steer=0.004776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.4210484202613
+++++++++++++: 2.3261564502323497
23.646286061033607 seconds in game passed.
At 23.646286061033607 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6219],
         [0.0047, 0.3292],
         [0.0047, 0.2238],
         [0.0038, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.379299, steer=0.006977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3261564502323497
Current reward: 0.5998253465033305
Current mitigation activation: 0
#############################
Total reward: 67.02087376676464
23.671286061406136 seconds in game passed.
Action: tensor([[[0.0033, 0.6219],
         [0.0047, 0.3292],
         [0.0047, 0.2238],
         [0.0038, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.377089, steer=0.006613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.02087376676464
23.696286061778665 seconds in game passed.
Action: tensor([[[0.0033, 0.6219],
         [0.0047, 0.3292],
         [0.0047, 0.2238],
         [0.0038, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.372860, steer=0.006615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.02087376676464
23.721286062151194 seconds in game passed.
Action: tensor([[[0.0033, 0.6219],
         [0.0047, 0.3292],
         [0.0047, 0.2238],
         [0.0038, 0.1710]]])
agent 0 action: VehicleControl(throttle=0.369092, steer=0.006617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.02087376676464
+++++++++++++: 2.3547695378264164
23.746286062523723 seconds in game passed.
At 23.746286062523723 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0037, 0.6187],
         [0.0054, 0.3293],
         [0.0056, 0.2239],
         [0.0049, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.331322, steer=0.007229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3547695378264164
Current reward: 0.6034590806058792
Current mitigation activation: 0
#############################
Total reward: 67.62433284737051
23.77128606289625 seconds in game passed.
Action: tensor([[[0.0037, 0.6187],
         [0.0054, 0.3293],
         [0.0056, 0.2239],
         [0.0049, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.331022, steer=0.007132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.62433284737051
23.79628606326878 seconds in game passed.
Action: tensor([[[0.0037, 0.6187],
         [0.0054, 0.3293],
         [0.0056, 0.2239],
         [0.0049, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.327700, steer=0.007136, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.62433284737051
23.82128606364131 seconds in game passed.
Action: tensor([[[0.0037, 0.6187],
         [0.0054, 0.3293],
         [0.0056, 0.2239],
         [0.0049, 0.1707]]])
agent 0 action: VehicleControl(throttle=0.325210, steer=0.007140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.62433284737051
+++++++++++++: 2.3868711784779615
23.84628606401384 seconds in game passed.
At 23.84628606401384 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6064],
         [0.0021, 0.3270],
         [0.0016, 0.2233],
         [0.0006, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.278489, steer=0.004035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3868711784779615
Current reward: 0.606671004880341
Current mitigation activation: 0
#############################
Total reward: 68.23100385225085
23.871286064386368 seconds in game passed.
Action: tensor([[[0.0020, 0.6064],
         [0.0021, 0.3270],
         [0.0016, 0.2233],
         [0.0006, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.281787, steer=0.004462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.23100385225085
23.896286064758897 seconds in game passed.
Action: tensor([[[0.0020, 0.6064],
         [0.0021, 0.3270],
         [0.0016, 0.2233],
         [0.0006, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.281036, steer=0.004384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.23100385225085
23.921286065131426 seconds in game passed.
Action: tensor([[[0.0020, 0.6064],
         [0.0021, 0.3270],
         [0.0016, 0.2233],
         [0.0006, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.281248, steer=0.004306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.23100385225085
+++++++++++++: 2.4232391946905776
23.946286065503955 seconds in game passed.
At 23.946286065503955 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.5668e-04, 6.1599e-01],
         [1.6603e-03, 3.2764e-01],
         [1.3459e-03, 2.2279e-01],
         [3.7827e-04, 1.6946e-01]]])
agent 0 action: VehicleControl(throttle=0.358768, steer=0.003376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4232391946905776
Current reward: 0.6094046191946495
Current mitigation activation: 0
#############################
Total reward: 68.8404084714455
23.971286065876484 seconds in game passed.
Action: tensor([[[8.5668e-04, 6.1599e-01],
         [1.6603e-03, 3.2764e-01],
         [1.3459e-03, 2.2279e-01],
         [3.7827e-04, 1.6946e-01]]])
agent 0 action: VehicleControl(throttle=0.353705, steer=0.003352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.8404084714455
23.996286066249013 seconds in game passed.
Action: tensor([[[8.5668e-04, 6.1599e-01],
         [1.6603e-03, 3.2764e-01],
         [1.3459e-03, 2.2279e-01],
         [3.7827e-04, 1.6946e-01]]])
agent 0 action: VehicleControl(throttle=0.357096, steer=0.003199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.8404084714455
24.021286066621542 seconds in game passed.
Action: tensor([[[8.5668e-04, 6.1599e-01],
         [1.6603e-03, 3.2764e-01],
         [1.3459e-03, 2.2279e-01],
         [3.7827e-04, 1.6946e-01]]])
agent 0 action: VehicleControl(throttle=0.360377, steer=0.003046, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 68.8404084714455
+++++++++++++: 2.46391675261101
24.04628606699407 seconds in game passed.
At 24.04628606699407 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6241],
         [-0.0010,  0.3298],
         [-0.0016,  0.2236],
         [-0.0026,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.368726, steer=-0.000188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.46391675261101
Current reward: 0.611713114639487
Current mitigation activation: 0
#############################
Total reward: 69.45212158608498
24.0712860673666 seconds in game passed.
Action: tensor([[[-0.0022,  0.6241],
         [-0.0010,  0.3298],
         [-0.0016,  0.2236],
         [-0.0026,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.371519, steer=0.000233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.45212158608498
24.09628606773913 seconds in game passed.
Action: tensor([[[-0.0022,  0.6241],
         [-0.0010,  0.3298],
         [-0.0016,  0.2236],
         [-0.0026,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.374849, steer=0.000132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.45212158608498
24.121286068111658 seconds in game passed.
Action: tensor([[[-0.0022,  0.6241],
         [-0.0010,  0.3298],
         [-0.0016,  0.2236],
         [-0.0026,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.378148, steer=0.000031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.45212158608498
+++++++++++++: 2.50496188746331
24.146286068484187 seconds in game passed.
At 24.146286068484187 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.6073],
         [-0.0014,  0.3249],
         [-0.0021,  0.2211],
         [-0.0032,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.385217, steer=-0.000251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.50496188746331
Current reward: 0.6141244785872979
Current mitigation activation: 0
#############################
Total reward: 70.06624606467228
24.171286068856716 seconds in game passed.
Action: tensor([[[-0.0019,  0.6073],
         [-0.0014,  0.3249],
         [-0.0021,  0.2211],
         [-0.0032,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.388147, steer=-0.000289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.06624606467228
24.196286069229245 seconds in game passed.
Action: tensor([[[-0.0019,  0.6073],
         [-0.0014,  0.3249],
         [-0.0021,  0.2211],
         [-0.0032,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.391430, steer=-0.000362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.06624606467228
24.221286069601774 seconds in game passed.
Action: tensor([[[-0.0019,  0.6073],
         [-0.0014,  0.3249],
         [-0.0021,  0.2211],
         [-0.0032,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.394644, steer=-0.000434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.06624606467228
+++++++++++++: 2.5446906628228616
24.246286069974303 seconds in game passed.
At 24.246286069974303 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0026,  0.6147],
         [-0.0029,  0.3279],
         [-0.0032,  0.2231],
         [-0.0038,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.365875, steer=-0.001888, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5446906628228616
Current reward: 0.6168288463575584
Current mitigation activation: 0
#############################
Total reward: 70.68307491102985
24.271286070346832 seconds in game passed.
Action: tensor([[[-0.0026,  0.6147],
         [-0.0029,  0.3279],
         [-0.0032,  0.2231],
         [-0.0038,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.371721, steer=-0.001754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.68307491102985
24.29628607071936 seconds in game passed.
Action: tensor([[[-0.0026,  0.6147],
         [-0.0029,  0.3279],
         [-0.0032,  0.2231],
         [-0.0038,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.374234, steer=-0.001846, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.68307491102985
24.32128607109189 seconds in game passed.
Action: tensor([[[-0.0026,  0.6147],
         [-0.0029,  0.3279],
         [-0.0032,  0.2231],
         [-0.0038,  0.1702]]])
agent 0 action: VehicleControl(throttle=0.376944, steer=-0.001939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.68307491102985
+++++++++++++: 2.5832391490902817
24.34628607146442 seconds in game passed.
At 24.34628607146442 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0007,  0.6070],
         [-0.0014,  0.3262],
         [-0.0015,  0.2222],
         [-0.0019,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.362966, steer=-0.000101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.5832391490902817
Current reward: 0.6197796168151963
Current mitigation activation: 0
#############################
Total reward: 71.30285452784504
24.37128607183695 seconds in game passed.
Action: tensor([[[-0.0007,  0.6070],
         [-0.0014,  0.3262],
         [-0.0015,  0.2222],
         [-0.0019,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.367276, steer=-0.000474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.30285452784504
24.396286072209477 seconds in game passed.
Action: tensor([[[-0.0007,  0.6070],
         [-0.0014,  0.3262],
         [-0.0015,  0.2222],
         [-0.0019,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.369924, steer=-0.000530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.30285452784504
24.421286072582006 seconds in game passed.
Action: tensor([[[-0.0007,  0.6070],
         [-0.0014,  0.3262],
         [-0.0015,  0.2222],
         [-0.0019,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.372748, steer=-0.000587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.30285452784504
+++++++++++++: 2.6218408839910676
24.446286072954535 seconds in game passed.
At 24.446286072954535 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.8046e-05,  6.1348e-01],
         [ 1.2904e-04,  3.2876e-01],
         [-2.1169e-04,  2.2362e-01],
         [-9.3390e-04,  1.7029e-01]]])
agent 0 action: VehicleControl(throttle=0.348463, steer=0.000767, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6218408839910676
Current reward: 0.6228117992376331
Current mitigation activation: 0
#############################
Total reward: 71.92566632708268
24.471286073327065 seconds in game passed.
Action: tensor([[[ 6.8046e-05,  6.1348e-01],
         [ 1.2904e-04,  3.2876e-01],
         [-2.1169e-04,  2.2362e-01],
         [-9.3390e-04,  1.7029e-01]]])
agent 0 action: VehicleControl(throttle=0.354271, steer=0.000516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.92566632708268
24.496286073699594 seconds in game passed.
Action: tensor([[[ 6.8046e-05,  6.1348e-01],
         [ 1.2904e-04,  3.2876e-01],
         [-2.1169e-04,  2.2362e-01],
         [-9.3390e-04,  1.7029e-01]]])
agent 0 action: VehicleControl(throttle=0.357300, steer=0.000494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.92566632708268
24.521286074072123 seconds in game passed.
Action: tensor([[[ 6.8046e-05,  6.1348e-01],
         [ 1.2904e-04,  3.2876e-01],
         [-2.1169e-04,  2.2362e-01],
         [-9.3390e-04,  1.7029e-01]]])
agent 0 action: VehicleControl(throttle=0.360578, steer=0.000472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.92566632708268
+++++++++++++: 2.66115493474352
24.54628607444465 seconds in game passed.
At 24.54628607444465 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.4188e-04,  6.1411e-01],
         [ 4.6715e-04,  3.2867e-01],
         [-2.4319e-04,  2.2364e-01],
         [-1.2784e-03,  1.7008e-01]]])
agent 0 action: VehicleControl(throttle=0.373813, steer=0.000534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.66115493474352
Current reward: 0.6258480517248173
Current mitigation activation: 0
#############################
Total reward: 72.5515143788075
24.57128607481718 seconds in game passed.
Action: tensor([[[-3.4188e-04,  6.1411e-01],
         [ 4.6715e-04,  3.2867e-01],
         [-2.4319e-04,  2.2364e-01],
         [-1.2784e-03,  1.7008e-01]]])
agent 0 action: VehicleControl(throttle=0.376255, steer=0.000495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.5515143788075
24.59628607518971 seconds in game passed.
Action: tensor([[[-3.4188e-04,  6.1411e-01],
         [ 4.6715e-04,  3.2867e-01],
         [-2.4319e-04,  2.2364e-01],
         [-1.2784e-03,  1.7008e-01]]])
agent 0 action: VehicleControl(throttle=0.379783, steer=0.000471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.5515143788075
24.62128607556224 seconds in game passed.
Action: tensor([[[-3.4188e-04,  6.1411e-01],
         [ 4.6715e-04,  3.2867e-01],
         [-2.4319e-04,  2.2364e-01],
         [-1.2784e-03,  1.7008e-01]]])
agent 0 action: VehicleControl(throttle=0.383252, steer=0.000447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 72.5515143788075
+++++++++++++: 2.701452736804833
24.646286075934768 seconds in game passed.
At 24.646286075934768 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.1101e-03,  6.2202e-01],
         [ 1.0271e-03,  3.3000e-01],
         [ 3.9724e-04,  2.2481e-01],
         [-4.0815e-04,  1.7098e-01]]])
agent 0 action: VehicleControl(throttle=0.419835, steer=0.002178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.701452736804833
Current reward: 0.6288580957039362
Current mitigation activation: 0
#############################
Total reward: 73.18037247451143
24.671286076307297 seconds in game passed.
Action: tensor([[[ 3.1101e-03,  6.2202e-01],
         [ 1.0271e-03,  3.3000e-01],
         [ 3.9724e-04,  2.2481e-01],
         [-4.0815e-04,  1.7098e-01]]])
agent 0 action: VehicleControl(throttle=0.420292, steer=0.001856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.18037247451143
24.696286076679826 seconds in game passed.
Action: tensor([[[ 3.1101e-03,  6.2202e-01],
         [ 1.0271e-03,  3.3000e-01],
         [ 3.9724e-04,  2.2481e-01],
         [-4.0815e-04,  1.7098e-01]]])
agent 0 action: VehicleControl(throttle=0.424055, steer=0.001827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.18037247451143
24.721286077052355 seconds in game passed.
Action: tensor([[[ 3.1101e-03,  6.2202e-01],
         [ 1.0271e-03,  3.3000e-01],
         [ 3.9724e-04,  2.2481e-01],
         [-4.0815e-04,  1.7098e-01]]])
agent 0 action: VehicleControl(throttle=0.427422, steer=0.001798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.18037247451143
+++++++++++++: 2.741473090973123
24.746286077424884 seconds in game passed.
At 24.746286077424884 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0012,  0.6179],
         [-0.0008,  0.3279],
         [-0.0011,  0.2235],
         [-0.0014,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.464972, steer=-0.000342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.741473090973123
Current reward: 0.6319851580205043
Current mitigation activation: 0
#############################
Total reward: 73.81235763253193
24.771286077797413 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6179],
         [-0.0008,  0.3279],
         [-0.0011,  0.2235],
         [-0.0014,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.464869, steer=-0.000052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.81235763253193
24.796286078169942 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6179],
         [-0.0008,  0.3279],
         [-0.0011,  0.2235],
         [-0.0014,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.467999, steer=-0.000109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.81235763253193
24.82128607854247 seconds in game passed.
Action: tensor([[[ 0.0012,  0.6179],
         [-0.0008,  0.3279],
         [-0.0011,  0.2235],
         [-0.0014,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.470563, steer=-0.000166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.81235763253193
+++++++++++++: 2.7790336216510725
24.846286078915 seconds in game passed.
At 24.846286078915 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.3006e-04,  6.1448e-01],
         [-2.7345e-03,  3.2741e-01],
         [-3.1328e-03,  2.2340e-01],
         [-3.4698e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.456065, steer=-0.002313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7790336216510725
Current reward: 0.6354483301596905
Current mitigation activation: 0
#############################
Total reward: 74.44780596269162
24.87128607928753 seconds in game passed.
Action: tensor([[[-5.3006e-04,  6.1448e-01],
         [-2.7345e-03,  3.2741e-01],
         [-3.1328e-03,  2.2340e-01],
         [-3.4698e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.459876, steer=-0.002011, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.44780596269162
24.896286079660058 seconds in game passed.
Action: tensor([[[-5.3006e-04,  6.1448e-01],
         [-2.7345e-03,  3.2741e-01],
         [-3.1328e-03,  2.2340e-01],
         [-3.4698e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.461547, steer=-0.002058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.44780596269162
24.921286080032587 seconds in game passed.
Action: tensor([[[-5.3006e-04,  6.1448e-01],
         [-2.7345e-03,  3.2741e-01],
         [-3.1328e-03,  2.2340e-01],
         [-3.4698e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.463000, steer=-0.002105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.44780596269162
+++++++++++++: 2.8129217743501598
24.946286080405116 seconds in game passed.
At 24.946286080405116 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.6239e-04,  6.1360e-01],
         [-2.7663e-03,  3.2746e-01],
         [-3.2888e-03,  2.2276e-01],
         [-3.8236e-03,  1.6888e-01]]])
agent 0 action: VehicleControl(throttle=0.452029, steer=-0.002180, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.8129217743501598
Current reward: 0.6393353934438499
Current mitigation activation: 0
#############################
Total reward: 75.08714135613546
24.971286080777645 seconds in game passed.
Action: tensor([[[-5.6239e-04,  6.1360e-01],
         [-2.7663e-03,  3.2746e-01],
         [-3.2888e-03,  2.2276e-01],
         [-3.8236e-03,  1.6888e-01]]])
agent 0 action: VehicleControl(throttle=0.453253, steer=-0.002214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.08714135613546
24.996286081150174 seconds in game passed.
Action: tensor([[[-5.6239e-04,  6.1360e-01],
         [-2.7663e-03,  3.2746e-01],
         [-3.2888e-03,  2.2276e-01],
         [-3.8236e-03,  1.6888e-01]]])
agent 0 action: VehicleControl(throttle=0.453095, steer=-0.002253, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.08714135613546
25.021286081522703 seconds in game passed.
Action: tensor([[[-5.6239e-04,  6.1360e-01],
         [-2.7663e-03,  3.2746e-01],
         [-3.2888e-03,  2.2276e-01],
         [-3.8236e-03,  1.6888e-01]]])
agent 0 action: VehicleControl(throttle=0.452846, steer=-0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.08714135613546
+++++++++++++: 2.844539986549893
25.046286081895232 seconds in game passed.
At 25.046286081895232 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0046,  0.6121],
         [-0.0067,  0.3274],
         [-0.0074,  0.2227],
         [-0.0080,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.438341, steer=-0.006772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.844539986549893
Current reward: 0.6434589866429874
Current mitigation activation: 0
#############################
Total reward: 75.73060034277844
25.07128608226776 seconds in game passed.
Action: tensor([[[-0.0046,  0.6121],
         [-0.0067,  0.3274],
         [-0.0074,  0.2227],
         [-0.0080,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.439179, steer=-0.006088, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.73060034277844
25.09628608264029 seconds in game passed.
Action: tensor([[[-0.0046,  0.6121],
         [-0.0067,  0.3274],
         [-0.0074,  0.2227],
         [-0.0080,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.438526, steer=-0.006141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.73060034277844
25.12128608301282 seconds in game passed.
Action: tensor([[[-0.0046,  0.6121],
         [-0.0067,  0.3274],
         [-0.0074,  0.2227],
         [-0.0080,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.437890, steer=-0.006194, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 75.73060034277844
+++++++++++++: 2.875501887569623
25.14628608338535 seconds in game passed.
At 25.14628608338535 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.7082e-05, 6.0498e-01],
         [4.4190e-04, 3.2542e-01],
         [9.7556e-04, 2.2202e-01],
         [1.2268e-03, 1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.435431, steer=0.000841, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.875501887569623
Current reward: 0.6476272646461179
Current mitigation activation: 0
#############################
Total reward: 76.37822760742456
25.171286083757877 seconds in game passed.
Action: tensor([[[3.7082e-05, 6.0498e-01],
         [4.4190e-04, 3.2542e-01],
         [9.7556e-04, 2.2202e-01],
         [1.2268e-03, 1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.434951, steer=-0.000306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.37822760742456
25.196286084130406 seconds in game passed.
Action: tensor([[[3.7082e-05, 6.0498e-01],
         [4.4190e-04, 3.2542e-01],
         [9.7556e-04, 2.2202e-01],
         [1.2268e-03, 1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.434292, steer=-0.000283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.37822760742456
25.221286084502935 seconds in game passed.
Action: tensor([[[3.7082e-05, 6.0498e-01],
         [4.4190e-04, 3.2542e-01],
         [9.7556e-04, 2.2202e-01],
         [1.2268e-03, 1.6856e-01]]])
agent 0 action: VehicleControl(throttle=0.433653, steer=-0.000261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.37822760742456
+++++++++++++: 2.906849501227957
25.246286084875464 seconds in game passed.
At 25.246286084875464 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.0522e-04, 6.0476e-01],
         [1.2385e-03, 3.2585e-01],
         [1.5784e-03, 2.2213e-01],
         [1.3837e-03, 1.6854e-01]]])
agent 0 action: VehicleControl(throttle=0.415114, steer=0.000430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.906849501227957
Current reward: 0.6517346687288764
Current mitigation activation: 0
#############################
Total reward: 77.02996227615344
25.271286085247993 seconds in game passed.
Action: tensor([[[2.0522e-04, 6.0476e-01],
         [1.2385e-03, 3.2585e-01],
         [1.5784e-03, 2.2213e-01],
         [1.3837e-03, 1.6854e-01]]])
agent 0 action: VehicleControl(throttle=0.416597, steer=0.000365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.02996227615344
25.296286085620522 seconds in game passed.
Action: tensor([[[2.0522e-04, 6.0476e-01],
         [1.2385e-03, 3.2585e-01],
         [1.5784e-03, 2.2213e-01],
         [1.3837e-03, 1.6854e-01]]])
agent 0 action: VehicleControl(throttle=0.416213, steer=0.000408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.02996227615344
25.32128608599305 seconds in game passed.
Action: tensor([[[2.0522e-04, 6.0476e-01],
         [1.2385e-03, 3.2585e-01],
         [1.5784e-03, 2.2213e-01],
         [1.3837e-03, 1.6854e-01]]])
agent 0 action: VehicleControl(throttle=0.415994, steer=0.000451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.02996227615344
+++++++++++++: 2.9389360060152896
25.34628608636558 seconds in game passed.
At 25.34628608636558 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.7145e-04, 6.0302e-01],
         [1.1069e-03, 3.2515e-01],
         [1.0155e-03, 2.2223e-01],
         [5.6908e-04, 1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.423384, steer=0.000562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9389360060152896
Current reward: 0.655752062326919
Current mitigation activation: 0
#############################
Total reward: 77.68571433848037
25.37128608673811 seconds in game passed.
Action: tensor([[[6.7145e-04, 6.0302e-01],
         [1.1069e-03, 3.2515e-01],
         [1.0155e-03, 2.2223e-01],
         [5.6908e-04, 1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.422847, steer=0.000572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.68571433848037
25.39628608711064 seconds in game passed.
Action: tensor([[[6.7145e-04, 6.0302e-01],
         [1.1069e-03, 3.2515e-01],
         [1.0155e-03, 2.2223e-01],
         [5.6908e-04, 1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.423133, steer=0.000596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.68571433848037
25.421286087483168 seconds in game passed.
Action: tensor([[[6.7145e-04, 6.0302e-01],
         [1.1069e-03, 3.2515e-01],
         [1.0155e-03, 2.2223e-01],
         [5.6908e-04, 1.6851e-01]]])
agent 0 action: VehicleControl(throttle=0.423406, steer=0.000621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.68571433848037
+++++++++++++: 2.9721767765285914
25.446286087855697 seconds in game passed.
At 25.446286087855697 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6081],
         [0.0020, 0.3262],
         [0.0021, 0.2230],
         [0.0017, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.438098, steer=0.001871, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9721767765285914
Current reward: 0.6596388068694766
Current mitigation activation: 0
#############################
Total reward: 78.34535314534985
25.471286088228226 seconds in game passed.
Action: tensor([[[0.0022, 0.6081],
         [0.0020, 0.3262],
         [0.0021, 0.2230],
         [0.0017, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.437312, steer=0.001689, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.34535314534985
25.496286088600755 seconds in game passed.
Action: tensor([[[0.0022, 0.6081],
         [0.0020, 0.3262],
         [0.0021, 0.2230],
         [0.0017, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.437965, steer=0.001712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.34535314534985
25.521286088973284 seconds in game passed.
Action: tensor([[[0.0022, 0.6081],
         [0.0020, 0.3262],
         [0.0021, 0.2230],
         [0.0017, 0.1692]]])
agent 0 action: VehicleControl(throttle=0.438462, steer=0.001735, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 78.34535314534985
+++++++++++++: 3.005895500574512
25.546286089345813 seconds in game passed.
At 25.546286089345813 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.6135],
         [0.0017, 0.3278],
         [0.0019, 0.2234],
         [0.0019, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.438407, steer=0.001725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.005895500574512
Current reward: 0.6634742324115923
Current mitigation activation: 0
#############################
Total reward: 79.00882737776143
25.571286089718342 seconds in game passed.
Action: tensor([[[0.0027, 0.6135],
         [0.0017, 0.3278],
         [0.0019, 0.2234],
         [0.0019, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.438596, steer=0.001751, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.00882737776143
25.59628609009087 seconds in game passed.
Action: tensor([[[0.0027, 0.6135],
         [0.0017, 0.3278],
         [0.0019, 0.2234],
         [0.0019, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.438648, steer=0.001773, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.00882737776143
25.6212860904634 seconds in game passed.
Action: tensor([[[0.0027, 0.6135],
         [0.0017, 0.3278],
         [0.0019, 0.2234],
         [0.0019, 0.1694]]])
agent 0 action: VehicleControl(throttle=0.438609, steer=0.001794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.00882737776143
+++++++++++++: 3.0390684105065073
25.64628609083593 seconds in game passed.
At 25.64628609083593 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.4762e-05,  6.2156e-01],
         [-5.5285e-04,  3.2769e-01],
         [-6.7023e-04,  2.2269e-01],
         [-7.4226e-04,  1.6868e-01]]])
agent 0 action: VehicleControl(throttle=0.524872, steer=-0.000885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.0390684105065073
Current reward: 0.6673584177678529
Current mitigation activation: 0
#############################
Total reward: 79.67618579552929
25.671286091208458 seconds in game passed.
Action: tensor([[[ 5.4762e-05,  6.2156e-01],
         [-5.5285e-04,  3.2769e-01],
         [-6.7023e-04,  2.2269e-01],
         [-7.4226e-04,  1.6868e-01]]])
agent 0 action: VehicleControl(throttle=0.516078, steer=-0.000467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.67618579552929
25.696286091580987 seconds in game passed.
Action: tensor([[[ 5.4762e-05,  6.2156e-01],
         [-5.5285e-04,  3.2769e-01],
         [-6.7023e-04,  2.2269e-01],
         [-7.4226e-04,  1.6868e-01]]])
agent 0 action: VehicleControl(throttle=0.516196, steer=-0.000492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.67618579552929
25.721286091953516 seconds in game passed.
Action: tensor([[[ 5.4762e-05,  6.2156e-01],
         [-5.5285e-04,  3.2769e-01],
         [-6.7023e-04,  2.2269e-01],
         [-7.4226e-04,  1.6868e-01]]])
agent 0 action: VehicleControl(throttle=0.515520, steer=-0.000516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.67618579552929
+++++++++++++: 3.071151023342154
25.746286092326045 seconds in game passed.
At 25.746286092326045 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6127],
         [-0.0031,  0.3258],
         [-0.0034,  0.2223],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.491028, steer=-0.002826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.071151023342154
Current reward: 0.6713238309565113
Current mitigation activation: 0
#############################
Total reward: 80.3475096264858
25.771286092698574 seconds in game passed.
Action: tensor([[[-0.0011,  0.6127],
         [-0.0031,  0.3258],
         [-0.0034,  0.2223],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.491140, steer=-0.002472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.3475096264858
25.796286093071103 seconds in game passed.
Action: tensor([[[-0.0011,  0.6127],
         [-0.0031,  0.3258],
         [-0.0034,  0.2223],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.488515, steer=-0.002498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.3475096264858
25.821286093443632 seconds in game passed.
Action: tensor([[[-0.0011,  0.6127],
         [-0.0031,  0.3258],
         [-0.0034,  0.2223],
         [-0.0035,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.485772, steer=-0.002525, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.3475096264858
+++++++++++++: 3.099170715861238
25.84628609381616 seconds in game passed.
At 25.84628609381616 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0032,  0.6264],
         [-0.0063,  0.3297],
         [-0.0068,  0.2235],
         [-0.0070,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.482622, steer=-0.005786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.099170715861238
Current reward: 0.6755910614609344
Current mitigation activation: 0
#############################
Total reward: 81.02310068794674
25.87128609418869 seconds in game passed.
Action: tensor([[[-0.0032,  0.6264],
         [-0.0063,  0.3297],
         [-0.0068,  0.2235],
         [-0.0070,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.479937, steer=-0.005287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.02310068794674
25.89628609456122 seconds in game passed.
Action: tensor([[[-0.0032,  0.6264],
         [-0.0063,  0.3297],
         [-0.0068,  0.2235],
         [-0.0070,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.477199, steer=-0.005326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.02310068794674
25.92128609493375 seconds in game passed.
Action: tensor([[[-0.0032,  0.6264],
         [-0.0063,  0.3297],
         [-0.0068,  0.2235],
         [-0.0070,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.474436, steer=-0.005364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 81.02310068794674
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [92mSUCCESS[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 18:58:42 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 18:59:29 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 47.0s               │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 24.43s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.52                │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ SUCCESS │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 81.02, average_reward: 81.02310068794674 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_slowdown_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_slowdown_00000/fi_lead_slowdown_data
