New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_logs/routes_fi_route_highway-1127_210112-fi_lead_cutin_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_logs/routes_fi_route_highway-1127_210112-fi_lead_cutin_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_logs/routes_fi_route_highway-1127_210112-fi_lead_cutin_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_logs/routes_fi_route_highway-1127_210112-fi_lead_cutin_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_logs/routes_fi_route_highway-1127_210112-fi_lead_cutin_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_logs/routes_fi_route_highway-1127_210112-fi_lead_cutin_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_data/route_highway.xml_fi_lead_cutin.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key event_trigger_distance's value from 8 to 5.
Replacing key distance_lane_change's value from 11 to 5.
Replacing key speed_lane_change's value from 10 to 5.
Config for LeadCutIn scenario is {'first_vehicle_location': 22, 'first_vehicle_speed': 16, 'event_trigger_distance': 5, 'distance_lane_change': 5, 'speed_lane_change': 5}
1.5488424971699715 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5738424975425005 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.5988424979150295 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6238424982875586 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002719, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6488424986600876 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0015, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.6738424990326166 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0076, 0.6043],
         [0.0046, 0.3283],
         [0.0042, 0.2263],
         [0.0035, 0.1722]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.006065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.6988424994051456 seconds in game passed.
Action: tensor([[[0.0076, 0.6043],
         [0.0046, 0.3283],
         [0.0042, 0.2263],
         [0.0035, 0.1722]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7238424997776747 seconds in game passed.
Action: tensor([[[0.0076, 0.6043],
         [0.0046, 0.3283],
         [0.0042, 0.2263],
         [0.0035, 0.1722]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005656, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7488425001502037 seconds in game passed.
Action: tensor([[[0.0076, 0.6043],
         [0.0046, 0.3283],
         [0.0042, 0.2263],
         [0.0035, 0.1722]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.005722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7738425005227327 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0055, 0.6027],
         [0.0031, 0.3266],
         [0.0027, 0.2244],
         [0.0022, 0.1702]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7988425008952618 seconds in game passed.
Action: tensor([[[0.0055, 0.6027],
         [0.0031, 0.3266],
         [0.0027, 0.2244],
         [0.0022, 0.1702]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8238425012677908 seconds in game passed.
Action: tensor([[[0.0055, 0.6027],
         [0.0031, 0.3266],
         [0.0027, 0.2244],
         [0.0022, 0.1702]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8488425016403198 seconds in game passed.
Action: tensor([[[0.0055, 0.6027],
         [0.0031, 0.3266],
         [0.0027, 0.2244],
         [0.0022, 0.1702]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.004297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8738425020128489 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0045, 0.6033],
         [0.0023, 0.3266],
         [0.0018, 0.2243],
         [0.0013, 0.1700]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.8988425023853779 seconds in game passed.
Action: tensor([[[0.0045, 0.6033],
         [0.0023, 0.3266],
         [0.0018, 0.2243],
         [0.0013, 0.1700]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.923842502757907 seconds in game passed.
Action: tensor([[[0.0045, 0.6033],
         [0.0023, 0.3266],
         [0.0018, 0.2243],
         [0.0013, 0.1700]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.948842503130436 seconds in game passed.
Action: tensor([[[0.0045, 0.6033],
         [0.0023, 0.3266],
         [0.0018, 0.2243],
         [0.0013, 0.1700]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.973842503502965 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0039, 0.6020],
         [0.0022, 0.3259],
         [0.0019, 0.2237],
         [0.0013, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.998842503875494 seconds in game passed.
Action: tensor([[[0.0039, 0.6020],
         [0.0022, 0.3259],
         [0.0019, 0.2237],
         [0.0013, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.023842504248023 seconds in game passed.
Action: tensor([[[0.0039, 0.6020],
         [0.0022, 0.3259],
         [0.0019, 0.2237],
         [0.0013, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003514, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.048842504620552 seconds in game passed.
Action: tensor([[[0.0039, 0.6020],
         [0.0022, 0.3259],
         [0.0019, 0.2237],
         [0.0013, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.073842504993081 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0031, 0.6006],
         [0.0019, 0.3254],
         [0.0015, 0.2234],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002998, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.09884250536561 seconds in game passed.
Action: tensor([[[0.0031, 0.6006],
         [0.0019, 0.3254],
         [0.0015, 0.2234],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.123842505738139 seconds in game passed.
Action: tensor([[[0.0031, 0.6006],
         [0.0019, 0.3254],
         [0.0015, 0.2234],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.148842506110668 seconds in game passed.
Action: tensor([[[0.0031, 0.6006],
         [0.0019, 0.3254],
         [0.0015, 0.2234],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003176, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.173842506483197 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0030, 0.6008],
         [0.0020, 0.3253],
         [0.0016, 0.2232],
         [0.0009, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003182, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.1988425068557262 seconds in game passed.
Action: tensor([[[0.0030, 0.6008],
         [0.0020, 0.3253],
         [0.0016, 0.2232],
         [0.0009, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2238425072282553 seconds in game passed.
Action: tensor([[[0.0030, 0.6008],
         [0.0020, 0.3253],
         [0.0016, 0.2232],
         [0.0009, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2488425076007843 seconds in game passed.
Action: tensor([[[0.0030, 0.6008],
         [0.0020, 0.3253],
         [0.0016, 0.2232],
         [0.0009, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.2738425079733133 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.6008],
         [0.0022, 0.3253],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.2988425083458424 seconds in game passed.
Action: tensor([[[0.0028, 0.6008],
         [0.0022, 0.3253],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003405, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3238425087183714 seconds in game passed.
Action: tensor([[[0.0028, 0.6008],
         [0.0022, 0.3253],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3488425090909004 seconds in game passed.
Action: tensor([[[0.0028, 0.6008],
         [0.0022, 0.3253],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.3738425094634295 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.6020],
         [0.0022, 0.3256],
         [0.0018, 0.2232],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.3988425098359585 seconds in game passed.
Action: tensor([[[0.0028, 0.6020],
         [0.0022, 0.3256],
         [0.0018, 0.2232],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4238425102084875 seconds in game passed.
Action: tensor([[[0.0028, 0.6020],
         [0.0022, 0.3256],
         [0.0018, 0.2232],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4488425105810165 seconds in game passed.
Action: tensor([[[0.0028, 0.6020],
         [0.0022, 0.3256],
         [0.0018, 0.2232],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.4738425109535456 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0025, 0.6023],
         [0.0022, 0.3259],
         [0.0018, 0.2234],
         [0.0010, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4988425113260746 seconds in game passed.
Action: tensor([[[0.0025, 0.6023],
         [0.0022, 0.3259],
         [0.0018, 0.2234],
         [0.0010, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5238425116986036 seconds in game passed.
Action: tensor([[[0.0025, 0.6023],
         [0.0022, 0.3259],
         [0.0018, 0.2234],
         [0.0010, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003572, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5488425120711327 seconds in game passed.
Action: tensor([[[0.0025, 0.6023],
         [0.0022, 0.3259],
         [0.0018, 0.2234],
         [0.0010, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5738425124436617 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0024, 0.6032],
         [0.0020, 0.3260],
         [0.0016, 0.2234],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5988425128161907 seconds in game passed.
Action: tensor([[[0.0024, 0.6032],
         [0.0020, 0.3260],
         [0.0016, 0.2234],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6238425131887197 seconds in game passed.
Action: tensor([[[0.0024, 0.6032],
         [0.0020, 0.3260],
         [0.0016, 0.2234],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.648842513561249 seconds in game passed.
Action: tensor([[[0.0024, 0.6032],
         [0.0020, 0.3260],
         [0.0016, 0.2234],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.673842513933778 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.6031],
         [0.0021, 0.3261],
         [0.0018, 0.2234],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.698842514306307 seconds in game passed.
Action: tensor([[[0.0021, 0.6031],
         [0.0021, 0.3261],
         [0.0018, 0.2234],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003269, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.723842514678836 seconds in game passed.
Action: tensor([[[0.0021, 0.6031],
         [0.0021, 0.3261],
         [0.0018, 0.2234],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003228, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.748842515051365 seconds in game passed.
Action: tensor([[[0.0021, 0.6031],
         [0.0021, 0.3261],
         [0.0018, 0.2234],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.773842515423894 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.6030],
         [0.0020, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003030, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.798842515796423 seconds in game passed.
Action: tensor([[[0.0020, 0.6030],
         [0.0020, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003029, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.823842516168952 seconds in game passed.
Action: tensor([[[0.0020, 0.6030],
         [0.0020, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.848842516541481 seconds in game passed.
Action: tensor([[[0.0020, 0.6030],
         [0.0020, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002984, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.87384251691401 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.6026],
         [0.0021, 0.3260],
         [0.0018, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.898842517286539 seconds in game passed.
Action: tensor([[[0.0019, 0.6026],
         [0.0021, 0.3260],
         [0.0018, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002995, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.923842517659068 seconds in game passed.
Action: tensor([[[0.0019, 0.6026],
         [0.0021, 0.3260],
         [0.0018, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.948842518031597 seconds in game passed.
Action: tensor([[[0.0019, 0.6026],
         [0.0021, 0.3260],
         [0.0018, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.973842518404126 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.6017],
         [0.0021, 0.3256],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.998842518776655 seconds in game passed.
Action: tensor([[[0.0019, 0.6017],
         [0.0021, 0.3256],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0238425191491842 seconds in game passed.
Action: tensor([[[0.0019, 0.6017],
         [0.0021, 0.3256],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0488425195217133 seconds in game passed.
Action: tensor([[[0.0019, 0.6017],
         [0.0021, 0.3256],
         [0.0018, 0.2231],
         [0.0010, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.0738425198942423 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.6019],
         [0.0021, 0.3257],
         [0.0018, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002863, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.0988425202667713 seconds in game passed.
Action: tensor([[[0.0017, 0.6019],
         [0.0021, 0.3257],
         [0.0018, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1238425206393003 seconds in game passed.
Action: tensor([[[0.0017, 0.6019],
         [0.0021, 0.3257],
         [0.0018, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1488425210118294 seconds in game passed.
Action: tensor([[[0.0017, 0.6019],
         [0.0021, 0.3257],
         [0.0018, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002858, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.1738425213843584 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.6024],
         [0.0019, 0.3259],
         [0.0016, 0.2233],
         [0.0007, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.1988425217568874 seconds in game passed.
Action: tensor([[[0.0018, 0.6024],
         [0.0019, 0.3259],
         [0.0016, 0.2233],
         [0.0007, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2238425221294165 seconds in game passed.
Action: tensor([[[0.0018, 0.6024],
         [0.0019, 0.3259],
         [0.0016, 0.2233],
         [0.0007, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2488425225019455 seconds in game passed.
Action: tensor([[[0.0018, 0.6024],
         [0.0019, 0.3259],
         [0.0016, 0.2233],
         [0.0007, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.2738425228744745 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.6017],
         [0.0021, 0.3258],
         [0.0019, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002897, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.2988425232470036 seconds in game passed.
Action: tensor([[[0.0017, 0.6017],
         [0.0021, 0.3258],
         [0.0019, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3238425236195326 seconds in game passed.
Action: tensor([[[0.0017, 0.6017],
         [0.0021, 0.3258],
         [0.0019, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3488425239920616 seconds in game passed.
Action: tensor([[[0.0017, 0.6017],
         [0.0021, 0.3258],
         [0.0019, 0.2232],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3738425243645906 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.6027],
         [0.0019, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3988425247371197 seconds in game passed.
Action: tensor([[[0.0017, 0.6027],
         [0.0019, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4238425251096487 seconds in game passed.
Action: tensor([[[0.0017, 0.6027],
         [0.0019, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4488425254821777 seconds in game passed.
Action: tensor([[[0.0017, 0.6027],
         [0.0019, 0.3260],
         [0.0016, 0.2233],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4738425258547068 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0015, 0.6021],
         [0.0019, 0.3260],
         [0.0017, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.498842526227236 seconds in game passed.
Action: tensor([[[0.0015, 0.6021],
         [0.0019, 0.3260],
         [0.0017, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.523842526599765 seconds in game passed.
Action: tensor([[[0.0015, 0.6021],
         [0.0019, 0.3260],
         [0.0017, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.548842526972294 seconds in game passed.
Action: tensor([[[0.0015, 0.6021],
         [0.0019, 0.3260],
         [0.0017, 0.2233],
         [0.0009, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002610, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.573842527344823 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.6029],
         [0.0019, 0.3261],
         [0.0017, 0.2233],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.598842527717352 seconds in game passed.
Action: tensor([[[0.0017, 0.6029],
         [0.0019, 0.3261],
         [0.0017, 0.2233],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.623842528089881 seconds in game passed.
Action: tensor([[[0.0017, 0.6029],
         [0.0019, 0.3261],
         [0.0017, 0.2233],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002650, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.64884252846241 seconds in game passed.
Action: tensor([[[0.0017, 0.6029],
         [0.0019, 0.3261],
         [0.0017, 0.2233],
         [0.0008, 0.1694]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.673842528834939 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.6013],
         [0.0021, 0.3257],
         [0.0019, 0.2231],
         [0.0011, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.698842529207468 seconds in game passed.
Action: tensor([[[0.0017, 0.6013],
         [0.0021, 0.3257],
         [0.0019, 0.2231],
         [0.0011, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.723842529579997 seconds in game passed.
Action: tensor([[[0.0017, 0.6013],
         [0.0021, 0.3257],
         [0.0019, 0.2231],
         [0.0011, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002758, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.748842529952526 seconds in game passed.
Action: tensor([[[0.0017, 0.6013],
         [0.0021, 0.3257],
         [0.0019, 0.2231],
         [0.0011, 0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.773842530325055 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.6024],
         [0.0019, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002551, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.798842530697584 seconds in game passed.
Action: tensor([[[0.0016, 0.6024],
         [0.0019, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.823842531070113 seconds in game passed.
Action: tensor([[[0.0016, 0.6024],
         [0.0019, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002580, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.848842531442642 seconds in game passed.
Action: tensor([[[0.0016, 0.6024],
         [0.0019, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8738425318151712 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.6018],
         [0.0021, 0.3259],
         [0.0019, 0.2233],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8988425321877003 seconds in game passed.
Action: tensor([[[0.0016, 0.6018],
         [0.0021, 0.3259],
         [0.0019, 0.2233],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9238425325602293 seconds in game passed.
Action: tensor([[[0.0016, 0.6018],
         [0.0021, 0.3259],
         [0.0019, 0.2233],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002678, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9488425329327583 seconds in game passed.
Action: tensor([[[0.0016, 0.6018],
         [0.0021, 0.3259],
         [0.0019, 0.2233],
         [0.0010, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 45.56455083942705
3.9738425333052874 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.6021],
         [0.0020, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602289529110478
Current mitigation activation: 0
#############################
Total reward: 0
3.9988425336778164 seconds in game passed.
Action: tensor([[[0.0019, 0.6021],
         [0.0020, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002716, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.023842534050345 seconds in game passed.
Action: tensor([[[0.0019, 0.6021],
         [0.0020, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.0488425344228745 seconds in game passed.
Action: tensor([[[0.0019, 0.6021],
         [0.0020, 0.3259],
         [0.0017, 0.2232],
         [0.0008, 0.1693]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 12.089990940274568
4.0738425347954035 seconds in game passed.
At 4.0738425347954035 seconds, saving state-action tuples.
Action: tensor([[[1.4333e-03, 6.0329e-01],
         [1.4171e-03, 3.2593e-01],
         [1.1646e-03, 2.2309e-01],
         [4.3422e-04, 1.6922e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.24851657571039604
Current mitigation activation: 0
#############################
Total reward: 0.24851657571039604
4.0988425351679325 seconds in game passed.
Action: tensor([[[1.4333e-03, 6.0329e-01],
         [1.4171e-03, 3.2593e-01],
         [1.1646e-03, 2.2309e-01],
         [4.3422e-04, 1.6922e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.24851657571039604
4.1238425355404615 seconds in game passed.
Action: tensor([[[1.4333e-03, 6.0329e-01],
         [1.4171e-03, 3.2593e-01],
         [1.1646e-03, 2.2309e-01],
         [4.3422e-04, 1.6922e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.24851657571039604
4.148842535912991 seconds in game passed.
Action: tensor([[[1.4333e-03, 6.0329e-01],
         [1.4171e-03, 3.2593e-01],
         [1.1646e-03, 2.2309e-01],
         [4.3422e-04, 1.6922e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.24851657571039604
+++++++++++++: 7.359844037372008
4.17384253628552 seconds in game passed.
At 4.17384253628552 seconds, saving state-action tuples.
Action: tensor([[[0.0021, 0.6033],
         [0.0015, 0.3261],
         [0.0015, 0.2231],
         [0.0011, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002493, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 7.359844037372008
Current reward: 0.3233872050710598
Current mitigation activation: 0
#############################
Total reward: 0.5719037807814558
4.198842536658049 seconds in game passed.
Action: tensor([[[0.0021, 0.6033],
         [0.0015, 0.3261],
         [0.0015, 0.2231],
         [0.0011, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.5719037807814558
4.223842537030578 seconds in game passed.
Action: tensor([[[0.0021, 0.6033],
         [0.0015, 0.3261],
         [0.0015, 0.2231],
         [0.0011, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002440, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.5719037807814558
4.248842537403107 seconds in game passed.
Action: tensor([[[0.0021, 0.6033],
         [0.0015, 0.3261],
         [0.0015, 0.2231],
         [0.0011, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002438, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.5719037807814558
+++++++++++++: 5.527995812484477
4.273842537775636 seconds in game passed.
At 4.273842537775636 seconds, saving state-action tuples.
Action: tensor([[[0.0030, 0.6065],
         [0.0022, 0.3273],
         [0.0022, 0.2235],
         [0.0017, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 5.527995812484477
Current reward: 0.3520607731283827
Current mitigation activation: 0
#############################
Total reward: 0.9239645539098384
4.298842538148165 seconds in game passed.
Action: tensor([[[0.0030, 0.6065],
         [0.0022, 0.3273],
         [0.0022, 0.2235],
         [0.0017, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003163, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.9239645539098384
4.323842538520694 seconds in game passed.
Action: tensor([[[0.0030, 0.6065],
         [0.0022, 0.3273],
         [0.0022, 0.2235],
         [0.0017, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.9239645539098384
4.348842538893223 seconds in game passed.
Action: tensor([[[0.0030, 0.6065],
         [0.0022, 0.3273],
         [0.0022, 0.2235],
         [0.0017, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.9239645539098384
+++++++++++++: 4.567735123492299
4.373842539265752 seconds in game passed.
At 4.373842539265752 seconds, saving state-action tuples.
Action: tensor([[[0.0030, 0.6101],
         [0.0026, 0.3281],
         [0.0026, 0.2235],
         [0.0022, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 4.567735123492299
Current reward: 0.3757174905257349
Current mitigation activation: 0
#############################
Total reward: 1.2996820444355732
4.398842539638281 seconds in game passed.
Action: tensor([[[0.0030, 0.6101],
         [0.0026, 0.3281],
         [0.0026, 0.2235],
         [0.0022, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2996820444355732
4.42384254001081 seconds in game passed.
Action: tensor([[[0.0030, 0.6101],
         [0.0026, 0.3281],
         [0.0026, 0.2235],
         [0.0022, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2996820444355732
4.448842540383339 seconds in game passed.
Action: tensor([[[0.0030, 0.6101],
         [0.0026, 0.3281],
         [0.0026, 0.2235],
         [0.0022, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2996820444355732
+++++++++++++: 3.971756932451692
4.473842540755868 seconds in game passed.
At 4.473842540755868 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.6115],
         [0.0019, 0.3273],
         [0.0019, 0.2227],
         [0.0016, 0.1687]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.971756932451692
Current reward: 0.39511837490385926
Current mitigation activation: 0
#############################
Total reward: 1.6948004193394324
4.498842541128397 seconds in game passed.
Action: tensor([[[0.0018, 0.6115],
         [0.0019, 0.3273],
         [0.0019, 0.2227],
         [0.0016, 0.1687]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6948004193394324
4.523842541500926 seconds in game passed.
Action: tensor([[[0.0018, 0.6115],
         [0.0019, 0.3273],
         [0.0019, 0.2227],
         [0.0016, 0.1687]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6948004193394324
4.548842541873455 seconds in game passed.
Action: tensor([[[0.0018, 0.6115],
         [0.0019, 0.3273],
         [0.0019, 0.2227],
         [0.0016, 0.1687]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.6948004193394324
+++++++++++++: 3.556827849105644
4.573842542245984 seconds in game passed.
At 4.573842542245984 seconds, saving state-action tuples.
Action: tensor([[[ 1.2396e-03,  6.1160e-01],
         [ 7.1967e-04,  3.2800e-01],
         [ 4.4249e-04,  2.2314e-01],
         [-1.8361e-04,  1.6911e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001579, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.556827849105644
Current reward: 0.41100291967721636
Current mitigation activation: 0
#############################
Total reward: 2.105803339016649
4.598842542618513 seconds in game passed.
Action: tensor([[[ 1.2396e-03,  6.1160e-01],
         [ 7.1967e-04,  3.2800e-01],
         [ 4.4249e-04,  2.2314e-01],
         [-1.8361e-04,  1.6911e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.105803339016649
4.623842542991042 seconds in game passed.
Action: tensor([[[ 1.2396e-03,  6.1160e-01],
         [ 7.1967e-04,  3.2800e-01],
         [ 4.4249e-04,  2.2314e-01],
         [-1.8361e-04,  1.6911e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.105803339016649
4.648842543363571 seconds in game passed.
Action: tensor([[[ 1.2396e-03,  6.1160e-01],
         [ 7.1967e-04,  3.2800e-01],
         [ 4.4249e-04,  2.2314e-01],
         [-1.8361e-04,  1.6911e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001719, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.105803339016649
+++++++++++++: 3.2447415292573307
4.6738425437361 seconds in game passed.
At 4.6738425437361 seconds, saving state-action tuples.
Action: tensor([[[ 1.5926e-03,  6.1398e-01],
         [ 8.7511e-04,  3.2793e-01],
         [ 5.1022e-04,  2.2305e-01],
         [-8.6613e-05,  1.6915e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001961, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 3.2447415292573307
Current reward: 0.4240319621448065
Current mitigation activation: 0
#############################
Total reward: 2.529835301161455
4.698842544108629 seconds in game passed.
Action: tensor([[[ 1.5926e-03,  6.1398e-01],
         [ 8.7511e-04,  3.2793e-01],
         [ 5.1022e-04,  2.2305e-01],
         [-8.6613e-05,  1.6915e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.529835301161455
4.723842544481158 seconds in game passed.
Action: tensor([[[ 1.5926e-03,  6.1398e-01],
         [ 8.7511e-04,  3.2793e-01],
         [ 5.1022e-04,  2.2305e-01],
         [-8.6613e-05,  1.6915e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001899, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.529835301161455
4.748842544853687 seconds in game passed.
Action: tensor([[[ 1.5926e-03,  6.1398e-01],
         [ 8.7511e-04,  3.2793e-01],
         [ 5.1022e-04,  2.2305e-01],
         [-8.6613e-05,  1.6915e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.529835301161455
+++++++++++++: 2.9964052203837594
4.773842545226216 seconds in game passed.
At 4.773842545226216 seconds, saving state-action tuples.
Action: tensor([[[-1.8649e-04,  6.1093e-01],
         [-8.5627e-04,  3.2666e-01],
         [-1.2328e-03,  2.2245e-01],
         [-1.9959e-03,  1.6861e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.9964052203837594
Current reward: 0.4348057208268419
Current mitigation activation: 0
#############################
Total reward: 2.964641021988297
4.798842545598745 seconds in game passed.
Action: tensor([[[-1.8649e-04,  6.1093e-01],
         [-8.5627e-04,  3.2666e-01],
         [-1.2328e-03,  2.2245e-01],
         [-1.9959e-03,  1.6861e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.964641021988297
4.823842545971274 seconds in game passed.
Action: tensor([[[-1.8649e-04,  6.1093e-01],
         [-8.5627e-04,  3.2666e-01],
         [-1.2328e-03,  2.2245e-01],
         [-1.9959e-03,  1.6861e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.964641021988297
4.848842546343803 seconds in game passed.
Action: tensor([[[-1.8649e-04,  6.1093e-01],
         [-8.5627e-04,  3.2666e-01],
         [-1.2328e-03,  2.2245e-01],
         [-1.9959e-03,  1.6861e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.964641021988297
+++++++++++++: 2.7888484440705827
4.873842546716332 seconds in game passed.
At 4.873842546716332 seconds, saving state-action tuples.
Action: tensor([[[ 0.0009,  0.6075],
         [-0.0008,  0.3271],
         [-0.0012,  0.2232],
         [-0.0017,  0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.7888484440705827
Current reward: 0.44384974341506356
Current mitigation activation: 0
#############################
Total reward: 3.4084907654033603
4.8988425470888615 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6075],
         [-0.0008,  0.3271],
         [-0.0012,  0.2232],
         [-0.0017,  0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4084907654033603
4.9238425474613905 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6075],
         [-0.0008,  0.3271],
         [-0.0012,  0.2232],
         [-0.0017,  0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4084907654033603
4.9488425478339195 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6075],
         [-0.0008,  0.3271],
         [-0.0012,  0.2232],
         [-0.0017,  0.1692]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4084907654033603
+++++++++++++: 2.6089969753157662
4.9738425482064486 seconds in game passed.
At 4.9738425482064486 seconds, saving state-action tuples.
Action: tensor([[[1.4008e-03, 5.9853e-01],
         [2.6115e-04, 3.2520e-01],
         [3.5017e-04, 2.2327e-01],
         [4.8174e-04, 1.6942e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.6089969753157662
Current reward: 0.45154017843939115
Current mitigation activation: 0
#############################
Total reward: 3.8600309438427516
4.998842548578978 seconds in game passed.
Action: tensor([[[1.4008e-03, 5.9853e-01],
         [2.6115e-04, 3.2520e-01],
         [3.5017e-04, 2.2327e-01],
         [4.8174e-04, 1.6942e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001213, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8600309438427516
5.023842548951507 seconds in game passed.
Action: tensor([[[1.4008e-03, 5.9853e-01],
         [2.6115e-04, 3.2520e-01],
         [3.5017e-04, 2.2327e-01],
         [4.8174e-04, 1.6942e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8600309438427516
5.048842549324036 seconds in game passed.
Action: tensor([[[1.4008e-03, 5.9853e-01],
         [2.6115e-04, 3.2520e-01],
         [3.5017e-04, 2.2327e-01],
         [4.8174e-04, 1.6942e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001182, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.8600309438427516
+++++++++++++: 2.4493285775407228
5.073842549696565 seconds in game passed.
At 5.073842549696565 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.8041e-04,  5.9886e-01],
         [-3.4803e-04,  3.2536e-01],
         [-8.0274e-04,  2.2392e-01],
         [-1.3908e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.4493285775407228
Current reward: 0.45816538434071724
Current mitigation activation: 0
#############################
Total reward: 4.318196328183469
5.098842550069094 seconds in game passed.
Action: tensor([[[ 6.8041e-04,  5.9886e-01],
         [-3.4803e-04,  3.2536e-01],
         [-8.0274e-04,  2.2392e-01],
         [-1.3908e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000542, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.318196328183469
5.123842550441623 seconds in game passed.
Action: tensor([[[ 6.8041e-04,  5.9886e-01],
         [-3.4803e-04,  3.2536e-01],
         [-8.0274e-04,  2.2392e-01],
         [-1.3908e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.318196328183469
5.148842550814152 seconds in game passed.
Action: tensor([[[ 6.8041e-04,  5.9886e-01],
         [-3.4803e-04,  3.2536e-01],
         [-8.0274e-04,  2.2392e-01],
         [-1.3908e-03,  1.6962e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.318196328183469
+++++++++++++: 2.3042328198699744
5.173842551186681 seconds in game passed.
At 5.173842551186681 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4981e-03, 5.9990e-01],
         [5.3131e-04, 3.2547e-01],
         [3.2310e-04, 2.2351e-01],
         [7.0877e-05, 1.6958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.3042328198699744
Current reward: 0.4638989519354692
Current mitigation activation: 0
#############################
Total reward: 4.782095280118939
5.19884255155921 seconds in game passed.
Action: tensor([[[1.4981e-03, 5.9990e-01],
         [5.3131e-04, 3.2547e-01],
         [3.2310e-04, 2.2351e-01],
         [7.0877e-05, 1.6958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.782095280118939
5.223842551931739 seconds in game passed.
Action: tensor([[[1.4981e-03, 5.9990e-01],
         [5.3131e-04, 3.2547e-01],
         [3.2310e-04, 2.2351e-01],
         [7.0877e-05, 1.6958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.782095280118939
5.248842552304268 seconds in game passed.
Action: tensor([[[1.4981e-03, 5.9990e-01],
         [5.3131e-04, 3.2547e-01],
         [3.2310e-04, 2.2351e-01],
         [7.0877e-05, 1.6958e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.782095280118939
+++++++++++++: 2.170531794945002
5.273842552676797 seconds in game passed.
At 5.273842552676797 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.3525e-03,  6.1992e-01],
         [ 1.8643e-04,  3.3359e-01],
         [-1.5273e-04,  2.2791e-01],
         [-4.9524e-04,  1.7332e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.170531794945002
Current reward: 0.4688754707700692
Current mitigation activation: 0
#############################
Total reward: 5.2509707508890076
5.298842553049326 seconds in game passed.
Action: tensor([[[ 2.3525e-03,  6.1992e-01],
         [ 1.8643e-04,  3.3359e-01],
         [-1.5273e-04,  2.2791e-01],
         [-4.9524e-04,  1.7332e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.2509707508890076
5.323842553421855 seconds in game passed.
Action: tensor([[[ 2.3525e-03,  6.1992e-01],
         [ 1.8643e-04,  3.3359e-01],
         [-1.5273e-04,  2.2791e-01],
         [-4.9524e-04,  1.7332e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.2509707508890076
5.348842553794384 seconds in game passed.
Action: tensor([[[ 2.3525e-03,  6.1992e-01],
         [ 1.8643e-04,  3.3359e-01],
         [-1.5273e-04,  2.2791e-01],
         [-4.9524e-04,  1.7332e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.2509707508890076
+++++++++++++: 2.04590021666285
5.373842554166913 seconds in game passed.
At 5.373842554166913 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.6122],
         [0.0013, 0.3318],
         [0.0012, 0.2268],
         [0.0008, 0.1726]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 2.04590021666285
Current reward: 0.47321269444243064
Current mitigation activation: 0
#############################
Total reward: 5.724183445331438
5.398842554539442 seconds in game passed.
Action: tensor([[[0.0028, 0.6122],
         [0.0013, 0.3318],
         [0.0012, 0.2268],
         [0.0008, 0.1726]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.724183445331438
5.423842554911971 seconds in game passed.
Action: tensor([[[0.0028, 0.6122],
         [0.0013, 0.3318],
         [0.0012, 0.2268],
         [0.0008, 0.1726]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002074, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.724183445331438
5.4488425552845 seconds in game passed.
Action: tensor([[[0.0028, 0.6122],
         [0.0013, 0.3318],
         [0.0012, 0.2268],
         [0.0008, 0.1726]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.724183445331438
+++++++++++++: 1.9524683583772096
5.473842555657029 seconds in game passed.
At 5.473842555657029 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6071],
         [-0.0008,  0.3285],
         [-0.0008,  0.2244],
         [-0.0010,  0.1705]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000278, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9524683583772096
Current reward: 0.47382484612285425
Current mitigation activation: 0
#############################
Total reward: 6.198008291454292
5.498842556029558 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6071],
         [-0.0008,  0.3285],
         [-0.0008,  0.2244],
         [-0.0010,  0.1705]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.198008291454292
5.523842556402087 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6071],
         [-0.0008,  0.3285],
         [-0.0008,  0.2244],
         [-0.0010,  0.1705]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000060, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.198008291454292
5.548842556774616 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6071],
         [-0.0008,  0.3285],
         [-0.0008,  0.2244],
         [-0.0010,  0.1705]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000036, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.198008291454292
+++++++++++++: 1.9035060219624667
5.573842557147145 seconds in game passed.
At 5.573842557147145 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6178],
         [-0.0034,  0.3324],
         [-0.0039,  0.2258],
         [-0.0044,  0.1718]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.9035060219624667
Current reward: 0.46838495840846384
Current mitigation activation: 0
#############################
Total reward: 6.6663932498627565
5.598842557519674 seconds in game passed.
Action: tensor([[[-0.0011,  0.6178],
         [-0.0034,  0.3324],
         [-0.0039,  0.2258],
         [-0.0044,  0.1718]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002239, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.6663932498627565
5.623842557892203 seconds in game passed.
Action: tensor([[[-0.0011,  0.6178],
         [-0.0034,  0.3324],
         [-0.0039,  0.2258],
         [-0.0044,  0.1718]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.6663932498627565
5.648842558264732 seconds in game passed.
Action: tensor([[[-0.0011,  0.6178],
         [-0.0034,  0.3324],
         [-0.0039,  0.2258],
         [-0.0044,  0.1718]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.6663932498627565
+++++++++++++: 1.8546650895442833
5.673842558637261 seconds in game passed.
At 5.673842558637261 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6358],
         [-0.0031,  0.3408],
         [-0.0037,  0.2305],
         [-0.0041,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002774, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8546650895442833
Current reward: 0.4628574982896583
Current mitigation activation: 0
#############################
Total reward: 7.1292507481524146
5.69884255900979 seconds in game passed.
Action: tensor([[[-0.0025,  0.6358],
         [-0.0031,  0.3408],
         [-0.0037,  0.2305],
         [-0.0041,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1292507481524146
5.7238425593823195 seconds in game passed.
Action: tensor([[[-0.0025,  0.6358],
         [-0.0031,  0.3408],
         [-0.0037,  0.2305],
         [-0.0041,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1292507481524146
5.7488425597548485 seconds in game passed.
Action: tensor([[[-0.0025,  0.6358],
         [-0.0031,  0.3408],
         [-0.0037,  0.2305],
         [-0.0041,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.1292507481524146
+++++++++++++: 1.8058578105589895
5.7738425601273775 seconds in game passed.
At 5.7738425601273775 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0031,  0.6503],
         [-0.0031,  0.3476],
         [-0.0032,  0.2346],
         [-0.0032,  0.1773]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.8058578105589895
Current reward: 0.4573390456574383
Current mitigation activation: 0
#############################
Total reward: 7.5865897938098525
5.7988425604999065 seconds in game passed.
Action: tensor([[[-0.0031,  0.6503],
         [-0.0031,  0.3476],
         [-0.0032,  0.2346],
         [-0.0032,  0.1773]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.5865897938098525
5.823842560872436 seconds in game passed.
Action: tensor([[[-0.0031,  0.6503],
         [-0.0031,  0.3476],
         [-0.0032,  0.2346],
         [-0.0032,  0.1773]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.5865897938098525
5.848842561244965 seconds in game passed.
Action: tensor([[[-0.0031,  0.6503],
         [-0.0031,  0.3476],
         [-0.0032,  0.2346],
         [-0.0032,  0.1773]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.5865897938098525
+++++++++++++: 1.757266775336521
5.873842561617494 seconds in game passed.
At 5.873842561617494 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.6482],
         [-0.0025,  0.3483],
         [-0.0025,  0.2357],
         [-0.0025,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.757266775336521
Current reward: 0.4518428796749946
Current mitigation activation: 0
#############################
Total reward: 8.038432673484847
5.898842561990023 seconds in game passed.
Action: tensor([[[-0.0035,  0.6482],
         [-0.0025,  0.3483],
         [-0.0025,  0.2357],
         [-0.0025,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002952, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.038432673484847
5.923842562362552 seconds in game passed.
Action: tensor([[[-0.0035,  0.6482],
         [-0.0025,  0.3483],
         [-0.0025,  0.2357],
         [-0.0025,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.038432673484847
5.948842562735081 seconds in game passed.
Action: tensor([[[-0.0035,  0.6482],
         [-0.0025,  0.3483],
         [-0.0025,  0.2357],
         [-0.0025,  0.1781]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.038432673484847
+++++++++++++: 1.6853437663949897
5.97384256310761 seconds in game passed.
At 5.97384256310761 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0011,  0.6728],
         [-0.0016,  0.3584],
         [-0.0017,  0.2416],
         [-0.0016,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.764189, steer=-0.000600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.6853437663949897
Current reward: 0.45001420853741925
Current mitigation activation: 0
#############################
Total reward: 8.488446882022266
5.998842563480139 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6728],
         [-0.0016,  0.3584],
         [-0.0017,  0.2416],
         [-0.0016,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.710671, steer=-0.001021, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.488446882022266
6.023842563852668 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6728],
         [-0.0016,  0.3584],
         [-0.0017,  0.2416],
         [-0.0016,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.648737, steer=-0.001037, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.488446882022266
6.048842564225197 seconds in game passed.
Action: tensor([[[ 0.0011,  0.6728],
         [-0.0016,  0.3584],
         [-0.0017,  0.2416],
         [-0.0016,  0.1819]]])
agent 0 action: VehicleControl(throttle=0.589696, steer=-0.001053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.488446882022266
+++++++++++++: 1.5579192199198417
6.073842564597726 seconds in game passed.
At 6.073842564597726 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2416e-02, 7.0029e-01],
         [3.1582e-03, 3.7366e-01],
         [1.6826e-03, 2.5142e-01],
         [6.0470e-04, 1.8919e-01]]])
agent 0 action: VehicleControl(throttle=0.338281, steer=0.007052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.5579192199198417
Current reward: 0.45803475639078717
Current mitigation activation: 0
#############################
Total reward: 8.946481638413054
6.098842564970255 seconds in game passed.
Action: tensor([[[1.2416e-02, 7.0029e-01],
         [3.1582e-03, 3.7366e-01],
         [1.6826e-03, 2.5142e-01],
         [6.0470e-04, 1.8919e-01]]])
agent 0 action: VehicleControl(throttle=0.348848, steer=0.005789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.946481638413054
6.123842565342784 seconds in game passed.
Action: tensor([[[1.2416e-02, 7.0029e-01],
         [3.1582e-03, 3.7366e-01],
         [1.6826e-03, 2.5142e-01],
         [6.0470e-04, 1.8919e-01]]])
agent 0 action: VehicleControl(throttle=0.334025, steer=0.005865, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.946481638413054
6.148842565715313 seconds in game passed.
Action: tensor([[[1.2416e-02, 7.0029e-01],
         [3.1582e-03, 3.7366e-01],
         [1.6826e-03, 2.5142e-01],
         [6.0470e-04, 1.8919e-01]]])
agent 0 action: VehicleControl(throttle=0.319648, steer=0.005940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.946481638413054
+++++++++++++: 1.452381925632472
6.173842566087842 seconds in game passed.
At 6.173842566087842 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.6247e-03,  6.9277e-01],
         [ 3.0625e-03,  3.7687e-01],
         [ 1.2064e-03,  2.5416e-01],
         [-6.3408e-04,  1.9138e-01]]])
agent 0 action: VehicleControl(throttle=0.305632, steer=0.004447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.452381925632472
Current reward: 0.46330277832469735
Current mitigation activation: 0
#############################
Total reward: 9.409784416737752
6.198842566460371 seconds in game passed.
Action: tensor([[[ 8.6247e-03,  6.9277e-01],
         [ 3.0625e-03,  3.7687e-01],
         [ 1.2064e-03,  2.5416e-01],
         [-6.3408e-04,  1.9138e-01]]])
agent 0 action: VehicleControl(throttle=0.292052, steer=0.004753, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.409784416737752
6.2238425668329 seconds in game passed.
Action: tensor([[[ 8.6247e-03,  6.9277e-01],
         [ 3.0625e-03,  3.7687e-01],
         [ 1.2064e-03,  2.5416e-01],
         [-6.3408e-04,  1.9138e-01]]])
agent 0 action: VehicleControl(throttle=0.278905, steer=0.004803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.409784416737752
6.248842567205429 seconds in game passed.
Action: tensor([[[ 8.6247e-03,  6.9277e-01],
         [ 3.0625e-03,  3.7687e-01],
         [ 1.2064e-03,  2.5416e-01],
         [-6.3408e-04,  1.9138e-01]]])
agent 0 action: VehicleControl(throttle=0.266187, steer=0.004852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.409784416737752
+++++++++++++: 1.374921366494931
6.273842567577958 seconds in game passed.
At 6.273842567577958 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.6381e-03,  7.3006e-01],
         [ 2.1223e-03,  3.9411e-01],
         [ 7.1546e-04,  2.6218e-01],
         [-1.2924e-03,  1.9546e-01]]])
agent 0 action: VehicleControl(throttle=0.254799, steer=0.001786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 1.374921366494931
Current reward: 0.46354747835049137
Current mitigation activation: 0
#############################
Total reward: 9.873331895088244
6.298842567950487 seconds in game passed.
Action: tensor([[[ 2.6381e-03,  7.3006e-01],
         [ 2.1223e-03,  3.9411e-01],
         [ 7.1546e-04,  2.6218e-01],
         [-1.2924e-03,  1.9546e-01]]])
agent 0 action: VehicleControl(throttle=0.243832, steer=0.002316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.873331895088244
6.323842568323016 seconds in game passed.
Action: tensor([[[ 2.6381e-03,  7.3006e-01],
         [ 2.1223e-03,  3.9411e-01],
         [ 7.1546e-04,  2.6218e-01],
         [-1.2924e-03,  1.9546e-01]]])
agent 0 action: VehicleControl(throttle=0.233283, steer=0.002333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.873331895088244
6.348842568695545 seconds in game passed.
Action: tensor([[[ 2.6381e-03,  7.3006e-01],
         [ 2.1223e-03,  3.9411e-01],
         [ 7.1546e-04,  2.6218e-01],
         [-1.2924e-03,  1.9546e-01]]])
agent 0 action: VehicleControl(throttle=0.223147, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.873331895088244
+++++++++++++: inf
6.373842569068074 seconds in game passed.
At 6.373842569068074 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 8.4499e-03,  7.7586e-01],
         [ 2.9659e-04,  4.1662e-01],
         [-1.8952e-03,  2.7632e-01],
         [-3.9916e-03,  2.0274e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003348, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4326162146109023
Current mitigation activation: 0
#############################
Total reward: 11.305948109699147
6.398842569440603 seconds in game passed.
Action: tensor([[[ 8.4499e-03,  7.7586e-01],
         [ 2.9659e-04,  4.1662e-01],
         [-1.8952e-03,  2.7632e-01],
         [-3.9916e-03,  2.0274e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003201, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.305948109699147
6.423842569813132 seconds in game passed.
Action: tensor([[[ 8.4499e-03,  7.7586e-01],
         [ 2.9659e-04,  4.1662e-01],
         [-1.8952e-03,  2.7632e-01],
         [-3.9916e-03,  2.0274e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003217, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.305948109699147
6.448842570185661 seconds in game passed.
Action: tensor([[[ 8.4499e-03,  7.7586e-01],
         [ 2.9659e-04,  4.1662e-01],
         [-1.8952e-03,  2.7632e-01],
         [-3.9916e-03,  2.0274e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003233, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 11.305948109699147
+++++++++++++: inf
6.47384257055819 seconds in game passed.
At 6.47384257055819 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0063,  0.8150],
         [-0.0027,  0.4250],
         [-0.0045,  0.2751],
         [-0.0051,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.176116, steer=0.000055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4219582611344943
Current mitigation activation: 0
#############################
Total reward: 12.72790637083364
6.498842570930719 seconds in game passed.
Action: tensor([[[ 0.0063,  0.8150],
         [-0.0027,  0.4250],
         [-0.0045,  0.2751],
         [-0.0051,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.166157, steer=0.000593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.72790637083364
6.523842571303248 seconds in game passed.
Action: tensor([[[ 0.0063,  0.8150],
         [-0.0027,  0.4250],
         [-0.0045,  0.2751],
         [-0.0051,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.156179, steer=0.000601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.72790637083364
6.548842571675777 seconds in game passed.
Action: tensor([[[ 0.0063,  0.8150],
         [-0.0027,  0.4250],
         [-0.0045,  0.2751],
         [-0.0051,  0.1985]]])
agent 0 action: VehicleControl(throttle=0.146182, steer=0.000608, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.72790637083364
+++++++++++++: inf
6.5738425720483065 seconds in game passed.
At 6.5738425720483065 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.7694],
         [-0.0032,  0.4004],
         [-0.0043,  0.2605],
         [-0.0046,  0.1900]]])
agent 0 action: VehicleControl(throttle=0.136481, steer=-0.003794, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3803136701411356
Current mitigation activation: 0
#############################
Total reward: 14.108220040974775
6.5988425724208355 seconds in game passed.
Action: tensor([[[-0.0039,  0.7694],
         [-0.0032,  0.4004],
         [-0.0043,  0.2605],
         [-0.0046,  0.1900]]])
agent 0 action: VehicleControl(throttle=0.126761, steer=-0.003073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.108220040974775
6.6238425727933645 seconds in game passed.
Action: tensor([[[-0.0039,  0.7694],
         [-0.0032,  0.4004],
         [-0.0043,  0.2605],
         [-0.0046,  0.1900]]])
agent 0 action: VehicleControl(throttle=0.117022, steer=-0.003085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.108220040974775
6.6488425731658936 seconds in game passed.
Action: tensor([[[-0.0039,  0.7694],
         [-0.0032,  0.4004],
         [-0.0043,  0.2605],
         [-0.0046,  0.1900]]])
agent 0 action: VehicleControl(throttle=0.107265, steer=-0.003096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.108220040974775
+++++++++++++: inf
6.673842573538423 seconds in game passed.
At 6.673842573538423 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0045,  0.8652],
         [-0.0071,  0.4674],
         [-0.0087,  0.3021],
         [-0.0072,  0.2119]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.006351, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3428514146962067
Current mitigation activation: 0
#############################
Total reward: 15.45107145567098
6.698842573910952 seconds in game passed.
Action: tensor([[[-0.0045,  0.8652],
         [-0.0071,  0.4674],
         [-0.0087,  0.3021],
         [-0.0072,  0.2119]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005855, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.45107145567098
6.723842574283481 seconds in game passed.
Action: tensor([[[-0.0045,  0.8652],
         [-0.0071,  0.4674],
         [-0.0087,  0.3021],
         [-0.0072,  0.2119]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005896, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.45107145567098
6.74884257465601 seconds in game passed.
Action: tensor([[[-0.0045,  0.8652],
         [-0.0071,  0.4674],
         [-0.0087,  0.3021],
         [-0.0072,  0.2119]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=-0.005936, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 15.45107145567098
+++++++++++++: inf
6.773842575028539 seconds in game passed.
At 6.773842575028539 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0429,  0.8608],
         [-0.0061,  0.5057],
         [-0.0113,  0.3400],
         [-0.0094,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.015504, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3076424323994231
Current mitigation activation: 0
#############################
Total reward: 16.758713888070403
6.798842575401068 seconds in game passed.
Action: tensor([[[ 0.0429,  0.8608],
         [-0.0061,  0.5057],
         [-0.0113,  0.3400],
         [-0.0094,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012145, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.758713888070403
6.823842575773597 seconds in game passed.
Action: tensor([[[ 0.0429,  0.8608],
         [-0.0061,  0.5057],
         [-0.0113,  0.3400],
         [-0.0094,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012328, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.758713888070403
6.848842576146126 seconds in game passed.
Action: tensor([[[ 0.0429,  0.8608],
         [-0.0061,  0.5057],
         [-0.0113,  0.3400],
         [-0.0094,  0.2421]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.012511, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.758713888070403
+++++++++++++: inf
6.873842576518655 seconds in game passed.
At 6.873842576518655 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0573,  0.8626],
         [ 0.0010,  0.5110],
         [-0.0067,  0.3513],
         [-0.0060,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.024454, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2459849027015704
Current mitigation activation: 0
#############################
Total reward: 18.004698790771975
6.898842576891184 seconds in game passed.
Action: tensor([[[ 0.0573,  0.8626],
         [ 0.0010,  0.5110],
         [-0.0067,  0.3513],
         [-0.0060,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.022815, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.004698790771975
6.923842577263713 seconds in game passed.
Action: tensor([[[ 0.0573,  0.8626],
         [ 0.0010,  0.5110],
         [-0.0067,  0.3513],
         [-0.0060,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.023117, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.004698790771975
6.948842577636242 seconds in game passed.
Action: tensor([[[ 0.0573,  0.8626],
         [ 0.0010,  0.5110],
         [-0.0067,  0.3513],
         [-0.0060,  0.2531]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.023418, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.004698790771975
+++++++++++++: inf
6.973842578008771 seconds in game passed.
At 6.973842578008771 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.9104e-02,  8.7484e-01],
         [-3.7998e-04,  5.3346e-01],
         [-1.3213e-02,  3.6840e-01],
         [-1.2826e-02,  2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.028537, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1501519072799797
Current mitigation activation: 0
#############################
Total reward: 19.154850698051956
6.9988425783813 seconds in game passed.
Action: tensor([[[ 6.9104e-02,  8.7484e-01],
         [-3.7998e-04,  5.3346e-01],
         [-1.3213e-02,  3.6840e-01],
         [-1.2826e-02,  2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.028064, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.154850698051956
7.023842578753829 seconds in game passed.
Action: tensor([[[ 6.9104e-02,  8.7484e-01],
         [-3.7998e-04,  5.3346e-01],
         [-1.3213e-02,  3.6840e-01],
         [-1.2826e-02,  2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.028390, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.154850698051956
7.048842579126358 seconds in game passed.
Action: tensor([[[ 6.9104e-02,  8.7484e-01],
         [-3.7998e-04,  5.3346e-01],
         [-1.3213e-02,  3.6840e-01],
         [-1.2826e-02,  2.6293e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.028716, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.154850698051956
+++++++++++++: inf
7.073842579498887 seconds in game passed.
At 7.073842579498887 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0267,  0.8096],
         [-0.0065,  0.4798],
         [-0.0128,  0.3331],
         [-0.0125,  0.2431]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0412793097711595
Current mitigation activation: 0
#############################
Total reward: 20.196130007823115
7.098842579871416 seconds in game passed.
Action: tensor([[[ 0.0267,  0.8096],
         [-0.0065,  0.4798],
         [-0.0128,  0.3331],
         [-0.0125,  0.2431]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.196130007823115
7.123842580243945 seconds in game passed.
Action: tensor([[[ 0.0267,  0.8096],
         [-0.0065,  0.4798],
         [-0.0128,  0.3331],
         [-0.0125,  0.2431]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.196130007823115
7.148842580616474 seconds in game passed.
Action: tensor([[[ 0.0267,  0.8096],
         [-0.0065,  0.4798],
         [-0.0128,  0.3331],
         [-0.0125,  0.2431]]])
agent 0 action: VehicleControl(throttle=0.069911, steer=0.008903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 20.196130007823115
+++++++++++++: inf
7.173842580989003 seconds in game passed.
At 7.173842580989003 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0210,  0.8255],
         [-0.0103,  0.4603],
         [-0.0182,  0.3106],
         [-0.0199,  0.2253]]])
agent 0 action: VehicleControl(throttle=0.574789, steer=0.003149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9321031555755096
Current mitigation activation: 0
#############################
Total reward: 21.128233163398626
7.198842581361532 seconds in game passed.
Action: tensor([[[ 0.0210,  0.8255],
         [-0.0103,  0.4603],
         [-0.0182,  0.3106],
         [-0.0199,  0.2253]]])
agent 0 action: VehicleControl(throttle=0.581953, steer=0.004052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.128233163398626
7.223842581734061 seconds in game passed.
Action: tensor([[[ 0.0210,  0.8255],
         [-0.0103,  0.4603],
         [-0.0182,  0.3106],
         [-0.0199,  0.2253]]])
agent 0 action: VehicleControl(throttle=0.624867, steer=0.004003, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.128233163398626
7.24884258210659 seconds in game passed.
Action: tensor([[[ 0.0210,  0.8255],
         [-0.0103,  0.4603],
         [-0.0182,  0.3106],
         [-0.0199,  0.2253]]])
agent 0 action: VehicleControl(throttle=0.664656, steer=0.003955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.128233163398626
+++++++++++++: inf
7.273842582479119 seconds in game passed.
At 7.273842582479119 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0267,  0.7974],
         [-0.0144,  0.4535],
         [-0.0250,  0.3081],
         [-0.0292,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.662300, steer=0.003499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8641537483774583
Current mitigation activation: 0
#############################
Total reward: 21.992386911776084
7.298842582851648 seconds in game passed.
Action: tensor([[[ 0.0267,  0.7974],
         [-0.0144,  0.4535],
         [-0.0250,  0.3081],
         [-0.0292,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.694513, steer=0.003550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.992386911776084
7.323842583224177 seconds in game passed.
Action: tensor([[[ 0.0267,  0.7974],
         [-0.0144,  0.4535],
         [-0.0250,  0.3081],
         [-0.0292,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.716635, steer=0.003530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.992386911776084
7.348842583596706 seconds in game passed.
Action: tensor([[[ 0.0267,  0.7974],
         [-0.0144,  0.4535],
         [-0.0250,  0.3081],
         [-0.0292,  0.2246]]])
agent 0 action: VehicleControl(throttle=0.733448, steer=0.003509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.992386911776084
+++++++++++++: inf
7.373842583969235 seconds in game passed.
At 7.373842583969235 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0213,  0.7547],
         [-0.0164,  0.4271],
         [-0.0259,  0.2917],
         [-0.0302,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8361526739563949
Current mitigation activation: 0
#############################
Total reward: 22.82853958573248
7.3988425843417645 seconds in game passed.
Action: tensor([[[ 0.0213,  0.7547],
         [-0.0164,  0.4271],
         [-0.0259,  0.2917],
         [-0.0302,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.82853958573248
7.4238425847142935 seconds in game passed.
Action: tensor([[[ 0.0213,  0.7547],
         [-0.0164,  0.4271],
         [-0.0259,  0.2917],
         [-0.0302,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.82853958573248
7.4488425850868225 seconds in game passed.
Action: tensor([[[ 0.0213,  0.7547],
         [-0.0164,  0.4271],
         [-0.0259,  0.2917],
         [-0.0302,  0.2149]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.82853958573248
+++++++++++++: inf
7.4738425854593515 seconds in game passed.
At 7.4738425854593515 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0161,  0.7371],
         [-0.0247,  0.4245],
         [-0.0330,  0.2913],
         [-0.0354,  0.2147]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.008150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8346595630040238
Current mitigation activation: 0
#############################
Total reward: 23.663199148736503
7.498842585831881 seconds in game passed.
Action: tensor([[[ 0.0161,  0.7371],
         [-0.0247,  0.4245],
         [-0.0330,  0.2913],
         [-0.0354,  0.2147]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.006926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.663199148736503
7.52384258620441 seconds in game passed.
Action: tensor([[[ 0.0161,  0.7371],
         [-0.0247,  0.4245],
         [-0.0330,  0.2913],
         [-0.0354,  0.2147]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.663199148736503
7.548842586576939 seconds in game passed.
Action: tensor([[[ 0.0161,  0.7371],
         [-0.0247,  0.4245],
         [-0.0330,  0.2913],
         [-0.0354,  0.2147]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.007170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 23.663199148736503
+++++++++++++: inf
7.573842586949468 seconds in game passed.
At 7.573842586949468 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0345,  0.7848],
         [-0.0260,  0.4546],
         [-0.0361,  0.3123],
         [-0.0367,  0.2286]]])
agent 0 action: VehicleControl(throttle=0.607354, steer=-0.000317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8534063095011527
Current mitigation activation: 0
#############################
Total reward: 24.516605458237656
7.598842587321997 seconds in game passed.
Action: tensor([[[ 0.0345,  0.7848],
         [-0.0260,  0.4546],
         [-0.0361,  0.3123],
         [-0.0367,  0.2286]]])
agent 0 action: VehicleControl(throttle=0.617454, steer=-0.001464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.516605458237656
7.623842587694526 seconds in game passed.
Action: tensor([[[ 0.0345,  0.7848],
         [-0.0260,  0.4546],
         [-0.0361,  0.3123],
         [-0.0367,  0.2286]]])
agent 0 action: VehicleControl(throttle=0.596358, steer=-0.001469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.516605458237656
7.648842588067055 seconds in game passed.
Action: tensor([[[ 0.0345,  0.7848],
         [-0.0260,  0.4546],
         [-0.0361,  0.3123],
         [-0.0367,  0.2286]]])
agent 0 action: VehicleControl(throttle=0.576487, steer=-0.001474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.516605458237656
+++++++++++++: inf
7.673842588439584 seconds in game passed.
At 7.673842588439584 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0580,  0.7909],
         [-0.0156,  0.4690],
         [-0.0307,  0.3247],
         [-0.0331,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.335951, steer=0.016806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8836851706226525
Current mitigation activation: 0
#############################
Total reward: 25.400290628860308
7.698842588812113 seconds in game passed.
Action: tensor([[[ 0.0580,  0.7909],
         [-0.0156,  0.4690],
         [-0.0307,  0.3247],
         [-0.0331,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.339786, steer=0.014012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.400290628860308
7.723842589184642 seconds in game passed.
Action: tensor([[[ 0.0580,  0.7909],
         [-0.0156,  0.4690],
         [-0.0307,  0.3247],
         [-0.0331,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.322273, steer=0.014229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.400290628860308
7.748842589557171 seconds in game passed.
Action: tensor([[[ 0.0580,  0.7909],
         [-0.0156,  0.4690],
         [-0.0307,  0.3247],
         [-0.0331,  0.2361]]])
agent 0 action: VehicleControl(throttle=0.308040, steer=0.014446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.400290628860308
+++++++++++++: inf
7.7738425899297 seconds in game passed.
At 7.7738425899297 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0117,  0.7560],
         [-0.0289,  0.4469],
         [-0.0395,  0.3096],
         [-0.0425,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.471320, steer=-0.015423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9109929308373191
Current mitigation activation: 0
#############################
Total reward: 26.311283559697628
7.798842590302229 seconds in game passed.
Action: tensor([[[ 0.0117,  0.7560],
         [-0.0289,  0.4469],
         [-0.0395,  0.3096],
         [-0.0425,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.446481, steer=-0.010809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.311283559697628
7.823842590674758 seconds in game passed.
Action: tensor([[[ 0.0117,  0.7560],
         [-0.0289,  0.4469],
         [-0.0395,  0.3096],
         [-0.0425,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.442861, steer=-0.011121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.311283559697628
7.848842591047287 seconds in game passed.
Action: tensor([[[ 0.0117,  0.7560],
         [-0.0289,  0.4469],
         [-0.0395,  0.3096],
         [-0.0425,  0.2298]]])
agent 0 action: VehicleControl(throttle=0.439217, steer=-0.011433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 26.311283559697628
+++++++++++++: inf
7.873842591419816 seconds in game passed.
At 7.873842591419816 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.7367],
         [-0.0310,  0.4440],
         [-0.0403,  0.3105],
         [-0.0427,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.355613, steer=-0.017359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9252500247593579
Current mitigation activation: 0
#############################
Total reward: 27.236533584456986
7.898842591792345 seconds in game passed.
Action: tensor([[[ 0.0021,  0.7367],
         [-0.0310,  0.4440],
         [-0.0403,  0.3105],
         [-0.0427,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.360742, steer=-0.016944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.236533584456986
7.923842592164874 seconds in game passed.
Action: tensor([[[ 0.0021,  0.7367],
         [-0.0310,  0.4440],
         [-0.0403,  0.3105],
         [-0.0427,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.358300, steer=-0.017434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.236533584456986
7.948842592537403 seconds in game passed.
Action: tensor([[[ 0.0021,  0.7367],
         [-0.0310,  0.4440],
         [-0.0403,  0.3105],
         [-0.0427,  0.2309]]])
agent 0 action: VehicleControl(throttle=0.357091, steer=-0.017924, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.236533584456986
+++++++++++++: inf
7.973842592909932 seconds in game passed.
At 7.973842592909932 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0036,  0.6841],
         [-0.0235,  0.4150],
         [-0.0291,  0.2897],
         [-0.0301,  0.2162]]])
agent 0 action: VehicleControl(throttle=0.559416, steer=-0.015423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9321918536280662
Current mitigation activation: 0
#############################
Total reward: 28.16872543808505
7.998842593282461 seconds in game passed.
Action: tensor([[[-0.0036,  0.6841],
         [-0.0235,  0.4150],
         [-0.0291,  0.2897],
         [-0.0301,  0.2162]]])
agent 0 action: VehicleControl(throttle=0.540836, steer=-0.016433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.16872543808505
8.02384259365499 seconds in game passed.
Action: tensor([[[-0.0036,  0.6841],
         [-0.0235,  0.4150],
         [-0.0291,  0.2897],
         [-0.0301,  0.2162]]])
agent 0 action: VehicleControl(throttle=0.544062, steer=-0.016942, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.16872543808505
8.04884259402752 seconds in game passed.
Action: tensor([[[-0.0036,  0.6841],
         [-0.0235,  0.4150],
         [-0.0291,  0.2897],
         [-0.0301,  0.2162]]])
agent 0 action: VehicleControl(throttle=0.546111, steer=-0.017451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.16872543808505
+++++++++++++: inf
8.073842594400048 seconds in game passed.
At 8.073842594400048 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0092,  0.7060],
         [-0.0117,  0.4206],
         [-0.0141,  0.2923],
         [-0.0130,  0.2166]]])
agent 0 action: VehicleControl(throttle=0.597912, steer=-0.003695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9350256356505802
Current mitigation activation: 0
#############################
Total reward: 29.10375107373563
8.098842594772577 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7060],
         [-0.0117,  0.4206],
         [-0.0141,  0.2923],
         [-0.0130,  0.2166]]])
agent 0 action: VehicleControl(throttle=0.592912, steer=-0.006124, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.10375107373563
8.123842595145106 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7060],
         [-0.0117,  0.4206],
         [-0.0141,  0.2923],
         [-0.0130,  0.2166]]])
agent 0 action: VehicleControl(throttle=0.592135, steer=-0.006241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.10375107373563
8.148842595517635 seconds in game passed.
Action: tensor([[[ 0.0092,  0.7060],
         [-0.0117,  0.4206],
         [-0.0141,  0.2923],
         [-0.0130,  0.2166]]])
agent 0 action: VehicleControl(throttle=0.589289, steer=-0.006358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 29.10375107373563
+++++++++++++: inf
8.173842595890164 seconds in game passed.
At 8.173842595890164 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0078,  0.6630],
         [-0.0016,  0.3857],
         [-0.0032,  0.2671],
         [-0.0037,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000223, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9400092361739528
Current mitigation activation: 0
#############################
Total reward: 30.043760309909583
8.198842596262693 seconds in game passed.
Action: tensor([[[ 0.0078,  0.6630],
         [-0.0016,  0.3857],
         [-0.0032,  0.2671],
         [-0.0037,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.043760309909583
8.223842596635222 seconds in game passed.
Action: tensor([[[ 0.0078,  0.6630],
         [-0.0016,  0.3857],
         [-0.0032,  0.2671],
         [-0.0037,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.043760309909583
8.248842597007751 seconds in game passed.
Action: tensor([[[ 0.0078,  0.6630],
         [-0.0016,  0.3857],
         [-0.0032,  0.2671],
         [-0.0037,  0.2010]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000839, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.043760309909583
+++++++++++++: inf
8.27384259738028 seconds in game passed.
At 8.27384259738028 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0079,  0.6698],
         [-0.0101,  0.3872],
         [-0.0089,  0.2699],
         [-0.0078,  0.2051]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.013680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9504464730627459
Current mitigation activation: 0
#############################
Total reward: 30.99420678297233
8.29884259775281 seconds in game passed.
Action: tensor([[[-0.0079,  0.6698],
         [-0.0101,  0.3872],
         [-0.0089,  0.2699],
         [-0.0078,  0.2051]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.99420678297233
8.323842598125339 seconds in game passed.
Action: tensor([[[-0.0079,  0.6698],
         [-0.0101,  0.3872],
         [-0.0089,  0.2699],
         [-0.0078,  0.2051]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.99420678297233
8.348842598497868 seconds in game passed.
Action: tensor([[[-0.0079,  0.6698],
         [-0.0101,  0.3872],
         [-0.0089,  0.2699],
         [-0.0078,  0.2051]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011911, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.99420678297233
+++++++++++++: inf
8.373842598870397 seconds in game passed.
At 8.373842598870397 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0035,  0.6339],
         [-0.0058,  0.3702],
         [-0.0067,  0.2609],
         [-0.0064,  0.2003]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004001, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9713617365953899
Current mitigation activation: 0
#############################
Total reward: 31.96556851956772
8.398842599242926 seconds in game passed.
Action: tensor([[[ 0.0035,  0.6339],
         [-0.0058,  0.3702],
         [-0.0067,  0.2609],
         [-0.0064,  0.2003]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.96556851956772
8.423842599615455 seconds in game passed.
Action: tensor([[[ 0.0035,  0.6339],
         [-0.0058,  0.3702],
         [-0.0067,  0.2609],
         [-0.0064,  0.2003]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.96556851956772
8.448842599987984 seconds in game passed.
Action: tensor([[[ 0.0035,  0.6339],
         [-0.0058,  0.3702],
         [-0.0067,  0.2609],
         [-0.0064,  0.2003]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.96556851956772
+++++++++++++: inf
8.473842600360513 seconds in game passed.
At 8.473842600360513 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0042,  0.6446],
         [-0.0102,  0.3884],
         [-0.0109,  0.2773],
         [-0.0094,  0.2141]]])
agent 0 action: VehicleControl(throttle=0.514223, steer=-0.007969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0027879667148376
Current mitigation activation: 0
#############################
Total reward: 32.96835648628256
8.498842600733042 seconds in game passed.
Action: tensor([[[ 0.0042,  0.6446],
         [-0.0102,  0.3884],
         [-0.0109,  0.2773],
         [-0.0094,  0.2141]]])
agent 0 action: VehicleControl(throttle=0.549334, steer=-0.007454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.96835648628256
8.52384260110557 seconds in game passed.
Action: tensor([[[ 0.0042,  0.6446],
         [-0.0102,  0.3884],
         [-0.0109,  0.2773],
         [-0.0094,  0.2141]]])
agent 0 action: VehicleControl(throttle=0.543484, steer=-0.007393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.96835648628256
8.5488426014781 seconds in game passed.
Action: tensor([[[ 0.0042,  0.6446],
         [-0.0102,  0.3884],
         [-0.0109,  0.2773],
         [-0.0094,  0.2141]]])
agent 0 action: VehicleControl(throttle=0.538379, steer=-0.007332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 32.96835648628256
+++++++++++++: inf
8.573842601850629 seconds in game passed.
At 8.573842601850629 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0057,  0.6168],
         [-0.0043,  0.3629],
         [-0.0053,  0.2560],
         [-0.0049,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.002529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0205085177543518
Current mitigation activation: 0
#############################
Total reward: 33.98886500403691
8.598842602223158 seconds in game passed.
Action: tensor([[[ 0.0057,  0.6168],
         [-0.0043,  0.3629],
         [-0.0053,  0.2560],
         [-0.0049,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98886500403691
8.623842602595687 seconds in game passed.
Action: tensor([[[ 0.0057,  0.6168],
         [-0.0043,  0.3629],
         [-0.0053,  0.2560],
         [-0.0049,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003245, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98886500403691
8.648842602968216 seconds in game passed.
Action: tensor([[[ 0.0057,  0.6168],
         [-0.0043,  0.3629],
         [-0.0053,  0.2560],
         [-0.0049,  0.1975]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.98886500403691
+++++++++++++: inf
8.673842603340745 seconds in game passed.
At 8.673842603340745 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0030,  0.5950],
         [-0.0029,  0.3511],
         [-0.0037,  0.2519],
         [-0.0038,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0189518140316858
Current mitigation activation: 0
#############################
Total reward: 35.0078168180686
8.698842603713274 seconds in game passed.
Action: tensor([[[ 0.0030,  0.5950],
         [-0.0029,  0.3511],
         [-0.0037,  0.2519],
         [-0.0038,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.0078168180686
8.723842604085803 seconds in game passed.
Action: tensor([[[ 0.0030,  0.5950],
         [-0.0029,  0.3511],
         [-0.0037,  0.2519],
         [-0.0038,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.0078168180686
8.748842604458332 seconds in game passed.
Action: tensor([[[ 0.0030,  0.5950],
         [-0.0029,  0.3511],
         [-0.0037,  0.2519],
         [-0.0038,  0.1986]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.003929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 35.0078168180686
+++++++++++++: inf
8.773842604830861 seconds in game passed.
At 8.773842604830861 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0036,  0.6043],
         [-0.0024,  0.3697],
         [-0.0046,  0.2698],
         [-0.0054,  0.2146]]])
agent 0 action: VehicleControl(throttle=0.639065, steer=-0.003122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.017524773867324
Current mitigation activation: 0
#############################
Total reward: 36.02534159193592
8.79884260520339 seconds in game passed.
Action: tensor([[[ 0.0036,  0.6043],
         [-0.0024,  0.3697],
         [-0.0046,  0.2698],
         [-0.0054,  0.2146]]])
agent 0 action: VehicleControl(throttle=0.691196, steer=-0.003066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.02534159193592
8.82384260557592 seconds in game passed.
Action: tensor([[[ 0.0036,  0.6043],
         [-0.0024,  0.3697],
         [-0.0046,  0.2698],
         [-0.0054,  0.2146]]])
agent 0 action: VehicleControl(throttle=0.694428, steer=-0.002902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.02534159193592
8.848842605948448 seconds in game passed.
Action: tensor([[[ 0.0036,  0.6043],
         [-0.0024,  0.3697],
         [-0.0046,  0.2698],
         [-0.0054,  0.2146]]])
agent 0 action: VehicleControl(throttle=0.697767, steer=-0.002738, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.02534159193592
+++++++++++++: inf
8.873842606320977 seconds in game passed.
At 8.873842606320977 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0042,  0.6036],
         [-0.0095,  0.3652],
         [-0.0150,  0.2653],
         [-0.0196,  0.2103]]])
agent 0 action: VehicleControl(throttle=0.826458, steer=-0.010920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.016094554371317
Current mitigation activation: 0
#############################
Total reward: 37.041436146307234
8.898842606693506 seconds in game passed.
Action: tensor([[[-0.0042,  0.6036],
         [-0.0095,  0.3652],
         [-0.0150,  0.2653],
         [-0.0196,  0.2103]]])
agent 0 action: VehicleControl(throttle=0.819066, steer=-0.009400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.041436146307234
8.923842607066035 seconds in game passed.
Action: tensor([[[-0.0042,  0.6036],
         [-0.0095,  0.3652],
         [-0.0150,  0.2653],
         [-0.0196,  0.2103]]])
agent 0 action: VehicleControl(throttle=0.825034, steer=-0.009266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.041436146307234
8.948842607438564 seconds in game passed.
Action: tensor([[[-0.0042,  0.6036],
         [-0.0095,  0.3652],
         [-0.0150,  0.2653],
         [-0.0196,  0.2103]]])
agent 0 action: VehicleControl(throttle=0.830974, steer=-0.009132, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.041436146307234
+++++++++++++: inf
8.973842607811093 seconds in game passed.
At 8.973842607811093 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0118,  0.6380],
         [-0.0159,  0.3773],
         [-0.0202,  0.2693],
         [-0.0240,  0.2104]]])
agent 0 action: VehicleControl(throttle=0.841518, steer=-0.016941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.014654332039721
Current mitigation activation: 0
#############################
Total reward: 38.05609047834695
8.998842608183622 seconds in game passed.
Action: tensor([[[-0.0118,  0.6380],
         [-0.0159,  0.3773],
         [-0.0202,  0.2693],
         [-0.0240,  0.2104]]])
agent 0 action: VehicleControl(throttle=0.844644, steer=-0.015615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.05609047834695
9.023842608556151 seconds in game passed.
Action: tensor([[[-0.0118,  0.6380],
         [-0.0159,  0.3773],
         [-0.0202,  0.2693],
         [-0.0240,  0.2104]]])
agent 0 action: VehicleControl(throttle=0.802540, steer=-0.015594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.05609047834695
9.04884260892868 seconds in game passed.
Action: tensor([[[-0.0118,  0.6380],
         [-0.0159,  0.3773],
         [-0.0202,  0.2693],
         [-0.0240,  0.2104]]])
agent 0 action: VehicleControl(throttle=0.770922, steer=-0.015573, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 38.05609047834695
+++++++++++++: inf
9.07384260930121 seconds in game passed.
At 9.07384260930121 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0125,  0.6412],
         [-0.0169,  0.3764],
         [-0.0215,  0.2710],
         [-0.0252,  0.2133]]])
agent 0 action: VehicleControl(throttle=0.793388, steer=-0.016703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.029148324239015
Current mitigation activation: 0
#############################
Total reward: 39.08523880258597
9.098842609673738 seconds in game passed.
Action: tensor([[[-0.0125,  0.6412],
         [-0.0169,  0.3764],
         [-0.0215,  0.2710],
         [-0.0252,  0.2133]]])
agent 0 action: VehicleControl(throttle=0.758609, steer=-0.016671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.08523880258597
9.123842610046268 seconds in game passed.
Action: tensor([[[-0.0125,  0.6412],
         [-0.0169,  0.3764],
         [-0.0215,  0.2710],
         [-0.0252,  0.2133]]])
agent 0 action: VehicleControl(throttle=0.730925, steer=-0.016804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.08523880258597
9.148842610418797 seconds in game passed.
Action: tensor([[[-0.0125,  0.6412],
         [-0.0169,  0.3764],
         [-0.0215,  0.2710],
         [-0.0252,  0.2133]]])
agent 0 action: VehicleControl(throttle=0.704303, steer=-0.016938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.08523880258597
+++++++++++++: inf
9.173842610791326 seconds in game passed.
At 9.173842610791326 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0112,  0.6809],
         [-0.0168,  0.3878],
         [-0.0243,  0.2679],
         [-0.0316,  0.2022]]])
agent 0 action: VehicleControl(throttle=0.724192, steer=-0.016661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0679814368165697
Current mitigation activation: 0
#############################
Total reward: 40.153220239402536
9.198842611163855 seconds in game passed.
Action: tensor([[[-0.0112,  0.6809],
         [-0.0168,  0.3878],
         [-0.0243,  0.2679],
         [-0.0316,  0.2022]]])
agent 0 action: VehicleControl(throttle=0.689974, steer=-0.016937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.153220239402536
9.223842611536384 seconds in game passed.
Action: tensor([[[-0.0112,  0.6809],
         [-0.0168,  0.3878],
         [-0.0243,  0.2679],
         [-0.0316,  0.2022]]])
agent 0 action: VehicleControl(throttle=0.662266, steer=-0.017135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.153220239402536
9.248842611908913 seconds in game passed.
Action: tensor([[[-0.0112,  0.6809],
         [-0.0168,  0.3878],
         [-0.0243,  0.2679],
         [-0.0316,  0.2022]]])
agent 0 action: VehicleControl(throttle=0.635505, steer=-0.017332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.153220239402536
+++++++++++++: inf
9.273842612281442 seconds in game passed.
At 9.273842612281442 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0137,  0.7150],
         [-0.0193,  0.4261],
         [-0.0207,  0.3018],
         [-0.0220,  0.2303]]])
agent 0 action: VehicleControl(throttle=0.231115, steer=-0.020360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0993134867768242
Current mitigation activation: 0
#############################
Total reward: 41.25253372617936
9.29884261265397 seconds in game passed.
Action: tensor([[[-0.0137,  0.7150],
         [-0.0193,  0.4261],
         [-0.0207,  0.3018],
         [-0.0220,  0.2303]]])
agent 0 action: VehicleControl(throttle=0.264575, steer=-0.019967, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.25253372617936
9.3238426130265 seconds in game passed.
Action: tensor([[[-0.0137,  0.7150],
         [-0.0193,  0.4261],
         [-0.0207,  0.3018],
         [-0.0220,  0.2303]]])
agent 0 action: VehicleControl(throttle=0.255677, steer=-0.020062, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.25253372617936
9.348842613399029 seconds in game passed.
Action: tensor([[[-0.0137,  0.7150],
         [-0.0193,  0.4261],
         [-0.0207,  0.3018],
         [-0.0220,  0.2303]]])
agent 0 action: VehicleControl(throttle=0.247054, steer=-0.020157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.25253372617936
+++++++++++++: inf
9.373842613771558 seconds in game passed.
At 9.373842613771558 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-7.8031e-04,  6.2055e-01],
         [ 6.6620e-04,  3.8214e-01],
         [ 1.6764e-06,  2.8531e-01],
         [-1.8192e-03,  2.3229e-01]]])
agent 0 action: VehicleControl(throttle=0.237227, steer=-0.000232, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1236402097108913
Current mitigation activation: 0
#############################
Total reward: 42.37617393589025
9.398842614144087 seconds in game passed.
Action: tensor([[[-7.8031e-04,  6.2055e-01],
         [ 6.6620e-04,  3.8214e-01],
         [ 1.6764e-06,  2.8531e-01],
         [-1.8192e-03,  2.3229e-01]]])
agent 0 action: VehicleControl(throttle=0.227719, steer=-0.003519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.37617393589025
9.423842614516616 seconds in game passed.
Action: tensor([[[-7.8031e-04,  6.2055e-01],
         [ 6.6620e-04,  3.8214e-01],
         [ 1.6764e-06,  2.8531e-01],
         [-1.8192e-03,  2.3229e-01]]])
agent 0 action: VehicleControl(throttle=0.218547, steer=-0.003489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.37617393589025
9.448842614889145 seconds in game passed.
Action: tensor([[[-7.8031e-04,  6.2055e-01],
         [ 6.6620e-04,  3.8214e-01],
         [ 1.6764e-06,  2.8531e-01],
         [-1.8192e-03,  2.3229e-01]]])
agent 0 action: VehicleControl(throttle=0.209724, steer=-0.003460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 42.37617393589025
+++++++++++++: inf
9.473842615261674 seconds in game passed.
At 9.473842615261674 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.2996e-03, 6.1846e-01],
         [3.6635e-03, 3.5891e-01],
         [2.3614e-03, 2.5771e-01],
         [5.5802e-04, 2.0394e-01]]])
agent 0 action: VehicleControl(throttle=0.723498, steer=0.001758, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1353173555035634
Current mitigation activation: 0
#############################
Total reward: 43.51149129139382
9.498842615634203 seconds in game passed.
Action: tensor([[[6.2996e-03, 6.1846e-01],
         [3.6635e-03, 3.5891e-01],
         [2.3614e-03, 2.5771e-01],
         [5.5802e-04, 2.0394e-01]]])
agent 0 action: VehicleControl(throttle=0.670211, steer=0.001018, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.51149129139382
9.523842616006732 seconds in game passed.
Action: tensor([[[6.2996e-03, 6.1846e-01],
         [3.6635e-03, 3.5891e-01],
         [2.3614e-03, 2.5771e-01],
         [5.5802e-04, 2.0394e-01]]])
agent 0 action: VehicleControl(throttle=0.673056, steer=0.001129, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.51149129139382
9.548842616379261 seconds in game passed.
Action: tensor([[[6.2996e-03, 6.1846e-01],
         [3.6635e-03, 3.5891e-01],
         [2.3614e-03, 2.5771e-01],
         [5.5802e-04, 2.0394e-01]]])
agent 0 action: VehicleControl(throttle=0.675420, steer=0.001240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.51149129139382
+++++++++++++: inf
9.57384261675179 seconds in game passed.
At 9.57384261675179 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.6019e-04,  6.0913e-01],
         [ 1.1290e-03,  3.5935e-01],
         [ 6.7168e-04,  2.6094e-01],
         [-4.7679e-04,  2.0891e-01]]])
agent 0 action: VehicleControl(throttle=0.560686, steer=-0.003247, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.136736464290912
Current mitigation activation: 0
#############################
Total reward: 44.64822775568473
9.598842617124319 seconds in game passed.
Action: tensor([[[-1.6019e-04,  6.0913e-01],
         [ 1.1290e-03,  3.5935e-01],
         [ 6.7168e-04,  2.6094e-01],
         [-4.7679e-04,  2.0891e-01]]])
agent 0 action: VehicleControl(throttle=0.564775, steer=-0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.64822775568473
9.623842617496848 seconds in game passed.
Action: tensor([[[-1.6019e-04,  6.0913e-01],
         [ 1.1290e-03,  3.5935e-01],
         [ 6.7168e-04,  2.6094e-01],
         [-4.7679e-04,  2.0891e-01]]])
agent 0 action: VehicleControl(throttle=0.555552, steer=-0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.64822775568473
9.648842617869377 seconds in game passed.
Action: tensor([[[-1.6019e-04,  6.0913e-01],
         [ 1.1290e-03,  3.5935e-01],
         [ 6.7168e-04,  2.6094e-01],
         [-4.7679e-04,  2.0891e-01]]])
agent 0 action: VehicleControl(throttle=0.545648, steer=-0.002453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.64822775568473
+++++++++++++: inf
9.673842618241906 seconds in game passed.
At 9.673842618241906 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.6871e-03, 6.0908e-01],
         [3.0409e-03, 3.7185e-01],
         [1.7742e-03, 2.7088e-01],
         [1.3634e-04, 2.1622e-01]]])
agent 0 action: VehicleControl(throttle=0.165771, steer=0.000146, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1397043122785897
Current mitigation activation: 0
#############################
Total reward: 45.78793206796332
9.698842618614435 seconds in game passed.
Action: tensor([[[2.6871e-03, 6.0908e-01],
         [3.0409e-03, 3.7185e-01],
         [1.7742e-03, 2.7088e-01],
         [1.3634e-04, 2.1622e-01]]])
agent 0 action: VehicleControl(throttle=0.188194, steer=-0.000238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.78793206796332
9.723842618986964 seconds in game passed.
Action: tensor([[[2.6871e-03, 6.0908e-01],
         [3.0409e-03, 3.7185e-01],
         [1.7742e-03, 2.7088e-01],
         [1.3634e-04, 2.1622e-01]]])
agent 0 action: VehicleControl(throttle=0.171680, steer=-0.000195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.78793206796332
9.748842619359493 seconds in game passed.
Action: tensor([[[2.6871e-03, 6.0908e-01],
         [3.0409e-03, 3.7185e-01],
         [1.7742e-03, 2.7088e-01],
         [1.3634e-04, 2.1622e-01]]])
agent 0 action: VehicleControl(throttle=0.157330, steer=-0.000152, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 45.78793206796332
+++++++++++++: inf
9.773842619732022 seconds in game passed.
At 9.773842619732022 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.3955e-04,  6.2681e-01],
         [ 7.9524e-04,  3.5771e-01],
         [-2.6126e-04,  2.5034e-01],
         [-1.6331e-03,  1.9428e-01]]])
agent 0 action: VehicleControl(throttle=0.750189, steer=-0.002680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1466296341618096
Current mitigation activation: 0
#############################
Total reward: 46.93456170212513
9.798842620104551 seconds in game passed.
Action: tensor([[[ 4.3955e-04,  6.2681e-01],
         [ 7.9524e-04,  3.5771e-01],
         [-2.6126e-04,  2.5034e-01],
         [-1.6331e-03,  1.9428e-01]]])
agent 0 action: VehicleControl(throttle=0.688337, steer=-0.002248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93456170212513
9.82384262047708 seconds in game passed.
Action: tensor([[[ 4.3955e-04,  6.2681e-01],
         [ 7.9524e-04,  3.5771e-01],
         [-2.6126e-04,  2.5034e-01],
         [-1.6331e-03,  1.9428e-01]]])
agent 0 action: VehicleControl(throttle=0.691462, steer=-0.002238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93456170212513
9.84884262084961 seconds in game passed.
Action: tensor([[[ 4.3955e-04,  6.2681e-01],
         [ 7.9524e-04,  3.5771e-01],
         [-2.6126e-04,  2.5034e-01],
         [-1.6331e-03,  1.9428e-01]]])
agent 0 action: VehicleControl(throttle=0.694424, steer=-0.002229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.93456170212513
+++++++++++++: inf
9.873842621222138 seconds in game passed.
At 9.873842621222138 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0097,  0.6173],
         [-0.0143,  0.3477],
         [-0.0185,  0.2456],
         [-0.0224,  0.1917]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.017318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1478557819318804
Current mitigation activation: 0
#############################
Total reward: 48.08241748405701
9.898842621594667 seconds in game passed.
Action: tensor([[[-0.0097,  0.6173],
         [-0.0143,  0.3477],
         [-0.0185,  0.2456],
         [-0.0224,  0.1917]]])
agent 0 action: VehicleControl(throttle=0.891368, steer=-0.014873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.08241748405701
9.923842621967196 seconds in game passed.
Action: tensor([[[-0.0097,  0.6173],
         [-0.0143,  0.3477],
         [-0.0185,  0.2456],
         [-0.0224,  0.1917]]])
agent 0 action: VehicleControl(throttle=0.889422, steer=-0.014934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.08241748405701
9.948842622339725 seconds in game passed.
Action: tensor([[[-0.0097,  0.6173],
         [-0.0143,  0.3477],
         [-0.0185,  0.2456],
         [-0.0224,  0.1917]]])
agent 0 action: VehicleControl(throttle=0.883844, steer=-0.014994, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.08241748405701
+++++++++++++: inf
9.973842622712255 seconds in game passed.
At 9.973842622712255 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0060,  0.6294],
         [-0.0102,  0.3338],
         [-0.0121,  0.2272],
         [-0.0134,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.010499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.150219672705274
Current mitigation activation: 0
#############################
Total reward: 49.23263715676229
9.998842623084784 seconds in game passed.
Action: tensor([[[-0.0060,  0.6294],
         [-0.0102,  0.3338],
         [-0.0121,  0.2272],
         [-0.0134,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011170, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.23263715676229
10.023842623457313 seconds in game passed.
Action: tensor([[[-0.0060,  0.6294],
         [-0.0102,  0.3338],
         [-0.0121,  0.2272],
         [-0.0134,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.23263715676229
10.048842623829842 seconds in game passed.
Action: tensor([[[-0.0060,  0.6294],
         [-0.0102,  0.3338],
         [-0.0121,  0.2272],
         [-0.0134,  0.1735]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.011035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 49.23263715676229
+++++++++++++: inf
10.07384262420237 seconds in game passed.
At 10.07384262420237 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.6265],
         [-0.0022,  0.3304],
         [-0.0022,  0.2243],
         [-0.0021,  0.1709]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1649907287271892
Current mitigation activation: 0
#############################
Total reward: 50.39762788548948
10.0988426245749 seconds in game passed.
Action: tensor([[[-0.0034,  0.6265],
         [-0.0022,  0.3304],
         [-0.0022,  0.2243],
         [-0.0021,  0.1709]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005009, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.39762788548948
10.123842624947429 seconds in game passed.
Action: tensor([[[-0.0034,  0.6265],
         [-0.0022,  0.3304],
         [-0.0022,  0.2243],
         [-0.0021,  0.1709]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004859, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.39762788548948
10.148842625319958 seconds in game passed.
Action: tensor([[[-0.0034,  0.6265],
         [-0.0022,  0.3304],
         [-0.0022,  0.2243],
         [-0.0021,  0.1709]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.39762788548948
+++++++++++++: inf
10.173842625692487 seconds in game passed.
At 10.173842625692487 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.6102],
         [-0.0029,  0.3271],
         [-0.0035,  0.2233],
         [-0.0041,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.005106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1886565975813836
Current mitigation activation: 0
#############################
Total reward: 51.58628448307086
10.198842626065016 seconds in game passed.
Action: tensor([[[-0.0035,  0.6102],
         [-0.0029,  0.3271],
         [-0.0035,  0.2233],
         [-0.0041,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004878, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.58628448307086
10.223842626437545 seconds in game passed.
Action: tensor([[[-0.0035,  0.6102],
         [-0.0029,  0.3271],
         [-0.0035,  0.2233],
         [-0.0041,  0.1701]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.004739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 51.58628448307086
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [91mFAILURE[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-27 21:01:17 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-27 21:01:38 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 20.84s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 8.7s                │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.418               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ FAILURE │ 31.38 % │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ FAILURE │ 1 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 51.59, average_reward: 51.58628448307086 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_lead_cutin_acc_only_lbc_ttc_redo/SINGLE_AGENT_fi_lead_cutin_00000/fi_lead_cutin_data
