New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004105-fi_ghost_cutin_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004105-fi_ghost_cutin_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004105-fi_ghost_cutin_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004105-fi_ghost_cutin_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004105-fi_ghost_cutin_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004105-fi_ghost_cutin_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_data/route_highway.xml_fi_ghost_cutin.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key distance_same_lane's value from 15 to 10.
Replacing key distance_lane_change's value from 11 to 6.
Replacing key speed_lane_change's value from 13.5 to 14.
Config for GhostCutIn scenario is {'first_vehicle_location': 0, 'first_vehicle_speed': 200, 'event_trigger_distance': 4, 'distance_lane_change': 6, 'speed_lane_change': 14, 'distance_same_lane': 10}
2.257349409162998 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.2823494095355272 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3073494099080563 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3323494102805853 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.3573494106531143 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0024, 0.3305],
         [0.0022, 0.2343],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002750, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.3823494110256433 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003880, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4073494113981724 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003742, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4323494117707014 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003786, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4573494121432304 seconds in game passed.
Action: tensor([[[0.0054, 0.5909],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0024, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003830, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.4823494125157595 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003172, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5073494128882885 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5323494132608175 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5573494136333466 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5823494140058756 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.6073494143784046 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6323494147509336 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6573494151234627 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6823494154959917 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.7073494158685207 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7323494162410498 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.757349416613579 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.782349416986108 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.807349417358637 seconds in game passed.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.832349417731166 seconds in game passed.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.857349418103695 seconds in game passed.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 20297.16684299258
2.882349418476224 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.907349418848753 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.932349419221282 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.957349419593811 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.71016465861
2.98234941996634 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
3.007349420338869 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.032349420711398 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.057349421083927 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0015, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.082349421456456 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002703, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.107349421828985 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1323494222015142 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.1573494225740433 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.1823494229465723 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002773, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.2073494233191013 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002793, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2323494236916304 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2573494240641594 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.2823494244366884 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5890],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3073494248092175 seconds in game passed.
Action: tensor([[[0.0020, 0.5890],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002652, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3323494251817465 seconds in game passed.
Action: tensor([[[0.0020, 0.5890],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3573494255542755 seconds in game passed.
Action: tensor([[[0.0020, 0.5890],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3823494259268045 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4073494262993336 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4323494266718626 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4573494270443916 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.6593486434
3.4823494274169207 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
3.5073494277894497 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5323494281619787 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002473, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5573494285345078 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.582349428907037 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.607349429279566 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.632349429652095 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.657349430024624 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.682349430397153 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.707349430769682 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.732349431142211 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.75734943151474 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.782349431887269 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002560, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.807349432259798 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.832349432632327 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.857349433004856 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.882349433377385 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.907349433749914 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.932349434122443 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.9573494344949722 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3212],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.9823494348675013 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.00734943524003 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.032349435612559 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.057349435985088 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.082349436357617 seconds in game passed.
At 4.082349436357617 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002263, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.107349436730146 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002290, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.132349437102675 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.1573494374752045 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.1823494378477335 seconds in game passed.
At 4.1823494378477335 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.2073494382202625 seconds in game passed.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.232349438592792 seconds in game passed.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.257349438965321 seconds in game passed.
Action: tensor([[[0.0016, 0.5871],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.28234943933785 seconds in game passed.
At 4.28234943933785 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.307349439710379 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.332349440082908 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.357349440455437 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.382349440827966 seconds in game passed.
At 4.382349440827966 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.407349441200495 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002402, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.432349441573024 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.457349441945553 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.482349442318082 seconds in game passed.
At 4.482349442318082 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.507349442690611 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.53234944306314 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.557349443435669 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.582349443808198 seconds in game passed.
At 4.582349443808198 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.607349444180727 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.632349444553256 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.657349444925785 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.682349445298314 seconds in game passed.
At 4.682349445298314 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0.06602266588708589
4.707349445670843 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.732349446043372 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.757349446415901 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
+++++++++++++: inf
4.78234944678843 seconds in game passed.
At 4.78234944678843 seconds, saving state-action tuples.
Action: tensor([[[1.4063e-03, 5.8602e-01],
         [1.1322e-03, 3.2065e-01],
         [9.9931e-04, 2.2099e-01],
         [3.4845e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.3145396919977081
4.807349447160959 seconds in game passed.
Action: tensor([[[1.4063e-03, 5.8602e-01],
         [1.1322e-03, 3.2065e-01],
         [9.9931e-04, 2.2099e-01],
         [3.4845e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.832349447533488 seconds in game passed.
Action: tensor([[[1.4063e-03, 5.8602e-01],
         [1.1322e-03, 3.2065e-01],
         [9.9931e-04, 2.2099e-01],
         [3.4845e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.857349447906017 seconds in game passed.
Action: tensor([[[1.4063e-03, 5.8602e-01],
         [1.1322e-03, 3.2065e-01],
         [9.9931e-04, 2.2099e-01],
         [3.4845e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
+++++++++++++: inf
4.882349448278546 seconds in game passed.
At 4.882349448278546 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.7221479506394559
4.907349448651075 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.932349449023604 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002100, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.957349449396133 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
+++++++++++++: inf
4.9823494497686625 seconds in game passed.
At 4.9823494497686625 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5812],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.541619495703239
Current mitigation activation: 0
#############################
Total reward: 1.263767446342695
5.0073494501411915 seconds in game passed.
Action: tensor([[[0.0016, 0.5812],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
5.0323494505137205 seconds in game passed.
Action: tensor([[[0.0016, 0.5812],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
5.0573494508862495 seconds in game passed.
Action: tensor([[[0.0016, 0.5812],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002186, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
+++++++++++++: inf
5.082349451258779 seconds in game passed.
At 5.082349451258779 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0026, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.6535768229361686
Current mitigation activation: 0
#############################
Total reward: 1.9173442692788636
5.107349451631308 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0026, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
5.132349452003837 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0026, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
5.157349452376366 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0026, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
+++++++++++++: inf
5.182349452748895 seconds in game passed.
At 5.182349452748895 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.7480164605334304
Current mitigation activation: 0
#############################
Total reward: 2.665360729812294
5.207349453121424 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.665360729812294
5.232349453493953 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.665360729812294
5.257349453866482 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.665360729812294
+++++++++++++: inf
5.282349454239011 seconds in game passed.
At 5.282349454239011 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.1645e-05,  5.8851e-01],
         [-5.0701e-05,  3.2182e-01],
         [ 4.1060e-05,  2.2106e-01],
         [-3.4557e-04,  1.6703e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000383, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8290660923172777
Current mitigation activation: 0
#############################
Total reward: 3.4944268221295713
5.30734945461154 seconds in game passed.
Action: tensor([[[ 1.1645e-05,  5.8851e-01],
         [-5.0701e-05,  3.2182e-01],
         [ 4.1060e-05,  2.2106e-01],
         [-3.4557e-04,  1.6703e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944268221295713
5.332349454984069 seconds in game passed.
Action: tensor([[[ 1.1645e-05,  5.8851e-01],
         [-5.0701e-05,  3.2182e-01],
         [ 4.1060e-05,  2.2106e-01],
         [-3.4557e-04,  1.6703e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944268221295713
5.357349455356598 seconds in game passed.
Action: tensor([[[ 1.1645e-05,  5.8851e-01],
         [-5.0701e-05,  3.2182e-01],
         [ 4.1060e-05,  2.2106e-01],
         [-3.4557e-04,  1.6703e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944268221295713
+++++++++++++: inf
5.382349455729127 seconds in game passed.
At 5.382349455729127 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.2001e-04,  5.8922e-01],
         [-2.4032e-04,  3.2120e-01],
         [-1.8649e-04,  2.2088e-01],
         [-4.3317e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8996363842488972
Current mitigation activation: 0
#############################
Total reward: 4.394063206378469
5.407349456101656 seconds in game passed.
Action: tensor([[[ 3.2001e-04,  5.8922e-01],
         [-2.4032e-04,  3.2120e-01],
         [-1.8649e-04,  2.2088e-01],
         [-4.3317e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394063206378469
5.432349456474185 seconds in game passed.
Action: tensor([[[ 3.2001e-04,  5.8922e-01],
         [-2.4032e-04,  3.2120e-01],
         [-1.8649e-04,  2.2088e-01],
         [-4.3317e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000604, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394063206378469
5.457349456846714 seconds in game passed.
Action: tensor([[[ 3.2001e-04,  5.8922e-01],
         [-2.4032e-04,  3.2120e-01],
         [-1.8649e-04,  2.2088e-01],
         [-4.3317e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394063206378469
+++++++++++++: inf
5.482349457219243 seconds in game passed.
At 5.482349457219243 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.4871e-04,  5.9114e-01],
         [-1.0510e-03,  3.2139e-01],
         [-9.0942e-04,  2.2095e-01],
         [-1.0526e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.962209169765081
Current mitigation activation: 0
#############################
Total reward: 5.35627237614355
5.507349457591772 seconds in game passed.
Action: tensor([[[-4.4871e-04,  5.9114e-01],
         [-1.0510e-03,  3.2139e-01],
         [-9.0942e-04,  2.2095e-01],
         [-1.0526e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.35627237614355
5.532349457964301 seconds in game passed.
Action: tensor([[[-4.4871e-04,  5.9114e-01],
         [-1.0510e-03,  3.2139e-01],
         [-9.0942e-04,  2.2095e-01],
         [-1.0526e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000251, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.35627237614355
5.55734945833683 seconds in game passed.
Action: tensor([[[-4.4871e-04,  5.9114e-01],
         [-1.0510e-03,  3.2139e-01],
         [-9.0942e-04,  2.2095e-01],
         [-1.0526e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.35627237614355
+++++++++++++: inf
5.582349458709359 seconds in game passed.
At 5.582349458709359 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.8061e-04,  5.9020e-01],
         [-3.6302e-04,  3.2152e-01],
         [-2.3831e-04,  2.2103e-01],
         [-3.1757e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0188346436642688
Current mitigation activation: 0
#############################
Total reward: 6.375107019807818
5.607349459081888 seconds in game passed.
Action: tensor([[[ 7.8061e-04,  5.9020e-01],
         [-3.6302e-04,  3.2152e-01],
         [-2.3831e-04,  2.2103e-01],
         [-3.1757e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000505, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375107019807818
5.632349459454417 seconds in game passed.
Action: tensor([[[ 7.8061e-04,  5.9020e-01],
         [-3.6302e-04,  3.2152e-01],
         [-2.3831e-04,  2.2103e-01],
         [-3.1757e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375107019807818
5.657349459826946 seconds in game passed.
Action: tensor([[[ 7.8061e-04,  5.9020e-01],
         [-3.6302e-04,  3.2152e-01],
         [-2.3831e-04,  2.2103e-01],
         [-3.1757e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375107019807818
+++++++++++++: inf
5.682349460199475 seconds in game passed.
At 5.682349460199475 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5880],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.07104450827436
Current mitigation activation: 0
#############################
Total reward: 7.446151528082178
5.707349460572004 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446151528082178
5.732349460944533 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001618, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446151528082178
5.757349461317062 seconds in game passed.
Action: tensor([[[0.0018, 0.5880],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446151528082178
+++++++++++++: inf
5.782349461689591 seconds in game passed.
At 5.782349461689591 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2972e-03, 5.8977e-01],
         [8.7887e-04, 3.2203e-01],
         [7.5083e-04, 2.2272e-01],
         [3.9126e-04, 1.6869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001322, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1199918056465623
Current mitigation activation: 0
#############################
Total reward: 8.566143333728741
5.80734946206212 seconds in game passed.
Action: tensor([[[1.2972e-03, 5.8977e-01],
         [8.7887e-04, 3.2203e-01],
         [7.5083e-04, 2.2272e-01],
         [3.9126e-04, 1.6869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566143333728741
5.8323494624346495 seconds in game passed.
Action: tensor([[[1.2972e-03, 5.8977e-01],
         [8.7887e-04, 3.2203e-01],
         [7.5083e-04, 2.2272e-01],
         [3.9126e-04, 1.6869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566143333728741
5.8573494628071785 seconds in game passed.
Action: tensor([[[1.2972e-03, 5.8977e-01],
         [8.7887e-04, 3.2203e-01],
         [7.5083e-04, 2.2272e-01],
         [3.9126e-04, 1.6869e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566143333728741
+++++++++++++: inf
5.8823494631797075 seconds in game passed.
At 5.8823494631797075 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5848],
         [0.0020, 0.3191],
         [0.0019, 0.2209],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1663832448568863
Current mitigation activation: 0
#############################
Total reward: 9.732526578585627
5.907349463552237 seconds in game passed.
Action: tensor([[[0.0016, 0.5848],
         [0.0020, 0.3191],
         [0.0019, 0.2209],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732526578585627
5.932349463924766 seconds in game passed.
Action: tensor([[[0.0016, 0.5848],
         [0.0020, 0.3191],
         [0.0019, 0.2209],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732526578585627
5.957349464297295 seconds in game passed.
Action: tensor([[[0.0016, 0.5848],
         [0.0020, 0.3191],
         [0.0019, 0.2209],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002129, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732526578585627
+++++++++++++: inf
5.982349464669824 seconds in game passed.
At 5.982349464669824 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2107462073921762
Current mitigation activation: 0
#############################
Total reward: 10.943272785977804
6.007349465042353 seconds in game passed.
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943272785977804
6.032349465414882 seconds in game passed.
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943272785977804
6.057349465787411 seconds in game passed.
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943272785977804
+++++++++++++: inf
6.08234946615994 seconds in game passed.
At 6.08234946615994 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5909],
         [0.0015, 0.3210],
         [0.0016, 0.2205],
         [0.0013, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.253504995220451
Current mitigation activation: 0
#############################
Total reward: 12.196777781198255
6.107349466532469 seconds in game passed.
Action: tensor([[[0.0016, 0.5909],
         [0.0015, 0.3210],
         [0.0016, 0.2205],
         [0.0013, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196777781198255
6.132349466904998 seconds in game passed.
Action: tensor([[[0.0016, 0.5909],
         [0.0015, 0.3210],
         [0.0016, 0.2205],
         [0.0013, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196777781198255
6.157349467277527 seconds in game passed.
Action: tensor([[[0.0016, 0.5909],
         [0.0015, 0.3210],
         [0.0016, 0.2205],
         [0.0013, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196777781198255
+++++++++++++: inf
6.182349467650056 seconds in game passed.
At 6.182349467650056 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0402e-03, 5.8978e-01],
         [6.4328e-04, 3.2033e-01],
         [6.3111e-04, 2.1991e-01],
         [3.2369e-04, 1.6599e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2799438329900252
Current mitigation activation: 0
#############################
Total reward: 13.47672161418828
6.207349468022585 seconds in game passed.
Action: tensor([[[1.0402e-03, 5.8978e-01],
         [6.4328e-04, 3.2033e-01],
         [6.3111e-04, 2.1991e-01],
         [3.2369e-04, 1.6599e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001065, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.47672161418828
6.232349468395114 seconds in game passed.
Action: tensor([[[1.0402e-03, 5.8978e-01],
         [6.4328e-04, 3.2033e-01],
         [6.3111e-04, 2.1991e-01],
         [3.2369e-04, 1.6599e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.47672161418828
6.257349468767643 seconds in game passed.
Action: tensor([[[1.0402e-03, 5.8978e-01],
         [6.4328e-04, 3.2033e-01],
         [6.3111e-04, 2.1991e-01],
         [3.2369e-04, 1.6599e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.47672161418828
+++++++++++++: inf
6.282349469140172 seconds in game passed.
At 6.282349469140172 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.7414e-04,  5.9113e-01],
         [-2.9527e-04,  3.2046e-01],
         [-4.8493e-04,  2.1969e-01],
         [-9.3008e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.278468999070138
Current mitigation activation: 0
#############################
Total reward: 14.755190613258417
6.307349469512701 seconds in game passed.
Action: tensor([[[ 4.7414e-04,  5.9113e-01],
         [-2.9527e-04,  3.2046e-01],
         [-4.8493e-04,  2.1969e-01],
         [-9.3008e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755190613258417
6.33234946988523 seconds in game passed.
Action: tensor([[[ 4.7414e-04,  5.9113e-01],
         [-2.9527e-04,  3.2046e-01],
         [-4.8493e-04,  2.1969e-01],
         [-9.3008e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755190613258417
6.357349470257759 seconds in game passed.
Action: tensor([[[ 4.7414e-04,  5.9113e-01],
         [-2.9527e-04,  3.2046e-01],
         [-4.8493e-04,  2.1969e-01],
         [-9.3008e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755190613258417
+++++++++++++: inf
6.382349470630288 seconds in game passed.
At 6.382349470630288 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2767191943000114
Current mitigation activation: 0
#############################
Total reward: 16.031909807558428
6.407349471002817 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031909807558428
6.432349471375346 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031909807558428
6.457349471747875 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001279, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031909807558428
+++++++++++++: inf
6.482349472120404 seconds in game passed.
At 6.482349472120404 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.5908],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2749365065470508
Current mitigation activation: 0
#############################
Total reward: 17.306846314105478
6.507349472492933 seconds in game passed.
Action: tensor([[[-0.0011,  0.5908],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306846314105478
6.532349472865462 seconds in game passed.
Action: tensor([[[-0.0011,  0.5908],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306846314105478
6.557349473237991 seconds in game passed.
Action: tensor([[[-0.0011,  0.5908],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306846314105478
+++++++++++++: inf
6.58234947361052 seconds in game passed.
At 6.58234947361052 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.6538e-05,  5.9017e-01],
         [-9.1805e-04,  3.2115e-01],
         [-1.0757e-03,  2.2067e-01],
         [-1.3658e-03,  1.6679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2730962204764769
Current mitigation activation: 0
#############################
Total reward: 18.579942534581953
6.607349473983049 seconds in game passed.
Action: tensor([[[ 3.6538e-05,  5.9017e-01],
         [-9.1805e-04,  3.2115e-01],
         [-1.0757e-03,  2.2067e-01],
         [-1.3658e-03,  1.6679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579942534581953
6.632349474355578 seconds in game passed.
Action: tensor([[[ 3.6538e-05,  5.9017e-01],
         [-9.1805e-04,  3.2115e-01],
         [-1.0757e-03,  2.2067e-01],
         [-1.3658e-03,  1.6679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579942534581953
6.6573494747281075 seconds in game passed.
Action: tensor([[[ 3.6538e-05,  5.9017e-01],
         [-9.1805e-04,  3.2115e-01],
         [-1.0757e-03,  2.2067e-01],
         [-1.3658e-03,  1.6679e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000394, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579942534581953
+++++++++++++: inf
6.6823494751006365 seconds in game passed.
At 6.6823494751006365 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3712e-03,  5.9034e-01],
         [ 1.8900e-04,  3.2129e-01],
         [ 2.1007e-04,  2.2086e-01],
         [-6.6102e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2883820104733363
Current mitigation activation: 0
#############################
Total reward: 19.868324545055287
6.7073494754731655 seconds in game passed.
Action: tensor([[[ 1.3712e-03,  5.9034e-01],
         [ 1.8900e-04,  3.2129e-01],
         [ 2.1007e-04,  2.2086e-01],
         [-6.6102e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868324545055287
6.7323494758456945 seconds in game passed.
Action: tensor([[[ 1.3712e-03,  5.9034e-01],
         [ 1.8900e-04,  3.2129e-01],
         [ 2.1007e-04,  2.2086e-01],
         [-6.6102e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868324545055287
6.757349476218224 seconds in game passed.
Action: tensor([[[ 1.3712e-03,  5.9034e-01],
         [ 1.8900e-04,  3.2129e-01],
         [ 2.1007e-04,  2.2086e-01],
         [-6.6102e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868324545055287
+++++++++++++: inf
6.782349476590753 seconds in game passed.
At 6.782349476590753 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.5909],
         [0.0023, 0.3218],
         [0.0018, 0.2215],
         [0.0008, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3503237992588943
Current mitigation activation: 0
#############################
Total reward: 21.218648344314182
6.807349476963282 seconds in game passed.
Action: tensor([[[0.0028, 0.5909],
         [0.0023, 0.3218],
         [0.0018, 0.2215],
         [0.0008, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218648344314182
6.832349477335811 seconds in game passed.
Action: tensor([[[0.0028, 0.5909],
         [0.0023, 0.3218],
         [0.0018, 0.2215],
         [0.0008, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218648344314182
6.85734947770834 seconds in game passed.
Action: tensor([[[0.0028, 0.5909],
         [0.0023, 0.3218],
         [0.0018, 0.2215],
         [0.0008, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.855779, steer=0.002530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218648344314182
+++++++++++++: inf
6.882349478080869 seconds in game passed.
At 6.882349478080869 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.0813e-03,  5.9209e-01],
         [ 9.4535e-04,  3.2216e-01],
         [ 2.6668e-04,  2.2152e-01],
         [-8.9749e-04,  1.6793e-01]]])
agent 0 action: VehicleControl(throttle=0.806303, steer=0.001224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4066996487303676
Current mitigation activation: 0
#############################
Total reward: 22.62534799304455
6.907349478453398 seconds in game passed.
Action: tensor([[[ 2.0813e-03,  5.9209e-01],
         [ 9.4535e-04,  3.2216e-01],
         [ 2.6668e-04,  2.2152e-01],
         [-8.9749e-04,  1.6793e-01]]])
agent 0 action: VehicleControl(throttle=0.756879, steer=0.001435, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.62534799304455
6.932349478825927 seconds in game passed.
Action: tensor([[[ 2.0813e-03,  5.9209e-01],
         [ 9.4535e-04,  3.2216e-01],
         [ 2.6668e-04,  2.2152e-01],
         [-8.9749e-04,  1.6793e-01]]])
agent 0 action: VehicleControl(throttle=0.708950, steer=0.001430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.62534799304455
6.957349479198456 seconds in game passed.
Action: tensor([[[ 2.0813e-03,  5.9209e-01],
         [ 9.4535e-04,  3.2216e-01],
         [ 2.6668e-04,  2.2152e-01],
         [-8.9749e-04,  1.6793e-01]]])
agent 0 action: VehicleControl(throttle=0.662757, steer=0.001424, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.62534799304455
+++++++++++++: inf
6.982349479570985 seconds in game passed.
At 6.982349479570985 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0154e-04,  5.9639e-01],
         [-6.1093e-04,  3.2304e-01],
         [-1.5030e-03,  2.2110e-01],
         [-2.7883e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.633024, steer=-0.000428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4565143048212634
Current mitigation activation: 0
#############################
Total reward: 24.08186229786581
7.007349479943514 seconds in game passed.
Action: tensor([[[ 3.0154e-04,  5.9639e-01],
         [-6.1093e-04,  3.2304e-01],
         [-1.5030e-03,  2.2110e-01],
         [-2.7883e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.589699, steer=-0.000137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08186229786581
7.032349480316043 seconds in game passed.
Action: tensor([[[ 3.0154e-04,  5.9639e-01],
         [-6.1093e-04,  3.2304e-01],
         [-1.5030e-03,  2.2110e-01],
         [-2.7883e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.550440, steer=-0.000152, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08186229786581
7.057349480688572 seconds in game passed.
Action: tensor([[[ 3.0154e-04,  5.9639e-01],
         [-6.1093e-04,  3.2304e-01],
         [-1.5030e-03,  2.2110e-01],
         [-2.7883e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.513804, steer=-0.000167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08186229786581
+++++++++++++: inf
7.082349481061101 seconds in game passed.
At 7.082349481061101 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.8747e-05,  5.9861e-01],
         [-1.0463e-03,  3.2435e-01],
         [-1.9493e-03,  2.2227e-01],
         [-3.3588e-03,  1.6857e-01]]])
agent 0 action: VehicleControl(throttle=0.455353, steer=-0.000656, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.497322396818132
Current mitigation activation: 0
#############################
Total reward: 25.579184694683942
7.10734948143363 seconds in game passed.
Action: tensor([[[-6.8747e-05,  5.9861e-01],
         [-1.0463e-03,  3.2435e-01],
         [-1.9493e-03,  2.2227e-01],
         [-3.3588e-03,  1.6857e-01]]])
agent 0 action: VehicleControl(throttle=0.427018, steer=-0.000605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579184694683942
7.132349481806159 seconds in game passed.
Action: tensor([[[-6.8747e-05,  5.9861e-01],
         [-1.0463e-03,  3.2435e-01],
         [-1.9493e-03,  2.2227e-01],
         [-3.3588e-03,  1.6857e-01]]])
agent 0 action: VehicleControl(throttle=0.398741, steer=-0.000631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579184694683942
7.157349482178688 seconds in game passed.
Action: tensor([[[-6.8747e-05,  5.9861e-01],
         [-1.0463e-03,  3.2435e-01],
         [-1.9493e-03,  2.2227e-01],
         [-3.3588e-03,  1.6857e-01]]])
agent 0 action: VehicleControl(throttle=0.373420, steer=-0.000657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579184694683942
+++++++++++++: inf
7.182349482551217 seconds in game passed.
At 7.182349482551217 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0041,  0.6096],
         [-0.0063,  0.3268],
         [-0.0079,  0.2222],
         [-0.0094,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.380519, steer=-0.006157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5251171258408434
Current mitigation activation: 0
#############################
Total reward: 27.104301820524785
7.207349482923746 seconds in game passed.
Action: tensor([[[-0.0041,  0.6096],
         [-0.0063,  0.3268],
         [-0.0079,  0.2222],
         [-0.0094,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.358047, steer=-0.005327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104301820524785
7.232349483296275 seconds in game passed.
Action: tensor([[[-0.0041,  0.6096],
         [-0.0063,  0.3268],
         [-0.0079,  0.2222],
         [-0.0094,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.341515, steer=-0.005400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104301820524785
7.257349483668804 seconds in game passed.
Action: tensor([[[-0.0041,  0.6096],
         [-0.0063,  0.3268],
         [-0.0079,  0.2222],
         [-0.0094,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.327354, steer=-0.005474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104301820524785
+++++++++++++: inf
7.282349484041333 seconds in game passed.
At 7.282349484041333 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0029,  0.6078],
         [-0.0051,  0.3267],
         [-0.0062,  0.2225],
         [-0.0072,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.299652, steer=-0.004173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5379761386133077
Current mitigation activation: 0
#############################
Total reward: 28.64227795913809
7.307349484413862 seconds in game passed.
Action: tensor([[[-0.0029,  0.6078],
         [-0.0051,  0.3267],
         [-0.0062,  0.2225],
         [-0.0072,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.291524, steer=-0.004449, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64227795913809
7.332349484786391 seconds in game passed.
Action: tensor([[[-0.0029,  0.6078],
         [-0.0051,  0.3267],
         [-0.0062,  0.2225],
         [-0.0072,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.283875, steer=-0.004499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64227795913809
7.35734948515892 seconds in game passed.
Action: tensor([[[-0.0029,  0.6078],
         [-0.0051,  0.3267],
         [-0.0062,  0.2225],
         [-0.0072,  0.1687]]])
agent 0 action: VehicleControl(throttle=0.278336, steer=-0.004550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64227795913809
+++++++++++++: inf
7.382349485531449 seconds in game passed.
At 7.382349485531449 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.5979],
         [-0.0042,  0.3242],
         [-0.0049,  0.2220],
         [-0.0054,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.261386, steer=-0.003617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5377803731775523
Current mitigation activation: 0
#############################
Total reward: 30.180058332315642
7.407349485903978 seconds in game passed.
Action: tensor([[[-0.0021,  0.5979],
         [-0.0042,  0.3242],
         [-0.0049,  0.2220],
         [-0.0054,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.260815, steer=-0.003798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.180058332315642
7.432349486276507 seconds in game passed.
Action: tensor([[[-0.0021,  0.5979],
         [-0.0042,  0.3242],
         [-0.0049,  0.2220],
         [-0.0054,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.260385, steer=-0.003820, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.180058332315642
7.457349486649036 seconds in game passed.
Action: tensor([[[-0.0021,  0.5979],
         [-0.0042,  0.3242],
         [-0.0049,  0.2220],
         [-0.0054,  0.1681]]])
agent 0 action: VehicleControl(throttle=0.261453, steer=-0.003842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.180058332315642
+++++++++++++: inf
7.482349487021565 seconds in game passed.
At 7.482349487021565 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.5935],
         [-0.0027,  0.3228],
         [-0.0032,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.266667, steer=-0.002250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5277738095987465
Current mitigation activation: 0
#############################
Total reward: 31.707832141914388
7.5073494873940945 seconds in game passed.
Action: tensor([[[-0.0008,  0.5935],
         [-0.0027,  0.3228],
         [-0.0032,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.269825, steer=-0.002516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707832141914388
7.5323494877666235 seconds in game passed.
Action: tensor([[[-0.0008,  0.5935],
         [-0.0027,  0.3228],
         [-0.0032,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.274241, steer=-0.002517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707832141914388
7.5573494881391525 seconds in game passed.
Action: tensor([[[-0.0008,  0.5935],
         [-0.0027,  0.3228],
         [-0.0032,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.279447, steer=-0.002517, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707832141914388
+++++++++++++: inf
7.582349488511682 seconds in game passed.
At 7.582349488511682 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6015],
         [-0.0013,  0.3244],
         [-0.0027,  0.2216],
         [-0.0045,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.311264, steer=-0.000842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5112255467986428
Current mitigation activation: 0
#############################
Total reward: 33.21905768871303
7.607349488884211 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6015],
         [-0.0013,  0.3244],
         [-0.0027,  0.2216],
         [-0.0045,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.315577, steer=-0.001121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21905768871303
7.63234948925674 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6015],
         [-0.0013,  0.3244],
         [-0.0027,  0.2216],
         [-0.0045,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.323304, steer=-0.001121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21905768871303
7.657349489629269 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6015],
         [-0.0013,  0.3244],
         [-0.0027,  0.2216],
         [-0.0045,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.331785, steer=-0.001121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21905768871303
+++++++++++++: inf
7.682349490001798 seconds in game passed.
At 7.682349490001798 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4863e-04,  6.0037e-01],
         [-6.1399e-04,  3.2341e-01],
         [-1.4160e-03,  2.2113e-01],
         [-2.9332e-03,  1.6705e-01]]])
agent 0 action: VehicleControl(throttle=0.366777, steer=-0.000880, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4915587147670397
Current mitigation activation: 0
#############################
Total reward: 34.71061640348007
7.707349490374327 seconds in game passed.
Action: tensor([[[ 1.4863e-04,  6.0037e-01],
         [-6.1399e-04,  3.2341e-01],
         [-1.4160e-03,  2.2113e-01],
         [-2.9332e-03,  1.6705e-01]]])
agent 0 action: VehicleControl(throttle=0.374153, steer=-0.000933, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71061640348007
7.732349490746856 seconds in game passed.
Action: tensor([[[ 1.4863e-04,  6.0037e-01],
         [-6.1399e-04,  3.2341e-01],
         [-1.4160e-03,  2.2113e-01],
         [-2.9332e-03,  1.6705e-01]]])
agent 0 action: VehicleControl(throttle=0.384682, steer=-0.000944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71061640348007
7.757349491119385 seconds in game passed.
Action: tensor([[[ 1.4863e-04,  6.0037e-01],
         [-6.1399e-04,  3.2341e-01],
         [-1.4160e-03,  2.2113e-01],
         [-2.9332e-03,  1.6705e-01]]])
agent 0 action: VehicleControl(throttle=0.395354, steer=-0.000955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71061640348007
+++++++++++++: inf
7.782349491491914 seconds in game passed.
At 7.782349491491914 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7399e-03,  5.9862e-01],
         [-2.6165e-04,  3.2567e-01],
         [-1.1672e-03,  2.2406e-01],
         [-2.5814e-03,  1.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.302931, steer=0.000309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4719913545013281
Current mitigation activation: 0
#############################
Total reward: 36.182607757981394
7.807349491864443 seconds in game passed.
Action: tensor([[[ 2.7399e-03,  5.9862e-01],
         [-2.6165e-04,  3.2567e-01],
         [-1.1672e-03,  2.2406e-01],
         [-2.5814e-03,  1.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.323789, steer=0.000075, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.182607757981394
7.832349492236972 seconds in game passed.
Action: tensor([[[ 2.7399e-03,  5.9862e-01],
         [-2.6165e-04,  3.2567e-01],
         [-1.1672e-03,  2.2406e-01],
         [-2.5814e-03,  1.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.334052, steer=0.000055, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.182607757981394
7.857349492609501 seconds in game passed.
Action: tensor([[[ 2.7399e-03,  5.9862e-01],
         [-2.6165e-04,  3.2567e-01],
         [-1.1672e-03,  2.2406e-01],
         [-2.5814e-03,  1.7017e-01]]])
agent 0 action: VehicleControl(throttle=0.345383, steer=0.000035, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.182607757981394
+++++++++++++: inf
7.88234949298203 seconds in game passed.
At 7.88234949298203 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.5703e-05,  6.0196e-01],
         [-1.1083e-03,  3.2608e-01],
         [-1.5956e-03,  2.2292e-01],
         [-2.6563e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.378587, steer=-0.001677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4545965599658217
Current mitigation activation: 0
#############################
Total reward: 37.637204317947216
7.907349493354559 seconds in game passed.
Action: tensor([[[ 3.5703e-05,  6.0196e-01],
         [-1.1083e-03,  3.2608e-01],
         [-1.5956e-03,  2.2292e-01],
         [-2.6563e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.389143, steer=-0.001420, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.637204317947216
7.932349493727088 seconds in game passed.
Action: tensor([[[ 3.5703e-05,  6.0196e-01],
         [-1.1083e-03,  3.2608e-01],
         [-1.5956e-03,  2.2292e-01],
         [-2.6563e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.402305, steer=-0.001444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.637204317947216
7.957349494099617 seconds in game passed.
Action: tensor([[[ 3.5703e-05,  6.0196e-01],
         [-1.1083e-03,  3.2608e-01],
         [-1.5956e-03,  2.2292e-01],
         [-2.6563e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.415538, steer=-0.001468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.637204317947216
+++++++++++++: inf
7.982349494472146 seconds in game passed.
At 7.982349494472146 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6041],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.415199, steer=-0.004026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4380445802895185
Current mitigation activation: 0
#############################
Total reward: 39.07524889823674
8.007349494844675 seconds in game passed.
Action: tensor([[[-0.0012,  0.6041],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.429472, steer=-0.003636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07524889823674
8.032349495217204 seconds in game passed.
Action: tensor([[[-0.0012,  0.6041],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.442193, steer=-0.003667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07524889823674
8.057349495589733 seconds in game passed.
Action: tensor([[[-0.0012,  0.6041],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.454787, steer=-0.003699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07524889823674
+++++++++++++: inf
8.082349495962262 seconds in game passed.
At 8.082349495962262 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6053],
         [-0.0052,  0.3265],
         [-0.0059,  0.2229],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.500906, steer=-0.005015, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4235544399307187
Current mitigation activation: 0
#############################
Total reward: 40.498803338167455
8.107349496334791 seconds in game passed.
Action: tensor([[[-0.0021,  0.6053],
         [-0.0052,  0.3265],
         [-0.0059,  0.2229],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.510005, steer=-0.004842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.498803338167455
8.13234949670732 seconds in game passed.
Action: tensor([[[-0.0021,  0.6053],
         [-0.0052,  0.3265],
         [-0.0059,  0.2229],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.522128, steer=-0.004882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.498803338167455
8.15734949707985 seconds in game passed.
Action: tensor([[[-0.0021,  0.6053],
         [-0.0052,  0.3265],
         [-0.0059,  0.2229],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.533380, steer=-0.004922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.498803338167455
+++++++++++++: inf
8.182349497452378 seconds in game passed.
At 8.182349497452378 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.4877e-04,  5.9954e-01],
         [-2.2271e-03,  3.2477e-01],
         [-2.8287e-03,  2.2206e-01],
         [-3.4694e-03,  1.6874e-01]]])
agent 0 action: VehicleControl(throttle=0.545762, steer=-0.002038, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4124966890874568
Current mitigation activation: 0
#############################
Total reward: 41.91130002725491
8.207349497824907 seconds in game passed.
Action: tensor([[[-3.4877e-04,  5.9954e-01],
         [-2.2271e-03,  3.2477e-01],
         [-2.8287e-03,  2.2206e-01],
         [-3.4694e-03,  1.6874e-01]]])
agent 0 action: VehicleControl(throttle=0.552510, steer=-0.002464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91130002725491
8.232349498197436 seconds in game passed.
Action: tensor([[[-3.4877e-04,  5.9954e-01],
         [-2.2271e-03,  3.2477e-01],
         [-2.8287e-03,  2.2206e-01],
         [-3.4694e-03,  1.6874e-01]]])
agent 0 action: VehicleControl(throttle=0.558989, steer=-0.002418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91130002725491
8.257349498569965 seconds in game passed.
Action: tensor([[[-3.4877e-04,  5.9954e-01],
         [-2.2271e-03,  3.2477e-01],
         [-2.8287e-03,  2.2206e-01],
         [-3.4694e-03,  1.6874e-01]]])
agent 0 action: VehicleControl(throttle=0.565499, steer=-0.002372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91130002725491
+++++++++++++: inf
8.282349498942494 seconds in game passed.
At 8.282349498942494 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0099,  0.6368],
         [-0.0007,  0.3439],
         [-0.0025,  0.2351],
         [-0.0034,  0.1785]]])
agent 0 action: VehicleControl(throttle=0.281612, steer=0.002869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4073657714686718
Current mitigation activation: 0
#############################
Total reward: 43.31866579872358
8.307349499315023 seconds in game passed.
Action: tensor([[[ 0.0099,  0.6368],
         [-0.0007,  0.3439],
         [-0.0025,  0.2351],
         [-0.0034,  0.1785]]])
agent 0 action: VehicleControl(throttle=0.315922, steer=0.002096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.31866579872358
8.332349499687552 seconds in game passed.
Action: tensor([[[ 0.0099,  0.6368],
         [-0.0007,  0.3439],
         [-0.0025,  0.2351],
         [-0.0034,  0.1785]]])
agent 0 action: VehicleControl(throttle=0.319440, steer=0.002182, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.31866579872358
8.357349500060081 seconds in game passed.
Action: tensor([[[ 0.0099,  0.6368],
         [-0.0007,  0.3439],
         [-0.0025,  0.2351],
         [-0.0034,  0.1785]]])
agent 0 action: VehicleControl(throttle=0.322902, steer=0.002268, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.31866579872358
+++++++++++++: inf
8.38234950043261 seconds in game passed.
At 8.38234950043261 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0162, 0.6412],
         [0.0035, 0.3490],
         [0.0020, 0.2396],
         [0.0011, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.204349, steer=0.008058, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4052778605948941
Current mitigation activation: 0
#############################
Total reward: 44.72394365931847
8.40734950080514 seconds in game passed.
Action: tensor([[[0.0162, 0.6412],
         [0.0035, 0.3490],
         [0.0020, 0.2396],
         [0.0011, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.219393, steer=0.007250, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72394365931847
8.432349501177669 seconds in game passed.
Action: tensor([[[0.0162, 0.6412],
         [0.0035, 0.3490],
         [0.0020, 0.2396],
         [0.0011, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.221458, steer=0.007385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72394365931847
8.457349501550198 seconds in game passed.
Action: tensor([[[0.0162, 0.6412],
         [0.0035, 0.3490],
         [0.0020, 0.2396],
         [0.0011, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.223357, steer=0.007520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72394365931847
+++++++++++++: inf
8.482349501922727 seconds in game passed.
At 8.482349501922727 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.6322e-03, 6.0045e-01],
         [1.7449e-03, 3.2448e-01],
         [1.0904e-03, 2.2269e-01],
         [2.4490e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.658517, steer=0.002025, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4031697163173955
Current mitigation activation: 0
#############################
Total reward: 46.127113375635865
8.507349502295256 seconds in game passed.
Action: tensor([[[5.6322e-03, 6.0045e-01],
         [1.7449e-03, 3.2448e-01],
         [1.0904e-03, 2.2269e-01],
         [2.4490e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.618946, steer=0.003012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.127113375635865
8.532349502667785 seconds in game passed.
Action: tensor([[[5.6322e-03, 6.0045e-01],
         [1.7449e-03, 3.2448e-01],
         [1.0904e-03, 2.2269e-01],
         [2.4490e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.625111, steer=0.003072, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.127113375635865
8.557349503040314 seconds in game passed.
Action: tensor([[[5.6322e-03, 6.0045e-01],
         [1.7449e-03, 3.2448e-01],
         [1.0904e-03, 2.2269e-01],
         [2.4490e-04, 1.6929e-01]]])
agent 0 action: VehicleControl(throttle=0.631121, steer=0.003133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.127113375635865
+++++++++++++: inf
8.582349503412843 seconds in game passed.
At 8.582349503412843 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.3751e-03,  5.9466e-01],
         [-1.2355e-04,  3.2355e-01],
         [-6.4292e-04,  2.2252e-01],
         [-1.2052e-03,  1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.607483, steer=0.000905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4010555568481315
Current mitigation activation: 0
#############################
Total reward: 47.52816893248399
8.607349503785372 seconds in game passed.
Action: tensor([[[ 3.3751e-03,  5.9466e-01],
         [-1.2355e-04,  3.2355e-01],
         [-6.4292e-04,  2.2252e-01],
         [-1.2052e-03,  1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.615631, steer=0.001299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52816893248399
8.6323495041579 seconds in game passed.
Action: tensor([[[ 3.3751e-03,  5.9466e-01],
         [-1.2355e-04,  3.2355e-01],
         [-6.4292e-04,  2.2252e-01],
         [-1.2052e-03,  1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.620502, steer=0.001319, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52816893248399
8.65734950453043 seconds in game passed.
Action: tensor([[[ 3.3751e-03,  5.9466e-01],
         [-1.2355e-04,  3.2355e-01],
         [-6.4292e-04,  2.2252e-01],
         [-1.2052e-03,  1.6911e-01]]])
agent 0 action: VehicleControl(throttle=0.625195, steer=0.001339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52816893248399
+++++++++++++: inf
8.682349504902959 seconds in game passed.
At 8.682349504902959 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.7265e-04,  5.9660e-01],
         [-7.9001e-04,  3.2303e-01],
         [-9.8688e-04,  2.2177e-01],
         [-1.2187e-03,  1.6840e-01]]])
agent 0 action: VehicleControl(throttle=0.670448, steer=-0.000416, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3989887634257594
Current mitigation activation: 0
#############################
Total reward: 48.927157695909756
8.707349505275488 seconds in game passed.
Action: tensor([[[ 1.7265e-04,  5.9660e-01],
         [-7.9001e-04,  3.2303e-01],
         [-9.8688e-04,  2.2177e-01],
         [-1.2187e-03,  1.6840e-01]]])
agent 0 action: VehicleControl(throttle=0.670612, steer=-0.000125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.927157695909756
8.732349505648017 seconds in game passed.
Action: tensor([[[ 1.7265e-04,  5.9660e-01],
         [-7.9001e-04,  3.2303e-01],
         [-9.8688e-04,  2.2177e-01],
         [-1.2187e-03,  1.6840e-01]]])
agent 0 action: VehicleControl(throttle=0.654726, steer=-0.000126, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.927157695909756
8.757349506020546 seconds in game passed.
Action: tensor([[[ 1.7265e-04,  5.9660e-01],
         [-7.9001e-04,  3.2303e-01],
         [-9.8688e-04,  2.2177e-01],
         [-1.2187e-03,  1.6840e-01]]])
agent 0 action: VehicleControl(throttle=0.642165, steer=-0.000127, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.927157695909756
+++++++++++++: inf
8.782349506393075 seconds in game passed.
At 8.782349506393075 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6092],
         [-0.0037,  0.3270],
         [-0.0038,  0.2228],
         [-0.0040,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.618499, steer=-0.003272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4041391302085688
Current mitigation activation: 0
#############################
Total reward: 50.331296826118326
8.807349506765604 seconds in game passed.
Action: tensor([[[-0.0024,  0.6092],
         [-0.0037,  0.3270],
         [-0.0038,  0.2228],
         [-0.0040,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.608204, steer=-0.002802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.331296826118326
8.832349507138133 seconds in game passed.
Action: tensor([[[-0.0024,  0.6092],
         [-0.0037,  0.3270],
         [-0.0038,  0.2228],
         [-0.0040,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.596817, steer=-0.002849, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.331296826118326
8.857349507510662 seconds in game passed.
Action: tensor([[[-0.0024,  0.6092],
         [-0.0037,  0.3270],
         [-0.0038,  0.2228],
         [-0.0040,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.585692, steer=-0.002896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.331296826118326
+++++++++++++: inf
8.882349507883191 seconds in game passed.
At 8.882349507883191 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0044,  0.6100],
         [-0.0060,  0.3278],
         [-0.0064,  0.2236],
         [-0.0068,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.553935, steer=-0.005453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4217203945074592
Current mitigation activation: 0
#############################
Total reward: 51.753017220625786
8.90734950825572 seconds in game passed.
Action: tensor([[[-0.0044,  0.6100],
         [-0.0060,  0.3278],
         [-0.0064,  0.2236],
         [-0.0068,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.545098, steer=-0.005091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.753017220625786
8.93234950862825 seconds in game passed.
Action: tensor([[[-0.0044,  0.6100],
         [-0.0060,  0.3278],
         [-0.0064,  0.2236],
         [-0.0068,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.534452, steer=-0.005147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.753017220625786
8.957349509000778 seconds in game passed.
Action: tensor([[[-0.0044,  0.6100],
         [-0.0060,  0.3278],
         [-0.0064,  0.2236],
         [-0.0068,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.524286, steer=-0.005202, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.753017220625786
+++++++++++++: inf
8.982349509373307 seconds in game passed.
At 8.982349509373307 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.5997],
         [-0.0026,  0.3246],
         [-0.0028,  0.2228],
         [-0.0032,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.522261, steer=-0.001571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.436651012060723
Current mitigation activation: 0
#############################
Total reward: 53.18966823268651
9.007349509745836 seconds in game passed.
Action: tensor([[[-0.0016,  0.5997],
         [-0.0026,  0.3246],
         [-0.0028,  0.2228],
         [-0.0032,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.512423, steer=-0.002166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18966823268651
9.032349510118365 seconds in game passed.
Action: tensor([[[-0.0016,  0.5997],
         [-0.0026,  0.3246],
         [-0.0028,  0.2228],
         [-0.0032,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.503786, steer=-0.002157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18966823268651
9.057349510490894 seconds in game passed.
Action: tensor([[[-0.0016,  0.5997],
         [-0.0026,  0.3246],
         [-0.0028,  0.2228],
         [-0.0032,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.495512, steer=-0.002148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18966823268651
+++++++++++++: inf
9.082349510863423 seconds in game passed.
At 9.082349510863423 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.1910e-03,  6.0843e-01],
         [ 1.2323e-03,  3.2979e-01],
         [ 6.5801e-04,  2.2602e-01],
         [-2.2291e-04,  1.7195e-01]]])
agent 0 action: VehicleControl(throttle=0.391379, steer=0.002567, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4481504931392992
Current mitigation activation: 0
#############################
Total reward: 54.63781872582581
9.107349511235952 seconds in game passed.
Action: tensor([[[ 3.1910e-03,  6.0843e-01],
         [ 1.2323e-03,  3.2979e-01],
         [ 6.5801e-04,  2.2602e-01],
         [-2.2291e-04,  1.7195e-01]]])
agent 0 action: VehicleControl(throttle=0.392569, steer=0.001863, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.63781872582581
9.132349511608481 seconds in game passed.
Action: tensor([[[ 3.1910e-03,  6.0843e-01],
         [ 1.2323e-03,  3.2979e-01],
         [ 6.5801e-04,  2.2602e-01],
         [-2.2291e-04,  1.7195e-01]]])
agent 0 action: VehicleControl(throttle=0.384255, steer=0.001934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.63781872582581
9.15734951198101 seconds in game passed.
Action: tensor([[[ 3.1910e-03,  6.0843e-01],
         [ 1.2323e-03,  3.2979e-01],
         [ 6.5801e-04,  2.2602e-01],
         [-2.2291e-04,  1.7195e-01]]])
agent 0 action: VehicleControl(throttle=0.377127, steer=0.002004, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.63781872582581
+++++++++++++: inf
9.18234951235354 seconds in game passed.
At 9.18234951235354 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0077, 0.6343],
         [0.0034, 0.3543],
         [0.0028, 0.2480],
         [0.0020, 0.1915]]])
agent 0 action: VehicleControl(throttle=0.143284, steer=0.005503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4563036660920339
Current mitigation activation: 0
#############################
Total reward: 56.09412239191784
9.207349512726068 seconds in game passed.
Action: tensor([[[0.0077, 0.6343],
         [0.0034, 0.3543],
         [0.0028, 0.2480],
         [0.0020, 0.1915]]])
agent 0 action: VehicleControl(throttle=0.162318, steer=0.005009, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09412239191784
9.232349513098598 seconds in game passed.
Action: tensor([[[0.0077, 0.6343],
         [0.0034, 0.3543],
         [0.0028, 0.2480],
         [0.0020, 0.1915]]])
agent 0 action: VehicleControl(throttle=0.156803, steer=0.005086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09412239191784
9.257349513471127 seconds in game passed.
Action: tensor([[[0.0077, 0.6343],
         [0.0034, 0.3543],
         [0.0028, 0.2480],
         [0.0020, 0.1915]]])
agent 0 action: VehicleControl(throttle=0.151267, steer=0.005162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09412239191784
+++++++++++++: inf
9.282349513843656 seconds in game passed.
At 9.282349513843656 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0069, 0.6159],
         [0.0031, 0.3389],
         [0.0022, 0.2355],
         [0.0013, 0.1816]]])
agent 0 action: VehicleControl(throttle=0.148917, steer=0.004602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.459330190091635
Current mitigation activation: 0
#############################
Total reward: 57.55345258200948
9.307349514216185 seconds in game passed.
Action: tensor([[[0.0069, 0.6159],
         [0.0031, 0.3389],
         [0.0022, 0.2355],
         [0.0013, 0.1816]]])
agent 0 action: VehicleControl(throttle=0.146547, steer=0.004715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55345258200948
9.332349514588714 seconds in game passed.
Action: tensor([[[0.0069, 0.6159],
         [0.0031, 0.3389],
         [0.0022, 0.2355],
         [0.0013, 0.1816]]])
agent 0 action: VehicleControl(throttle=0.144157, steer=0.004731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55345258200948
9.357349514961243 seconds in game passed.
Action: tensor([[[0.0069, 0.6159],
         [0.0031, 0.3389],
         [0.0022, 0.2355],
         [0.0013, 0.1816]]])
agent 0 action: VehicleControl(throttle=0.149148, steer=0.004748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55345258200948
+++++++++++++: inf
9.382349515333772 seconds in game passed.
At 9.382349515333772 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.4375e-03,  6.1971e-01],
         [ 1.3782e-03,  3.3738e-01],
         [ 3.9876e-04,  2.3289e-01],
         [-4.8997e-04,  1.7871e-01]]])
agent 0 action: VehicleControl(throttle=0.248000, steer=0.003248, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4541811844004258
Current mitigation activation: 0
#############################
Total reward: 59.0076337664099
9.4073495157063 seconds in game passed.
Action: tensor([[[ 6.4375e-03,  6.1971e-01],
         [ 1.3782e-03,  3.3738e-01],
         [ 3.9876e-04,  2.3289e-01],
         [-4.8997e-04,  1.7871e-01]]])
agent 0 action: VehicleControl(throttle=0.247666, steer=0.003431, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.0076337664099
9.43234951607883 seconds in game passed.
Action: tensor([[[ 6.4375e-03,  6.1971e-01],
         [ 1.3782e-03,  3.3738e-01],
         [ 3.9876e-04,  2.3289e-01],
         [-4.8997e-04,  1.7871e-01]]])
agent 0 action: VehicleControl(throttle=0.257463, steer=0.003374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.0076337664099
9.457349516451359 seconds in game passed.
Action: tensor([[[ 6.4375e-03,  6.1971e-01],
         [ 1.3782e-03,  3.3738e-01],
         [ 3.9876e-04,  2.3289e-01],
         [-4.8997e-04,  1.7871e-01]]])
agent 0 action: VehicleControl(throttle=0.267037, steer=0.003317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.0076337664099
+++++++++++++: inf
9.482349516823888 seconds in game passed.
At 9.482349516823888 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6164],
         [-0.0019,  0.3334],
         [-0.0026,  0.2289],
         [-0.0035,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.377182, steer=-0.001335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4434932558075166
Current mitigation activation: 0
#############################
Total reward: 60.45112702221742
9.507349517196417 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6164],
         [-0.0019,  0.3334],
         [-0.0026,  0.2289],
         [-0.0035,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.371616, steer=-0.000615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.45112702221742
9.532349517568946 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6164],
         [-0.0019,  0.3334],
         [-0.0026,  0.2289],
         [-0.0035,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.376820, steer=-0.000662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.45112702221742
9.557349517941475 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6164],
         [-0.0019,  0.3334],
         [-0.0026,  0.2289],
         [-0.0035,  0.1752]]])
agent 0 action: VehicleControl(throttle=0.380992, steer=-0.000709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.45112702221742
+++++++++++++: inf
9.582349518314004 seconds in game passed.
At 9.582349518314004 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6169],
         [-0.0052,  0.3307],
         [-0.0060,  0.2249],
         [-0.0069,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.485989, steer=-0.004792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.432736854804895
Current mitigation activation: 0
#############################
Total reward: 61.883863877022314
9.607349518686533 seconds in game passed.
Action: tensor([[[-0.0033,  0.6169],
         [-0.0052,  0.3307],
         [-0.0060,  0.2249],
         [-0.0069,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.479387, steer=-0.004188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.883863877022314
9.632349519059062 seconds in game passed.
Action: tensor([[[-0.0033,  0.6169],
         [-0.0052,  0.3307],
         [-0.0060,  0.2249],
         [-0.0069,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.482727, steer=-0.004254, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.883863877022314
9.657349519431591 seconds in game passed.
Action: tensor([[[-0.0033,  0.6169],
         [-0.0052,  0.3307],
         [-0.0060,  0.2249],
         [-0.0069,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.484692, steer=-0.004320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.883863877022314
+++++++++++++: inf
9.68234951980412 seconds in game passed.
At 9.68234951980412 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0074,  0.6246],
         [-0.0116,  0.3318],
         [-0.0133,  0.2247],
         [-0.0144,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.523444, steer=-0.010800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4255873734274425
Current mitigation activation: 0
#############################
Total reward: 63.309451250449754
9.707349520176649 seconds in game passed.
Action: tensor([[[-0.0074,  0.6246],
         [-0.0116,  0.3318],
         [-0.0133,  0.2247],
         [-0.0144,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.519357, steer=-0.009852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.309451250449754
9.732349520549178 seconds in game passed.
Action: tensor([[[-0.0074,  0.6246],
         [-0.0116,  0.3318],
         [-0.0133,  0.2247],
         [-0.0144,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.518760, steer=-0.009966, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.309451250449754
9.757349520921707 seconds in game passed.
Action: tensor([[[-0.0074,  0.6246],
         [-0.0116,  0.3318],
         [-0.0133,  0.2247],
         [-0.0144,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.517326, steer=-0.010080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.309451250449754
+++++++++++++: inf
9.782349521294236 seconds in game passed.
At 9.782349521294236 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6140],
         [-0.0043,  0.3291],
         [-0.0047,  0.2240],
         [-0.0046,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.504639, steer=-0.002790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.423423454809667
Current mitigation activation: 0
#############################
Total reward: 64.73287470525942
9.807349521666765 seconds in game passed.
Action: tensor([[[-0.0024,  0.6140],
         [-0.0043,  0.3291],
         [-0.0047,  0.2240],
         [-0.0046,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.503355, steer=-0.004012, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73287470525942
9.832349522039294 seconds in game passed.
Action: tensor([[[-0.0024,  0.6140],
         [-0.0043,  0.3291],
         [-0.0047,  0.2240],
         [-0.0046,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.500570, steer=-0.004017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73287470525942
9.857349522411823 seconds in game passed.
Action: tensor([[[-0.0024,  0.6140],
         [-0.0043,  0.3291],
         [-0.0047,  0.2240],
         [-0.0046,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.497643, steer=-0.004023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73287470525942
+++++++++++++: inf
9.882349522784352 seconds in game passed.
At 9.882349522784352 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.1272e-04,  6.0377e-01],
         [-2.1495e-03,  3.2601e-01],
         [-2.7265e-03,  2.2280e-01],
         [-3.0914e-03,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.499176, steer=-0.001578, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4252625335429656
Current mitigation activation: 0
#############################
Total reward: 66.15813723880238
9.907349523156881 seconds in game passed.
Action: tensor([[[-4.1272e-04,  6.0377e-01],
         [-2.1495e-03,  3.2601e-01],
         [-2.7265e-03,  2.2280e-01],
         [-3.0914e-03,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.495904, steer=-0.001932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.15813723880238
9.93234952352941 seconds in game passed.
Action: tensor([[[-4.1272e-04,  6.0377e-01],
         [-2.1495e-03,  3.2601e-01],
         [-2.7265e-03,  2.2280e-01],
         [-3.0914e-03,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.493064, steer=-0.001887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.15813723880238
9.95734952390194 seconds in game passed.
Action: tensor([[[-4.1272e-04,  6.0377e-01],
         [-2.1495e-03,  3.2601e-01],
         [-2.7265e-03,  2.2280e-01],
         [-3.0914e-03,  1.6909e-01]]])
agent 0 action: VehicleControl(throttle=0.490208, steer=-0.001841, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.15813723880238
+++++++++++++: inf
9.982349524274468 seconds in game passed.
At 9.982349524274468 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0766e-03,  6.2079e-01],
         [ 5.8711e-04,  3.3182e-01],
         [ 3.5837e-06,  2.2635e-01],
         [-5.1415e-04,  1.7218e-01]]])
agent 0 action: VehicleControl(throttle=0.454624, steer=0.001571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4289030003111918
Current mitigation activation: 0
#############################
Total reward: 67.58704023911358
10.007349524646997 seconds in game passed.
Action: tensor([[[ 3.0766e-03,  6.2079e-01],
         [ 5.8711e-04,  3.3182e-01],
         [ 3.5837e-06,  2.2635e-01],
         [-5.1415e-04,  1.7218e-01]]])
agent 0 action: VehicleControl(throttle=0.454859, steer=0.001052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.58704023911358
10.032349525019526 seconds in game passed.
Action: tensor([[[ 3.0766e-03,  6.2079e-01],
         [ 5.8711e-04,  3.3182e-01],
         [ 3.5837e-06,  2.2635e-01],
         [-5.1415e-04,  1.7218e-01]]])
agent 0 action: VehicleControl(throttle=0.451805, steer=0.001095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.58704023911358
10.057349525392056 seconds in game passed.
Action: tensor([[[ 3.0766e-03,  6.2079e-01],
         [ 5.8711e-04,  3.3182e-01],
         [ 3.5837e-06,  2.2635e-01],
         [-5.1415e-04,  1.7218e-01]]])
agent 0 action: VehicleControl(throttle=0.449113, steer=0.001138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.58704023911358
+++++++++++++: inf
10.082349525764585 seconds in game passed.
At 10.082349525764585 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.1580e-03, 6.0857e-01],
         [5.8708e-04, 3.2649e-01],
         [5.9071e-04, 2.2266e-01],
         [3.9622e-04, 1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.513941, steer=0.000372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4329115009517848
Current mitigation activation: 0
#############################
Total reward: 69.01995174006537
10.107349526137114 seconds in game passed.
Action: tensor([[[1.1580e-03, 6.0857e-01],
         [5.8708e-04, 3.2649e-01],
         [5.9071e-04, 2.2266e-01],
         [3.9622e-04, 1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.506586, steer=0.000484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.01995174006537
10.132349526509643 seconds in game passed.
Action: tensor([[[1.1580e-03, 6.0857e-01],
         [5.8708e-04, 3.2649e-01],
         [5.9071e-04, 2.2266e-01],
         [3.9622e-04, 1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.506297, steer=0.000471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.01995174006537
10.157349526882172 seconds in game passed.
Action: tensor([[[1.1580e-03, 6.0857e-01],
         [5.8708e-04, 3.2649e-01],
         [5.9071e-04, 2.2266e-01],
         [3.9622e-04, 1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.505641, steer=0.000457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.01995174006537
+++++++++++++: inf
10.1823495272547 seconds in game passed.
At 10.1823495272547 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0024, 0.6129],
         [0.0014, 0.3272],
         [0.0019, 0.2227],
         [0.0022, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.526998, steer=0.001520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4363115939419089
Current mitigation activation: 0
#############################
Total reward: 70.45626333400728
10.20734952762723 seconds in game passed.
Action: tensor([[[0.0024, 0.6129],
         [0.0014, 0.3272],
         [0.0019, 0.2227],
         [0.0022, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.526564, steer=0.001299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.45626333400728
10.232349527999759 seconds in game passed.
Action: tensor([[[0.0024, 0.6129],
         [0.0014, 0.3272],
         [0.0019, 0.2227],
         [0.0022, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.527974, steer=0.001261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.45626333400728
10.257349528372288 seconds in game passed.
Action: tensor([[[0.0024, 0.6129],
         [0.0014, 0.3272],
         [0.0019, 0.2227],
         [0.0022, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.529032, steer=0.001224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.45626333400728
+++++++++++++: inf
10.282349528744817 seconds in game passed.
At 10.282349528744817 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.9461e-04, 5.9752e-01],
         [7.6064e-04, 3.2292e-01],
         [1.1901e-03, 2.2105e-01],
         [1.2115e-03, 1.6774e-01]]])
agent 0 action: VehicleControl(throttle=0.523790, steer=-0.000135, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4402803838332239
Current mitigation activation: 0
#############################
Total reward: 71.8965437178405
10.307349529117346 seconds in game passed.
Action: tensor([[[2.9461e-04, 5.9752e-01],
         [7.6064e-04, 3.2292e-01],
         [1.1901e-03, 2.2105e-01],
         [1.2115e-03, 1.6774e-01]]])
agent 0 action: VehicleControl(throttle=0.524879, steer=0.000039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.8965437178405
10.332349529489875 seconds in game passed.
Action: tensor([[[2.9461e-04, 5.9752e-01],
         [7.6064e-04, 3.2292e-01],
         [1.1901e-03, 2.2105e-01],
         [1.2115e-03, 1.6774e-01]]])
agent 0 action: VehicleControl(throttle=0.525117, steer=-0.000006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.8965437178405
10.357349529862404 seconds in game passed.
Action: tensor([[[2.9461e-04, 5.9752e-01],
         [7.6064e-04, 3.2292e-01],
         [1.1901e-03, 2.2105e-01],
         [1.2115e-03, 1.6774e-01]]])
agent 0 action: VehicleControl(throttle=0.525117, steer=-0.000051, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.8965437178405
+++++++++++++: inf
10.382349530234933 seconds in game passed.
At 10.382349530234933 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.4213e-05,  6.0345e-01],
         [-5.8743e-04,  3.2555e-01],
         [-1.5162e-04,  2.2289e-01],
         [ 1.1861e-04,  1.6971e-01]]])
agent 0 action: VehicleControl(throttle=0.490071, steer=-0.001230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4453799225697024
Current mitigation activation: 0
#############################
Total reward: 73.3419236404102
10.407349530607462 seconds in game passed.
Action: tensor([[[-9.4213e-05,  6.0345e-01],
         [-5.8743e-04,  3.2555e-01],
         [-1.5162e-04,  2.2289e-01],
         [ 1.1861e-04,  1.6971e-01]]])
agent 0 action: VehicleControl(throttle=0.491768, steer=-0.001083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.3419236404102
10.432349530979991 seconds in game passed.
Action: tensor([[[-9.4213e-05,  6.0345e-01],
         [-5.8743e-04,  3.2555e-01],
         [-1.5162e-04,  2.2289e-01],
         [ 1.1861e-04,  1.6971e-01]]])
agent 0 action: VehicleControl(throttle=0.489749, steer=-0.001125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.3419236404102
10.45734953135252 seconds in game passed.
Action: tensor([[[-9.4213e-05,  6.0345e-01],
         [-5.8743e-04,  3.2555e-01],
         [-1.5162e-04,  2.2289e-01],
         [ 1.1861e-04,  1.6971e-01]]])
agent 0 action: VehicleControl(throttle=0.487813, steer=-0.001167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.3419236404102
+++++++++++++: inf
10.482349531725049 seconds in game passed.
At 10.482349531725049 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0010, 0.5962],
         [0.0009, 0.3221],
         [0.0018, 0.2205],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.533880, steer=0.000393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4510065019983074
Current mitigation activation: 0
#############################
Total reward: 74.79293014240851
10.507349532097578 seconds in game passed.
Action: tensor([[[0.0010, 0.5962],
         [0.0009, 0.3221],
         [0.0018, 0.2205],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.526134, steer=0.000159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79293014240851
10.532349532470107 seconds in game passed.
Action: tensor([[[0.0010, 0.5962],
         [0.0009, 0.3221],
         [0.0018, 0.2205],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.523470, steer=0.000181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79293014240851
10.557349532842636 seconds in game passed.
Action: tensor([[[0.0010, 0.5962],
         [0.0009, 0.3221],
         [0.0018, 0.2205],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.520401, steer=0.000203, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79293014240851
+++++++++++++: inf
10.582349533215165 seconds in game passed.
At 10.582349533215165 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.5968],
         [0.0031, 0.3229],
         [0.0040, 0.2211],
         [0.0044, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.493706, steer=0.002348, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.45623276999151
Current mitigation activation: 0
#############################
Total reward: 76.24916291240002
10.607349533587694 seconds in game passed.
Action: tensor([[[0.0022, 0.5968],
         [0.0031, 0.3229],
         [0.0040, 0.2211],
         [0.0044, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.491187, steer=0.002090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.24916291240002
10.632349533960223 seconds in game passed.
Action: tensor([[[0.0022, 0.5968],
         [0.0031, 0.3229],
         [0.0040, 0.2211],
         [0.0044, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.486236, steer=0.002176, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.24916291240002
10.657349534332752 seconds in game passed.
Action: tensor([[[0.0022, 0.5968],
         [0.0031, 0.3229],
         [0.0040, 0.2211],
         [0.0044, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.481389, steer=0.002261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.24916291240002
+++++++++++++: inf
10.682349534705281 seconds in game passed.
At 10.682349534705281 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.6153],
         [0.0014, 0.3330],
         [0.0017, 0.2283],
         [0.0015, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.303280, steer=0.001034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.461596187119736
Current mitigation activation: 0
#############################
Total reward: 77.71075909951976
10.70734953507781 seconds in game passed.
Action: tensor([[[0.0018, 0.6153],
         [0.0014, 0.3330],
         [0.0017, 0.2283],
         [0.0015, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.314655, steer=0.001399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.71075909951976
10.73234953545034 seconds in game passed.
Action: tensor([[[0.0018, 0.6153],
         [0.0014, 0.3330],
         [0.0017, 0.2283],
         [0.0015, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.308196, steer=0.001536, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.71075909951976
10.757349535822868 seconds in game passed.
Action: tensor([[[0.0018, 0.6153],
         [0.0014, 0.3330],
         [0.0017, 0.2283],
         [0.0015, 0.1741]]])
agent 0 action: VehicleControl(throttle=0.303369, steer=0.001674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.71075909951976
+++++++++++++: inf
10.782349536195397 seconds in game passed.
At 10.782349536195397 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6104],
         [0.0018, 0.3270],
         [0.0019, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.466734, steer=0.002672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4659868846864392
Current mitigation activation: 0
#############################
Total reward: 79.1767459842062
10.807349536567926 seconds in game passed.
Action: tensor([[[0.0035, 0.6104],
         [0.0018, 0.3270],
         [0.0019, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.448532, steer=0.002588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.1767459842062
10.832349536940455 seconds in game passed.
Action: tensor([[[0.0035, 0.6104],
         [0.0018, 0.3270],
         [0.0019, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.448750, steer=0.002659, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.1767459842062
10.857349537312984 seconds in game passed.
Action: tensor([[[0.0035, 0.6104],
         [0.0018, 0.3270],
         [0.0019, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.448521, steer=0.002731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.1767459842062
+++++++++++++: inf
10.882349537685513 seconds in game passed.
At 10.882349537685513 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.8491e-03, 6.0873e-01],
         [7.1603e-04, 3.2463e-01],
         [8.0878e-04, 2.2152e-01],
         [5.7975e-04, 1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.517726, steer=0.001315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4661481550794848
Current mitigation activation: 0
#############################
Total reward: 80.64289413928569
10.907349538058043 seconds in game passed.
Action: tensor([[[1.8491e-03, 6.0873e-01],
         [7.1603e-04, 3.2463e-01],
         [8.0878e-04, 2.2152e-01],
         [5.7975e-04, 1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.510285, steer=0.001587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64289413928569
10.932349538430572 seconds in game passed.
Action: tensor([[[1.8491e-03, 6.0873e-01],
         [7.1603e-04, 3.2463e-01],
         [8.0878e-04, 2.2152e-01],
         [5.7975e-04, 1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.509842, steer=0.001618, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64289413928569
10.9573495388031 seconds in game passed.
Action: tensor([[[1.8491e-03, 6.0873e-01],
         [7.1603e-04, 3.2463e-01],
         [8.0878e-04, 2.2152e-01],
         [5.7975e-04, 1.6781e-01]]])
agent 0 action: VehicleControl(throttle=0.508652, steer=0.001649, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64289413928569
+++++++++++++: inf
10.98234953917563 seconds in game passed.
At 10.98234953917563 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.5083e-03, 6.0656e-01],
         [1.6538e-04, 3.2457e-01],
         [3.4518e-04, 2.2172e-01],
         [2.2897e-04, 1.6794e-01]]])
agent 0 action: VehicleControl(throttle=0.486659, steer=0.001104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4657914469220092
Current mitigation activation: 0
#############################
Total reward: 82.1086855862077
11.007349539548159 seconds in game passed.
Action: tensor([[[1.5083e-03, 6.0656e-01],
         [1.6538e-04, 3.2457e-01],
         [3.4518e-04, 2.2172e-01],
         [2.2897e-04, 1.6794e-01]]])
agent 0 action: VehicleControl(throttle=0.486863, steer=0.001183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.1086855862077
11.032349539920688 seconds in game passed.
Action: tensor([[[1.5083e-03, 6.0656e-01],
         [1.6538e-04, 3.2457e-01],
         [3.4518e-04, 2.2172e-01],
         [2.2897e-04, 1.6794e-01]]])
agent 0 action: VehicleControl(throttle=0.484593, steer=0.001174, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.1086855862077
11.057349540293217 seconds in game passed.
Action: tensor([[[1.5083e-03, 6.0656e-01],
         [1.6538e-04, 3.2457e-01],
         [3.4518e-04, 2.2172e-01],
         [2.2897e-04, 1.6794e-01]]])
agent 0 action: VehicleControl(throttle=0.482228, steer=0.001164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.1086855862077
+++++++++++++: inf
11.082349540665746 seconds in game passed.
At 11.082349540665746 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.9540e-04, 6.1916e-01],
         [1.7448e-04, 3.2752e-01],
         [3.8396e-04, 2.2369e-01],
         [4.8667e-05, 1.7026e-01]]])
agent 0 action: VehicleControl(throttle=0.501742, steer=0.000689, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4677752070675671
Current mitigation activation: 0
#############################
Total reward: 83.57646079327526
11.107349541038275 seconds in game passed.
Action: tensor([[[2.9540e-04, 6.1916e-01],
         [1.7448e-04, 3.2752e-01],
         [3.8396e-04, 2.2369e-01],
         [4.8667e-05, 1.7026e-01]]])
agent 0 action: VehicleControl(throttle=0.496332, steer=0.000760, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.57646079327526
11.132349541410804 seconds in game passed.
Action: tensor([[[2.9540e-04, 6.1916e-01],
         [1.7448e-04, 3.2752e-01],
         [3.8396e-04, 2.2369e-01],
         [4.8667e-05, 1.7026e-01]]])
agent 0 action: VehicleControl(throttle=0.493234, steer=0.000754, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.57646079327526
11.157349541783333 seconds in game passed.
Action: tensor([[[2.9540e-04, 6.1916e-01],
         [1.7448e-04, 3.2752e-01],
         [3.8396e-04, 2.2369e-01],
         [4.8667e-05, 1.7026e-01]]])
agent 0 action: VehicleControl(throttle=0.489947, steer=0.000747, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.57646079327526
+++++++++++++: inf
11.182349542155862 seconds in game passed.
At 11.182349542155862 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6258],
         [-0.0019,  0.3275],
         [-0.0022,  0.2225],
         [-0.0032,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.554132, steer=-0.001395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.470846037700574
Current mitigation activation: 0
#############################
Total reward: 85.04730683097583
11.20734954252839 seconds in game passed.
Action: tensor([[[-0.0012,  0.6258],
         [-0.0019,  0.3275],
         [-0.0022,  0.2225],
         [-0.0032,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.544052, steer=-0.001085, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.04730683097583
11.23234954290092 seconds in game passed.
Action: tensor([[[-0.0012,  0.6258],
         [-0.0019,  0.3275],
         [-0.0022,  0.2225],
         [-0.0032,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.540960, steer=-0.001125, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.04730683097583
11.257349543273449 seconds in game passed.
Action: tensor([[[-0.0012,  0.6258],
         [-0.0019,  0.3275],
         [-0.0022,  0.2225],
         [-0.0032,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.537299, steer=-0.001165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.04730683097583
+++++++++++++: inf
11.282349543645978 seconds in game passed.
At 11.282349543645978 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.0798e-04,  6.2339e-01],
         [-5.4294e-04,  3.2728e-01],
         [-3.1504e-04,  2.2279e-01],
         [-8.7774e-04,  1.6948e-01]]])
agent 0 action: VehicleControl(throttle=0.517638, steer=-0.000073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4745755994181355
Current mitigation activation: 0
#############################
Total reward: 86.52188243039396
11.307349544018507 seconds in game passed.
Action: tensor([[[-9.0798e-04,  6.2339e-01],
         [-5.4294e-04,  3.2728e-01],
         [-3.1504e-04,  2.2279e-01],
         [-8.7774e-04,  1.6948e-01]]])
agent 0 action: VehicleControl(throttle=0.514948, steer=-0.000273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52188243039396
11.332349544391036 seconds in game passed.
Action: tensor([[[-9.0798e-04,  6.2339e-01],
         [-5.4294e-04,  3.2728e-01],
         [-3.1504e-04,  2.2279e-01],
         [-8.7774e-04,  1.6948e-01]]])
agent 0 action: VehicleControl(throttle=0.510454, steer=-0.000287, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52188243039396
11.357349544763565 seconds in game passed.
Action: tensor([[[-9.0798e-04,  6.2339e-01],
         [-5.4294e-04,  3.2728e-01],
         [-3.1504e-04,  2.2279e-01],
         [-8.7774e-04,  1.6948e-01]]])
agent 0 action: VehicleControl(throttle=0.505981, steer=-0.000302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52188243039396
+++++++++++++: inf
11.382349545136094 seconds in game passed.
At 11.382349545136094 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0017,  0.6114],
         [-0.0021,  0.3242],
         [-0.0017,  0.2220],
         [-0.0020,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.493126, steer=-0.001772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4796403824257691
Current mitigation activation: 0
#############################
Total reward: 88.00152281281973
11.407349545508623 seconds in game passed.
Action: tensor([[[-0.0017,  0.6114],
         [-0.0021,  0.3242],
         [-0.0017,  0.2220],
         [-0.0020,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.489964, steer=-0.001548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.00152281281973
11.432349545881152 seconds in game passed.
Action: tensor([[[-0.0017,  0.6114],
         [-0.0021,  0.3242],
         [-0.0017,  0.2220],
         [-0.0020,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.485999, steer=-0.001566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.00152281281973
11.457349546253681 seconds in game passed.
Action: tensor([[[-0.0017,  0.6114],
         [-0.0021,  0.3242],
         [-0.0017,  0.2220],
         [-0.0020,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.482223, steer=-0.001584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.00152281281973
+++++++++++++: inf
11.48234954662621 seconds in game passed.
At 11.48234954662621 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6161],
         [-0.0027,  0.3265],
         [-0.0027,  0.2227],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.440972, steer=-0.002392, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.484962051454204
Current mitigation activation: 0
#############################
Total reward: 89.48648486427393
11.50734954699874 seconds in game passed.
Action: tensor([[[-0.0025,  0.6161],
         [-0.0027,  0.3265],
         [-0.0027,  0.2227],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.440549, steer=-0.002307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.48648486427393
11.532349547371268 seconds in game passed.
Action: tensor([[[-0.0025,  0.6161],
         [-0.0027,  0.3265],
         [-0.0027,  0.2227],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.436495, steer=-0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.48648486427393
11.557349547743797 seconds in game passed.
Action: tensor([[[-0.0025,  0.6161],
         [-0.0027,  0.3265],
         [-0.0027,  0.2227],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.432968, steer=-0.002391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.48648486427393
+++++++++++++: inf
11.582349548116326 seconds in game passed.
At 11.582349548116326 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0036, 0.6234],
         [0.0044, 0.3275],
         [0.0053, 0.2230],
         [0.0051, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.468818, steer=0.005244, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4894355657188343
Current mitigation activation: 0
#############################
Total reward: 90.97592042999277
11.607349548488855 seconds in game passed.
Action: tensor([[[0.0036, 0.6234],
         [0.0044, 0.3275],
         [0.0053, 0.2230],
         [0.0051, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.462688, steer=0.003990, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.97592042999277
11.632349548861384 seconds in game passed.
Action: tensor([[[0.0036, 0.6234],
         [0.0044, 0.3275],
         [0.0053, 0.2230],
         [0.0051, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.460971, steer=0.004006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.97592042999277
11.657349549233913 seconds in game passed.
Action: tensor([[[0.0036, 0.6234],
         [0.0044, 0.3275],
         [0.0053, 0.2230],
         [0.0051, 0.1697]]])
agent 0 action: VehicleControl(throttle=0.459209, steer=0.004022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.97592042999277
+++++++++++++: inf
11.682349549606442 seconds in game passed.
At 11.682349549606442 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0048, 0.6295],
         [0.0050, 0.3369],
         [0.0053, 0.2325],
         [0.0049, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.186168, steer=0.004948, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.492277934865938
Current mitigation activation: 0
#############################
Total reward: 92.46819836485871
11.707349549978971 seconds in game passed.
Action: tensor([[[0.0048, 0.6295],
         [0.0050, 0.3369],
         [0.0053, 0.2325],
         [0.0049, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.212415, steer=0.004839, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.46819836485871
11.7323495503515 seconds in game passed.
Action: tensor([[[0.0048, 0.6295],
         [0.0050, 0.3369],
         [0.0053, 0.2325],
         [0.0049, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.210148, steer=0.004879, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.46819836485871
11.75734955072403 seconds in game passed.
Action: tensor([[[0.0048, 0.6295],
         [0.0050, 0.3369],
         [0.0053, 0.2325],
         [0.0049, 0.1784]]])
agent 0 action: VehicleControl(throttle=0.210024, steer=0.004918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.46819836485871
+++++++++++++: inf
11.782349551096559 seconds in game passed.
At 11.782349551096559 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.6707],
         [ 0.0077,  0.4134],
         [ 0.0125,  0.3080],
         [ 0.0156,  0.2460]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004409, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4938471459438758
Current mitigation activation: 0
#############################
Total reward: 93.96204551080258
11.807349551469088 seconds in game passed.
Action: tensor([[[-0.0010,  0.6707],
         [ 0.0077,  0.4134],
         [ 0.0125,  0.3080],
         [ 0.0156,  0.2460]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004522, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96204551080258
11.832349551841617 seconds in game passed.
Action: tensor([[[-0.0010,  0.6707],
         [ 0.0077,  0.4134],
         [ 0.0125,  0.3080],
         [ 0.0156,  0.2460]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004546, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96204551080258
11.857349552214146 seconds in game passed.
Action: tensor([[[-0.0010,  0.6707],
         [ 0.0077,  0.4134],
         [ 0.0125,  0.3080],
         [ 0.0156,  0.2460]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004570, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96204551080258
+++++++++++++: inf
11.882349552586675 seconds in game passed.
At 11.882349552586675 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.4454e-04, 7.0759e-01],
         [2.5632e-03, 4.3538e-01],
         [3.7686e-03, 3.2253e-01],
         [5.7259e-03, 2.5652e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001548, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4861610232940219
Current mitigation activation: 0
#############################
Total reward: 95.4482065340966
11.907349552959204 seconds in game passed.
Action: tensor([[[3.4454e-04, 7.0759e-01],
         [2.5632e-03, 4.3538e-01],
         [3.7686e-03, 3.2253e-01],
         [5.7259e-03, 2.5652e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002060, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.4482065340966
11.932349553331733 seconds in game passed.
Action: tensor([[[3.4454e-04, 7.0759e-01],
         [2.5632e-03, 4.3538e-01],
         [3.7686e-03, 3.2253e-01],
         [5.7259e-03, 2.5652e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002068, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.4482065340966
11.957349553704262 seconds in game passed.
Action: tensor([[[3.4454e-04, 7.0759e-01],
         [2.5632e-03, 4.3538e-01],
         [3.7686e-03, 3.2253e-01],
         [5.7259e-03, 2.5652e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002076, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.4482065340966
+++++++++++++: inf
11.98234955407679 seconds in game passed.
At 11.98234955407679 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0085, 0.8130],
         [0.0110, 0.4861],
         [0.0093, 0.3416],
         [0.0084, 0.2530]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.011894, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4343556217625877
Current mitigation activation: 0
#############################
Total reward: 96.88256215585919
12.00734955444932 seconds in game passed.
Action: tensor([[[0.0085, 0.8130],
         [0.0110, 0.4861],
         [0.0093, 0.3416],
         [0.0084, 0.2530]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.010391, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 96.88256215585919
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [91mFAILURE[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-15 00:41:12 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-15 00:41:52 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 39.37s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 9.78s               │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.248               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ FAILURE │ 46.64 % │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ FAILURE │ 1 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 96.88, average_reward: 96.88256215585919 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00005/fi_ghost_cutin_data
