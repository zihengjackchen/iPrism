New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004454-fi_ghost_cutin_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004454-fi_ghost_cutin_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004454-fi_ghost_cutin_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004454-fi_ghost_cutin_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004454-fi_ghost_cutin_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004454-fi_ghost_cutin_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_data/route_highway.xml_fi_ghost_cutin.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key distance_same_lane's value from 15 to 10.
Replacing key distance_lane_change's value from 11 to 6.
Replacing key speed_lane_change's value from 13.5 to 18.
Config for GhostCutIn scenario is {'first_vehicle_location': 0, 'first_vehicle_speed': 200, 'event_trigger_distance': 4, 'distance_lane_change': 6, 'speed_lane_change': 18, 'distance_same_lane': 10}
1.5861290581524372 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6111290585249662 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6361290588974953 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6611290592700243 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002736, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6861290596425533 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7111290600150824 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003972, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7361290603876114 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003824, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7611290607601404 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7861290611326694 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8111290615051985 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.8361290618777275 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8611290622502565 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8861290626227856 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9111290629953146 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9361290633678436 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002642, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9611290637403727 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9861290641129017 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0111290644854307 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0015, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0361290648579597 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0015, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0611290652304888 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0015, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.086129065603018 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0015, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002488, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.111129065975547 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4320e-03, 5.9059e-01],
         [1.3292e-03, 3.2233e-01],
         [1.1056e-03, 2.2210e-01],
         [5.6553e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.136129066348076 seconds in game passed.
Action: tensor([[[2.4320e-03, 5.9059e-01],
         [1.3292e-03, 3.2233e-01],
         [1.1056e-03, 2.2210e-01],
         [5.6553e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.161129066720605 seconds in game passed.
Action: tensor([[[2.4320e-03, 5.9059e-01],
         [1.3292e-03, 3.2233e-01],
         [1.1056e-03, 2.2210e-01],
         [5.6553e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.186129067093134 seconds in game passed.
Action: tensor([[[2.4320e-03, 5.9059e-01],
         [1.3292e-03, 3.2233e-01],
         [1.1056e-03, 2.2210e-01],
         [5.6553e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 20297.16684299258
2.211129067465663 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.236129067838192 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.261129068210721 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.28612906858325 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.71016465861
2.311129068955779 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.336129069328308 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.361129069700837 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.386129070073366 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.411129070445895 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002686, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.4361290708184242 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4611290711909533 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002705, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4861290715634823 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.5111290719360113 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002760, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.5361290723085403 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5611290726810694 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5861290730535984 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002790, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6111290734261274 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6361290737986565 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6611290741711855 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6861290745437145 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7111290749162436 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002682, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.7361290752887726 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7611290756613016 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002620, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7861290760338306 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002596, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.6593486434
2.8111290764063597 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.8361290767788887 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8611290771514177 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002461, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8861290775239468 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.911129077896476 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5877],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.936129078269005 seconds in game passed.
Action: tensor([[[0.0017, 0.5877],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002473, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.961129078641534 seconds in game passed.
Action: tensor([[[0.0017, 0.5877],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.986129079014063 seconds in game passed.
Action: tensor([[[0.0017, 0.5877],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.011129079386592 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.036129079759121 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.06112908013165 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.086129080504179 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.111129080876708 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002558, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.136129081249237 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.161129081621766 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.186129081994295 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002529, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.211129082366824 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.236129082739353 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.261129083111882 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.2861290834844112 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.3111290838569403 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.3361290842294693 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3611290846019983 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002450, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.3861290849745274 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0017, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4111290853470564 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4361290857195854 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4611290860921144 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4861290864646435 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5111290868371725 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3210],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5361290872097015 seconds in game passed.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3210],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5611290875822306 seconds in game passed.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3210],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5861290879547596 seconds in game passed.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3210],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6111290883272886 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6361290886998177 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6611290890723467 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002300, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6861290894448757 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7111290898174047 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002426, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7361290901899338 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.761129090562463 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.786129090934992 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002403, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.811129091307521 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002381, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.83612909168005 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.861129092052579 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.886129092425108 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.911129092797637 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.936129093170166 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.961129093542695 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.986129093915224 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.011129094287753 seconds in game passed.
At 4.011129094287753 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0.06602266588708589
4.036129094660282 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.061129095032811 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.08612909540534 seconds in game passed.
Action: tensor([[[0.0018, 0.5868],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
+++++++++++++: inf
4.111129095777869 seconds in game passed.
At 4.111129095777869 seconds, saving state-action tuples.
Action: tensor([[[1.4185e-03, 5.8602e-01],
         [1.1467e-03, 3.2065e-01],
         [1.0144e-03, 2.2100e-01],
         [3.6338e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001858, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.3145396919977081
4.136129096150398 seconds in game passed.
Action: tensor([[[1.4185e-03, 5.8602e-01],
         [1.1467e-03, 3.2065e-01],
         [1.0144e-03, 2.2100e-01],
         [3.6338e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.161129096522927 seconds in game passed.
Action: tensor([[[1.4185e-03, 5.8602e-01],
         [1.1467e-03, 3.2065e-01],
         [1.0144e-03, 2.2100e-01],
         [3.6338e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001925, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.186129096895456 seconds in game passed.
Action: tensor([[[1.4185e-03, 5.8602e-01],
         [1.1467e-03, 3.2065e-01],
         [1.0144e-03, 2.2100e-01],
         [3.6338e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
+++++++++++++: inf
4.211129097267985 seconds in game passed.
At 4.211129097267985 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002162, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.7221479506394559
4.236129097640514 seconds in game passed.
Action: tensor([[[0.0018, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.261129098013043 seconds in game passed.
Action: tensor([[[0.0018, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002118, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.286129098385572 seconds in game passed.
Action: tensor([[[0.0018, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002117, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
+++++++++++++: inf
4.3111290987581015 seconds in game passed.
At 4.3111290987581015 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.5416188264081325
Current mitigation activation: 0
#############################
Total reward: 1.2637667770475884
4.3361290991306305 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002201, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2637667770475884
4.3611290995031595 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2637667770475884
4.3861290998756886 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002196, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2637667770475884
+++++++++++++: inf
4.411129100248218 seconds in game passed.
At 4.411129100248218 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5850],
         [0.0024, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.6535768231130932
Current mitigation activation: 0
#############################
Total reward: 1.9173436001606816
4.436129100620747 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0024, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173436001606816
4.461129100993276 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0024, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002964, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173436001606816
4.486129101365805 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0024, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002973, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173436001606816
+++++++++++++: inf
4.511129101738334 seconds in game passed.
At 4.511129101738334 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5884],
         [0.0018, 0.3215],
         [0.0020, 0.2209],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.7480162555726918
Current mitigation activation: 0
#############################
Total reward: 2.6653598557333735
4.536129102110863 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0018, 0.3215],
         [0.0020, 0.2209],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653598557333735
4.561129102483392 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0018, 0.3215],
         [0.0020, 0.2209],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653598557333735
4.586129102855921 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0018, 0.3215],
         [0.0020, 0.2209],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653598557333735
+++++++++++++: inf
4.61112910322845 seconds in game passed.
At 4.61112910322845 seconds, saving state-action tuples.
Action: tensor([[[ 1.7568e-05,  5.8842e-01],
         [-3.7678e-05,  3.2176e-01],
         [ 3.9279e-05,  2.2102e-01],
         [-3.6177e-04,  1.6700e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000405, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8290658960857651
Current mitigation activation: 0
#############################
Total reward: 3.4944257518191386
4.636129103600979 seconds in game passed.
Action: tensor([[[ 1.7568e-05,  5.8842e-01],
         [-3.7678e-05,  3.2176e-01],
         [ 3.9279e-05,  2.2102e-01],
         [-3.6177e-04,  1.6700e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000729, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944257518191386
4.661129103973508 seconds in game passed.
Action: tensor([[[ 1.7568e-05,  5.8842e-01],
         [-3.7678e-05,  3.2176e-01],
         [ 3.9279e-05,  2.2102e-01],
         [-3.6177e-04,  1.6700e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944257518191386
4.686129104346037 seconds in game passed.
Action: tensor([[[ 1.7568e-05,  5.8842e-01],
         [-3.7678e-05,  3.2176e-01],
         [ 3.9279e-05,  2.2102e-01],
         [-3.6177e-04,  1.6700e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944257518191386
+++++++++++++: inf
4.711129104718566 seconds in game passed.
At 4.711129104718566 seconds, saving state-action tuples.
Action: tensor([[[ 3.0805e-04,  5.8920e-01],
         [-2.5725e-04,  3.2119e-01],
         [-2.0100e-04,  2.2087e-01],
         [-4.4128e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.899636384553004
Current mitigation activation: 0
#############################
Total reward: 4.394062136372143
4.736129105091095 seconds in game passed.
Action: tensor([[[ 3.0805e-04,  5.8920e-01],
         [-2.5725e-04,  3.2119e-01],
         [-2.0100e-04,  2.2087e-01],
         [-4.4128e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394062136372143
4.761129105463624 seconds in game passed.
Action: tensor([[[ 3.0805e-04,  5.8920e-01],
         [-2.5725e-04,  3.2119e-01],
         [-2.0100e-04,  2.2087e-01],
         [-4.4128e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394062136372143
4.786129105836153 seconds in game passed.
Action: tensor([[[ 3.0805e-04,  5.8920e-01],
         [-2.5725e-04,  3.2119e-01],
         [-2.0100e-04,  2.2087e-01],
         [-4.4128e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394062136372143
+++++++++++++: inf
4.811129106208682 seconds in game passed.
At 4.811129106208682 seconds, saving state-action tuples.
Action: tensor([[[-4.5786e-04,  5.9105e-01],
         [-1.0840e-03,  3.2137e-01],
         [-9.3745e-04,  2.2094e-01],
         [-1.0678e-03,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9622091701098011
Current mitigation activation: 0
#############################
Total reward: 5.356271306481944
4.836129106581211 seconds in game passed.
Action: tensor([[[-4.5786e-04,  5.9105e-01],
         [-1.0840e-03,  3.2137e-01],
         [-9.3745e-04,  2.2094e-01],
         [-1.0678e-03,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.356271306481944
4.86112910695374 seconds in game passed.
Action: tensor([[[-4.5786e-04,  5.9105e-01],
         [-1.0840e-03,  3.2137e-01],
         [-9.3745e-04,  2.2094e-01],
         [-1.0678e-03,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000273, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.356271306481944
4.886129107326269 seconds in game passed.
Action: tensor([[[-4.5786e-04,  5.9105e-01],
         [-1.0840e-03,  3.2137e-01],
         [-9.3745e-04,  2.2094e-01],
         [-1.0678e-03,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.356271306481944
+++++++++++++: inf
4.911129107698798 seconds in game passed.
At 4.911129107698798 seconds, saving state-action tuples.
Action: tensor([[[ 7.4230e-04,  5.8993e-01],
         [-4.0746e-04,  3.2144e-01],
         [-2.8232e-04,  2.2101e-01],
         [-3.5588e-04,  1.6712e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0188346440458274
Current mitigation activation: 0
#############################
Total reward: 6.375105950527772
4.936129108071327 seconds in game passed.
Action: tensor([[[ 7.4230e-04,  5.8993e-01],
         [-4.0746e-04,  3.2144e-01],
         [-2.8232e-04,  2.2101e-01],
         [-3.5588e-04,  1.6712e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000465, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375105950527772
4.961129108443856 seconds in game passed.
Action: tensor([[[ 7.4230e-04,  5.8993e-01],
         [-4.0746e-04,  3.2144e-01],
         [-2.8232e-04,  2.2101e-01],
         [-3.5588e-04,  1.6712e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375105950527772
4.986129108816385 seconds in game passed.
Action: tensor([[[ 7.4230e-04,  5.8993e-01],
         [-4.0746e-04,  3.2144e-01],
         [-2.8232e-04,  2.2101e-01],
         [-3.5588e-04,  1.6712e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375105950527772
+++++++++++++: inf
5.011129109188914 seconds in game passed.
At 5.011129109188914 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0710445086844924
Current mitigation activation: 0
#############################
Total reward: 7.446150459212264
5.036129109561443 seconds in game passed.
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150459212264
5.061129109933972 seconds in game passed.
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150459212264
5.086129110306501 seconds in game passed.
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150459212264
+++++++++++++: inf
5.11112911067903 seconds in game passed.
At 5.11112911067903 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2498e-03, 5.8966e-01],
         [8.5910e-04, 3.2201e-01],
         [7.2961e-04, 2.2273e-01],
         [3.7007e-04, 1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001283, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1199923847584652
Current mitigation activation: 0
#############################
Total reward: 8.566142843970729
5.1361291110515594 seconds in game passed.
Action: tensor([[[1.2498e-03, 5.8966e-01],
         [8.5910e-04, 3.2201e-01],
         [7.2961e-04, 2.2273e-01],
         [3.7007e-04, 1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566142843970729
5.1611291114240885 seconds in game passed.
Action: tensor([[[1.2498e-03, 5.8966e-01],
         [8.5910e-04, 3.2201e-01],
         [7.2961e-04, 2.2273e-01],
         [3.7007e-04, 1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001335, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566142843970729
5.1861291117966175 seconds in game passed.
Action: tensor([[[1.2498e-03, 5.8966e-01],
         [8.5910e-04, 3.2201e-01],
         [7.2961e-04, 2.2273e-01],
         [3.7007e-04, 1.6872e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566142843970729
+++++++++++++: inf
5.2111291121691465 seconds in game passed.
At 5.2111291121691465 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5846],
         [0.0020, 0.3191],
         [0.0019, 0.2208],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002252, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1663832449804383
Current mitigation activation: 0
#############################
Total reward: 9.732526088951168
5.236129112541676 seconds in game passed.
Action: tensor([[[0.0016, 0.5846],
         [0.0020, 0.3191],
         [0.0019, 0.2208],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732526088951168
5.261129112914205 seconds in game passed.
Action: tensor([[[0.0016, 0.5846],
         [0.0020, 0.3191],
         [0.0019, 0.2208],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732526088951168
5.286129113286734 seconds in game passed.
Action: tensor([[[0.0016, 0.5846],
         [0.0020, 0.3191],
         [0.0019, 0.2208],
         [0.0016, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732526088951168
+++++++++++++: inf
5.311129113659263 seconds in game passed.
At 5.311129113659263 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.5930],
         [0.0008, 0.3213],
         [0.0009, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001267, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2107460334754279
Current mitigation activation: 0
#############################
Total reward: 10.943272122426595
5.336129114031792 seconds in game passed.
Action: tensor([[[0.0015, 0.5930],
         [0.0008, 0.3213],
         [0.0009, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943272122426595
5.361129114404321 seconds in game passed.
Action: tensor([[[0.0015, 0.5930],
         [0.0008, 0.3213],
         [0.0009, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943272122426595
5.38612911477685 seconds in game passed.
Action: tensor([[[0.0015, 0.5930],
         [0.0008, 0.3213],
         [0.0009, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001390, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943272122426595
+++++++++++++: inf
5.411129115149379 seconds in game passed.
At 5.411129115149379 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5911],
         [0.0015, 0.3211],
         [0.0016, 0.2205],
         [0.0013, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2534932613492704
Current mitigation activation: 0
#############################
Total reward: 12.196765383775865
5.436129115521908 seconds in game passed.
Action: tensor([[[0.0016, 0.5911],
         [0.0015, 0.3211],
         [0.0016, 0.2205],
         [0.0013, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196765383775865
5.461129115894437 seconds in game passed.
Action: tensor([[[0.0016, 0.5911],
         [0.0015, 0.3211],
         [0.0016, 0.2205],
         [0.0013, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001816, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196765383775865
5.486129116266966 seconds in game passed.
Action: tensor([[[0.0016, 0.5911],
         [0.0015, 0.3211],
         [0.0016, 0.2205],
         [0.0013, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001807, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196765383775865
+++++++++++++: inf
5.511129116639495 seconds in game passed.
At 5.511129116639495 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0743e-03, 5.8993e-01],
         [6.4416e-04, 3.2038e-01],
         [6.2031e-04, 2.1993e-01],
         [3.1135e-04, 1.6601e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.279943520666769
Current mitigation activation: 0
#############################
Total reward: 13.476708904442635
5.536129117012024 seconds in game passed.
Action: tensor([[[1.0743e-03, 5.8993e-01],
         [6.4416e-04, 3.2038e-01],
         [6.2031e-04, 2.1993e-01],
         [3.1135e-04, 1.6601e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476708904442635
5.561129117384553 seconds in game passed.
Action: tensor([[[1.0743e-03, 5.8993e-01],
         [6.4416e-04, 3.2038e-01],
         [6.2031e-04, 2.1993e-01],
         [3.1135e-04, 1.6601e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476708904442635
5.586129117757082 seconds in game passed.
Action: tensor([[[1.0743e-03, 5.8993e-01],
         [6.4416e-04, 3.2038e-01],
         [6.2031e-04, 2.1993e-01],
         [3.1135e-04, 1.6601e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476708904442635
+++++++++++++: inf
5.611129118129611 seconds in game passed.
At 5.611129118129611 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.1595e-04,  5.9107e-01],
         [-2.3146e-04,  3.2047e-01],
         [-4.2085e-04,  2.1969e-01],
         [-8.7260e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2784691484564896
Current mitigation activation: 0
#############################
Total reward: 14.755178052899124
5.63612911850214 seconds in game passed.
Action: tensor([[[ 5.1595e-04,  5.9107e-01],
         [-2.3146e-04,  3.2047e-01],
         [-4.2085e-04,  2.1969e-01],
         [-8.7260e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755178052899124
5.661129118874669 seconds in game passed.
Action: tensor([[[ 5.1595e-04,  5.9107e-01],
         [-2.3146e-04,  3.2047e-01],
         [-4.2085e-04,  2.1969e-01],
         [-8.7260e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755178052899124
5.686129119247198 seconds in game passed.
Action: tensor([[[ 5.1595e-04,  5.9107e-01],
         [-2.3146e-04,  3.2047e-01],
         [-4.2085e-04,  2.1969e-01],
         [-8.7260e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755178052899124
+++++++++++++: inf
5.711129119619727 seconds in game passed.
At 5.711129119619727 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0026,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2767190469039722
Current mitigation activation: 0
#############################
Total reward: 16.031897099803096
5.736129119992256 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0026,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031897099803096
5.761129120364785 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0026,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031897099803096
5.786129120737314 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0026,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031897099803096
+++++++++++++: inf
5.811129121109843 seconds in game passed.
At 5.811129121109843 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.5907],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2749363529754845
Current mitigation activation: 0
#############################
Total reward: 17.30683345277858
5.836129121482372 seconds in game passed.
Action: tensor([[[-0.0011,  0.5907],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.30683345277858
5.861129121854901 seconds in game passed.
Action: tensor([[[-0.0011,  0.5907],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001695, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.30683345277858
5.88612912222743 seconds in game passed.
Action: tensor([[[-0.0011,  0.5907],
         [-0.0025,  0.3205],
         [-0.0029,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.30683345277858
+++++++++++++: inf
5.911129122599959 seconds in game passed.
At 5.911129122599959 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.5343e-05,  5.8999e-01],
         [-9.1009e-04,  3.2109e-01],
         [-1.0761e-03,  2.2063e-01],
         [-1.3643e-03,  1.6675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000084, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2730962206179621
Current mitigation activation: 0
#############################
Total reward: 18.579929673396542
5.936129122972488 seconds in game passed.
Action: tensor([[[ 5.5343e-05,  5.8999e-01],
         [-9.1009e-04,  3.2109e-01],
         [-1.0761e-03,  2.2063e-01],
         [-1.3643e-03,  1.6675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579929673396542
5.961129123345017 seconds in game passed.
Action: tensor([[[ 5.5343e-05,  5.8999e-01],
         [-9.1009e-04,  3.2109e-01],
         [-1.0761e-03,  2.2063e-01],
         [-1.3643e-03,  1.6675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579929673396542
5.9861291237175465 seconds in game passed.
Action: tensor([[[ 5.5343e-05,  5.8999e-01],
         [-9.1009e-04,  3.2109e-01],
         [-1.0761e-03,  2.2063e-01],
         [-1.3643e-03,  1.6675e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579929673396542
+++++++++++++: inf
6.0111291240900755 seconds in game passed.
At 6.0111291240900755 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.4157e-03,  5.9071e-01],
         [ 1.9436e-04,  3.2145e-01],
         [ 2.0804e-04,  2.2094e-01],
         [-6.7078e-05,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000958, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2883942429849304
Current mitigation activation: 0
#############################
Total reward: 19.868323916381474
6.0361291244626045 seconds in game passed.
Action: tensor([[[ 1.4157e-03,  5.9071e-01],
         [ 1.9436e-04,  3.2145e-01],
         [ 2.0804e-04,  2.2094e-01],
         [-6.7078e-05,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868323916381474
6.0611291248351336 seconds in game passed.
Action: tensor([[[ 1.4157e-03,  5.9071e-01],
         [ 1.9436e-04,  3.2145e-01],
         [ 2.0804e-04,  2.2094e-01],
         [-6.7078e-05,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868323916381474
6.086129125207663 seconds in game passed.
Action: tensor([[[ 1.4157e-03,  5.9071e-01],
         [ 1.9436e-04,  3.2145e-01],
         [ 2.0804e-04,  2.2094e-01],
         [-6.7078e-05,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868323916381474
+++++++++++++: inf
6.111129125580192 seconds in game passed.
At 6.111129125580192 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0027, 0.5908],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002751, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3503112412423306
Current mitigation activation: 0
#############################
Total reward: 21.218635157623805
6.136129125952721 seconds in game passed.
Action: tensor([[[0.0027, 0.5908],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218635157623805
6.16112912632525 seconds in game passed.
Action: tensor([[[0.0027, 0.5908],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002447, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218635157623805
6.186129126697779 seconds in game passed.
Action: tensor([[[0.0027, 0.5908],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.854026, steer=0.002464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218635157623805
+++++++++++++: inf
6.211129127070308 seconds in game passed.
At 6.211129127070308 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1667e-03,  5.9171e-01],
         [ 1.0439e-03,  3.2205e-01],
         [ 3.5480e-04,  2.2147e-01],
         [-8.2583e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.806080, steer=0.001350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4066994969980104
Current mitigation activation: 0
#############################
Total reward: 22.625334654621817
6.236129127442837 seconds in game passed.
Action: tensor([[[ 2.1667e-03,  5.9171e-01],
         [ 1.0439e-03,  3.2205e-01],
         [ 3.5480e-04,  2.2147e-01],
         [-8.2583e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.756491, steer=0.001531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625334654621817
6.261129127815366 seconds in game passed.
Action: tensor([[[ 2.1667e-03,  5.9171e-01],
         [ 1.0439e-03,  3.2205e-01],
         [ 3.5480e-04,  2.2147e-01],
         [-8.2583e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.708576, steer=0.001527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625334654621817
6.286129128187895 seconds in game passed.
Action: tensor([[[ 2.1667e-03,  5.9171e-01],
         [ 1.0439e-03,  3.2205e-01],
         [ 3.5480e-04,  2.2147e-01],
         [-8.2583e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.662397, steer=0.001522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625334654621817
+++++++++++++: inf
6.311129128560424 seconds in game passed.
At 6.311129128560424 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0971e-04,  5.9651e-01],
         [-5.6791e-04,  3.2307e-01],
         [-1.4544e-03,  2.2110e-01],
         [-2.7407e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.633307, steer=-0.000401, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4565015441439038
Current mitigation activation: 0
#############################
Total reward: 24.08183619876572
6.336129128932953 seconds in game passed.
Action: tensor([[[ 3.0971e-04,  5.9651e-01],
         [-5.6791e-04,  3.2307e-01],
         [-1.4544e-03,  2.2110e-01],
         [-2.7407e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.589941, steer=-0.000099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08183619876572
6.361129129305482 seconds in game passed.
Action: tensor([[[ 3.0971e-04,  5.9651e-01],
         [-5.6791e-04,  3.2307e-01],
         [-1.4544e-03,  2.2110e-01],
         [-2.7407e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.550707, steer=-0.000114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08183619876572
6.386129129678011 seconds in game passed.
Action: tensor([[[ 3.0971e-04,  5.9651e-01],
         [-5.6791e-04,  3.2307e-01],
         [-1.4544e-03,  2.2110e-01],
         [-2.7407e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.514092, steer=-0.000130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08183619876572
+++++++++++++: inf
6.41112913005054 seconds in game passed.
At 6.41112913005054 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-2.9638e-05,  5.9909e-01],
         [-9.9883e-04,  3.2452e-01],
         [-1.9134e-03,  2.2236e-01],
         [-3.3502e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.454404, steer=-0.000604, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4972855194076828
Current mitigation activation: 0
#############################
Total reward: 25.579121718173404
6.436129130423069 seconds in game passed.
Action: tensor([[[-2.9638e-05,  5.9909e-01],
         [-9.9883e-04,  3.2452e-01],
         [-1.9134e-03,  2.2236e-01],
         [-3.3502e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.426211, steer=-0.000555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579121718173404
6.461129130795598 seconds in game passed.
Action: tensor([[[-2.9638e-05,  5.9909e-01],
         [-9.9883e-04,  3.2452e-01],
         [-1.9134e-03,  2.2236e-01],
         [-3.3502e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.397943, steer=-0.000581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579121718173404
6.486129131168127 seconds in game passed.
Action: tensor([[[-2.9638e-05,  5.9909e-01],
         [-9.9883e-04,  3.2452e-01],
         [-1.9134e-03,  2.2236e-01],
         [-3.3502e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.372640, steer=-0.000607, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579121718173404
+++++++++++++: inf
6.511129131540656 seconds in game passed.
At 6.511129131540656 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.6089],
         [-0.0062,  0.3266],
         [-0.0077,  0.2221],
         [-0.0092,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.378655, steer=-0.005983, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5250806538819512
Current mitigation activation: 0
#############################
Total reward: 27.104202372055354
6.536129131913185 seconds in game passed.
Action: tensor([[[-0.0039,  0.6089],
         [-0.0062,  0.3266],
         [-0.0077,  0.2221],
         [-0.0092,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.356313, steer=-0.005171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104202372055354
6.561129132285714 seconds in game passed.
Action: tensor([[[-0.0039,  0.6089],
         [-0.0062,  0.3266],
         [-0.0077,  0.2221],
         [-0.0092,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.339801, steer=-0.005243, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104202372055354
6.586129132658243 seconds in game passed.
Action: tensor([[[-0.0039,  0.6089],
         [-0.0062,  0.3266],
         [-0.0077,  0.2221],
         [-0.0092,  0.1684]]])
agent 0 action: VehicleControl(throttle=0.325676, steer=-0.005316, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104202372055354
+++++++++++++: inf
6.611129133030772 seconds in game passed.
At 6.611129133030772 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.6079],
         [-0.0052,  0.3266],
         [-0.0063,  0.2225],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.303499, steer=-0.004318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5378783262694338
Current mitigation activation: 0
#############################
Total reward: 28.64208069832479
6.636129133403301 seconds in game passed.
Action: tensor([[[-0.0030,  0.6079],
         [-0.0052,  0.3266],
         [-0.0063,  0.2225],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.294918, steer=-0.004546, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64208069832479
6.66112913377583 seconds in game passed.
Action: tensor([[[-0.0030,  0.6079],
         [-0.0052,  0.3266],
         [-0.0063,  0.2225],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.287386, steer=-0.004598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64208069832479
6.686129134148359 seconds in game passed.
Action: tensor([[[-0.0030,  0.6079],
         [-0.0052,  0.3266],
         [-0.0063,  0.2225],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.281908, steer=-0.004651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64208069832479
+++++++++++++: inf
6.711129134520888 seconds in game passed.
At 6.711129134520888 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261659, steer=-0.003379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5376459045595083
Current mitigation activation: 0
#############################
Total reward: 30.179726602884298
6.736129134893417 seconds in game passed.
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261382, steer=-0.003614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.179726602884298
6.761129135265946 seconds in game passed.
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.260878, steer=-0.003634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.179726602884298
6.786129135638475 seconds in game passed.
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261881, steer=-0.003654, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.179726602884298
+++++++++++++: inf
6.8111291360110044 seconds in game passed.
At 6.8111291360110044 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0010,  0.5936],
         [-0.0029,  0.3228],
         [-0.0034,  0.2215],
         [-0.0040,  0.1674]]])
agent 0 action: VehicleControl(throttle=0.266659, steer=-0.002433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5276632451685497
Current mitigation activation: 0
#############################
Total reward: 31.70738984805285
6.8361291363835335 seconds in game passed.
Action: tensor([[[-0.0010,  0.5936],
         [-0.0029,  0.3228],
         [-0.0034,  0.2215],
         [-0.0040,  0.1674]]])
agent 0 action: VehicleControl(throttle=0.269788, steer=-0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.70738984805285
6.8611291367560625 seconds in game passed.
Action: tensor([[[-0.0010,  0.5936],
         [-0.0029,  0.3228],
         [-0.0034,  0.2215],
         [-0.0040,  0.1674]]])
agent 0 action: VehicleControl(throttle=0.274141, steer=-0.002641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.70738984805285
6.8861291371285915 seconds in game passed.
Action: tensor([[[-0.0010,  0.5936],
         [-0.0029,  0.3228],
         [-0.0034,  0.2215],
         [-0.0040,  0.1674]]])
agent 0 action: VehicleControl(throttle=0.279293, steer=-0.002643, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.70738984805285
+++++++++++++: inf
6.911129137501121 seconds in game passed.
At 6.911129137501121 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0010,  0.6015],
         [-0.0012,  0.3244],
         [-0.0027,  0.2215],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.312814, steer=-0.000675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5111871914179043
Current mitigation activation: 0
#############################
Total reward: 33.21857703947075
6.93612913787365 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6015],
         [-0.0012,  0.3244],
         [-0.0027,  0.2215],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.316927, steer=-0.001002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21857703947075
6.961129138246179 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6015],
         [-0.0012,  0.3244],
         [-0.0027,  0.2215],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.324638, steer=-0.001000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21857703947075
6.986129138618708 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6015],
         [-0.0012,  0.3244],
         [-0.0027,  0.2215],
         [-0.0046,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.333092, steer=-0.000999, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21857703947075
+++++++++++++: inf
7.011129138991237 seconds in game passed.
At 7.011129138991237 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9586e-04,  6.0099e-01],
         [-6.5915e-04,  3.2374e-01],
         [-1.3907e-03,  2.2139e-01],
         [-2.8202e-03,  1.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.360641, steer=-0.000862, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4915803283332019
Current mitigation activation: 0
#############################
Total reward: 34.71015736780395
7.036129139363766 seconds in game passed.
Action: tensor([[[ 2.9586e-04,  6.0099e-01],
         [-6.5915e-04,  3.2374e-01],
         [-1.3907e-03,  2.2139e-01],
         [-2.8202e-03,  1.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.368701, steer=-0.000898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71015736780395
7.061129139736295 seconds in game passed.
Action: tensor([[[ 2.9586e-04,  6.0099e-01],
         [-6.5915e-04,  3.2374e-01],
         [-1.3907e-03,  2.2139e-01],
         [-2.8202e-03,  1.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.379145, steer=-0.000909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71015736780395
7.086129140108824 seconds in game passed.
Action: tensor([[[ 2.9586e-04,  6.0099e-01],
         [-6.5915e-04,  3.2374e-01],
         [-1.3907e-03,  2.2139e-01],
         [-2.8202e-03,  1.6723e-01]]])
agent 0 action: VehicleControl(throttle=0.389805, steer=-0.000920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71015736780395
+++++++++++++: inf
7.111129140481353 seconds in game passed.
At 7.111129140481353 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0021,  0.5979],
         [-0.0006,  0.3251],
         [-0.0015,  0.2236],
         [-0.0029,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.317512, steer=-0.000193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.472048576431106
Current mitigation activation: 0
#############################
Total reward: 36.18220594423506
7.136129140853882 seconds in game passed.
Action: tensor([[[ 0.0021,  0.5979],
         [-0.0006,  0.3251],
         [-0.0015,  0.2236],
         [-0.0029,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.336547, steer=-0.000343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18220594423506
7.161129141226411 seconds in game passed.
Action: tensor([[[ 0.0021,  0.5979],
         [-0.0006,  0.3251],
         [-0.0015,  0.2236],
         [-0.0029,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.347089, steer=-0.000367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18220594423506
7.18612914159894 seconds in game passed.
Action: tensor([[[ 0.0021,  0.5979],
         [-0.0006,  0.3251],
         [-0.0015,  0.2236],
         [-0.0029,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.358521, steer=-0.000391, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18220594423506
+++++++++++++: inf
7.211129141971469 seconds in game passed.
At 7.211129141971469 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2929e-04,  6.0104e-01],
         [-1.1375e-03,  3.2583e-01],
         [-1.6243e-03,  2.2280e-01],
         [-2.6063e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.376646, steer=-0.001581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4546076000240518
Current mitigation activation: 0
#############################
Total reward: 37.63681354425911
7.236129142343998 seconds in game passed.
Action: tensor([[[ 1.2929e-04,  6.0104e-01],
         [-1.1375e-03,  3.2583e-01],
         [-1.6243e-03,  2.2280e-01],
         [-2.6063e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.388487, steer=-0.001412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63681354425911
7.261129142716527 seconds in game passed.
Action: tensor([[[ 1.2929e-04,  6.0104e-01],
         [-1.1375e-03,  3.2583e-01],
         [-1.6243e-03,  2.2280e-01],
         [-2.6063e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.401294, steer=-0.001437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63681354425911
7.286129143089056 seconds in game passed.
Action: tensor([[[ 1.2929e-04,  6.0104e-01],
         [-1.1375e-03,  3.2583e-01],
         [-1.6243e-03,  2.2280e-01],
         [-2.6063e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.414250, steer=-0.001462, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63681354425911
+++++++++++++: inf
7.311129143461585 seconds in game passed.
At 7.311129143461585 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6050],
         [-0.0039,  0.3273],
         [-0.0048,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.415806, steer=-0.004051, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4383028681936125
Current mitigation activation: 0
#############################
Total reward: 39.07511641245272
7.336129143834114 seconds in game passed.
Action: tensor([[[-0.0013,  0.6050],
         [-0.0039,  0.3273],
         [-0.0048,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.429674, steer=-0.003657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07511641245272
7.361129144206643 seconds in game passed.
Action: tensor([[[-0.0013,  0.6050],
         [-0.0039,  0.3273],
         [-0.0048,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.442248, steer=-0.003688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07511641245272
7.386129144579172 seconds in game passed.
Action: tensor([[[-0.0013,  0.6050],
         [-0.0039,  0.3273],
         [-0.0048,  0.2237],
         [-0.0060,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.454706, steer=-0.003720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07511641245272
+++++++++++++: inf
7.411129144951701 seconds in game passed.
At 7.411129144951701 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6052],
         [-0.0051,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.501761, steer=-0.005017, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4240728416509603
Current mitigation activation: 0
#############################
Total reward: 40.49918925410368
7.43612914532423 seconds in game passed.
Action: tensor([[[-0.0021,  0.6052],
         [-0.0051,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.510674, steer=-0.004848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49918925410368
7.461129145696759 seconds in game passed.
Action: tensor([[[-0.0021,  0.6052],
         [-0.0051,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.522729, steer=-0.004888, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49918925410368
7.486129146069288 seconds in game passed.
Action: tensor([[[-0.0021,  0.6052],
         [-0.0051,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.533917, steer=-0.004928, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49918925410368
+++++++++++++: inf
7.511129146441817 seconds in game passed.
At 7.511129146441817 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.8918e-04,  5.9978e-01],
         [-2.3674e-03,  3.2489e-01],
         [-2.9968e-03,  2.2212e-01],
         [-3.6653e-03,  1.6879e-01]]])
agent 0 action: VehicleControl(throttle=0.541924, steer=-0.002211, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4131296428959483
Current mitigation activation: 0
#############################
Total reward: 41.91231889699963
7.536129146814346 seconds in game passed.
Action: tensor([[[-4.8918e-04,  5.9978e-01],
         [-2.3674e-03,  3.2489e-01],
         [-2.9968e-03,  2.2212e-01],
         [-3.6653e-03,  1.6879e-01]]])
agent 0 action: VehicleControl(throttle=0.549089, steer=-0.002614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91231889699963
7.561129147186875 seconds in game passed.
Action: tensor([[[-4.8918e-04,  5.9978e-01],
         [-2.3674e-03,  3.2489e-01],
         [-2.9968e-03,  2.2212e-01],
         [-3.6653e-03,  1.6879e-01]]])
agent 0 action: VehicleControl(throttle=0.555539, steer=-0.002571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91231889699963
7.586129147559404 seconds in game passed.
Action: tensor([[[-4.8918e-04,  5.9978e-01],
         [-2.3674e-03,  3.2489e-01],
         [-2.9968e-03,  2.2212e-01],
         [-3.6653e-03,  1.6879e-01]]])
agent 0 action: VehicleControl(throttle=0.562019, steer=-0.002528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91231889699963
+++++++++++++: inf
7.611129147931933 seconds in game passed.
At 7.611129147931933 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0147e-02,  6.3935e-01],
         [-5.2646e-04,  3.4517e-01],
         [-2.2959e-03,  2.3587e-01],
         [-3.2487e-03,  1.7896e-01]]])
agent 0 action: VehicleControl(throttle=0.264249, steer=0.003113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4080178050675736
Current mitigation activation: 0
#############################
Total reward: 43.3203367020672
7.636129148304462 seconds in game passed.
Action: tensor([[[ 1.0147e-02,  6.3935e-01],
         [-5.2646e-04,  3.4517e-01],
         [-2.2959e-03,  2.3587e-01],
         [-3.2487e-03,  1.7896e-01]]])
agent 0 action: VehicleControl(throttle=0.299777, steer=0.002277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.3203367020672
7.6611291486769915 seconds in game passed.
Action: tensor([[[ 1.0147e-02,  6.3935e-01],
         [-5.2646e-04,  3.4517e-01],
         [-2.2959e-03,  2.3587e-01],
         [-3.2487e-03,  1.7896e-01]]])
agent 0 action: VehicleControl(throttle=0.303054, steer=0.002367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.3203367020672
7.6861291490495205 seconds in game passed.
Action: tensor([[[ 1.0147e-02,  6.3935e-01],
         [-5.2646e-04,  3.4517e-01],
         [-2.2959e-03,  2.3587e-01],
         [-3.2487e-03,  1.7896e-01]]])
agent 0 action: VehicleControl(throttle=0.306272, steer=0.002457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.3203367020672
+++++++++++++: inf
7.7111291494220495 seconds in game passed.
At 7.7111291494220495 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0164, 0.6424],
         [0.0038, 0.3498],
         [0.0023, 0.2402],
         [0.0013, 0.1827]]])
agent 0 action: VehicleControl(throttle=0.189466, steer=0.008264, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4059466543821162
Current mitigation activation: 0
#############################
Total reward: 44.726283356449315
7.7361291497945786 seconds in game passed.
Action: tensor([[[0.0164, 0.6424],
         [0.0038, 0.3498],
         [0.0023, 0.2402],
         [0.0013, 0.1827]]])
agent 0 action: VehicleControl(throttle=0.204119, steer=0.007455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.726283356449315
7.761129150167108 seconds in game passed.
Action: tensor([[[0.0164, 0.6424],
         [0.0038, 0.3498],
         [0.0023, 0.2402],
         [0.0013, 0.1827]]])
agent 0 action: VehicleControl(throttle=0.206001, steer=0.007590, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.726283356449315
7.786129150539637 seconds in game passed.
Action: tensor([[[0.0164, 0.6424],
         [0.0038, 0.3498],
         [0.0023, 0.2402],
         [0.0013, 0.1827]]])
agent 0 action: VehicleControl(throttle=0.207718, steer=0.007726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.726283356449315
+++++++++++++: inf
7.811129150912166 seconds in game passed.
At 7.811129150912166 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.1367e-03, 5.9857e-01],
         [1.6496e-03, 3.2377e-01],
         [1.0653e-03, 2.2231e-01],
         [2.7330e-04, 1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.662259, steer=0.001710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4038256771386484
Current mitigation activation: 0
#############################
Total reward: 46.13010903358796
7.836129151284695 seconds in game passed.
Action: tensor([[[5.1367e-03, 5.9857e-01],
         [1.6496e-03, 3.2377e-01],
         [1.0653e-03, 2.2231e-01],
         [2.7330e-04, 1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.620654, steer=0.002782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.13010903358796
7.861129151657224 seconds in game passed.
Action: tensor([[[5.1367e-03, 5.9857e-01],
         [1.6496e-03, 3.2377e-01],
         [1.0653e-03, 2.2231e-01],
         [2.7330e-04, 1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.626859, steer=0.002841, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.13010903358796
7.886129152029753 seconds in game passed.
Action: tensor([[[5.1367e-03, 5.9857e-01],
         [1.6496e-03, 3.2377e-01],
         [1.0653e-03, 2.2231e-01],
         [2.7330e-04, 1.6898e-01]]])
agent 0 action: VehicleControl(throttle=0.632907, steer=0.002901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.13010903358796
+++++++++++++: inf
7.911129152402282 seconds in game passed.
At 7.911129152402282 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.5830e-03,  5.9426e-01],
         [-9.5628e-05,  3.2350e-01],
         [-6.6265e-04,  2.2255e-01],
         [-1.2689e-03,  1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.601132, steer=0.001041, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4017295243354218
Current mitigation activation: 0
#############################
Total reward: 47.531838557923386
7.936129152774811 seconds in game passed.
Action: tensor([[[ 3.5830e-03,  5.9426e-01],
         [-9.5628e-05,  3.2350e-01],
         [-6.6265e-04,  2.2255e-01],
         [-1.2689e-03,  1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.610075, steer=0.001373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.531838557923386
7.96112915314734 seconds in game passed.
Action: tensor([[[ 3.5830e-03,  5.9426e-01],
         [-9.5628e-05,  3.2350e-01],
         [-6.6265e-04,  2.2255e-01],
         [-1.2689e-03,  1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.614878, steer=0.001393, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.531838557923386
7.986129153519869 seconds in game passed.
Action: tensor([[[ 3.5830e-03,  5.9426e-01],
         [-9.5628e-05,  3.2350e-01],
         [-6.6265e-04,  2.2255e-01],
         [-1.2689e-03,  1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.619504, steer=0.001412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.531838557923386
+++++++++++++: inf
8.011129153892398 seconds in game passed.
At 8.011129153892398 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8422e-04,  5.9686e-01],
         [-8.7222e-04,  3.2312e-01],
         [-1.0861e-03,  2.2180e-01],
         [-1.3565e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.666620, steer=-0.000502, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3996336100796845
Current mitigation activation: 0
#############################
Total reward: 48.93147216800307
8.036129154264927 seconds in game passed.
Action: tensor([[[ 1.8422e-04,  5.9686e-01],
         [-8.7222e-04,  3.2312e-01],
         [-1.0861e-03,  2.2180e-01],
         [-1.3565e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.666623, steer=-0.000185, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.93147216800307
8.061129154637456 seconds in game passed.
Action: tensor([[[ 1.8422e-04,  5.9686e-01],
         [-8.7222e-04,  3.2312e-01],
         [-1.0861e-03,  2.2180e-01],
         [-1.3565e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.650731, steer=-0.000187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.93147216800307
8.086129155009985 seconds in game passed.
Action: tensor([[[ 1.8422e-04,  5.9686e-01],
         [-8.7222e-04,  3.2312e-01],
         [-1.0861e-03,  2.2180e-01],
         [-1.3565e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.638210, steer=-0.000190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.93147216800307
+++++++++++++: inf
8.111129155382514 seconds in game passed.
At 8.111129155382514 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6088],
         [-0.0037,  0.3269],
         [-0.0039,  0.2227],
         [-0.0041,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.613337, steer=-0.003275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4048201666738167
Current mitigation activation: 0
#############################
Total reward: 50.336292334676884
8.136129155755043 seconds in game passed.
Action: tensor([[[-0.0023,  0.6088],
         [-0.0037,  0.3269],
         [-0.0039,  0.2227],
         [-0.0041,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.603021, steer=-0.002809, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.336292334676884
8.161129156127572 seconds in game passed.
Action: tensor([[[-0.0023,  0.6088],
         [-0.0037,  0.3269],
         [-0.0039,  0.2227],
         [-0.0041,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.591528, steer=-0.002851, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.336292334676884
8.186129156500101 seconds in game passed.
Action: tensor([[[-0.0023,  0.6088],
         [-0.0037,  0.3269],
         [-0.0039,  0.2227],
         [-0.0041,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.580331, steer=-0.002893, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.336292334676884
+++++++++++++: inf
8.21112915687263 seconds in game passed.
At 8.21112915687263 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0049,  0.6105],
         [-0.0066,  0.3281],
         [-0.0070,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.546175, steer=-0.006063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4223169715182638
Current mitigation activation: 0
#############################
Total reward: 51.75860930619515
8.23612915724516 seconds in game passed.
Action: tensor([[[-0.0049,  0.6105],
         [-0.0066,  0.3281],
         [-0.0070,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.537727, steer=-0.005606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.75860930619515
8.261129157617688 seconds in game passed.
Action: tensor([[[-0.0049,  0.6105],
         [-0.0066,  0.3281],
         [-0.0070,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.527245, steer=-0.005668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.75860930619515
8.286129157990217 seconds in game passed.
Action: tensor([[[-0.0049,  0.6105],
         [-0.0066,  0.3281],
         [-0.0070,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.517278, steer=-0.005730, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.75860930619515
+++++++++++++: inf
8.311129158362746 seconds in game passed.
At 8.311129158362746 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0018,  0.5990],
         [-0.0027,  0.3242],
         [-0.0030,  0.2224],
         [-0.0034,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.527007, steer=-0.001709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.437044533594014
Current mitigation activation: 0
#############################
Total reward: 53.19565383978916
8.336129158735275 seconds in game passed.
Action: tensor([[[-0.0018,  0.5990],
         [-0.0027,  0.3242],
         [-0.0030,  0.2224],
         [-0.0034,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.516302, steer=-0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19565383978916
8.361129159107804 seconds in game passed.
Action: tensor([[[-0.0018,  0.5990],
         [-0.0027,  0.3242],
         [-0.0030,  0.2224],
         [-0.0034,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.508008, steer=-0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19565383978916
8.386129159480333 seconds in game passed.
Action: tensor([[[-0.0018,  0.5990],
         [-0.0027,  0.3242],
         [-0.0030,  0.2224],
         [-0.0034,  0.1695]]])
agent 0 action: VehicleControl(throttle=0.499988, steer=-0.002358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19565383978916
+++++++++++++: inf
8.411129159852862 seconds in game passed.
At 8.411129159852862 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0580e-03,  6.0724e-01],
         [ 1.0841e-03,  3.2935e-01],
         [ 5.0176e-04,  2.2576e-01],
         [-3.7643e-04,  1.7174e-01]]])
agent 0 action: VehicleControl(throttle=0.391770, steer=0.002411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4482321010264187
Current mitigation activation: 0
#############################
Total reward: 54.64388594081558
8.436129160225391 seconds in game passed.
Action: tensor([[[ 3.0580e-03,  6.0724e-01],
         [ 1.0841e-03,  3.2935e-01],
         [ 5.0176e-04,  2.2576e-01],
         [-3.7643e-04,  1.7174e-01]]])
agent 0 action: VehicleControl(throttle=0.393499, steer=0.001697, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.64388594081558
8.46112916059792 seconds in game passed.
Action: tensor([[[ 3.0580e-03,  6.0724e-01],
         [ 1.0841e-03,  3.2935e-01],
         [ 5.0176e-04,  2.2576e-01],
         [-3.7643e-04,  1.7174e-01]]])
agent 0 action: VehicleControl(throttle=0.385237, steer=0.001765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.64388594081558
8.48612916097045 seconds in game passed.
Action: tensor([[[ 3.0580e-03,  6.0724e-01],
         [ 1.0841e-03,  3.2935e-01],
         [ 5.0176e-04,  2.2576e-01],
         [-3.7643e-04,  1.7174e-01]]])
agent 0 action: VehicleControl(throttle=0.378159, steer=0.001834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.64388594081558
+++++++++++++: inf
8.511129161342978 seconds in game passed.
At 8.511129161342978 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0081, 0.6319],
         [0.0037, 0.3509],
         [0.0031, 0.2452],
         [0.0022, 0.1892]]])
agent 0 action: VehicleControl(throttle=0.141114, steer=0.005836, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4562670487539815
Current mitigation activation: 0
#############################
Total reward: 56.10015298956956
8.536129161715508 seconds in game passed.
Action: tensor([[[0.0081, 0.6319],
         [0.0037, 0.3509],
         [0.0031, 0.2452],
         [0.0022, 0.1892]]])
agent 0 action: VehicleControl(throttle=0.160544, steer=0.005265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.10015298956956
8.561129162088037 seconds in game passed.
Action: tensor([[[0.0081, 0.6319],
         [0.0037, 0.3509],
         [0.0031, 0.2452],
         [0.0022, 0.1892]]])
agent 0 action: VehicleControl(throttle=0.155077, steer=0.005346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.10015298956956
8.586129162460566 seconds in game passed.
Action: tensor([[[0.0081, 0.6319],
         [0.0037, 0.3509],
         [0.0031, 0.2452],
         [0.0022, 0.1892]]])
agent 0 action: VehicleControl(throttle=0.149588, steer=0.005428, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.10015298956956
+++++++++++++: inf
8.611129162833095 seconds in game passed.
At 8.611129162833095 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0070, 0.6170],
         [0.0028, 0.3396],
         [0.0019, 0.2361],
         [0.0011, 0.1821]]])
agent 0 action: VehicleControl(throttle=0.147439, steer=0.004382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4592968337540055
Current mitigation activation: 0
#############################
Total reward: 57.55944982332356
8.636129163205624 seconds in game passed.
Action: tensor([[[0.0070, 0.6170],
         [0.0028, 0.3396],
         [0.0019, 0.2361],
         [0.0011, 0.1821]]])
agent 0 action: VehicleControl(throttle=0.145270, steer=0.004571, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55944982332356
8.661129163578153 seconds in game passed.
Action: tensor([[[0.0070, 0.6170],
         [0.0028, 0.3396],
         [0.0019, 0.2361],
         [0.0011, 0.1821]]])
agent 0 action: VehicleControl(throttle=0.143079, steer=0.004584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55944982332356
8.686129163950682 seconds in game passed.
Action: tensor([[[0.0070, 0.6170],
         [0.0028, 0.3396],
         [0.0019, 0.2361],
         [0.0011, 0.1821]]])
agent 0 action: VehicleControl(throttle=0.140868, steer=0.004597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55944982332356
+++++++++++++: inf
8.71112916432321 seconds in game passed.
At 8.71112916432321 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.8458e-03,  6.1812e-01],
         [ 1.1715e-03,  3.3651e-01],
         [ 2.9662e-04,  2.3235e-01],
         [-5.0870e-04,  1.7825e-01]]])
agent 0 action: VehicleControl(throttle=0.262015, steer=0.002847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4541173274959729
Current mitigation activation: 0
#############################
Total reward: 59.01356715081953
8.73612916469574 seconds in game passed.
Action: tensor([[[ 5.8458e-03,  6.1812e-01],
         [ 1.1715e-03,  3.3651e-01],
         [ 2.9662e-04,  2.3235e-01],
         [-5.0870e-04,  1.7825e-01]]])
agent 0 action: VehicleControl(throttle=0.259812, steer=0.003064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01356715081953
8.761129165068269 seconds in game passed.
Action: tensor([[[ 5.8458e-03,  6.1812e-01],
         [ 1.1715e-03,  3.3651e-01],
         [ 2.9662e-04,  2.3235e-01],
         [-5.0870e-04,  1.7825e-01]]])
agent 0 action: VehicleControl(throttle=0.270064, steer=0.003000, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01356715081953
8.786129165440798 seconds in game passed.
Action: tensor([[[ 5.8458e-03,  6.1812e-01],
         [ 1.1715e-03,  3.3651e-01],
         [ 2.9662e-04,  2.3235e-01],
         [-5.0870e-04,  1.7825e-01]]])
agent 0 action: VehicleControl(throttle=0.279977, steer=0.002937, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01356715081953
+++++++++++++: inf
8.811129165813327 seconds in game passed.
At 8.811129165813327 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6142],
         [-0.0016,  0.3321],
         [-0.0022,  0.2279],
         [-0.0030,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.399543, steer=-0.001105, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4433590289431233
Current mitigation activation: 0
#############################
Total reward: 60.456926179762654
8.836129166185856 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6142],
         [-0.0016,  0.3321],
         [-0.0022,  0.2279],
         [-0.0030,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.393024, steer=-0.000480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.456926179762654
8.861129166558385 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6142],
         [-0.0016,  0.3321],
         [-0.0022,  0.2279],
         [-0.0030,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.398196, steer=-0.000522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.456926179762654
8.886129166930914 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6142],
         [-0.0016,  0.3321],
         [-0.0022,  0.2279],
         [-0.0030,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.402203, steer=-0.000565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.456926179762654
+++++++++++++: inf
8.911129167303443 seconds in game passed.
At 8.911129167303443 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0034,  0.6168],
         [-0.0050,  0.3307],
         [-0.0058,  0.2249],
         [-0.0068,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.483049, steer=-0.004762, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4327890794627294
Current mitigation activation: 0
#############################
Total reward: 61.88971525922538
8.936129167675972 seconds in game passed.
Action: tensor([[[-0.0034,  0.6168],
         [-0.0050,  0.3307],
         [-0.0058,  0.2249],
         [-0.0068,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.478442, steer=-0.004139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88971525922538
8.961129168048501 seconds in game passed.
Action: tensor([[[-0.0034,  0.6168],
         [-0.0050,  0.3307],
         [-0.0058,  0.2249],
         [-0.0068,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.481157, steer=-0.004205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88971525922538
8.98612916842103 seconds in game passed.
Action: tensor([[[-0.0034,  0.6168],
         [-0.0050,  0.3307],
         [-0.0058,  0.2249],
         [-0.0068,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.482612, steer=-0.004271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88971525922538
+++++++++++++: inf
9.011129168793559 seconds in game passed.
At 9.011129168793559 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0070,  0.6258],
         [-0.0110,  0.3319],
         [-0.0125,  0.2247],
         [-0.0135,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.530787, steer=-0.010241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4262730064069356
Current mitigation activation: 0
#############################
Total reward: 63.31598826563232
9.036129169166088 seconds in game passed.
Action: tensor([[[-0.0070,  0.6258],
         [-0.0110,  0.3319],
         [-0.0125,  0.2247],
         [-0.0135,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.525413, steer=-0.009371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31598826563232
9.061129169538617 seconds in game passed.
Action: tensor([[[-0.0070,  0.6258],
         [-0.0110,  0.3319],
         [-0.0125,  0.2247],
         [-0.0135,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.524611, steer=-0.009478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31598826563232
9.086129169911146 seconds in game passed.
Action: tensor([[[-0.0070,  0.6258],
         [-0.0110,  0.3319],
         [-0.0125,  0.2247],
         [-0.0135,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.522958, steer=-0.009584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31598826563232
+++++++++++++: inf
9.111129170283675 seconds in game passed.
At 9.111129170283675 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6116],
         [-0.0042,  0.3287],
         [-0.0045,  0.2239],
         [-0.0044,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.491631, steer=-0.002756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4246090270639395
Current mitigation activation: 0
#############################
Total reward: 64.74059729269626
9.136129170656204 seconds in game passed.
Action: tensor([[[-0.0023,  0.6116],
         [-0.0042,  0.3287],
         [-0.0045,  0.2239],
         [-0.0044,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.491892, steer=-0.003899, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.74059729269626
9.161129171028733 seconds in game passed.
Action: tensor([[[-0.0023,  0.6116],
         [-0.0042,  0.3287],
         [-0.0045,  0.2239],
         [-0.0044,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.488755, steer=-0.003903, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.74059729269626
9.186129171401262 seconds in game passed.
Action: tensor([[[-0.0023,  0.6116],
         [-0.0042,  0.3287],
         [-0.0045,  0.2239],
         [-0.0044,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.485636, steer=-0.003907, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.74059729269626
+++++++++++++: inf
9.211129171773791 seconds in game passed.
At 9.211129171773791 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.7730e-04,  6.0334e-01],
         [-2.0371e-03,  3.2584e-01],
         [-2.6270e-03,  2.2274e-01],
         [-3.0317e-03,  1.6904e-01]]])
agent 0 action: VehicleControl(throttle=0.498283, steer=-0.001503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4267661771955487
Current mitigation activation: 0
#############################
Total reward: 66.16736346989181
9.23612917214632 seconds in game passed.
Action: tensor([[[-3.7730e-04,  6.0334e-01],
         [-2.0371e-03,  3.2584e-01],
         [-2.6270e-03,  2.2274e-01],
         [-3.0317e-03,  1.6904e-01]]])
agent 0 action: VehicleControl(throttle=0.493987, steer=-0.001842, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16736346989181
9.26112917251885 seconds in game passed.
Action: tensor([[[-3.7730e-04,  6.0334e-01],
         [-2.0371e-03,  3.2584e-01],
         [-2.6270e-03,  2.2274e-01],
         [-3.0317e-03,  1.6904e-01]]])
agent 0 action: VehicleControl(throttle=0.491354, steer=-0.001789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16736346989181
9.286129172891378 seconds in game passed.
Action: tensor([[[-3.7730e-04,  6.0334e-01],
         [-2.0371e-03,  3.2584e-01],
         [-2.6270e-03,  2.2274e-01],
         [-3.0317e-03,  1.6904e-01]]])
agent 0 action: VehicleControl(throttle=0.488673, steer=-0.001736, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16736346989181
+++++++++++++: inf
9.311129173263907 seconds in game passed.
At 9.311129173263907 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9923e-03,  6.2242e-01],
         [ 5.7709e-04,  3.3242e-01],
         [-6.3628e-06,  2.2664e-01],
         [-5.3731e-04,  1.7242e-01]]])
agent 0 action: VehicleControl(throttle=0.446563, steer=0.001541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4303272513000742
Current mitigation activation: 0
#############################
Total reward: 67.59769072119188
9.336129173636436 seconds in game passed.
Action: tensor([[[ 2.9923e-03,  6.2242e-01],
         [ 5.7709e-04,  3.3242e-01],
         [-6.3628e-06,  2.2664e-01],
         [-5.3731e-04,  1.7242e-01]]])
agent 0 action: VehicleControl(throttle=0.447449, steer=0.001047, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59769072119188
9.361129174008965 seconds in game passed.
Action: tensor([[[ 2.9923e-03,  6.2242e-01],
         [ 5.7709e-04,  3.3242e-01],
         [-6.3628e-06,  2.2664e-01],
         [-5.3731e-04,  1.7242e-01]]])
agent 0 action: VehicleControl(throttle=0.444360, steer=0.001092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59769072119188
9.386129174381495 seconds in game passed.
Action: tensor([[[ 2.9923e-03,  6.2242e-01],
         [ 5.7709e-04,  3.3242e-01],
         [-6.3628e-06,  2.2664e-01],
         [-5.3731e-04,  1.7242e-01]]])
agent 0 action: VehicleControl(throttle=0.441681, steer=0.001137, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59769072119188
+++++++++++++: inf
9.411129174754024 seconds in game passed.
At 9.411129174754024 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3572e-03, 6.1115e-01],
         [7.0055e-04, 3.2715e-01],
         [6.9606e-04, 2.2294e-01],
         [4.8569e-04, 1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.514497, steer=0.000575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.434154483191507
Current mitigation activation: 0
#############################
Total reward: 69.03184520438339
9.436129175126553 seconds in game passed.
Action: tensor([[[1.3572e-03, 6.1115e-01],
         [7.0055e-04, 3.2715e-01],
         [6.9606e-04, 2.2294e-01],
         [4.8569e-04, 1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.506511, steer=0.000657, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.03184520438339
9.461129175499082 seconds in game passed.
Action: tensor([[[1.3572e-03, 6.1115e-01],
         [7.0055e-04, 3.2715e-01],
         [6.9606e-04, 2.2294e-01],
         [4.8569e-04, 1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.506428, steer=0.000647, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.03184520438339
9.48612917587161 seconds in game passed.
Action: tensor([[[1.3572e-03, 6.1115e-01],
         [7.0055e-04, 3.2715e-01],
         [6.9606e-04, 2.2294e-01],
         [4.8569e-04, 1.6914e-01]]])
agent 0 action: VehicleControl(throttle=0.505930, steer=0.000637, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.03184520438339
+++++++++++++: inf
9.51112917624414 seconds in game passed.
At 9.51112917624414 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2228],
         [0.0023, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.529621, steer=0.001670, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4372654237846096
Current mitigation activation: 0
#############################
Total reward: 70.469110628168
9.536129176616669 seconds in game passed.
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2228],
         [0.0023, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.529118, steer=0.001452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.469110628168
9.561129176989198 seconds in game passed.
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2228],
         [0.0023, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.530661, steer=0.001412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.469110628168
9.586129177361727 seconds in game passed.
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2228],
         [0.0023, 0.1687]]])
agent 0 action: VehicleControl(throttle=0.531811, steer=0.001373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.469110628168
+++++++++++++: inf
9.611129177734256 seconds in game passed.
At 9.611129177734256 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.5260e-04, 5.9818e-01],
         [7.0616e-04, 3.2310e-01],
         [1.0971e-03, 2.2110e-01],
         [1.0958e-03, 1.6776e-01]]])
agent 0 action: VehicleControl(throttle=0.521948, steer=-0.000175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4410700648961088
Current mitigation activation: 0
#############################
Total reward: 71.9101806930641
9.636129178106785 seconds in game passed.
Action: tensor([[[2.5260e-04, 5.9818e-01],
         [7.0616e-04, 3.2310e-01],
         [1.0971e-03, 2.2110e-01],
         [1.0958e-03, 1.6776e-01]]])
agent 0 action: VehicleControl(throttle=0.523516, steer=0.000031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.9101806930641
9.661129178479314 seconds in game passed.
Action: tensor([[[2.5260e-04, 5.9818e-01],
         [7.0616e-04, 3.2310e-01],
         [1.0971e-03, 2.2110e-01],
         [1.0958e-03, 1.6776e-01]]])
agent 0 action: VehicleControl(throttle=0.523725, steer=-0.000013, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.9101806930641
9.686129178851843 seconds in game passed.
Action: tensor([[[2.5260e-04, 5.9818e-01],
         [7.0616e-04, 3.2310e-01],
         [1.0971e-03, 2.2110e-01],
         [1.0958e-03, 1.6776e-01]]])
agent 0 action: VehicleControl(throttle=0.523798, steer=-0.000057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.9101806930641
+++++++++++++: inf
9.711129179224372 seconds in game passed.
At 9.711129179224372 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.3643e-05,  6.0292e-01],
         [-4.9610e-04,  3.2571e-01],
         [-7.8857e-05,  2.2299e-01],
         [ 2.1727e-04,  1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.476295, steer=-0.001045, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4461146910125873
Current mitigation activation: 0
#############################
Total reward: 73.35629538407669
9.736129179596901 seconds in game passed.
Action: tensor([[[ 6.3643e-05,  6.0292e-01],
         [-4.9610e-04,  3.2571e-01],
         [-7.8857e-05,  2.2299e-01],
         [ 2.1727e-04,  1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.479014, steer=-0.000923, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.35629538407669
9.76112917996943 seconds in game passed.
Action: tensor([[[ 6.3643e-05,  6.0292e-01],
         [-4.9610e-04,  3.2571e-01],
         [-7.8857e-05,  2.2299e-01],
         [ 2.1727e-04,  1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.476754, steer=-0.000960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.35629538407669
9.786129180341959 seconds in game passed.
Action: tensor([[[ 6.3643e-05,  6.0292e-01],
         [-4.9610e-04,  3.2571e-01],
         [-7.8857e-05,  2.2299e-01],
         [ 2.1727e-04,  1.6976e-01]]])
agent 0 action: VehicleControl(throttle=0.474693, steer=-0.000997, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.35629538407669
+++++++++++++: inf
9.811129180714488 seconds in game passed.
At 9.811129180714488 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0011, 0.5976],
         [0.0010, 0.3226],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.529238, steer=0.000559, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4516745934996746
Current mitigation activation: 0
#############################
Total reward: 74.80796997757636
9.836129181087017 seconds in game passed.
Action: tensor([[[0.0011, 0.5976],
         [0.0010, 0.3226],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.520599, steer=0.000324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.80796997757636
9.861129181459546 seconds in game passed.
Action: tensor([[[0.0011, 0.5976],
         [0.0010, 0.3226],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.517992, steer=0.000345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.80796997757636
9.886129181832075 seconds in game passed.
Action: tensor([[[0.0011, 0.5976],
         [0.0010, 0.3226],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.514963, steer=0.000366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.80796997757636
+++++++++++++: inf
9.911129182204604 seconds in game passed.
At 9.911129182204604 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.5972],
         [0.0030, 0.3233],
         [0.0039, 0.2213],
         [0.0042, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.482694, steer=0.002329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4565561236927442
Current mitigation activation: 0
#############################
Total reward: 76.26452610126911
9.936129182577133 seconds in game passed.
Action: tensor([[[0.0022, 0.5972],
         [0.0030, 0.3233],
         [0.0039, 0.2213],
         [0.0042, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.481043, steer=0.002099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26452610126911
9.961129182949662 seconds in game passed.
Action: tensor([[[0.0022, 0.5972],
         [0.0030, 0.3233],
         [0.0039, 0.2213],
         [0.0042, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.476355, steer=0.002183, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26452610126911
9.986129183322191 seconds in game passed.
Action: tensor([[[0.0022, 0.5972],
         [0.0030, 0.3233],
         [0.0039, 0.2213],
         [0.0042, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.471825, steer=0.002266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26452610126911
+++++++++++++: inf
10.01112918369472 seconds in game passed.
At 10.01112918369472 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.6159],
         [0.0010, 0.3331],
         [0.0014, 0.2282],
         [0.0011, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.308747, steer=0.000598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4614968417430059
Current mitigation activation: 0
#############################
Total reward: 77.72602294301211
10.03612918406725 seconds in game passed.
Action: tensor([[[0.0013, 0.6159],
         [0.0010, 0.3331],
         [0.0014, 0.2282],
         [0.0011, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.318984, steer=0.001023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.72602294301211
10.061129184439778 seconds in game passed.
Action: tensor([[[0.0013, 0.6159],
         [0.0010, 0.3331],
         [0.0014, 0.2282],
         [0.0011, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.312976, steer=0.001149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.72602294301211
10.086129184812307 seconds in game passed.
Action: tensor([[[0.0013, 0.6159],
         [0.0010, 0.3331],
         [0.0014, 0.2282],
         [0.0011, 0.1740]]])
agent 0 action: VehicleControl(throttle=0.308500, steer=0.001275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.72602294301211
+++++++++++++: inf
10.111129185184836 seconds in game passed.
At 10.111129185184836 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6122],
         [0.0016, 0.3278],
         [0.0017, 0.2245],
         [0.0016, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.455445, steer=0.002609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4654124355390237
Current mitigation activation: 0
#############################
Total reward: 79.19143537855113
10.136129185557365 seconds in game passed.
Action: tensor([[[0.0035, 0.6122],
         [0.0016, 0.3278],
         [0.0017, 0.2245],
         [0.0016, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.439240, steer=0.002466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.19143537855113
10.161129185929894 seconds in game passed.
Action: tensor([[[0.0035, 0.6122],
         [0.0016, 0.3278],
         [0.0017, 0.2245],
         [0.0016, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.439601, steer=0.002534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.19143537855113
10.186129186302423 seconds in game passed.
Action: tensor([[[0.0035, 0.6122],
         [0.0016, 0.3278],
         [0.0017, 0.2245],
         [0.0016, 0.1704]]])
agent 0 action: VehicleControl(throttle=0.439518, steer=0.002602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.19143537855113
+++++++++++++: inf
10.211129186674953 seconds in game passed.
At 10.211129186674953 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.7043e-03, 6.0801e-01],
         [6.1172e-04, 3.2437e-01],
         [7.2739e-04, 2.2139e-01],
         [5.2702e-04, 1.6770e-01]]])
agent 0 action: VehicleControl(throttle=0.521995, steer=0.001198, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4653345702358624
Current mitigation activation: 0
#############################
Total reward: 80.656769948787
10.236129187047482 seconds in game passed.
Action: tensor([[[1.7043e-03, 6.0801e-01],
         [6.1172e-04, 3.2437e-01],
         [7.2739e-04, 2.2139e-01],
         [5.2702e-04, 1.6770e-01]]])
agent 0 action: VehicleControl(throttle=0.513451, steer=0.001466, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.656769948787
10.26112918742001 seconds in game passed.
Action: tensor([[[1.7043e-03, 6.0801e-01],
         [6.1172e-04, 3.2437e-01],
         [7.2739e-04, 2.2139e-01],
         [5.2702e-04, 1.6770e-01]]])
agent 0 action: VehicleControl(throttle=0.513325, steer=0.001494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.656769948787
10.28612918779254 seconds in game passed.
Action: tensor([[[1.7043e-03, 6.0801e-01],
         [6.1172e-04, 3.2437e-01],
         [7.2739e-04, 2.2139e-01],
         [5.2702e-04, 1.6770e-01]]])
agent 0 action: VehicleControl(throttle=0.512379, steer=0.001523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.656769948787
+++++++++++++: inf
10.311129188165069 seconds in game passed.
At 10.311129188165069 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.7121e-03, 6.0750e-01],
         [5.8858e-04, 3.2462e-01],
         [7.4893e-04, 2.2166e-01],
         [5.7701e-04, 1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.496817, steer=0.001504, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4647851133157195
Current mitigation activation: 0
#############################
Total reward: 82.12155506210271
10.336129188537598 seconds in game passed.
Action: tensor([[[1.7121e-03, 6.0750e-01],
         [5.8858e-04, 3.2462e-01],
         [7.4893e-04, 2.2166e-01],
         [5.7701e-04, 1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.496651, steer=0.001501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.12155506210271
10.361129188910127 seconds in game passed.
Action: tensor([[[1.7121e-03, 6.0750e-01],
         [5.8858e-04, 3.2462e-01],
         [7.4893e-04, 2.2166e-01],
         [5.7701e-04, 1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.494606, steer=0.001496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.12155506210271
10.386129189282656 seconds in game passed.
Action: tensor([[[1.7121e-03, 6.0750e-01],
         [5.8858e-04, 3.2462e-01],
         [7.4893e-04, 2.2166e-01],
         [5.7701e-04, 1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.492371, steer=0.001491, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.12155506210271
+++++++++++++: inf
10.411129189655185 seconds in game passed.
At 10.411129189655185 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.2450e-04, 6.1910e-01],
         [3.5232e-04, 3.2778e-01],
         [5.7413e-04, 2.2417e-01],
         [2.2442e-04, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.493404, steer=0.000808, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4667011618948662
Current mitigation activation: 0
#############################
Total reward: 83.58825622399758
10.436129190027714 seconds in game passed.
Action: tensor([[[4.2450e-04, 6.1910e-01],
         [3.5232e-04, 3.2778e-01],
         [5.7413e-04, 2.2417e-01],
         [2.2442e-04, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.489655, steer=0.000914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.58825622399758
10.461129190400243 seconds in game passed.
Action: tensor([[[4.2450e-04, 6.1910e-01],
         [3.5232e-04, 3.2778e-01],
         [5.7413e-04, 2.2417e-01],
         [2.2442e-04, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.486261, steer=0.000908, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.58825622399758
10.486129190772772 seconds in game passed.
Action: tensor([[[4.2450e-04, 6.1910e-01],
         [3.5232e-04, 3.2778e-01],
         [5.7413e-04, 2.2417e-01],
         [2.2442e-04, 1.7086e-01]]])
agent 0 action: VehicleControl(throttle=0.482793, steer=0.000901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.58825622399758
+++++++++++++: inf
10.5111291911453 seconds in game passed.
At 10.5111291911453 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6228],
         [-0.0020,  0.3266],
         [-0.0023,  0.2221],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.559878, steer=-0.001528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4699639519986172
Current mitigation activation: 0
#############################
Total reward: 85.0582201759962
10.53612919151783 seconds in game passed.
Action: tensor([[[-0.0013,  0.6228],
         [-0.0020,  0.3266],
         [-0.0023,  0.2221],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.548488, steer=-0.001173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.0582201759962
10.561129191890359 seconds in game passed.
Action: tensor([[[-0.0013,  0.6228],
         [-0.0020,  0.3266],
         [-0.0023,  0.2221],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.545488, steer=-0.001215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.0582201759962
10.586129192262888 seconds in game passed.
Action: tensor([[[-0.0013,  0.6228],
         [-0.0020,  0.3266],
         [-0.0023,  0.2221],
         [-0.0033,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.541857, steer=-0.001258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.0582201759962
+++++++++++++: inf
10.611129192635417 seconds in game passed.
At 10.611129192635417 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.2713e-04,  6.2368e-01],
         [-2.3769e-04,  3.2747e-01],
         [ 9.5345e-05,  2.2293e-01],
         [-4.1585e-04,  1.6966e-01]]])
agent 0 action: VehicleControl(throttle=0.515289, steer=0.000197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.473739263093543
Current mitigation activation: 0
#############################
Total reward: 86.53195943908975
10.636129193007946 seconds in game passed.
Action: tensor([[[-8.2713e-04,  6.2368e-01],
         [-2.3769e-04,  3.2747e-01],
         [ 9.5345e-05,  2.2293e-01],
         [-4.1585e-04,  1.6966e-01]]])
agent 0 action: VehicleControl(throttle=0.513270, steer=-0.000059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.53195943908975
10.661129193380475 seconds in game passed.
Action: tensor([[[-8.2713e-04,  6.2368e-01],
         [-2.3769e-04,  3.2747e-01],
         [ 9.5345e-05,  2.2293e-01],
         [-4.1585e-04,  1.6966e-01]]])
agent 0 action: VehicleControl(throttle=0.508701, steer=-0.000070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.53195943908975
10.686129193753004 seconds in game passed.
Action: tensor([[[-8.2713e-04,  6.2368e-01],
         [-2.3769e-04,  3.2747e-01],
         [ 9.5345e-05,  2.2293e-01],
         [-4.1585e-04,  1.6966e-01]]])
agent 0 action: VehicleControl(throttle=0.504190, steer=-0.000082, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.53195943908975
+++++++++++++: inf
10.711129194125533 seconds in game passed.
At 10.711129194125533 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6125],
         [-0.0017,  0.3246],
         [-0.0013,  0.2222],
         [-0.0015,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.491657, steer=-0.001330, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.478842434762327
Current mitigation activation: 0
#############################
Total reward: 88.01080187385207
10.736129194498062 seconds in game passed.
Action: tensor([[[-0.0013,  0.6125],
         [-0.0017,  0.3246],
         [-0.0013,  0.2222],
         [-0.0015,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.488611, steer=-0.001139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.01080187385207
10.761129194870591 seconds in game passed.
Action: tensor([[[-0.0013,  0.6125],
         [-0.0017,  0.3246],
         [-0.0013,  0.2222],
         [-0.0015,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.484795, steer=-0.001153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.01080187385207
10.78612919524312 seconds in game passed.
Action: tensor([[[-0.0013,  0.6125],
         [-0.0017,  0.3246],
         [-0.0013,  0.2222],
         [-0.0015,  0.1690]]])
agent 0 action: VehicleControl(throttle=0.481179, steer=-0.001168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.01080187385207
+++++++++++++: inf
10.81112919561565 seconds in game passed.
At 10.81112919561565 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6143],
         [-0.0027,  0.3261],
         [-0.0028,  0.2226],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.439737, steer=-0.002369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4841926103073233
Current mitigation activation: 0
#############################
Total reward: 89.49499448415939
10.836129195988178 seconds in game passed.
Action: tensor([[[-0.0023,  0.6143],
         [-0.0027,  0.3261],
         [-0.0028,  0.2226],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.439408, steer=-0.002219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.49499448415939
10.861129196360707 seconds in game passed.
Action: tensor([[[-0.0023,  0.6143],
         [-0.0027,  0.3261],
         [-0.0028,  0.2226],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.435421, steer=-0.002261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.49499448415939
10.886129196733236 seconds in game passed.
Action: tensor([[[-0.0023,  0.6143],
         [-0.0027,  0.3261],
         [-0.0028,  0.2226],
         [-0.0036,  0.1691]]])
agent 0 action: VehicleControl(throttle=0.431960, steer=-0.002304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.49499448415939
+++++++++++++: inf
10.911129197105765 seconds in game passed.
At 10.911129197105765 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6233],
         [0.0041, 0.3276],
         [0.0049, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.465398, steer=0.005014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4886395832160293
Current mitigation activation: 0
#############################
Total reward: 90.98363406737542
10.936129197478294 seconds in game passed.
Action: tensor([[[0.0035, 0.6233],
         [0.0041, 0.3276],
         [0.0049, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.459637, steer=0.003811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.98363406737542
10.961129197850823 seconds in game passed.
Action: tensor([[[0.0035, 0.6233],
         [0.0041, 0.3276],
         [0.0049, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.458018, steer=0.003825, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.98363406737542
10.986129198223352 seconds in game passed.
Action: tensor([[[0.0035, 0.6233],
         [0.0041, 0.3276],
         [0.0049, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.456376, steer=0.003838, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.98363406737542
+++++++++++++: inf
11.011129198595881 seconds in game passed.
At 11.011129198595881 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0050, 0.6233],
         [0.0051, 0.3329],
         [0.0055, 0.2292],
         [0.0051, 0.1754]]])
agent 0 action: VehicleControl(throttle=0.267631, steer=0.005215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4914227095438397
Current mitigation activation: 0
#############################
Total reward: 92.47505677691926
11.03612919896841 seconds in game passed.
Action: tensor([[[0.0050, 0.6233],
         [0.0051, 0.3329],
         [0.0055, 0.2292],
         [0.0051, 0.1754]]])
agent 0 action: VehicleControl(throttle=0.285845, steer=0.005040, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.47505677691926
11.06112919934094 seconds in game passed.
Action: tensor([[[0.0050, 0.6233],
         [0.0051, 0.3329],
         [0.0055, 0.2292],
         [0.0051, 0.1754]]])
agent 0 action: VehicleControl(throttle=0.284487, steer=0.005087, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.47505677691926
11.086129199713469 seconds in game passed.
Action: tensor([[[0.0050, 0.6233],
         [0.0051, 0.3329],
         [0.0055, 0.2292],
         [0.0051, 0.1754]]])
agent 0 action: VehicleControl(throttle=0.284747, steer=0.005133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.47505677691926
+++++++++++++: inf
11.111129200085998 seconds in game passed.
At 11.111129200085998 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0025,  0.6594],
         [ 0.0060,  0.4034],
         [ 0.0102,  0.2995],
         [ 0.0128,  0.2391]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002540, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.493006671122227
Current mitigation activation: 0
#############################
Total reward: 93.96806344804149
11.136129200458527 seconds in game passed.
Action: tensor([[[-0.0025,  0.6594],
         [ 0.0060,  0.4034],
         [ 0.0102,  0.2995],
         [ 0.0128,  0.2391]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002979, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96806344804149
11.161129200831056 seconds in game passed.
Action: tensor([[[-0.0025,  0.6594],
         [ 0.0060,  0.4034],
         [ 0.0102,  0.2995],
         [ 0.0128,  0.2391]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002985, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96806344804149
11.186129201203585 seconds in game passed.
Action: tensor([[[-0.0025,  0.6594],
         [ 0.0060,  0.4034],
         [ 0.0102,  0.2995],
         [ 0.0128,  0.2391]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002992, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96806344804149
+++++++++++++: inf
11.211129201576114 seconds in game passed.
At 11.211129201576114 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.0712e-04,  7.1826e-01],
         [ 4.7144e-04,  4.4392e-01],
         [ 1.3543e-03,  3.2679e-01],
         [ 3.3006e-03,  2.5754e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000036, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4867105393700106
Current mitigation activation: 0
#############################
Total reward: 95.4547739874115
11.236129201948643 seconds in game passed.
Action: tensor([[[-3.0712e-04,  7.1826e-01],
         [ 4.7144e-04,  4.4392e-01],
         [ 1.3543e-03,  3.2679e-01],
         [ 3.3006e-03,  2.5754e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000518, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.4547739874115
11.261129202321172 seconds in game passed.
Action: tensor([[[-3.0712e-04,  7.1826e-01],
         [ 4.7144e-04,  4.4392e-01],
         [ 1.3543e-03,  3.2679e-01],
         [ 3.3006e-03,  2.5754e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000508, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.4547739874115
11.2861292026937 seconds in game passed.
Action: tensor([[[-3.0712e-04,  7.1826e-01],
         [ 4.7144e-04,  4.4392e-01],
         [ 1.3543e-03,  3.2679e-01],
         [ 3.3006e-03,  2.5754e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000499, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.4547739874115
+++++++++++++: inf
11.31112920306623 seconds in game passed.
At 11.31112920306623 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0078, 0.8064],
         [0.0090, 0.4817],
         [0.0074, 0.3400],
         [0.0069, 0.2530]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.010317, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.436760547788645
Current mitigation activation: 0
#############################
Total reward: 96.89153453520015
11.336129203438759 seconds in game passed.
Action: tensor([[[0.0078, 0.8064],
         [0.0090, 0.4817],
         [0.0074, 0.3400],
         [0.0069, 0.2530]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008788, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 96.89153453520015
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [91mFAILURE[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-15 00:44:59 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-15 00:45:20 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 21.28s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 9.78s               │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.459               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ FAILURE │ 46.64 % │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ FAILURE │ 1 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 96.89, average_reward: 96.89153453520015 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00009/fi_ghost_cutin_data
