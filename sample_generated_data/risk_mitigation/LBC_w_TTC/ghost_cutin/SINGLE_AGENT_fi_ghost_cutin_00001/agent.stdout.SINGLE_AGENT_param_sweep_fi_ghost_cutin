New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003636-fi_ghost_cutin_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003636-fi_ghost_cutin_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003636-fi_ghost_cutin_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003636-fi_ghost_cutin_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003636-fi_ghost_cutin_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003636-fi_ghost_cutin_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_data/route_highway.xml_fi_ghost_cutin.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key distance_same_lane's value from 15 to 10.
Replacing key distance_lane_change's value from 11 to 6.
Replacing key speed_lane_change's value from 13.5 to 10.
Config for GhostCutIn scenario is {'first_vehicle_location': 0, 'first_vehicle_speed': 200, 'event_trigger_distance': 4, 'distance_lane_change': 6, 'speed_lane_change': 10, 'distance_same_lane': 10}
2.327188365161419 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.352188365533948 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.377188365906477 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002707, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.402188366279006 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002740, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.427188366651535 seconds in game passed.
Action: tensor([[[0.0034, 0.5919],
         [0.0025, 0.3305],
         [0.0023, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002773, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.452188367024064 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003959, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.477188367396593 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.502188367769122 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.527188368141651 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.55218836851418 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.577188368886709 seconds in game passed.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003344, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6021883692592382 seconds in game passed.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003381, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6271883696317673 seconds in game passed.
Action: tensor([[[0.0049, 0.5951],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6521883700042963 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.6771883703768253 seconds in game passed.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7021883707493544 seconds in game passed.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002662, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7271883711218834 seconds in game passed.
Action: tensor([[[0.0035, 0.5933],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002688, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7521883714944124 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.7771883718669415 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002434, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8021883722394705 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8271883726119995 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.8521883729845285 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4426e-03, 5.9061e-01],
         [1.3352e-03, 3.2234e-01],
         [1.1111e-03, 2.2211e-01],
         [5.7088e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002281, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.8771883733570576 seconds in game passed.
Action: tensor([[[2.4426e-03, 5.9061e-01],
         [1.3352e-03, 3.2234e-01],
         [1.1111e-03, 2.2211e-01],
         [5.7088e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9021883737295866 seconds in game passed.
Action: tensor([[[2.4426e-03, 5.9061e-01],
         [1.3352e-03, 3.2234e-01],
         [1.1111e-03, 2.2211e-01],
         [5.7088e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9271883741021156 seconds in game passed.
Action: tensor([[[2.4426e-03, 5.9061e-01],
         [1.3352e-03, 3.2234e-01],
         [1.1111e-03, 2.2211e-01],
         [5.7088e-04, 1.6811e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 20297.16684299258
2.9521883744746447 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5896],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.9771883748471737 seconds in game passed.
Action: tensor([[[0.0023, 0.5896],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0021883752197027 seconds in game passed.
Action: tensor([[[0.0023, 0.5896],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0271883755922318 seconds in game passed.
Action: tensor([[[0.0023, 0.5896],
         [0.0015, 0.3219],
         [0.0013, 0.2219],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002520, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.71016465861
3.052188375964761 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
3.07718837633729 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.102188376709819 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.127188377082348 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.152188377454877 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002682, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.177188377827406 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.202188378199935 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002702, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.227188378572464 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.252188378944993 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.277188379317522 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002778, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.302188379690051 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002799, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.32718838006258 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.352188380435109 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.377188380807638 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002646, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.402188381180167 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4271883815526962 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4521883819252253 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4771883822977543 seconds in game passed.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5021883826702833 seconds in game passed.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002622, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5271883830428123 seconds in game passed.
Action: tensor([[[0.0019, 0.5879],
         [0.0017, 0.3214],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002598, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.6593486434
3.5521883834153414 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
3.5771883837878704 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6021883841603994 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002460, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6271883845329285 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6521883849054575 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0018, 0.3212],
         [0.0017, 0.2214],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6771883852779865 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0018, 0.3212],
         [0.0017, 0.2214],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7021883856505156 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0018, 0.3212],
         [0.0017, 0.2214],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002476, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7271883860230446 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0018, 0.3212],
         [0.0017, 0.2214],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7521883863955736 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7771883867681026 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8021883871406317 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8271883875131607 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8521883878856897 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8771883882582188 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.902188388630748 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.927188389003277 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002534, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.952188389375806 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.977188389748335 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.002188390120864 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.027188390493393 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.052188390865922 seconds in game passed.
At 4.052188390865922 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.077188391238451 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.10218839161098 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.127188391983509 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002446, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.152188392356038 seconds in game passed.
At 4.152188392356038 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002280, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.177188392728567 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.202188393101096 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002302, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.227188393473625 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.252188393846154 seconds in game passed.
At 4.252188393846154 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002344, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.277188394218683 seconds in game passed.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002334, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.302188394591212 seconds in game passed.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.327188394963741 seconds in game passed.
Action: tensor([[[0.0017, 0.5870],
         [0.0016, 0.3211],
         [0.0016, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.35218839533627 seconds in game passed.
At 4.35218839533627 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.377188395708799 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.402188396081328 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.427188396453857 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.4521883968263865 seconds in game passed.
At 4.4521883968263865 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002432, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.4771883971989155 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.5021883975714445 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.5271883979439735 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002407, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.552188398316503 seconds in game passed.
At 4.552188398316503 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.577188398689032 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.602188399061561 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.62718839943409 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.652188399806619 seconds in game passed.
At 4.652188399806619 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.677188400179148 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.702188400551677 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.727188400924206 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.752188401296735 seconds in game passed.
At 4.752188401296735 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0.06602266588708589
4.777188401669264 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.802188402041793 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.827188402414322 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002353, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
+++++++++++++: inf
4.852188402786851 seconds in game passed.
At 4.852188402786851 seconds, saving state-action tuples.
Action: tensor([[[1.4084e-03, 5.8601e-01],
         [1.1327e-03, 3.2065e-01],
         [1.0012e-03, 2.2099e-01],
         [3.5280e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001843, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.3145396919977081
4.87718840315938 seconds in game passed.
Action: tensor([[[1.4084e-03, 5.8601e-01],
         [1.1327e-03, 3.2065e-01],
         [1.0012e-03, 2.2099e-01],
         [3.5280e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001920, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.902188403531909 seconds in game passed.
Action: tensor([[[1.4084e-03, 5.8601e-01],
         [1.1327e-03, 3.2065e-01],
         [1.0012e-03, 2.2099e-01],
         [3.5280e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.927188403904438 seconds in game passed.
Action: tensor([[[1.4084e-03, 5.8601e-01],
         [1.1327e-03, 3.2065e-01],
         [1.0012e-03, 2.2099e-01],
         [3.5280e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
+++++++++++++: inf
4.952188404276967 seconds in game passed.
At 4.952188404276967 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002159, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.7221479506394559
4.977188404649496 seconds in game passed.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
5.002188405022025 seconds in game passed.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
5.027188405394554 seconds in game passed.
Action: tensor([[[0.0017, 0.5839],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0011, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002112, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
+++++++++++++: inf
5.052188405767083 seconds in game passed.
At 5.052188405767083 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002220, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.5416192717651775
Current mitigation activation: 0
#############################
Total reward: 1.2637672224046335
5.077188406139612 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002199, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2637672224046335
5.102188406512141 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2637672224046335
5.12718840688467 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0015, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.2637672224046335
+++++++++++++: inf
5.152188407257199 seconds in game passed.
At 5.152188407257199 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5851],
         [0.0023, 0.3209],
         [0.0027, 0.2210],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003082, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.6535766068045812
Current mitigation activation: 0
#############################
Total reward: 1.9173438292092146
5.177188407629728 seconds in game passed.
Action: tensor([[[0.0023, 0.5851],
         [0.0023, 0.3209],
         [0.0027, 0.2210],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002944, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173438292092146
5.202188408002257 seconds in game passed.
Action: tensor([[[0.0023, 0.5851],
         [0.0023, 0.3209],
         [0.0027, 0.2210],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002953, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173438292092146
5.227188408374786 seconds in game passed.
Action: tensor([[[0.0023, 0.5851],
         [0.0023, 0.3209],
         [0.0027, 0.2210],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002962, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173438292092146
+++++++++++++: inf
5.252188408747315 seconds in game passed.
At 5.252188408747315 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.7480162555166024
Current mitigation activation: 0
#############################
Total reward: 2.665360084725817
5.277188409119844 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002516, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.665360084725817
5.3021884094923735 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.665360084725817
5.3271884098649025 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.665360084725817
+++++++++++++: inf
5.3521884102374315 seconds in game passed.
At 5.3521884102374315 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.2539e-05,  5.8834e-01],
         [-5.5462e-05,  3.2175e-01],
         [ 2.3544e-05,  2.2102e-01],
         [-3.7869e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8290662894709695
Current mitigation activation: 0
#############################
Total reward: 3.4944263741967867
5.377188410609961 seconds in game passed.
Action: tensor([[[-1.2539e-05,  5.8834e-01],
         [-5.5462e-05,  3.2175e-01],
         [ 2.3544e-05,  2.2102e-01],
         [-3.7869e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944263741967867
5.40218841098249 seconds in game passed.
Action: tensor([[[-1.2539e-05,  5.8834e-01],
         [-5.5462e-05,  3.2175e-01],
         [ 2.3544e-05,  2.2102e-01],
         [-3.7869e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000690, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944263741967867
5.427188411355019 seconds in game passed.
Action: tensor([[[-1.2539e-05,  5.8834e-01],
         [-5.5462e-05,  3.2175e-01],
         [ 2.3544e-05,  2.2102e-01],
         [-3.7869e-04,  1.6700e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944263741967867
+++++++++++++: inf
5.452188411727548 seconds in game passed.
At 5.452188411727548 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.3692e-04,  5.8921e-01],
         [-2.0862e-04,  3.2119e-01],
         [-1.4779e-04,  2.2087e-01],
         [-3.8750e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8996361861755311
Current mitigation activation: 0
#############################
Total reward: 4.394062560372317
5.477188412100077 seconds in game passed.
Action: tensor([[[ 3.3692e-04,  5.8921e-01],
         [-2.0862e-04,  3.2119e-01],
         [-1.4779e-04,  2.2087e-01],
         [-3.8750e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000652, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394062560372317
5.502188412472606 seconds in game passed.
Action: tensor([[[ 3.3692e-04,  5.8921e-01],
         [-2.0862e-04,  3.2119e-01],
         [-1.4779e-04,  2.2087e-01],
         [-3.8750e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394062560372317
5.527188412845135 seconds in game passed.
Action: tensor([[[ 3.3692e-04,  5.8921e-01],
         [-2.0862e-04,  3.2119e-01],
         [-1.4779e-04,  2.2087e-01],
         [-3.8750e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000612, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.394062560372317
+++++++++++++: inf
5.552188413217664 seconds in game passed.
At 5.552188413217664 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.4511e-04,  5.9109e-01],
         [-1.0651e-03,  3.2138e-01],
         [-9.3214e-04,  2.2095e-01],
         [-1.0778e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000351, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.9622091699719221
Current mitigation activation: 0
#############################
Total reward: 5.35627173034424
5.577188413590193 seconds in game passed.
Action: tensor([[[-4.4511e-04,  5.9109e-01],
         [-1.0651e-03,  3.2138e-01],
         [-9.3214e-04,  2.2095e-01],
         [-1.0778e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000225, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.35627173034424
5.602188413962722 seconds in game passed.
Action: tensor([[[-4.4511e-04,  5.9109e-01],
         [-1.0651e-03,  3.2138e-01],
         [-9.3214e-04,  2.2095e-01],
         [-1.0778e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.35627173034424
5.627188414335251 seconds in game passed.
Action: tensor([[[-4.4511e-04,  5.9109e-01],
         [-1.0651e-03,  3.2138e-01],
         [-9.3214e-04,  2.2095e-01],
         [-1.0778e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.35627173034424
+++++++++++++: inf
5.65218841470778 seconds in game passed.
At 5.65218841470778 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.9969e-04,  5.9015e-01],
         [-3.5734e-04,  3.2150e-01],
         [-2.3559e-04,  2.2102e-01],
         [-3.1676e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000704, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0188223792634241
Current mitigation activation: 0
#############################
Total reward: 6.375094109607664
5.677188415080309 seconds in game passed.
Action: tensor([[[ 7.9969e-04,  5.9015e-01],
         [-3.5734e-04,  3.2150e-01],
         [-2.3559e-04,  2.2102e-01],
         [-3.1676e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375094109607664
5.702188415452838 seconds in game passed.
Action: tensor([[[ 7.9969e-04,  5.9015e-01],
         [-3.5734e-04,  3.2150e-01],
         [-2.3559e-04,  2.2102e-01],
         [-3.1676e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375094109607664
5.727188415825367 seconds in game passed.
Action: tensor([[[ 7.9969e-04,  5.9015e-01],
         [-3.5734e-04,  3.2150e-01],
         [-2.3559e-04,  2.2102e-01],
         [-3.1676e-04,  1.6713e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375094109607664
+++++++++++++: inf
5.752188416197896 seconds in game passed.
At 5.752188416197896 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001884, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.07105636801549
Current mitigation activation: 0
#############################
Total reward: 7.446150477623155
5.777188416570425 seconds in game passed.
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150477623155
5.802188416942954 seconds in game passed.
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150477623155
5.827188417315483 seconds in game passed.
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150477623155
+++++++++++++: inf
5.852188417688012 seconds in game passed.
At 5.852188417688012 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2745e-03, 5.8964e-01],
         [8.9103e-04, 3.2204e-01],
         [7.7027e-04, 2.2274e-01],
         [4.0968e-04, 1.6873e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1199797436543193
Current mitigation activation: 0
#############################
Total reward: 8.566130221277474
5.877188418060541 seconds in game passed.
Action: tensor([[[1.2745e-03, 5.8964e-01],
         [8.9103e-04, 3.2204e-01],
         [7.7027e-04, 2.2274e-01],
         [4.0968e-04, 1.6873e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566130221277474
5.90218841843307 seconds in game passed.
Action: tensor([[[1.2745e-03, 5.8964e-01],
         [8.9103e-04, 3.2204e-01],
         [7.7027e-04, 2.2274e-01],
         [4.0968e-04, 1.6873e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566130221277474
5.927188418805599 seconds in game passed.
Action: tensor([[[1.2745e-03, 5.8964e-01],
         [8.9103e-04, 3.2204e-01],
         [7.7027e-04, 2.2274e-01],
         [4.0968e-04, 1.6873e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566130221277474
+++++++++++++: inf
5.952188419178128 seconds in game passed.
At 5.952188419178128 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5849],
         [0.0020, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1663711827942826
Current mitigation activation: 0
#############################
Total reward: 9.732501404071757
5.977188419550657 seconds in game passed.
Action: tensor([[[0.0016, 0.5849],
         [0.0020, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002161, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732501404071757
6.002188419923186 seconds in game passed.
Action: tensor([[[0.0016, 0.5849],
         [0.0020, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732501404071757
6.027188420295715 seconds in game passed.
Action: tensor([[[0.0016, 0.5849],
         [0.0020, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732501404071757
+++++++++++++: inf
6.052188420668244 seconds in game passed.
At 6.052188420668244 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.5933],
         [0.0008, 0.3214],
         [0.0008, 0.2210],
         [0.0007, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2107698115505894
Current mitigation activation: 0
#############################
Total reward: 10.943271215622346
6.077188421040773 seconds in game passed.
Action: tensor([[[0.0015, 0.5933],
         [0.0008, 0.3214],
         [0.0008, 0.2210],
         [0.0007, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943271215622346
6.102188421413302 seconds in game passed.
Action: tensor([[[0.0015, 0.5933],
         [0.0008, 0.3214],
         [0.0008, 0.2210],
         [0.0007, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001404, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943271215622346
6.1271884217858315 seconds in game passed.
Action: tensor([[[0.0015, 0.5933],
         [0.0008, 0.3214],
         [0.0008, 0.2210],
         [0.0007, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943271215622346
+++++++++++++: inf
6.1521884221583605 seconds in game passed.
At 6.1521884221583605 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0017, 0.5914],
         [0.0016, 0.3212],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2534927693024798
Current mitigation activation: 0
#############################
Total reward: 12.196763984924825
6.1771884225308895 seconds in game passed.
Action: tensor([[[0.0017, 0.5914],
         [0.0016, 0.3212],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001883, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196763984924825
6.2021884229034185 seconds in game passed.
Action: tensor([[[0.0017, 0.5914],
         [0.0016, 0.3212],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196763984924825
6.227188423275948 seconds in game passed.
Action: tensor([[[0.0017, 0.5914],
         [0.0016, 0.3212],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001866, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196763984924825
+++++++++++++: inf
6.252188423648477 seconds in game passed.
At 6.252188423648477 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0486e-03, 5.9020e-01],
         [6.5559e-04, 3.2047e-01],
         [6.2509e-04, 2.1998e-01],
         [2.9701e-04, 1.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2799433651508216
Current mitigation activation: 0
#############################
Total reward: 13.476707350075646
6.277188424021006 seconds in game passed.
Action: tensor([[[1.0486e-03, 5.9020e-01],
         [6.5559e-04, 3.2047e-01],
         [6.2509e-04, 2.1998e-01],
         [2.9701e-04, 1.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476707350075646
6.302188424393535 seconds in game passed.
Action: tensor([[[1.0486e-03, 5.9020e-01],
         [6.5559e-04, 3.2047e-01],
         [6.2509e-04, 2.1998e-01],
         [2.9701e-04, 1.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476707350075646
6.327188424766064 seconds in game passed.
Action: tensor([[[1.0486e-03, 5.9020e-01],
         [6.5559e-04, 3.2047e-01],
         [6.2509e-04, 2.1998e-01],
         [2.9701e-04, 1.6607e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476707350075646
+++++++++++++: inf
6.352188425138593 seconds in game passed.
At 6.352188425138593 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.2744e-04,  5.9220e-01],
         [-3.5747e-04,  3.2081e-01],
         [-5.4690e-04,  2.1979e-01],
         [-9.8213e-04,  1.6634e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.278468110285936
Current mitigation activation: 0
#############################
Total reward: 14.755175460361581
6.377188425511122 seconds in game passed.
Action: tensor([[[ 4.2744e-04,  5.9220e-01],
         [-3.5747e-04,  3.2081e-01],
         [-5.4690e-04,  2.1979e-01],
         [-9.8213e-04,  1.6634e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755175460361581
6.402188425883651 seconds in game passed.
Action: tensor([[[ 4.2744e-04,  5.9220e-01],
         [-3.5747e-04,  3.2081e-01],
         [-5.4690e-04,  2.1979e-01],
         [-9.8213e-04,  1.6634e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755175460361581
6.42718842625618 seconds in game passed.
Action: tensor([[[ 4.2744e-04,  5.9220e-01],
         [-3.5747e-04,  3.2081e-01],
         [-5.4690e-04,  2.1979e-01],
         [-9.8213e-04,  1.6634e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755175460361581
+++++++++++++: inf
6.452188426628709 seconds in game passed.
At 6.452188426628709 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0027,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.276718753156084
Current mitigation activation: 0
#############################
Total reward: 16.031894213517667
6.477188427001238 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0027,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001269, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031894213517667
6.502188427373767 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0027,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001288, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031894213517667
6.527188427746296 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0021,  0.3197],
         [-0.0027,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031894213517667
+++++++++++++: inf
6.552188428118825 seconds in game passed.
At 6.552188428118825 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.5907],
         [-0.0026,  0.3204],
         [-0.0030,  0.2197],
         [-0.0034,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001810, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.274923984525727
Current mitigation activation: 0
#############################
Total reward: 17.306818198043395
6.577188428491354 seconds in game passed.
Action: tensor([[[-0.0011,  0.5907],
         [-0.0026,  0.3204],
         [-0.0030,  0.2197],
         [-0.0034,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001743, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306818198043395
6.602188428863883 seconds in game passed.
Action: tensor([[[-0.0011,  0.5907],
         [-0.0026,  0.3204],
         [-0.0030,  0.2197],
         [-0.0034,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001757, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306818198043395
6.627188429236412 seconds in game passed.
Action: tensor([[[-0.0011,  0.5907],
         [-0.0026,  0.3204],
         [-0.0030,  0.2197],
         [-0.0034,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001772, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306818198043395
+++++++++++++: inf
6.652188429608941 seconds in game passed.
At 6.652188429608941 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.1958e-05,  5.8978e-01],
         [-9.2077e-04,  3.2099e-01],
         [-1.0773e-03,  2.2060e-01],
         [-1.3397e-03,  1.6671e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000076, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.273107623718436
Current mitigation activation: 0
#############################
Total reward: 18.57992582176183
6.67718842998147 seconds in game passed.
Action: tensor([[[ 7.1958e-05,  5.8978e-01],
         [-9.2077e-04,  3.2099e-01],
         [-1.0773e-03,  2.2060e-01],
         [-1.3397e-03,  1.6671e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.57992582176183
6.702188430353999 seconds in game passed.
Action: tensor([[[ 7.1958e-05,  5.8978e-01],
         [-9.2077e-04,  3.2099e-01],
         [-1.0773e-03,  2.2060e-01],
         [-1.3397e-03,  1.6671e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.57992582176183
6.727188430726528 seconds in game passed.
Action: tensor([[[ 7.1958e-05,  5.8978e-01],
         [-9.2077e-04,  3.2099e-01],
         [-1.0773e-03,  2.2060e-01],
         [-1.3397e-03,  1.6671e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000381, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.57992582176183
+++++++++++++: inf
6.752188431099057 seconds in game passed.
At 6.752188431099057 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3473e-03,  5.9020e-01],
         [ 1.8289e-04,  3.2128e-01],
         [ 1.9784e-04,  2.2086e-01],
         [-7.8432e-05,  1.6692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000917, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.288382351904863
Current mitigation activation: 0
#############################
Total reward: 19.86830817366669
6.777188431471586 seconds in game passed.
Action: tensor([[[ 1.3473e-03,  5.9020e-01],
         [ 1.8289e-04,  3.2128e-01],
         [ 1.9784e-04,  2.2086e-01],
         [-7.8432e-05,  1.6692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.86830817366669
6.802188431844115 seconds in game passed.
Action: tensor([[[ 1.3473e-03,  5.9020e-01],
         [ 1.8289e-04,  3.2128e-01],
         [ 1.9784e-04,  2.2086e-01],
         [-7.8432e-05,  1.6692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.86830817366669
6.827188432216644 seconds in game passed.
Action: tensor([[[ 1.3473e-03,  5.9020e-01],
         [ 1.8289e-04,  3.2128e-01],
         [ 1.9784e-04,  2.2086e-01],
         [-7.8432e-05,  1.6692e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.86830817366669
+++++++++++++: inf
6.852188432589173 seconds in game passed.
At 6.852188432589173 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.5909],
         [0.0022, 0.3219],
         [0.0017, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002750, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3503231399640634
Current mitigation activation: 0
#############################
Total reward: 21.218631313630755
6.877188432961702 seconds in game passed.
Action: tensor([[[0.0028, 0.5909],
         [0.0022, 0.3219],
         [0.0017, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218631313630755
6.902188433334231 seconds in game passed.
Action: tensor([[[0.0028, 0.5909],
         [0.0022, 0.3219],
         [0.0017, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218631313630755
6.92718843370676 seconds in game passed.
Action: tensor([[[0.0028, 0.5909],
         [0.0022, 0.3219],
         [0.0017, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.854241, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218631313630755
+++++++++++++: inf
6.952188434079289 seconds in game passed.
At 6.952188434079289 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1478e-03,  5.9161e-01],
         [ 1.0037e-03,  3.2203e-01],
         [ 3.0736e-04,  2.2145e-01],
         [-8.7320e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.805760, steer=0.001305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.40669934576345
Current mitigation activation: 0
#############################
Total reward: 22.625330659394205
6.9771884344518185 seconds in game passed.
Action: tensor([[[ 2.1478e-03,  5.9161e-01],
         [ 1.0037e-03,  3.2203e-01],
         [ 3.0736e-04,  2.2145e-01],
         [-8.7320e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.756262, steer=0.001490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625330659394205
7.0021884348243475 seconds in game passed.
Action: tensor([[[ 2.1478e-03,  5.9161e-01],
         [ 1.0037e-03,  3.2203e-01],
         [ 3.0736e-04,  2.2145e-01],
         [-8.7320e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.708375, steer=0.001485, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625330659394205
7.0271884351968765 seconds in game passed.
Action: tensor([[[ 2.1478e-03,  5.9161e-01],
         [ 1.0037e-03,  3.2203e-01],
         [ 3.0736e-04,  2.2145e-01],
         [-8.7320e-04,  1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.662228, steer=0.001480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625330659394205
+++++++++++++: inf
7.0521884355694056 seconds in game passed.
At 7.0521884355694056 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7005e-04,  5.9657e-01],
         [-6.1316e-04,  3.2307e-01],
         [-1.4882e-03,  2.2110e-01],
         [-2.7578e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.633927, steer=-0.000456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.456501961666536
Current mitigation activation: 0
#############################
Total reward: 24.08183262106074
7.077188435941935 seconds in game passed.
Action: tensor([[[ 2.7005e-04,  5.9657e-01],
         [-6.1316e-04,  3.2307e-01],
         [-1.4882e-03,  2.2110e-01],
         [-2.7578e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.590493, steer=-0.000152, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08183262106074
7.102188436314464 seconds in game passed.
Action: tensor([[[ 2.7005e-04,  5.9657e-01],
         [-6.1316e-04,  3.2307e-01],
         [-1.4882e-03,  2.2110e-01],
         [-2.7578e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.551272, steer=-0.000168, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08183262106074
7.127188436686993 seconds in game passed.
Action: tensor([[[ 2.7005e-04,  5.9657e-01],
         [-6.1316e-04,  3.2307e-01],
         [-1.4882e-03,  2.2110e-01],
         [-2.7578e-03,  1.6767e-01]]])
agent 0 action: VehicleControl(throttle=0.514664, steer=-0.000184, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.08183262106074
+++++++++++++: inf
7.152188437059522 seconds in game passed.
At 7.152188437059522 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-8.3707e-05,  5.9918e-01],
         [-1.0539e-03,  3.2450e-01],
         [-1.9718e-03,  2.2232e-01],
         [-3.4109e-03,  1.6863e-01]]])
agent 0 action: VehicleControl(throttle=0.456182, steer=-0.000672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4972738692913032
Current mitigation activation: 0
#############################
Total reward: 25.579106490352043
7.177188437432051 seconds in game passed.
Action: tensor([[[-8.3707e-05,  5.9918e-01],
         [-1.0539e-03,  3.2450e-01],
         [-1.9718e-03,  2.2232e-01],
         [-3.4109e-03,  1.6863e-01]]])
agent 0 action: VehicleControl(throttle=0.427853, steer=-0.000622, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579106490352043
7.20218843780458 seconds in game passed.
Action: tensor([[[-8.3707e-05,  5.9918e-01],
         [-1.0539e-03,  3.2450e-01],
         [-1.9718e-03,  2.2232e-01],
         [-3.4109e-03,  1.6863e-01]]])
agent 0 action: VehicleControl(throttle=0.399570, steer=-0.000649, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579106490352043
7.227188438177109 seconds in game passed.
Action: tensor([[[-8.3707e-05,  5.9918e-01],
         [-1.0539e-03,  3.2450e-01],
         [-1.9718e-03,  2.2232e-01],
         [-3.4109e-03,  1.6863e-01]]])
agent 0 action: VehicleControl(throttle=0.374236, steer=-0.000677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579106490352043
+++++++++++++: inf
7.252188438549638 seconds in game passed.
At 7.252188438549638 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0040,  0.6095],
         [-0.0062,  0.3268],
         [-0.0078,  0.2222],
         [-0.0093,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.379331, steer=-0.006094, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5250807956403294
Current mitigation activation: 0
#############################
Total reward: 27.10418728599237
7.277188438922167 seconds in game passed.
Action: tensor([[[-0.0040,  0.6095],
         [-0.0062,  0.3268],
         [-0.0078,  0.2222],
         [-0.0093,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.357033, steer=-0.005277, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.10418728599237
7.302188439294696 seconds in game passed.
Action: tensor([[[-0.0040,  0.6095],
         [-0.0062,  0.3268],
         [-0.0078,  0.2222],
         [-0.0093,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.340464, steer=-0.005350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.10418728599237
7.327188439667225 seconds in game passed.
Action: tensor([[[-0.0040,  0.6095],
         [-0.0062,  0.3268],
         [-0.0078,  0.2222],
         [-0.0093,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.326285, steer=-0.005423, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.10418728599237
+++++++++++++: inf
7.352188440039754 seconds in game passed.
At 7.352188440039754 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.6076],
         [-0.0052,  0.3265],
         [-0.0064,  0.2224],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.303668, steer=-0.004318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5379635830021887
Current mitigation activation: 0
#############################
Total reward: 28.64215086899456
7.377188440412283 seconds in game passed.
Action: tensor([[[-0.0030,  0.6076],
         [-0.0052,  0.3265],
         [-0.0064,  0.2224],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.295069, steer=-0.004562, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64215086899456
7.402188440784812 seconds in game passed.
Action: tensor([[[-0.0030,  0.6076],
         [-0.0052,  0.3265],
         [-0.0064,  0.2224],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.287482, steer=-0.004613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64215086899456
7.427188441157341 seconds in game passed.
Action: tensor([[[-0.0030,  0.6076],
         [-0.0052,  0.3265],
         [-0.0064,  0.2224],
         [-0.0074,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.281956, steer=-0.004664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64215086899456
+++++++++++++: inf
7.45218844152987 seconds in game passed.
At 7.45218844152987 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.5975],
         [-0.0042,  0.3240],
         [-0.0049,  0.2219],
         [-0.0054,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261983, steer=-0.003568, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5378043033147466
Current mitigation activation: 0
#############################
Total reward: 30.179955172309306
7.477188441902399 seconds in game passed.
Action: tensor([[[-0.0021,  0.5975],
         [-0.0042,  0.3240],
         [-0.0049,  0.2219],
         [-0.0054,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261631, steer=-0.003775, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.179955172309306
7.502188442274928 seconds in game passed.
Action: tensor([[[-0.0021,  0.5975],
         [-0.0042,  0.3240],
         [-0.0049,  0.2219],
         [-0.0054,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261091, steer=-0.003796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.179955172309306
7.527188442647457 seconds in game passed.
Action: tensor([[[-0.0021,  0.5975],
         [-0.0042,  0.3240],
         [-0.0049,  0.2219],
         [-0.0054,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.262060, steer=-0.003817, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.179955172309306
+++++++++++++: inf
7.552188443019986 seconds in game passed.
At 7.552188443019986 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.5936],
         [-0.0027,  0.3228],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.267152, steer=-0.002282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5278700903520266
Current mitigation activation: 0
#############################
Total reward: 31.707825262661334
7.577188443392515 seconds in game passed.
Action: tensor([[[-0.0009,  0.5936],
         [-0.0027,  0.3228],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.270206, steer=-0.002538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707825262661334
7.602188443765044 seconds in game passed.
Action: tensor([[[-0.0009,  0.5936],
         [-0.0027,  0.3228],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.274525, steer=-0.002538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707825262661334
7.627188444137573 seconds in game passed.
Action: tensor([[[-0.0009,  0.5936],
         [-0.0027,  0.3228],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.279641, steer=-0.002538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707825262661334
+++++++++++++: inf
7.652188444510102 seconds in game passed.
At 7.652188444510102 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6014],
         [-0.0013,  0.3243],
         [-0.0027,  0.2215],
         [-0.0045,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.313084, steer=-0.000832, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5114187939985282
Current mitigation activation: 0
#############################
Total reward: 33.21924405665986
7.677188444882631 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6014],
         [-0.0013,  0.3243],
         [-0.0027,  0.2215],
         [-0.0045,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.317158, steer=-0.001116, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21924405665986
7.70218844525516 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6014],
         [-0.0013,  0.3243],
         [-0.0027,  0.2215],
         [-0.0045,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.324827, steer=-0.001116, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21924405665986
7.727188445627689 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6014],
         [-0.0013,  0.3243],
         [-0.0027,  0.2215],
         [-0.0045,  0.1676]]])
agent 0 action: VehicleControl(throttle=0.333239, steer=-0.001116, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21924405665986
+++++++++++++: inf
7.752188446000218 seconds in game passed.
At 7.752188446000218 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.6309e-04,  6.0057e-01],
         [-6.5041e-04,  3.2348e-01],
         [-1.4368e-03,  2.2115e-01],
         [-2.9473e-03,  1.6706e-01]]])
agent 0 action: VehicleControl(throttle=0.364954, steer=-0.000906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4918353918369196
Current mitigation activation: 0
#############################
Total reward: 34.71107944849678
7.777188446372747 seconds in game passed.
Action: tensor([[[ 1.6309e-04,  6.0057e-01],
         [-6.5041e-04,  3.2348e-01],
         [-1.4368e-03,  2.2115e-01],
         [-2.9473e-03,  1.6706e-01]]])
agent 0 action: VehicleControl(throttle=0.372592, steer=-0.000954, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71107944849678
7.8021884467452765 seconds in game passed.
Action: tensor([[[ 1.6309e-04,  6.0057e-01],
         [-6.5041e-04,  3.2348e-01],
         [-1.4368e-03,  2.2115e-01],
         [-2.9473e-03,  1.6706e-01]]])
agent 0 action: VehicleControl(throttle=0.383048, steer=-0.000965, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71107944849678
7.8271884471178055 seconds in game passed.
Action: tensor([[[ 1.6309e-04,  6.0057e-01],
         [-6.5041e-04,  3.2348e-01],
         [-1.4368e-03,  2.2115e-01],
         [-2.9473e-03,  1.6706e-01]]])
agent 0 action: VehicleControl(throttle=0.393678, steer=-0.000977, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71107944849678
+++++++++++++: inf
7.8521884474903345 seconds in game passed.
At 7.8521884474903345 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9021e-03,  5.9918e-01],
         [-2.4336e-04,  3.2595e-01],
         [-1.1690e-03,  2.2431e-01],
         [-2.6084e-03,  1.7040e-01]]])
agent 0 action: VehicleControl(throttle=0.297495, steer=0.000388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.472353226663164
Current mitigation activation: 0
#############################
Total reward: 36.18343267515995
7.8771884478628635 seconds in game passed.
Action: tensor([[[ 2.9021e-03,  5.9918e-01],
         [-2.4336e-04,  3.2595e-01],
         [-1.1690e-03,  2.2431e-01],
         [-2.6084e-03,  1.7040e-01]]])
agent 0 action: VehicleControl(throttle=0.318709, steer=0.000139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18343267515995
7.902188448235393 seconds in game passed.
Action: tensor([[[ 2.9021e-03,  5.9918e-01],
         [-2.4336e-04,  3.2595e-01],
         [-1.1690e-03,  2.2431e-01],
         [-2.6084e-03,  1.7040e-01]]])
agent 0 action: VehicleControl(throttle=0.328962, steer=0.000121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18343267515995
7.927188448607922 seconds in game passed.
Action: tensor([[[ 2.9021e-03,  5.9918e-01],
         [-2.4336e-04,  3.2595e-01],
         [-1.1690e-03,  2.2431e-01],
         [-2.6084e-03,  1.7040e-01]]])
agent 0 action: VehicleControl(throttle=0.340336, steer=0.000103, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18343267515995
+++++++++++++: inf
7.952188448980451 seconds in game passed.
At 7.952188448980451 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8869e-04,  6.0165e-01],
         [-1.0533e-03,  3.2603e-01],
         [-1.5388e-03,  2.2291e-01],
         [-2.5650e-03,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.376368, steer=-0.001586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4549647248324487
Current mitigation activation: 0
#############################
Total reward: 37.6383973999924
7.97718844935298 seconds in game passed.
Action: tensor([[[ 1.8869e-04,  6.0165e-01],
         [-1.0533e-03,  3.2603e-01],
         [-1.5388e-03,  2.2291e-01],
         [-2.5650e-03,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.386772, steer=-0.001332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.6383973999924
8.002188449725509 seconds in game passed.
Action: tensor([[[ 1.8869e-04,  6.0165e-01],
         [-1.0533e-03,  3.2603e-01],
         [-1.5388e-03,  2.2291e-01],
         [-2.5650e-03,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.400095, steer=-0.001356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.6383973999924
8.027188450098038 seconds in game passed.
Action: tensor([[[ 1.8869e-04,  6.0165e-01],
         [-1.0533e-03,  3.2603e-01],
         [-1.5388e-03,  2.2291e-01],
         [-2.5650e-03,  1.6924e-01]]])
agent 0 action: VehicleControl(throttle=0.413485, steer=-0.001380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.6383973999924
+++++++++++++: inf
8.052188450470567 seconds in game passed.
At 8.052188450470567 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6045],
         [-0.0040,  0.3272],
         [-0.0050,  0.2238],
         [-0.0061,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.414287, steer=-0.004158, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.438242547311377
Current mitigation activation: 0
#############################
Total reward: 39.076639947303775
8.077188450843096 seconds in game passed.
Action: tensor([[[-0.0013,  0.6045],
         [-0.0040,  0.3272],
         [-0.0050,  0.2238],
         [-0.0061,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.428607, steer=-0.003732, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.076639947303775
8.102188451215625 seconds in game passed.
Action: tensor([[[-0.0013,  0.6045],
         [-0.0040,  0.3272],
         [-0.0050,  0.2238],
         [-0.0061,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.441477, steer=-0.003765, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.076639947303775
8.127188451588154 seconds in game passed.
Action: tensor([[[-0.0013,  0.6045],
         [-0.0040,  0.3272],
         [-0.0050,  0.2238],
         [-0.0061,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.454204, steer=-0.003797, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.076639947303775
+++++++++++++: inf
8.152188451960683 seconds in game passed.
At 8.152188451960683 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0021,  0.6049],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.502311, steer=-0.004981, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4235360777922301
Current mitigation activation: 0
#############################
Total reward: 40.500176025096
8.177188452333212 seconds in game passed.
Action: tensor([[[-0.0021,  0.6049],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.511345, steer=-0.004830, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.500176025096
8.202188452705741 seconds in game passed.
Action: tensor([[[-0.0021,  0.6049],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.523581, steer=-0.004869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.500176025096
8.22718845307827 seconds in game passed.
Action: tensor([[[-0.0021,  0.6049],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.534916, steer=-0.004909, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.500176025096
+++++++++++++: inf
8.252188453450799 seconds in game passed.
At 8.252188453450799 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.6480e-04,  6.0000e-01],
         [-2.1672e-03,  3.2498e-01],
         [-2.8072e-03,  2.2218e-01],
         [-3.5285e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.543137, steer=-0.002002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4123275309288328
Current mitigation activation: 0
#############################
Total reward: 41.91250355602484
8.277188453823328 seconds in game passed.
Action: tensor([[[-3.6480e-04,  6.0000e-01],
         [-2.1672e-03,  3.2498e-01],
         [-2.8072e-03,  2.2218e-01],
         [-3.5285e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.550326, steer=-0.002433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91250355602484
8.302188454195857 seconds in game passed.
Action: tensor([[[-3.6480e-04,  6.0000e-01],
         [-2.1672e-03,  3.2498e-01],
         [-2.8072e-03,  2.2218e-01],
         [-3.5285e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.556794, steer=-0.002387, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91250355602484
8.327188454568386 seconds in game passed.
Action: tensor([[[-3.6480e-04,  6.0000e-01],
         [-2.1672e-03,  3.2498e-01],
         [-2.8072e-03,  2.2218e-01],
         [-3.5285e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.563293, steer=-0.002341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91250355602484
+++++++++++++: inf
8.352188454940915 seconds in game passed.
At 8.352188454940915 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0096,  0.6373],
         [-0.0007,  0.3441],
         [-0.0024,  0.2351],
         [-0.0034,  0.1784]]])
agent 0 action: VehicleControl(throttle=0.280651, steer=0.002771, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4071540473154383
Current mitigation activation: 0
#############################
Total reward: 43.319657603340275
8.377188455313444 seconds in game passed.
Action: tensor([[[ 0.0096,  0.6373],
         [-0.0007,  0.3441],
         [-0.0024,  0.2351],
         [-0.0034,  0.1784]]])
agent 0 action: VehicleControl(throttle=0.314769, steer=0.002019, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.319657603340275
8.402188455685973 seconds in game passed.
Action: tensor([[[ 0.0096,  0.6373],
         [-0.0007,  0.3441],
         [-0.0024,  0.2351],
         [-0.0034,  0.1784]]])
agent 0 action: VehicleControl(throttle=0.318233, steer=0.002106, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.319657603340275
8.427188456058502 seconds in game passed.
Action: tensor([[[ 0.0096,  0.6373],
         [-0.0007,  0.3441],
         [-0.0024,  0.2351],
         [-0.0034,  0.1784]]])
agent 0 action: VehicleControl(throttle=0.321641, steer=0.002192, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.319657603340275
+++++++++++++: inf
8.452188456431031 seconds in game passed.
At 8.452188456431031 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0154, 0.6386],
         [0.0037, 0.3473],
         [0.0023, 0.2386],
         [0.0014, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.234796, steer=0.007898, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4050483870855834
Current mitigation activation: 0
#############################
Total reward: 44.72470599042586
8.47718845680356 seconds in game passed.
Action: tensor([[[0.0154, 0.6386],
         [0.0037, 0.3473],
         [0.0023, 0.2386],
         [0.0014, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.246810, steer=0.007102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72470599042586
8.50218845717609 seconds in game passed.
Action: tensor([[[0.0154, 0.6386],
         [0.0037, 0.3473],
         [0.0023, 0.2386],
         [0.0014, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.249206, steer=0.007235, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72470599042586
8.527188457548618 seconds in game passed.
Action: tensor([[[0.0154, 0.6386],
         [0.0037, 0.3473],
         [0.0023, 0.2386],
         [0.0014, 0.1815]]])
agent 0 action: VehicleControl(throttle=0.251439, steer=0.007368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72470599042586
+++++++++++++: inf
8.552188457921147 seconds in game passed.
At 8.552188457921147 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.4731e-03, 6.0026e-01],
         [1.7405e-03, 3.2436e-01],
         [1.1193e-03, 2.2260e-01],
         [2.9340e-04, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.659009, steer=0.001980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4029351103860686
Current mitigation activation: 0
#############################
Total reward: 46.12764110081193
8.577188458293676 seconds in game passed.
Action: tensor([[[5.4731e-03, 6.0026e-01],
         [1.7405e-03, 3.2436e-01],
         [1.1193e-03, 2.2260e-01],
         [2.9340e-04, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.622424, steer=0.002948, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12764110081193
8.602188458666205 seconds in game passed.
Action: tensor([[[5.4731e-03, 6.0026e-01],
         [1.7405e-03, 3.2436e-01],
         [1.1193e-03, 2.2260e-01],
         [2.9340e-04, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.628621, steer=0.003008, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12764110081193
8.627188459038734 seconds in game passed.
Action: tensor([[[5.4731e-03, 6.0026e-01],
         [1.7405e-03, 3.2436e-01],
         [1.1193e-03, 2.2260e-01],
         [2.9340e-04, 1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.634661, steer=0.003068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12764110081193
+++++++++++++: inf
8.652188459411263 seconds in game passed.
At 8.652188459411263 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.5466e-03,  5.9501e-01],
         [-4.4174e-05,  3.2378e-01],
         [-5.8809e-04,  2.2269e-01],
         [-1.1606e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.604472, steer=0.001034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4008510326494958
Current mitigation activation: 0
#############################
Total reward: 47.52849213346143
8.677188459783792 seconds in game passed.
Action: tensor([[[ 3.5466e-03,  5.9501e-01],
         [-4.4174e-05,  3.2378e-01],
         [-5.8809e-04,  2.2269e-01],
         [-1.1606e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.613257, steer=0.001397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52849213346143
8.702188460156322 seconds in game passed.
Action: tensor([[[ 3.5466e-03,  5.9501e-01],
         [-4.4174e-05,  3.2378e-01],
         [-5.8809e-04,  2.2269e-01],
         [-1.1606e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.618069, steer=0.001418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52849213346143
8.72718846052885 seconds in game passed.
Action: tensor([[[ 3.5466e-03,  5.9501e-01],
         [-4.4174e-05,  3.2378e-01],
         [-5.8809e-04,  2.2269e-01],
         [-1.1606e-03,  1.6925e-01]]])
agent 0 action: VehicleControl(throttle=0.622705, steer=0.001439, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52849213346143
+++++++++++++: inf
8.75218846090138 seconds in game passed.
At 8.75218846090138 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 9.3326e-05,  5.9693e-01],
         [-8.6867e-04,  3.2319e-01],
         [-1.0648e-03,  2.2184e-01],
         [-1.3056e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.670182, steer=-0.000531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3987658823890015
Current mitigation activation: 0
#############################
Total reward: 48.92725801585043
8.777188461273909 seconds in game passed.
Action: tensor([[[ 9.3326e-05,  5.9693e-01],
         [-8.6867e-04,  3.2319e-01],
         [-1.0648e-03,  2.2184e-01],
         [-1.3056e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.670112, steer=-0.000205, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92725801585043
8.802188461646438 seconds in game passed.
Action: tensor([[[ 9.3326e-05,  5.9693e-01],
         [-8.6867e-04,  3.2319e-01],
         [-1.0648e-03,  2.2184e-01],
         [-1.3056e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.654256, steer=-0.000207, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92725801585043
8.827188462018967 seconds in game passed.
Action: tensor([[[ 9.3326e-05,  5.9693e-01],
         [-8.6867e-04,  3.2319e-01],
         [-1.0648e-03,  2.2184e-01],
         [-1.3056e-03,  1.6844e-01]]])
agent 0 action: VehicleControl(throttle=0.641721, steer=-0.000209, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92725801585043
+++++++++++++: inf
8.852188462391496 seconds in game passed.
At 8.852188462391496 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6088],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.622236, steer=-0.003298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4039227808096963
Current mitigation activation: 0
#############################
Total reward: 50.33118079666012
8.877188462764025 seconds in game passed.
Action: tensor([[[-0.0024,  0.6088],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.611620, steer=-0.002839, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33118079666012
8.902188463136554 seconds in game passed.
Action: tensor([[[-0.0024,  0.6088],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.600338, steer=-0.002887, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33118079666012
8.927188463509083 seconds in game passed.
Action: tensor([[[-0.0024,  0.6088],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.589280, steer=-0.002935, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33118079666012
+++++++++++++: inf
8.952188463881612 seconds in game passed.
At 8.952188463881612 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0045,  0.6107],
         [-0.0061,  0.3280],
         [-0.0065,  0.2237],
         [-0.0069,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.555377, steer=-0.005594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.421485994175827
Current mitigation activation: 0
#############################
Total reward: 51.752666790835946
8.97718846425414 seconds in game passed.
Action: tensor([[[-0.0045,  0.6107],
         [-0.0061,  0.3280],
         [-0.0065,  0.2237],
         [-0.0069,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.546728, steer=-0.005218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.752666790835946
9.00218846462667 seconds in game passed.
Action: tensor([[[-0.0045,  0.6107],
         [-0.0061,  0.3280],
         [-0.0065,  0.2237],
         [-0.0069,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.536027, steer=-0.005276, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.752666790835946
9.027188464999199 seconds in game passed.
Action: tensor([[[-0.0045,  0.6107],
         [-0.0061,  0.3280],
         [-0.0065,  0.2237],
         [-0.0069,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.525804, steer=-0.005333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.752666790835946
+++++++++++++: inf
9.052188465371728 seconds in game passed.
At 9.052188465371728 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0015,  0.5999],
         [-0.0025,  0.3247],
         [-0.0027,  0.2228],
         [-0.0031,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.524126, steer=-0.001533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4364655413821363
Current mitigation activation: 0
#############################
Total reward: 53.18913233221808
9.077188465744257 seconds in game passed.
Action: tensor([[[-0.0015,  0.5999],
         [-0.0025,  0.3247],
         [-0.0027,  0.2228],
         [-0.0031,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.514173, steer=-0.002154, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18913233221808
9.102188466116786 seconds in game passed.
Action: tensor([[[-0.0015,  0.5999],
         [-0.0025,  0.3247],
         [-0.0027,  0.2228],
         [-0.0031,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.505464, steer=-0.002144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18913233221808
9.127188466489315 seconds in game passed.
Action: tensor([[[-0.0015,  0.5999],
         [-0.0025,  0.3247],
         [-0.0027,  0.2228],
         [-0.0031,  0.1698]]])
agent 0 action: VehicleControl(throttle=0.497110, steer=-0.002133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.18913233221808
+++++++++++++: inf
9.152188466861844 seconds in game passed.
At 9.152188466861844 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.0664e-03,  6.0676e-01],
         [ 1.2231e-03,  3.2908e-01],
         [ 6.5217e-04,  2.2563e-01],
         [-2.3758e-04,  1.7170e-01]]])
agent 0 action: VehicleControl(throttle=0.400653, steer=0.002489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4480924096069412
Current mitigation activation: 0
#############################
Total reward: 54.63722474182502
9.177188467234373 seconds in game passed.
Action: tensor([[[ 3.0664e-03,  6.0676e-01],
         [ 1.2231e-03,  3.2908e-01],
         [ 6.5217e-04,  2.2563e-01],
         [-2.3758e-04,  1.7170e-01]]])
agent 0 action: VehicleControl(throttle=0.400999, steer=0.001800, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.63722474182502
9.202188467606902 seconds in game passed.
Action: tensor([[[ 3.0664e-03,  6.0676e-01],
         [ 1.2231e-03,  3.2908e-01],
         [ 6.5217e-04,  2.2563e-01],
         [-2.3758e-04,  1.7170e-01]]])
agent 0 action: VehicleControl(throttle=0.392642, steer=0.001869, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.63722474182502
9.227188467979431 seconds in game passed.
Action: tensor([[[ 3.0664e-03,  6.0676e-01],
         [ 1.2231e-03,  3.2908e-01],
         [ 6.5217e-04,  2.2563e-01],
         [-2.3758e-04,  1.7170e-01]]])
agent 0 action: VehicleControl(throttle=0.385404, steer=0.001939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.63722474182502
+++++++++++++: inf
9.25218846835196 seconds in game passed.
At 9.25218846835196 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0076, 0.6347],
         [0.0034, 0.3543],
         [0.0028, 0.2478],
         [0.0019, 0.1913]]])
agent 0 action: VehicleControl(throttle=0.144127, steer=0.005433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4563791225945328
Current mitigation activation: 0
#############################
Total reward: 56.093603864419556
9.27718846872449 seconds in game passed.
Action: tensor([[[0.0076, 0.6347],
         [0.0034, 0.3543],
         [0.0028, 0.2478],
         [0.0019, 0.1913]]])
agent 0 action: VehicleControl(throttle=0.163988, steer=0.004939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.093603864419556
9.302188469097018 seconds in game passed.
Action: tensor([[[0.0076, 0.6347],
         [0.0034, 0.3543],
         [0.0028, 0.2478],
         [0.0019, 0.1913]]])
agent 0 action: VehicleControl(throttle=0.158497, steer=0.005014, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.093603864419556
9.327188469469547 seconds in game passed.
Action: tensor([[[0.0076, 0.6347],
         [0.0034, 0.3543],
         [0.0028, 0.2478],
         [0.0019, 0.1913]]])
agent 0 action: VehicleControl(throttle=0.152985, steer=0.005090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.093603864419556
+++++++++++++: inf
9.352188469842076 seconds in game passed.
At 9.352188469842076 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0067, 0.6164],
         [0.0030, 0.3395],
         [0.0021, 0.2361],
         [0.0013, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.150646, steer=0.004418, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4596825074835826
Current mitigation activation: 0
#############################
Total reward: 57.55328637190314
9.377188470214605 seconds in game passed.
Action: tensor([[[0.0067, 0.6164],
         [0.0030, 0.3395],
         [0.0021, 0.2361],
         [0.0013, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.148286, steer=0.004549, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55328637190314
9.402188470587134 seconds in game passed.
Action: tensor([[[0.0067, 0.6164],
         [0.0030, 0.3395],
         [0.0021, 0.2361],
         [0.0013, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.145906, steer=0.004565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55328637190314
9.427188470959663 seconds in game passed.
Action: tensor([[[0.0067, 0.6164],
         [0.0030, 0.3395],
         [0.0021, 0.2361],
         [0.0013, 0.1822]]])
agent 0 action: VehicleControl(throttle=0.143505, steer=0.004581, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55328637190314
+++++++++++++: inf
9.452188471332192 seconds in game passed.
At 9.452188471332192 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.0229e-03,  6.1890e-01],
         [ 1.1893e-03,  3.3687e-01],
         [ 2.5959e-04,  2.3265e-01],
         [-6.0172e-04,  1.7856e-01]]])
agent 0 action: VehicleControl(throttle=0.257025, steer=0.002946, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4547691546657622
Current mitigation activation: 0
#############################
Total reward: 59.0080555265689
9.477188471704721 seconds in game passed.
Action: tensor([[[ 6.0229e-03,  6.1890e-01],
         [ 1.1893e-03,  3.3687e-01],
         [ 2.5959e-04,  2.3265e-01],
         [-6.0172e-04,  1.7856e-01]]])
agent 0 action: VehicleControl(throttle=0.254796, steer=0.003150, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.0080555265689
9.50218847207725 seconds in game passed.
Action: tensor([[[ 6.0229e-03,  6.1890e-01],
         [ 1.1893e-03,  3.3687e-01],
         [ 2.5959e-04,  2.3265e-01],
         [-6.0172e-04,  1.7856e-01]]])
agent 0 action: VehicleControl(throttle=0.264300, steer=0.003092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.0080555265689
9.52718847244978 seconds in game passed.
Action: tensor([[[ 6.0229e-03,  6.1890e-01],
         [ 1.1893e-03,  3.3687e-01],
         [ 2.5959e-04,  2.3265e-01],
         [-6.0172e-04,  1.7856e-01]]])
agent 0 action: VehicleControl(throttle=0.273527, steer=0.003033, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.0080555265689
+++++++++++++: inf
9.552188472822309 seconds in game passed.
At 9.552188472822309 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0009,  0.6147],
         [-0.0014,  0.3323],
         [-0.0020,  0.2280],
         [-0.0028,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.394245, steer=-0.000938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4442212299802955
Current mitigation activation: 0
#############################
Total reward: 60.452276756549196
9.577188473194838 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6147],
         [-0.0014,  0.3323],
         [-0.0020,  0.2280],
         [-0.0028,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.387557, steer=-0.000326, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.452276756549196
9.602188473567367 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6147],
         [-0.0014,  0.3323],
         [-0.0020,  0.2280],
         [-0.0028,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.392742, steer=-0.000368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.452276756549196
9.627188473939896 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6147],
         [-0.0014,  0.3323],
         [-0.0020,  0.2280],
         [-0.0028,  0.1743]]])
agent 0 action: VehicleControl(throttle=0.396795, steer=-0.000411, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.452276756549196
+++++++++++++: inf
9.652188474312425 seconds in game passed.
At 9.652188474312425 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6171],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0066,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.483509, steer=-0.004655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4336383354248445
Current mitigation activation: 0
#############################
Total reward: 61.88591509197404
9.677188474684954 seconds in game passed.
Action: tensor([[[-0.0033,  0.6171],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0066,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.478430, steer=-0.004023, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88591509197404
9.702188475057483 seconds in game passed.
Action: tensor([[[-0.0033,  0.6171],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0066,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.481310, steer=-0.004088, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88591509197404
9.727188475430012 seconds in game passed.
Action: tensor([[[-0.0033,  0.6171],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0066,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.482902, steer=-0.004153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88591509197404
+++++++++++++: inf
9.75218847580254 seconds in game passed.
At 9.75218847580254 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0073,  0.6249],
         [-0.0115,  0.3319],
         [-0.0132,  0.2247],
         [-0.0143,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.519530, steer=-0.010770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.426958576426348
Current mitigation activation: 0
#############################
Total reward: 63.31287366840039
9.77718847617507 seconds in game passed.
Action: tensor([[[-0.0073,  0.6249],
         [-0.0115,  0.3319],
         [-0.0132,  0.2247],
         [-0.0143,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.515352, steer=-0.009798, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31287366840039
9.802188476547599 seconds in game passed.
Action: tensor([[[-0.0073,  0.6249],
         [-0.0115,  0.3319],
         [-0.0132,  0.2247],
         [-0.0143,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.514539, steer=-0.009910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31287366840039
9.827188476920128 seconds in game passed.
Action: tensor([[[-0.0073,  0.6249],
         [-0.0115,  0.3319],
         [-0.0132,  0.2247],
         [-0.0143,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.512951, steer=-0.010022, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31287366840039
+++++++++++++: inf
9.852188477292657 seconds in game passed.
At 9.852188477292657 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6118],
         [-0.0041,  0.3287],
         [-0.0044,  0.2239],
         [-0.0043,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.492754, steer=-0.002577, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4251089778901922
Current mitigation activation: 0
#############################
Total reward: 64.73798264629059
9.877188477665186 seconds in game passed.
Action: tensor([[[-0.0023,  0.6118],
         [-0.0041,  0.3287],
         [-0.0044,  0.2239],
         [-0.0043,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.492068, steer=-0.003821, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73798264629059
9.902188478037715 seconds in game passed.
Action: tensor([[[-0.0023,  0.6118],
         [-0.0041,  0.3287],
         [-0.0044,  0.2239],
         [-0.0043,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.489162, steer=-0.003824, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73798264629059
9.927188478410244 seconds in game passed.
Action: tensor([[[-0.0023,  0.6118],
         [-0.0041,  0.3287],
         [-0.0044,  0.2239],
         [-0.0043,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.486212, steer=-0.003827, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73798264629059
+++++++++++++: inf
9.952188478782773 seconds in game passed.
At 9.952188478782773 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.1905e-04,  6.0293e-01],
         [-2.0072e-03,  3.2559e-01],
         [-2.6321e-03,  2.2258e-01],
         [-3.0740e-03,  1.6893e-01]]])
agent 0 action: VehicleControl(throttle=0.501725, steer=-0.001504, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4269524347937597
Current mitigation activation: 0
#############################
Total reward: 66.16493508108435
9.977188479155302 seconds in game passed.
Action: tensor([[[-4.1905e-04,  6.0293e-01],
         [-2.0072e-03,  3.2559e-01],
         [-2.6321e-03,  2.2258e-01],
         [-3.0740e-03,  1.6893e-01]]])
agent 0 action: VehicleControl(throttle=0.497271, steer=-0.001835, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16493508108435
10.002188479527831 seconds in game passed.
Action: tensor([[[-4.1905e-04,  6.0293e-01],
         [-2.0072e-03,  3.2559e-01],
         [-2.6321e-03,  2.2258e-01],
         [-3.0740e-03,  1.6893e-01]]])
agent 0 action: VehicleControl(throttle=0.494736, steer=-0.001787, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16493508108435
10.02718847990036 seconds in game passed.
Action: tensor([[[-4.1905e-04,  6.0293e-01],
         [-2.0072e-03,  3.2559e-01],
         [-2.6321e-03,  2.2258e-01],
         [-3.0740e-03,  1.6893e-01]]])
agent 0 action: VehicleControl(throttle=0.492110, steer=-0.001739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16493508108435
+++++++++++++: inf
10.05218848027289 seconds in game passed.
At 10.05218848027289 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.8242e-03,  6.2111e-01],
         [ 6.2118e-04,  3.3180e-01],
         [ 7.3135e-05,  2.2622e-01],
         [-4.4605e-04,  1.7210e-01]]])
agent 0 action: VehicleControl(throttle=0.454087, steer=0.001496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4303155090465154
Current mitigation activation: 0
#############################
Total reward: 67.59525059013086
10.077188480645418 seconds in game passed.
Action: tensor([[[ 2.8242e-03,  6.2111e-01],
         [ 6.2118e-04,  3.3180e-01],
         [ 7.3135e-05,  2.2622e-01],
         [-4.4605e-04,  1.7210e-01]]])
agent 0 action: VehicleControl(throttle=0.454714, steer=0.001006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59525059013086
10.102188481017947 seconds in game passed.
Action: tensor([[[ 2.8242e-03,  6.2111e-01],
         [ 6.2118e-04,  3.3180e-01],
         [ 7.3135e-05,  2.2622e-01],
         [-4.4605e-04,  1.7210e-01]]])
agent 0 action: VehicleControl(throttle=0.451747, steer=0.001048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59525059013086
10.127188481390476 seconds in game passed.
Action: tensor([[[ 2.8242e-03,  6.2111e-01],
         [ 6.2118e-04,  3.3180e-01],
         [ 7.3135e-05,  2.2622e-01],
         [-4.4605e-04,  1.7210e-01]]])
agent 0 action: VehicleControl(throttle=0.449135, steer=0.001089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59525059013086
+++++++++++++: inf
10.152188481763005 seconds in game passed.
At 10.152188481763005 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.3670e-03, 6.1132e-01],
         [6.8363e-04, 3.2722e-01],
         [6.6567e-04, 2.2299e-01],
         [4.5697e-04, 1.6917e-01]]])
agent 0 action: VehicleControl(throttle=0.512076, steer=0.000552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4341423968675815
Current mitigation activation: 0
#############################
Total reward: 69.02939298699845
10.177188482135534 seconds in game passed.
Action: tensor([[[1.3670e-03, 6.1132e-01],
         [6.8363e-04, 3.2722e-01],
         [6.6567e-04, 2.2299e-01],
         [4.5697e-04, 1.6917e-01]]])
agent 0 action: VehicleControl(throttle=0.504872, steer=0.000629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.02939298699845
10.202188482508063 seconds in game passed.
Action: tensor([[[1.3670e-03, 6.1132e-01],
         [6.8363e-04, 3.2722e-01],
         [6.6567e-04, 2.2299e-01],
         [4.5697e-04, 1.6917e-01]]])
agent 0 action: VehicleControl(throttle=0.504534, steer=0.000617, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.02939298699845
10.227188482880592 seconds in game passed.
Action: tensor([[[1.3670e-03, 6.1132e-01],
         [6.8363e-04, 3.2722e-01],
         [6.6567e-04, 2.2299e-01],
         [4.5697e-04, 1.6917e-01]]])
agent 0 action: VehicleControl(throttle=0.503842, steer=0.000606, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.02939298699845
+++++++++++++: inf
10.252188483253121 seconds in game passed.
At 10.252188483253121 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2227],
         [0.0023, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.529047, steer=0.001605, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4374523509078945
Current mitigation activation: 0
#############################
Total reward: 70.46684533790634
10.27718848362565 seconds in game passed.
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2227],
         [0.0023, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.528308, steer=0.001397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46684533790634
10.30218848399818 seconds in game passed.
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2227],
         [0.0023, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.529810, steer=0.001361, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46684533790634
10.327188484370708 seconds in game passed.
Action: tensor([[[0.0025, 0.6135],
         [0.0015, 0.3272],
         [0.0020, 0.2227],
         [0.0023, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.530929, steer=0.001325, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46684533790634
+++++++++++++: inf
10.352188484743237 seconds in game passed.
At 10.352188484743237 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[2.4344e-04, 5.9809e-01],
         [7.2369e-04, 3.2310e-01],
         [1.1335e-03, 2.2113e-01],
         [1.1284e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.519475, steer=-0.000167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.441335068065004
Current mitigation activation: 0
#############################
Total reward: 71.90818040597134
10.377188485115767 seconds in game passed.
Action: tensor([[[2.4344e-04, 5.9809e-01],
         [7.2369e-04, 3.2310e-01],
         [1.1335e-03, 2.2113e-01],
         [1.1284e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.521182, steer=0.000030, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.90818040597134
10.402188485488296 seconds in game passed.
Action: tensor([[[2.4344e-04, 5.9809e-01],
         [7.2369e-04, 3.2310e-01],
         [1.1335e-03, 2.2113e-01],
         [1.1284e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.521378, steer=-0.000013, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.90818040597134
10.427188485860825 seconds in game passed.
Action: tensor([[[2.4344e-04, 5.9809e-01],
         [7.2369e-04, 3.2310e-01],
         [1.1335e-03, 2.2113e-01],
         [1.1284e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.521460, steer=-0.000057, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.90818040597134
+++++++++++++: inf
10.452188486233354 seconds in game passed.
At 10.452188486233354 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.2295e-04,  6.0330e-01],
         [-4.3304e-04,  3.2572e-01],
         [-1.4633e-05,  2.2309e-01],
         [ 2.4437e-04,  1.6988e-01]]])
agent 0 action: VehicleControl(throttle=0.479117, steer=-0.000985, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.446398753690371
Current mitigation activation: 0
#############################
Total reward: 73.35457915966171
10.477188486605883 seconds in game passed.
Action: tensor([[[ 1.2295e-04,  6.0330e-01],
         [-4.3304e-04,  3.2572e-01],
         [-1.4633e-05,  2.2309e-01],
         [ 2.4437e-04,  1.6988e-01]]])
agent 0 action: VehicleControl(throttle=0.481473, steer=-0.000874, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.35457915966171
10.502188486978412 seconds in game passed.
Action: tensor([[[ 1.2295e-04,  6.0330e-01],
         [-4.3304e-04,  3.2572e-01],
         [-1.4633e-05,  2.2309e-01],
         [ 2.4437e-04,  1.6988e-01]]])
agent 0 action: VehicleControl(throttle=0.479384, steer=-0.000910, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.35457915966171
10.52718848735094 seconds in game passed.
Action: tensor([[[ 1.2295e-04,  6.0330e-01],
         [-4.3304e-04,  3.2572e-01],
         [-1.4633e-05,  2.2309e-01],
         [ 2.4437e-04,  1.6988e-01]]])
agent 0 action: VehicleControl(throttle=0.477460, steer=-0.000947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.35457915966171
+++++++++++++: inf
10.55218848772347 seconds in game passed.
At 10.55218848772347 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.5972],
         [0.0011, 0.3225],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.528844, steer=0.000600, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4519097653441777
Current mitigation activation: 0
#############################
Total reward: 74.8064889250059
10.577188488095999 seconds in game passed.
Action: tensor([[[0.0012, 0.5972],
         [0.0011, 0.3225],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.520591, steer=0.000366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.8064889250059
10.602188488468528 seconds in game passed.
Action: tensor([[[0.0012, 0.5972],
         [0.0011, 0.3225],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.518015, steer=0.000386, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.8064889250059
10.627188488841057 seconds in game passed.
Action: tensor([[[0.0012, 0.5972],
         [0.0011, 0.3225],
         [0.0019, 0.2207],
         [0.0026, 0.1676]]])
agent 0 action: VehicleControl(throttle=0.515028, steer=0.000406, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.8064889250059
+++++++++++++: inf
10.652188489213586 seconds in game passed.
At 10.652188489213586 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.5979],
         [0.0030, 0.3234],
         [0.0039, 0.2213],
         [0.0042, 0.1680]]])
agent 0 action: VehicleControl(throttle=0.483332, steer=0.002314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.456802704798428
Current mitigation activation: 0
#############################
Total reward: 76.26329162980433
10.677188489586115 seconds in game passed.
Action: tensor([[[0.0022, 0.5979],
         [0.0030, 0.3234],
         [0.0039, 0.2213],
         [0.0042, 0.1680]]])
agent 0 action: VehicleControl(throttle=0.481605, steer=0.002093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26329162980433
10.702188489958644 seconds in game passed.
Action: tensor([[[0.0022, 0.5979],
         [0.0030, 0.3234],
         [0.0039, 0.2213],
         [0.0042, 0.1680]]])
agent 0 action: VehicleControl(throttle=0.476902, steer=0.002175, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26329162980433
10.727188490331173 seconds in game passed.
Action: tensor([[[0.0022, 0.5979],
         [0.0030, 0.3234],
         [0.0039, 0.2213],
         [0.0042, 0.1680]]])
agent 0 action: VehicleControl(throttle=0.472354, steer=0.002258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.26329162980433
+++++++++++++: inf
10.752188490703702 seconds in game passed.
At 10.752188490703702 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.6170],
         [0.0009, 0.3337],
         [0.0012, 0.2286],
         [0.0010, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.295882, steer=0.000480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4617802622747673
Current mitigation activation: 0
#############################
Total reward: 77.7250718920791
10.777188491076231 seconds in game passed.
Action: tensor([[[0.0013, 0.6170],
         [0.0009, 0.3337],
         [0.0012, 0.2286],
         [0.0010, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.307505, steer=0.000929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.7250718920791
10.80218849144876 seconds in game passed.
Action: tensor([[[0.0013, 0.6170],
         [0.0009, 0.3337],
         [0.0012, 0.2286],
         [0.0010, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.301450, steer=0.001059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.7250718920791
10.827188491821289 seconds in game passed.
Action: tensor([[[0.0013, 0.6170],
         [0.0009, 0.3337],
         [0.0012, 0.2286],
         [0.0010, 0.1743]]])
agent 0 action: VehicleControl(throttle=0.297027, steer=0.001190, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.7250718920791
+++++++++++++: inf
10.852188492193818 seconds in game passed.
At 10.852188492193818 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6128],
         [0.0016, 0.3282],
         [0.0017, 0.2247],
         [0.0016, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.450184, steer=0.002630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4656958586086386
Current mitigation activation: 0
#############################
Total reward: 79.19076775068774
10.877188492566347 seconds in game passed.
Action: tensor([[[0.0035, 0.6128],
         [0.0016, 0.3282],
         [0.0017, 0.2247],
         [0.0016, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.433470, steer=0.002468, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.19076775068774
10.902188492938876 seconds in game passed.
Action: tensor([[[0.0035, 0.6128],
         [0.0016, 0.3282],
         [0.0017, 0.2247],
         [0.0016, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.434035, steer=0.002535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.19076775068774
10.927188493311405 seconds in game passed.
Action: tensor([[[0.0035, 0.6128],
         [0.0016, 0.3282],
         [0.0017, 0.2247],
         [0.0016, 0.1706]]])
agent 0 action: VehicleControl(throttle=0.434169, steer=0.002602, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.19076775068774
+++++++++++++: inf
10.952188493683934 seconds in game passed.
At 10.952188493683934 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0017, 0.6079],
         [0.0007, 0.3244],
         [0.0008, 0.2214],
         [0.0006, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.522274, steer=0.001260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.465382792730737
Current mitigation activation: 0
#############################
Total reward: 80.65615054341848
10.977188494056463 seconds in game passed.
Action: tensor([[[0.0017, 0.6079],
         [0.0007, 0.3244],
         [0.0008, 0.2214],
         [0.0006, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.513391, steer=0.001518, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.65615054341848
11.002188494428992 seconds in game passed.
Action: tensor([[[0.0017, 0.6079],
         [0.0007, 0.3244],
         [0.0008, 0.2214],
         [0.0006, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.513500, steer=0.001547, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.65615054341848
11.027188494801521 seconds in game passed.
Action: tensor([[[0.0017, 0.6079],
         [0.0007, 0.3244],
         [0.0008, 0.2214],
         [0.0006, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.512743, steer=0.001576, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.65615054341848
+++++++++++++: inf
11.05218849517405 seconds in game passed.
At 11.05218849517405 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.6607e-03, 6.0796e-01],
         [5.2804e-04, 3.2469e-01],
         [6.7473e-04, 2.2166e-01],
         [4.8640e-04, 1.6792e-01]]])
agent 0 action: VehicleControl(throttle=0.499983, steer=0.001430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4644780683636025
Current mitigation activation: 0
#############################
Total reward: 82.12062861178208
11.07718849554658 seconds in game passed.
Action: tensor([[[1.6607e-03, 6.0796e-01],
         [5.2804e-04, 3.2469e-01],
         [6.7473e-04, 2.2166e-01],
         [4.8640e-04, 1.6792e-01]]])
agent 0 action: VehicleControl(throttle=0.499635, steer=0.001448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.12062861178208
11.102188495919108 seconds in game passed.
Action: tensor([[[1.6607e-03, 6.0796e-01],
         [5.2804e-04, 3.2469e-01],
         [6.7473e-04, 2.2166e-01],
         [4.8640e-04, 1.6792e-01]]])
agent 0 action: VehicleControl(throttle=0.497657, steer=0.001442, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.12062861178208
11.127188496291637 seconds in game passed.
Action: tensor([[[1.6607e-03, 6.0796e-01],
         [5.2804e-04, 3.2469e-01],
         [6.7473e-04, 2.2166e-01],
         [4.8640e-04, 1.6792e-01]]])
agent 0 action: VehicleControl(throttle=0.495443, steer=0.001437, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.12062861178208
+++++++++++++: inf
11.152188496664166 seconds in game passed.
At 11.152188496664166 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.6560e-04, 6.1453e-01],
         [2.5038e-04, 3.2645e-01],
         [5.9777e-04, 2.2316e-01],
         [4.0661e-04, 1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.496253, steer=0.000759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4661764463753515
Current mitigation activation: 0
#############################
Total reward: 83.58680505815744
11.177188497036695 seconds in game passed.
Action: tensor([[[4.6560e-04, 6.1453e-01],
         [2.5038e-04, 3.2645e-01],
         [5.9777e-04, 2.2316e-01],
         [4.0661e-04, 1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.492598, steer=0.000864, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.58680505815744
11.202188497409225 seconds in game passed.
Action: tensor([[[4.6560e-04, 6.1453e-01],
         [2.5038e-04, 3.2645e-01],
         [5.9777e-04, 2.2316e-01],
         [4.0661e-04, 1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.489239, steer=0.000857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.58680505815744
11.227188497781754 seconds in game passed.
Action: tensor([[[4.6560e-04, 6.1453e-01],
         [2.5038e-04, 3.2645e-01],
         [5.9777e-04, 2.2316e-01],
         [4.0661e-04, 1.6997e-01]]])
agent 0 action: VehicleControl(throttle=0.485789, steer=0.000850, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.58680505815744
+++++++++++++: inf
11.252188498154283 seconds in game passed.
At 11.252188498154283 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.3301e-04,  6.2566e-01],
         [-3.3389e-04,  3.2753e-01],
         [-3.8362e-04,  2.2265e-01],
         [-1.1300e-03,  1.6890e-01]]])
agent 0 action: VehicleControl(throttle=0.555970, steer=0.000005, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.469427953614039
Current mitigation activation: 0
#############################
Total reward: 85.05623301177148
11.277188498526812 seconds in game passed.
Action: tensor([[[-5.3301e-04,  6.2566e-01],
         [-3.3389e-04,  3.2753e-01],
         [-3.8362e-04,  2.2265e-01],
         [-1.1300e-03,  1.6890e-01]]])
agent 0 action: VehicleControl(throttle=0.545199, steer=0.000115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.05623301177148
11.30218849889934 seconds in game passed.
Action: tensor([[[-5.3301e-04,  6.2566e-01],
         [-3.3389e-04,  3.2753e-01],
         [-3.8362e-04,  2.2265e-01],
         [-1.1300e-03,  1.6890e-01]]])
agent 0 action: VehicleControl(throttle=0.542084, steer=0.000089, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.05623301177148
11.32718849927187 seconds in game passed.
Action: tensor([[[-5.3301e-04,  6.2566e-01],
         [-3.3389e-04,  3.2753e-01],
         [-3.8362e-04,  2.2265e-01],
         [-1.1300e-03,  1.6890e-01]]])
agent 0 action: VehicleControl(throttle=0.538389, steer=0.000062, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.05623301177148
+++++++++++++: inf
11.352188499644399 seconds in game passed.
At 11.352188499644399 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.0533e-04,  6.2195e-01],
         [-2.9616e-04,  3.2662e-01],
         [-1.9880e-04,  2.2240e-01],
         [-7.8292e-04,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.530424, steer=0.000090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4732767231024853
Current mitigation activation: 0
#############################
Total reward: 86.52950973487397
11.377188500016928 seconds in game passed.
Action: tensor([[[-5.0533e-04,  6.2195e-01],
         [-2.9616e-04,  3.2662e-01],
         [-1.9880e-04,  2.2240e-01],
         [-7.8292e-04,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.526653, steer=0.000073, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52950973487397
11.402188500389457 seconds in game passed.
Action: tensor([[[-5.0533e-04,  6.2195e-01],
         [-2.9616e-04,  3.2662e-01],
         [-1.9880e-04,  2.2240e-01],
         [-7.8292e-04,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.522278, steer=0.000062, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52950973487397
11.427188500761986 seconds in game passed.
Action: tensor([[[-5.0533e-04,  6.2195e-01],
         [-2.9616e-04,  3.2662e-01],
         [-1.9880e-04,  2.2240e-01],
         [-7.8292e-04,  1.6907e-01]]])
agent 0 action: VehicleControl(throttle=0.517817, steer=0.000051, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52950973487397
+++++++++++++: inf
11.452188501134515 seconds in game passed.
At 11.452188501134515 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.6164],
         [-0.0007,  0.3257],
         [-0.0006,  0.2225],
         [-0.0012,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.491161, steer=-0.000676, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.478410163216083
Current mitigation activation: 0
#############################
Total reward: 88.00791989809005
11.477188501507044 seconds in game passed.
Action: tensor([[[-0.0016,  0.6164],
         [-0.0007,  0.3257],
         [-0.0006,  0.2225],
         [-0.0012,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.489266, steer=-0.000565, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.00791989809005
11.502188501879573 seconds in game passed.
Action: tensor([[[-0.0016,  0.6164],
         [-0.0007,  0.3257],
         [-0.0006,  0.2225],
         [-0.0012,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.485085, steer=-0.000574, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.00791989809005
11.527188502252102 seconds in game passed.
Action: tensor([[[-0.0016,  0.6164],
         [-0.0007,  0.3257],
         [-0.0006,  0.2225],
         [-0.0012,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.481170, steer=-0.000583, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.00791989809005
+++++++++++++: inf
11.552188502624631 seconds in game passed.
At 11.552188502624631 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.5729e-03,  6.1609e-01],
         [-5.7491e-04,  3.2720e-01],
         [-7.8512e-04,  2.2343e-01],
         [-1.8306e-03,  1.6983e-01]]])
agent 0 action: VehicleControl(throttle=0.418164, steer=-0.000511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.484053709701708
Current mitigation activation: 0
#############################
Total reward: 89.49197360779176
11.57718850299716 seconds in game passed.
Action: tensor([[[-1.5729e-03,  6.1609e-01],
         [-5.7491e-04,  3.2720e-01],
         [-7.8512e-04,  2.2343e-01],
         [-1.8306e-03,  1.6983e-01]]])
agent 0 action: VehicleControl(throttle=0.419666, steer=-0.000551, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.49197360779176
11.602188503369689 seconds in game passed.
Action: tensor([[[-1.5729e-03,  6.1609e-01],
         [-5.7491e-04,  3.2720e-01],
         [-7.8512e-04,  2.2343e-01],
         [-1.8306e-03,  1.6983e-01]]])
agent 0 action: VehicleControl(throttle=0.415336, steer=-0.000575, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.49197360779176
11.627188503742218 seconds in game passed.
Action: tensor([[[-1.5729e-03,  6.1609e-01],
         [-5.7491e-04,  3.2720e-01],
         [-7.8512e-04,  2.2343e-01],
         [-1.8306e-03,  1.6983e-01]]])
agent 0 action: VehicleControl(throttle=0.411749, steer=-0.000599, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.49197360779176
+++++++++++++: inf
11.652188504114747 seconds in game passed.
At 11.652188504114747 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6243],
         [0.0024, 0.3300],
         [0.0024, 0.2258],
         [0.0019, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.392449, steer=0.003128, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4887006685671418
Current mitigation activation: 0
#############################
Total reward: 90.98067427635891
11.677188504487276 seconds in game passed.
Action: tensor([[[0.0025, 0.6243],
         [0.0024, 0.3300],
         [0.0024, 0.2258],
         [0.0019, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.391842, steer=0.002502, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.98067427635891
11.702188504859805 seconds in game passed.
Action: tensor([[[0.0025, 0.6243],
         [0.0024, 0.3300],
         [0.0024, 0.2258],
         [0.0019, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.390017, steer=0.002498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.98067427635891
11.727188505232334 seconds in game passed.
Action: tensor([[[0.0025, 0.6243],
         [0.0024, 0.3300],
         [0.0024, 0.2258],
         [0.0019, 0.1715]]])
agent 0 action: VehicleControl(throttle=0.388748, steer=0.002494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.98067427635891
+++++++++++++: inf
11.752188505604863 seconds in game passed.
At 11.752188505604863 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0042,  0.7050],
         [-0.0032,  0.3815],
         [-0.0039,  0.2667],
         [-0.0042,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.120800, steer=-0.004271, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4909462689447879
Current mitigation activation: 0
#############################
Total reward: 92.4716205453037
11.777188505977392 seconds in game passed.
Action: tensor([[[-0.0042,  0.7050],
         [-0.0032,  0.3815],
         [-0.0039,  0.2667],
         [-0.0042,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.147623, steer=-0.003206, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.4716205453037
11.802188506349921 seconds in game passed.
Action: tensor([[[-0.0042,  0.7050],
         [-0.0032,  0.3815],
         [-0.0039,  0.2667],
         [-0.0042,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.145952, steer=-0.003260, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.4716205453037
11.82718850672245 seconds in game passed.
Action: tensor([[[-0.0042,  0.7050],
         [-0.0032,  0.3815],
         [-0.0039,  0.2667],
         [-0.0042,  0.2053]]])
agent 0 action: VehicleControl(throttle=0.144298, steer=-0.003314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.4716205453037
+++++++++++++: inf
11.85218850709498 seconds in game passed.
At 11.85218850709498 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0046,  0.6948],
         [-0.0077,  0.3744],
         [-0.0077,  0.2584],
         [-0.0068,  0.1976]]])
agent 0 action: VehicleControl(throttle=0.140922, steer=-0.006931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.490300455095139
Current mitigation activation: 0
#############################
Total reward: 93.96192100039883
11.877188507467508 seconds in game passed.
Action: tensor([[[-0.0046,  0.6948],
         [-0.0077,  0.3744],
         [-0.0077,  0.2584],
         [-0.0068,  0.1976]]])
agent 0 action: VehicleControl(throttle=0.137535, steer=-0.006451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96192100039883
11.902188507840037 seconds in game passed.
Action: tensor([[[-0.0046,  0.6948],
         [-0.0077,  0.3744],
         [-0.0077,  0.2584],
         [-0.0068,  0.1976]]])
agent 0 action: VehicleControl(throttle=0.134126, steer=-0.006556, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96192100039883
11.927188508212566 seconds in game passed.
Action: tensor([[[-0.0046,  0.6948],
         [-0.0077,  0.3744],
         [-0.0077,  0.2584],
         [-0.0068,  0.1976]]])
agent 0 action: VehicleControl(throttle=0.130700, steer=-0.006661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.96192100039883
+++++++++++++: inf
11.952188508585095 seconds in game passed.
At 11.952188508585095 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0082,  0.6679],
         [-0.0111,  0.3602],
         [-0.0115,  0.2468],
         [-0.0111,  0.1871]]])
agent 0 action: VehicleControl(throttle=0.126286, steer=-0.010674, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4831900009179237
Current mitigation activation: 0
#############################
Total reward: 95.44511100131676
11.977188508957624 seconds in game passed.
Action: tensor([[[-0.0082,  0.6679],
         [-0.0111,  0.3602],
         [-0.0115,  0.2468],
         [-0.0111,  0.1871]]])
agent 0 action: VehicleControl(throttle=0.121861, steer=-0.010158, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.44511100131676
12.002188509330153 seconds in game passed.
Action: tensor([[[-0.0082,  0.6679],
         [-0.0111,  0.3602],
         [-0.0115,  0.2468],
         [-0.0111,  0.1871]]])
agent 0 action: VehicleControl(throttle=0.117431, steer=-0.010289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.44511100131676
12.027188509702682 seconds in game passed.
Action: tensor([[[-0.0082,  0.6679],
         [-0.0111,  0.3602],
         [-0.0115,  0.2468],
         [-0.0111,  0.1871]]])
agent 0 action: VehicleControl(throttle=0.113006, steer=-0.010420, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.44511100131676
+++++++++++++: inf
12.052188510075212 seconds in game passed.
At 12.052188510075212 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6223],
         [-0.0030,  0.3279],
         [-0.0026,  0.2240],
         [-0.0025,  0.1703]]])
agent 0 action: VehicleControl(throttle=0.526537, steer=-0.002538, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
#############################
Current risk: 10.0
Current reward: 1.4708063579988695
Current mitigation activation: 0
#############################
Total reward: 96.91591735931563
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [91mFAILURE[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-15 00:36:44 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-15 00:37:24 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 40.05s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 9.75s               │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.243               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ FAILURE │ 46.64 % │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ FAILURE │ 1 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 96.92, average_reward: 96.91591735931563 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00001/fi_ghost_cutin_data
