New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004412-fi_ghost_cutin_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004412-fi_ghost_cutin_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004412-fi_ghost_cutin_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004412-fi_ghost_cutin_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004412-fi_ghost_cutin_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_logs/routes_fi_route_highway-1115_004412-fi_ghost_cutin_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_data/route_highway.xml_fi_ghost_cutin.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key distance_same_lane's value from 15 to 10.
Replacing key distance_lane_change's value from 11 to 6.
Replacing key speed_lane_change's value from 13.5 to 17.
Config for GhostCutIn scenario is {'first_vehicle_location': 0, 'first_vehicle_speed': 200, 'event_trigger_distance': 4, 'distance_lane_change': 6, 'speed_lane_change': 17, 'distance_same_lane': 10}
1.594252198934555 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0025, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003148, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.619252199307084 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0025, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6442521996796131 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0025, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6692522000521421 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0025, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.6942522004246712 seconds in game passed.
Action: tensor([[[0.0033, 0.5919],
         [0.0025, 0.3305],
         [0.0022, 0.2344],
         [0.0016, 0.1818]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.7192522007972002 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.7442522011697292 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003823, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7692522015422583 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.7942522019147873 seconds in game passed.
Action: tensor([[[0.0055, 0.5911],
         [0.0029, 0.3229],
         [0.0028, 0.2229],
         [0.0024, 0.1689]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003913, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.8192522022873163 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003171, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
1.8442522026598454 seconds in game passed.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8692522030323744 seconds in game passed.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003374, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.8942522034049034 seconds in game passed.
Action: tensor([[[0.0049, 0.5950],
         [0.0022, 0.3243],
         [0.0019, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003410, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
1.9192522037774324 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
1.9442522041499615 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9692522045224905 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002671, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
1.9942522048950195 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2231],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002697, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.0192522052675486 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002349, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.0442522056400776 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002433, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0692522060126066 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.0942522063851357 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.1192522067576647 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[2.4326e-03, 5.9056e-01],
         [1.3315e-03, 3.2232e-01],
         [1.1080e-03, 2.2210e-01],
         [5.6684e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.1442522071301937 seconds in game passed.
Action: tensor([[[2.4326e-03, 5.9056e-01],
         [1.3315e-03, 3.2232e-01],
         [1.1080e-03, 2.2210e-01],
         [5.6684e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1692522075027227 seconds in game passed.
Action: tensor([[[2.4326e-03, 5.9056e-01],
         [1.3315e-03, 3.2232e-01],
         [1.1080e-03, 2.2210e-01],
         [5.6684e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002352, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.1942522078752518 seconds in game passed.
Action: tensor([[[2.4326e-03, 5.9056e-01],
         [1.3315e-03, 3.2232e-01],
         [1.1080e-03, 2.2210e-01],
         [5.6684e-04, 1.6810e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002372, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 20297.16684299258
2.219252208247781 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.24425220862031 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.269252208992839 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.294252209365368 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.71016465861
2.319252209737897 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.344252210110426 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.369252210482955 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.394252210855484 seconds in game passed.
Action: tensor([[[0.0020, 0.5892],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002519, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.419252211228013 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.444252211600542 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.469252211973071 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.4942522123456 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0016, 0.3217],
         [0.0014, 0.2216],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.519252212718129 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002764, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.544252213090658 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002782, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.569252213463187 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002803, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.5942522138357162 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002792, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.6192522142082453 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5890],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002626, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.6442522145807743 seconds in game passed.
Action: tensor([[[0.0020, 0.5890],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6692522149533033 seconds in game passed.
Action: tensor([[[0.0020, 0.5890],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002627, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6942522153258324 seconds in game passed.
Action: tensor([[[0.0020, 0.5890],
         [0.0015, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7192522156983614 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002673, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.7442522160708904 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002636, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7692522164434195 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002612, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7942522168159485 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.6593486434
2.8192522171884775 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
2.8442522175610065 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8692522179335356 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8942522183060646 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.9192522186785936 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002477, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.9442522190511227 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9692522194236517 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9942522197961807 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3212],
         [0.0016, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.0192522201687098 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.044252220541239 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.069252220913768 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002356, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.094252221286297 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002353, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.119252221658826 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002552, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.144252222031355 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.169252222403884 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.194252222776413 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0018, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002523, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.219252223148942 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.244252223521471 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.269252223894 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.294252224266529 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.319252224639058 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.344252225011587 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.369252225384116 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.394252225756645 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.4192522261291742 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002274, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.4442522265017033 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4692522268742323 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.4942522272467613 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002293, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.5192522276192904 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002332, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.5442522279918194 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002323, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5692522283643484 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002320, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5942522287368774 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002318, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6192522291094065 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6442522294819355 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6692522298544645 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6942522302269936 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7192522305995226 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7442522309720516 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002398, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7692522313445807 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002397, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7942522317171097 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002396, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8192522320896387 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8442522324621677 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8692522328346968 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.894252233207226 seconds in game passed.
Action: tensor([[[0.0018, 0.5874],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002379, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.919252233579755 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002299, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.944252233952284 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002311, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.969252234324813 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.994252234697342 seconds in game passed.
Action: tensor([[[0.0016, 0.5868],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002308, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.019252235069871 seconds in game passed.
At 4.019252235069871 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0.06602266588708589
4.0442522354424 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.069252235814929 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002340, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.094252236187458 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002341, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
+++++++++++++: inf
4.119252236559987 seconds in game passed.
At 4.119252236559987 seconds, saving state-action tuples.
Action: tensor([[[1.4085e-03, 5.8603e-01],
         [1.1335e-03, 3.2065e-01],
         [1.0001e-03, 2.2100e-01],
         [3.4910e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.3145396919977081
4.144252236932516 seconds in game passed.
Action: tensor([[[1.4085e-03, 5.8603e-01],
         [1.1335e-03, 3.2065e-01],
         [1.0001e-03, 2.2100e-01],
         [3.4910e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.169252237305045 seconds in game passed.
Action: tensor([[[1.4085e-03, 5.8603e-01],
         [1.1335e-03, 3.2065e-01],
         [1.0001e-03, 2.2100e-01],
         [3.4910e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.194252237677574 seconds in game passed.
Action: tensor([[[1.4085e-03, 5.8603e-01],
         [1.1335e-03, 3.2065e-01],
         [1.0001e-03, 2.2100e-01],
         [3.4910e-04, 1.6728e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001905, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
+++++++++++++: inf
4.219252238050103 seconds in game passed.
At 4.219252238050103 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002140, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.7221479506394559
4.244252238422632 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002099, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.269252238795161 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.29425223916769 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002095, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
+++++++++++++: inf
4.319252239540219 seconds in game passed.
At 4.319252239540219 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.541619495703239
Current mitigation activation: 0
#############################
Total reward: 1.263767446342695
4.344252239912748 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
4.369252240285277 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
4.394252240657806 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3195],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
+++++++++++++: inf
4.419252241030335 seconds in game passed.
At 4.419252241030335 seconds, saving state-action tuples.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003066, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.6535768229361686
Current mitigation activation: 0
#############################
Total reward: 1.9173442692788636
4.4442522414028645 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002930, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
4.4692522417753935 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
4.4942522421479225 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002947, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
+++++++++++++: inf
4.5192522425204515 seconds in game passed.
At 4.5192522425204515 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.7480162554044171
Current mitigation activation: 0
#############################
Total reward: 2.6653605246832806
4.544252242892981 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653605246832806
4.56925224326551 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653605246832806
4.594252243638039 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653605246832806
+++++++++++++: inf
4.619252244010568 seconds in game passed.
At 4.619252244010568 seconds, saving state-action tuples.
Action: tensor([[[ 2.3976e-05,  5.8848e-01],
         [-4.4689e-05,  3.2180e-01],
         [ 4.1850e-05,  2.2105e-01],
         [-3.5018e-04,  1.6702e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000395, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.829066092370805
Current mitigation activation: 0
#############################
Total reward: 3.4944266170540854
4.644252244383097 seconds in game passed.
Action: tensor([[[ 2.3976e-05,  5.8848e-01],
         [-4.4689e-05,  3.2180e-01],
         [ 4.1850e-05,  2.2105e-01],
         [-3.5018e-04,  1.6702e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000725, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944266170540854
4.669252244755626 seconds in game passed.
Action: tensor([[[ 2.3976e-05,  5.8848e-01],
         [-4.4689e-05,  3.2180e-01],
         [ 4.1850e-05,  2.2105e-01],
         [-3.5018e-04,  1.6702e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000706, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944266170540854
4.694252245128155 seconds in game passed.
Action: tensor([[[ 2.3976e-05,  5.8848e-01],
         [-4.4689e-05,  3.2180e-01],
         [ 4.1850e-05,  2.2105e-01],
         [-3.5018e-04,  1.6702e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.4944266170540854
+++++++++++++: inf
4.719252245500684 seconds in game passed.
At 4.719252245500684 seconds, saving state-action tuples.
Action: tensor([[[ 3.2394e-04,  5.8907e-01],
         [-2.2776e-04,  3.2115e-01],
         [-1.7720e-04,  2.2086e-01],
         [-4.2862e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000653, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8996363843097241
Current mitigation activation: 0
#############################
Total reward: 4.39406300136381
4.744252245873213 seconds in game passed.
Action: tensor([[[ 3.2394e-04,  5.8907e-01],
         [-2.2776e-04,  3.2115e-01],
         [-1.7720e-04,  2.2086e-01],
         [-4.2862e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.39406300136381
4.769252246245742 seconds in game passed.
Action: tensor([[[ 3.2394e-04,  5.8907e-01],
         [-2.2776e-04,  3.2115e-01],
         [-1.7720e-04,  2.2086e-01],
         [-4.2862e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.39406300136381
4.794252246618271 seconds in game passed.
Action: tensor([[[ 3.2394e-04,  5.8907e-01],
         [-2.2776e-04,  3.2115e-01],
         [-1.7720e-04,  2.2086e-01],
         [-4.2862e-04,  1.6698e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000593, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.39406300136381
+++++++++++++: inf
4.8192522469908 seconds in game passed.
At 4.8192522469908 seconds, saving state-action tuples.
Action: tensor([[[-4.2789e-04,  5.9107e-01],
         [-1.0300e-03,  3.2138e-01],
         [-8.8550e-04,  2.2095e-01],
         [-1.0252e-03,  1.6699e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000317, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.962209169834031
Current mitigation activation: 0
#############################
Total reward: 5.3562721711978405
4.844252247363329 seconds in game passed.
Action: tensor([[[-4.2789e-04,  5.9107e-01],
         [-1.0300e-03,  3.2138e-01],
         [-8.8550e-04,  2.2095e-01],
         [-1.0252e-03,  1.6699e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000200, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.3562721711978405
4.869252247735858 seconds in game passed.
Action: tensor([[[-4.2789e-04,  5.9107e-01],
         [-1.0300e-03,  3.2138e-01],
         [-8.8550e-04,  2.2095e-01],
         [-1.0252e-03,  1.6699e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000229, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.3562721711978405
4.894252248108387 seconds in game passed.
Action: tensor([[[-4.2789e-04,  5.9107e-01],
         [-1.0300e-03,  3.2138e-01],
         [-8.8550e-04,  2.2095e-01],
         [-1.0252e-03,  1.6699e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000259, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.3562721711978405
+++++++++++++: inf
4.919252248480916 seconds in game passed.
At 4.919252248480916 seconds, saving state-action tuples.
Action: tensor([[[ 7.5211e-04,  5.9018e-01],
         [-4.1185e-04,  3.2150e-01],
         [-2.9615e-04,  2.2102e-01],
         [-3.7695e-04,  1.6713e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.018834441410853
Current mitigation activation: 0
#############################
Total reward: 6.375106612608693
4.944252248853445 seconds in game passed.
Action: tensor([[[ 7.5211e-04,  5.9018e-01],
         [-4.1185e-04,  3.2150e-01],
         [-2.9615e-04,  2.2102e-01],
         [-3.7695e-04,  1.6713e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375106612608693
4.969252249225974 seconds in game passed.
Action: tensor([[[ 7.5211e-04,  5.9018e-01],
         [-4.1185e-04,  3.2150e-01],
         [-2.9615e-04,  2.2102e-01],
         [-3.7695e-04,  1.6713e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375106612608693
4.994252249598503 seconds in game passed.
Action: tensor([[[ 7.5211e-04,  5.9018e-01],
         [-4.1185e-04,  3.2150e-01],
         [-2.9615e-04,  2.2102e-01],
         [-3.7695e-04,  1.6713e-01]]], device='cuda:0',
       grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000429, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375106612608693
+++++++++++++: inf
5.019252249971032 seconds in game passed.
At 5.019252249971032 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3212],
         [0.0015, 0.2216],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.071044103099224
Current mitigation activation: 0
#############################
Total reward: 7.446150715707917
5.044252250343561 seconds in game passed.
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3212],
         [0.0015, 0.2216],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001638, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150715707917
5.06925225071609 seconds in game passed.
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3212],
         [0.0015, 0.2216],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150715707917
5.094252251088619 seconds in game passed.
Action: tensor([[[0.0018, 0.5882],
         [0.0010, 0.3212],
         [0.0015, 0.2216],
         [0.0017, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001630, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446150715707917
+++++++++++++: inf
5.119252251461148 seconds in game passed.
At 5.119252251461148 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2979e-03, 5.8972e-01],
         [9.0352e-04, 3.2203e-01],
         [7.7312e-04, 2.2273e-01],
         [4.0455e-04, 1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1199919984407805
Current mitigation activation: 0
#############################
Total reward: 8.566142714148697
5.144252251833677 seconds in game passed.
Action: tensor([[[1.2979e-03, 5.8972e-01],
         [9.0352e-04, 3.2203e-01],
         [7.7312e-04, 2.2273e-01],
         [4.0455e-04, 1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566142714148697
5.169252252206206 seconds in game passed.
Action: tensor([[[1.2979e-03, 5.8972e-01],
         [9.0352e-04, 3.2203e-01],
         [7.7312e-04, 2.2273e-01],
         [4.0455e-04, 1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566142714148697
5.194252252578735 seconds in game passed.
Action: tensor([[[1.2979e-03, 5.8972e-01],
         [9.0352e-04, 3.2203e-01],
         [7.7312e-04, 2.2273e-01],
         [4.0455e-04, 1.6871e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001380, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.566142714148697
+++++++++++++: inf
5.219252252951264 seconds in game passed.
At 5.219252252951264 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5848],
         [0.0019, 0.3191],
         [0.0019, 0.2208],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.166383060133097
Current mitigation activation: 0
#############################
Total reward: 9.732525774281793
5.244252253323793 seconds in game passed.
Action: tensor([[[0.0016, 0.5848],
         [0.0019, 0.3191],
         [0.0019, 0.2208],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732525774281793
5.269252253696322 seconds in game passed.
Action: tensor([[[0.0016, 0.5848],
         [0.0019, 0.3191],
         [0.0019, 0.2208],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002097, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732525774281793
5.2942522540688515 seconds in game passed.
Action: tensor([[[0.0016, 0.5848],
         [0.0019, 0.3191],
         [0.0019, 0.2208],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.732525774281793
+++++++++++++: inf
5.3192522544413805 seconds in game passed.
At 5.3192522544413805 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.5932],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001233, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.210746207576749
Current mitigation activation: 0
#############################
Total reward: 10.943271981858542
5.3442522548139095 seconds in game passed.
Action: tensor([[[0.0015, 0.5932],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943271981858542
5.369252255186439 seconds in game passed.
Action: tensor([[[0.0015, 0.5932],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001364, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943271981858542
5.394252255558968 seconds in game passed.
Action: tensor([[[0.0015, 0.5932],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001358, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943271981858542
+++++++++++++: inf
5.419252255931497 seconds in game passed.
At 5.419252255931497 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.5908],
         [0.0015, 0.3210],
         [0.0016, 0.2204],
         [0.0014, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001889, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2535049953398798
Current mitigation activation: 0
#############################
Total reward: 12.196776977198422
5.444252256304026 seconds in game passed.
Action: tensor([[[0.0015, 0.5908],
         [0.0015, 0.3210],
         [0.0016, 0.2204],
         [0.0014, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001789, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196776977198422
5.469252256676555 seconds in game passed.
Action: tensor([[[0.0015, 0.5908],
         [0.0015, 0.3210],
         [0.0016, 0.2204],
         [0.0014, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001780, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196776977198422
5.494252257049084 seconds in game passed.
Action: tensor([[[0.0015, 0.5908],
         [0.0015, 0.3210],
         [0.0016, 0.2204],
         [0.0014, 0.1665]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001770, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196776977198422
+++++++++++++: inf
5.519252257421613 seconds in game passed.
At 5.519252257421613 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0208e-03, 5.8992e-01],
         [6.4940e-04, 3.2039e-01],
         [6.2916e-04, 2.1994e-01],
         [3.0705e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2799436767097052
Current mitigation activation: 0
#############################
Total reward: 13.476720653908126
5.544252257794142 seconds in game passed.
Action: tensor([[[1.0208e-03, 5.8992e-01],
         [6.4940e-04, 3.2039e-01],
         [6.2916e-04, 2.1994e-01],
         [3.0705e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476720653908126
5.569252258166671 seconds in game passed.
Action: tensor([[[1.0208e-03, 5.8992e-01],
         [6.4940e-04, 3.2039e-01],
         [6.2916e-04, 2.1994e-01],
         [3.0705e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001050, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476720653908126
5.5942522585392 seconds in game passed.
Action: tensor([[[1.0208e-03, 5.8992e-01],
         [6.4940e-04, 3.2039e-01],
         [6.2916e-04, 2.1994e-01],
         [3.0705e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001038, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.476720653908126
+++++++++++++: inf
5.619252258911729 seconds in game passed.
At 5.619252258911729 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.8508e-04,  5.9114e-01],
         [-2.6072e-04,  3.2046e-01],
         [-4.4898e-04,  2.1968e-01],
         [-8.9557e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2784691484655326
Current mitigation activation: 0
#############################
Total reward: 14.755189802373659
5.644252259284258 seconds in game passed.
Action: tensor([[[ 4.8508e-04,  5.9114e-01],
         [-2.6072e-04,  3.2046e-01],
         [-4.4898e-04,  2.1968e-01],
         [-8.9557e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755189802373659
5.669252259656787 seconds in game passed.
Action: tensor([[[ 4.8508e-04,  5.9114e-01],
         [-2.6072e-04,  3.2046e-01],
         [-4.4898e-04,  2.1968e-01],
         [-8.9557e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755189802373659
5.694252260029316 seconds in game passed.
Action: tensor([[[ 4.8508e-04,  5.9114e-01],
         [-2.6072e-04,  3.2046e-01],
         [-4.4898e-04,  2.1968e-01],
         [-8.9557e-04,  1.6625e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000310, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755189802373659
+++++++++++++: inf
5.719252260401845 seconds in game passed.
At 5.719252260401845 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0025,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2767188998606855
Current mitigation activation: 0
#############################
Total reward: 16.031908702234343
5.744252260774374 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0025,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001204, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031908702234343
5.769252261146903 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0025,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031908702234343
5.794252261519432 seconds in game passed.
Action: tensor([[[-0.0008,  0.5877],
         [-0.0020,  0.3197],
         [-0.0025,  0.2193],
         [-0.0032,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031908702234343
+++++++++++++: inf
5.819252261891961 seconds in game passed.
At 5.819252261891961 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.5909],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001781, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2749366605899253
Current mitigation activation: 0
#############################
Total reward: 17.30684536282427
5.84425226226449 seconds in game passed.
Action: tensor([[[-0.0011,  0.5909],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001708, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.30684536282427
5.869252262637019 seconds in game passed.
Action: tensor([[[-0.0011,  0.5909],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001722, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.30684536282427
5.894252263009548 seconds in game passed.
Action: tensor([[[-0.0011,  0.5909],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001737, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.30684536282427
+++++++++++++: inf
5.919252263382077 seconds in game passed.
At 5.919252263382077 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.2944e-05,  5.8999e-01],
         [-9.1098e-04,  3.2110e-01],
         [-1.0715e-03,  2.2064e-01],
         [-1.3580e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000086, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2730962206534566
Current mitigation activation: 0
#############################
Total reward: 18.579941583477726
5.944252263754606 seconds in game passed.
Action: tensor([[[ 5.2944e-05,  5.8999e-01],
         [-9.1098e-04,  3.2110e-01],
         [-1.0715e-03,  2.2064e-01],
         [-1.3580e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579941583477726
5.969252264127135 seconds in game passed.
Action: tensor([[[ 5.2944e-05,  5.8999e-01],
         [-9.1098e-04,  3.2110e-01],
         [-1.0715e-03,  2.2064e-01],
         [-1.3580e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579941583477726
5.994252264499664 seconds in game passed.
Action: tensor([[[ 5.2944e-05,  5.8999e-01],
         [-9.1098e-04,  3.2110e-01],
         [-1.0715e-03,  2.2064e-01],
         [-1.3580e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000382, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579941583477726
+++++++++++++: inf
6.019252264872193 seconds in game passed.
At 6.019252264872193 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3749e-03,  5.9058e-01],
         [ 1.6841e-04,  3.2138e-01],
         [ 1.8916e-04,  2.2090e-01],
         [-8.9824e-05,  1.6695e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000918, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2883823508596943
Current mitigation activation: 0
#############################
Total reward: 19.868323934337422
6.044252265244722 seconds in game passed.
Action: tensor([[[ 1.3749e-03,  5.9058e-01],
         [ 1.6841e-04,  3.2138e-01],
         [ 1.8916e-04,  2.2090e-01],
         [-8.9824e-05,  1.6695e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868323934337422
6.069252265617251 seconds in game passed.
Action: tensor([[[ 1.3749e-03,  5.9058e-01],
         [ 1.6841e-04,  3.2138e-01],
         [ 1.8916e-04,  2.2090e-01],
         [-8.9824e-05,  1.6695e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000683, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868323934337422
6.09425226598978 seconds in game passed.
Action: tensor([[[ 1.3749e-03,  5.9058e-01],
         [ 1.6841e-04,  3.2138e-01],
         [ 1.8916e-04,  2.2090e-01],
         [-8.9824e-05,  1.6695e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868323934337422
+++++++++++++: inf
6.1192522663623095 seconds in game passed.
At 6.1192522663623095 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.5910],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3503231391342108
Current mitigation activation: 0
#############################
Total reward: 21.218647073471633
6.1442522667348385 seconds in game passed.
Action: tensor([[[0.0028, 0.5910],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002490, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218647073471633
6.1692522671073675 seconds in game passed.
Action: tensor([[[0.0028, 0.5910],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218647073471633
6.1942522674798965 seconds in game passed.
Action: tensor([[[0.0028, 0.5910],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.855678, steer=0.002524, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.218647073471633
+++++++++++++: inf
6.219252267852426 seconds in game passed.
At 6.219252267852426 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1215e-03,  5.9182e-01],
         [ 1.0204e-03,  3.2206e-01],
         [ 3.4568e-04,  2.2148e-01],
         [-8.1449e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.807087, steer=0.001297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4066993455282932
Current mitigation activation: 0
#############################
Total reward: 22.625346418999925
6.244252268224955 seconds in game passed.
Action: tensor([[[ 2.1215e-03,  5.9182e-01],
         [ 1.0204e-03,  3.2206e-01],
         [ 3.4568e-04,  2.2148e-01],
         [-8.1449e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.757571, steer=0.001496, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625346418999925
6.269252268597484 seconds in game passed.
Action: tensor([[[ 2.1215e-03,  5.9182e-01],
         [ 1.0204e-03,  3.2206e-01],
         [ 3.4568e-04,  2.2148e-01],
         [-8.1449e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.709642, steer=0.001492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625346418999925
6.294252268970013 seconds in game passed.
Action: tensor([[[ 2.1215e-03,  5.9182e-01],
         [ 1.0204e-03,  3.2206e-01],
         [ 3.4568e-04,  2.2148e-01],
         [-8.1449e-04,  1.6789e-01]]])
agent 0 action: VehicleControl(throttle=0.663443, steer=0.001487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625346418999925
+++++++++++++: inf
6.319252269342542 seconds in game passed.
At 6.319252269342542 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.8391e-04,  5.9655e-01],
         [-6.0871e-04,  3.2310e-01],
         [-1.5002e-03,  2.2112e-01],
         [-2.7865e-03,  1.6768e-01]]])
agent 0 action: VehicleControl(throttle=0.632535, steer=-0.000441, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4565140245413426
Current mitigation activation: 0
#############################
Total reward: 24.081860443541267
6.344252269715071 seconds in game passed.
Action: tensor([[[ 2.8391e-04,  5.9655e-01],
         [-6.0871e-04,  3.2310e-01],
         [-1.5002e-03,  2.2112e-01],
         [-2.7865e-03,  1.6768e-01]]])
agent 0 action: VehicleControl(throttle=0.589302, steer=-0.000138, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.081860443541267
6.3692522700876 seconds in game passed.
Action: tensor([[[ 2.8391e-04,  5.9655e-01],
         [-6.0871e-04,  3.2310e-01],
         [-1.5002e-03,  2.2112e-01],
         [-2.7865e-03,  1.6768e-01]]])
agent 0 action: VehicleControl(throttle=0.550010, steer=-0.000153, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.081860443541267
6.394252270460129 seconds in game passed.
Action: tensor([[[ 2.8391e-04,  5.9655e-01],
         [-6.0871e-04,  3.2310e-01],
         [-1.5002e-03,  2.2112e-01],
         [-2.7865e-03,  1.6768e-01]]])
agent 0 action: VehicleControl(throttle=0.513349, steer=-0.000169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.081860443541267
+++++++++++++: inf
6.419252270832658 seconds in game passed.
At 6.419252270832658 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.0324e-04,  5.9908e-01],
         [-1.0794e-03,  3.2454e-01],
         [-1.9846e-03,  2.2238e-01],
         [-3.4119e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.453721, steer=-0.000691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4973340444931278
Current mitigation activation: 0
#############################
Total reward: 25.579194488034396
6.444252271205187 seconds in game passed.
Action: tensor([[[-1.0324e-04,  5.9908e-01],
         [-1.0794e-03,  3.2454e-01],
         [-1.9846e-03,  2.2238e-01],
         [-3.4119e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.425481, steer=-0.000635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579194488034396
6.469252271577716 seconds in game passed.
Action: tensor([[[-1.0324e-04,  5.9908e-01],
         [-1.0794e-03,  3.2454e-01],
         [-1.9846e-03,  2.2238e-01],
         [-3.4119e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.397186, steer=-0.000661, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579194488034396
6.494252271950245 seconds in game passed.
Action: tensor([[[-1.0324e-04,  5.9908e-01],
         [-1.0794e-03,  3.2454e-01],
         [-1.9846e-03,  2.2238e-01],
         [-3.4119e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.371863, steer=-0.000687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579194488034396
+++++++++++++: inf
6.519252272322774 seconds in game passed.
At 6.519252272322774 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.378554, steer=-0.005939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.525141108484752
Current mitigation activation: 0
#############################
Total reward: 27.10433559651915
6.544252272695303 seconds in game passed.
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.356161, steer=-0.005147, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.10433559651915
6.569252273067832 seconds in game passed.
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.339670, steer=-0.005219, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.10433559651915
6.594252273440361 seconds in game passed.
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.325568, steer=-0.005291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.10433559651915
+++++++++++++: inf
6.61925227381289 seconds in game passed.
At 6.61925227381289 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0030,  0.6075],
         [-0.0051,  0.3265],
         [-0.0063,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.303268, steer=-0.004257, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5379391287629212
Current mitigation activation: 0
#############################
Total reward: 28.64227472528207
6.644252274185419 seconds in game passed.
Action: tensor([[[-0.0030,  0.6075],
         [-0.0051,  0.3265],
         [-0.0063,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.294704, steer=-0.004489, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64227472528207
6.669252274557948 seconds in game passed.
Action: tensor([[[-0.0030,  0.6075],
         [-0.0051,  0.3265],
         [-0.0063,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.287174, steer=-0.004541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64227472528207
6.694252274930477 seconds in game passed.
Action: tensor([[[-0.0030,  0.6075],
         [-0.0051,  0.3265],
         [-0.0063,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.281698, steer=-0.004592, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64227472528207
+++++++++++++: inf
6.719252275303006 seconds in game passed.
At 6.719252275303006 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261161, steer=-0.003421, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5376710179898283
Current mitigation activation: 0
#############################
Total reward: 30.1799457432719
6.744252275675535 seconds in game passed.
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.260937, steer=-0.003640, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.1799457432719
6.769252276048064 seconds in game passed.
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.260454, steer=-0.003660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.1799457432719
6.794252276420593 seconds in game passed.
Action: tensor([[[-0.0020,  0.5975],
         [-0.0040,  0.3240],
         [-0.0047,  0.2220],
         [-0.0052,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261481, steer=-0.003681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.1799457432719
+++++++++++++: inf
6.819252276793122 seconds in game passed.
At 6.819252276793122 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.5935],
         [-0.0029,  0.3227],
         [-0.0034,  0.2215],
         [-0.0040,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.267768, steer=-0.002419, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5276634652599441
Current mitigation activation: 0
#############################
Total reward: 31.707609208531846
6.844252277165651 seconds in game passed.
Action: tensor([[[-0.0009,  0.5935],
         [-0.0029,  0.3227],
         [-0.0034,  0.2215],
         [-0.0040,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.270770, steer=-0.002632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707609208531846
6.86925227753818 seconds in game passed.
Action: tensor([[[-0.0009,  0.5935],
         [-0.0029,  0.3227],
         [-0.0034,  0.2215],
         [-0.0040,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.275152, steer=-0.002633, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707609208531846
6.894252277910709 seconds in game passed.
Action: tensor([[[-0.0009,  0.5935],
         [-0.0029,  0.3227],
         [-0.0034,  0.2215],
         [-0.0040,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.280318, steer=-0.002635, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707609208531846
+++++++++++++: inf
6.919252278283238 seconds in game passed.
At 6.919252278283238 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0009,  0.6020],
         [-0.0015,  0.3244],
         [-0.0030,  0.2215],
         [-0.0049,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.316023, steer=-0.000896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5111760921163582
Current mitigation activation: 0
#############################
Total reward: 33.21878530064821
6.944252278655767 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6020],
         [-0.0015,  0.3244],
         [-0.0030,  0.2215],
         [-0.0049,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.319926, steer=-0.001187, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21878530064821
6.9692522790282965 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6020],
         [-0.0015,  0.3244],
         [-0.0030,  0.2215],
         [-0.0049,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.327643, steer=-0.001188, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21878530064821
6.9942522794008255 seconds in game passed.
Action: tensor([[[ 0.0009,  0.6020],
         [-0.0015,  0.3244],
         [-0.0030,  0.2215],
         [-0.0049,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.336072, steer=-0.001189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21878530064821
+++++++++++++: inf
7.0192522797733545 seconds in game passed.
At 7.0192522797733545 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7426e-04,  6.0074e-01],
         [-6.9056e-04,  3.2358e-01],
         [-1.4507e-03,  2.2127e-01],
         [-2.9035e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.363657, steer=-0.000868, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.491569773123298
Current mitigation activation: 0
#############################
Total reward: 34.7103550737715
7.044252280145884 seconds in game passed.
Action: tensor([[[ 2.7426e-04,  6.0074e-01],
         [-6.9056e-04,  3.2358e-01],
         [-1.4507e-03,  2.2127e-01],
         [-2.9035e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.371631, steer=-0.000934, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.7103550737715
7.069252280518413 seconds in game passed.
Action: tensor([[[ 2.7426e-04,  6.0074e-01],
         [-6.9056e-04,  3.2358e-01],
         [-1.4507e-03,  2.2127e-01],
         [-2.9035e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.381980, steer=-0.000945, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.7103550737715
7.094252280890942 seconds in game passed.
Action: tensor([[[ 2.7426e-04,  6.0074e-01],
         [-6.9056e-04,  3.2358e-01],
         [-1.4507e-03,  2.2127e-01],
         [-2.9035e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.392532, steer=-0.000956, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.7103550737715
+++++++++++++: inf
7.119252281263471 seconds in game passed.
At 7.119252281263471 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.8575e-03,  5.9964e-01],
         [-3.2500e-04,  3.2593e-01],
         [-1.2847e-03,  2.2419e-01],
         [-2.7498e-03,  1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.304103, steer=0.000314, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4721589345017763
Current mitigation activation: 0
#############################
Total reward: 36.18251400827328
7.144252281636 seconds in game passed.
Action: tensor([[[ 2.8575e-03,  5.9964e-01],
         [-3.2500e-04,  3.2593e-01],
         [-1.2847e-03,  2.2419e-01],
         [-2.7498e-03,  1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.324520, steer=0.000079, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18251400827328
7.169252282008529 seconds in game passed.
Action: tensor([[[ 2.8575e-03,  5.9964e-01],
         [-3.2500e-04,  3.2593e-01],
         [-1.2847e-03,  2.2419e-01],
         [-2.7498e-03,  1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.334794, steer=0.000059, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18251400827328
7.194252282381058 seconds in game passed.
Action: tensor([[[ 2.8575e-03,  5.9964e-01],
         [-3.2500e-04,  3.2593e-01],
         [-1.2847e-03,  2.2419e-01],
         [-2.7498e-03,  1.7028e-01]]])
agent 0 action: VehicleControl(throttle=0.346121, steer=0.000039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.18251400827328
+++++++++++++: inf
7.219252282753587 seconds in game passed.
At 7.219252282753587 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.2791e-04,  6.0146e-01],
         [-1.0368e-03,  3.2597e-01],
         [-1.5410e-03,  2.2289e-01],
         [-2.5704e-03,  1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.376476, steer=-0.001544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4548252284150625
Current mitigation activation: 0
#############################
Total reward: 37.63733923668834
7.244252283126116 seconds in game passed.
Action: tensor([[[ 2.2791e-04,  6.0146e-01],
         [-1.0368e-03,  3.2597e-01],
         [-1.5410e-03,  2.2289e-01],
         [-2.5704e-03,  1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.387278, steer=-0.001307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63733923668834
7.269252283498645 seconds in game passed.
Action: tensor([[[ 2.2791e-04,  6.0146e-01],
         [-1.0368e-03,  3.2597e-01],
         [-1.5410e-03,  2.2289e-01],
         [-2.5704e-03,  1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.400391, steer=-0.001331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63733923668834
7.294252283871174 seconds in game passed.
Action: tensor([[[ 2.2791e-04,  6.0146e-01],
         [-1.0368e-03,  3.2597e-01],
         [-1.5410e-03,  2.2289e-01],
         [-2.5704e-03,  1.6921e-01]]])
agent 0 action: VehicleControl(throttle=0.413602, steer=-0.001354, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63733923668834
+++++++++++++: inf
7.319252284243703 seconds in game passed.
At 7.319252284243703 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0012,  0.6046],
         [-0.0040,  0.3272],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.414562, steer=-0.004101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.438301530253162
Current mitigation activation: 0
#############################
Total reward: 39.075640766941504
7.344252284616232 seconds in game passed.
Action: tensor([[[-0.0012,  0.6046],
         [-0.0040,  0.3272],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.428739, steer=-0.003680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.075640766941504
7.369252284988761 seconds in game passed.
Action: tensor([[[-0.0012,  0.6046],
         [-0.0040,  0.3272],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.441513, steer=-0.003712, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.075640766941504
7.39425228536129 seconds in game passed.
Action: tensor([[[-0.0012,  0.6046],
         [-0.0040,  0.3272],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.454156, steer=-0.003744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.075640766941504
+++++++++++++: inf
7.419252285733819 seconds in game passed.
At 7.419252285733819 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6049],
         [-0.0051,  0.3264],
         [-0.0058,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.500932, steer=-0.004929, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4237767461411575
Current mitigation activation: 0
#############################
Total reward: 40.49941751308266
7.444252286106348 seconds in game passed.
Action: tensor([[[-0.0020,  0.6049],
         [-0.0051,  0.3264],
         [-0.0058,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.510040, steer=-0.004776, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49941751308266
7.469252286478877 seconds in game passed.
Action: tensor([[[-0.0020,  0.6049],
         [-0.0051,  0.3264],
         [-0.0058,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.522231, steer=-0.004815, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49941751308266
7.494252286851406 seconds in game passed.
Action: tensor([[[-0.0020,  0.6049],
         [-0.0051,  0.3264],
         [-0.0058,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.533545, steer=-0.004854, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49941751308266
+++++++++++++: inf
7.519252287223935 seconds in game passed.
At 7.519252287223935 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.3697e-04,  6.0015e-01],
         [-2.3127e-03,  3.2501e-01],
         [-2.9654e-03,  2.2219e-01],
         [-3.6725e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.543016, steer=-0.002141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4126452745782212
Current mitigation activation: 0
#############################
Total reward: 41.912062787660886
7.544252287596464 seconds in game passed.
Action: tensor([[[-4.3697e-04,  6.0015e-01],
         [-2.3127e-03,  3.2501e-01],
         [-2.9654e-03,  2.2219e-01],
         [-3.6725e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.550077, steer=-0.002543, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.912062787660886
7.569252287968993 seconds in game passed.
Action: tensor([[[-4.3697e-04,  6.0015e-01],
         [-2.3127e-03,  3.2501e-01],
         [-2.9654e-03,  2.2219e-01],
         [-3.6725e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.556545, steer=-0.002500, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.912062787660886
7.594252288341522 seconds in game passed.
Action: tensor([[[-4.3697e-04,  6.0015e-01],
         [-2.3127e-03,  3.2501e-01],
         [-2.9654e-03,  2.2219e-01],
         [-3.6725e-03,  1.6884e-01]]])
agent 0 action: VehicleControl(throttle=0.563046, steer=-0.002456, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.912062787660886
+++++++++++++: inf
7.619252288714051 seconds in game passed.
At 7.619252288714051 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0478e-02,  6.4033e-01],
         [-4.5478e-04,  3.4638e-01],
         [-2.2735e-03,  2.3690e-01],
         [-3.2049e-03,  1.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.235210, steer=0.003315, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4074847384052536
Current mitigation activation: 0
#############################
Total reward: 43.31954752606614
7.64425228908658 seconds in game passed.
Action: tensor([[[ 1.0478e-02,  6.4033e-01],
         [-4.5478e-04,  3.4638e-01],
         [-2.2735e-03,  2.3690e-01],
         [-3.2049e-03,  1.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.273613, steer=0.002459, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.31954752606614
7.669252289459109 seconds in game passed.
Action: tensor([[[ 1.0478e-02,  6.4033e-01],
         [-4.5478e-04,  3.4638e-01],
         [-2.2735e-03,  2.3690e-01],
         [-3.2049e-03,  1.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.276579, steer=0.002550, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.31954752606614
7.694252289831638 seconds in game passed.
Action: tensor([[[ 1.0478e-02,  6.4033e-01],
         [-4.5478e-04,  3.4638e-01],
         [-2.2735e-03,  2.3690e-01],
         [-3.2049e-03,  1.7978e-01]]])
agent 0 action: VehicleControl(throttle=0.279484, steer=0.002641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.31954752606614
+++++++++++++: inf
7.719252290204167 seconds in game passed.
At 7.719252290204167 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0167, 0.6444],
         [0.0040, 0.3508],
         [0.0024, 0.2408],
         [0.0014, 0.1831]]])
agent 0 action: VehicleControl(throttle=0.179350, steer=0.008507, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4053948993219083
Current mitigation activation: 0
#############################
Total reward: 44.72494242538804
7.744252290576696 seconds in game passed.
Action: tensor([[[0.0167, 0.6444],
         [0.0040, 0.3508],
         [0.0024, 0.2408],
         [0.0014, 0.1831]]])
agent 0 action: VehicleControl(throttle=0.192081, steer=0.007691, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72494242538804
7.769252290949225 seconds in game passed.
Action: tensor([[[0.0167, 0.6444],
         [0.0040, 0.3508],
         [0.0024, 0.2408],
         [0.0014, 0.1831]]])
agent 0 action: VehicleControl(throttle=0.193843, steer=0.007829, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72494242538804
7.7942522913217545 seconds in game passed.
Action: tensor([[[0.0167, 0.6444],
         [0.0040, 0.3508],
         [0.0024, 0.2408],
         [0.0014, 0.1831]]])
agent 0 action: VehicleControl(throttle=0.195438, steer=0.007968, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72494242538804
+++++++++++++: inf
7.8192522916942835 seconds in game passed.
At 7.8192522916942835 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.2326e-03, 5.9913e-01],
         [1.7198e-03, 3.2397e-01],
         [1.1421e-03, 2.2242e-01],
         [3.6287e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.662145, steer=0.001796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.403278903370253
Current mitigation activation: 0
#############################
Total reward: 46.12822132875829
7.8442522920668125 seconds in game passed.
Action: tensor([[[5.2326e-03, 5.9913e-01],
         [1.7198e-03, 3.2397e-01],
         [1.1421e-03, 2.2242e-01],
         [3.6287e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.619233, steer=0.002895, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12822132875829
7.8692522924393415 seconds in game passed.
Action: tensor([[[5.2326e-03, 5.9913e-01],
         [1.7198e-03, 3.2397e-01],
         [1.1421e-03, 2.2242e-01],
         [3.6287e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.625431, steer=0.002955, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12822132875829
7.894252292811871 seconds in game passed.
Action: tensor([[[5.2326e-03, 5.9913e-01],
         [1.7198e-03, 3.2397e-01],
         [1.1421e-03, 2.2242e-01],
         [3.6287e-04, 1.6908e-01]]])
agent 0 action: VehicleControl(throttle=0.631475, steer=0.003016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.12822132875829
+++++++++++++: inf
7.9192522931844 seconds in game passed.
At 7.9192522931844 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.8427e-03,  5.9395e-01],
         [-1.7513e-04,  3.2345e-01],
         [-7.4583e-04,  2.2261e-01],
         [-1.2961e-03,  1.6920e-01]]])
agent 0 action: VehicleControl(throttle=0.599411, steer=0.001115, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4011713913725043
Current mitigation activation: 0
#############################
Total reward: 47.5293927201308
7.944252293556929 seconds in game passed.
Action: tensor([[[ 3.8427e-03,  5.9395e-01],
         [-1.7513e-04,  3.2345e-01],
         [-7.4583e-04,  2.2261e-01],
         [-1.2961e-03,  1.6920e-01]]])
agent 0 action: VehicleControl(throttle=0.608351, steer=0.001457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.5293927201308
7.969252293929458 seconds in game passed.
Action: tensor([[[ 3.8427e-03,  5.9395e-01],
         [-1.7513e-04,  3.2345e-01],
         [-7.4583e-04,  2.2261e-01],
         [-1.2961e-03,  1.6920e-01]]])
agent 0 action: VehicleControl(throttle=0.613122, steer=0.001479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.5293927201308
7.994252294301987 seconds in game passed.
Action: tensor([[[ 3.8427e-03,  5.9395e-01],
         [-1.7513e-04,  3.2345e-01],
         [-7.4583e-04,  2.2261e-01],
         [-1.2961e-03,  1.6920e-01]]])
agent 0 action: VehicleControl(throttle=0.617718, steer=0.001501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.5293927201308
+++++++++++++: inf
8.019252294674516 seconds in game passed.
At 8.019252294674516 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.2480e-04,  5.9621e-01],
         [-7.8722e-04,  3.2306e-01],
         [-9.9401e-04,  2.2184e-01],
         [-1.2297e-03,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.661427, steer=-0.000339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3991044562480437
Current mitigation activation: 0
#############################
Total reward: 48.92849717637885
8.044252295047045 seconds in game passed.
Action: tensor([[[ 3.2480e-04,  5.9621e-01],
         [-7.8722e-04,  3.2306e-01],
         [-9.9401e-04,  2.2184e-01],
         [-1.2297e-03,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.661722, steer=-0.000033, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92849717637885
8.069252295419574 seconds in game passed.
Action: tensor([[[ 3.2480e-04,  5.9621e-01],
         [-7.8722e-04,  3.2306e-01],
         [-9.9401e-04,  2.2184e-01],
         [-1.2297e-03,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.645856, steer=-0.000033, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92849717637885
8.094252295792103 seconds in game passed.
Action: tensor([[[ 3.2480e-04,  5.9621e-01],
         [-7.8722e-04,  3.2306e-01],
         [-9.9401e-04,  2.2184e-01],
         [-1.2297e-03,  1.6850e-01]]])
agent 0 action: VehicleControl(throttle=0.633389, steer=-0.000034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92849717637885
+++++++++++++: inf
8.119252296164632 seconds in game passed.
At 8.119252296164632 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6077],
         [-0.0039,  0.3267],
         [-0.0040,  0.2226],
         [-0.0043,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.612683, steer=-0.003373, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4042242097364634
Current mitigation activation: 0
#############################
Total reward: 50.33272138611531
8.14425229653716 seconds in game passed.
Action: tensor([[[-0.0023,  0.6077],
         [-0.0039,  0.3267],
         [-0.0040,  0.2226],
         [-0.0043,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.602278, steer=-0.002873, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33272138611531
8.16925229690969 seconds in game passed.
Action: tensor([[[-0.0023,  0.6077],
         [-0.0039,  0.3267],
         [-0.0040,  0.2226],
         [-0.0043,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.591121, steer=-0.002921, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33272138611531
8.194252297282219 seconds in game passed.
Action: tensor([[[-0.0023,  0.6077],
         [-0.0039,  0.3267],
         [-0.0040,  0.2226],
         [-0.0043,  0.1688]]])
agent 0 action: VehicleControl(throttle=0.580235, steer=-0.002969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33272138611531
+++++++++++++: inf
8.219252297654748 seconds in game passed.
At 8.219252297654748 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0047,  0.6103],
         [-0.0066,  0.3279],
         [-0.0071,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.551044, steer=-0.005967, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4215642131698139
Current mitigation activation: 0
#############################
Total reward: 51.754285599285126
8.244252298027277 seconds in game passed.
Action: tensor([[[-0.0047,  0.6103],
         [-0.0066,  0.3279],
         [-0.0071,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.542279, steer=-0.005541, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.754285599285126
8.269252298399806 seconds in game passed.
Action: tensor([[[-0.0047,  0.6103],
         [-0.0066,  0.3279],
         [-0.0071,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.531954, steer=-0.005603, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.754285599285126
8.294252298772335 seconds in game passed.
Action: tensor([[[-0.0047,  0.6103],
         [-0.0066,  0.3279],
         [-0.0071,  0.2237],
         [-0.0074,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.522084, steer=-0.005666, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.754285599285126
+++++++++++++: inf
8.319252299144864 seconds in game passed.
At 8.319252299144864 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0019,  0.6000],
         [-0.0029,  0.3245],
         [-0.0032,  0.2226],
         [-0.0036,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.529591, steer=-0.001847, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4361458834107035
Current mitigation activation: 0
#############################
Total reward: 53.19043148269583
8.344252299517393 seconds in game passed.
Action: tensor([[[-0.0019,  0.6000],
         [-0.0029,  0.3245],
         [-0.0032,  0.2226],
         [-0.0036,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.519124, steer=-0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19043148269583
8.369252299889922 seconds in game passed.
Action: tensor([[[-0.0019,  0.6000],
         [-0.0029,  0.3245],
         [-0.0032,  0.2226],
         [-0.0036,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.510796, steer=-0.002472, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19043148269583
8.394252300262451 seconds in game passed.
Action: tensor([[[-0.0019,  0.6000],
         [-0.0029,  0.3245],
         [-0.0032,  0.2226],
         [-0.0036,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.502734, steer=-0.002467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19043148269583
+++++++++++++: inf
8.41925230063498 seconds in game passed.
At 8.41925230063498 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7249e-03,  6.0502e-01],
         [ 8.4386e-04,  3.2850e-01],
         [ 3.3119e-04,  2.2531e-01],
         [-4.8137e-04,  1.7144e-01]]])
agent 0 action: VehicleControl(throttle=0.400203, steer=0.002151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4473815578530043
Current mitigation activation: 0
#############################
Total reward: 54.637813040548835
8.44425230100751 seconds in game passed.
Action: tensor([[[ 2.7249e-03,  6.0502e-01],
         [ 8.4386e-04,  3.2850e-01],
         [ 3.3119e-04,  2.2531e-01],
         [-4.8137e-04,  1.7144e-01]]])
agent 0 action: VehicleControl(throttle=0.401326, steer=0.001457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.637813040548835
8.469252301380038 seconds in game passed.
Action: tensor([[[ 2.7249e-03,  6.0502e-01],
         [ 8.4386e-04,  3.2850e-01],
         [ 3.3119e-04,  2.2531e-01],
         [-4.8137e-04,  1.7144e-01]]])
agent 0 action: VehicleControl(throttle=0.393039, steer=0.001522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.637813040548835
8.494252301752567 seconds in game passed.
Action: tensor([[[ 2.7249e-03,  6.0502e-01],
         [ 8.4386e-04,  3.2850e-01],
         [ 3.3119e-04,  2.2531e-01],
         [-4.8137e-04,  1.7144e-01]]])
agent 0 action: VehicleControl(throttle=0.385880, steer=0.001586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.637813040548835
+++++++++++++: inf
8.519252302125096 seconds in game passed.
At 8.519252302125096 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0078, 0.6383],
         [0.0033, 0.3557],
         [0.0027, 0.2489],
         [0.0018, 0.1922]]])
agent 0 action: VehicleControl(throttle=0.139317, steer=0.005557, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4555861043481884
Current mitigation activation: 0
#############################
Total reward: 56.09339914489702
8.544252302497625 seconds in game passed.
Action: tensor([[[0.0078, 0.6383],
         [0.0033, 0.3557],
         [0.0027, 0.2489],
         [0.0018, 0.1922]]])
agent 0 action: VehicleControl(throttle=0.159751, steer=0.004986, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09339914489702
8.569252302870154 seconds in game passed.
Action: tensor([[[0.0078, 0.6383],
         [0.0033, 0.3557],
         [0.0027, 0.2489],
         [0.0018, 0.1922]]])
agent 0 action: VehicleControl(throttle=0.154267, steer=0.005063, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09339914489702
8.594252303242683 seconds in game passed.
Action: tensor([[[0.0078, 0.6383],
         [0.0033, 0.3557],
         [0.0027, 0.2489],
         [0.0018, 0.1922]]])
agent 0 action: VehicleControl(throttle=0.148762, steer=0.005141, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09339914489702
+++++++++++++: inf
8.619252303615212 seconds in game passed.
At 8.619252303615212 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0071, 0.6152],
         [0.0029, 0.3383],
         [0.0021, 0.2350],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.147417, steer=0.004522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4588722118124147
Current mitigation activation: 0
#############################
Total reward: 57.55227135670943
8.644252303987741 seconds in game passed.
Action: tensor([[[0.0071, 0.6152],
         [0.0029, 0.3383],
         [0.0021, 0.2350],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.150814, steer=0.004639, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55227135670943
8.66925230436027 seconds in game passed.
Action: tensor([[[0.0071, 0.6152],
         [0.0029, 0.3383],
         [0.0021, 0.2350],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.155351, steer=0.004651, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55227135670943
8.6942523047328 seconds in game passed.
Action: tensor([[[0.0071, 0.6152],
         [0.0029, 0.3383],
         [0.0021, 0.2350],
         [0.0012, 0.1812]]])
agent 0 action: VehicleControl(throttle=0.161086, steer=0.004663, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55227135670943
+++++++++++++: inf
8.719252305105329 seconds in game passed.
At 8.719252305105329 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.0912e-03,  6.1872e-01],
         [ 1.2954e-03,  3.3705e-01],
         [ 3.5151e-04,  2.3280e-01],
         [-5.1855e-04,  1.7872e-01]]])
agent 0 action: VehicleControl(throttle=0.248744, steer=0.003008, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4539163847213472
Current mitigation activation: 0
#############################
Total reward: 59.00618774143078
8.744252305477858 seconds in game passed.
Action: tensor([[[ 6.0912e-03,  6.1872e-01],
         [ 1.2954e-03,  3.3705e-01],
         [ 3.5151e-04,  2.3280e-01],
         [-5.1855e-04,  1.7872e-01]]])
agent 0 action: VehicleControl(throttle=0.249765, steer=0.003208, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.00618774143078
8.769252305850387 seconds in game passed.
Action: tensor([[[ 6.0912e-03,  6.1872e-01],
         [ 1.2954e-03,  3.3705e-01],
         [ 3.5151e-04,  2.3280e-01],
         [-5.1855e-04,  1.7872e-01]]])
agent 0 action: VehicleControl(throttle=0.259640, steer=0.003144, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.00618774143078
8.794252306222916 seconds in game passed.
Action: tensor([[[ 6.0912e-03,  6.1872e-01],
         [ 1.2954e-03,  3.3705e-01],
         [ 3.5151e-04,  2.3280e-01],
         [-5.1855e-04,  1.7872e-01]]])
agent 0 action: VehicleControl(throttle=0.269320, steer=0.003080, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.00618774143078
+++++++++++++: inf
8.819252306595445 seconds in game passed.
At 8.819252306595445 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0010,  0.6170],
         [-0.0020,  0.3341],
         [-0.0028,  0.2296],
         [-0.0037,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.359439, steer=-0.001408, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4434046263774565
Current mitigation activation: 0
#############################
Total reward: 60.449592367808236
8.844252306967974 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6170],
         [-0.0020,  0.3341],
         [-0.0028,  0.2296],
         [-0.0037,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.355542, steer=-0.000713, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.449592367808236
8.869252307340503 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6170],
         [-0.0020,  0.3341],
         [-0.0028,  0.2296],
         [-0.0037,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.360328, steer=-0.000759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.449592367808236
8.894252307713032 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6170],
         [-0.0020,  0.3341],
         [-0.0028,  0.2296],
         [-0.0037,  0.1758]]])
agent 0 action: VehicleControl(throttle=0.364237, steer=-0.000805, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.449592367808236
+++++++++++++: inf
8.91925230808556 seconds in game passed.
At 8.91925230808556 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0035,  0.6176],
         [-0.0056,  0.3311],
         [-0.0064,  0.2251],
         [-0.0074,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.480458, steer=-0.005240, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.432872232441822
Current mitigation activation: 0
#############################
Total reward: 61.88246460025006
8.94425230845809 seconds in game passed.
Action: tensor([[[-0.0035,  0.6176],
         [-0.0056,  0.3311],
         [-0.0064,  0.2251],
         [-0.0074,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.472865, steer=-0.004584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88246460025006
8.969252308830619 seconds in game passed.
Action: tensor([[[-0.0035,  0.6176],
         [-0.0056,  0.3311],
         [-0.0064,  0.2251],
         [-0.0074,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.476510, steer=-0.004655, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88246460025006
8.994252309203148 seconds in game passed.
Action: tensor([[[-0.0035,  0.6176],
         [-0.0056,  0.3311],
         [-0.0064,  0.2251],
         [-0.0074,  0.1715]]])
agent 0 action: VehicleControl(throttle=0.478778, steer=-0.004726, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88246460025006
+++++++++++++: inf
9.019252309575677 seconds in game passed.
At 9.019252309575677 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0078,  0.6241],
         [-0.0127,  0.3319],
         [-0.0145,  0.2248],
         [-0.0157,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.517784, steer=-0.011769, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4255001218476124
Current mitigation activation: 0
#############################
Total reward: 63.30796472209767
9.044252309948206 seconds in game passed.
Action: tensor([[[-0.0078,  0.6241],
         [-0.0127,  0.3319],
         [-0.0145,  0.2248],
         [-0.0157,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.514019, steer=-0.010740, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.30796472209767
9.069252310320735 seconds in game passed.
Action: tensor([[[-0.0078,  0.6241],
         [-0.0127,  0.3319],
         [-0.0145,  0.2248],
         [-0.0157,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.513749, steer=-0.010864, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.30796472209767
9.094252310693264 seconds in game passed.
Action: tensor([[[-0.0078,  0.6241],
         [-0.0127,  0.3319],
         [-0.0145,  0.2248],
         [-0.0157,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.512625, steer=-0.010988, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.30796472209767
+++++++++++++: inf
9.119252311065793 seconds in game passed.
At 9.119252311065793 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0027,  0.6126],
         [-0.0046,  0.3289],
         [-0.0049,  0.2240],
         [-0.0048,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.500903, steer=-0.003027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4229324946563064
Current mitigation activation: 0
#############################
Total reward: 64.73089721675397
9.144252311438322 seconds in game passed.
Action: tensor([[[-0.0027,  0.6126],
         [-0.0046,  0.3289],
         [-0.0049,  0.2240],
         [-0.0048,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.499812, steer=-0.004362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73089721675397
9.169252311810851 seconds in game passed.
Action: tensor([[[-0.0027,  0.6126],
         [-0.0046,  0.3289],
         [-0.0049,  0.2240],
         [-0.0048,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.497271, steer=-0.004369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73089721675397
9.19425231218338 seconds in game passed.
Action: tensor([[[-0.0027,  0.6126],
         [-0.0046,  0.3289],
         [-0.0049,  0.2240],
         [-0.0048,  0.1707]]])
agent 0 action: VehicleControl(throttle=0.494575, steer=-0.004376, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73089721675397
+++++++++++++: inf
9.21925231255591 seconds in game passed.
At 9.21925231255591 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-3.8225e-04,  6.0506e-01],
         [-2.1439e-03,  3.2624e-01],
         [-2.7542e-03,  2.2281e-01],
         [-3.1189e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.508443, steer=-0.001649, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4244142059147256
Current mitigation activation: 0
#############################
Total reward: 66.1553114226687
9.244252312928438 seconds in game passed.
Action: tensor([[[-3.8225e-04,  6.0506e-01],
         [-2.1439e-03,  3.2624e-01],
         [-2.7542e-03,  2.2281e-01],
         [-3.1189e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.504194, steer=-0.002044, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.1553114226687
9.269252313300967 seconds in game passed.
Action: tensor([[[-3.8225e-04,  6.0506e-01],
         [-2.1439e-03,  3.2624e-01],
         [-2.7542e-03,  2.2281e-01],
         [-3.1189e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.501613, steer=-0.001992, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.1553114226687
9.294252313673496 seconds in game passed.
Action: tensor([[[-3.8225e-04,  6.0506e-01],
         [-2.1439e-03,  3.2624e-01],
         [-2.7542e-03,  2.2281e-01],
         [-3.1189e-03,  1.6915e-01]]])
agent 0 action: VehicleControl(throttle=0.498898, steer=-0.001940, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.1553114226687
+++++++++++++: inf
9.319252314046025 seconds in game passed.
At 9.319252314046025 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9551e-03,  6.2033e-01],
         [ 8.2108e-04,  3.3094e-01],
         [ 2.3683e-04,  2.2579e-01],
         [-3.3203e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.484628, steer=0.001584, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4277775879198225
Current mitigation activation: 0
#############################
Total reward: 67.58308901058852
9.344252314418554 seconds in game passed.
Action: tensor([[[ 2.9551e-03,  6.2033e-01],
         [ 8.2108e-04,  3.3094e-01],
         [ 2.3683e-04,  2.2579e-01],
         [-3.3203e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.482717, steer=0.001053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.58308901058852
9.369252314791083 seconds in game passed.
Action: tensor([[[ 2.9551e-03,  6.2033e-01],
         [ 8.2108e-04,  3.3094e-01],
         [ 2.3683e-04,  2.2579e-01],
         [-3.3203e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.479660, steer=0.001101, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.58308901058852
9.394252315163612 seconds in game passed.
Action: tensor([[[ 2.9551e-03,  6.2033e-01],
         [ 8.2108e-04,  3.3094e-01],
         [ 2.3683e-04,  2.2579e-01],
         [-3.3203e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.476725, steer=0.001149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.58308901058852
+++++++++++++: inf
9.419252315536141 seconds in game passed.
At 9.419252315536141 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[8.2217e-04, 6.0729e-01],
         [4.1209e-04, 3.2586e-01],
         [4.0893e-04, 2.2227e-01],
         [1.4013e-04, 1.6866e-01]]])
agent 0 action: VehicleControl(throttle=0.523967, steer=0.000002, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.431923938132771
Current mitigation activation: 0
#############################
Total reward: 69.01501294872129
9.44425231590867 seconds in game passed.
Action: tensor([[[8.2217e-04, 6.0729e-01],
         [4.1209e-04, 3.2586e-01],
         [4.0893e-04, 2.2227e-01],
         [1.4013e-04, 1.6866e-01]]])
agent 0 action: VehicleControl(throttle=0.517678, steer=0.000181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.01501294872129
9.4692523162812 seconds in game passed.
Action: tensor([[[8.2217e-04, 6.0729e-01],
         [4.1209e-04, 3.2586e-01],
         [4.0893e-04, 2.2227e-01],
         [1.4013e-04, 1.6866e-01]]])
agent 0 action: VehicleControl(throttle=0.516573, steer=0.000169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.01501294872129
9.494252316653728 seconds in game passed.
Action: tensor([[[8.2217e-04, 6.0729e-01],
         [4.1209e-04, 3.2586e-01],
         [4.0893e-04, 2.2227e-01],
         [1.4013e-04, 1.6866e-01]]])
agent 0 action: VehicleControl(throttle=0.515157, steer=0.000158, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.01501294872129
+++++++++++++: inf
9.519252317026258 seconds in game passed.
At 9.519252317026258 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.6157],
         [0.0015, 0.3275],
         [0.0019, 0.2227],
         [0.0021, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.544958, steer=0.001448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4361168176279484
Current mitigation activation: 0
#############################
Total reward: 70.45112976634924
9.544252317398787 seconds in game passed.
Action: tensor([[[0.0023, 0.6157],
         [0.0015, 0.3275],
         [0.0019, 0.2227],
         [0.0021, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.543094, steer=0.001189, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.45112976634924
9.569252317771316 seconds in game passed.
Action: tensor([[[0.0023, 0.6157],
         [0.0015, 0.3275],
         [0.0019, 0.2227],
         [0.0021, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.544036, steer=0.001151, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.45112976634924
9.594252318143845 seconds in game passed.
Action: tensor([[[0.0023, 0.6157],
         [0.0015, 0.3275],
         [0.0019, 0.2227],
         [0.0021, 0.1686]]])
agent 0 action: VehicleControl(throttle=0.544570, steer=0.001113, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.45112976634924
+++++++++++++: inf
9.619252318516374 seconds in game passed.
At 9.619252318516374 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[4.2205e-04, 5.9693e-01],
         [6.2886e-04, 3.2249e-01],
         [9.8415e-04, 2.2076e-01],
         [1.0168e-03, 1.6748e-01]]])
agent 0 action: VehicleControl(throttle=0.529827, steer=-0.000259, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4409617623281434
Current mitigation activation: 0
#############################
Total reward: 71.89209152867738
9.644252318888903 seconds in game passed.
Action: tensor([[[4.2205e-04, 5.9693e-01],
         [6.2886e-04, 3.2249e-01],
         [9.8415e-04, 2.2076e-01],
         [1.0168e-03, 1.6748e-01]]])
agent 0 action: VehicleControl(throttle=0.531129, steer=-0.000083, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.89209152867738
9.669252319261432 seconds in game passed.
Action: tensor([[[4.2205e-04, 5.9693e-01],
         [6.2886e-04, 3.2249e-01],
         [9.8415e-04, 2.2076e-01],
         [1.0168e-03, 1.6748e-01]]])
agent 0 action: VehicleControl(throttle=0.530566, steer=-0.000128, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.89209152867738
9.69425231963396 seconds in game passed.
Action: tensor([[[4.2205e-04, 5.9693e-01],
         [6.2886e-04, 3.2249e-01],
         [9.8415e-04, 2.2076e-01],
         [1.0168e-03, 1.6748e-01]]])
agent 0 action: VehicleControl(throttle=0.529825, steer=-0.000173, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.89209152867738
+++++++++++++: inf
9.71925232000649 seconds in game passed.
At 9.71925232000649 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.8955e-05,  6.0642e-01],
         [-5.4745e-04,  3.2731e-01],
         [-2.0257e-04,  2.2408e-01],
         [ 2.2270e-05,  1.7073e-01]]])
agent 0 action: VehicleControl(throttle=0.451632, steer=-0.001210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4469174173075545
Current mitigation activation: 0
#############################
Total reward: 73.33900894598494
9.744252320379019 seconds in game passed.
Action: tensor([[[ 6.8955e-05,  6.0642e-01],
         [-5.4745e-04,  3.2731e-01],
         [-2.0257e-04,  2.2408e-01],
         [ 2.2270e-05,  1.7073e-01]]])
agent 0 action: VehicleControl(throttle=0.456857, steer=-0.001082, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.33900894598494
9.769252320751548 seconds in game passed.
Action: tensor([[[ 6.8955e-05,  6.0642e-01],
         [-5.4745e-04,  3.2731e-01],
         [-2.0257e-04,  2.2408e-01],
         [ 2.2270e-05,  1.7073e-01]]])
agent 0 action: VehicleControl(throttle=0.454022, steer=-0.001121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.33900894598494
9.794252321124077 seconds in game passed.
Action: tensor([[[ 6.8955e-05,  6.0642e-01],
         [-5.4745e-04,  3.2731e-01],
         [-2.0257e-04,  2.2408e-01],
         [ 2.2270e-05,  1.7073e-01]]])
agent 0 action: VehicleControl(throttle=0.451689, steer=-0.001160, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.33900894598494
+++++++++++++: inf
9.819252321496606 seconds in game passed.
At 9.819252321496606 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0013, 0.5979],
         [0.0013, 0.3225],
         [0.0021, 0.2207],
         [0.0028, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.533413, steer=0.000728, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4531308669974363
Current mitigation activation: 0
#############################
Total reward: 74.79213981298238
9.844252321869135 seconds in game passed.
Action: tensor([[[0.0013, 0.5979],
         [0.0013, 0.3225],
         [0.0021, 0.2207],
         [0.0028, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.522660, steer=0.000445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79213981298238
9.869252322241664 seconds in game passed.
Action: tensor([[[0.0013, 0.5979],
         [0.0013, 0.3225],
         [0.0021, 0.2207],
         [0.0028, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.520889, steer=0.000471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79213981298238
9.894252322614193 seconds in game passed.
Action: tensor([[[0.0013, 0.5979],
         [0.0013, 0.3225],
         [0.0021, 0.2207],
         [0.0028, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.518592, steer=0.000498, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79213981298238
+++++++++++++: inf
9.919252322986722 seconds in game passed.
At 9.919252322986722 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.5973],
         [0.0035, 0.3230],
         [0.0044, 0.2212],
         [0.0047, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.493179, steer=0.002660, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4578552797350952
Current mitigation activation: 0
#############################
Total reward: 76.24999509271748
9.944252323359251 seconds in game passed.
Action: tensor([[[0.0025, 0.5973],
         [0.0035, 0.3230],
         [0.0044, 0.2212],
         [0.0047, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.491114, steer=0.002409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.24999509271748
9.96925232373178 seconds in game passed.
Action: tensor([[[0.0025, 0.5973],
         [0.0035, 0.3230],
         [0.0044, 0.2212],
         [0.0047, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.486630, steer=0.002503, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.24999509271748
9.994252324104309 seconds in game passed.
Action: tensor([[[0.0025, 0.5973],
         [0.0035, 0.3230],
         [0.0044, 0.2212],
         [0.0047, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.482189, steer=0.002597, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.24999509271748
+++++++++++++: inf
10.019252324476838 seconds in game passed.
At 10.019252324476838 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.6121],
         [0.0018, 0.3305],
         [0.0022, 0.2264],
         [0.0021, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.357212, steer=0.001285, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4626049809954824
Current mitigation activation: 0
#############################
Total reward: 77.71260007371296
10.044252324849367 seconds in game passed.
Action: tensor([[[0.0020, 0.6121],
         [0.0018, 0.3305],
         [0.0022, 0.2264],
         [0.0021, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.363875, steer=0.001679, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.71260007371296
10.069252325221896 seconds in game passed.
Action: tensor([[[0.0020, 0.6121],
         [0.0018, 0.3305],
         [0.0022, 0.2264],
         [0.0021, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.358250, steer=0.001830, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.71260007371296
10.094252325594425 seconds in game passed.
Action: tensor([[[0.0020, 0.6121],
         [0.0018, 0.3305],
         [0.0022, 0.2264],
         [0.0021, 0.1725]]])
agent 0 action: VehicleControl(throttle=0.353813, steer=0.001980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.71260007371296
+++++++++++++: inf
10.119252325966954 seconds in game passed.
At 10.119252325966954 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0036, 0.6121],
         [0.0017, 0.3272],
         [0.0018, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.472521, steer=0.002614, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4667948250860419
Current mitigation activation: 0
#############################
Total reward: 79.179394898799
10.144252326339483 seconds in game passed.
Action: tensor([[[0.0036, 0.6121],
         [0.0017, 0.3272],
         [0.0018, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.458231, steer=0.002594, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.179394898799
10.169252326712012 seconds in game passed.
Action: tensor([[[0.0036, 0.6121],
         [0.0017, 0.3272],
         [0.0018, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.457358, steer=0.002667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.179394898799
10.194252327084541 seconds in game passed.
Action: tensor([[[0.0036, 0.6121],
         [0.0017, 0.3272],
         [0.0018, 0.2239],
         [0.0018, 0.1701]]])
agent 0 action: VehicleControl(throttle=0.456085, steer=0.002741, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.179394898799
+++++++++++++: inf
10.21925232745707 seconds in game passed.
At 10.21925232745707 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0022, 0.6132],
         [0.0008, 0.3255],
         [0.0009, 0.2217],
         [0.0007, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.526768, steer=0.001528, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4678658718478426
Current mitigation activation: 0
#############################
Total reward: 80.64726077064685
10.2442523278296 seconds in game passed.
Action: tensor([[[0.0022, 0.6132],
         [0.0008, 0.3255],
         [0.0009, 0.2217],
         [0.0007, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.518118, steer=0.001768, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64726077064685
10.269252328202128 seconds in game passed.
Action: tensor([[[0.0022, 0.6132],
         [0.0008, 0.3255],
         [0.0009, 0.2217],
         [0.0007, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.516814, steer=0.001801, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64726077064685
10.294252328574657 seconds in game passed.
Action: tensor([[[0.0022, 0.6132],
         [0.0008, 0.3255],
         [0.0009, 0.2217],
         [0.0007, 0.1679]]])
agent 0 action: VehicleControl(throttle=0.514818, steer=0.001834, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64726077064685
+++++++++++++: inf
10.319252328947186 seconds in game passed.
At 10.319252328947186 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.5586e-03, 6.0772e-01],
         [3.8489e-04, 3.2474e-01],
         [5.6162e-04, 2.2180e-01],
         [4.2041e-04, 1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.483981, steer=0.001306, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4686722889379642
Current mitigation activation: 0
#############################
Total reward: 82.11593305958482
10.344252329319715 seconds in game passed.
Action: tensor([[[1.5586e-03, 6.0772e-01],
         [3.8489e-04, 3.2474e-01],
         [5.6162e-04, 2.2180e-01],
         [4.2041e-04, 1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.484003, steer=0.001384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.11593305958482
10.369252329692245 seconds in game passed.
Action: tensor([[[1.5586e-03, 6.0772e-01],
         [3.8489e-04, 3.2474e-01],
         [5.6162e-04, 2.2180e-01],
         [4.2041e-04, 1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.480794, steer=0.001375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.11593305958482
10.394252330064774 seconds in game passed.
Action: tensor([[[1.5586e-03, 6.0772e-01],
         [3.8489e-04, 3.2474e-01],
         [5.6162e-04, 2.2180e-01],
         [4.2041e-04, 1.6804e-01]]])
agent 0 action: VehicleControl(throttle=0.477615, steer=0.001366, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.11593305958482
+++++++++++++: inf
10.419252330437303 seconds in game passed.
At 10.419252330437303 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.9443e-04, 6.1782e-01],
         [2.1716e-04, 3.2708e-01],
         [5.6276e-04, 2.2355e-01],
         [3.1584e-04, 1.7021e-01]]])
agent 0 action: VehicleControl(throttle=0.493029, steer=0.000705, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.471438652388684
Current mitigation activation: 0
#############################
Total reward: 83.5873717119735
10.444252330809832 seconds in game passed.
Action: tensor([[[1.9443e-04, 6.1782e-01],
         [2.1716e-04, 3.2708e-01],
         [5.6276e-04, 2.2355e-01],
         [3.1584e-04, 1.7021e-01]]])
agent 0 action: VehicleControl(throttle=0.487532, steer=0.000810, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.5873717119735
10.46925233118236 seconds in game passed.
Action: tensor([[[1.9443e-04, 6.1782e-01],
         [2.1716e-04, 3.2708e-01],
         [5.6276e-04, 2.2355e-01],
         [3.1584e-04, 1.7021e-01]]])
agent 0 action: VehicleControl(throttle=0.484068, steer=0.000806, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.5873717119735
10.49425233155489 seconds in game passed.
Action: tensor([[[1.9443e-04, 6.1782e-01],
         [2.1716e-04, 3.2708e-01],
         [5.6276e-04, 2.2355e-01],
         [3.1584e-04, 1.7021e-01]]])
agent 0 action: VehicleControl(throttle=0.480525, steer=0.000802, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.5873717119735
+++++++++++++: inf
10.519252331927419 seconds in game passed.
At 10.519252331927419 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.6210],
         [-0.0015,  0.3263],
         [-0.0017,  0.2219],
         [-0.0025,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.537915, steer=-0.000901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4748217873174643
Current mitigation activation: 0
#############################
Total reward: 85.06219349929097
10.544252332299948 seconds in game passed.
Action: tensor([[[-0.0009,  0.6210],
         [-0.0015,  0.3263],
         [-0.0017,  0.2219],
         [-0.0025,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.528274, steer=-0.000659, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.06219349929097
10.569252332672477 seconds in game passed.
Action: tensor([[[-0.0009,  0.6210],
         [-0.0015,  0.3263],
         [-0.0017,  0.2219],
         [-0.0025,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.525016, steer=-0.000694, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.06219349929097
10.594252333045006 seconds in game passed.
Action: tensor([[[-0.0009,  0.6210],
         [-0.0015,  0.3263],
         [-0.0017,  0.2219],
         [-0.0025,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.521315, steer=-0.000729, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.06219349929097
+++++++++++++: inf
10.619252333417535 seconds in game passed.
At 10.619252333417535 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-6.7548e-04,  6.2480e-01],
         [-1.7375e-04,  3.2774e-01],
         [ 1.0907e-04,  2.2300e-01],
         [-4.5674e-04,  1.6959e-01]]])
agent 0 action: VehicleControl(throttle=0.503016, steer=0.000303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4784178759120117
Current mitigation activation: 0
#############################
Total reward: 86.54061137520299
10.644252333790064 seconds in game passed.
Action: tensor([[[-6.7548e-04,  6.2480e-01],
         [-1.7375e-04,  3.2774e-01],
         [ 1.0907e-04,  2.2300e-01],
         [-4.5674e-04,  1.6959e-01]]])
agent 0 action: VehicleControl(throttle=0.500452, steer=0.000119, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.54061137520299
10.669252334162593 seconds in game passed.
Action: tensor([[[-6.7548e-04,  6.2480e-01],
         [-1.7375e-04,  3.2774e-01],
         [ 1.0907e-04,  2.2300e-01],
         [-4.5674e-04,  1.6959e-01]]])
agent 0 action: VehicleControl(throttle=0.496282, steer=0.000108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.54061137520299
10.694252334535122 seconds in game passed.
Action: tensor([[[-6.7548e-04,  6.2480e-01],
         [-1.7375e-04,  3.2774e-01],
         [ 1.0907e-04,  2.2300e-01],
         [-4.5674e-04,  1.6959e-01]]])
agent 0 action: VehicleControl(throttle=0.492185, steer=0.000098, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.54061137520299
+++++++++++++: inf
10.719252334907651 seconds in game passed.
At 10.719252334907651 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.6101],
         [-0.0014,  0.3242],
         [-0.0010,  0.2221],
         [-0.0012,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.466775, steer=-0.001007, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4829196635000925
Current mitigation activation: 0
#############################
Total reward: 88.02353103870308
10.74425233528018 seconds in game passed.
Action: tensor([[[-0.0011,  0.6101],
         [-0.0014,  0.3242],
         [-0.0010,  0.2221],
         [-0.0012,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.465815, steer=-0.000837, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.02353103870308
10.769252335652709 seconds in game passed.
Action: tensor([[[-0.0011,  0.6101],
         [-0.0014,  0.3242],
         [-0.0010,  0.2221],
         [-0.0012,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.462689, steer=-0.000848, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.02353103870308
10.794252336025238 seconds in game passed.
Action: tensor([[[-0.0011,  0.6101],
         [-0.0014,  0.3242],
         [-0.0010,  0.2221],
         [-0.0012,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.459882, steer=-0.000860, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.02353103870308
+++++++++++++: inf
10.819252336397767 seconds in game passed.
At 10.819252336397767 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0022,  0.6168],
         [-0.0025,  0.3268],
         [-0.0026,  0.2230],
         [-0.0035,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.429690, steer=-0.002145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4874351389280882
Current mitigation activation: 0
#############################
Total reward: 89.51096617763118
10.844252336770296 seconds in game passed.
Action: tensor([[[-0.0022,  0.6168],
         [-0.0025,  0.3268],
         [-0.0026,  0.2230],
         [-0.0035,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.428987, steer=-0.001982, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.51096617763118
10.869252337142825 seconds in game passed.
Action: tensor([[[-0.0022,  0.6168],
         [-0.0025,  0.3268],
         [-0.0026,  0.2230],
         [-0.0035,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.425766, steer=-0.002026, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.51096617763118
10.894252337515354 seconds in game passed.
Action: tensor([[[-0.0022,  0.6168],
         [-0.0025,  0.3268],
         [-0.0026,  0.2230],
         [-0.0035,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.423006, steer=-0.002070, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.51096617763118
+++++++++++++: inf
10.919252337887883 seconds in game passed.
At 10.919252337887883 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0032, 0.6212],
         [0.0040, 0.3274],
         [0.0048, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.445605, steer=0.004857, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4908495269163535
Current mitigation activation: 0
#############################
Total reward: 91.00181570454752
10.944252338260412 seconds in game passed.
Action: tensor([[[0.0032, 0.6212],
         [0.0040, 0.3274],
         [0.0048, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.441472, steer=0.003710, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 91.00181570454752
10.969252338632941 seconds in game passed.
Action: tensor([[[0.0032, 0.6212],
         [0.0040, 0.3274],
         [0.0048, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.440260, steer=0.003717, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 91.00181570454752
10.99425233900547 seconds in game passed.
Action: tensor([[[0.0032, 0.6212],
         [0.0040, 0.3274],
         [0.0048, 0.2232],
         [0.0047, 0.1698]]])
agent 0 action: VehicleControl(throttle=0.439094, steer=0.003723, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 91.00181570454752
+++++++++++++: inf
11.019252339378 seconds in game passed.
At 11.019252339378 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0040, 0.6226],
         [0.0045, 0.3355],
         [0.0051, 0.2323],
         [0.0050, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.162941, steer=0.004409, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4926766477251685
Current mitigation activation: 0
#############################
Total reward: 92.49449235227269
11.044252339750528 seconds in game passed.
Action: tensor([[[0.0040, 0.6226],
         [0.0045, 0.3355],
         [0.0051, 0.2323],
         [0.0050, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.189579, steer=0.004328, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.49449235227269
11.069252340123057 seconds in game passed.
Action: tensor([[[0.0040, 0.6226],
         [0.0045, 0.3355],
         [0.0051, 0.2323],
         [0.0050, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.187390, steer=0.004357, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.49449235227269
11.094252340495586 seconds in game passed.
Action: tensor([[[0.0040, 0.6226],
         [0.0045, 0.3355],
         [0.0051, 0.2323],
         [0.0050, 0.1786]]])
agent 0 action: VehicleControl(throttle=0.187383, steer=0.004385, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.49449235227269
+++++++++++++: inf
11.119252340868115 seconds in game passed.
At 11.119252340868115 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[6.4000e-05, 6.5169e-01],
         [8.9907e-03, 3.9815e-01],
         [1.3520e-02, 2.9515e-01],
         [1.6429e-02, 2.3561e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005958, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4931534508508097
Current mitigation activation: 0
#############################
Total reward: 93.9876458031235
11.144252341240644 seconds in game passed.
Action: tensor([[[6.4000e-05, 6.5169e-01],
         [8.9907e-03, 3.9815e-01],
         [1.3520e-02, 2.9515e-01],
         [1.6429e-02, 2.3561e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005741, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.9876458031235
11.169252341613173 seconds in game passed.
Action: tensor([[[6.4000e-05, 6.5169e-01],
         [8.9907e-03, 3.9815e-01],
         [1.3520e-02, 2.9515e-01],
         [1.6429e-02, 2.3561e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005780, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.9876458031235
11.194252341985703 seconds in game passed.
Action: tensor([[[6.4000e-05, 6.5169e-01],
         [8.9907e-03, 3.9815e-01],
         [1.3520e-02, 2.9515e-01],
         [1.6429e-02, 2.3561e-01]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.005819, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.9876458031235
+++++++++++++: inf
11.219252342358232 seconds in game passed.
At 11.219252342358232 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0030, 0.6937],
         [0.0022, 0.4257],
         [0.0030, 0.3148],
         [0.0047, 0.2499]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002376, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4843283908258718
Current mitigation activation: 0
#############################
Total reward: 95.47197419394936
11.24425234273076 seconds in game passed.
Action: tensor([[[0.0030, 0.6937],
         [0.0022, 0.4257],
         [0.0030, 0.3148],
         [0.0047, 0.2499]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002968, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.47197419394936
11.26925234310329 seconds in game passed.
Action: tensor([[[0.0030, 0.6937],
         [0.0022, 0.4257],
         [0.0030, 0.3148],
         [0.0047, 0.2499]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.002984, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.47197419394936
11.294252343475819 seconds in game passed.
Action: tensor([[[0.0030, 0.6937],
         [0.0022, 0.4257],
         [0.0030, 0.3148],
         [0.0047, 0.2499]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003000, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.47197419394936
+++++++++++++: inf
11.319252343848348 seconds in game passed.
At 11.319252343848348 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0053, 0.7916],
         [0.0077, 0.4702],
         [0.0070, 0.3333],
         [0.0066, 0.2497]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.008049, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4319571296926312
Current mitigation activation: 0
#############################
Total reward: 96.903931323642
11.344252344220877 seconds in game passed.
Action: tensor([[[0.0053, 0.7916],
         [0.0077, 0.4702],
         [0.0070, 0.3333],
         [0.0066, 0.2497]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.007292, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 96.903931323642
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [91mFAILURE[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-15 00:44:17 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-15 00:44:38 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 20.93s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 9.78s               │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.467               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ FAILURE │ 46.64 % │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ FAILURE │ 1 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 96.9, average_reward: 96.903931323642 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00008/fi_ghost_cutin_data
