New episode load state dicts.

creating control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003957-fi_ghost_cutin_logs-single_ctl.csv

creating ego trajectory dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003957-fi_ghost_cutin_logs-single_traj.csv

creating cvip dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003957-fi_ghost_cutin_logs-single_cvip.csv

creating network points dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003957-fi_ghost_cutin_logs-single_points.csv

creating pid delta dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003957-fi_ghost_cutin_logs-single_piddelta.csv

creating unclipped control dump file at: //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_logs/routes_fi_route_highway-1115_003957-fi_ghost_cutin_logs-single_unclip_ctl.csv

done creating dump files.
Positional uncertainty is not enabled for this run.
Prediction type: CVCTR
Prepare for stepping

[1m========= Preparing RouteScenario_0 (repetition 0) =========
> Setting up the agent[0m
Loading the world
Save to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_data/route_highway.xml_fi_ghost_cutin.json.pkl
Exclude list: [17, 23]
Location(x=192.362411, y=-86.262680, z=0.700000) Rotation(pitch=0.000000, yaw=89.330902, roll=0.000000)
Base scenario time out after: 36.333333333333336
Replacing key distance_same_lane's value from 15 to 10.
Replacing key distance_lane_change's value from 11 to 6.
Replacing key speed_lane_change's value from 13.5 to 13.
Config for GhostCutIn scenario is {'first_vehicle_location': 0, 'first_vehicle_speed': 200, 'event_trigger_distance': 4, 'distance_lane_change': 6, 'speed_lane_change': 13, 'distance_same_lane': 10}
2.285827446728945 seconds in game passed.
Action: tensor([[[0.0033, 0.5918],
         [0.0022, 0.3304],
         [0.0019, 0.2342],
         [0.0012, 0.1817]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002932, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.310827447101474 seconds in game passed.
Action: tensor([[[0.0033, 0.5918],
         [0.0022, 0.3304],
         [0.0019, 0.2342],
         [0.0012, 0.1817]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.335827447474003 seconds in game passed.
Action: tensor([[[0.0033, 0.5918],
         [0.0022, 0.3304],
         [0.0019, 0.2342],
         [0.0012, 0.1817]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.360827447846532 seconds in game passed.
Action: tensor([[[0.0033, 0.5918],
         [0.0022, 0.3304],
         [0.0019, 0.2342],
         [0.0012, 0.1817]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002539, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.385827448219061 seconds in game passed.
Action: tensor([[[0.0033, 0.5918],
         [0.0022, 0.3304],
         [0.0019, 0.2342],
         [0.0012, 0.1817]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002569, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.41082744859159 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003826, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.435827448964119 seconds in game passed.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003666, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.460827449336648 seconds in game passed.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.485827449709177 seconds in game passed.
Action: tensor([[[0.0053, 0.5908],
         [0.0028, 0.3227],
         [0.0027, 0.2228],
         [0.0023, 0.1688]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003752, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.510827450081706 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003155, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
2.535827450454235 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.560827450826764 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003333, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.585827451199293 seconds in game passed.
Action: tensor([[[0.0048, 0.5950],
         [0.0022, 0.3243],
         [0.0018, 0.2237],
         [0.0014, 0.1695]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.610827451571822 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002427, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.5134413525390814e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.635827451944351 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002615, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6608274523168802 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.6858274526894093 seconds in game passed.
Action: tensor([[[0.0035, 0.5932],
         [0.0015, 0.3236],
         [0.0012, 0.2232],
         [0.0007, 0.1690]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002667, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.7108274530619383 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 5.500325018928188e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.7358274534344673 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002414, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7608274538069963 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002436, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.7858274541795254 seconds in game passed.
Action: tensor([[[0.0028, 0.5917],
         [0.0014, 0.3227],
         [0.0012, 0.2224],
         [0.0007, 0.1683]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002458, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
2.8108274545520544 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002291, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 3.636705603973527e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.8358274549245834 seconds in game passed.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8608274552971125 seconds in game passed.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.8858274556696415 seconds in game passed.
Action: tensor([[[0.0025, 0.5905],
         [0.0014, 0.3223],
         [0.0011, 0.2221],
         [0.0006, 0.1681]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002384, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 20297.16684299258
2.9108274560421705 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0008, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 2.6203783366597982e-05
Current mitigation activation: 0
#############################
Total reward: 0
2.9358274564146996 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0008, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9608274567872286 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0008, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002505, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
2.9858274571597576 seconds in game passed.
Action: tensor([[[0.0023, 0.5895],
         [0.0015, 0.3219],
         [0.0013, 0.2218],
         [0.0008, 0.1679]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002526, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.71016465861
3.0108274575322866 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002443, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.818116288998224e-06
Current mitigation activation: 0
#############################
Total reward: 0
3.0358274579048157 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002481, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0608274582773447 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002501, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.0858274586498737 seconds in game passed.
Action: tensor([[[0.0020, 0.5891],
         [0.0016, 0.3218],
         [0.0014, 0.2218],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002521, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.1108274590224028 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002687, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.135827459394932 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.160827459767461 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002706, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.18582746013999 seconds in game passed.
Action: tensor([[[0.0022, 0.5888],
         [0.0017, 0.3217],
         [0.0015, 0.2217],
         [0.0008, 0.1677]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002727, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.210827460512519 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002763, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.235827460885048 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002783, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.260827461257577 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.285827461630106 seconds in game passed.
Action: tensor([[[0.0021, 0.5882],
         [0.0017, 0.3216],
         [0.0015, 0.2217],
         [0.0008, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002796, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.310827462002635 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.335827462375164 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002644, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.360827462747693 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002634, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.385827463120222 seconds in game passed.
Action: tensor([[[0.0020, 0.5889],
         [0.0016, 0.3218],
         [0.0014, 0.2217],
         [0.0007, 0.1678]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002624, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.410827463492751 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002680, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.43582746386528 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002645, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.460827464237809 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002623, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.485827464610338 seconds in game passed.
Action: tensor([[[0.0019, 0.5880],
         [0.0017, 0.3214],
         [0.0016, 0.2215],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002601, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: 89360.6593486434
3.5108274649828672 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 6.8181162889922514e-06
Current mitigation activation: 0
#############################
Total reward: 0
3.5358274653553963 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5608274657279253 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002470, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.5858274661004543 seconds in game passed.
Action: tensor([[[0.0018, 0.5878],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002454, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.6108274664729834 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002480, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.6358274668455124 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002469, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6608274672180414 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002463, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.6858274675905704 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0017, 0.3213],
         [0.0016, 0.2214],
         [0.0009, 0.1676]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002457, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.7108274679630995 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002359, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.7358274683356285 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002371, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7608274687081575 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002368, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.7858274690806866 seconds in game passed.
Action: tensor([[[0.0017, 0.5879],
         [0.0016, 0.3213],
         [0.0015, 0.2214],
         [0.0009, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.8108274694532156 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002563, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.8358274698257446 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002531, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8608274701982737 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002532, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.8858274705708027 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0019, 0.3211],
         [0.0018, 0.2213],
         [0.0011, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002533, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
3.9108274709433317 seconds in game passed.
Skip conversion, the game just started.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
3.9358274713158607 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.96082747168839 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002301, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
3.985827472060919 seconds in game passed.
Action: tensor([[[0.0017, 0.5873],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002298, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.010827472433448 seconds in game passed.
At 4.010827472433448 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002473, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.035827472805977 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.060827473178506 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.085827473551035 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3211],
         [0.0016, 0.2213],
         [0.0010, 0.1675]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002445, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.110827473923564 seconds in game passed.
At 4.110827473923564 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002266, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.135827474296093 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002292, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.160827474668622 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002289, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.185827475041151 seconds in game passed.
Action: tensor([[[0.0017, 0.5875],
         [0.0015, 0.3211],
         [0.0015, 0.2213],
         [0.0008, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002286, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.21082747541368 seconds in game passed.
At 4.21082747541368 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.235827475786209 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002327, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.260827476158738 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.285827476531267 seconds in game passed.
Action: tensor([[[0.0016, 0.5870],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.310827476903796 seconds in game passed.
At 4.310827476903796 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002294, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.335827477276325 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.360827477648854 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002296, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.385827478021383 seconds in game passed.
Action: tensor([[[0.0017, 0.5876],
         [0.0016, 0.3211],
         [0.0015, 0.2213],
         [0.0009, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.410827478393912 seconds in game passed.
At 4.410827478393912 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002422, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.435827478766441 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002400, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.46082747913897 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.485827479511499 seconds in game passed.
Action: tensor([[[0.0017, 0.5871],
         [0.0017, 0.3210],
         [0.0017, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002399, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.510827479884028 seconds in game passed.
At 4.510827479884028 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.5358274802565575 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.5608274806290865 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.5858274810016155 seconds in game passed.
Action: tensor([[[0.0018, 0.5873],
         [0.0017, 0.3210],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002375, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.6108274813741446 seconds in game passed.
At 4.6108274813741446 seconds, saving state-action tuples.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002295, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: nan
Current mitigation activation: 0
#############################
Total reward: 0
4.635827481746674 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002307, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.660827482119203 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
4.685827482491732 seconds in game passed.
Action: tensor([[[0.0016, 0.5869],
         [0.0016, 0.3209],
         [0.0016, 0.2212],
         [0.0010, 0.1674]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002304, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0
+++++++++++++: inf
4.710827482864261 seconds in game passed.
At 4.710827482864261 seconds, saving state-action tuples.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002345, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.06602266588708589
Current mitigation activation: 0
#############################
Total reward: 0.06602266588708589
4.73582748323679 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.760827483609319 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002338, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
4.785827483981848 seconds in game passed.
Action: tensor([[[0.0018, 0.5867],
         [0.0016, 0.3210],
         [0.0015, 0.2211],
         [0.0008, 0.1673]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002339, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.06602266588708589
+++++++++++++: inf
4.810827484354377 seconds in game passed.
At 4.810827484354377 seconds, saving state-action tuples.
Action: tensor([[[1.4129e-03, 5.8608e-01],
         [1.1332e-03, 3.2068e-01],
         [9.9862e-04, 2.2101e-01],
         [3.4603e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001845, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.2485170261106222
Current mitigation activation: 0
#############################
Total reward: 0.3145396919977081
4.835827484726906 seconds in game passed.
Action: tensor([[[1.4129e-03, 5.8608e-01],
         [1.1332e-03, 3.2068e-01],
         [9.9862e-04, 2.2101e-01],
         [3.4603e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.860827485099435 seconds in game passed.
Action: tensor([[[1.4129e-03, 5.8608e-01],
         [1.1332e-03, 3.2068e-01],
         [9.9862e-04, 2.2101e-01],
         [3.4603e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001912, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
4.885827485471964 seconds in game passed.
Action: tensor([[[1.4129e-03, 5.8608e-01],
         [1.1332e-03, 3.2068e-01],
         [9.9862e-04, 2.2101e-01],
         [3.4603e-04, 1.6729e-01]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001906, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.3145396919977081
+++++++++++++: inf
4.910827485844493 seconds in game passed.
At 4.910827485844493 seconds, saving state-action tuples.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002133, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.40760825864174777
Current mitigation activation: 0
#############################
Total reward: 0.7221479506394559
4.935827486217022 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002093, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.960827486589551 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
4.98582748696208 seconds in game passed.
Action: tensor([[[0.0017, 0.5838],
         [0.0013, 0.3201],
         [0.0014, 0.2208],
         [0.0010, 0.1669]]], device='cuda:0', grad_fn=<StackBackward0>)
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002090, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 0.7221479506394559
+++++++++++++: inf
5.010827487334609 seconds in game passed.
At 5.010827487334609 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002222, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.541619495703239
Current mitigation activation: 0
#############################
Total reward: 1.263767446342695
5.035827487707138 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
5.060827488079667 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002195, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
5.085827488452196 seconds in game passed.
Action: tensor([[[0.0016, 0.5811],
         [0.0015, 0.3194],
         [0.0017, 0.2205],
         [0.0014, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002193, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.263767446342695
+++++++++++++: inf
5.110827488824725 seconds in game passed.
At 5.110827488824725 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.003078, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.6535768229361686
Current mitigation activation: 0
#############################
Total reward: 1.9173442692788636
5.135827489197254 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002941, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
5.160827489569783 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002950, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
5.185827489942312 seconds in game passed.
Action: tensor([[[0.0023, 0.5850],
         [0.0023, 0.3209],
         [0.0027, 0.2209],
         [0.0026, 0.1671]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002958, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 1.9173442692788636
+++++++++++++: inf
5.210827490314841 seconds in game passed.
At 5.210827490314841 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.7480283176913025
Current mitigation activation: 0
#############################
Total reward: 2.6653725869701663
5.23582749068737 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002506, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653725869701663
5.260827491059899 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002509, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653725869701663
5.285827491432428 seconds in game passed.
Action: tensor([[[0.0018, 0.5884],
         [0.0019, 0.3215],
         [0.0020, 0.2210],
         [0.0018, 0.1670]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002511, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 2.6653725869701663
+++++++++++++: inf
5.310827491804957 seconds in game passed.
At 5.310827491804957 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8716e-05,  5.8851e-01],
         [-5.1759e-05,  3.2180e-01],
         [ 3.1956e-05,  2.2105e-01],
         [-3.6263e-04,  1.6702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8290540300480296
Current mitigation activation: 0
#############################
Total reward: 3.494426617018196
5.335827492177486 seconds in game passed.
Action: tensor([[[ 1.8716e-05,  5.8851e-01],
         [-5.1759e-05,  3.2180e-01],
         [ 3.1956e-05,  2.2105e-01],
         [-3.6263e-04,  1.6702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000719, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.494426617018196
5.3608274925500154 seconds in game passed.
Action: tensor([[[ 1.8716e-05,  5.8851e-01],
         [-5.1759e-05,  3.2180e-01],
         [ 3.1956e-05,  2.2105e-01],
         [-3.6263e-04,  1.6702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000700, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.494426617018196
5.3858274929225445 seconds in game passed.
Action: tensor([[[ 1.8716e-05,  5.8851e-01],
         [-5.1759e-05,  3.2180e-01],
         [ 3.1956e-05,  2.2105e-01],
         [-3.6263e-04,  1.6702e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000681, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 3.494426617018196
+++++++++++++: inf
5.4108274932950735 seconds in game passed.
At 5.4108274932950735 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.1200e-04,  5.8911e-01],
         [-2.2926e-04,  3.2116e-01],
         [-1.7606e-04,  2.2086e-01],
         [-4.2595e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.8996363843097241
Current mitigation activation: 0
#############################
Total reward: 4.39406300132792
5.4358274936676025 seconds in game passed.
Action: tensor([[[ 3.1200e-04,  5.8911e-01],
         [-2.2926e-04,  3.2116e-01],
         [-1.7606e-04,  2.2086e-01],
         [-4.2595e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000629, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.39406300132792
5.460827494040132 seconds in game passed.
Action: tensor([[[ 3.1200e-04,  5.8911e-01],
         [-2.2926e-04,  3.2116e-01],
         [-1.7606e-04,  2.2086e-01],
         [-4.2595e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000609, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.39406300132792
5.485827494412661 seconds in game passed.
Action: tensor([[[ 3.1200e-04,  5.8911e-01],
         [-2.2926e-04,  3.2116e-01],
         [-1.7606e-04,  2.2086e-01],
         [-4.2595e-04,  1.6698e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000588, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 4.39406300132792
+++++++++++++: inf
5.51082749478519 seconds in game passed.
At 5.51082749478519 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.4136e-04,  5.9112e-01],
         [-1.0424e-03,  3.2138e-01],
         [-9.0019e-04,  2.2095e-01],
         [-1.0424e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000331, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 0.962209169834031
Current mitigation activation: 0
#############################
Total reward: 5.356272171161951
5.535827495157719 seconds in game passed.
Action: tensor([[[-4.4136e-04,  5.9112e-01],
         [-1.0424e-03,  3.2138e-01],
         [-9.0019e-04,  2.2095e-01],
         [-1.0424e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000212, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.356272171161951
5.560827495530248 seconds in game passed.
Action: tensor([[[-4.4136e-04,  5.9112e-01],
         [-1.0424e-03,  3.2138e-01],
         [-9.0019e-04,  2.2095e-01],
         [-1.0424e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.356272171161951
5.585827495902777 seconds in game passed.
Action: tensor([[[-4.4136e-04,  5.9112e-01],
         [-1.0424e-03,  3.2138e-01],
         [-9.0019e-04,  2.2095e-01],
         [-1.0424e-03,  1.6699e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000272, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 5.356272171161951
+++++++++++++: inf
5.610827496275306 seconds in game passed.
At 5.610827496275306 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 7.6474e-04,  5.9017e-01],
         [-3.8671e-04,  3.2150e-01],
         [-2.6911e-04,  2.2102e-01],
         [-3.4630e-04,  1.6712e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000664, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.0188346437405869
Current mitigation activation: 0
#############################
Total reward: 6.375106814902538
5.635827496647835 seconds in game passed.
Action: tensor([[[ 7.6474e-04,  5.9017e-01],
         [-3.8671e-04,  3.2150e-01],
         [-2.6911e-04,  2.2102e-01],
         [-3.4630e-04,  1.6712e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000486, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375106814902538
5.660827497020364 seconds in game passed.
Action: tensor([[[ 7.6474e-04,  5.9017e-01],
         [-3.8671e-04,  3.2150e-01],
         [-2.6911e-04,  2.2102e-01],
         [-3.4630e-04,  1.6712e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000467, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375106814902538
5.685827497392893 seconds in game passed.
Action: tensor([[[ 7.6474e-04,  5.9017e-01],
         [-3.8671e-04,  3.2150e-01],
         [-2.6911e-04,  2.2102e-01],
         [-3.4630e-04,  1.6712e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 6.375106814902538
+++++++++++++: inf
5.710827497765422 seconds in game passed.
At 5.710827497765422 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001867, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.071044305475438
Current mitigation activation: 0
#############################
Total reward: 7.446151120377976
5.735827498137951 seconds in game passed.
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001625, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446151120377976
5.76082749851048 seconds in game passed.
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446151120377976
5.785827498883009 seconds in game passed.
Action: tensor([[[0.0018, 0.5881],
         [0.0010, 0.3211],
         [0.0015, 0.2215],
         [0.0018, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001616, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 7.446151120377976
+++++++++++++: inf
5.810827499255538 seconds in game passed.
At 5.810827499255538 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2888e-03, 5.8975e-01],
         [8.8573e-04, 3.2203e-01],
         [7.5395e-04, 2.2272e-01],
         [3.9004e-04, 1.6870e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001324, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.119991805786244
Current mitigation activation: 0
#############################
Total reward: 8.56614292616422
5.835827499628067 seconds in game passed.
Action: tensor([[[1.2888e-03, 5.8975e-01],
         [8.8573e-04, 3.2203e-01],
         [7.5395e-04, 2.2272e-01],
         [3.9004e-04, 1.6870e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001370, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.56614292616422
5.860827500000596 seconds in game passed.
Action: tensor([[[1.2888e-03, 5.8975e-01],
         [8.8573e-04, 3.2203e-01],
         [7.5395e-04, 2.2272e-01],
         [3.9004e-04, 1.6870e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001367, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.56614292616422
5.885827500373125 seconds in game passed.
Action: tensor([[[1.2888e-03, 5.8975e-01],
         [8.8573e-04, 3.2203e-01],
         [7.5395e-04, 2.2272e-01],
         [3.9004e-04, 1.6870e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001365, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 8.56614292616422
+++++++++++++: inf
5.910827500745654 seconds in game passed.
At 5.910827500745654 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0015, 0.5849],
         [0.0019, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002227, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.1663832449804383
Current mitigation activation: 0
#############################
Total reward: 9.73252617114466
5.935827501118183 seconds in game passed.
Action: tensor([[[0.0015, 0.5849],
         [0.0019, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002088, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.73252617114466
5.960827501490712 seconds in game passed.
Action: tensor([[[0.0015, 0.5849],
         [0.0019, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002092, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.73252617114466
5.985827501863241 seconds in game passed.
Action: tensor([[[0.0015, 0.5849],
         [0.0019, 0.3192],
         [0.0019, 0.2209],
         [0.0015, 0.1674]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002096, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 9.73252617114466
+++++++++++++: inf
6.01082750223577 seconds in game passed.
At 6.01082750223577 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001209, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2107580958907376
Current mitigation activation: 0
#############################
Total reward: 10.943284267035397
6.035827502608299 seconds in game passed.
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001350, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943284267035397
6.060827502980828 seconds in game passed.
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001343, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943284267035397
6.085827503353357 seconds in game passed.
Action: tensor([[[0.0014, 0.5931],
         [0.0008, 0.3213],
         [0.0008, 0.2209],
         [0.0007, 0.1669]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 10.943284267035397
+++++++++++++: inf
6.110827503725886 seconds in game passed.
At 6.110827503725886 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0016, 0.5911],
         [0.0016, 0.3211],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001978, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2534932613493657
Current mitigation activation: 0
#############################
Total reward: 12.196777528384763
6.135827504098415 seconds in game passed.
Action: tensor([[[0.0016, 0.5911],
         [0.0016, 0.3211],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001861, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196777528384763
6.160827504470944 seconds in game passed.
Action: tensor([[[0.0016, 0.5911],
         [0.0016, 0.3211],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001852, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196777528384763
6.185827504843473 seconds in game passed.
Action: tensor([[[0.0016, 0.5911],
         [0.0016, 0.3211],
         [0.0016, 0.2205],
         [0.0014, 0.1666]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001844, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 12.196777528384763
+++++++++++++: inf
6.2108275052160025 seconds in game passed.
At 6.2108275052160025 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.0437e-03, 5.8987e-01],
         [6.3772e-04, 3.2037e-01],
         [6.2224e-04, 2.1993e-01],
         [3.1566e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000926, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.279943520666818
Current mitigation activation: 0
#############################
Total reward: 13.47672104905158
6.2358275055885315 seconds in game passed.
Action: tensor([[[1.0437e-03, 5.8987e-01],
         [6.3772e-04, 3.2037e-01],
         [6.2224e-04, 2.1993e-01],
         [3.1566e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001064, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.47672104905158
6.2608275059610605 seconds in game passed.
Action: tensor([[[1.0437e-03, 5.8987e-01],
         [6.3772e-04, 3.2037e-01],
         [6.2224e-04, 2.1993e-01],
         [3.1566e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001052, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.47672104905158
6.2858275063335896 seconds in game passed.
Action: tensor([[[1.0437e-03, 5.8987e-01],
         [6.3772e-04, 3.2037e-01],
         [6.2224e-04, 2.1993e-01],
         [3.1566e-04, 1.6602e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.001039, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 13.47672104905158
+++++++++++++: inf
6.310827506706119 seconds in game passed.
At 6.310827506706119 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 4.9609e-04,  5.9100e-01],
         [-2.6451e-04,  3.2044e-01],
         [-4.5747e-04,  2.1967e-01],
         [-9.0701e-04,  1.6624e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000167, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2784812109551715
Current mitigation activation: 0
#############################
Total reward: 14.755202260006751
6.335827507078648 seconds in game passed.
Action: tensor([[[ 4.9609e-04,  5.9100e-01],
         [-2.6451e-04,  3.2044e-01],
         [-4.5747e-04,  2.1967e-01],
         [-9.0701e-04,  1.6624e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000312, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755202260006751
6.360827507451177 seconds in game passed.
Action: tensor([[[ 4.9609e-04,  5.9100e-01],
         [-2.6451e-04,  3.2044e-01],
         [-4.5747e-04,  2.1967e-01],
         [-9.0701e-04,  1.6624e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755202260006751
6.385827507823706 seconds in game passed.
Action: tensor([[[ 4.9609e-04,  5.9100e-01],
         [-2.6451e-04,  3.2044e-01],
         [-4.5747e-04,  2.1967e-01],
         [-9.0701e-04,  1.6624e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 14.755202260006751
+++++++++++++: inf
6.410827508196235 seconds in game passed.
At 6.410827508196235 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.5878],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001522, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2767190469039733
Current mitigation activation: 0
#############################
Total reward: 16.031921306910725
6.435827508568764 seconds in game passed.
Action: tensor([[[-0.0008,  0.5878],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001238, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031921306910725
6.460827508941293 seconds in game passed.
Action: tensor([[[-0.0008,  0.5878],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001256, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031921306910725
6.485827509313822 seconds in game passed.
Action: tensor([[[-0.0008,  0.5878],
         [-0.0021,  0.3197],
         [-0.0026,  0.2193],
         [-0.0033,  0.1657]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001275, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 16.031921306910725
+++++++++++++: inf
6.510827509686351 seconds in game passed.
At 6.510827509686351 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0011,  0.5908],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001788, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2749245980660904
Current mitigation activation: 0
#############################
Total reward: 17.306845904976814
6.53582751005888 seconds in game passed.
Action: tensor([[[-0.0011,  0.5908],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001720, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306845904976814
6.560827510431409 seconds in game passed.
Action: tensor([[[-0.0011,  0.5908],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001734, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306845904976814
6.585827510803938 seconds in game passed.
Action: tensor([[[-0.0011,  0.5908],
         [-0.0026,  0.3205],
         [-0.0030,  0.2198],
         [-0.0033,  0.1660]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.001748, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 17.306845904976814
+++++++++++++: inf
6.610827511176467 seconds in game passed.
At 6.610827511176467 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 5.7444e-05,  5.8988e-01],
         [-8.9145e-04,  3.2106e-01],
         [-1.0471e-03,  2.2064e-01],
         [-1.3352e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000067, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.27310811745959
Current mitigation activation: 0
#############################
Total reward: 18.579954022436404
6.635827511548996 seconds in game passed.
Action: tensor([[[ 5.7444e-05,  5.8988e-01],
         [-8.9145e-04,  3.2106e-01],
         [-1.0471e-03,  2.2064e-01],
         [-1.3352e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000355, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579954022436404
6.660827511921525 seconds in game passed.
Action: tensor([[[ 5.7444e-05,  5.8988e-01],
         [-8.9145e-04,  3.2106e-01],
         [-1.0471e-03,  2.2064e-01],
         [-1.3352e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579954022436404
6.685827512294054 seconds in game passed.
Action: tensor([[[ 5.7444e-05,  5.8988e-01],
         [-8.9145e-04,  3.2106e-01],
         [-1.0471e-03,  2.2064e-01],
         [-1.3352e-03,  1.6677e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=-0.000369, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 18.579954022436404
+++++++++++++: inf
6.710827512666583 seconds in game passed.
At 6.710827512666583 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.3688e-03,  5.9040e-01],
         [ 2.0065e-04,  3.2131e-01],
         [ 2.1623e-04,  2.2086e-01],
         [-6.1810e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000936, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.2883823507688201
Current mitigation activation: 0
#############################
Total reward: 19.868336373205224
6.735827513039112 seconds in game passed.
Action: tensor([[[ 1.3688e-03,  5.9040e-01],
         [ 2.0065e-04,  3.2131e-01],
         [ 2.1623e-04,  2.2086e-01],
         [-6.1810e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000709, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868336373205224
6.760827513411641 seconds in game passed.
Action: tensor([[[ 1.3688e-03,  5.9040e-01],
         [ 2.0065e-04,  3.2131e-01],
         [ 2.1623e-04,  2.2086e-01],
         [-6.1810e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000701, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868336373205224
6.78582751378417 seconds in game passed.
Action: tensor([[[ 1.3688e-03,  5.9040e-01],
         [ 2.0065e-04,  3.2131e-01],
         [ 2.1623e-04,  2.2086e-01],
         [-6.1810e-05,  1.6691e-01]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.000693, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 19.868336373205224
+++++++++++++: inf
6.810827514156699 seconds in game passed.
At 6.810827514156699 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0028, 0.5911],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002811, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.350323139062026
Current mitigation activation: 0
#############################
Total reward: 21.21865951226725
6.835827514529228 seconds in game passed.
Action: tensor([[[0.0028, 0.5911],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002478, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.21865951226725
6.860827514901757 seconds in game passed.
Action: tensor([[[0.0028, 0.5911],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.900000, steer=0.002495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.21865951226725
6.885827515274286 seconds in game passed.
Action: tensor([[[0.0028, 0.5911],
         [0.0023, 0.3219],
         [0.0018, 0.2215],
         [0.0007, 0.1677]]])
agent 0 action: VehicleControl(throttle=0.855533, steer=0.002512, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 21.21865951226725
+++++++++++++: inf
6.910827515646815 seconds in game passed.
At 6.910827515646815 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.1278e-03,  5.9183e-01],
         [ 9.9470e-04,  3.2207e-01],
         [ 3.1782e-04,  2.2149e-01],
         [-8.3532e-04,  1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.806828, steer=0.001284, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.406699496987092
Current mitigation activation: 0
#############################
Total reward: 22.625359009254343
6.935827516019344 seconds in game passed.
Action: tensor([[[ 2.1278e-03,  5.9183e-01],
         [ 9.9470e-04,  3.2207e-01],
         [ 3.1782e-04,  2.2149e-01],
         [-8.3532e-04,  1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.757331, steer=0.001484, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625359009254343
6.960827516391873 seconds in game passed.
Action: tensor([[[ 2.1278e-03,  5.9183e-01],
         [ 9.9470e-04,  3.2207e-01],
         [ 3.1782e-04,  2.2149e-01],
         [-8.3532e-04,  1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.709412, steer=0.001479, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625359009254343
6.985827516764402 seconds in game passed.
Action: tensor([[[ 2.1278e-03,  5.9183e-01],
         [ 9.9470e-04,  3.2207e-01],
         [ 3.1782e-04,  2.2149e-01],
         [-8.3532e-04,  1.6791e-01]]])
agent 0 action: VehicleControl(throttle=0.663223, steer=0.001474, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 22.625359009254343
+++++++++++++: inf
7.010827517136931 seconds in game passed.
At 7.010827517136931 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7443e-04,  5.9663e-01],
         [-6.2303e-04,  3.2312e-01],
         [-1.5156e-03,  2.2112e-01],
         [-2.8055e-03,  1.6769e-01]]])
agent 0 action: VehicleControl(throttle=0.632900, steer=-0.000452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4565141645073236
Current mitigation activation: 0
#############################
Total reward: 24.081873173761664
7.0358275175094604 seconds in game passed.
Action: tensor([[[ 2.7443e-04,  5.9663e-01],
         [-6.2303e-04,  3.2312e-01],
         [-1.5156e-03,  2.2112e-01],
         [-2.8055e-03,  1.6769e-01]]])
agent 0 action: VehicleControl(throttle=0.589615, steer=-0.000149, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.081873173761664
7.0608275178819895 seconds in game passed.
Action: tensor([[[ 2.7443e-04,  5.9663e-01],
         [-6.2303e-04,  3.2312e-01],
         [-1.5156e-03,  2.2112e-01],
         [-2.8055e-03,  1.6769e-01]]])
agent 0 action: VehicleControl(throttle=0.550334, steer=-0.000164, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.081873173761664
7.0858275182545185 seconds in game passed.
Action: tensor([[[ 2.7443e-04,  5.9663e-01],
         [-6.2303e-04,  3.2312e-01],
         [-1.5156e-03,  2.2112e-01],
         [-2.8055e-03,  1.6769e-01]]])
agent 0 action: VehicleControl(throttle=0.513678, steer=-0.000180, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 24.081873173761664
+++++++++++++: inf
7.1108275186270475 seconds in game passed.
At 7.1108275186270475 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-9.8720e-05,  5.9888e-01],
         [-1.0593e-03,  3.2449e-01],
         [-1.9685e-03,  2.2238e-01],
         [-3.4016e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.453157, steer=-0.000672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4973340445745837
Current mitigation activation: 0
#############################
Total reward: 25.579207218336247
7.135827518999577 seconds in game passed.
Action: tensor([[[-9.8720e-05,  5.9888e-01],
         [-1.0593e-03,  3.2449e-01],
         [-1.9685e-03,  2.2238e-01],
         [-3.4016e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.425004, steer=-0.000621, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579207218336247
7.160827519372106 seconds in game passed.
Action: tensor([[[-9.8720e-05,  5.9888e-01],
         [-1.0593e-03,  3.2449e-01],
         [-1.9685e-03,  2.2238e-01],
         [-3.4016e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.396701, steer=-0.000648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579207218336247
7.185827519744635 seconds in game passed.
Action: tensor([[[-9.8720e-05,  5.9888e-01],
         [-1.0593e-03,  3.2449e-01],
         [-1.9685e-03,  2.2238e-01],
         [-3.4016e-03,  1.6867e-01]]])
agent 0 action: VehicleControl(throttle=0.371376, steer=-0.000675, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 25.579207218336247
+++++++++++++: inf
7.210827520117164 seconds in game passed.
At 7.210827520117164 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.378514, steer=-0.005962, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5251291882605973
Current mitigation activation: 0
#############################
Total reward: 27.104336406596843
7.235827520489693 seconds in game passed.
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.356080, steer=-0.005165, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104336406596843
7.260827520862222 seconds in game passed.
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.339600, steer=-0.005237, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104336406596843
7.285827521234751 seconds in game passed.
Action: tensor([[[-0.0039,  0.6095],
         [-0.0061,  0.3268],
         [-0.0076,  0.2222],
         [-0.0092,  0.1685]]])
agent 0 action: VehicleControl(throttle=0.325505, steer=-0.005309, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 27.104336406596843
+++++++++++++: inf
7.31082752160728 seconds in game passed.
At 7.31082752160728 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0029,  0.6075],
         [-0.0051,  0.3265],
         [-0.0062,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.302465, steer=-0.004224, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5379029412003375
Current mitigation activation: 0
#############################
Total reward: 28.64223934779718
7.335827521979809 seconds in game passed.
Action: tensor([[[-0.0029,  0.6075],
         [-0.0051,  0.3265],
         [-0.0062,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.293992, steer=-0.004464, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64223934779718
7.360827522352338 seconds in game passed.
Action: tensor([[[-0.0029,  0.6075],
         [-0.0051,  0.3265],
         [-0.0062,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.286475, steer=-0.004515, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64223934779718
7.385827522724867 seconds in game passed.
Action: tensor([[[-0.0029,  0.6075],
         [-0.0051,  0.3265],
         [-0.0062,  0.2225],
         [-0.0073,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.281020, steer=-0.004566, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 28.64223934779718
+++++++++++++: inf
7.410827523097396 seconds in game passed.
At 7.410827523097396 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.5976],
         [-0.0041,  0.3240],
         [-0.0048,  0.2220],
         [-0.0053,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261848, steer=-0.003495, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5376227680968435
Current mitigation activation: 0
#############################
Total reward: 30.17986211589402
7.435827523469925 seconds in game passed.
Action: tensor([[[-0.0020,  0.5976],
         [-0.0041,  0.3240],
         [-0.0048,  0.2220],
         [-0.0053,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261505, steer=-0.003698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.17986211589402
7.460827523842454 seconds in game passed.
Action: tensor([[[-0.0020,  0.5976],
         [-0.0041,  0.3240],
         [-0.0048,  0.2220],
         [-0.0053,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.261045, steer=-0.003718, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.17986211589402
7.485827524214983 seconds in game passed.
Action: tensor([[[-0.0020,  0.5976],
         [-0.0041,  0.3240],
         [-0.0048,  0.2220],
         [-0.0053,  0.1680]]])
agent 0 action: VehicleControl(throttle=0.262085, steer=-0.003739, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 30.17986211589402
+++++++++++++: inf
7.510827524587512 seconds in game passed.
At 7.510827524587512 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.5935],
         [-0.0028,  0.3227],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.267932, steer=-0.002305, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5276152155169365
Current mitigation activation: 0
#############################
Total reward: 31.707477331410956
7.535827524960041 seconds in game passed.
Action: tensor([[[-0.0009,  0.5935],
         [-0.0028,  0.3227],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.270981, steer=-0.002544, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707477331410956
7.56082752533257 seconds in game passed.
Action: tensor([[[-0.0009,  0.5935],
         [-0.0028,  0.3227],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.275357, steer=-0.002545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707477331410956
7.585827525705099 seconds in game passed.
Action: tensor([[[-0.0009,  0.5935],
         [-0.0028,  0.3227],
         [-0.0033,  0.2215],
         [-0.0039,  0.1673]]])
agent 0 action: VehicleControl(throttle=0.280516, steer=-0.002545, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 31.707477331410956
+++++++++++++: inf
7.610827526077628 seconds in game passed.
At 7.610827526077628 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0008,  0.6019],
         [-0.0014,  0.3244],
         [-0.0029,  0.2215],
         [-0.0047,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.315955, steer=-0.000902, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.5111037183513214
Current mitigation activation: 0
#############################
Total reward: 33.21858104976228
7.635827526450157 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6019],
         [-0.0014,  0.3244],
         [-0.0029,  0.2215],
         [-0.0047,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.319874, steer=-0.001177, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21858104976228
7.660827526822686 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6019],
         [-0.0014,  0.3244],
         [-0.0029,  0.2215],
         [-0.0047,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.327581, steer=-0.001178, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21858104976228
7.685827527195215 seconds in game passed.
Action: tensor([[[ 0.0008,  0.6019],
         [-0.0014,  0.3244],
         [-0.0029,  0.2215],
         [-0.0047,  0.1677]]])
agent 0 action: VehicleControl(throttle=0.336002, steer=-0.001179, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 33.21858104976228
+++++++++++++: inf
7.710827527567744 seconds in game passed.
At 7.710827527567744 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.6269e-04,  6.0099e-01],
         [-7.0932e-04,  3.2361e-01],
         [-1.4815e-03,  2.2127e-01],
         [-2.9384e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.365596, steer=-0.000886, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4915212710147068
Current mitigation activation: 0
#############################
Total reward: 34.71010232077698
7.735827527940273 seconds in game passed.
Action: tensor([[[ 2.6269e-04,  6.0099e-01],
         [-7.0932e-04,  3.2361e-01],
         [-1.4815e-03,  2.2127e-01],
         [-2.9384e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.373364, steer=-0.000948, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71010232077698
7.760827528312802 seconds in game passed.
Action: tensor([[[ 2.6269e-04,  6.0099e-01],
         [-7.0932e-04,  3.2361e-01],
         [-1.4815e-03,  2.2127e-01],
         [-2.9384e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.383717, steer=-0.000960, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71010232077698
7.785827528685331 seconds in game passed.
Action: tensor([[[ 2.6269e-04,  6.0099e-01],
         [-7.0932e-04,  3.2361e-01],
         [-1.4815e-03,  2.2127e-01],
         [-2.9384e-03,  1.6715e-01]]])
agent 0 action: VehicleControl(throttle=0.394252, steer=-0.000971, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 34.71010232077698
+++++++++++++: inf
7.81082752905786 seconds in game passed.
At 7.81082752905786 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.7396e-03,  5.9953e-01],
         [-4.3318e-04,  3.2594e-01],
         [-1.3813e-03,  2.2423e-01],
         [-2.8298e-03,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.302373, steer=0.000191, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.472134291721184
Current mitigation activation: 0
#############################
Total reward: 36.182236612498166
7.835827529430389 seconds in game passed.
Action: tensor([[[ 2.7396e-03,  5.9953e-01],
         [-4.3318e-04,  3.2594e-01],
         [-1.3813e-03,  2.2423e-01],
         [-2.8298e-03,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.323083, steer=-0.000027, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.182236612498166
7.860827529802918 seconds in game passed.
Action: tensor([[[ 2.7396e-03,  5.9953e-01],
         [-4.3318e-04,  3.2594e-01],
         [-1.3813e-03,  2.2423e-01],
         [-2.8298e-03,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.333287, steer=-0.000048, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.182236612498166
7.8858275301754475 seconds in game passed.
Action: tensor([[[ 2.7396e-03,  5.9953e-01],
         [-4.3318e-04,  3.2594e-01],
         [-1.3813e-03,  2.2423e-01],
         [-2.8298e-03,  1.7033e-01]]])
agent 0 action: VehicleControl(throttle=0.344571, steer=-0.000069, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 36.182236612498166
+++++++++++++: inf
7.9108275305479765 seconds in game passed.
At 7.9108275305479765 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.8791e-04,  6.0129e-01],
         [-1.0189e-03,  3.2588e-01],
         [-1.5277e-03,  2.2284e-01],
         [-2.5624e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.378082, steer=-0.001530, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4548312588089725
Current mitigation activation: 0
#############################
Total reward: 37.63706787130714
7.9358275309205055 seconds in game passed.
Action: tensor([[[ 1.8791e-04,  6.0129e-01],
         [-1.0189e-03,  3.2588e-01],
         [-1.5277e-03,  2.2284e-01],
         [-2.5624e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.388577, steer=-0.001313, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63706787130714
7.9608275312930346 seconds in game passed.
Action: tensor([[[ 1.8791e-04,  6.0129e-01],
         [-1.0189e-03,  3.2588e-01],
         [-1.5277e-03,  2.2284e-01],
         [-2.5624e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.401722, steer=-0.001337, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63706787130714
7.985827531665564 seconds in game passed.
Action: tensor([[[ 1.8791e-04,  6.0129e-01],
         [-1.0189e-03,  3.2588e-01],
         [-1.5277e-03,  2.2284e-01],
         [-2.5624e-03,  1.6918e-01]]])
agent 0 action: VehicleControl(throttle=0.414946, steer=-0.001360, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 37.63706787130714
+++++++++++++: inf
8.010827532038093 seconds in game passed.
At 8.010827532038093 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0013,  0.6044],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.416133, steer=-0.004114, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4383149198096492
Current mitigation activation: 0
#############################
Total reward: 39.07538279111679
8.035827532410622 seconds in game passed.
Action: tensor([[[-0.0013,  0.6044],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.430270, steer=-0.003692, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07538279111679
8.06082753278315 seconds in game passed.
Action: tensor([[[-0.0013,  0.6044],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.443017, steer=-0.003724, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07538279111679
8.08582753315568 seconds in game passed.
Action: tensor([[[-0.0013,  0.6044],
         [-0.0039,  0.3271],
         [-0.0049,  0.2237],
         [-0.0061,  0.1699]]])
agent 0 action: VehicleControl(throttle=0.455624, steer=-0.003756, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 39.07538279111679
+++++++++++++: inf
8.110827533528209 seconds in game passed.
At 8.110827533528209 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0020,  0.6050],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.501356, steer=-0.004996, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.423837624181919
Current mitigation activation: 0
#############################
Total reward: 40.49922041529871
8.135827533900738 seconds in game passed.
Action: tensor([[[-0.0020,  0.6050],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.510516, steer=-0.004835, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49922041529871
8.160827534273267 seconds in game passed.
Action: tensor([[[-0.0020,  0.6050],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.522649, steer=-0.004875, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49922041529871
8.185827534645796 seconds in game passed.
Action: tensor([[[-0.0020,  0.6050],
         [-0.0052,  0.3264],
         [-0.0059,  0.2228],
         [-0.0065,  0.1693]]])
agent 0 action: VehicleControl(throttle=0.533911, steer=-0.004914, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 40.49922041529871
+++++++++++++: inf
8.210827535018325 seconds in game passed.
At 8.210827535018325 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-4.3878e-04,  6.0008e-01],
         [-2.2896e-03,  3.2498e-01],
         [-2.9219e-03,  2.2216e-01],
         [-3.6028e-03,  1.6882e-01]]])
agent 0 action: VehicleControl(throttle=0.543014, steer=-0.002121, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.412755086282131
Current mitigation activation: 0
#############################
Total reward: 41.91197550158084
8.235827535390854 seconds in game passed.
Action: tensor([[[-4.3878e-04,  6.0008e-01],
         [-2.2896e-03,  3.2498e-01],
         [-2.9219e-03,  2.2216e-01],
         [-3.6028e-03,  1.6882e-01]]])
agent 0 action: VehicleControl(throttle=0.550095, steer=-0.002535, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91197550158084
8.260827535763383 seconds in game passed.
Action: tensor([[[-4.3878e-04,  6.0008e-01],
         [-2.2896e-03,  3.2498e-01],
         [-2.9219e-03,  2.2216e-01],
         [-3.6028e-03,  1.6882e-01]]])
agent 0 action: VehicleControl(throttle=0.556563, steer=-0.002492, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91197550158084
8.285827536135912 seconds in game passed.
Action: tensor([[[-4.3878e-04,  6.0008e-01],
         [-2.2896e-03,  3.2498e-01],
         [-2.9219e-03,  2.2216e-01],
         [-3.6028e-03,  1.6882e-01]]])
agent 0 action: VehicleControl(throttle=0.563062, steer=-0.002448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 41.91197550158084
+++++++++++++: inf
8.310827536508441 seconds in game passed.
At 8.310827536508441 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0098,  0.6391],
         [-0.0008,  0.3451],
         [-0.0025,  0.2357],
         [-0.0035,  0.1788]]])
agent 0 action: VehicleControl(throttle=0.266036, steer=0.002822, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.407642537909596
Current mitigation activation: 0
#############################
Total reward: 43.319618039490436
8.33582753688097 seconds in game passed.
Action: tensor([[[ 0.0098,  0.6391],
         [-0.0008,  0.3451],
         [-0.0025,  0.2357],
         [-0.0035,  0.1788]]])
agent 0 action: VehicleControl(throttle=0.301522, steer=0.002043, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.319618039490436
8.360827537253499 seconds in game passed.
Action: tensor([[[ 0.0098,  0.6391],
         [-0.0008,  0.3451],
         [-0.0025,  0.2357],
         [-0.0035,  0.1788]]])
agent 0 action: VehicleControl(throttle=0.304830, steer=0.002129, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.319618039490436
8.385827537626028 seconds in game passed.
Action: tensor([[[ 0.0098,  0.6391],
         [-0.0008,  0.3451],
         [-0.0025,  0.2357],
         [-0.0035,  0.1788]]])
agent 0 action: VehicleControl(throttle=0.308081, steer=0.002215, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 43.319618039490436
+++++++++++++: inf
8.410827537998557 seconds in game passed.
At 8.410827537998557 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0160, 0.6423],
         [0.0039, 0.3495],
         [0.0025, 0.2400],
         [0.0016, 0.1826]]])
agent 0 action: VehicleControl(throttle=0.199144, steer=0.008262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4055492710313335
Current mitigation activation: 0
#############################
Total reward: 44.72516731052177
8.435827538371086 seconds in game passed.
Action: tensor([[[0.0160, 0.6423],
         [0.0039, 0.3495],
         [0.0025, 0.2400],
         [0.0016, 0.1826]]])
agent 0 action: VehicleControl(throttle=0.213072, steer=0.007412, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72516731052177
8.460827538743615 seconds in game passed.
Action: tensor([[[0.0160, 0.6423],
         [0.0039, 0.3495],
         [0.0025, 0.2400],
         [0.0016, 0.1826]]])
agent 0 action: VehicleControl(throttle=0.215064, steer=0.007548, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72516731052177
8.485827539116144 seconds in game passed.
Action: tensor([[[0.0160, 0.6423],
         [0.0039, 0.3495],
         [0.0025, 0.2400],
         [0.0016, 0.1826]]])
agent 0 action: VehicleControl(throttle=0.216888, steer=0.007684, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 44.72516731052177
+++++++++++++: inf
8.510827539488673 seconds in game passed.
At 8.510827539488673 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[5.1815e-03, 5.9935e-01],
         [1.6788e-03, 3.2400e-01],
         [1.0775e-03, 2.2237e-01],
         [2.3678e-04, 1.6901e-01]]])
agent 0 action: VehicleControl(throttle=0.662897, steer=0.001757, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.403428201339393
Current mitigation activation: 0
#############################
Total reward: 46.128595511861164
8.535827539861202 seconds in game passed.
Action: tensor([[[5.1815e-03, 5.9935e-01],
         [1.6788e-03, 3.2400e-01],
         [1.0775e-03, 2.2237e-01],
         [2.3678e-04, 1.6901e-01]]])
agent 0 action: VehicleControl(throttle=0.622206, steer=0.002814, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.128595511861164
8.560827540233731 seconds in game passed.
Action: tensor([[[5.1815e-03, 5.9935e-01],
         [1.6788e-03, 3.2400e-01],
         [1.0775e-03, 2.2237e-01],
         [2.3678e-04, 1.6901e-01]]])
agent 0 action: VehicleControl(throttle=0.628410, steer=0.002872, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.128595511861164
8.58582754060626 seconds in game passed.
Action: tensor([[[5.1815e-03, 5.9935e-01],
         [1.6788e-03, 3.2400e-01],
         [1.0775e-03, 2.2237e-01],
         [2.3678e-04, 1.6901e-01]]])
agent 0 action: VehicleControl(throttle=0.634458, steer=0.002931, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 46.128595511861164
+++++++++++++: inf
8.61082754097879 seconds in game passed.
At 8.61082754097879 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.4622e-03,  5.9390e-01],
         [-1.1783e-04,  3.2332e-01],
         [-6.6251e-04,  2.2243e-01],
         [-1.2516e-03,  1.6905e-01]]])
agent 0 action: VehicleControl(throttle=0.605694, steer=0.000970, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4013324890603942
Current mitigation activation: 0
#############################
Total reward: 47.52992800092156
8.635827541351318 seconds in game passed.
Action: tensor([[[ 3.4622e-03,  5.9390e-01],
         [-1.1783e-04,  3.2332e-01],
         [-6.6251e-04,  2.2243e-01],
         [-1.2516e-03,  1.6905e-01]]])
agent 0 action: VehicleControl(throttle=0.614329, steer=0.001321, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52992800092156
8.660827541723847 seconds in game passed.
Action: tensor([[[ 3.4622e-03,  5.9390e-01],
         [-1.1783e-04,  3.2332e-01],
         [-6.6251e-04,  2.2243e-01],
         [-1.2516e-03,  1.6905e-01]]])
agent 0 action: VehicleControl(throttle=0.619145, steer=0.001342, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52992800092156
8.685827542096376 seconds in game passed.
Action: tensor([[[ 3.4622e-03,  5.9390e-01],
         [-1.1783e-04,  3.2332e-01],
         [-6.6251e-04,  2.2243e-01],
         [-1.2516e-03,  1.6905e-01]]])
agent 0 action: VehicleControl(throttle=0.623784, steer=0.001363, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 47.52992800092156
+++++++++++++: inf
8.710827542468905 seconds in game passed.
At 8.710827542468905 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.6492e-04,  5.9661e-01],
         [-9.1627e-04,  3.2298e-01],
         [-1.1251e-03,  2.2172e-01],
         [-1.3680e-03,  1.6838e-01]]])
agent 0 action: VehicleControl(throttle=0.670610, steer=-0.000527, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.3992601780479248
Current mitigation activation: 0
#############################
Total reward: 48.92918817896948
8.735827542841434 seconds in game passed.
Action: tensor([[[ 1.6492e-04,  5.9661e-01],
         [-9.1627e-04,  3.2298e-01],
         [-1.1251e-03,  2.2172e-01],
         [-1.3680e-03,  1.6838e-01]]])
agent 0 action: VehicleControl(throttle=0.670632, steer=-0.000214, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92918817896948
8.760827543213964 seconds in game passed.
Action: tensor([[[ 1.6492e-04,  5.9661e-01],
         [-9.1627e-04,  3.2298e-01],
         [-1.1251e-03,  2.2172e-01],
         [-1.3680e-03,  1.6838e-01]]])
agent 0 action: VehicleControl(throttle=0.654754, steer=-0.000216, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92918817896948
8.785827543586493 seconds in game passed.
Action: tensor([[[ 1.6492e-04,  5.9661e-01],
         [-9.1627e-04,  3.2298e-01],
         [-1.1251e-03,  2.2172e-01],
         [-1.3680e-03,  1.6838e-01]]])
agent 0 action: VehicleControl(throttle=0.642204, steer=-0.000218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 48.92918817896948
+++++++++++++: inf
8.810827543959022 seconds in game passed.
At 8.810827543959022 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0023,  0.6086],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.617672, steer=-0.003265, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4044283882034305
Current mitigation activation: 0
#############################
Total reward: 50.33361656717291
8.83582754433155 seconds in game passed.
Action: tensor([[[-0.0023,  0.6086],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.607471, steer=-0.002810, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33361656717291
8.86082754470408 seconds in game passed.
Action: tensor([[[-0.0023,  0.6086],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.596090, steer=-0.002856, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33361656717291
8.885827545076609 seconds in game passed.
Action: tensor([[[-0.0023,  0.6086],
         [-0.0037,  0.3268],
         [-0.0038,  0.2227],
         [-0.0040,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.584980, steer=-0.002901, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 50.33361656717291
+++++++++++++: inf
8.910827545449138 seconds in game passed.
At 8.910827545449138 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0046,  0.6108],
         [-0.0062,  0.3281],
         [-0.0067,  0.2238],
         [-0.0070,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.550285, steer=-0.005731, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4220219657226738
Current mitigation activation: 0
#############################
Total reward: 51.75563853289558
8.935827545821667 seconds in game passed.
Action: tensor([[[-0.0046,  0.6108],
         [-0.0062,  0.3281],
         [-0.0067,  0.2238],
         [-0.0070,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.541752, steer=-0.005329, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.75563853289558
8.960827546194196 seconds in game passed.
Action: tensor([[[-0.0046,  0.6108],
         [-0.0062,  0.3281],
         [-0.0067,  0.2238],
         [-0.0070,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.531113, steer=-0.005388, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.75563853289558
8.985827546566725 seconds in game passed.
Action: tensor([[[-0.0046,  0.6108],
         [-0.0062,  0.3281],
         [-0.0067,  0.2238],
         [-0.0070,  0.1700]]])
agent 0 action: VehicleControl(throttle=0.520981, steer=-0.005448, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 51.75563853289558
+++++++++++++: inf
9.010827546939254 seconds in game passed.
At 9.010827546939254 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.5991],
         [-0.0026,  0.3244],
         [-0.0029,  0.2226],
         [-0.0032,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.521728, steer=-0.001632, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4369175723131054
Current mitigation activation: 0
#############################
Total reward: 53.19255610520869
9.035827547311783 seconds in game passed.
Action: tensor([[[-0.0016,  0.5991],
         [-0.0026,  0.3244],
         [-0.0029,  0.2226],
         [-0.0032,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.511685, steer=-0.002258, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19255610520869
9.060827547684312 seconds in game passed.
Action: tensor([[[-0.0016,  0.5991],
         [-0.0026,  0.3244],
         [-0.0029,  0.2226],
         [-0.0032,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.503139, steer=-0.002249, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19255610520869
9.085827548056841 seconds in game passed.
Action: tensor([[[-0.0016,  0.5991],
         [-0.0026,  0.3244],
         [-0.0029,  0.2226],
         [-0.0032,  0.1696]]])
agent 0 action: VehicleControl(throttle=0.494944, steer=-0.002241, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 53.19255610520869
+++++++++++++: inf
9.11082754842937 seconds in game passed.
At 9.11082754842937 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 3.1109e-03,  6.0701e-01],
         [ 1.1218e-03,  3.2926e-01],
         [ 5.3673e-04,  2.2575e-01],
         [-3.3463e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.393981, steer=0.002444, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.448334286070377
Current mitigation activation: 0
#############################
Total reward: 54.640890391279065
9.135827548801899 seconds in game passed.
Action: tensor([[[ 3.1109e-03,  6.0701e-01],
         [ 1.1218e-03,  3.2926e-01],
         [ 5.3673e-04,  2.2575e-01],
         [-3.3463e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.394949, steer=0.001744, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.640890391279065
9.160827549174428 seconds in game passed.
Action: tensor([[[ 3.1109e-03,  6.0701e-01],
         [ 1.1218e-03,  3.2926e-01],
         [ 5.3673e-04,  2.2575e-01],
         [-3.3463e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.386725, steer=0.001813, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.640890391279065
9.185827549546957 seconds in game passed.
Action: tensor([[[ 3.1109e-03,  6.0701e-01],
         [ 1.1218e-03,  3.2926e-01],
         [ 5.3673e-04,  2.2575e-01],
         [-3.3463e-04,  1.7179e-01]]])
agent 0 action: VehicleControl(throttle=0.379656, steer=0.001882, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 54.640890391279065
+++++++++++++: inf
9.210827549919486 seconds in game passed.
At 9.210827549919486 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0078, 0.6341],
         [0.0034, 0.3539],
         [0.0028, 0.2475],
         [0.0019, 0.1911]]])
agent 0 action: VehicleControl(throttle=0.142096, steer=0.005587, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4563981534360768
Current mitigation activation: 0
#############################
Total reward: 56.09728854471514
9.235827550292015 seconds in game passed.
Action: tensor([[[0.0078, 0.6341],
         [0.0034, 0.3539],
         [0.0028, 0.2475],
         [0.0019, 0.1911]]])
agent 0 action: VehicleControl(throttle=0.161565, steer=0.005061, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09728854471514
9.260827550664544 seconds in game passed.
Action: tensor([[[0.0078, 0.6341],
         [0.0034, 0.3539],
         [0.0028, 0.2475],
         [0.0019, 0.1911]]])
agent 0 action: VehicleControl(throttle=0.156082, steer=0.005139, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09728854471514
9.285827551037073 seconds in game passed.
Action: tensor([[[0.0078, 0.6341],
         [0.0034, 0.3539],
         [0.0028, 0.2475],
         [0.0019, 0.1911]]])
agent 0 action: VehicleControl(throttle=0.150579, steer=0.005218, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 56.09728854471514
+++++++++++++: inf
9.310827551409602 seconds in game passed.
At 9.310827551409602 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0071, 0.6172],
         [0.0030, 0.3403],
         [0.0021, 0.2368],
         [0.0012, 0.1828]]])
agent 0 action: VehicleControl(throttle=0.148407, steer=0.004570, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4594231861608393
Current mitigation activation: 0
#############################
Total reward: 57.55671173087598
9.335827551782131 seconds in game passed.
Action: tensor([[[0.0071, 0.6172],
         [0.0030, 0.3403],
         [0.0021, 0.2368],
         [0.0012, 0.1828]]])
agent 0 action: VehicleControl(throttle=0.146214, steer=0.004698, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55671173087598
9.36082755215466 seconds in game passed.
Action: tensor([[[0.0071, 0.6172],
         [0.0030, 0.3403],
         [0.0021, 0.2368],
         [0.0012, 0.1828]]])
agent 0 action: VehicleControl(throttle=0.144001, steer=0.004715, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55671173087598
9.38582755252719 seconds in game passed.
Action: tensor([[[0.0071, 0.6172],
         [0.0030, 0.3403],
         [0.0021, 0.2368],
         [0.0012, 0.1828]]])
agent 0 action: VehicleControl(throttle=0.141767, steer=0.004733, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 57.55671173087598
+++++++++++++: inf
9.410827552899718 seconds in game passed.
At 9.410827552899718 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 6.2562e-03,  6.1920e-01],
         [ 1.1913e-03,  3.3713e-01],
         [ 2.4801e-04,  2.3280e-01],
         [-5.8536e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.251743, steer=0.003016, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.454315350333602
Current mitigation activation: 0
#############################
Total reward: 59.01102708120958
9.435827553272247 seconds in game passed.
Action: tensor([[[ 6.2562e-03,  6.1920e-01],
         [ 1.1913e-03,  3.3713e-01],
         [ 2.4801e-04,  2.3280e-01],
         [-5.8536e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.250440, steer=0.003230, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01102708120958
9.460827553644776 seconds in game passed.
Action: tensor([[[ 6.2562e-03,  6.1920e-01],
         [ 1.1913e-03,  3.3713e-01],
         [ 2.4801e-04,  2.3280e-01],
         [-5.8536e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.260423, steer=0.003169, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01102708120958
9.485827554017305 seconds in game passed.
Action: tensor([[[ 6.2562e-03,  6.1920e-01],
         [ 1.1913e-03,  3.3713e-01],
         [ 2.4801e-04,  2.3280e-01],
         [-5.8536e-04,  1.7866e-01]]])
agent 0 action: VehicleControl(throttle=0.270148, steer=0.003108, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 59.01102708120958
+++++++++++++: inf
9.510827554389834 seconds in game passed.
At 9.510827554389834 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 0.0010,  0.6155],
         [-0.0016,  0.3331],
         [-0.0023,  0.2287],
         [-0.0032,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.377276, steer=-0.001104, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4435803657066457
Current mitigation activation: 0
#############################
Total reward: 60.45460744691623
9.535827554762363 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6155],
         [-0.0016,  0.3331],
         [-0.0023,  0.2287],
         [-0.0032,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.371969, steer=-0.000452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.45460744691623
9.560827555134892 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6155],
         [-0.0016,  0.3331],
         [-0.0023,  0.2287],
         [-0.0032,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.377089, steer=-0.000494, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.45460744691623
9.585827555507421 seconds in game passed.
Action: tensor([[[ 0.0010,  0.6155],
         [-0.0016,  0.3331],
         [-0.0023,  0.2287],
         [-0.0032,  0.1751]]])
agent 0 action: VehicleControl(throttle=0.381180, steer=-0.000537, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 60.45460744691623
+++++++++++++: inf
9.61082755587995 seconds in game passed.
At 9.61082755587995 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0033,  0.6172],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0067,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.488943, steer=-0.004699, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4328174528101867
Current mitigation activation: 0
#############################
Total reward: 61.88742489972641
9.63582755625248 seconds in game passed.
Action: tensor([[[-0.0033,  0.6172],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0067,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.482058, steer=-0.004081, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88742489972641
9.660827556625009 seconds in game passed.
Action: tensor([[[-0.0033,  0.6172],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0067,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.485411, steer=-0.004145, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88742489972641
9.685827556997538 seconds in game passed.
Action: tensor([[[-0.0033,  0.6172],
         [-0.0049,  0.3307],
         [-0.0057,  0.2248],
         [-0.0067,  0.1713]]])
agent 0 action: VehicleControl(throttle=0.487372, steer=-0.004210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 61.88742489972641
+++++++++++++: inf
9.710827557370067 seconds in game passed.
At 9.710827557370067 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0067,  0.6246],
         [-0.0107,  0.3318],
         [-0.0123,  0.2247],
         [-0.0133,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.523689, steer=-0.009922, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4257041337700476
Current mitigation activation: 0
#############################
Total reward: 63.31312903349646
9.735827557742596 seconds in game passed.
Action: tensor([[[-0.0067,  0.6246],
         [-0.0107,  0.3318],
         [-0.0123,  0.2247],
         [-0.0133,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.519778, steer=-0.009091, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31312903349646
9.760827558115125 seconds in game passed.
Action: tensor([[[-0.0067,  0.6246],
         [-0.0107,  0.3318],
         [-0.0123,  0.2247],
         [-0.0133,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.519082, steer=-0.009194, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31312903349646
9.785827558487654 seconds in game passed.
Action: tensor([[[-0.0067,  0.6246],
         [-0.0107,  0.3318],
         [-0.0123,  0.2247],
         [-0.0133,  0.1714]]])
agent 0 action: VehicleControl(throttle=0.517572, steer=-0.009297, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 63.31312903349646
+++++++++++++: inf
9.810827558860183 seconds in game passed.
At 9.810827558860183 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6134],
         [-0.0043,  0.3289],
         [-0.0046,  0.2239],
         [-0.0045,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.503448, steer=-0.002896, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4236164378900222
Current mitigation activation: 0
#############################
Total reward: 64.73674547138648
9.835827559232712 seconds in game passed.
Action: tensor([[[-0.0024,  0.6134],
         [-0.0043,  0.3289],
         [-0.0046,  0.2239],
         [-0.0045,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.502244, steer=-0.003969, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73674547138648
9.86082755960524 seconds in game passed.
Action: tensor([[[-0.0024,  0.6134],
         [-0.0043,  0.3289],
         [-0.0046,  0.2239],
         [-0.0045,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.499409, steer=-0.003974, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73674547138648
9.88582755997777 seconds in game passed.
Action: tensor([[[-0.0024,  0.6134],
         [-0.0043,  0.3289],
         [-0.0046,  0.2239],
         [-0.0045,  0.1706]]])
agent 0 action: VehicleControl(throttle=0.496448, steer=-0.003980, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 64.73674547138648
+++++++++++++: inf
9.910827560350299 seconds in game passed.
At 9.910827560350299 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-5.9046e-04,  6.0293e-01],
         [-2.2688e-03,  3.2559e-01],
         [-2.8639e-03,  2.2255e-01],
         [-3.2670e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.505131, steer=-0.001707, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4255242253497298
Current mitigation activation: 0
#############################
Total reward: 66.16226969673622
9.935827560722828 seconds in game passed.
Action: tensor([[[-5.9046e-04,  6.0293e-01],
         [-2.2688e-03,  3.2559e-01],
         [-2.8639e-03,  2.2255e-01],
         [-3.2670e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.501202, steer=-0.002031, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16226969673622
9.960827561095357 seconds in game passed.
Action: tensor([[[-5.9046e-04,  6.0293e-01],
         [-2.2688e-03,  3.2559e-01],
         [-2.8639e-03,  2.2255e-01],
         [-3.2670e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.498448, steer=-0.001984, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16226969673622
9.985827561467886 seconds in game passed.
Action: tensor([[[-5.9046e-04,  6.0293e-01],
         [-2.2688e-03,  3.2559e-01],
         [-2.8639e-03,  2.2255e-01],
         [-3.2670e-03,  1.6889e-01]]])
agent 0 action: VehicleControl(throttle=0.495625, steer=-0.001938, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 66.16226969673622
+++++++++++++: inf
10.010827561840415 seconds in game passed.
At 10.010827561840415 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.9732e-03,  6.2300e-01],
         [ 6.9628e-04,  3.3255e-01],
         [ 1.0543e-04,  2.2676e-01],
         [-4.5293e-04,  1.7249e-01]]])
agent 0 action: VehicleControl(throttle=0.449870, steer=0.001672, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4291776846699171
Current mitigation activation: 0
#############################
Total reward: 67.59144738140614
10.035827562212944 seconds in game passed.
Action: tensor([[[ 2.9732e-03,  6.2300e-01],
         [ 6.9628e-04,  3.3255e-01],
         [ 1.0543e-04,  2.2676e-01],
         [-4.5293e-04,  1.7249e-01]]])
agent 0 action: VehicleControl(throttle=0.451001, steer=0.001122, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59144738140614
10.060827562585473 seconds in game passed.
Action: tensor([[[ 2.9732e-03,  6.2300e-01],
         [ 6.9628e-04,  3.3255e-01],
         [ 1.0543e-04,  2.2676e-01],
         [-4.5293e-04,  1.7249e-01]]])
agent 0 action: VehicleControl(throttle=0.447772, steer=0.001166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59144738140614
10.085827562958002 seconds in game passed.
Action: tensor([[[ 2.9732e-03,  6.2300e-01],
         [ 6.9628e-04,  3.3255e-01],
         [ 1.0543e-04,  2.2676e-01],
         [-4.5293e-04,  1.7249e-01]]])
agent 0 action: VehicleControl(throttle=0.444970, steer=0.001210, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 67.59144738140614
+++++++++++++: inf
10.110827563330531 seconds in game passed.
At 10.110827563330531 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.2786e-03, 6.1145e-01],
         [7.2438e-04, 3.2725e-01],
         [7.2950e-04, 2.2302e-01],
         [5.1445e-04, 1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.515658, steer=0.000555, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.433289410360439
Current mitigation activation: 0
#############################
Total reward: 69.02473679176659
10.13582756370306 seconds in game passed.
Action: tensor([[[1.2786e-03, 6.1145e-01],
         [7.2438e-04, 3.2725e-01],
         [7.2950e-04, 2.2302e-01],
         [5.1445e-04, 1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.507667, steer=0.000652, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.02473679176659
10.16082756407559 seconds in game passed.
Action: tensor([[[1.2786e-03, 6.1145e-01],
         [7.2438e-04, 3.2725e-01],
         [7.2950e-04, 2.2302e-01],
         [5.1445e-04, 1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.507389, steer=0.000641, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.02473679176659
10.185827564448118 seconds in game passed.
Action: tensor([[[1.2786e-03, 6.1145e-01],
         [7.2438e-04, 3.2725e-01],
         [7.2950e-04, 2.2302e-01],
         [5.1445e-04, 1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.506719, steer=0.000631, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 69.02473679176659
+++++++++++++: inf
10.210827564820647 seconds in game passed.
At 10.210827564820647 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0025, 0.6136],
         [0.0015, 0.3274],
         [0.0019, 0.2229],
         [0.0022, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.524357, steer=0.001669, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4366875837265254
Current mitigation activation: 0
#############################
Total reward: 70.46142437549311
10.235827565193176 seconds in game passed.
Action: tensor([[[0.0025, 0.6136],
         [0.0015, 0.3274],
         [0.0019, 0.2229],
         [0.0022, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.524284, steer=0.001452, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46142437549311
10.260827565565705 seconds in game passed.
Action: tensor([[[0.0025, 0.6136],
         [0.0015, 0.3274],
         [0.0019, 0.2229],
         [0.0022, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.525664, steer=0.001415, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46142437549311
10.285827565938234 seconds in game passed.
Action: tensor([[[0.0025, 0.6136],
         [0.0015, 0.3274],
         [0.0019, 0.2229],
         [0.0022, 0.1688]]])
agent 0 action: VehicleControl(throttle=0.526716, steer=0.001378, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 70.46142437549311
+++++++++++++: inf
10.310827566310763 seconds in game passed.
At 10.310827566310763 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[3.2713e-04, 5.9823e-01],
         [6.5880e-04, 3.2312e-01],
         [1.0617e-03, 2.2109e-01],
         [1.0683e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.523037, steer=-0.000166, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4406497856873886
Current mitigation activation: 0
#############################
Total reward: 71.9020741611805
10.335827566683292 seconds in game passed.
Action: tensor([[[3.2713e-04, 5.9823e-01],
         [6.5880e-04, 3.2312e-01],
         [1.0617e-03, 2.2109e-01],
         [1.0683e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.524001, steer=0.000038, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.9020741611805
10.360827567055821 seconds in game passed.
Action: tensor([[[3.2713e-04, 5.9823e-01],
         [6.5880e-04, 3.2312e-01],
         [1.0617e-03, 2.2109e-01],
         [1.0683e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.524287, steer=-0.000008, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.9020741611805
10.38582756742835 seconds in game passed.
Action: tensor([[[3.2713e-04, 5.9823e-01],
         [6.5880e-04, 3.2312e-01],
         [1.0617e-03, 2.2109e-01],
         [1.0683e-03, 1.6780e-01]]])
agent 0 action: VehicleControl(throttle=0.524413, steer=-0.000054, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 71.9020741611805
+++++++++++++: inf
10.41082756780088 seconds in game passed.
At 10.41082756780088 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 1.0180e-04,  6.0151e-01],
         [-4.5531e-04,  3.2502e-01],
         [ 9.3058e-06,  2.2246e-01],
         [ 3.7784e-04,  1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.488176, steer=-0.000993, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.445695427090258
Current mitigation activation: 0
#############################
Total reward: 73.34776958827075
10.435827568173409 seconds in game passed.
Action: tensor([[[ 1.0180e-04,  6.0151e-01],
         [-4.5531e-04,  3.2502e-01],
         [ 9.3058e-06,  2.2246e-01],
         [ 3.7784e-04,  1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.489997, steer=-0.000881, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.34776958827075
10.460827568545938 seconds in game passed.
Action: tensor([[[ 1.0180e-04,  6.0151e-01],
         [-4.5531e-04,  3.2502e-01],
         [ 9.3058e-06,  2.2246e-01],
         [ 3.7784e-04,  1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.487973, steer=-0.000919, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.34776958827075
10.485827568918467 seconds in game passed.
Action: tensor([[[ 1.0180e-04,  6.0151e-01],
         [-4.5531e-04,  3.2502e-01],
         [ 9.3058e-06,  2.2246e-01],
         [ 3.7784e-04,  1.6922e-01]]])
agent 0 action: VehicleControl(throttle=0.486043, steer=-0.000957, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 73.34776958827075
+++++++++++++: inf
10.510827569290996 seconds in game passed.
At 10.510827569290996 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0011, 0.5961],
         [0.0009, 0.3223],
         [0.0018, 0.2206],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.527030, steer=0.000453, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4512549785043378
Current mitigation activation: 0
#############################
Total reward: 74.79902456677509
10.535827569663525 seconds in game passed.
Action: tensor([[[0.0011, 0.5961],
         [0.0009, 0.3223],
         [0.0018, 0.2206],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.519821, steer=0.000242, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79902456677509
10.560827570036054 seconds in game passed.
Action: tensor([[[0.0011, 0.5961],
         [0.0009, 0.3223],
         [0.0018, 0.2206],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.517168, steer=0.000262, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79902456677509
10.585827570408583 seconds in game passed.
Action: tensor([[[0.0011, 0.5961],
         [0.0009, 0.3223],
         [0.0018, 0.2206],
         [0.0026, 0.1675]]])
agent 0 action: VehicleControl(throttle=0.514159, steer=0.000282, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 74.79902456677509
+++++++++++++: inf
10.610827570781112 seconds in game passed.
At 10.610827570781112 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0020, 0.5975],
         [0.0029, 0.3233],
         [0.0037, 0.2212],
         [0.0041, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.487452, steer=0.002157, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4563777345547388
Current mitigation activation: 0
#############################
Total reward: 76.25540230132982
10.63582757115364 seconds in game passed.
Action: tensor([[[0.0020, 0.5975],
         [0.0029, 0.3233],
         [0.0037, 0.2212],
         [0.0041, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.485030, steer=0.001939, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.25540230132982
10.66082757152617 seconds in game passed.
Action: tensor([[[0.0020, 0.5975],
         [0.0029, 0.3233],
         [0.0037, 0.2212],
         [0.0041, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.480191, steer=0.002020, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.25540230132982
10.685827571898699 seconds in game passed.
Action: tensor([[[0.0020, 0.5975],
         [0.0029, 0.3233],
         [0.0037, 0.2212],
         [0.0041, 0.1678]]])
agent 0 action: VehicleControl(throttle=0.475477, steer=0.002102, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 76.25540230132982
+++++++++++++: inf
10.710827572271228 seconds in game passed.
At 10.710827572271228 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0012, 0.6148],
         [0.0009, 0.3325],
         [0.0012, 0.2276],
         [0.0010, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.319129, steer=0.000471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.461523941816971
Current mitigation activation: 0
#############################
Total reward: 77.7169262431468
10.735827572643757 seconds in game passed.
Action: tensor([[[0.0012, 0.6148],
         [0.0009, 0.3325],
         [0.0012, 0.2276],
         [0.0010, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.328646, steer=0.000885, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.7169262431468
10.760827573016286 seconds in game passed.
Action: tensor([[[0.0012, 0.6148],
         [0.0009, 0.3325],
         [0.0012, 0.2276],
         [0.0010, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.322627, steer=0.001006, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.7169262431468
10.785827573388815 seconds in game passed.
Action: tensor([[[0.0012, 0.6148],
         [0.0009, 0.3325],
         [0.0012, 0.2276],
         [0.0010, 0.1734]]])
agent 0 action: VehicleControl(throttle=0.318084, steer=0.001128, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 77.7169262431468
+++++++++++++: inf
10.810827573761344 seconds in game passed.
At 10.810827573761344 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0033, 0.6142],
         [0.0016, 0.3291],
         [0.0017, 0.2255],
         [0.0016, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.427482, steer=0.002513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4656465094521622
Current mitigation activation: 0
#############################
Total reward: 79.18257275259896
10.835827574133873 seconds in game passed.
Action: tensor([[[0.0033, 0.6142],
         [0.0016, 0.3291],
         [0.0017, 0.2255],
         [0.0016, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.414462, steer=0.002362, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.18257275259896
10.860827574506402 seconds in game passed.
Action: tensor([[[0.0033, 0.6142],
         [0.0016, 0.3291],
         [0.0017, 0.2255],
         [0.0016, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.414030, steer=0.002430, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.18257275259896
10.885827574878931 seconds in game passed.
Action: tensor([[[0.0033, 0.6142],
         [0.0016, 0.3291],
         [0.0017, 0.2255],
         [0.0016, 0.1713]]])
agent 0 action: VehicleControl(throttle=0.413414, steer=0.002499, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 79.18257275259896
+++++++++++++: inf
10.91082757525146 seconds in game passed.
At 10.91082757525146 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.7167e-03, 6.0892e-01],
         [6.1712e-04, 3.2480e-01],
         [7.3306e-04, 2.2161e-01],
         [5.3046e-04, 1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.517170, steer=0.001197, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.465846114656423
Current mitigation activation: 0
#############################
Total reward: 80.64841886725539
10.935827575623989 seconds in game passed.
Action: tensor([[[1.7167e-03, 6.0892e-01],
         [6.1712e-04, 3.2480e-01],
         [7.3306e-04, 2.2161e-01],
         [5.3046e-04, 1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.506510, steer=0.001451, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64841886725539
10.960827575996518 seconds in game passed.
Action: tensor([[[1.7167e-03, 6.0892e-01],
         [6.1712e-04, 3.2480e-01],
         [7.3306e-04, 2.2161e-01],
         [5.3046e-04, 1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.506715, steer=0.001482, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64841886725539
10.985827576369047 seconds in game passed.
Action: tensor([[[1.7167e-03, 6.0892e-01],
         [6.1712e-04, 3.2480e-01],
         [7.3306e-04, 2.2161e-01],
         [5.3046e-04, 1.6787e-01]]])
agent 0 action: VehicleControl(throttle=0.506078, steer=0.001513, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 80.64841886725539
+++++++++++++: inf
11.010827576741576 seconds in game passed.
At 11.010827576741576 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[1.4281e-03, 6.0656e-01],
         [1.7630e-04, 3.2440e-01],
         [3.5058e-04, 2.2158e-01],
         [2.0072e-04, 1.6788e-01]]])
agent 0 action: VehicleControl(throttle=0.495033, steer=0.001068, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.465008616221582
Current mitigation activation: 0
#############################
Total reward: 82.11342748347697
11.035827577114105 seconds in game passed.
Action: tensor([[[1.4281e-03, 6.0656e-01],
         [1.7630e-04, 3.2440e-01],
         [3.5058e-04, 2.2158e-01],
         [2.0072e-04, 1.6788e-01]]])
agent 0 action: VehicleControl(throttle=0.494787, steer=0.001130, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.11342748347697
11.060827577486634 seconds in game passed.
Action: tensor([[[1.4281e-03, 6.0656e-01],
         [1.7630e-04, 3.2440e-01],
         [3.5058e-04, 2.2158e-01],
         [2.0072e-04, 1.6788e-01]]])
agent 0 action: VehicleControl(throttle=0.493079, steer=0.001120, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.11342748347697
11.085827577859163 seconds in game passed.
Action: tensor([[[1.4281e-03, 6.0656e-01],
         [1.7630e-04, 3.2440e-01],
         [3.5058e-04, 2.2158e-01],
         [2.0072e-04, 1.6788e-01]]])
agent 0 action: VehicleControl(throttle=0.491134, steer=0.001109, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 82.11342748347697
+++++++++++++: inf
11.110827578231692 seconds in game passed.
At 11.110827578231692 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[ 2.6873e-04,  6.1962e-01],
         [ 1.3033e-04,  3.2787e-01],
         [ 3.2543e-04,  2.2397e-01],
         [-5.3331e-05,  1.7056e-01]]])
agent 0 action: VehicleControl(throttle=0.496630, steer=0.000613, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4663821388146943
Current mitigation activation: 0
#############################
Total reward: 83.57980962229166
11.135827578604221 seconds in game passed.
Action: tensor([[[ 2.6873e-04,  6.1962e-01],
         [ 1.3033e-04,  3.2787e-01],
         [ 3.2543e-04,  2.2397e-01],
         [-5.3331e-05,  1.7056e-01]]])
agent 0 action: VehicleControl(throttle=0.492724, steer=0.000685, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.57980962229166
11.16082757897675 seconds in game passed.
Action: tensor([[[ 2.6873e-04,  6.1962e-01],
         [ 1.3033e-04,  3.2787e-01],
         [ 3.2543e-04,  2.2397e-01],
         [-5.3331e-05,  1.7056e-01]]])
agent 0 action: VehicleControl(throttle=0.489576, steer=0.000677, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.57980962229166
11.18582757934928 seconds in game passed.
Action: tensor([[[ 2.6873e-04,  6.1962e-01],
         [ 1.3033e-04,  3.2787e-01],
         [ 3.2543e-04,  2.2397e-01],
         [-5.3331e-05,  1.7056e-01]]])
agent 0 action: VehicleControl(throttle=0.486292, steer=0.000668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 83.57980962229166
+++++++++++++: inf
11.210827579721808 seconds in game passed.
At 11.210827579721808 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0014,  0.6258],
         [-0.0020,  0.3274],
         [-0.0023,  0.2224],
         [-0.0033,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.562098, steer=-0.001586, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.469316093408552
Current mitigation activation: 0
#############################
Total reward: 85.04912571570021
11.235827580094337 seconds in game passed.
Action: tensor([[[-0.0014,  0.6258],
         [-0.0020,  0.3274],
         [-0.0023,  0.2224],
         [-0.0033,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.551006, steer=-0.001261, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.04912571570021
11.260827580466866 seconds in game passed.
Action: tensor([[[-0.0014,  0.6258],
         [-0.0020,  0.3274],
         [-0.0023,  0.2224],
         [-0.0033,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.548110, steer=-0.001303, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.04912571570021
11.285827580839396 seconds in game passed.
Action: tensor([[[-0.0014,  0.6258],
         [-0.0020,  0.3274],
         [-0.0023,  0.2224],
         [-0.0033,  0.1689]]])
agent 0 action: VehicleControl(throttle=0.544561, steer=-0.001346, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 85.04912571570021
+++++++++++++: inf
11.310827581211925 seconds in game passed.
At 11.310827581211925 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-1.1113e-03,  6.2319e-01],
         [-6.4131e-04,  3.2723e-01],
         [-3.9573e-04,  2.2277e-01],
         [-9.8270e-04,  1.6950e-01]]])
agent 0 action: VehicleControl(throttle=0.521163, steer=-0.000255, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.472997156354349
Current mitigation activation: 0
#############################
Total reward: 86.52212287205457
11.335827581584454 seconds in game passed.
Action: tensor([[[-1.1113e-03,  6.2319e-01],
         [-6.4131e-04,  3.2723e-01],
         [-3.9573e-04,  2.2277e-01],
         [-9.8270e-04,  1.6950e-01]]])
agent 0 action: VehicleControl(throttle=0.518816, steer=-0.000455, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52212287205457
11.360827581956983 seconds in game passed.
Action: tensor([[[-1.1113e-03,  6.2319e-01],
         [-6.4131e-04,  3.2723e-01],
         [-3.9573e-04,  2.2277e-01],
         [-9.8270e-04,  1.6950e-01]]])
agent 0 action: VehicleControl(throttle=0.514230, steer=-0.000471, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52212287205457
11.385827582329512 seconds in game passed.
Action: tensor([[[-1.1113e-03,  6.2319e-01],
         [-6.4131e-04,  3.2723e-01],
         [-3.9573e-04,  2.2277e-01],
         [-9.8270e-04,  1.6950e-01]]])
agent 0 action: VehicleControl(throttle=0.509661, steer=-0.000487, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 86.52212287205457
+++++++++++++: inf
11.41082758270204 seconds in game passed.
At 11.41082758270204 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0016,  0.6098],
         [-0.0022,  0.3239],
         [-0.0018,  0.2219],
         [-0.0020,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.491261, steer=-0.001828, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4781625642576275
Current mitigation activation: 0
#############################
Total reward: 88.0002854363122
11.43582758307457 seconds in game passed.
Action: tensor([[[-0.0016,  0.6098],
         [-0.0022,  0.3239],
         [-0.0018,  0.2219],
         [-0.0020,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.488516, steer=-0.001628, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.0002854363122
11.460827583447099 seconds in game passed.
Action: tensor([[[-0.0016,  0.6098],
         [-0.0022,  0.3239],
         [-0.0018,  0.2219],
         [-0.0020,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.484398, steer=-0.001648, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.0002854363122
11.485827583819628 seconds in game passed.
Action: tensor([[[-0.0016,  0.6098],
         [-0.0022,  0.3239],
         [-0.0018,  0.2219],
         [-0.0020,  0.1686]]])
agent 0 action: VehicleControl(throttle=0.480513, steer=-0.001668, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 88.0002854363122
+++++++++++++: inf
11.510827584192157 seconds in game passed.
At 11.510827584192157 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0024,  0.6159],
         [-0.0024,  0.3265],
         [-0.0024,  0.2227],
         [-0.0033,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.444086, steer=-0.002181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4836846899785336
Current mitigation activation: 0
#############################
Total reward: 89.48397012629073
11.535827584564686 seconds in game passed.
Action: tensor([[[-0.0024,  0.6159],
         [-0.0024,  0.3265],
         [-0.0024,  0.2227],
         [-0.0033,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.443204, steer=-0.002142, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.48397012629073
11.560827584937215 seconds in game passed.
Action: tensor([[[-0.0024,  0.6159],
         [-0.0024,  0.3265],
         [-0.0024,  0.2227],
         [-0.0033,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.439211, steer=-0.002181, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.48397012629073
11.585827585309744 seconds in game passed.
Action: tensor([[[-0.0024,  0.6159],
         [-0.0024,  0.3265],
         [-0.0024,  0.2227],
         [-0.0033,  0.1692]]])
agent 0 action: VehicleControl(throttle=0.435720, steer=-0.002221, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 89.48397012629073
+++++++++++++: inf
11.610827585682273 seconds in game passed.
At 11.610827585682273 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0035, 0.6228],
         [0.0046, 0.3273],
         [0.0055, 0.2229],
         [0.0053, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.471411, steer=0.005235, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4882685325009741
Current mitigation activation: 0
#############################
Total reward: 90.9722386587917
11.635827586054802 seconds in game passed.
Action: tensor([[[0.0035, 0.6228],
         [0.0046, 0.3273],
         [0.0055, 0.2229],
         [0.0053, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.465308, steer=0.004015, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.9722386587917
11.660827586427331 seconds in game passed.
Action: tensor([[[0.0035, 0.6228],
         [0.0046, 0.3273],
         [0.0055, 0.2229],
         [0.0053, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.463587, steer=0.004034, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.9722386587917
11.68582758679986 seconds in game passed.
Action: tensor([[[0.0035, 0.6228],
         [0.0046, 0.3273],
         [0.0055, 0.2229],
         [0.0053, 0.1696]]])
agent 0 action: VehicleControl(throttle=0.461811, steer=0.004053, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 90.9722386587917
+++++++++++++: inf
11.710827587172389 seconds in game passed.
At 11.710827587172389 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0047, 0.6288],
         [0.0049, 0.3358],
         [0.0053, 0.2315],
         [0.0051, 0.1775]]])
agent 0 action: VehicleControl(throttle=0.220769, steer=0.004784, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4912253535429059
Current mitigation activation: 0
#############################
Total reward: 92.4634640123346
11.735827587544918 seconds in game passed.
Action: tensor([[[0.0047, 0.6288],
         [0.0049, 0.3358],
         [0.0053, 0.2315],
         [0.0051, 0.1775]]])
agent 0 action: VehicleControl(throttle=0.243686, steer=0.004714, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.4634640123346
11.760827587917447 seconds in game passed.
Action: tensor([[[0.0047, 0.6288],
         [0.0049, 0.3358],
         [0.0053, 0.2315],
         [0.0051, 0.1775]]])
agent 0 action: VehicleControl(throttle=0.241494, steer=0.004759, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.4634640123346
11.785827588289976 seconds in game passed.
Action: tensor([[[0.0047, 0.6288],
         [0.0049, 0.3358],
         [0.0053, 0.2315],
         [0.0051, 0.1775]]])
agent 0 action: VehicleControl(throttle=0.241316, steer=0.004804, brake=0.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 92.4634640123346
+++++++++++++: inf
11.810827588662505 seconds in game passed.
At 11.810827588662505 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0008,  0.6727],
         [ 0.0069,  0.4178],
         [ 0.0116,  0.3124],
         [ 0.0146,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.003961, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4929630538867547
Current mitigation activation: 0
#############################
Total reward: 93.95642706622135
11.835827589035034 seconds in game passed.
Action: tensor([[[-0.0008,  0.6727],
         [ 0.0069,  0.4178],
         [ 0.0116,  0.3124],
         [ 0.0146,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004127, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.95642706622135
11.860827589407563 seconds in game passed.
Action: tensor([[[-0.0008,  0.6727],
         [ 0.0069,  0.4178],
         [ 0.0116,  0.3124],
         [ 0.0146,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004149, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.95642706622135
11.885827589780092 seconds in game passed.
Action: tensor([[[-0.0008,  0.6727],
         [ 0.0069,  0.4178],
         [ 0.0116,  0.3124],
         [ 0.0146,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.004171, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 93.95642706622135
+++++++++++++: inf
11.910827590152621 seconds in game passed.
At 11.910827590152621 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[-0.0009,  0.6999],
         [ 0.0024,  0.4289],
         [ 0.0034,  0.3158],
         [ 0.0050,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.000898, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.4859417303379636
Current mitigation activation: 0
#############################
Total reward: 95.44236879655932
11.93582759052515 seconds in game passed.
Action: tensor([[[-0.0009,  0.6999],
         [ 0.0024,  0.4289],
         [ 0.0034,  0.3158],
         [ 0.0050,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001445, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.44236879655932
11.96082759089768 seconds in game passed.
Action: tensor([[[-0.0009,  0.6999],
         [ 0.0024,  0.4289],
         [ 0.0034,  0.3158],
         [ 0.0050,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001447, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.44236879655932
11.985827591270208 seconds in game passed.
Action: tensor([[[-0.0009,  0.6999],
         [ 0.0024,  0.4289],
         [ 0.0034,  0.3158],
         [ 0.0050,  0.2501]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.001448, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Total reward: 95.44236879655932
+++++++++++++: inf
12.010827591642737 seconds in game passed.
At 12.010827591642737 seconds, saving state-action tuples.
Mitigation action constant threshold: 0
Action: tensor([[[0.0087, 0.8264],
         [0.0101, 0.4957],
         [0.0080, 0.3482],
         [0.0074, 0.2569]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.011449, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
#############################
Current risk: 10.0
Current reward: 1.434596340403309
Current mitigation activation: 0
#############################
Total reward: 96.87696513696262
12.035827592015266 seconds in game passed.
Action: tensor([[[0.0087, 0.8264],
         [0.0101, 0.4957],
         [0.0080, 0.3482],
         [0.0074, 0.2569]]])
agent 0 action: VehicleControl(throttle=0.000000, steer=0.009910, brake=1.000000, hand_brake=False, reverse=False, manual_gear_shift=False, gear=0)
Resetting ego-vehicle!
Total reward: 96.87696513696262
Post-processing after stepping
Simulation done, stopping the scenario
Stopping the route

========= Results of RouteScenario_0 (repetition 0) ------ [91mFAILURE[0m =========

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-11-15 00:40:05 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-11-15 00:40:45 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 39.88s              │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 9.78s               │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.245               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ FAILURE │ 46.64 % │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ SUCCESS │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ FAILURE │ 1 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ SUCCESS │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ SUCCESS │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ SUCCESS │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
Simulation saved.
Registering the global statistics
================= Finish episode 0 =================
Episode: 0, reward: 96.88, average_reward: 96.87696513696262 

Saving mitigation results to //home/sheng/projects/DiverseEnv/auto/mitigationsweep_results_ghost_cutin_acc_only_lbc_ttc/SINGLE_AGENT_fi_ghost_cutin_00004/fi_ghost_cutin_data
